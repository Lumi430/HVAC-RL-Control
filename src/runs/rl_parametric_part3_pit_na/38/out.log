Using TensorFlow backend.
[2019-03-23 08:15:37,695] A3C_AGENT_MAIN INFO:Namespace(action_repeat_n=1, action_space='part3_v1', activation='relu', agent_num=5, check_args_only=False, clip_norm=5.0, debug_log_prob=0.0005, decay_steps=1000000, dropout_prob=0.0, end_e=0.0, env='Part3-NA-Pit-Train-v1', eval_act_func='part3_pit_det_v1', eval_env_res_max_keep=50, eval_epi_num=1, eval_freq=25000, forecast_dim=0, gamma=0.99, h_decay_bounds=[], h_regu_frac=[0.0], init_e=0.0, isNoisyNet=True, isNoisyNetEval_rmNoise=True, is_greedy_policy=False, is_learning_rate_decay_staircase=False, is_warm_start=False, job_mode='Train', learning_rate=0.0005, learning_rate_decay_rate=1.0, learning_rate_decay_steps=100000, max_interactions=2500000, metric_func='part3_v1', model_dir='None', model_param=[256, 8], model_type='nn', num_threads=16, output='./Part3-NA-Pit-Train-v1-res1', p_loss_frac=1.0, raw_state_prcs_func='cslDx_1', reward_func='part3_v3', rmsprop_decay=0.99, rmsprop_epsil=1e-10, rmsprop_momet=0.0, rwd_e_para=1.0, rwd_p_para=1.0, save_freq=500000, save_max_to_keep=5, save_scope='all', sharedNet_type='Dense', state_dim=17, test_env=['Part3-NA-Pit-Test-v1', 'Part3-NA-Pit-Test-v2', 'Part3-NA-Pit-Test-v3', 'Part3-NA-Pit-Test-v4'], test_mode='Multiple', train_act_func='part3_pit_sto_v1', train_freq=5, v_loss_frac=0.5, violation_penalty_scl=50.0, weight_initer='glorot_uniform', window_len=21)
[2019-03-23 08:15:37,695] A3C_AGENT_MAIN INFO:Start compiling...
2019-03-23 08:15:37.784456: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
[2019-03-23 08:16:09,334] A3C_AGENT_MAIN INFO:Start the learning...
[2019-03-23 08:16:09,334] A3C_AGENT_MAIN INFO:Prepare the evaluation environments ['Part3-NA-Pit-Train-v1', 'Part3-NA-Pit-Test-v1', 'Part3-NA-Pit-Test-v2', 'Part3-NA-Pit-Test-v3', 'Part3-NA-Pit-Test-v4'] ...
[2019-03-23 08:16:09,347] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation worker starts!
[2019-03-23 08:16:09,351] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation worker starts!
[2019-03-23 08:16:09,353] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation worker starts!
[2019-03-23 08:16:09,359] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation worker starts!
[2019-03-23 08:16:09,364] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation worker starts!
[2019-03-23 08:16:09,364] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 08:16:09,365] A3C_AGENT_WORKER-Thread-2 INFO:Local worker starts!
[2019-03-23 08:16:09,463] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:16:09,464] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run1
[2019-03-23 08:16:10,366] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 08:16:10,368] A3C_AGENT_WORKER-Thread-3 INFO:Local worker starts!
[2019-03-23 08:16:10,480] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:16:10,481] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run1
[2019-03-23 08:16:11,019] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-23 08:16:11,020] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 08:16:11,020] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 08:16:11,020] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:16:11,021] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:16:11,021] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 08:16:11,024] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:16:11,023] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 08:16:11,024] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 08:16:11,025] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:16:11,025] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:16:11,028] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run1
[2019-03-23 08:16:11,028] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run1
[2019-03-23 08:16:11,041] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run1
[2019-03-23 08:16:11,066] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run1
[2019-03-23 08:16:11,078] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run1
[2019-03-23 08:16:11,369] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 08:16:11,370] A3C_AGENT_WORKER-Thread-9 INFO:Local worker starts!
[2019-03-23 08:16:11,499] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:16:11,500] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run1
[2019-03-23 08:16:12,371] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 08:16:12,373] A3C_AGENT_WORKER-Thread-10 INFO:Local worker starts!
[2019-03-23 08:16:12,820] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:16:12,820] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run1
[2019-03-23 08:16:13,372] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 08:16:13,373] A3C_AGENT_WORKER-Thread-11 INFO:Local worker starts!
[2019-03-23 08:16:13,506] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:16:13,507] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run1
[2019-03-23 08:16:14,374] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 08:16:14,375] A3C_AGENT_WORKER-Thread-12 INFO:Local worker starts!
[2019-03-23 08:16:14,553] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:16:14,571] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run1
[2019-03-23 08:16:15,376] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 08:16:15,380] A3C_AGENT_WORKER-Thread-13 INFO:Local worker starts!
[2019-03-23 08:16:15,491] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:16:15,517] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run1
[2019-03-23 08:16:16,380] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 08:16:16,387] A3C_AGENT_WORKER-Thread-14 INFO:Local worker starts!
[2019-03-23 08:16:16,504] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:16:16,528] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run1
[2019-03-23 08:16:17,387] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 08:16:17,391] A3C_AGENT_WORKER-Thread-15 INFO:Local worker starts!
[2019-03-23 08:16:17,507] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:16:17,535] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run1
[2019-03-23 08:16:18,392] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 08:16:18,402] A3C_AGENT_WORKER-Thread-16 INFO:Local worker starts!
[2019-03-23 08:16:18,520] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:16:18,542] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run1
[2019-03-23 08:16:19,401] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 08:16:19,402] A3C_AGENT_WORKER-Thread-17 INFO:Local worker starts!
[2019-03-23 08:16:19,541] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:16:19,556] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run1
[2019-03-23 08:16:20,404] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 08:16:20,409] A3C_AGENT_WORKER-Thread-18 INFO:Local worker starts!
[2019-03-23 08:16:20,541] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:16:20,560] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run1
[2019-03-23 08:16:21,325] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-23 08:16:21,325] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.6, 33.5, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5807435493137633, 6.9112, 6.9112, 95.55338769695034, 337783.4771016571, 337783.4771016571, 83381.75299718912]
[2019-03-23 08:16:21,326] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 08:16:21,327] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.21874006 0.21671534 0.1909603  0.18290919 0.19067506], sampled 0.30482658253646666
[2019-03-23 08:16:21,409] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 08:16:21,413] A3C_AGENT_WORKER-Thread-19 INFO:Local worker starts!
[2019-03-23 08:16:21,549] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:16:21,572] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run1
[2019-03-23 08:16:22,412] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 08:16:22,422] A3C_AGENT_WORKER-Thread-20 INFO:Local worker starts!
[2019-03-23 08:16:22,564] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:16:22,596] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run1
[2019-03-23 08:16:23,418] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 08:16:23,420] A3C_AGENT_WORKER-Thread-21 INFO:Local worker starts!
[2019-03-23 08:16:23,547] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:16:23,567] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run1
[2019-03-23 08:16:24,421] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 08:16:24,423] A3C_AGENT_WORKER-Thread-22 INFO:Local worker starts!
[2019-03-23 08:16:24,551] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:16:24,577] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run1
[2019-03-23 08:17:25,650] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-23 08:17:25,651] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [17.06666666666667, 76.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4555119487776739, 6.911199999999999, 6.9112, 95.55338769695034, 264927.7584046256, 264927.758404626, 88926.50438848503]
[2019-03-23 08:17:25,654] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 08:17:25,658] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.21811561 0.21645647 0.18729919 0.18647301 0.19165565], sampled 0.8933604406629725
[2019-03-23 08:18:02,268] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 2429.9412 1999560607.7924 938.0000
[2019-03-23 08:18:02,357] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 2687.0870 2069205900.2633 765.0000
[2019-03-23 08:18:02,460] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 2593.1757 1987571277.4793 983.0000
[2019-03-23 08:18:02,603] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2317.2322 2013631506.6093 1214.0000
[2019-03-23 08:18:02,809] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 2500.4832 1982319862.4785 984.0000
[2019-03-23 08:18:03,824] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 0, evaluation results [0.0, 2687.0870207547196, 2069205900.2632732, 765.0, 2500.4832051561125, 1982319862.4784603, 984.0, 2593.1757137628624, 1987571277.4792662, 983.0, 2317.2321525800594, 2013631506.6093218, 1214.0, 2429.9412231243946, 1999560607.7923932, 938.0]
[2019-03-23 08:18:07,568] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.22581616 0.21598797 0.18688242 0.18296964 0.18834384], sum to 1.0000
[2019-03-23 08:18:07,574] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8546
[2019-03-23 08:18:07,736] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [17.2, 92.0, 1.0, 1.0, 0.3385727943037295, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 370374.578998175, 370374.578998175, 114791.4572240693], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 12000.0000, 
sim time next is 12600.0000, 
raw observation next is [17.15, 94.0, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 1.0, 0.3, 6.9112, 6.9112, 77.3421103, 374214.4794066647, 374214.4794066647, 168953.8089198227], 
processed observation next is [1.0, 0.13043478260869565, 0.41590909090909084, 0.94, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 0.5, 0.0, 0.0, 0.0, 0.5085185399722538, 0.13859795533580174, 0.13859795533580174, 0.4120824607800554], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8318707], dtype=float32), -0.27484772]. 
=============================================
[2019-03-23 08:18:08,758] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.2283561  0.22221452 0.18736124 0.16787481 0.1941933 ], sum to 1.0000
[2019-03-23 08:18:08,768] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5733
[2019-03-23 08:18:08,924] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.6, 92.0, 1.0, 2.0, 0.6876764270494387, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354077, 779838.9829769352, 779838.9829769352, 158979.6992821894], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 32400.0000, 
sim time next is 33000.0000, 
raw observation next is [19.83333333333334, 90.5, 1.0, 2.0, 0.3654029454479574, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7254911401248175, 6.9112, 6.9112, 77.32846344354104, 829288.5967694103, 829288.5967694103, 201892.1606800883], 
processed observation next is [1.0, 0.391304347826087, 0.5378787878787882, 0.905, 1.0, 1.0, 0.2067536818099467, 0.0, 1.0, -0.25, 1.0, 0.5, 0.6078444858925965, 0.0, 0.0, 0.5084288129206541, 0.3071439247294112, 0.3071439247294112, 0.49241990409777636], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.7039309], dtype=float32), -0.61364466]. 
=============================================
[2019-03-23 08:18:08,941] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[0.30642176]
 [0.31102875]
 [0.27044347]
 [0.32571688]
 [0.30349776]], R is [[0.32566079]
 [0.32240418]
 [0.76383597]
 [1.37220657]
 [1.35848451]].
[2019-03-23 08:18:12,434] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.9618245e-13 1.0000000e+00 4.9494749e-11 4.7880948e-13 1.6524845e-10], sum to 1.0000
[2019-03-23 08:18:12,445] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1253
[2019-03-23 08:18:12,604] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 211433.679677329, 211433.6796773287, 69934.0541956312], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 100800.0000, 
sim time next is 101400.0000, 
raw observation next is [13.0, 87.00000000000001, 1.0, 2.0, 0.2070469349687024, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 224799.0614036791, 224799.0614036794, 71286.06792038484], 
processed observation next is [1.0, 0.17391304347826086, 0.22727272727272727, 0.8700000000000001, 1.0, 1.0, 0.008808668710878001, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08325891163099226, 0.08325891163099237, 0.17386845834240205], 
reward next is 0.8261, 
noisyNet noise sample is [array([-0.19720632], dtype=float32), 0.026310805]. 
=============================================
[2019-03-23 08:18:15,951] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.7518319e-08 9.9999344e-01 3.3566694e-09 1.1176469e-09 6.5347326e-06], sum to 1.0000
[2019-03-23 08:18:15,958] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8165
[2019-03-23 08:18:16,121] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.33333333333333, 69.0, 1.0, 2.0, 0.2373309832978029, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 257688.3627707408, 257688.3627707406, 77420.80611241696], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 164400.0000, 
sim time next is 165000.0000, 
raw observation next is [16.16666666666667, 70.5, 1.0, 2.0, 0.2346356853069102, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 254761.1055761044, 254761.1055761044, 77207.12887866379], 
processed observation next is [1.0, 0.9130434782608695, 0.37121212121212144, 0.705, 1.0, 1.0, 0.04329460663363774, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09435596502818681, 0.09435596502818681, 0.18831007043576534], 
reward next is 0.8117, 
noisyNet noise sample is [array([0.28754774], dtype=float32), 0.3791535]. 
=============================================
[2019-03-23 08:18:16,158] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[43.1292  ]
 [43.194134]
 [42.935467]
 [42.49306 ]
 [43.027153]], R is [[43.41993332]
 [43.7969017 ]
 [44.16947174]
 [44.5374794 ]
 [44.90116119]].
[2019-03-23 08:18:19,013] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.09198936 0.8983682  0.0019787  0.00262519 0.0050385 ], sum to 1.0000
[2019-03-23 08:18:19,021] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9694
[2019-03-23 08:18:19,032] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 52.33333333333334, 1.0, 2.0, 0.2762553168353845, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 299964.5158720849, 299964.5158720847, 100938.4405289969], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 219000.0000, 
sim time next is 219600.0000, 
raw observation next is [22.0, 50.0, 1.0, 2.0, 0.2786691465589966, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 302586.3242944745, 302586.3242944742, 99888.65233229715], 
processed observation next is [0.0, 0.5652173913043478, 0.6363636363636364, 0.5, 1.0, 1.0, 0.09833643319874574, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11206900899795352, 0.11206900899795341, 0.24363085934706621], 
reward next is 0.7564, 
noisyNet noise sample is [array([0.12414978], dtype=float32), 0.13703462]. 
=============================================
[2019-03-23 08:18:22,982] A3C_AGENT_WORKER-Thread-2 INFO:Local step 500, global step 7865: loss 893.8967
[2019-03-23 08:18:23,080] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 500, global step 7865: learning rate 0.0005
[2019-03-23 08:18:23,117] A3C_AGENT_WORKER-Thread-18 INFO:Local step 500, global step 7891: loss 34.2189
[2019-03-23 08:18:23,118] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 500, global step 7892: learning rate 0.0005
[2019-03-23 08:18:23,213] A3C_AGENT_WORKER-Thread-10 INFO:Local step 500, global step 7945: loss 1.5008
[2019-03-23 08:18:23,216] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 500, global step 7946: learning rate 0.0005
[2019-03-23 08:18:23,246] A3C_AGENT_WORKER-Thread-12 INFO:Local step 500, global step 7960: loss 3.3821
[2019-03-23 08:18:23,249] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 500, global step 7960: learning rate 0.0005
[2019-03-23 08:18:23,275] A3C_AGENT_WORKER-Thread-13 INFO:Local step 500, global step 7974: loss 5.4489
[2019-03-23 08:18:23,278] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 500, global step 7975: learning rate 0.0005
[2019-03-23 08:18:23,289] A3C_AGENT_WORKER-Thread-17 INFO:Local step 500, global step 7984: loss 5.8122
[2019-03-23 08:18:23,292] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 500, global step 7984: learning rate 0.0005
[2019-03-23 08:18:23,308] A3C_AGENT_WORKER-Thread-3 INFO:Local step 500, global step 7992: loss 6.7183
[2019-03-23 08:18:23,310] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 500, global step 7993: learning rate 0.0005
[2019-03-23 08:18:23,330] A3C_AGENT_WORKER-Thread-14 INFO:Local step 500, global step 8004: loss 7.2024
[2019-03-23 08:18:23,330] A3C_AGENT_WORKER-Thread-21 INFO:Local step 500, global step 8004: loss 7.4502
[2019-03-23 08:18:23,332] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 500, global step 8005: learning rate 0.0005
[2019-03-23 08:18:23,332] A3C_AGENT_WORKER-Thread-19 INFO:Local step 500, global step 8006: loss 6.7415
[2019-03-23 08:18:23,334] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 500, global step 8006: learning rate 0.0005
[2019-03-23 08:18:23,337] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 500, global step 8007: learning rate 0.0005
[2019-03-23 08:18:23,350] A3C_AGENT_WORKER-Thread-16 INFO:Local step 500, global step 8014: loss 6.8316
[2019-03-23 08:18:23,353] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 500, global step 8016: learning rate 0.0005
[2019-03-23 08:18:23,356] A3C_AGENT_WORKER-Thread-20 INFO:Local step 500, global step 8017: loss 9.9372
[2019-03-23 08:18:23,359] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 500, global step 8019: learning rate 0.0005
[2019-03-23 08:18:23,372] A3C_AGENT_WORKER-Thread-11 INFO:Local step 500, global step 8024: loss 3.8644
[2019-03-23 08:18:23,373] A3C_AGENT_WORKER-Thread-9 INFO:Local step 500, global step 8024: loss 5.9846
[2019-03-23 08:18:23,374] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 500, global step 8024: learning rate 0.0005
[2019-03-23 08:18:23,375] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 500, global step 8024: learning rate 0.0005
[2019-03-23 08:18:23,388] A3C_AGENT_WORKER-Thread-22 INFO:Local step 500, global step 8032: loss 4.6965
[2019-03-23 08:18:23,390] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 500, global step 8032: learning rate 0.0005
[2019-03-23 08:18:23,410] A3C_AGENT_WORKER-Thread-15 INFO:Local step 500, global step 8042: loss 2.8857
[2019-03-23 08:18:23,411] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 500, global step 8043: learning rate 0.0005
[2019-03-23 08:18:29,290] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 4.0573652e-11 2.4369519e-28 4.5850101e-31 0.0000000e+00], sum to 1.0000
[2019-03-23 08:18:29,300] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1111
[2019-03-23 08:18:29,467] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [15.33333333333333, 78.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3826018613094114, 6.9112, 6.9112, 77.32846344354104, 222524.7884848814, 222524.7884848814, 70656.24650045348], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 420000.0000, 
sim time next is 420600.0000, 
raw observation next is [15.16666666666667, 80.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.381002075769231, 6.911199999999998, 6.9112, 77.32846344354104, 221594.1264428284, 221594.1264428289, 70564.42064186695], 
processed observation next is [1.0, 0.8695652173913043, 0.3257575757575759, 0.8033333333333335, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.11571725109890146, -1.7763568394002506e-16, 0.0, 0.5084288129206541, 0.08207189868252904, 0.08207189868252923, 0.1721083430289438], 
reward next is 0.8279, 
noisyNet noise sample is [array([1.141977], dtype=float32), 0.76150256]. 
=============================================
[2019-03-23 08:18:31,847] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.0476271e-29 1.0000000e+00 2.2262588e-32 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 08:18:31,855] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5424
[2019-03-23 08:18:31,857] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.2577871581723156, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 279905.5844561803, 279905.58445618, 79486.81044573913], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 463200.0000, 
sim time next is 463800.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.283355055667102, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 307676.0177598943, 307676.017759894, 82240.50029306677], 
processed observation next is [1.0, 0.34782608695652173, 0.22727272727272727, 1.0, 1.0, 1.0, 0.1041938195838775, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11395408065181271, 0.1139540806518126, 0.20058658608065066], 
reward next is 0.7994, 
noisyNet noise sample is [array([-2.0062265], dtype=float32), 1.1202778]. 
=============================================
[2019-03-23 08:18:37,934] A3C_AGENT_WORKER-Thread-17 INFO:Local step 1000, global step 15850: loss 0.2110
[2019-03-23 08:18:37,936] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 1000, global step 15850: learning rate 0.0005
[2019-03-23 08:18:37,997] A3C_AGENT_WORKER-Thread-13 INFO:Local step 1000, global step 15881: loss 1.2137
[2019-03-23 08:18:37,998] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 1000, global step 15881: learning rate 0.0005
[2019-03-23 08:18:38,064] A3C_AGENT_WORKER-Thread-2 INFO:Local step 1000, global step 15912: loss 2.0077
[2019-03-23 08:18:38,065] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 1000, global step 15912: learning rate 0.0005
[2019-03-23 08:18:38,083] A3C_AGENT_WORKER-Thread-12 INFO:Local step 1000, global step 15927: loss 1.9255
[2019-03-23 08:18:38,085] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 1000, global step 15927: learning rate 0.0005
[2019-03-23 08:18:38,104] A3C_AGENT_WORKER-Thread-9 INFO:Local step 1000, global step 15940: loss 1.1629
[2019-03-23 08:18:38,105] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 1000, global step 15940: learning rate 0.0005
[2019-03-23 08:18:38,130] A3C_AGENT_WORKER-Thread-21 INFO:Local step 1000, global step 15951: loss 0.8915
[2019-03-23 08:18:38,133] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 1000, global step 15951: learning rate 0.0005
[2019-03-23 08:18:38,134] A3C_AGENT_WORKER-Thread-18 INFO:Local step 1000, global step 15951: loss 0.5279
[2019-03-23 08:18:38,137] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 1000, global step 15951: learning rate 0.0005
[2019-03-23 08:18:38,170] A3C_AGENT_WORKER-Thread-14 INFO:Local step 1000, global step 15969: loss 0.0881
[2019-03-23 08:18:38,175] A3C_AGENT_WORKER-Thread-10 INFO:Local step 1000, global step 15970: loss 0.0308
[2019-03-23 08:18:38,175] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 1000, global step 15970: learning rate 0.0005
[2019-03-23 08:18:38,180] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 1000, global step 15972: learning rate 0.0005
[2019-03-23 08:18:38,180] A3C_AGENT_WORKER-Thread-3 INFO:Local step 1000, global step 15972: loss 0.0986
[2019-03-23 08:18:38,183] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 1000, global step 15972: learning rate 0.0005
[2019-03-23 08:18:38,270] A3C_AGENT_WORKER-Thread-22 INFO:Local step 1000, global step 16028: loss 3.8731
[2019-03-23 08:18:38,274] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 1000, global step 16028: learning rate 0.0005
[2019-03-23 08:18:38,281] A3C_AGENT_WORKER-Thread-20 INFO:Local step 1000, global step 16031: loss 4.9273
[2019-03-23 08:18:38,282] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 1000, global step 16031: learning rate 0.0005
[2019-03-23 08:18:38,330] A3C_AGENT_WORKER-Thread-19 INFO:Local step 1000, global step 16054: loss 10.0628
[2019-03-23 08:18:38,333] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 1000, global step 16054: learning rate 0.0005
[2019-03-23 08:18:38,360] A3C_AGENT_WORKER-Thread-16 INFO:Local step 1000, global step 16073: loss 7.9248
[2019-03-23 08:18:38,362] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 1000, global step 16073: learning rate 0.0005
[2019-03-23 08:18:38,392] A3C_AGENT_WORKER-Thread-15 INFO:Local step 1000, global step 16093: loss 3.8071
[2019-03-23 08:18:38,395] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 1000, global step 16093: learning rate 0.0005
[2019-03-23 08:18:38,624] A3C_AGENT_WORKER-Thread-11 INFO:Local step 1000, global step 16215: loss 2.6673
[2019-03-23 08:18:38,626] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 1000, global step 16216: learning rate 0.0005
[2019-03-23 08:18:48,226] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.0773526e-07 9.9999833e-01 1.4189274e-06 1.5884384e-08 3.1673081e-11], sum to 1.0000
[2019-03-23 08:18:48,233] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8539
[2019-03-23 08:18:48,403] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.33333333333334, 93.00000000000001, 1.0, 2.0, 0.3886544649159174, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 438634.255897726, 438634.2558977258, 124204.0760112324], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 799800.0000, 
sim time next is 800400.0000, 
raw observation next is [19.66666666666667, 92.0, 1.0, 2.0, 0.3950171694603548, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 446675.0952701232, 446675.0952701232, 125276.7800462557], 
processed observation next is [0.0, 0.2608695652173913, 0.5303030303030305, 0.92, 1.0, 1.0, 0.2437714618254435, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.165435220470416, 0.165435220470416, 0.3055531220640383], 
reward next is 0.6944, 
noisyNet noise sample is [array([0.6986638], dtype=float32), -2.7753081]. 
=============================================
[2019-03-23 08:18:51,362] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.3362494e-19 1.0000000e+00 1.6661257e-13 3.1582588e-22 3.0765500e-32], sum to 1.0000
[2019-03-23 08:18:51,369] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8636
[2019-03-23 08:18:51,372] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.16666666666667, 87.16666666666667, 1.0, 2.0, 0.4076093213860184, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 460796.874983707, 460796.8749837073, 126362.7373423741], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 861000.0000, 
sim time next is 861600.0000, 
raw observation next is [20.33333333333334, 86.33333333333334, 1.0, 2.0, 0.4074473655745044, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 460845.7517401295, 460845.7517401298, 126487.5470642552], 
processed observation next is [0.0, 1.0, 0.5606060606060609, 0.8633333333333334, 1.0, 1.0, 0.2593092069681305, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1706836117556035, 0.17068361175560362, 0.30850621235184195], 
reward next is 0.6915, 
noisyNet noise sample is [array([-1.1264337], dtype=float32), -0.46220207]. 
=============================================
[2019-03-23 08:18:52,750] A3C_AGENT_WORKER-Thread-2 INFO:Local step 1500, global step 23742: loss 0.1101
[2019-03-23 08:18:52,753] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 1500, global step 23742: learning rate 0.0005
[2019-03-23 08:18:52,925] A3C_AGENT_WORKER-Thread-14 INFO:Local step 1500, global step 23841: loss 1.2277
[2019-03-23 08:18:52,928] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 1500, global step 23842: learning rate 0.0005
[2019-03-23 08:18:52,938] A3C_AGENT_WORKER-Thread-17 INFO:Local step 1500, global step 23847: loss 1.2394
[2019-03-23 08:18:52,938] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 1500, global step 23847: learning rate 0.0005
[2019-03-23 08:18:52,980] A3C_AGENT_WORKER-Thread-13 INFO:Local step 1500, global step 23866: loss 0.2411
[2019-03-23 08:18:52,985] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 1500, global step 23869: learning rate 0.0005
[2019-03-23 08:18:53,098] A3C_AGENT_WORKER-Thread-15 INFO:Local step 1500, global step 23935: loss 1.0428
[2019-03-23 08:18:53,102] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 1500, global step 23937: learning rate 0.0005
[2019-03-23 08:18:53,111] A3C_AGENT_WORKER-Thread-9 INFO:Local step 1500, global step 23941: loss 0.4972
[2019-03-23 08:18:53,112] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 1500, global step 23941: learning rate 0.0005
[2019-03-23 08:18:53,128] A3C_AGENT_WORKER-Thread-3 INFO:Local step 1500, global step 23947: loss 1.3169
[2019-03-23 08:18:53,129] A3C_AGENT_WORKER-Thread-12 INFO:Local step 1500, global step 23947: loss 1.4888
[2019-03-23 08:18:53,129] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 1500, global step 23947: learning rate 0.0005
[2019-03-23 08:18:53,130] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 1500, global step 23947: learning rate 0.0005
[2019-03-23 08:18:53,235] A3C_AGENT_WORKER-Thread-10 INFO:Local step 1500, global step 24008: loss 2.6005
[2019-03-23 08:18:53,236] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 1500, global step 24008: learning rate 0.0005
[2019-03-23 08:18:53,259] A3C_AGENT_WORKER-Thread-18 INFO:Local step 1500, global step 24019: loss 0.4024
[2019-03-23 08:18:53,261] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 1500, global step 24019: learning rate 0.0005
[2019-03-23 08:18:53,272] A3C_AGENT_WORKER-Thread-16 INFO:Local step 1500, global step 24024: loss 0.0002
[2019-03-23 08:18:53,274] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 1500, global step 24025: learning rate 0.0005
[2019-03-23 08:18:53,311] A3C_AGENT_WORKER-Thread-21 INFO:Local step 1500, global step 24041: loss 0.0168
[2019-03-23 08:18:53,313] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 1500, global step 24041: learning rate 0.0005
[2019-03-23 08:18:53,436] A3C_AGENT_WORKER-Thread-20 INFO:Local step 1500, global step 24111: loss 1.2461
[2019-03-23 08:18:53,437] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 1500, global step 24111: learning rate 0.0005
[2019-03-23 08:18:53,473] A3C_AGENT_WORKER-Thread-19 INFO:Local step 1500, global step 24128: loss 0.7866
[2019-03-23 08:18:53,474] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 1500, global step 24128: learning rate 0.0005
[2019-03-23 08:18:53,575] A3C_AGENT_WORKER-Thread-22 INFO:Local step 1500, global step 24190: loss 0.0793
[2019-03-23 08:18:53,577] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 1500, global step 24191: learning rate 0.0005
[2019-03-23 08:18:53,707] A3C_AGENT_WORKER-Thread-11 INFO:Local step 1500, global step 24258: loss 2.6705
[2019-03-23 08:18:53,711] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 1500, global step 24258: learning rate 0.0005
[2019-03-23 08:18:54,863] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.1013949e-21 1.0000000e+00 3.5435529e-21 2.3934189e-22 2.8638802e-30], sum to 1.0000
[2019-03-23 08:18:54,872] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6830
[2019-03-23 08:18:55,044] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 88.0, 1.0, 2.0, 0.4378720403501203, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 498184.193366529, 498184.193366529, 131505.2734807484], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 930000.0000, 
sim time next is 930600.0000, 
raw observation next is [21.0, 88.0, 1.0, 2.0, 0.4375236906570158, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 497789.0445275598, 497789.0445275598, 131471.3767264673], 
processed observation next is [0.0, 0.782608695652174, 0.5909090909090909, 0.88, 1.0, 1.0, 0.2969046133212697, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1843663127879851, 0.1843663127879851, 0.3206618944547983], 
reward next is 0.6793, 
noisyNet noise sample is [array([-0.9002242], dtype=float32), 0.986046]. 
=============================================
[2019-03-23 08:18:55,242] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 08:18:55,245] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 08:18:55,245] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:18:55,245] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 08:18:55,247] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 08:18:55,248] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 08:18:55,249] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:18:55,249] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:18:55,249] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:18:55,246] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 08:18:55,250] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:18:55,259] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run2
[2019-03-23 08:18:55,286] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run2
[2019-03-23 08:18:55,287] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run2
[2019-03-23 08:18:55,331] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run2
[2019-03-23 08:18:55,352] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run2
[2019-03-23 08:19:09,453] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.03390959], dtype=float32), 0.25111118]
[2019-03-23 08:19:09,455] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.2, 85.5, 1.0, 2.0, 0.4348879384593666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 494435.3207284831, 494435.3207284828, 135232.2891662579]
[2019-03-23 08:19:09,456] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 08:19:09,459] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.5361320e-15 1.0000000e+00 1.9970813e-11 1.1757499e-17 2.8048054e-22], sampled 0.607083035680851
[2019-03-23 08:19:10,542] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.03390959], dtype=float32), 0.25111118]
[2019-03-23 08:19:10,542] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.83333333333333, 100.0, 1.0, 2.0, 0.3716101287131086, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 416083.393605339, 416083.3936053393, 121010.1344459227]
[2019-03-23 08:19:10,544] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 08:19:10,547] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [6.5416510e-14 1.0000000e+00 1.2750404e-10 2.2303399e-16 1.1806426e-20], sampled 0.711112554158103
[2019-03-23 08:19:31,304] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.03390959], dtype=float32), 0.25111118]
[2019-03-23 08:19:31,307] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.14604605, 74.41963345, 1.0, 2.0, 0.4761868958539186, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 543294.9129870702, 543294.9129870698, 142800.0237411215]
[2019-03-23 08:19:31,309] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 08:19:31,312] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.6749971e-14 1.0000000e+00 8.2703178e-11 1.1218577e-16 4.9300687e-21], sampled 0.6527995006925102
[2019-03-23 08:20:26,647] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.03390959], dtype=float32), 0.25111118]
[2019-03-23 08:20:26,648] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.74453102666667, 100.0, 1.0, 2.0, 0.6075811110672802, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 693313.8594166455, 693313.8594166455, 158494.3135716578]
[2019-03-23 08:20:26,651] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 08:20:26,655] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.7602684e-14 1.0000000e+00 6.6711803e-11 7.9763412e-17 3.1959399e-21], sampled 0.14098041304222053
[2019-03-23 08:20:34,080] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.03390959], dtype=float32), 0.25111118]
[2019-03-23 08:20:34,081] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [16.8, 71.0, 1.0, 2.0, 0.2217075685327303, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 240709.2706587401, 240709.2706587405, 82804.03148278945]
[2019-03-23 08:20:34,082] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 08:20:34,085] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.8838346e-13 1.0000000e+00 2.8207889e-10 7.8663855e-16 5.8585144e-20], sampled 0.5160198735068264
[2019-03-23 08:20:38,462] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 08:20:38,505] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 08:20:38,623] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 08:20:38,672] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 08:20:38,741] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 08:20:39,756] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 25000, evaluation results [25000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 08:20:40,324] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.9747396e-11 1.0000000e+00 3.3002557e-08 1.2601579e-12 5.5626301e-17], sum to 1.0000
[2019-03-23 08:20:40,335] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1630
[2019-03-23 08:20:40,509] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 96.0, 1.0, 2.0, 0.389337202288077, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 439558.2539451619, 439558.2539451616, 124352.0307693779], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 955200.0000, 
sim time next is 955800.0000, 
raw observation next is [19.0, 97.0, 1.0, 2.0, 0.3915963763625777, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 442564.1240064517, 442564.124006452, 124819.8444274072], 
processed observation next is [1.0, 0.043478260869565216, 0.5, 0.97, 1.0, 1.0, 0.23949547045322211, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16391263852090804, 0.16391263852090815, 0.3044386449448956], 
reward next is 0.6956, 
noisyNet noise sample is [array([-0.46879247], dtype=float32), 1.0856528]. 
=============================================
[2019-03-23 08:20:41,424] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.9493735e-22 1.0000000e+00 3.0939669e-18 9.6837239e-23 2.3366108e-30], sum to 1.0000
[2019-03-23 08:20:41,430] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1107
[2019-03-23 08:20:41,435] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.4069752088150342, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 461346.7336140961, 461346.7336140964, 127112.2223812859], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 963600.0000, 
sim time next is 964200.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4037840598119037, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 457721.0301406559, 457721.0301406559, 126807.5164927755], 
processed observation next is [1.0, 0.13043478260869565, 0.5, 1.0, 1.0, 1.0, 0.2547300747648796, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16952630745950217, 0.16952630745950217, 0.3092866255921354], 
reward next is 0.6907, 
noisyNet noise sample is [array([0.76901597], dtype=float32), -0.5110309]. 
=============================================
[2019-03-23 08:20:41,940] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.2344355e-24 1.0000000e+00 5.5732447e-19 8.2555892e-28 3.1731035e-35], sum to 1.0000
[2019-03-23 08:20:41,948] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9559
[2019-03-23 08:20:42,104] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.5122294378509219, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 575616.6160294965, 575616.6160294965, 134999.3452137524], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 982800.0000, 
sim time next is 983400.0000, 
raw observation next is [17.83333333333333, 100.0, 1.0, 2.0, 0.6203586964080868, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 696488.7595957062, 696488.7595957065, 146640.0992897169], 
processed observation next is [1.0, 0.391304347826087, 0.44696969696969674, 1.0, 1.0, 1.0, 0.5254483705101085, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.25795879985026154, 0.25795879985026166, 0.357658778755407], 
reward next is 0.6423, 
noisyNet noise sample is [array([-0.94692296], dtype=float32), 0.36856765]. 
=============================================
[2019-03-23 08:20:46,282] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0264685e-09 1.0000000e+00 2.4410101e-08 1.2324092e-19 7.9041717e-22], sum to 1.0000
[2019-03-23 08:20:46,291] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8690
[2019-03-23 08:20:46,295] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 94.0, 1.0, 2.0, 0.4627171722405037, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 502533.8085797434, 502533.8085797434, 98787.29578845794], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1056000.0000, 
sim time next is 1056600.0000, 
raw observation next is [13.0, 94.0, 1.0, 2.0, 0.4691761297639991, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 509552.2333683389, 509552.2333683389, 100010.083905165], 
processed observation next is [1.0, 0.21739130434782608, 0.22727272727272727, 0.94, 1.0, 1.0, 0.3364701622049988, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18872304939568108, 0.18872304939568108, 0.2439270339150366], 
reward next is 0.7561, 
noisyNet noise sample is [array([1.6581287], dtype=float32), -0.044408266]. 
=============================================
[2019-03-23 08:20:46,348] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.4530127e-07 9.9999690e-01 2.8344496e-06 1.6945190e-13 2.6486842e-18], sum to 1.0000
[2019-03-23 08:20:46,352] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0226
[2019-03-23 08:20:46,507] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.5, 77.0, 1.0, 2.0, 0.3534146249946202, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 383778.9665277968, 383778.9665277968, 94094.37026729199], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1067400.0000, 
sim time next is 1068000.0000, 
raw observation next is [16.66666666666666, 77.0, 1.0, 2.0, 0.3526856106255759, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 382987.0056267598, 382987.0056267595, 95616.84493501695], 
processed observation next is [1.0, 0.34782608695652173, 0.39393939393939365, 0.77, 1.0, 1.0, 0.19085701328196986, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14184703912102214, 0.14184703912102203, 0.2332118169146755], 
reward next is 0.7668, 
noisyNet noise sample is [array([-0.77354777], dtype=float32), 0.98548836]. 
=============================================
[2019-03-23 08:20:46,528] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[48.546516]
 [48.480843]
 [48.442314]
 [48.394993]
 [48.32959 ]], R is [[48.84985352]
 [49.13185501]
 [49.43253708]
 [49.74399567]
 [50.05658722]].
[2019-03-23 08:20:51,549] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.8222288e-10 1.0000000e+00 1.7232926e-12 6.6673898e-22 5.7326486e-30], sum to 1.0000
[2019-03-23 08:20:51,553] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2935
[2019-03-23 08:20:51,718] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 99.0, 1.0, 2.0, 0.3661890346864636, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 410372.3726361143, 410372.3726361143, 120725.5950456322], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1147800.0000, 
sim time next is 1148400.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.3687835925934727, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 413830.4518646052, 413830.4518646052, 121206.4192798456], 
processed observation next is [1.0, 0.30434782608695654, 0.45454545454545453, 1.0, 1.0, 1.0, 0.21097949074184086, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15327053772763155, 0.15327053772763155, 0.2956254128776722], 
reward next is 0.7044, 
noisyNet noise sample is [array([-1.3403385], dtype=float32), 1.486317]. 
=============================================
[2019-03-23 08:20:53,505] A3C_AGENT_WORKER-Thread-2 INFO:Local step 2000, global step 31734: loss 0.9817
[2019-03-23 08:20:53,507] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 2000, global step 31734: learning rate 0.0005
[2019-03-23 08:20:53,551] A3C_AGENT_WORKER-Thread-14 INFO:Local step 2000, global step 31755: loss 0.6420
[2019-03-23 08:20:53,554] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 2000, global step 31756: learning rate 0.0005
[2019-03-23 08:20:53,860] A3C_AGENT_WORKER-Thread-13 INFO:Local step 2000, global step 31914: loss 1.0521
[2019-03-23 08:20:53,861] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 2000, global step 31914: learning rate 0.0005
[2019-03-23 08:20:53,864] A3C_AGENT_WORKER-Thread-15 INFO:Local step 2000, global step 31914: loss 1.1273
[2019-03-23 08:20:53,869] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 2000, global step 31918: learning rate 0.0005
[2019-03-23 08:20:53,871] A3C_AGENT_WORKER-Thread-17 INFO:Local step 2000, global step 31919: loss 1.0748
[2019-03-23 08:20:53,872] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 2000, global step 31919: learning rate 0.0005
[2019-03-23 08:20:53,897] A3C_AGENT_WORKER-Thread-18 INFO:Local step 2000, global step 31932: loss 1.4135
[2019-03-23 08:20:53,899] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 2000, global step 31932: learning rate 0.0005
[2019-03-23 08:20:53,920] A3C_AGENT_WORKER-Thread-12 INFO:Local step 2000, global step 31946: loss 1.2061
[2019-03-23 08:20:53,923] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 2000, global step 31948: learning rate 0.0005
[2019-03-23 08:20:53,945] A3C_AGENT_WORKER-Thread-10 INFO:Local step 2000, global step 31959: loss 1.0127
[2019-03-23 08:20:53,950] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 2000, global step 31960: learning rate 0.0005
[2019-03-23 08:20:53,967] A3C_AGENT_WORKER-Thread-9 INFO:Local step 2000, global step 31970: loss 0.7692
[2019-03-23 08:20:53,968] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 2000, global step 31970: learning rate 0.0005
[2019-03-23 08:20:53,988] A3C_AGENT_WORKER-Thread-3 INFO:Local step 2000, global step 31977: loss 0.5151
[2019-03-23 08:20:53,989] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 2000, global step 31978: learning rate 0.0005
[2019-03-23 08:20:54,005] A3C_AGENT_WORKER-Thread-16 INFO:Local step 2000, global step 31987: loss 0.3269
[2019-03-23 08:20:54,012] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 2000, global step 31990: learning rate 0.0005
[2019-03-23 08:20:54,128] A3C_AGENT_WORKER-Thread-21 INFO:Local step 2000, global step 32043: loss 0.0346
[2019-03-23 08:20:54,129] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 2000, global step 32044: learning rate 0.0005
[2019-03-23 08:20:54,341] A3C_AGENT_WORKER-Thread-20 INFO:Local step 2000, global step 32143: loss 0.0078
[2019-03-23 08:20:54,343] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 2000, global step 32144: learning rate 0.0005
[2019-03-23 08:20:54,410] A3C_AGENT_WORKER-Thread-19 INFO:Local step 2000, global step 32175: loss 0.4336
[2019-03-23 08:20:54,413] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 2000, global step 32175: learning rate 0.0005
[2019-03-23 08:20:54,446] A3C_AGENT_WORKER-Thread-11 INFO:Local step 2000, global step 32189: loss 0.9336
[2019-03-23 08:20:54,449] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 2000, global step 32191: learning rate 0.0005
[2019-03-23 08:20:54,527] A3C_AGENT_WORKER-Thread-22 INFO:Local step 2000, global step 32229: loss 1.0272
[2019-03-23 08:20:54,528] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 2000, global step 32229: learning rate 0.0005
[2019-03-23 08:20:59,650] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.2296129e-17 1.0000000e+00 1.7154923e-29 3.2338464e-29 3.4474586e-36], sum to 1.0000
[2019-03-23 08:20:59,657] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4804
[2019-03-23 08:20:59,664] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.3944510228895281, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 442886.4674956352, 442886.4674956352, 123533.9798800577], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1312800.0000, 
sim time next is 1313400.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.3899382528635771, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 437812.0924361501, 437812.0924361504, 123135.3189202837], 
processed observation next is [1.0, 0.17391304347826086, 0.45454545454545453, 1.0, 1.0, 1.0, 0.23742281607947133, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16215262682820375, 0.16215262682820386, 0.3003300461470334], 
reward next is 0.6997, 
noisyNet noise sample is [array([-0.11791016], dtype=float32), -0.09054065]. 
=============================================
[2019-03-23 08:21:08,426] A3C_AGENT_WORKER-Thread-2 INFO:Local step 2500, global step 39678: loss 0.7151
[2019-03-23 08:21:08,428] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 2500, global step 39679: learning rate 0.0005
[2019-03-23 08:21:08,436] A3C_AGENT_WORKER-Thread-14 INFO:Local step 2500, global step 39682: loss 0.7602
[2019-03-23 08:21:08,437] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 2500, global step 39682: learning rate 0.0005
[2019-03-23 08:21:08,752] A3C_AGENT_WORKER-Thread-15 INFO:Local step 2500, global step 39851: loss 1.2265
[2019-03-23 08:21:08,754] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 2500, global step 39851: learning rate 0.0005
[2019-03-23 08:21:08,815] A3C_AGENT_WORKER-Thread-12 INFO:Local step 2500, global step 39891: loss 0.6073
[2019-03-23 08:21:08,816] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 2500, global step 39891: learning rate 0.0005
[2019-03-23 08:21:08,832] A3C_AGENT_WORKER-Thread-9 INFO:Local step 2500, global step 39898: loss 0.2704
[2019-03-23 08:21:08,833] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 2500, global step 39899: learning rate 0.0005
[2019-03-23 08:21:08,851] A3C_AGENT_WORKER-Thread-3 INFO:Local step 2500, global step 39909: loss 0.1488
[2019-03-23 08:21:08,856] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 2500, global step 39909: learning rate 0.0005
[2019-03-23 08:21:08,899] A3C_AGENT_WORKER-Thread-13 INFO:Local step 2500, global step 39931: loss 0.0366
[2019-03-23 08:21:08,901] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 2500, global step 39932: learning rate 0.0005
[2019-03-23 08:21:08,945] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.7830029e-09 1.0000000e+00 2.5251483e-08 1.2256167e-10 1.1770788e-16], sum to 1.0000
[2019-03-23 08:21:08,952] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8376
[2019-03-23 08:21:09,130] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.5, 84.0, 1.0, 2.0, 0.5974324199609771, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 671715.9862289042, 671715.9862289042, 158462.398007246], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1503000.0000, 
sim time next is 1503600.0000, 
raw observation next is [25.66666666666666, 82.33333333333334, 1.0, 2.0, 0.5935527365367729, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 667883.7677019787, 667883.7677019787, 157815.4811854893], 
processed observation next is [0.0, 0.391304347826087, 0.8030303030303028, 0.8233333333333335, 1.0, 1.0, 0.49194092067096606, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.24736435840814025, 0.24736435840814025, 0.3849158077694861], 
reward next is 0.6151, 
noisyNet noise sample is [array([-0.08036298], dtype=float32), 1.9701703]. 
=============================================
[2019-03-23 08:21:09,159] A3C_AGENT_WORKER-Thread-16 INFO:Local step 2500, global step 39989: loss 0.8317
[2019-03-23 08:21:09,161] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 2500, global step 39990: learning rate 0.0005
[2019-03-23 08:21:09,182] A3C_AGENT_WORKER-Thread-17 INFO:Local step 2500, global step 39997: loss 0.6285
[2019-03-23 08:21:09,186] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 2500, global step 39997: learning rate 0.0005
[2019-03-23 08:21:09,223] A3C_AGENT_WORKER-Thread-18 INFO:Local step 2500, global step 40020: loss 0.3190
[2019-03-23 08:21:09,226] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 2500, global step 40021: learning rate 0.0005
[2019-03-23 08:21:09,261] A3C_AGENT_WORKER-Thread-21 INFO:Local step 2500, global step 40044: loss 0.1928
[2019-03-23 08:21:09,263] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 2500, global step 40044: learning rate 0.0005
[2019-03-23 08:21:09,306] A3C_AGENT_WORKER-Thread-10 INFO:Local step 2500, global step 40068: loss 0.0233
[2019-03-23 08:21:09,308] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 2500, global step 40068: learning rate 0.0005
[2019-03-23 08:21:09,546] A3C_AGENT_WORKER-Thread-11 INFO:Local step 2500, global step 40192: loss 0.3371
[2019-03-23 08:21:09,548] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 2500, global step 40193: learning rate 0.0005
[2019-03-23 08:21:09,594] A3C_AGENT_WORKER-Thread-19 INFO:Local step 2500, global step 40220: loss 0.0042
[2019-03-23 08:21:09,599] A3C_AGENT_WORKER-Thread-22 INFO:Local step 2500, global step 40222: loss 0.0400
[2019-03-23 08:21:09,601] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 2500, global step 40220: learning rate 0.0005
[2019-03-23 08:21:09,602] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 2500, global step 40222: learning rate 0.0005
[2019-03-23 08:21:09,641] A3C_AGENT_WORKER-Thread-20 INFO:Local step 2500, global step 40240: loss 0.1683
[2019-03-23 08:21:09,644] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 2500, global step 40240: learning rate 0.0005
[2019-03-23 08:21:10,764] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.53238141e-12 1.00000000e+00 1.13712115e-08 5.69556104e-11
 3.65959076e-16], sum to 1.0000
[2019-03-23 08:21:10,771] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1909
[2019-03-23 08:21:10,776] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.66666666666667, 81.66666666666666, 1.0, 2.0, 0.5486318106611606, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 622792.6811689954, 622792.6811689954, 150123.8438584058], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1536000.0000, 
sim time next is 1536600.0000, 
raw observation next is [24.33333333333333, 82.33333333333334, 1.0, 2.0, 0.5381323357092795, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 611718.4280815541, 611718.4280815541, 148368.3345876704], 
processed observation next is [0.0, 0.782608695652174, 0.7424242424242422, 0.8233333333333335, 1.0, 1.0, 0.42266541963659937, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22656238077094598, 0.22656238077094598, 0.3618739867991961], 
reward next is 0.6381, 
noisyNet noise sample is [array([1.6348641], dtype=float32), -0.23419867]. 
=============================================
[2019-03-23 08:21:11,727] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.2345395e-20 1.0000000e+00 1.4114711e-20 4.6643536e-19 2.2846692e-38], sum to 1.0000
[2019-03-23 08:21:11,732] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5157
[2019-03-23 08:21:11,740] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 94.0, 1.0, 2.0, 0.412955182398388, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 469165.8246442732, 469165.8246442734, 128449.9064680853], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1562400.0000, 
sim time next is 1563000.0000, 
raw observation next is [19.83333333333334, 95.0, 1.0, 2.0, 0.5099828593899987, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 579380.6536630861, 579380.6536630865, 138402.8237227538], 
processed observation next is [1.0, 0.08695652173913043, 0.5378787878787882, 0.95, 1.0, 1.0, 0.38747857423749826, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2145854272826245, 0.2145854272826246, 0.3375678627384239], 
reward next is 0.6624, 
noisyNet noise sample is [array([-0.47056112], dtype=float32), -0.81105703]. 
=============================================
[2019-03-23 08:21:11,751] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[104.72373 ]
 [104.18517 ]
 [104.568275]
 [104.63141 ]
 [105.05697 ]], R is [[104.12766266]
 [103.77309418]
 [103.42137146]
 [103.07250214]
 [102.72652435]].
[2019-03-23 08:21:15,370] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.4046614e-11 1.0000000e+00 3.8472230e-14 2.2769460e-13 1.0928749e-19], sum to 1.0000
[2019-03-23 08:21:15,375] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5615
[2019-03-23 08:21:15,380] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.66666666666667, 74.66666666666667, 1.0, 2.0, 0.4640807395772344, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 529430.5931707681, 529430.5931707685, 136189.1764070894], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1624200.0000, 
sim time next is 1624800.0000, 
raw observation next is [23.33333333333333, 75.33333333333334, 1.0, 2.0, 0.4592532968938258, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 523719.6431292801, 523719.6431292804, 135194.9351128834], 
processed observation next is [1.0, 0.8260869565217391, 0.6969696969696968, 0.7533333333333334, 1.0, 1.0, 0.32406662111728224, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19397023819602968, 0.1939702381960298, 0.32974374417776436], 
reward next is 0.6703, 
noisyNet noise sample is [array([-1.1427352], dtype=float32), 0.4785666]. 
=============================================
[2019-03-23 08:21:18,055] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.783511e-19 1.000000e+00 7.063903e-23 2.394272e-19 1.212897e-31], sum to 1.0000
[2019-03-23 08:21:18,062] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4362
[2019-03-23 08:21:18,067] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.18333333333333, 71.83333333333334, 1.0, 2.0, 0.6388633438977361, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 695493.0893424724, 695493.0893424724, 140913.6150191073], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1685400.0000, 
sim time next is 1686000.0000, 
raw observation next is [19.36666666666667, 70.66666666666667, 1.0, 2.0, 0.5036255290950755, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 547858.7142007984, 547858.7142007984, 127462.320786668], 
processed observation next is [1.0, 0.5217391304347826, 0.5166666666666668, 0.7066666666666667, 1.0, 1.0, 0.37953191136884434, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2029106348891846, 0.2029106348891846, 0.31088370923577563], 
reward next is 0.6891, 
noisyNet noise sample is [array([-0.3628398], dtype=float32), -1.1763864]. 
=============================================
[2019-03-23 08:21:18,089] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[82.247  ]
 [82.23879]
 [82.32457]
 [82.35674]
 [82.41249]], R is [[82.09740448]
 [81.93273926]
 [81.76864624]
 [81.60379028]
 [81.43817139]].
[2019-03-23 08:21:21,401] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.2873797e-09 1.0000000e+00 1.2859165e-09 1.9565520e-09 2.4504690e-13], sum to 1.0000
[2019-03-23 08:21:21,409] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5529
[2019-03-23 08:21:21,587] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [8.5, 84.0, 1.0, 2.0, 0.3421907114532287, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 371586.0704050267, 371586.070405027, 78956.60495387542], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1747800.0000, 
sim time next is 1748400.0000, 
raw observation next is [8.666666666666668, 83.0, 1.0, 2.0, 0.3453730981471897, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 375043.1677610659, 375043.1677610659, 79193.31962710316], 
processed observation next is [1.0, 0.21739130434782608, 0.030303030303030356, 0.83, 1.0, 1.0, 0.1817163726839871, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13890487694854292, 0.13890487694854292, 0.19315443811488575], 
reward next is 0.8068, 
noisyNet noise sample is [array([0.00894986], dtype=float32), -0.9772245]. 
=============================================
[2019-03-23 08:21:23,081] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.1621141e-27 1.0000000e+00 1.6618584e-26 7.2981960e-26 0.0000000e+00], sum to 1.0000
[2019-03-23 08:21:23,090] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4686
[2019-03-23 08:21:23,096] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.83333333333333, 45.83333333333334, 1.0, 2.0, 0.3844151422960067, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 417457.408161063, 417457.4081610627, 90212.16523025754], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1777800.0000, 
sim time next is 1778400.0000, 
raw observation next is [19.0, 46.0, 1.0, 2.0, 0.4015797214394307, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 436105.7222723926, 436105.7222723926, 92330.19911958734], 
processed observation next is [1.0, 0.6086956521739131, 0.5, 0.46, 1.0, 1.0, 0.25197465179928835, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16152063787866391, 0.16152063787866391, 0.22519560760874963], 
reward next is 0.7748, 
noisyNet noise sample is [array([-0.41926056], dtype=float32), -0.39276898]. 
=============================================
[2019-03-23 08:21:23,521] A3C_AGENT_WORKER-Thread-2 INFO:Local step 3000, global step 47641: loss 0.4947
[2019-03-23 08:21:23,523] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 3000, global step 47643: learning rate 0.0005
[2019-03-23 08:21:23,750] A3C_AGENT_WORKER-Thread-14 INFO:Local step 3000, global step 47766: loss 2.1507
[2019-03-23 08:21:23,751] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 3000, global step 47766: learning rate 0.0005
[2019-03-23 08:21:23,847] A3C_AGENT_WORKER-Thread-13 INFO:Local step 3000, global step 47817: loss 0.0129
[2019-03-23 08:21:23,848] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 3000, global step 47817: learning rate 0.0005
[2019-03-23 08:21:23,867] A3C_AGENT_WORKER-Thread-9 INFO:Local step 3000, global step 47828: loss 0.1857
[2019-03-23 08:21:23,869] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 3000, global step 47829: learning rate 0.0005
[2019-03-23 08:21:23,914] A3C_AGENT_WORKER-Thread-15 INFO:Local step 3000, global step 47852: loss 0.3363
[2019-03-23 08:21:23,917] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 3000, global step 47853: learning rate 0.0005
[2019-03-23 08:21:24,080] A3C_AGENT_WORKER-Thread-12 INFO:Local step 3000, global step 47943: loss 0.4339
[2019-03-23 08:21:24,081] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 3000, global step 47943: learning rate 0.0005
[2019-03-23 08:21:24,102] A3C_AGENT_WORKER-Thread-17 INFO:Local step 3000, global step 47954: loss 0.2752
[2019-03-23 08:21:24,104] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 3000, global step 47954: learning rate 0.0005
[2019-03-23 08:21:24,108] A3C_AGENT_WORKER-Thread-21 INFO:Local step 3000, global step 47955: loss 0.1815
[2019-03-23 08:21:24,109] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 3000, global step 47956: learning rate 0.0005
[2019-03-23 08:21:24,157] A3C_AGENT_WORKER-Thread-3 INFO:Local step 3000, global step 47984: loss 0.0007
[2019-03-23 08:21:24,159] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 3000, global step 47986: learning rate 0.0005
[2019-03-23 08:21:24,180] A3C_AGENT_WORKER-Thread-16 INFO:Local step 3000, global step 47998: loss 0.0325
[2019-03-23 08:21:24,182] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 3000, global step 47998: learning rate 0.0005
[2019-03-23 08:21:24,300] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.03427358e-20 1.00000000e+00 7.20106506e-28 1.31345735e-23
 1.78216466e-35], sum to 1.0000
[2019-03-23 08:21:24,307] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2544
[2019-03-23 08:21:24,479] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.16666666666666, 41.66666666666666, 1.0, 2.0, 0.410639195345552, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 445948.6006704398, 445948.6006704395, 92095.49763571196], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1788600.0000, 
sim time next is 1789200.0000, 
raw observation next is [19.2, 42.0, 1.0, 2.0, 0.4233775248051172, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 459788.7952596688, 459788.7952596688, 93519.65853064683], 
processed observation next is [1.0, 0.7391304347826086, 0.509090909090909, 0.42, 1.0, 1.0, 0.27922190600639646, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17029214639246992, 0.17029214639246992, 0.22809672812352885], 
reward next is 0.7719, 
noisyNet noise sample is [array([1.1926419], dtype=float32), -0.7292691]. 
=============================================
[2019-03-23 08:21:24,497] A3C_AGENT_WORKER-Thread-18 INFO:Local step 3000, global step 48086: loss 0.7883
[2019-03-23 08:21:24,499] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 3000, global step 48086: learning rate 0.0005
[2019-03-23 08:21:24,548] A3C_AGENT_WORKER-Thread-10 INFO:Local step 3000, global step 48110: loss 0.0403
[2019-03-23 08:21:24,551] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 3000, global step 48111: learning rate 0.0005
[2019-03-23 08:21:24,594] A3C_AGENT_WORKER-Thread-22 INFO:Local step 3000, global step 48134: loss 0.2388
[2019-03-23 08:21:24,597] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 3000, global step 48135: learning rate 0.0005
[2019-03-23 08:21:24,685] A3C_AGENT_WORKER-Thread-20 INFO:Local step 3000, global step 48183: loss 1.1224
[2019-03-23 08:21:24,687] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 3000, global step 48183: learning rate 0.0005
[2019-03-23 08:21:24,704] A3C_AGENT_WORKER-Thread-11 INFO:Local step 3000, global step 48193: loss 1.0194
[2019-03-23 08:21:24,708] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 3000, global step 48193: learning rate 0.0005
[2019-03-23 08:21:25,061] A3C_AGENT_WORKER-Thread-19 INFO:Local step 3000, global step 48385: loss 0.2592
[2019-03-23 08:21:25,063] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 3000, global step 48385: learning rate 0.0005
[2019-03-23 08:21:26,426] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.3997411e-24 1.0000000e+00 2.3406252e-30 8.1587631e-26 0.0000000e+00], sum to 1.0000
[2019-03-23 08:21:26,433] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2482
[2019-03-23 08:21:26,437] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [10.16666666666667, 100.0, 1.0, 2.0, 0.3499604760790149, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 380026.5815595462, 380026.5815595462, 82564.1849590038], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1833000.0000, 
sim time next is 1833600.0000, 
raw observation next is [10.33333333333333, 100.0, 1.0, 2.0, 0.3432035036269434, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 372686.2863741116, 372686.2863741119, 82229.50418580184], 
processed observation next is [1.0, 0.21739130434782608, 0.10606060606060592, 1.0, 1.0, 1.0, 0.17900437953367923, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13803195791633763, 0.13803195791633774, 0.20055976630683375], 
reward next is 0.7994, 
noisyNet noise sample is [array([0.07792086], dtype=float32), -0.69225436]. 
=============================================
[2019-03-23 08:21:27,301] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.8998226e-15 1.0000000e+00 1.6861915e-15 4.8778515e-16 6.9760189e-22], sum to 1.0000
[2019-03-23 08:21:27,308] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4597
[2019-03-23 08:21:27,312] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.66666666666667, 70.33333333333334, 1.0, 2.0, 0.2060546303461906, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 223721.4291835121, 223721.4291835118, 72896.2643062065], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1842600.0000, 
sim time next is 1843200.0000, 
raw observation next is [16.0, 68.0, 1.0, 2.0, 0.209392923091588, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 227346.7889397249, 227346.7889397249, 73326.79340555574], 
processed observation next is [1.0, 0.34782608695652173, 0.36363636363636365, 0.68, 1.0, 1.0, 0.01174115386448498, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08420251442212033, 0.08420251442212033, 0.1788458375745262], 
reward next is 0.8212, 
noisyNet noise sample is [array([-2.0540073], dtype=float32), 1.478721]. 
=============================================
[2019-03-23 08:21:28,043] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-23 08:21:28,044] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 08:21:28,045] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 08:21:28,046] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:21:28,046] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 08:21:28,046] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:21:28,047] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 08:21:28,046] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:21:28,050] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:21:28,052] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 08:21:28,053] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:21:28,064] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run3
[2019-03-23 08:21:28,089] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run3
[2019-03-23 08:21:28,122] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run3
[2019-03-23 08:21:28,123] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run3
[2019-03-23 08:21:28,168] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run3
[2019-03-23 08:21:33,489] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.07420736], dtype=float32), -0.14123508]
[2019-03-23 08:21:33,491] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.6, 66.0, 1.0, 2.0, 0.5616842239295922, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 632486.4442445417, 632486.4442445413, 145236.2493952943]
[2019-03-23 08:21:33,492] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 08:21:33,494] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.71756587e-23 1.00000000e+00 1.11207324e-26 4.87358344e-27
 2.36279184e-38], sampled 0.6499612199505452
[2019-03-23 08:21:41,045] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.07420736], dtype=float32), -0.14123508]
[2019-03-23 08:21:41,046] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.95, 63.83333333333333, 1.0, 2.0, 0.795645133266174, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769694995, 907215.9829364752, 907215.9829364748, 183032.1764846341]
[2019-03-23 08:21:41,047] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 08:21:41,049] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [7.6954447e-26 1.0000000e+00 1.3167894e-29 5.2635048e-30 0.0000000e+00], sampled 0.3166256842497216
[2019-03-23 08:21:57,589] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.07420736], dtype=float32), -0.14123508]
[2019-03-23 08:21:57,591] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [14.8431952, 62.15630336, 1.0, 2.0, 0.3554416261292284, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 385951.7803768946, 385951.7803768943, 88738.86582526895]
[2019-03-23 08:21:57,593] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 08:21:57,594] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.5319662e-22 1.0000000e+00 8.1063340e-26 3.6502307e-26 4.2331554e-37], sampled 0.4297100143493847
[2019-03-23 08:21:59,333] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.07420736], dtype=float32), -0.14123508]
[2019-03-23 08:21:59,334] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [11.97339778666667, 98.18552894000001, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 211000.3545588302, 211000.3545588302, 74210.51618863216]
[2019-03-23 08:21:59,337] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 08:21:59,341] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.9090873e-23 1.0000000e+00 1.6884862e-26 7.4419936e-27 4.3340188e-38], sampled 0.5436136714909044
[2019-03-23 08:22:29,975] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.07420736], dtype=float32), -0.14123508]
[2019-03-23 08:22:29,976] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.80051765333334, 93.01679027666667, 1.0, 2.0, 0.5268025725126904, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 599798.4825139538, 599798.4825139538, 150590.2189657486]
[2019-03-23 08:22:29,977] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 08:22:29,982] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.3347522e-23 1.0000000e+00 4.9143188e-27 2.1298014e-27 0.0000000e+00], sampled 0.04711856176224827
[2019-03-23 08:22:58,316] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.07420736], dtype=float32), -0.14123508]
[2019-03-23 08:22:58,318] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.45, 73.0, 1.0, 2.0, 0.4134665287067218, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 468802.7765014977, 468802.7765014977, 127791.8315022377]
[2019-03-23 08:22:58,319] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 08:22:58,323] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.4135524e-23 1.0000000e+00 1.9410798e-26 8.5716316e-27 5.3069919e-38], sampled 0.3313819850927521
[2019-03-23 08:23:10,499] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 08:23:11,075] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 08:23:11,492] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 08:23:11,494] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 08:23:11,564] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 08:23:12,581] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 50000, evaluation results [50000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 08:23:16,017] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.3768761e-10 1.0000000e+00 2.0504548e-11 1.7816358e-11 5.8433236e-17], sum to 1.0000
[2019-03-23 08:23:16,028] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7950
[2019-03-23 08:23:16,192] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333333, 81.33333333333334, 1.0, 2.0, 0.4723539522334876, 1.0, 2.0, 0.4723539522334876, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1074389.862327146, 1074389.862327146, 224660.5103044359], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1938000.0000, 
sim time next is 1938600.0000, 
raw observation next is [23.0, 83.0, 1.0, 2.0, 0.8901530883288699, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1015724.393968171, 1015724.393968172, 198914.2887999599], 
processed observation next is [1.0, 0.43478260869565216, 0.6818181818181818, 0.83, 1.0, 1.0, 0.8626913604110872, 0.0, 0.5, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.37619421998821145, 0.37619421998821184, 0.4851568019511217], 
reward next is 0.5148, 
noisyNet noise sample is [array([0.6382559], dtype=float32), 0.37829977]. 
=============================================
[2019-03-23 08:23:18,811] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.2251771e-20 1.0000000e+00 5.9898418e-24 1.3487597e-25 4.6971949e-32], sum to 1.0000
[2019-03-23 08:23:18,820] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4837
[2019-03-23 08:23:18,836] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333334, 65.33333333333334, 1.0, 2.0, 0.3173956146958047, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 345646.0006601858, 345646.0006601858, 112716.6564474112], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1984800.0000, 
sim time next is 1985400.0000, 
raw observation next is [20.0, 66.0, 1.0, 2.0, 0.311930846753211, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 338715.3350989922, 338715.3350989919, 111998.6333007394], 
processed observation next is [1.0, 1.0, 0.5454545454545454, 0.66, 1.0, 1.0, 0.1399135584415137, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12545012411073786, 0.12545012411073775, 0.27316739829448633], 
reward next is 0.7268, 
noisyNet noise sample is [array([-0.5906517], dtype=float32), 0.3405906]. 
=============================================
[2019-03-23 08:23:18,988] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.3044555e-14 1.0000000e+00 1.0496543e-17 1.0526371e-18 3.1583536e-23], sum to 1.0000
[2019-03-23 08:23:18,995] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7865
[2019-03-23 08:23:19,161] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 72.0, 1.0, 2.0, 0.2384804911919785, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 258936.8034661715, 258936.8034661712, 81579.20791616393], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2002800.0000, 
sim time next is 2003400.0000, 
raw observation next is [17.0, 72.0, 1.0, 2.0, 0.2381053513689479, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 258529.3767500604, 258529.3767500601, 81542.21114237112], 
processed observation next is [0.0, 0.17391304347826086, 0.4090909090909091, 0.72, 1.0, 1.0, 0.04763168921118485, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09575162101854089, 0.09575162101854078, 0.19888344181066125], 
reward next is 0.8011, 
noisyNet noise sample is [array([-0.67365795], dtype=float32), -0.4040612]. 
=============================================
[2019-03-23 08:23:19,162] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.1063072e-17 1.0000000e+00 5.2858836e-21 6.8568258e-20 1.5637720e-24], sum to 1.0000
[2019-03-23 08:23:19,169] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7033
[2019-03-23 08:23:19,178] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.5, 62.0, 1.0, 2.0, 0.2601335005053269, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 282453.9853835198, 282453.9853835196, 84691.84510582272], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1992600.0000, 
sim time next is 1993200.0000, 
raw observation next is [18.33333333333334, 62.66666666666667, 1.0, 2.0, 0.2573277988460951, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 279406.6683137975, 279406.6683137972, 84026.98504326218], 
processed observation next is [0.0, 0.043478260869565216, 0.46969696969696995, 0.6266666666666667, 1.0, 1.0, 0.07165974855761884, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10348395122733241, 0.1034839512273323, 0.20494386595917605], 
reward next is 0.7951, 
noisyNet noise sample is [array([0.19874938], dtype=float32), -0.7350087]. 
=============================================
[2019-03-23 08:23:20,530] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.8218265e-20 1.0000000e+00 4.5851465e-25 1.5597379e-25 5.8947051e-32], sum to 1.0000
[2019-03-23 08:23:20,540] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6248
[2019-03-23 08:23:20,554] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.83333333333333, 72.83333333333333, 1.0, 2.0, 0.2603491062534438, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 282688.1589960076, 282688.1589960073, 90490.30569922097], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2015400.0000, 
sim time next is 2016000.0000, 
raw observation next is [18.0, 73.0, 1.0, 2.0, 0.2657255221651049, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 288527.6257487519, 288527.6257487519, 93000.2557368444], 
processed observation next is [0.0, 0.34782608695652173, 0.45454545454545453, 0.73, 1.0, 1.0, 0.08215690270638114, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10686208361064886, 0.10686208361064886, 0.2268298920410839], 
reward next is 0.7732, 
noisyNet noise sample is [array([-1.9843084], dtype=float32), -0.55413187]. 
=============================================
[2019-03-23 08:23:20,573] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[81.224525]
 [81.225685]
 [81.22521 ]
 [81.22389 ]
 [81.229546]], R is [[81.18602753]
 [81.15345764]
 [81.1267395 ]
 [81.10544586]
 [81.08903503]].
[2019-03-23 08:23:23,956] A3C_AGENT_WORKER-Thread-2 INFO:Local step 3500, global step 55666: loss 0.6917
[2019-03-23 08:23:23,958] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 3500, global step 55666: learning rate 0.0005
[2019-03-23 08:23:24,066] A3C_AGENT_WORKER-Thread-9 INFO:Local step 3500, global step 55721: loss 0.0319
[2019-03-23 08:23:24,068] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 3500, global step 55721: learning rate 0.0005
[2019-03-23 08:23:24,143] A3C_AGENT_WORKER-Thread-14 INFO:Local step 3500, global step 55764: loss 0.0035
[2019-03-23 08:23:24,151] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 3500, global step 55765: learning rate 0.0005
[2019-03-23 08:23:24,165] A3C_AGENT_WORKER-Thread-13 INFO:Local step 3500, global step 55772: loss 0.0900
[2019-03-23 08:23:24,167] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 3500, global step 55773: learning rate 0.0005
[2019-03-23 08:23:24,173] A3C_AGENT_WORKER-Thread-15 INFO:Local step 3500, global step 55776: loss 0.2300
[2019-03-23 08:23:24,176] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 3500, global step 55776: learning rate 0.0005
[2019-03-23 08:23:24,308] A3C_AGENT_WORKER-Thread-12 INFO:Local step 3500, global step 55845: loss 0.6472
[2019-03-23 08:23:24,309] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 3500, global step 55845: learning rate 0.0005
[2019-03-23 08:23:24,375] A3C_AGENT_WORKER-Thread-21 INFO:Local step 3500, global step 55876: loss 0.1309
[2019-03-23 08:23:24,377] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 3500, global step 55876: learning rate 0.0005
[2019-03-23 08:23:24,540] A3C_AGENT_WORKER-Thread-17 INFO:Local step 3500, global step 55963: loss 0.5811
[2019-03-23 08:23:24,541] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 3500, global step 55963: learning rate 0.0005
[2019-03-23 08:23:24,611] A3C_AGENT_WORKER-Thread-3 INFO:Local step 3500, global step 55999: loss 0.5263
[2019-03-23 08:23:24,612] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 3500, global step 55999: learning rate 0.0005
[2019-03-23 08:23:24,716] A3C_AGENT_WORKER-Thread-16 INFO:Local step 3500, global step 56050: loss 0.0071
[2019-03-23 08:23:24,718] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 3500, global step 56050: learning rate 0.0005
[2019-03-23 08:23:24,843] A3C_AGENT_WORKER-Thread-18 INFO:Local step 3500, global step 56117: loss 0.2957
[2019-03-23 08:23:24,846] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 3500, global step 56117: learning rate 0.0005
[2019-03-23 08:23:24,968] A3C_AGENT_WORKER-Thread-22 INFO:Local step 3500, global step 56183: loss 0.1192
[2019-03-23 08:23:24,973] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 3500, global step 56183: learning rate 0.0005
[2019-03-23 08:23:24,976] A3C_AGENT_WORKER-Thread-11 INFO:Local step 3500, global step 56185: loss 0.0230
[2019-03-23 08:23:24,977] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 3500, global step 56186: learning rate 0.0005
[2019-03-23 08:23:25,063] A3C_AGENT_WORKER-Thread-10 INFO:Local step 3500, global step 56230: loss 0.3048
[2019-03-23 08:23:25,066] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 3500, global step 56231: learning rate 0.0005
[2019-03-23 08:23:25,113] A3C_AGENT_WORKER-Thread-20 INFO:Local step 3500, global step 56256: loss 0.5501
[2019-03-23 08:23:25,119] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 3500, global step 56260: learning rate 0.0005
[2019-03-23 08:23:25,411] A3C_AGENT_WORKER-Thread-19 INFO:Local step 3500, global step 56405: loss 0.0361
[2019-03-23 08:23:25,414] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 3500, global step 56406: learning rate 0.0005
[2019-03-23 08:23:36,977] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.1193262e-14 1.0000000e+00 4.3775970e-18 1.0114730e-19 1.9239429e-23], sum to 1.0000
[2019-03-23 08:23:36,982] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3138
[2019-03-23 08:23:36,986] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 68.0, 1.0, 2.0, 0.2205755736313416, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 239491.2566475902, 239491.2566475899, 74455.54298275789], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2332800.0000, 
sim time next is 2333400.0000, 
raw observation next is [15.83333333333333, 67.83333333333334, 1.0, 2.0, 0.2186108599945439, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 237357.5364908737, 237357.5364908734, 73831.94150852397], 
processed observation next is [1.0, 0.0, 0.3560606060606059, 0.6783333333333335, 1.0, 1.0, 0.023263574993179874, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08791019870032359, 0.08791019870032349, 0.18007790611835114], 
reward next is 0.8199, 
noisyNet noise sample is [array([0.6839588], dtype=float32), -0.122853935]. 
=============================================
[2019-03-23 08:23:39,123] A3C_AGENT_WORKER-Thread-2 INFO:Local step 4000, global step 63646: loss 0.5169
[2019-03-23 08:23:39,127] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 4000, global step 63646: learning rate 0.0005
[2019-03-23 08:23:39,241] A3C_AGENT_WORKER-Thread-14 INFO:Local step 4000, global step 63709: loss 0.6155
[2019-03-23 08:23:39,246] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 4000, global step 63709: learning rate 0.0005
[2019-03-23 08:23:39,355] A3C_AGENT_WORKER-Thread-9 INFO:Local step 4000, global step 63768: loss 0.0478
[2019-03-23 08:23:39,358] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 4000, global step 63769: learning rate 0.0005
[2019-03-23 08:23:39,414] A3C_AGENT_WORKER-Thread-13 INFO:Local step 4000, global step 63803: loss 0.0072
[2019-03-23 08:23:39,416] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 4000, global step 63804: learning rate 0.0005
[2019-03-23 08:23:39,449] A3C_AGENT_WORKER-Thread-15 INFO:Local step 4000, global step 63821: loss 0.0817
[2019-03-23 08:23:39,452] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 4000, global step 63821: learning rate 0.0005
[2019-03-23 08:23:39,485] A3C_AGENT_WORKER-Thread-12 INFO:Local step 4000, global step 63840: loss 0.0631
[2019-03-23 08:23:39,486] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 4000, global step 63840: learning rate 0.0005
[2019-03-23 08:23:39,593] A3C_AGENT_WORKER-Thread-21 INFO:Local step 4000, global step 63901: loss 0.0744
[2019-03-23 08:23:39,596] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 4000, global step 63901: learning rate 0.0005
[2019-03-23 08:23:39,699] A3C_AGENT_WORKER-Thread-3 INFO:Local step 4000, global step 63954: loss 0.6112
[2019-03-23 08:23:39,700] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 4000, global step 63955: learning rate 0.0005
[2019-03-23 08:23:39,755] A3C_AGENT_WORKER-Thread-17 INFO:Local step 4000, global step 63986: loss 0.2163
[2019-03-23 08:23:39,756] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 4000, global step 63986: learning rate 0.0005
[2019-03-23 08:23:39,894] A3C_AGENT_WORKER-Thread-16 INFO:Local step 4000, global step 64059: loss 0.0015
[2019-03-23 08:23:39,897] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 4000, global step 64060: learning rate 0.0005
[2019-03-23 08:23:39,959] A3C_AGENT_WORKER-Thread-18 INFO:Local step 4000, global step 64093: loss 0.1809
[2019-03-23 08:23:39,960] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 4000, global step 64093: learning rate 0.0005
[2019-03-23 08:23:40,027] A3C_AGENT_WORKER-Thread-11 INFO:Local step 4000, global step 64128: loss 0.4460
[2019-03-23 08:23:40,029] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 4000, global step 64128: learning rate 0.0005
[2019-03-23 08:23:40,082] A3C_AGENT_WORKER-Thread-22 INFO:Local step 4000, global step 64164: loss 0.0912
[2019-03-23 08:23:40,084] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 4000, global step 64165: learning rate 0.0005
[2019-03-23 08:23:40,112] A3C_AGENT_WORKER-Thread-20 INFO:Local step 4000, global step 64175: loss 0.0046
[2019-03-23 08:23:40,114] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 4000, global step 64175: learning rate 0.0005
[2019-03-23 08:23:40,381] A3C_AGENT_WORKER-Thread-10 INFO:Local step 4000, global step 64327: loss 0.1655
[2019-03-23 08:23:40,385] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 4000, global step 64328: learning rate 0.0005
[2019-03-23 08:23:40,469] A3C_AGENT_WORKER-Thread-19 INFO:Local step 4000, global step 64375: loss 0.0017
[2019-03-23 08:23:40,471] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 4000, global step 64375: learning rate 0.0005
[2019-03-23 08:23:41,253] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.4855863e-16 1.0000000e+00 1.0987128e-22 7.8139972e-21 1.6504812e-25], sum to 1.0000
[2019-03-23 08:23:41,261] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2566
[2019-03-23 08:23:41,265] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 75.33333333333334, 1.0, 2.0, 0.2540425226789548, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 275838.5020329688, 275838.5020329691, 85707.86874591075], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2416800.0000, 
sim time next is 2417400.0000, 
raw observation next is [17.0, 74.5, 1.0, 2.0, 0.2501152400782953, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 271573.0814764421, 271573.0814764421, 84603.72091446], 
processed observation next is [1.0, 1.0, 0.4090909090909091, 0.745, 1.0, 1.0, 0.06264405009786908, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10058262276905264, 0.10058262276905264, 0.2063505388157561], 
reward next is 0.7936, 
noisyNet noise sample is [array([0.9869817], dtype=float32), -1.7488093]. 
=============================================
[2019-03-23 08:23:44,357] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.7914113e-19 1.0000000e+00 1.2073906e-22 4.4217953e-22 1.2805481e-29], sum to 1.0000
[2019-03-23 08:23:44,367] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7131
[2019-03-23 08:23:44,373] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 94.0, 1.0, 2.0, 0.3012578984077333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 327122.0373559705, 327122.0373559702, 103211.974961835], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2484000.0000, 
sim time next is 2484600.0000, 
raw observation next is [15.66666666666667, 94.00000000000001, 1.0, 2.0, 0.2966320176110366, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 322097.3435833154, 322097.3435833157, 97884.5525967625], 
processed observation next is [1.0, 0.782608695652174, 0.3484848484848486, 0.9400000000000002, 1.0, 1.0, 0.12079002201379571, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11929531243826495, 0.11929531243826508, 0.23874281121161586], 
reward next is 0.7613, 
noisyNet noise sample is [array([0.5058412], dtype=float32), 0.44857696]. 
=============================================
[2019-03-23 08:23:51,554] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.1801515e-13 1.0000000e+00 9.3692888e-17 9.6180015e-17 2.2253892e-20], sum to 1.0000
[2019-03-23 08:23:51,564] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6144
[2019-03-23 08:23:51,571] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 37.0, 1.0, 2.0, 0.3548203289164971, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 397382.0300030187, 397382.0300030187, 119665.7505308666], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2646000.0000, 
sim time next is 2646600.0000, 
raw observation next is [28.0, 37.5, 1.0, 2.0, 0.3554009396028049, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 398341.6981399563, 398341.6981399563, 119860.7068228203], 
processed observation next is [0.0, 0.6521739130434783, 0.9090909090909091, 0.375, 1.0, 1.0, 0.1942511745035061, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14753396227405788, 0.14753396227405788, 0.29234318737273246], 
reward next is 0.7077, 
noisyNet noise sample is [array([0.3579113], dtype=float32), -0.5374671]. 
=============================================
[2019-03-23 08:23:51,836] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.3134117e-16 1.0000000e+00 1.1035777e-21 7.4831524e-21 1.1131859e-25], sum to 1.0000
[2019-03-23 08:23:51,842] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0807
[2019-03-23 08:23:51,847] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 39.5, 1.0, 2.0, 0.3687702926333499, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 415201.942525901, 415201.9425259013, 121908.8533715636], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2649000.0000, 
sim time next is 2649600.0000, 
raw observation next is [28.0, 40.0, 1.0, 2.0, 0.3717038527936875, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 418934.3603253736, 418934.3603253736, 122391.5708868516], 
processed observation next is [0.0, 0.6956521739130435, 0.9090909090909091, 0.4, 1.0, 1.0, 0.21462981599210937, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1551608741945828, 0.1551608741945828, 0.29851602655329657], 
reward next is 0.7015, 
noisyNet noise sample is [array([0.13872305], dtype=float32), 0.14716372]. 
=============================================
[2019-03-23 08:23:54,137] A3C_AGENT_WORKER-Thread-9 INFO:Local step 4500, global step 71715: loss 0.1587
[2019-03-23 08:23:54,140] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 4500, global step 71716: learning rate 0.0005
[2019-03-23 08:23:54,149] A3C_AGENT_WORKER-Thread-2 INFO:Local step 4500, global step 71717: loss 0.2686
[2019-03-23 08:23:54,154] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 4500, global step 71717: learning rate 0.0005
[2019-03-23 08:23:54,253] A3C_AGENT_WORKER-Thread-15 INFO:Local step 4500, global step 71777: loss 0.0163
[2019-03-23 08:23:54,254] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 4500, global step 71778: learning rate 0.0005
[2019-03-23 08:23:54,263] A3C_AGENT_WORKER-Thread-3 INFO:Local step 4500, global step 71782: loss 0.0186
[2019-03-23 08:23:54,265] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 4500, global step 71782: learning rate 0.0005
[2019-03-23 08:23:54,268] A3C_AGENT_WORKER-Thread-14 INFO:Local step 4500, global step 71783: loss 0.0092
[2019-03-23 08:23:54,270] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 4500, global step 71784: learning rate 0.0005
[2019-03-23 08:23:54,371] A3C_AGENT_WORKER-Thread-21 INFO:Local step 4500, global step 71841: loss 0.0530
[2019-03-23 08:23:54,372] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 4500, global step 71841: learning rate 0.0005
[2019-03-23 08:23:54,376] A3C_AGENT_WORKER-Thread-12 INFO:Local step 4500, global step 71844: loss 0.0285
[2019-03-23 08:23:54,381] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 4500, global step 71844: learning rate 0.0005
[2019-03-23 08:23:54,400] A3C_AGENT_WORKER-Thread-13 INFO:Local step 4500, global step 71853: loss 0.0955
[2019-03-23 08:23:54,403] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 4500, global step 71856: learning rate 0.0005
[2019-03-23 08:23:54,799] A3C_AGENT_WORKER-Thread-18 INFO:Local step 4500, global step 72060: loss 0.0431
[2019-03-23 08:23:54,800] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 4500, global step 72060: learning rate 0.0005
[2019-03-23 08:23:54,856] A3C_AGENT_WORKER-Thread-16 INFO:Local step 4500, global step 72095: loss 0.0077
[2019-03-23 08:23:54,858] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 4500, global step 72095: learning rate 0.0005
[2019-03-23 08:23:54,873] A3C_AGENT_WORKER-Thread-22 INFO:Local step 4500, global step 72109: loss 0.0021
[2019-03-23 08:23:54,877] A3C_AGENT_WORKER-Thread-17 INFO:Local step 4500, global step 72109: loss 0.0048
[2019-03-23 08:23:54,881] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 4500, global step 72110: learning rate 0.0005
[2019-03-23 08:23:54,881] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 4500, global step 72110: learning rate 0.0005
[2019-03-23 08:23:55,003] A3C_AGENT_WORKER-Thread-20 INFO:Local step 4500, global step 72175: loss 0.2520
[2019-03-23 08:23:55,006] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 4500, global step 72175: learning rate 0.0005
[2019-03-23 08:23:55,054] A3C_AGENT_WORKER-Thread-11 INFO:Local step 4500, global step 72205: loss 0.2376
[2019-03-23 08:23:55,055] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 4500, global step 72205: learning rate 0.0005
[2019-03-23 08:23:55,250] A3C_AGENT_WORKER-Thread-10 INFO:Local step 4500, global step 72302: loss 0.0213
[2019-03-23 08:23:55,252] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 4500, global step 72304: learning rate 0.0005
[2019-03-23 08:23:55,561] A3C_AGENT_WORKER-Thread-19 INFO:Local step 4500, global step 72474: loss 0.2526
[2019-03-23 08:23:55,563] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 4500, global step 72474: learning rate 0.0005
[2019-03-23 08:24:00,229] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-23 08:24:00,230] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 08:24:00,231] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:24:00,231] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 08:24:00,233] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 08:24:00,234] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 08:24:00,235] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 08:24:00,235] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:24:00,235] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:24:00,235] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:24:00,237] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:24:00,248] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run4
[2019-03-23 08:24:00,273] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run4
[2019-03-23 08:24:00,274] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run4
[2019-03-23 08:24:00,274] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run4
[2019-03-23 08:24:00,345] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run4
[2019-03-23 08:24:08,186] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.07420736], dtype=float32), -0.35710022]
[2019-03-23 08:24:08,186] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [13.4, 74.0, 1.0, 2.0, 0.3292476631519601, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 65.76411637765484, 357549.1179292198, 357549.11792922, 75117.31295743243]
[2019-03-23 08:24:08,187] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 08:24:08,192] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.0372248e-10 1.0000000e+00 8.1686855e-14 8.5117663e-14 7.4165332e-15], sampled 0.9581108610337113
[2019-03-23 08:25:30,998] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.07420736], dtype=float32), -0.35710022]
[2019-03-23 08:25:30,999] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [26.84467475333334, 61.46946661333333, 1.0, 2.0, 0.5027232239446977, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 573314.0720626302, 573314.0720626299, 146622.605642371]
[2019-03-23 08:25:31,001] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 08:25:31,005] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.0372248e-10 1.0000000e+00 8.1686855e-14 8.5117663e-14 7.4165332e-15], sampled 0.5915680009760994
[2019-03-23 08:25:43,084] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 08:25:43,507] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 08:25:43,509] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 08:25:43,529] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 08:25:43,632] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 08:25:44,648] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 75000, evaluation results [75000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 08:25:48,148] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.6152462e-16 1.0000000e+00 1.4130489e-21 4.6803547e-21 5.7869523e-26], sum to 1.0000
[2019-03-23 08:25:48,158] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1387
[2019-03-23 08:25:48,164] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 88.0, 1.0, 2.0, 0.4238502852571249, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 482199.2471648498, 482199.2471648498, 130078.3477696952], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2871000.0000, 
sim time next is 2871600.0000, 
raw observation next is [21.0, 88.0, 1.0, 2.0, 0.4219262756220962, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 480006.6243122802, 480006.6243122802, 129885.383497385], 
processed observation next is [1.0, 0.21739130434782608, 0.5909090909090909, 0.88, 1.0, 1.0, 0.27740784452762024, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17778023122677045, 0.17778023122677045, 0.31679361828630487], 
reward next is 0.6832, 
noisyNet noise sample is [array([0.97243565], dtype=float32), -1.0463159]. 
=============================================
[2019-03-23 08:25:50,690] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.5461970e-27 1.0000000e+00 2.6318164e-30 4.2333578e-33 4.6107944e-38], sum to 1.0000
[2019-03-23 08:25:50,697] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7344
[2019-03-23 08:25:50,700] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.16666666666667, 88.0, 1.0, 2.0, 0.5241531962662077, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 597054.4613144645, 597054.4613144647, 145788.1152929548], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2922600.0000, 
sim time next is 2923200.0000, 
raw observation next is [23.0, 89.0, 1.0, 2.0, 0.5227978844806147, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 595584.5439143927, 595584.543914393, 145556.2947145735], 
processed observation next is [1.0, 0.8695652173913043, 0.6818181818181818, 0.89, 1.0, 1.0, 0.4034973556007683, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22058686811644174, 0.22058686811644188, 0.3550153529623744], 
reward next is 0.6450, 
noisyNet noise sample is [array([2.2025077], dtype=float32), -0.8453779]. 
=============================================
[2019-03-23 08:25:53,909] A3C_AGENT_WORKER-Thread-2 INFO:Local step 5000, global step 79708: loss -40.1140
[2019-03-23 08:25:53,914] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 5000, global step 79708: learning rate 0.0005
[2019-03-23 08:25:54,110] A3C_AGENT_WORKER-Thread-15 INFO:Local step 5000, global step 79754: loss 63.3183
[2019-03-23 08:25:54,115] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 5000, global step 79754: learning rate 0.0005
[2019-03-23 08:25:54,121] A3C_AGENT_WORKER-Thread-14 INFO:Local step 5000, global step 79755: loss -45.0332
[2019-03-23 08:25:54,236] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 5000, global step 79758: learning rate 0.0005
[2019-03-23 08:25:54,477] A3C_AGENT_WORKER-Thread-3 INFO:Local step 5000, global step 79825: loss 38.6442
[2019-03-23 08:25:54,479] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 5000, global step 79826: learning rate 0.0005
[2019-03-23 08:25:54,626] A3C_AGENT_WORKER-Thread-21 INFO:Local step 5000, global step 79845: loss -37.8188
[2019-03-23 08:25:54,628] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 5000, global step 79845: learning rate 0.0005
[2019-03-23 08:25:54,767] A3C_AGENT_WORKER-Thread-12 INFO:Local step 5000, global step 79861: loss 62.6087
[2019-03-23 08:25:54,773] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 5000, global step 79862: learning rate 0.0005
[2019-03-23 08:25:54,775] A3C_AGENT_WORKER-Thread-9 INFO:Local step 5000, global step 79862: loss -13.1447
[2019-03-23 08:25:54,890] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 5000, global step 79862: learning rate 0.0005
[2019-03-23 08:25:55,120] A3C_AGENT_WORKER-Thread-13 INFO:Local step 5000, global step 79923: loss 11.2604
[2019-03-23 08:25:55,125] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 5000, global step 79925: learning rate 0.0005
[2019-03-23 08:25:55,306] A3C_AGENT_WORKER-Thread-16 INFO:Local step 5000, global step 79963: loss 53.1110
[2019-03-23 08:25:55,308] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 5000, global step 79963: learning rate 0.0005
[2019-03-23 08:25:55,549] A3C_AGENT_WORKER-Thread-18 INFO:Local step 5000, global step 80032: loss 35.9551
[2019-03-23 08:25:55,551] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 5000, global step 80033: learning rate 0.0005
[2019-03-23 08:25:55,703] A3C_AGENT_WORKER-Thread-22 INFO:Local step 5000, global step 80055: loss -43.2699
[2019-03-23 08:25:55,706] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 5000, global step 80055: learning rate 0.0005
[2019-03-23 08:25:56,014] A3C_AGENT_WORKER-Thread-20 INFO:Local step 5000, global step 80152: loss 1.0628
[2019-03-23 08:25:56,017] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 5000, global step 80154: learning rate 0.0005
[2019-03-23 08:25:56,203] A3C_AGENT_WORKER-Thread-11 INFO:Local step 5000, global step 80193: loss 19.4958
[2019-03-23 08:25:56,204] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 5000, global step 80193: learning rate 0.0005
[2019-03-23 08:25:56,364] A3C_AGENT_WORKER-Thread-17 INFO:Local step 5000, global step 80219: loss -1.5562
[2019-03-23 08:25:56,365] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 5000, global step 80219: learning rate 0.0005
[2019-03-23 08:25:56,710] A3C_AGENT_WORKER-Thread-10 INFO:Local step 5000, global step 80339: loss -333.9443
[2019-03-23 08:25:56,712] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 5000, global step 80339: learning rate 0.0005
[2019-03-23 08:25:57,057] A3C_AGENT_WORKER-Thread-19 INFO:Local step 5000, global step 80458: loss 28.4017
[2019-03-23 08:25:57,059] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 5000, global step 80458: learning rate 0.0005
[2019-03-23 08:26:02,557] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.6254709e-20 1.0000000e+00 5.3662086e-24 1.1206660e-28 1.1876302e-28], sum to 1.0000
[2019-03-23 08:26:02,563] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5500
[2019-03-23 08:26:02,569] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 82.16666666666667, 1.0, 2.0, 0.5112233038793611, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 582367.8865146019, 582367.8865146019, 140002.6301888747], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3129000.0000, 
sim time next is 3129600.0000, 
raw observation next is [22.0, 81.33333333333334, 1.0, 2.0, 0.4672560409441787, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 532023.5961813891, 532023.5961813894, 134927.3478294722], 
processed observation next is [1.0, 0.21739130434782608, 0.6363636363636364, 0.8133333333333335, 1.0, 1.0, 0.33407005118022337, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19704577636347742, 0.19704577636347756, 0.32909109226700534], 
reward next is 0.6709, 
noisyNet noise sample is [array([0.33846366], dtype=float32), 0.98107994]. 
=============================================
[2019-03-23 08:26:03,179] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.4049142e-17 1.0000000e+00 7.0151640e-23 3.1155349e-25 5.2325798e-28], sum to 1.0000
[2019-03-23 08:26:03,187] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9554
[2019-03-23 08:26:03,193] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 75.5, 1.0, 2.0, 0.522640321774871, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 594168.044033017, 594168.044033017, 140124.3819162897], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3137400.0000, 
sim time next is 3138000.0000, 
raw observation next is [22.66666666666666, 74.66666666666667, 1.0, 2.0, 0.5043304353681127, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 573467.8227407665, 573467.8227407665, 138201.4302227301], 
processed observation next is [1.0, 0.30434782608695654, 0.6666666666666664, 0.7466666666666667, 1.0, 1.0, 0.3804130442101409, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21239548990398757, 0.21239548990398757, 0.3370766590798295], 
reward next is 0.6629, 
noisyNet noise sample is [array([0.8985581], dtype=float32), -0.46645385]. 
=============================================
[2019-03-23 08:26:03,214] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[61.046425]
 [61.04689 ]
 [61.047546]
 [61.047234]
 [61.04618 ]], R is [[61.09827042]
 [61.14552307]
 [61.19716263]
 [61.25562668]
 [61.32222366]].
[2019-03-23 08:26:10,855] A3C_AGENT_WORKER-Thread-21 INFO:Local step 5500, global step 87644: loss 0.3111
[2019-03-23 08:26:10,857] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 5500, global step 87644: learning rate 0.0005
[2019-03-23 08:26:10,889] A3C_AGENT_WORKER-Thread-2 INFO:Local step 5500, global step 87662: loss 0.2250
[2019-03-23 08:26:10,891] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 5500, global step 87662: learning rate 0.0005
[2019-03-23 08:26:11,027] A3C_AGENT_WORKER-Thread-14 INFO:Local step 5500, global step 87735: loss 0.1066
[2019-03-23 08:26:11,028] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 5500, global step 87736: learning rate 0.0005
[2019-03-23 08:26:11,049] A3C_AGENT_WORKER-Thread-3 INFO:Local step 5500, global step 87750: loss 0.0794
[2019-03-23 08:26:11,054] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 5500, global step 87750: learning rate 0.0005
[2019-03-23 08:26:11,094] A3C_AGENT_WORKER-Thread-15 INFO:Local step 5500, global step 87771: loss 0.3650
[2019-03-23 08:26:11,096] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 5500, global step 87772: learning rate 0.0005
[2019-03-23 08:26:11,141] A3C_AGENT_WORKER-Thread-12 INFO:Local step 5500, global step 87792: loss 0.0833
[2019-03-23 08:26:11,143] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 5500, global step 87793: learning rate 0.0005
[2019-03-23 08:26:11,247] A3C_AGENT_WORKER-Thread-9 INFO:Local step 5500, global step 87852: loss 0.0116
[2019-03-23 08:26:11,252] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 5500, global step 87852: learning rate 0.0005
[2019-03-23 08:26:11,402] A3C_AGENT_WORKER-Thread-16 INFO:Local step 5500, global step 87934: loss 0.2983
[2019-03-23 08:26:11,404] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 5500, global step 87935: learning rate 0.0005
[2019-03-23 08:26:11,428] A3C_AGENT_WORKER-Thread-13 INFO:Local step 5500, global step 87940: loss 0.2527
[2019-03-23 08:26:11,432] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 5500, global step 87944: learning rate 0.0005
[2019-03-23 08:26:11,744] A3C_AGENT_WORKER-Thread-18 INFO:Local step 5500, global step 88075: loss 0.1636
[2019-03-23 08:26:11,745] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 5500, global step 88075: learning rate 0.0005
[2019-03-23 08:26:11,875] A3C_AGENT_WORKER-Thread-20 INFO:Local step 5500, global step 88141: loss 0.0058
[2019-03-23 08:26:11,878] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 5500, global step 88142: learning rate 0.0005
[2019-03-23 08:26:11,925] A3C_AGENT_WORKER-Thread-11 INFO:Local step 5500, global step 88172: loss 0.0116
[2019-03-23 08:26:11,926] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 5500, global step 88172: learning rate 0.0005
[2019-03-23 08:26:11,974] A3C_AGENT_WORKER-Thread-22 INFO:Local step 5500, global step 88195: loss 0.1289
[2019-03-23 08:26:11,977] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 5500, global step 88195: learning rate 0.0005
[2019-03-23 08:26:12,077] A3C_AGENT_WORKER-Thread-17 INFO:Local step 5500, global step 88252: loss 0.1562
[2019-03-23 08:26:12,077] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 5500, global step 88252: learning rate 0.0005
[2019-03-23 08:26:12,209] A3C_AGENT_WORKER-Thread-10 INFO:Local step 5500, global step 88322: loss 0.0132
[2019-03-23 08:26:12,211] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 5500, global step 88322: learning rate 0.0005
[2019-03-23 08:26:12,673] A3C_AGENT_WORKER-Thread-19 INFO:Local step 5500, global step 88571: loss 0.2173
[2019-03-23 08:26:12,673] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 5500, global step 88571: learning rate 0.0005
[2019-03-23 08:26:14,870] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.1778276e-20 1.0000000e+00 4.3339131e-26 4.9455320e-29 3.8425403e-31], sum to 1.0000
[2019-03-23 08:26:14,879] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5370
[2019-03-23 08:26:14,885] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.16666666666666, 68.16666666666666, 1.0, 2.0, 0.3497858254075567, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 388435.5357205032, 388435.5357205032, 117800.1788910011], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3358200.0000, 
sim time next is 3358800.0000, 
raw observation next is [21.0, 69.0, 1.0, 2.0, 0.3467190427306611, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 384795.8494077041, 384795.8494077044, 117464.1342442892], 
processed observation next is [0.0, 0.9130434782608695, 0.5909090909090909, 0.69, 1.0, 1.0, 0.18339880341332637, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14251698126211262, 0.14251698126211274, 0.2864978884007054], 
reward next is 0.7135, 
noisyNet noise sample is [array([-1.0383627], dtype=float32), -0.0030653216]. 
=============================================
[2019-03-23 08:26:16,463] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.5256644e-16 1.0000000e+00 9.2359134e-21 1.4453173e-21 6.0286877e-27], sum to 1.0000
[2019-03-23 08:26:16,472] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2244
[2019-03-23 08:26:16,478] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 69.33333333333333, 1.0, 2.0, 0.9399427475439973, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1072037.614974204, 1072037.614974204, 202375.0153663342], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3408000.0000, 
sim time next is 3408600.0000, 
raw observation next is [24.5, 67.16666666666667, 1.0, 2.0, 0.9786492264676998, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1116661.377607891, 1116661.377607891, 210024.4560141954], 
processed observation next is [1.0, 0.43478260869565216, 0.75, 0.6716666666666667, 1.0, 1.0, 0.9733115330846248, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.4135782880029226, 0.4135782880029226, 0.5122547707663302], 
reward next is 0.4877, 
noisyNet noise sample is [array([2.7759755], dtype=float32), -1.6960307]. 
=============================================
[2019-03-23 08:26:16,612] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.37672720e-19 1.00000000e+00 4.96052777e-24 1.00655416e-26
 7.75661364e-30], sum to 1.0000
[2019-03-23 08:26:16,634] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4682
[2019-03-23 08:26:16,637] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 78.0, 1.0, 2.0, 0.3788165409282067, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 426678.5113115128, 426678.5113115128, 122863.1562142011], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3398400.0000, 
sim time next is 3399000.0000, 
raw observation next is [21.16666666666667, 78.0, 1.0, 2.0, 0.4146349545722096, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 467792.8380450653, 467792.8380450656, 126477.3484563916], 
processed observation next is [1.0, 0.34782608695652173, 0.5984848484848487, 0.78, 1.0, 1.0, 0.268293693215262, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17325660668335752, 0.17325660668335763, 0.3084813376985161], 
reward next is 0.6915, 
noisyNet noise sample is [array([-0.9637599], dtype=float32), -0.16953936]. 
=============================================
[2019-03-23 08:26:16,649] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[63.41794]
 [63.41794]
 [63.41794]
 [63.41794]
 [63.41794]], R is [[63.47528458]
 [63.54086685]
 [63.60568237]
 [63.67165375]
 [63.73933411]].
[2019-03-23 08:26:17,349] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.1997554e-14 1.0000000e+00 7.5531698e-18 2.6925260e-20 3.7282276e-23], sum to 1.0000
[2019-03-23 08:26:17,357] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2363
[2019-03-23 08:26:17,363] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1333234.729593617 W.
[2019-03-23 08:26:17,367] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.6, 57.33333333333334, 1.0, 2.0, 0.5876886112778796, 1.0, 2.0, 0.5876886112778796, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1333234.729593617, 1333234.729593617, 255350.6780034562], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3421200.0000, 
sim time next is 3421800.0000, 
raw observation next is [27.65, 57.0, 1.0, 2.0, 0.7002946476986024, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9748407163271704, 6.911200000000001, 6.9112, 77.32846344354104, 1345856.812195783, 1345856.812195782, 289760.0029337192], 
processed observation next is [1.0, 0.6086956521739131, 0.8931818181818181, 0.57, 1.0, 1.0, 0.6253683096232528, 0.0, 0.5, -0.25, 1.0, 0.5, 0.964058166181672, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.49846548599843815, 0.4984654859984378, 0.7067317144724858], 
reward next is 0.2933, 
noisyNet noise sample is [array([-1.20705], dtype=float32), 0.04009715]. 
=============================================
[2019-03-23 08:26:19,202] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.3103489e-15 1.0000000e+00 9.0686538e-20 5.3692704e-20 1.3274207e-22], sum to 1.0000
[2019-03-23 08:26:19,222] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8606
[2019-03-23 08:26:19,233] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.5, 97.0, 1.0, 2.0, 0.4958405848366844, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 565606.7083883323, 565606.7083883319, 141351.3570486048], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3461400.0000, 
sim time next is 3462000.0000, 
raw observation next is [21.33333333333334, 98.0, 1.0, 2.0, 0.4936934801183694, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 563199.811803277, 563199.811803277, 141002.6319397173], 
processed observation next is [1.0, 0.043478260869565216, 0.6060606060606063, 0.98, 1.0, 1.0, 0.3671168501479617, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2085925228901026, 0.2085925228901026, 0.34390885838955443], 
reward next is 0.6561, 
noisyNet noise sample is [array([0.49090585], dtype=float32), -0.88121665]. 
=============================================
[2019-03-23 08:26:19,251] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[49.694347]
 [49.71697 ]
 [49.747715]
 [49.73157 ]
 [49.738853]], R is [[49.88536072]
 [50.04174805]
 [50.19572449]
 [50.34737396]
 [50.49701309]].
[2019-03-23 08:26:25,852] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.0120298e-12 1.0000000e+00 8.4030031e-16 1.7743199e-16 5.4518094e-19], sum to 1.0000
[2019-03-23 08:26:25,857] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6181
[2019-03-23 08:26:25,869] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1426365.638273543 W.
[2019-03-23 08:26:25,876] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.16666666666667, 93.16666666666667, 1.0, 2.0, 0.4228041926561125, 1.0, 2.0, 0.4228041926561125, 1.0, 2.0, 0.8554933078409592, 6.911199999999999, 6.9112, 77.3421103, 1426365.638273543, 1426365.638273544, 318576.3265745671], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3585000.0000, 
sim time next is 3585600.0000, 
raw observation next is [23.0, 94.0, 1.0, 2.0, 0.4253140242624379, 1.0, 2.0, 0.4253140242624379, 1.0, 2.0, 0.8605716494948829, 6.911199999999999, 6.9112, 77.3421103, 1434843.493405041, 1434843.493405041, 319846.5024562639], 
processed observation next is [1.0, 0.5217391304347826, 0.6818181818181818, 0.94, 1.0, 1.0, 0.28164253032804737, 1.0, 1.0, 0.28164253032804737, 1.0, 1.0, 0.800816642135547, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.5314235160759412, 0.5314235160759412, 0.7801134206250339], 
reward next is 0.2199, 
noisyNet noise sample is [array([-1.5604883], dtype=float32), -0.5589035]. 
=============================================
[2019-03-23 08:26:26,383] A3C_AGENT_WORKER-Thread-2 INFO:Local step 6000, global step 95622: loss -59.5420
[2019-03-23 08:26:26,386] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.1334629e-10 1.0000000e+00 6.4741879e-14 8.0066867e-14 8.5202323e-17], sum to 1.0000
[2019-03-23 08:26:26,386] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 6000, global step 95622: learning rate 0.0005
[2019-03-23 08:26:26,393] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7939
[2019-03-23 08:26:26,401] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1677717.525983428 W.
[2019-03-23 08:26:26,404] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.66666666666666, 71.33333333333333, 1.0, 2.0, 0.5068228335724181, 1.0, 2.0, 0.4971998537278162, 1.0, 2.0, 0.9865530188920543, 6.911199999999999, 6.9112, 77.3421103, 1677717.525983428, 1677717.525983429, 356927.3307681186], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3595200.0000, 
sim time next is 3595800.0000, 
raw observation next is [27.83333333333334, 70.66666666666667, 1.0, 2.0, 0.5280169657773951, 1.0, 2.0, 0.5077969198303048, 1.0, 2.0, 0.9865530188920543, 6.911199999999999, 6.9112, 77.3421103, 1713529.670995431, 1713529.670995431, 360775.3361804176], 
processed observation next is [1.0, 0.6086956521739131, 0.9015151515151518, 0.7066666666666667, 1.0, 1.0, 0.41002120722174384, 1.0, 1.0, 0.384746149787881, 1.0, 1.0, 0.9807900269886491, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.6346406188871967, 0.6346406188871967, 0.879939844342482], 
reward next is 0.1201, 
noisyNet noise sample is [array([0.1970764], dtype=float32), -1.8250504]. 
=============================================
[2019-03-23 08:26:26,595] A3C_AGENT_WORKER-Thread-14 INFO:Local step 6000, global step 95735: loss -49.6506
[2019-03-23 08:26:26,597] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 6000, global step 95735: learning rate 0.0005
[2019-03-23 08:26:26,604] A3C_AGENT_WORKER-Thread-21 INFO:Local step 6000, global step 95737: loss -34.6230
[2019-03-23 08:26:26,605] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 6000, global step 95737: learning rate 0.0005
[2019-03-23 08:26:26,686] A3C_AGENT_WORKER-Thread-12 INFO:Local step 6000, global step 95782: loss -55.2885
[2019-03-23 08:26:26,687] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 6000, global step 95782: learning rate 0.0005
[2019-03-23 08:26:26,818] A3C_AGENT_WORKER-Thread-3 INFO:Local step 6000, global step 95851: loss -4.9941
[2019-03-23 08:26:26,819] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 6000, global step 95851: learning rate 0.0005
[2019-03-23 08:26:26,849] A3C_AGENT_WORKER-Thread-13 INFO:Local step 6000, global step 95865: loss 3.6409
[2019-03-23 08:26:26,850] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 6000, global step 95866: learning rate 0.0005
[2019-03-23 08:26:26,862] A3C_AGENT_WORKER-Thread-9 INFO:Local step 6000, global step 95874: loss -6.9505
[2019-03-23 08:26:26,863] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 6000, global step 95874: learning rate 0.0005
[2019-03-23 08:26:26,906] A3C_AGENT_WORKER-Thread-15 INFO:Local step 6000, global step 95895: loss 14.9555
[2019-03-23 08:26:26,908] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 6000, global step 95895: learning rate 0.0005
[2019-03-23 08:26:26,924] A3C_AGENT_WORKER-Thread-16 INFO:Local step 6000, global step 95902: loss -28.0554
[2019-03-23 08:26:26,925] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 6000, global step 95903: learning rate 0.0005
[2019-03-23 08:26:27,129] A3C_AGENT_WORKER-Thread-18 INFO:Local step 6000, global step 96017: loss -16.3422
[2019-03-23 08:26:27,131] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 6000, global step 96018: learning rate 0.0005
[2019-03-23 08:26:27,383] A3C_AGENT_WORKER-Thread-20 INFO:Local step 6000, global step 96144: loss 5.2406
[2019-03-23 08:26:27,386] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 6000, global step 96144: learning rate 0.0005
[2019-03-23 08:26:27,515] A3C_AGENT_WORKER-Thread-11 INFO:Local step 6000, global step 96217: loss -24.1271
[2019-03-23 08:26:27,515] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 6000, global step 96217: learning rate 0.0005
[2019-03-23 08:26:27,653] A3C_AGENT_WORKER-Thread-10 INFO:Local step 6000, global step 96295: loss -118.2808
[2019-03-23 08:26:27,656] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 6000, global step 96295: learning rate 0.0005
[2019-03-23 08:26:27,777] A3C_AGENT_WORKER-Thread-22 INFO:Local step 6000, global step 96355: loss -77.3018
[2019-03-23 08:26:27,778] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 6000, global step 96355: learning rate 0.0005
[2019-03-23 08:26:27,822] A3C_AGENT_WORKER-Thread-17 INFO:Local step 6000, global step 96380: loss -103.0549
[2019-03-23 08:26:27,825] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 6000, global step 96380: learning rate 0.0005
[2019-03-23 08:26:28,016] A3C_AGENT_WORKER-Thread-19 INFO:Local step 6000, global step 96479: loss -64.3369
[2019-03-23 08:26:28,019] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 6000, global step 96481: learning rate 0.0005
[2019-03-23 08:26:28,363] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.9148126e-23 1.0000000e+00 1.1802403e-30 8.6277196e-29 8.6454467e-36], sum to 1.0000
[2019-03-23 08:26:28,372] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9110
[2019-03-23 08:26:28,377] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333333, 81.33333333333333, 1.0, 2.0, 0.4908025446103716, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 560001.8598673453, 560001.8598673453, 140352.3467313579], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3613200.0000, 
sim time next is 3613800.0000, 
raw observation next is [23.16666666666667, 82.16666666666667, 1.0, 2.0, 0.4904825884409207, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 559657.7154331133, 559657.7154331133, 140215.1722066574], 
processed observation next is [1.0, 0.8260869565217391, 0.6893939393939396, 0.8216666666666668, 1.0, 1.0, 0.3631032355511508, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2072806353455975, 0.2072806353455975, 0.3419882248942863], 
reward next is 0.6580, 
noisyNet noise sample is [array([-1.6776869], dtype=float32), -0.890571]. 
=============================================
[2019-03-23 08:26:31,993] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.8036095e-16 1.0000000e+00 4.5786865e-22 3.4662138e-19 6.8116838e-24], sum to 1.0000
[2019-03-23 08:26:32,000] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1144
[2019-03-23 08:26:32,002] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.66666666666667, 75.33333333333334, 1.0, 2.0, 0.5165867875026451, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 588966.734890917, 588966.734890917, 144306.8846562233], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3703200.0000, 
sim time next is 3703800.0000, 
raw observation next is [24.33333333333333, 76.66666666666666, 1.0, 2.0, 0.5114836234999686, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 583319.5378653273, 583319.5378653273, 143445.0382696481], 
processed observation next is [1.0, 0.8695652173913043, 0.7424242424242422, 0.7666666666666666, 1.0, 1.0, 0.3893545293749607, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21604427328345457, 0.21604427328345457, 0.3498659469991417], 
reward next is 0.6501, 
noisyNet noise sample is [array([1.0926911], dtype=float32), -0.23225123]. 
=============================================
[2019-03-23 08:26:33,179] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.6482986e-18 1.0000000e+00 7.4696184e-25 3.4479943e-23 7.7122509e-27], sum to 1.0000
[2019-03-23 08:26:33,188] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6082
[2019-03-23 08:26:33,195] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.33333333333334, 72.66666666666667, 1.0, 2.0, 0.5230551280319528, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 595912.9779795525, 595912.9779795525, 145555.1053728565], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3702000.0000, 
sim time next is 3702600.0000, 
raw observation next is [25.0, 74.0, 1.0, 2.0, 0.5199442561650198, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 592593.0254624969, 592593.0254624969, 144951.0009519437], 
processed observation next is [1.0, 0.8695652173913043, 0.7727272727272727, 0.74, 1.0, 1.0, 0.3999303202062747, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2194788983194433, 0.2194788983194433, 0.3535390267120578], 
reward next is 0.6465, 
noisyNet noise sample is [array([-0.44547912], dtype=float32), -0.43655527]. 
=============================================
[2019-03-23 08:26:34,614] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-23 08:26:34,615] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 08:26:34,616] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:26:34,619] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 08:26:34,619] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:26:34,620] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 08:26:34,621] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:26:34,621] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 08:26:34,622] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 08:26:34,623] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:26:34,623] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:26:34,635] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run5
[2019-03-23 08:26:34,636] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run5
[2019-03-23 08:26:34,681] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run5
[2019-03-23 08:26:34,706] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run5
[2019-03-23 08:26:34,707] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run5
[2019-03-23 08:26:36,760] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.09243652], dtype=float32), -0.5196297]
[2019-03-23 08:26:36,760] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [13.0, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 211433.679677329, 211433.6796773287, 69934.0541956312]
[2019-03-23 08:26:36,761] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 08:26:36,763] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.1052840e-17 1.0000000e+00 2.4355071e-24 1.7655843e-22 1.6365237e-27], sampled 0.19725611112286645
[2019-03-23 08:26:37,414] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.09243652], dtype=float32), -0.5196297]
[2019-03-23 08:26:37,415] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.0, 43.0, 1.0, 2.0, 0.2733583708055236, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 296800.7100598612, 296800.7100598612, 82690.66242173835]
[2019-03-23 08:26:37,415] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 08:26:37,418] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.0630713e-17 1.0000000e+00 2.3882636e-24 1.7339266e-22 1.6004808e-27], sampled 0.7141721579296063
[2019-03-23 08:27:05,330] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.09243652], dtype=float32), -0.5196297]
[2019-03-23 08:27:05,331] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [27.86666666666667, 48.66666666666666, 1.0, 2.0, 0.9147941187611408, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 1043142.841121382, 1043142.841121382, 202363.8971630431]
[2019-03-23 08:27:05,332] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 08:27:05,334] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.3812113e-17 1.0000000e+00 2.7510041e-24 1.9757998e-22 1.8795647e-27], sampled 0.28988100821399443
[2019-03-23 08:27:09,770] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.09243652], dtype=float32), -0.5196297]
[2019-03-23 08:27:09,771] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [26.18333333333333, 50.0, 1.0, 2.0, 0.6619690195206742, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 749769.8914027005, 749769.8914027001, 159420.0415410921]
[2019-03-23 08:27:09,772] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 08:27:09,774] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.3098100e-17 1.0000000e+00 2.6682368e-24 1.9208493e-22 1.8154097e-27], sampled 0.6548520092459339
[2019-03-23 08:27:19,324] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.09243652], dtype=float32), -0.5196297]
[2019-03-23 08:27:19,327] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [26.83333333333333, 67.33333333333333, 1.0, 2.0, 0.5363597180139463, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 609564.0886987346, 609564.0886987346, 148220.7687255387]
[2019-03-23 08:27:19,330] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 08:27:19,332] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.9376022e-17 1.0000000e+00 2.2495221e-24 1.6406971e-22 1.4952191e-27], sampled 0.7391373023626452
[2019-03-23 08:27:32,245] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.09243652], dtype=float32), -0.5196297]
[2019-03-23 08:27:32,246] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.0, 94.0, 1.0, 2.0, 0.4633273974126267, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 528460.1240268298, 528460.1240268298, 135821.8667224286]
[2019-03-23 08:27:32,248] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 08:27:32,251] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.1249388e-17 1.0000000e+00 2.4575792e-24 1.7803621e-22 1.6533845e-27], sampled 0.15451470457530758
[2019-03-23 08:27:32,524] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.09243652], dtype=float32), -0.5196297]
[2019-03-23 08:27:32,526] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.2, 91.0, 1.0, 2.0, 0.4985745711220325, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 568713.7351563, 568713.7351562997, 145859.9151260346]
[2019-03-23 08:27:32,529] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 08:27:32,533] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.1807675e-17 1.0000000e+00 2.5206526e-24 1.8225267e-22 1.7017089e-27], sampled 0.4277539768433465
[2019-03-23 08:27:43,119] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.09243652], dtype=float32), -0.5196297]
[2019-03-23 08:27:43,120] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [26.933210735, 41.072343695, 1.0, 2.0, 0.4237185346101112, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 476879.6842425375, 476879.6842425375, 131038.8666005374]
[2019-03-23 08:27:43,121] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 08:27:43,123] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.9618850e-17 1.0000000e+00 2.2761864e-24 1.6586446e-22 1.5153742e-27], sampled 0.058864829736700375
[2019-03-23 08:27:49,096] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.09243652], dtype=float32), -0.5196297]
[2019-03-23 08:27:49,098] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [17.79290521833333, 59.51199373833333, 1.0, 2.0, 0.2258630905701437, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 245221.8668130522, 245221.8668130522, 81136.6190549901]
[2019-03-23 08:27:49,099] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 08:27:49,102] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.0243728e-17 1.0000000e+00 2.3452083e-24 1.7050402e-22 1.5677236e-27], sampled 0.056825669134381696
[2019-03-23 08:28:05,429] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.09243652], dtype=float32), -0.5196297]
[2019-03-23 08:28:05,430] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [26.6, 47.0, 1.0, 2.0, 0.3866583758211539, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 95.55338769695034, 436717.7326999145, 436717.7326999138, 128546.8672776203]
[2019-03-23 08:28:05,431] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 08:28:05,434] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.1499527e-17 1.0000000e+00 2.4857705e-24 1.7992196e-22 1.6749749e-27], sampled 0.5274005955302519
[2019-03-23 08:28:17,111] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 08:28:17,672] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 08:28:17,965] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 08:28:17,968] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 08:28:17,972] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 08:28:18,987] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 100000, evaluation results [100000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 08:28:25,974] A3C_AGENT_WORKER-Thread-14 INFO:Local step 6500, global step 103557: loss 0.0860
[2019-03-23 08:28:25,977] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 6500, global step 103558: learning rate 0.0005
[2019-03-23 08:28:26,014] A3C_AGENT_WORKER-Thread-2 INFO:Local step 6500, global step 103575: loss 0.0019
[2019-03-23 08:28:26,019] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 6500, global step 103575: learning rate 0.0005
[2019-03-23 08:28:26,220] A3C_AGENT_WORKER-Thread-21 INFO:Local step 6500, global step 103684: loss 0.0892
[2019-03-23 08:28:26,224] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 6500, global step 103685: learning rate 0.0005
[2019-03-23 08:28:26,298] A3C_AGENT_WORKER-Thread-12 INFO:Local step 6500, global step 103722: loss 0.0000
[2019-03-23 08:28:26,303] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 6500, global step 103723: learning rate 0.0005
[2019-03-23 08:28:26,361] A3C_AGENT_WORKER-Thread-3 INFO:Local step 6500, global step 103753: loss 0.0582
[2019-03-23 08:28:26,364] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 6500, global step 103756: learning rate 0.0005
[2019-03-23 08:28:26,455] A3C_AGENT_WORKER-Thread-13 INFO:Local step 6500, global step 103802: loss 0.1546
[2019-03-23 08:28:26,458] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 6500, global step 103804: learning rate 0.0005
[2019-03-23 08:28:26,489] A3C_AGENT_WORKER-Thread-16 INFO:Local step 6500, global step 103818: loss 0.1414
[2019-03-23 08:28:26,493] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 6500, global step 103819: learning rate 0.0005
[2019-03-23 08:28:26,548] A3C_AGENT_WORKER-Thread-9 INFO:Local step 6500, global step 103849: loss 0.0654
[2019-03-23 08:28:26,551] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 6500, global step 103849: learning rate 0.0005
[2019-03-23 08:28:26,554] A3C_AGENT_WORKER-Thread-15 INFO:Local step 6500, global step 103852: loss 0.0554
[2019-03-23 08:28:26,557] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 6500, global step 103853: learning rate 0.0005
[2019-03-23 08:28:26,726] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.9099306e-25 1.0000000e+00 1.6387660e-35 7.0752678e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 08:28:26,734] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6515
[2019-03-23 08:28:26,743] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 77.0, 1.0, 2.0, 0.2813410383139067, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 305488.4461892591, 305488.4461892588, 101648.7945488037], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3893400.0000, 
sim time next is 3894000.0000, 
raw observation next is [18.0, 77.0, 1.0, 2.0, 0.2812653472231958, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 305406.2327507673, 305406.2327507673, 101637.6843283391], 
processed observation next is [0.0, 0.043478260869565216, 0.45454545454545453, 0.77, 1.0, 1.0, 0.10158168402899473, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11311341953732122, 0.11311341953732122, 0.24789679104472953], 
reward next is 0.7521, 
noisyNet noise sample is [array([0.8768949], dtype=float32), 0.34617904]. 
=============================================
[2019-03-23 08:28:26,759] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[85.72694 ]
 [85.72671 ]
 [85.726425]
 [85.726494]
 [85.72631 ]], R is [[85.62162781]
 [85.51748657]
 [85.41438293]
 [85.31233215]
 [85.21138   ]].
[2019-03-23 08:28:26,943] A3C_AGENT_WORKER-Thread-18 INFO:Local step 6500, global step 104050: loss 0.0036
[2019-03-23 08:28:26,946] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 6500, global step 104050: learning rate 0.0005
[2019-03-23 08:28:27,095] A3C_AGENT_WORKER-Thread-20 INFO:Local step 6500, global step 104127: loss 0.1457
[2019-03-23 08:28:27,099] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 6500, global step 104127: learning rate 0.0005
[2019-03-23 08:28:27,352] A3C_AGENT_WORKER-Thread-11 INFO:Local step 6500, global step 104252: loss 0.2352
[2019-03-23 08:28:27,355] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 6500, global step 104253: learning rate 0.0005
[2019-03-23 08:28:27,527] A3C_AGENT_WORKER-Thread-10 INFO:Local step 6500, global step 104344: loss 0.0020
[2019-03-23 08:28:27,530] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 6500, global step 104344: learning rate 0.0005
[2019-03-23 08:28:27,621] A3C_AGENT_WORKER-Thread-22 INFO:Local step 6500, global step 104390: loss 0.1146
[2019-03-23 08:28:27,622] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 6500, global step 104390: learning rate 0.0005
[2019-03-23 08:28:27,812] A3C_AGENT_WORKER-Thread-17 INFO:Local step 6500, global step 104488: loss 0.0035
[2019-03-23 08:28:27,814] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 6500, global step 104489: learning rate 0.0005
[2019-03-23 08:28:27,877] A3C_AGENT_WORKER-Thread-19 INFO:Local step 6500, global step 104516: loss 0.0018
[2019-03-23 08:28:27,880] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 6500, global step 104516: learning rate 0.0005
[2019-03-23 08:28:32,315] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.3213669e-21 1.0000000e+00 4.1288378e-29 1.0143171e-26 1.4500743e-33], sum to 1.0000
[2019-03-23 08:28:32,324] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0369
[2019-03-23 08:28:32,331] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 96.0, 1.0, 2.0, 0.5108839362330245, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 562216.6156760076, 562216.6156760076, 130203.6899639429], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4011600.0000, 
sim time next is 4012200.0000, 
raw observation next is [17.0, 97.0, 1.0, 2.0, 0.5091410610646961, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 561298.4172938638, 561298.4172938638, 130380.9520428471], 
processed observation next is [1.0, 0.43478260869565216, 0.4090909090909091, 0.97, 1.0, 1.0, 0.38642632633087015, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20788830270143105, 0.20788830270143105, 0.31800232205572465], 
reward next is 0.6820, 
noisyNet noise sample is [array([-0.59950495], dtype=float32), -0.93947035]. 
=============================================
[2019-03-23 08:28:33,986] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.0769629e-24 1.0000000e+00 8.3453937e-34 5.5917589e-31 0.0000000e+00], sum to 1.0000
[2019-03-23 08:28:33,994] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6069
[2019-03-23 08:28:34,002] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 100.0, 1.0, 2.0, 0.3414959803010829, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 377945.7247698671, 377945.7247698671, 116633.8486564676], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4047600.0000, 
sim time next is 4048200.0000, 
raw observation next is [17.0, 100.0, 1.0, 2.0, 0.3408459695497932, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 377223.2218319739, 377223.2218319739, 116582.9724520694], 
processed observation next is [1.0, 0.8695652173913043, 0.4090909090909091, 1.0, 1.0, 1.0, 0.17605746193724145, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13971230438221255, 0.13971230438221255, 0.28434871329773026], 
reward next is 0.7157, 
noisyNet noise sample is [array([-1.1815935], dtype=float32), -1.2698627]. 
=============================================
[2019-03-23 08:28:39,172] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.5648786e-20 1.0000000e+00 4.9135480e-28 2.2380481e-28 1.4027728e-31], sum to 1.0000
[2019-03-23 08:28:39,180] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0651
[2019-03-23 08:28:39,184] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 94.0, 1.0, 2.0, 0.3902768826572989, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 439997.6127142727, 439997.6127142727, 124089.098809519], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4125600.0000, 
sim time next is 4126200.0000, 
raw observation next is [19.01666666666667, 93.83333333333334, 1.0, 2.0, 0.3918086178273869, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 441503.5484806235, 441503.5484806233, 124106.8996731386], 
processed observation next is [1.0, 0.782608695652174, 0.5007575757575758, 0.9383333333333335, 1.0, 1.0, 0.23976077228423362, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1635198327706013, 0.16351983277060123, 0.30269975530033805], 
reward next is 0.6973, 
noisyNet noise sample is [array([0.5052239], dtype=float32), -1.5595056]. 
=============================================
[2019-03-23 08:28:40,451] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.3900603e-24 1.0000000e+00 1.1102388e-32 4.0088179e-30 2.3374136e-37], sum to 1.0000
[2019-03-23 08:28:40,461] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9780
[2019-03-23 08:28:40,466] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.3706158659522894, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 416044.3957989616, 416044.3957989616, 121437.856088541], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4150200.0000, 
sim time next is 4150800.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.3704134249196332, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 415816.2505319021, 415816.2505319018, 121420.2799917087], 
processed observation next is [1.0, 0.043478260869565216, 0.45454545454545453, 1.0, 1.0, 1.0, 0.21301678114954148, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15400601871551928, 0.15400601871551917, 0.2961470243700212], 
reward next is 0.7039, 
noisyNet noise sample is [array([0.4094691], dtype=float32), -1.5566914]. 
=============================================
[2019-03-23 08:28:41,474] A3C_AGENT_WORKER-Thread-14 INFO:Local step 7000, global step 111566: loss 0.0597
[2019-03-23 08:28:41,476] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 7000, global step 111567: learning rate 0.0005
[2019-03-23 08:28:41,548] A3C_AGENT_WORKER-Thread-21 INFO:Local step 7000, global step 111603: loss 0.0836
[2019-03-23 08:28:41,551] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 7000, global step 111606: learning rate 0.0005
[2019-03-23 08:28:41,617] A3C_AGENT_WORKER-Thread-2 INFO:Local step 7000, global step 111642: loss 0.0916
[2019-03-23 08:28:41,621] A3C_AGENT_WORKER-Thread-12 INFO:Local step 7000, global step 111644: loss 0.1157
[2019-03-23 08:28:41,623] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 7000, global step 111645: learning rate 0.0005
[2019-03-23 08:28:41,624] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 7000, global step 111644: learning rate 0.0005
[2019-03-23 08:28:41,760] A3C_AGENT_WORKER-Thread-3 INFO:Local step 7000, global step 111720: loss 0.0805
[2019-03-23 08:28:41,762] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 7000, global step 111720: learning rate 0.0005
[2019-03-23 08:28:41,934] A3C_AGENT_WORKER-Thread-16 INFO:Local step 7000, global step 111809: loss 0.0856
[2019-03-23 08:28:41,939] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 7000, global step 111810: learning rate 0.0005
[2019-03-23 08:28:41,958] A3C_AGENT_WORKER-Thread-9 INFO:Local step 7000, global step 111817: loss 0.0458
[2019-03-23 08:28:41,962] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 7000, global step 111818: learning rate 0.0005
[2019-03-23 08:28:42,047] A3C_AGENT_WORKER-Thread-13 INFO:Local step 7000, global step 111871: loss 0.0665
[2019-03-23 08:28:42,053] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 7000, global step 111872: learning rate 0.0005
[2019-03-23 08:28:42,076] A3C_AGENT_WORKER-Thread-15 INFO:Local step 7000, global step 111883: loss 0.0419
[2019-03-23 08:28:42,082] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 7000, global step 111884: learning rate 0.0005
[2019-03-23 08:28:42,231] A3C_AGENT_WORKER-Thread-18 INFO:Local step 7000, global step 111961: loss 0.0242
[2019-03-23 08:28:42,232] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 7000, global step 111961: learning rate 0.0005
[2019-03-23 08:28:42,490] A3C_AGENT_WORKER-Thread-20 INFO:Local step 7000, global step 112103: loss 0.0113
[2019-03-23 08:28:42,492] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 7000, global step 112104: learning rate 0.0005
[2019-03-23 08:28:42,899] A3C_AGENT_WORKER-Thread-10 INFO:Local step 7000, global step 112324: loss 0.3631
[2019-03-23 08:28:42,902] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 7000, global step 112324: learning rate 0.0005
[2019-03-23 08:28:42,921] A3C_AGENT_WORKER-Thread-11 INFO:Local step 7000, global step 112333: loss 0.3499
[2019-03-23 08:28:42,927] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 7000, global step 112333: learning rate 0.0005
[2019-03-23 08:28:42,996] A3C_AGENT_WORKER-Thread-22 INFO:Local step 7000, global step 112370: loss 0.3360
[2019-03-23 08:28:42,997] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 7000, global step 112370: learning rate 0.0005
[2019-03-23 08:28:43,284] A3C_AGENT_WORKER-Thread-17 INFO:Local step 7000, global step 112523: loss 0.0686
[2019-03-23 08:28:43,287] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 7000, global step 112524: learning rate 0.0005
[2019-03-23 08:28:43,559] A3C_AGENT_WORKER-Thread-19 INFO:Local step 7000, global step 112677: loss 0.3772
[2019-03-23 08:28:43,562] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 7000, global step 112677: learning rate 0.0005
[2019-03-23 08:28:43,679] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.3648794e-20 1.0000000e+00 3.0904565e-30 2.7816034e-26 1.9524667e-31], sum to 1.0000
[2019-03-23 08:28:43,688] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7046
[2019-03-23 08:28:43,694] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333333, 66.33333333333334, 1.0, 2.0, 0.3093517522646935, 1.0, 2.0, 0.3093517522646935, 1.0, 1.0, 0.6217477185583391, 6.911199999999999, 6.9112, 77.3421103, 1059019.133574839, 1059019.133574839, 253601.0797582816], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4207200.0000, 
sim time next is 4207800.0000, 
raw observation next is [23.16666666666667, 67.66666666666666, 1.0, 2.0, 0.8944561866649969, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1017116.903094984, 1017116.903094984, 191282.0448178279], 
processed observation next is [1.0, 0.6956521739130435, 0.6893939393939396, 0.6766666666666665, 1.0, 1.0, 0.8680702333312462, 0.0, 0.5, -0.25, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.37670996410925334, 0.37670996410925334, 0.4665415727264095], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1259878], dtype=float32), -0.41725314]. 
=============================================
[2019-03-23 08:28:51,048] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.7029880e-05 9.9993825e-01 3.1338820e-07 4.2484339e-06 1.6243240e-07], sum to 1.0000
[2019-03-23 08:28:51,054] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0812
[2019-03-23 08:28:51,061] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1569290.65524518 W.
[2019-03-23 08:28:51,064] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.33333333333333, 51.33333333333334, 1.0, 2.0, 0.461326651599227, 1.0, 2.0, 0.461326651599227, 1.0, 1.0, 0.9342507846553709, 6.911199999999999, 6.9112, 77.3421103, 1569290.65524518, 1569290.65524518, 333665.8513789158], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4380000.0000, 
sim time next is 4380600.0000, 
raw observation next is [28.16666666666667, 51.16666666666666, 1.0, 2.0, 0.8707647892297242, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9726905235293044, 6.911199999999999, 6.9112, 77.32846344354104, 1541687.497926407, 1541687.497926407, 314970.9814168885], 
processed observation next is [1.0, 0.6956521739130435, 0.9166666666666669, 0.5116666666666666, 1.0, 1.0, 0.8384559865371551, 0.0, 0.5, -0.25, 1.0, 1.0, 0.9609864621847206, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.570995369602373, 0.570995369602373, 0.76822190589485], 
reward next is 0.2318, 
noisyNet noise sample is [array([-1.1383946], dtype=float32), -1.5286883]. 
=============================================
[2019-03-23 08:28:56,473] A3C_AGENT_WORKER-Thread-2 INFO:Local step 7500, global step 119564: loss 0.1658
[2019-03-23 08:28:56,475] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 7500, global step 119565: learning rate 0.0005
[2019-03-23 08:28:56,507] A3C_AGENT_WORKER-Thread-14 INFO:Local step 7500, global step 119584: loss 0.1380
[2019-03-23 08:28:56,510] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 7500, global step 119585: learning rate 0.0005
[2019-03-23 08:28:56,555] A3C_AGENT_WORKER-Thread-21 INFO:Local step 7500, global step 119610: loss 0.1110
[2019-03-23 08:28:56,556] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 7500, global step 119610: learning rate 0.0005
[2019-03-23 08:28:56,758] A3C_AGENT_WORKER-Thread-12 INFO:Local step 7500, global step 119717: loss 0.0024
[2019-03-23 08:28:56,761] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 7500, global step 119717: learning rate 0.0005
[2019-03-23 08:28:56,789] A3C_AGENT_WORKER-Thread-3 INFO:Local step 7500, global step 119735: loss 0.0442
[2019-03-23 08:28:56,790] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 7500, global step 119735: learning rate 0.0005
[2019-03-23 08:28:56,937] A3C_AGENT_WORKER-Thread-9 INFO:Local step 7500, global step 119813: loss 0.0115
[2019-03-23 08:28:56,940] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 7500, global step 119814: learning rate 0.0005
[2019-03-23 08:28:56,965] A3C_AGENT_WORKER-Thread-15 INFO:Local step 7500, global step 119828: loss 0.0001
[2019-03-23 08:28:56,967] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 7500, global step 119828: learning rate 0.0005
[2019-03-23 08:28:57,019] A3C_AGENT_WORKER-Thread-16 INFO:Local step 7500, global step 119851: loss 0.0183
[2019-03-23 08:28:57,021] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 7500, global step 119853: learning rate 0.0005
[2019-03-23 08:28:57,036] A3C_AGENT_WORKER-Thread-13 INFO:Local step 7500, global step 119863: loss 0.0371
[2019-03-23 08:28:57,037] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 7500, global step 119863: learning rate 0.0005
[2019-03-23 08:28:57,166] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.9952858e-22 1.0000000e+00 1.7164693e-27 7.0012888e-23 2.1092523e-31], sum to 1.0000
[2019-03-23 08:28:57,174] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1571
[2019-03-23 08:28:57,182] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 94.0, 1.0, 2.0, 0.4236120280421113, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 481236.9680445376, 481236.9680445379, 129452.6261671528], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4503000.0000, 
sim time next is 4503600.0000, 
raw observation next is [20.0, 94.0, 1.0, 2.0, 0.4238623255214058, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 481521.4781384878, 481521.4781384878, 129477.1688771496], 
processed observation next is [0.0, 0.13043478260869565, 0.5454545454545454, 0.94, 1.0, 1.0, 0.2798279069017572, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17834128819943992, 0.17834128819943992, 0.31579797287109657], 
reward next is 0.6842, 
noisyNet noise sample is [array([-0.42609635], dtype=float32), 0.012202989]. 
=============================================
[2019-03-23 08:28:57,306] A3C_AGENT_WORKER-Thread-18 INFO:Local step 7500, global step 120007: loss 0.0028
[2019-03-23 08:28:57,308] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 7500, global step 120008: learning rate 0.0005
[2019-03-23 08:28:57,325] A3C_AGENT_WORKER-Thread-20 INFO:Local step 7500, global step 120016: loss 0.0035
[2019-03-23 08:28:57,328] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 7500, global step 120017: learning rate 0.0005
[2019-03-23 08:28:57,725] A3C_AGENT_WORKER-Thread-22 INFO:Local step 7500, global step 120230: loss 0.0887
[2019-03-23 08:28:57,726] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 7500, global step 120230: learning rate 0.0005
[2019-03-23 08:28:57,771] A3C_AGENT_WORKER-Thread-10 INFO:Local step 7500, global step 120256: loss 0.0361
[2019-03-23 08:28:57,772] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 7500, global step 120256: learning rate 0.0005
[2019-03-23 08:28:58,162] A3C_AGENT_WORKER-Thread-11 INFO:Local step 7500, global step 120463: loss 0.0060
[2019-03-23 08:28:58,164] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 7500, global step 120463: learning rate 0.0005
[2019-03-23 08:28:58,434] A3C_AGENT_WORKER-Thread-17 INFO:Local step 7500, global step 120605: loss 0.0004
[2019-03-23 08:28:58,437] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 7500, global step 120605: learning rate 0.0005
[2019-03-23 08:28:58,537] A3C_AGENT_WORKER-Thread-19 INFO:Local step 7500, global step 120659: loss 0.0459
[2019-03-23 08:28:58,537] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 7500, global step 120659: learning rate 0.0005
[2019-03-23 08:29:05,034] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.2552813e-26 1.0000000e+00 3.2087780e-29 1.5458299e-25 1.7466014e-35], sum to 1.0000
[2019-03-23 08:29:05,040] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8808
[2019-03-23 08:29:05,044] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 82.0, 1.0, 2.0, 0.2447101583592766, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 265702.684873203, 265702.6848732028, 83495.03320618016], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4671000.0000, 
sim time next is 4671600.0000, 
raw observation next is [16.0, 82.0, 1.0, 2.0, 0.2439387727475971, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 264864.8976793649, 264864.8976793646, 83409.96159285911], 
processed observation next is [1.0, 0.043478260869565216, 0.36363636363636365, 0.82, 1.0, 1.0, 0.05492346593449635, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09809811025161663, 0.09809811025161652, 0.2034389307142905], 
reward next is 0.7966, 
noisyNet noise sample is [array([-0.6436185], dtype=float32), -0.65507674]. 
=============================================
[2019-03-23 08:29:06,635] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 08:29:06,635] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 08:29:06,636] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:29:06,636] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 08:29:06,637] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 08:29:06,637] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:29:06,638] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 08:29:06,638] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:29:06,639] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 08:29:06,642] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:29:06,643] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:29:06,655] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run6
[2019-03-23 08:29:06,656] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run6
[2019-03-23 08:29:06,680] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run6
[2019-03-23 08:29:06,730] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run6
[2019-03-23 08:29:06,772] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run6
[2019-03-23 08:29:22,533] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02282269], dtype=float32), -0.7068283]
[2019-03-23 08:29:22,534] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [28.12364075, 82.42812854333333, 1.0, 2.0, 0.6612619353511905, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9405624264518986, 6.974868103062833, 6.9112, 95.55312764203619, 1291467.654080088, 1265916.171289594, 290392.2138530985]
[2019-03-23 08:29:22,535] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 08:29:22,536] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.9220585e-23 1.0000000e+00 8.4895624e-27 1.6314532e-23 1.0077278e-30], sampled 0.1416402652821669
[2019-03-23 08:29:22,538] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1291467.654080088 W.
[2019-03-23 08:29:26,539] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02282269], dtype=float32), -0.7068283]
[2019-03-23 08:29:26,540] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.8, 44.66666666666667, 1.0, 2.0, 0.3246010364647069, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 352454.0970732259, 352454.0970732259, 117179.9554569566]
[2019-03-23 08:29:26,542] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 08:29:26,546] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.9117323e-23 1.0000000e+00 4.5865760e-27 9.4971075e-24 4.9566704e-31], sampled 0.13721314672972418
[2019-03-23 08:29:47,071] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02282269], dtype=float32), -0.7068283]
[2019-03-23 08:29:47,073] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.4, 81.5, 1.0, 2.0, 0.355165705735016, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 394623.9845812991, 394623.9845812991, 122630.8828197562]
[2019-03-23 08:29:47,074] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 08:29:47,079] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.8978149e-23 1.0000000e+00 4.5606329e-27 9.4495502e-24 4.9243297e-31], sampled 0.2219988160194486
[2019-03-23 08:29:51,560] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02282269], dtype=float32), -0.7068283]
[2019-03-23 08:29:51,561] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.95, 88.0, 1.0, 2.0, 0.4285416310665116, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 487357.5811743826, 487357.5811743823, 134725.4983910402]
[2019-03-23 08:29:51,562] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 08:29:51,564] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.9187383e-23 1.0000000e+00 4.5996646e-27 9.5210478e-24 4.9729580e-31], sampled 0.07342392768952066
[2019-03-23 08:29:56,412] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02282269], dtype=float32), -0.7068283]
[2019-03-23 08:29:56,413] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [26.45, 50.0, 1.0, 2.0, 0.408732385032156, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 463242.2149047676, 463242.2149047676, 131546.4961238528]
[2019-03-23 08:29:56,414] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 08:29:56,417] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.9890943e-23 1.0000000e+00 4.7314660e-27 9.7623872e-24 5.1376325e-31], sampled 0.2547785393034311
[2019-03-23 08:29:58,595] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02282269], dtype=float32), -0.7068283]
[2019-03-23 08:29:58,596] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [28.56666666666667, 54.0, 1.0, 2.0, 0.6990173416345942, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 796771.669486024, 796771.669486024, 173264.1847028935]
[2019-03-23 08:29:58,601] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 08:29:58,605] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.5432653e-23 1.0000000e+00 5.7779940e-27 1.1639739e-23 6.4681704e-31], sampled 0.7256985430094104
[2019-03-23 08:30:14,182] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02282269], dtype=float32), -0.7068283]
[2019-03-23 08:30:14,186] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.3, 79.0, 1.0, 2.0, 0.3331000894263745, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 367926.3534625767, 367926.3534625763, 120025.4321370792]
[2019-03-23 08:30:14,187] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 08:30:14,192] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.8978149e-23 1.0000000e+00 4.5606329e-27 9.4495502e-24 4.9243297e-31], sampled 0.666405452399961
[2019-03-23 08:30:27,624] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02282269], dtype=float32), -0.7068283]
[2019-03-23 08:30:27,625] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [33.0833985, 57.92777299, 1.0, 2.0, 0.7207004507165821, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 809856.0562583825, 809856.0562583822, 181194.2789727252]
[2019-03-23 08:30:27,627] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 08:30:27,631] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.1604264e-23 1.0000000e+00 5.0526687e-27 1.0345414e-23 5.5418554e-31], sampled 0.2365179127744812
[2019-03-23 08:30:29,303] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02282269], dtype=float32), -0.7068283]
[2019-03-23 08:30:29,305] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [24.8, 69.0, 1.0, 2.0, 0.4923908517642505, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 561840.4098331841, 561840.4098331841, 139698.3263816008]
[2019-03-23 08:30:29,305] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 08:30:29,308] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.0283695e-23 1.0000000e+00 4.8052422e-27 9.8973787e-24 5.2301374e-31], sampled 0.034004245596712335
[2019-03-23 08:30:49,542] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 08:30:49,668] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 08:30:49,668] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 08:30:49,768] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 08:30:49,827] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 08:30:50,843] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 125000, evaluation results [125000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 08:30:52,292] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0761835e-16 1.0000000e+00 8.7556732e-20 2.3374910e-17 6.3539189e-22], sum to 1.0000
[2019-03-23 08:30:52,296] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7172
[2019-03-23 08:30:52,301] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333334, 56.0, 1.0, 2.0, 0.6624330933174374, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 739077.2087375271, 739077.2087375271, 149680.7431696823], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4707600.0000, 
sim time next is 4708200.0000, 
raw observation next is [23.66666666666666, 55.0, 1.0, 2.0, 0.6567812188502111, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 733978.0266050177, 733978.0266050181, 149503.5554072635], 
processed observation next is [1.0, 0.4782608695652174, 0.7121212121212118, 0.55, 1.0, 1.0, 0.5709765235627638, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.271843713557414, 0.2718437135574141, 0.3646428180664964], 
reward next is 0.6354, 
noisyNet noise sample is [array([-0.9791624], dtype=float32), 0.4451611]. 
=============================================
[2019-03-23 08:30:55,131] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.5202295e-24 1.0000000e+00 2.7378165e-29 1.3458763e-25 8.4124878e-33], sum to 1.0000
[2019-03-23 08:30:55,138] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6942
[2019-03-23 08:30:55,142] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.3663806582901976, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 411285.1430031187, 411285.143003119, 121077.9564935384], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4772400.0000, 
sim time next is 4773000.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.3663540995795839, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 411254.8178266307, 411254.8178266307, 121075.4712814174], 
processed observation next is [1.0, 0.21739130434782608, 0.45454545454545453, 1.0, 1.0, 1.0, 0.2079426244744799, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15231659919504842, 0.15231659919504842, 0.2953060275156522], 
reward next is 0.7047, 
noisyNet noise sample is [array([1.318085], dtype=float32), 0.9256704]. 
=============================================
[2019-03-23 08:30:55,161] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[75.667015]
 [75.667015]
 [75.667015]
 [75.667015]
 [75.667015]], R is [[75.61505127]
 [75.563591  ]
 [75.51261139]
 [75.46190643]
 [75.41036987]].
[2019-03-23 08:30:55,860] A3C_AGENT_WORKER-Thread-2 INFO:Local step 8000, global step 127557: loss 0.0206
[2019-03-23 08:30:55,862] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 8000, global step 127558: learning rate 0.0005
[2019-03-23 08:30:55,974] A3C_AGENT_WORKER-Thread-21 INFO:Local step 8000, global step 127617: loss 0.0340
[2019-03-23 08:30:55,979] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 8000, global step 127618: learning rate 0.0005
[2019-03-23 08:30:56,146] A3C_AGENT_WORKER-Thread-3 INFO:Local step 8000, global step 127706: loss 0.0488
[2019-03-23 08:30:56,149] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 8000, global step 127706: learning rate 0.0005
[2019-03-23 08:30:56,215] A3C_AGENT_WORKER-Thread-14 INFO:Local step 8000, global step 127737: loss 0.1267
[2019-03-23 08:30:56,217] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 8000, global step 127737: learning rate 0.0005
[2019-03-23 08:30:56,260] A3C_AGENT_WORKER-Thread-12 INFO:Local step 8000, global step 127759: loss 0.2491
[2019-03-23 08:30:56,262] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 8000, global step 127760: learning rate 0.0005
[2019-03-23 08:30:56,331] A3C_AGENT_WORKER-Thread-16 INFO:Local step 8000, global step 127798: loss 0.6445
[2019-03-23 08:30:56,337] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 8000, global step 127799: learning rate 0.0005
[2019-03-23 08:30:56,389] A3C_AGENT_WORKER-Thread-9 INFO:Local step 8000, global step 127824: loss 0.7307
[2019-03-23 08:30:56,391] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 8000, global step 127825: learning rate 0.0005
[2019-03-23 08:30:56,433] A3C_AGENT_WORKER-Thread-15 INFO:Local step 8000, global step 127846: loss 0.4560
[2019-03-23 08:30:56,434] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 8000, global step 127846: learning rate 0.0005
[2019-03-23 08:30:56,485] A3C_AGENT_WORKER-Thread-13 INFO:Local step 8000, global step 127876: loss 0.4601
[2019-03-23 08:30:56,487] A3C_AGENT_WORKER-Thread-18 INFO:Local step 8000, global step 127876: loss 0.4439
[2019-03-23 08:30:56,490] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 8000, global step 127879: learning rate 0.0005
[2019-03-23 08:30:56,491] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 8000, global step 127879: learning rate 0.0005
[2019-03-23 08:30:56,559] A3C_AGENT_WORKER-Thread-20 INFO:Local step 8000, global step 127907: loss 0.6737
[2019-03-23 08:30:56,562] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 8000, global step 127908: learning rate 0.0005
[2019-03-23 08:30:57,055] A3C_AGENT_WORKER-Thread-22 INFO:Local step 8000, global step 128160: loss 0.8677
[2019-03-23 08:30:57,055] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 8000, global step 128160: learning rate 0.0005
[2019-03-23 08:30:57,222] A3C_AGENT_WORKER-Thread-10 INFO:Local step 8000, global step 128244: loss 0.7748
[2019-03-23 08:30:57,225] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 8000, global step 128245: learning rate 0.0005
[2019-03-23 08:30:57,423] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.8339975e-20 1.0000000e+00 9.0982957e-24 5.2138118e-20 1.9512581e-26], sum to 1.0000
[2019-03-23 08:30:57,430] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5030
[2019-03-23 08:30:57,434] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4891511042858612, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 558097.1479106713, 558097.1479106711, 140239.2640342566], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4825200.0000, 
sim time next is 4825800.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.4905378134586687, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 559680.0991904326, 559680.0991904326, 140398.3989896334], 
processed observation next is [1.0, 0.8695652173913043, 0.5909090909090909, 1.0, 1.0, 1.0, 0.36317226682333587, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20728892562608614, 0.20728892562608614, 0.34243511948691074], 
reward next is 0.6576, 
noisyNet noise sample is [array([0.5086023], dtype=float32), -0.4146773]. 
=============================================
[2019-03-23 08:30:57,743] A3C_AGENT_WORKER-Thread-11 INFO:Local step 8000, global step 128508: loss 0.0248
[2019-03-23 08:30:57,744] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 8000, global step 128508: learning rate 0.0005
[2019-03-23 08:30:57,871] A3C_AGENT_WORKER-Thread-17 INFO:Local step 8000, global step 128571: loss 0.0432
[2019-03-23 08:30:57,873] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 8000, global step 128572: learning rate 0.0005
[2019-03-23 08:30:57,976] A3C_AGENT_WORKER-Thread-19 INFO:Local step 8000, global step 128627: loss 0.0368
[2019-03-23 08:30:57,980] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 8000, global step 128627: learning rate 0.0005
[2019-03-23 08:30:59,413] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.5075553e-20 1.0000000e+00 1.7053897e-24 3.6674757e-22 2.3203582e-28], sum to 1.0000
[2019-03-23 08:30:59,419] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5560
[2019-03-23 08:30:59,423] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.4191090764561712, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 475104.632146619, 475104.632146619, 128263.9011287549], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4860600.0000, 
sim time next is 4861200.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4109406333880577, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 465844.7055603672, 465844.7055603672, 127487.6463839013], 
processed observation next is [1.0, 0.2608695652173913, 0.5, 1.0, 1.0, 1.0, 0.2636757917350721, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17253507613346933, 0.17253507613346933, 0.31094547898512515], 
reward next is 0.6891, 
noisyNet noise sample is [array([-2.0997097], dtype=float32), 0.43425617]. 
=============================================
[2019-03-23 08:31:11,409] A3C_AGENT_WORKER-Thread-2 INFO:Local step 8500, global step 135548: loss 0.0662
[2019-03-23 08:31:11,413] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 8500, global step 135549: learning rate 0.0005
[2019-03-23 08:31:11,457] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.9611065e-23 1.0000000e+00 2.5963111e-27 8.6035521e-24 1.2305332e-29], sum to 1.0000
[2019-03-23 08:31:11,466] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5021
[2019-03-23 08:31:11,469] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 78.0, 1.0, 2.0, 0.4136626139148533, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 469773.0523224404, 469773.0523224404, 128360.9963390197], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5100000.0000, 
sim time next is 5100600.0000, 
raw observation next is [22.0, 78.0, 1.0, 2.0, 0.4148430156441618, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 471114.3920268615, 471114.3920268615, 128474.9663343542], 
processed observation next is [0.0, 0.0, 0.6363636363636364, 0.78, 1.0, 1.0, 0.2685537695552022, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17448681186180054, 0.17448681186180054, 0.31335357642525413], 
reward next is 0.6866, 
noisyNet noise sample is [array([-1.5158801], dtype=float32), -1.4387379]. 
=============================================
[2019-03-23 08:31:11,635] A3C_AGENT_WORKER-Thread-3 INFO:Local step 8500, global step 135674: loss 0.0058
[2019-03-23 08:31:11,637] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 8500, global step 135675: learning rate 0.0005
[2019-03-23 08:31:11,667] A3C_AGENT_WORKER-Thread-14 INFO:Local step 8500, global step 135689: loss 0.0416
[2019-03-23 08:31:11,670] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 8500, global step 135689: learning rate 0.0005
[2019-03-23 08:31:11,688] A3C_AGENT_WORKER-Thread-21 INFO:Local step 8500, global step 135697: loss 0.0441
[2019-03-23 08:31:11,690] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 8500, global step 135698: learning rate 0.0005
[2019-03-23 08:31:11,714] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.8616720e-23 1.0000000e+00 1.3143068e-27 1.8353831e-24 5.7214137e-32], sum to 1.0000
[2019-03-23 08:31:11,723] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7437
[2019-03-23 08:31:11,728] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 80.5, 1.0, 2.0, 0.4283156138530803, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 487389.0147424785, 487389.0147424788, 130625.6628451537], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5095800.0000, 
sim time next is 5096400.0000, 
raw observation next is [22.0, 79.66666666666667, 1.0, 2.0, 0.4249314496288941, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 483273.9570742114, 483273.9570742114, 130040.1834164642], 
processed observation next is [0.0, 1.0, 0.6363636363636364, 0.7966666666666667, 1.0, 1.0, 0.28116431203611764, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17899035447193015, 0.17899035447193015, 0.31717117906454684], 
reward next is 0.6828, 
noisyNet noise sample is [array([0.2919431], dtype=float32), -1.4284713]. 
=============================================
[2019-03-23 08:31:11,853] A3C_AGENT_WORKER-Thread-12 INFO:Local step 8500, global step 135788: loss 0.0022
[2019-03-23 08:31:11,854] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 8500, global step 135788: learning rate 0.0005
[2019-03-23 08:31:11,913] A3C_AGENT_WORKER-Thread-15 INFO:Local step 8500, global step 135823: loss 0.0546
[2019-03-23 08:31:11,915] A3C_AGENT_WORKER-Thread-9 INFO:Local step 8500, global step 135824: loss 0.0285
[2019-03-23 08:31:11,916] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 8500, global step 135824: learning rate 0.0005
[2019-03-23 08:31:11,917] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 8500, global step 135824: learning rate 0.0005
[2019-03-23 08:31:11,938] A3C_AGENT_WORKER-Thread-16 INFO:Local step 8500, global step 135836: loss 0.0721
[2019-03-23 08:31:11,939] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 8500, global step 135836: learning rate 0.0005
[2019-03-23 08:31:11,975] A3C_AGENT_WORKER-Thread-20 INFO:Local step 8500, global step 135852: loss 0.0853
[2019-03-23 08:31:11,978] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 8500, global step 135853: learning rate 0.0005
[2019-03-23 08:31:12,059] A3C_AGENT_WORKER-Thread-13 INFO:Local step 8500, global step 135901: loss 0.0306
[2019-03-23 08:31:12,061] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 8500, global step 135902: learning rate 0.0005
[2019-03-23 08:31:12,108] A3C_AGENT_WORKER-Thread-18 INFO:Local step 8500, global step 135927: loss 0.0002
[2019-03-23 08:31:12,109] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 8500, global step 135927: learning rate 0.0005
[2019-03-23 08:31:12,584] A3C_AGENT_WORKER-Thread-22 INFO:Local step 8500, global step 136185: loss 0.0712
[2019-03-23 08:31:12,585] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 8500, global step 136186: learning rate 0.0005
[2019-03-23 08:31:12,664] A3C_AGENT_WORKER-Thread-10 INFO:Local step 8500, global step 136233: loss 0.0031
[2019-03-23 08:31:12,665] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 8500, global step 136233: learning rate 0.0005
[2019-03-23 08:31:13,295] A3C_AGENT_WORKER-Thread-17 INFO:Local step 8500, global step 136563: loss 0.0014
[2019-03-23 08:31:13,299] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 8500, global step 136565: learning rate 0.0005
[2019-03-23 08:31:13,347] A3C_AGENT_WORKER-Thread-11 INFO:Local step 8500, global step 136595: loss 0.0035
[2019-03-23 08:31:13,350] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 8500, global step 136595: learning rate 0.0005
[2019-03-23 08:31:13,502] A3C_AGENT_WORKER-Thread-19 INFO:Local step 8500, global step 136674: loss 0.0020
[2019-03-23 08:31:13,504] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 8500, global step 136674: learning rate 0.0005
[2019-03-23 08:31:16,781] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.9715901e-23 1.0000000e+00 4.4308006e-27 4.0073929e-24 2.6083373e-31], sum to 1.0000
[2019-03-23 08:31:16,790] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9130
[2019-03-23 08:31:16,798] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 82.16666666666667, 1.0, 2.0, 0.4375265406204841, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 498329.4466243614, 498329.4466243617, 132035.6624747939], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5206200.0000, 
sim time next is 5206800.0000, 
raw observation next is [22.0, 81.33333333333334, 1.0, 2.0, 0.4241105164332144, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 482831.0635823695, 482831.0635823695, 130442.316851478], 
processed observation next is [1.0, 0.2608695652173913, 0.6363636363636364, 0.8133333333333335, 1.0, 1.0, 0.28013814554151795, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17882631984532202, 0.17882631984532202, 0.31815199232067803], 
reward next is 0.6818, 
noisyNet noise sample is [array([0.34569713], dtype=float32), 0.5555732]. 
=============================================
[2019-03-23 08:31:21,810] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.1365250e-21 1.0000000e+00 1.0170070e-24 1.6844753e-22 8.2358939e-29], sum to 1.0000
[2019-03-23 08:31:21,820] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3857
[2019-03-23 08:31:21,828] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.7, 73.0, 1.0, 2.0, 0.3960078891582422, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 449451.5083401317, 449451.508340132, 126478.8094918565], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5299200.0000, 
sim time next is 5299800.0000, 
raw observation next is [22.98333333333333, 71.16666666666667, 1.0, 2.0, 0.4186753125660381, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 475373.882394887, 475373.882394887, 128772.4770101918], 
processed observation next is [1.0, 0.34782608695652173, 0.6810606060606059, 0.7116666666666667, 1.0, 1.0, 0.27334414070754764, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17606440088699518, 0.17606440088699518, 0.31407921221998], 
reward next is 0.6859, 
noisyNet noise sample is [array([-1.0047679], dtype=float32), 0.4830712]. 
=============================================
[2019-03-23 08:31:26,073] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.9306637e-22 1.0000000e+00 2.4854520e-21 9.5996836e-15 1.1777484e-23], sum to 1.0000
[2019-03-23 08:31:26,081] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9384
[2019-03-23 08:31:26,089] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.7, 93.0, 1.0, 2.0, 0.424933698212422, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 481285.9588322458, 481285.9588322456, 128543.6165387027], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5380200.0000, 
sim time next is 5380800.0000, 
raw observation next is [19.8, 93.0, 1.0, 2.0, 0.4428473153633392, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 501974.4917466154, 501974.4917466154, 130543.976201332], 
processed observation next is [1.0, 0.2608695652173913, 0.5363636363636364, 0.93, 1.0, 1.0, 0.30355914420417396, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18591647842467238, 0.18591647842467238, 0.3183999419544683], 
reward next is 0.6816, 
noisyNet noise sample is [array([0.9382438], dtype=float32), 0.09419707]. 
=============================================
[2019-03-23 08:31:26,481] A3C_AGENT_WORKER-Thread-2 INFO:Local step 9000, global step 143611: loss 148.2636
[2019-03-23 08:31:26,484] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 9000, global step 143612: learning rate 0.0005
[2019-03-23 08:31:26,701] A3C_AGENT_WORKER-Thread-21 INFO:Local step 9000, global step 143731: loss 0.2131
[2019-03-23 08:31:26,702] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 9000, global step 143732: learning rate 0.0005
[2019-03-23 08:31:26,742] A3C_AGENT_WORKER-Thread-14 INFO:Local step 9000, global step 143753: loss 0.2555
[2019-03-23 08:31:26,743] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 9000, global step 143753: learning rate 0.0005
[2019-03-23 08:31:26,762] A3C_AGENT_WORKER-Thread-20 INFO:Local step 9000, global step 143763: loss 0.0396
[2019-03-23 08:31:26,764] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 9000, global step 143764: learning rate 0.0005
[2019-03-23 08:31:26,882] A3C_AGENT_WORKER-Thread-9 INFO:Local step 9000, global step 143826: loss -22.2809
[2019-03-23 08:31:26,883] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 9000, global step 143826: learning rate 0.0005
[2019-03-23 08:31:26,908] A3C_AGENT_WORKER-Thread-3 INFO:Local step 9000, global step 143839: loss 37.5745
[2019-03-23 08:31:26,912] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 9000, global step 143841: learning rate 0.0005
[2019-03-23 08:31:26,945] A3C_AGENT_WORKER-Thread-12 INFO:Local step 9000, global step 143859: loss 26.2532
[2019-03-23 08:31:26,946] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 9000, global step 143859: learning rate 0.0005
[2019-03-23 08:31:26,995] A3C_AGENT_WORKER-Thread-13 INFO:Local step 9000, global step 143884: loss 19.7298
[2019-03-23 08:31:26,997] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 9000, global step 143885: learning rate 0.0005
[2019-03-23 08:31:26,997] A3C_AGENT_WORKER-Thread-16 INFO:Local step 9000, global step 143885: loss 34.1080
[2019-03-23 08:31:27,008] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 9000, global step 143886: learning rate 0.0005
[2019-03-23 08:31:27,021] A3C_AGENT_WORKER-Thread-18 INFO:Local step 9000, global step 143897: loss -75.8127
[2019-03-23 08:31:27,022] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 9000, global step 143897: learning rate 0.0005
[2019-03-23 08:31:27,085] A3C_AGENT_WORKER-Thread-15 INFO:Local step 9000, global step 143929: loss 174.8993
[2019-03-23 08:31:27,091] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 9000, global step 143933: learning rate 0.0005
[2019-03-23 08:31:27,490] A3C_AGENT_WORKER-Thread-22 INFO:Local step 9000, global step 144145: loss 1.4336
[2019-03-23 08:31:27,495] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 9000, global step 144146: learning rate 0.0005
[2019-03-23 08:31:27,580] A3C_AGENT_WORKER-Thread-10 INFO:Local step 9000, global step 144191: loss -5.3955
[2019-03-23 08:31:27,583] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 9000, global step 144191: learning rate 0.0005
[2019-03-23 08:31:28,063] A3C_AGENT_WORKER-Thread-11 INFO:Local step 9000, global step 144451: loss 19.8972
[2019-03-23 08:31:28,064] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 9000, global step 144453: learning rate 0.0005
[2019-03-23 08:31:28,145] A3C_AGENT_WORKER-Thread-17 INFO:Local step 9000, global step 144492: loss 8.3397
[2019-03-23 08:31:28,147] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 9000, global step 144494: learning rate 0.0005
[2019-03-23 08:31:28,263] A3C_AGENT_WORKER-Thread-19 INFO:Local step 9000, global step 144554: loss 0.5595
[2019-03-23 08:31:28,266] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 9000, global step 144554: learning rate 0.0005
[2019-03-23 08:31:29,678] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.4323262e-21 1.0000000e+00 7.9113515e-22 1.0611492e-12 9.4523520e-26], sum to 1.0000
[2019-03-23 08:31:29,680] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8881
[2019-03-23 08:31:29,686] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.1, 95.0, 1.0, 2.0, 0.3979735967784411, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 449418.4144784815, 449418.4144784812, 125192.2559948009], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5427000.0000, 
sim time next is 5427600.0000, 
raw observation next is [19.0, 95.66666666666666, 1.0, 2.0, 0.3970694942735168, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 448296.2640756891, 448296.2640756891, 125052.4173724242], 
processed observation next is [1.0, 0.8260869565217391, 0.5, 0.9566666666666666, 1.0, 1.0, 0.24633686784189596, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16603565336136633, 0.16603565336136633, 0.3050058960303029], 
reward next is 0.6950, 
noisyNet noise sample is [array([-0.8836839], dtype=float32), -1.2441049]. 
=============================================
[2019-03-23 08:31:31,546] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.04036404e-10 9.81966734e-01 7.15548107e-11 1.80332065e-02
 5.00777059e-11], sum to 1.0000
[2019-03-23 08:31:31,553] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8554
[2019-03-23 08:31:31,561] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.8, 83.66666666666667, 1.0, 2.0, 0.8036105801382255, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 915800.6174273356, 915800.6174273356, 179043.9683138803], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5478000.0000, 
sim time next is 5478600.0000, 
raw observation next is [22.25, 82.83333333333334, 1.0, 2.0, 0.8197250537235348, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 935101.3056346566, 935101.3056346566, 182884.7248734751], 
processed observation next is [1.0, 0.391304347826087, 0.6477272727272727, 0.8283333333333335, 1.0, 1.0, 0.7746563171544185, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.34633381690172466, 0.34633381690172466, 0.44606030456945145], 
reward next is 0.5539, 
noisyNet noise sample is [array([-0.10286876], dtype=float32), -0.7631335]. 
=============================================
[2019-03-23 08:31:32,482] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.286862e-10 9.992391e-01 1.396578e-10 7.609030e-04 3.892719e-11], sum to 1.0000
[2019-03-23 08:31:32,489] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4831
[2019-03-23 08:31:32,493] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.21666666666667, 74.33333333333334, 1.0, 2.0, 0.4850607495818041, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 553490.3327124427, 553490.3327124425, 139440.2683443024], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5519400.0000, 
sim time next is 5520000.0000, 
raw observation next is [24.03333333333333, 74.66666666666667, 1.0, 2.0, 0.4801652257392837, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 547911.2132126631, 547911.2132126631, 138626.1510218682], 
processed observation next is [1.0, 0.9130434782608695, 0.7287878787878787, 0.7466666666666667, 1.0, 1.0, 0.35020653217410463, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.202930078967653, 0.202930078967653, 0.3381125634679712], 
reward next is 0.6619, 
noisyNet noise sample is [array([-0.45355862], dtype=float32), -0.68345606]. 
=============================================
[2019-03-23 08:31:32,509] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[26.742136]
 [26.709854]
 [26.72285 ]
 [26.885498]
 [27.758522]], R is [[27.19649315]
 [27.58443069]
 [27.9668541 ]
 [28.34487534]
 [28.71893501]].
[2019-03-23 08:31:34,023] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.5191445e-25 1.0000000e+00 1.2038674e-30 2.1952810e-19 1.8659791e-32], sum to 1.0000
[2019-03-23 08:31:34,028] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0535
[2019-03-23 08:31:34,043] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.5, 73.5, 1.0, 2.0, 0.4908056786238945, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 560006.6908933712, 560006.6908933712, 140347.4541045233], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5518200.0000, 
sim time next is 5518800.0000, 
raw observation next is [24.4, 74.0, 1.0, 2.0, 0.4891154148558473, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 558086.8110545768, 558086.811054577, 140110.039574587], 
processed observation next is [1.0, 0.9130434782608695, 0.7454545454545454, 0.74, 1.0, 1.0, 0.3613942685698091, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2066988189091025, 0.2066988189091026, 0.3417318038404561], 
reward next is 0.6583, 
noisyNet noise sample is [array([0.15471265], dtype=float32), -1.1872971]. 
=============================================
[2019-03-23 08:31:37,671] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.9830671e-24 1.0000000e+00 9.1123401e-29 6.6589463e-16 1.0470469e-32], sum to 1.0000
[2019-03-23 08:31:37,678] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0431
[2019-03-23 08:31:37,683] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 90.0, 1.0, 2.0, 0.3881734238682161, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 437087.1885394402, 437087.1885394399, 123614.7267434905], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5612400.0000, 
sim time next is 5613000.0000, 
raw observation next is [19.4, 90.5, 1.0, 2.0, 0.3883590806899814, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 437492.3614764941, 437492.3614764941, 123734.7069125567], 
processed observation next is [1.0, 1.0, 0.5181818181818181, 0.905, 1.0, 1.0, 0.2354488508624767, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16203420795425708, 0.16203420795425708, 0.3017919680794066], 
reward next is 0.6982, 
noisyNet noise sample is [array([-0.17097616], dtype=float32), 0.30020884]. 
=============================================
[2019-03-23 08:31:37,696] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[65.33424]
 [65.33424]
 [65.33424]
 [65.33424]
 [65.33424]], R is [[65.37909698]
 [65.42380524]
 [65.46800995]
 [65.51172638]
 [65.5549469 ]].
[2019-03-23 08:31:38,465] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 08:31:38,468] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 08:31:38,469] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 08:31:38,469] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:31:38,470] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:31:38,470] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 08:31:38,471] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:31:38,471] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 08:31:38,472] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:31:38,473] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 08:31:38,474] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:31:38,489] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run7
[2019-03-23 08:31:38,512] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run7
[2019-03-23 08:31:38,514] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run7
[2019-03-23 08:31:38,514] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run7
[2019-03-23 08:31:38,593] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run7
[2019-03-23 08:31:40,282] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02836603], dtype=float32), -0.81009614]
[2019-03-23 08:31:40,282] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.25, 35.0, 1.0, 2.0, 0.3587332168265785, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 389527.0707682433, 389527.0707682429, 95203.68402491031]
[2019-03-23 08:31:40,284] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 08:31:40,287] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.47345523e-25 1.00000000e+00 1.13995154e-29 9.26436827e-18
 4.32826387e-33], sampled 0.8449727472699806
[2019-03-23 08:31:48,344] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02836603], dtype=float32), -0.81009614]
[2019-03-23 08:31:48,345] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [17.55, 63.66666666666666, 1.0, 2.0, 0.2501135985339403, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 271556.8389665759, 271556.8389665756, 84977.34094536198]
[2019-03-23 08:31:48,346] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 08:31:48,348] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.47345523e-25 1.00000000e+00 1.13995154e-29 9.26436827e-18
 4.32826387e-33], sampled 0.7846869859342912
[2019-03-23 08:31:59,043] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02836603], dtype=float32), -0.81009614]
[2019-03-23 08:31:59,045] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.33333333333334, 44.0, 1.0, 2.0, 0.4761166557537839, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 517094.0524603709, 517094.0524603709, 100425.7868358169]
[2019-03-23 08:31:59,045] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 08:31:59,048] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.47345523e-25 1.00000000e+00 1.13995154e-29 9.26436827e-18
 4.32826387e-33], sampled 0.42082194535662587
[2019-03-23 08:32:15,107] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02836603], dtype=float32), -0.81009614]
[2019-03-23 08:32:15,109] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.41805722333333, 98.180064555, 1.0, 2.0, 0.5449030189841066, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 618821.5323629396, 618821.5323629396, 153796.8204475767]
[2019-03-23 08:32:15,111] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 08:32:15,114] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.5863007e-25 1.0000000e+00 3.2550350e-29 1.7964808e-17 1.3960191e-32], sampled 0.6775106533433097
[2019-03-23 08:32:30,629] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02836603], dtype=float32), -0.81009614]
[2019-03-23 08:32:30,632] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.0, 100.0, 1.0, 2.0, 0.3783627745050517, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 424781.8325276767, 424781.8325276767, 122117.6869267412]
[2019-03-23 08:32:30,633] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 08:32:30,635] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.47345523e-25 1.00000000e+00 1.13995154e-29 9.26436827e-18
 4.32826387e-33], sampled 0.9661482552140755
[2019-03-23 08:33:04,148] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02836603], dtype=float32), -0.81009614]
[2019-03-23 08:33:04,149] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.66666666666666, 67.33333333333333, 1.0, 2.0, 0.4153313277386148, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 471710.5117905923, 471710.511790592, 132895.7904854231]
[2019-03-23 08:33:04,150] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 08:33:04,152] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.6570105e-25 1.0000000e+00 1.3123064e-29 1.0238109e-17 5.0645399e-33], sampled 0.8745982508702727
[2019-03-23 08:33:20,956] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8679.4646 1699262540.4638 192.0000
[2019-03-23 08:33:21,183] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8504.6187 1758263570.1077 113.0000
[2019-03-23 08:33:21,343] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8878.3347 1662349760.3319 41.0000
[2019-03-23 08:33:21,385] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8614.0855 1679171267.9102 92.0000
[2019-03-23 08:33:21,521] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9074.4330 1656004021.4111 39.0000
[2019-03-23 08:33:22,536] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 150000, evaluation results [150000.0, 8504.618743760759, 1758263570.1077378, 113.0, 9074.43296612868, 1656004021.41109, 39.0, 8878.334661587252, 1662349760.3319273, 41.0, 8679.464619334098, 1699262540.4637544, 192.0, 8614.085486611686, 1679171267.9101872, 92.0]
[2019-03-23 08:33:25,643] A3C_AGENT_WORKER-Thread-2 INFO:Local step 9500, global step 151584: loss 9.5000
[2019-03-23 08:33:25,645] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 9500, global step 151584: learning rate 0.0005
[2019-03-23 08:33:25,738] A3C_AGENT_WORKER-Thread-21 INFO:Local step 9500, global step 151633: loss 8.3898
[2019-03-23 08:33:25,741] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 9500, global step 151634: learning rate 0.0005
[2019-03-23 08:33:25,906] A3C_AGENT_WORKER-Thread-9 INFO:Local step 9500, global step 151721: loss 6.9463
[2019-03-23 08:33:25,911] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 9500, global step 151721: learning rate 0.0005
[2019-03-23 08:33:25,949] A3C_AGENT_WORKER-Thread-14 INFO:Local step 9500, global step 151738: loss 6.5475
[2019-03-23 08:33:25,951] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 9500, global step 151739: learning rate 0.0005
[2019-03-23 08:33:25,987] A3C_AGENT_WORKER-Thread-12 INFO:Local step 9500, global step 151758: loss 6.1285
[2019-03-23 08:33:25,990] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 9500, global step 151758: learning rate 0.0005
[2019-03-23 08:33:26,148] A3C_AGENT_WORKER-Thread-13 INFO:Local step 9500, global step 151839: loss 5.4102
[2019-03-23 08:33:26,149] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 9500, global step 151839: learning rate 0.0005
[2019-03-23 08:33:26,213] A3C_AGENT_WORKER-Thread-3 INFO:Local step 9500, global step 151874: loss 5.2082
[2019-03-23 08:33:26,215] A3C_AGENT_WORKER-Thread-20 INFO:Local step 9500, global step 151874: loss 5.1215
[2019-03-23 08:33:26,216] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 9500, global step 151875: learning rate 0.0005
[2019-03-23 08:33:26,217] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 9500, global step 151875: learning rate 0.0005
[2019-03-23 08:33:26,257] A3C_AGENT_WORKER-Thread-15 INFO:Local step 9500, global step 151895: loss 5.3481
[2019-03-23 08:33:26,263] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 9500, global step 151896: learning rate 0.0005
[2019-03-23 08:33:26,307] A3C_AGENT_WORKER-Thread-18 INFO:Local step 9500, global step 151921: loss 4.8625
[2019-03-23 08:33:26,309] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 9500, global step 151921: learning rate 0.0005
[2019-03-23 08:33:26,323] A3C_AGENT_WORKER-Thread-16 INFO:Local step 9500, global step 151926: loss 4.4533
[2019-03-23 08:33:26,324] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 9500, global step 151926: learning rate 0.0005
[2019-03-23 08:33:26,712] A3C_AGENT_WORKER-Thread-22 INFO:Local step 9500, global step 152123: loss 3.5379
[2019-03-23 08:33:26,715] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 9500, global step 152125: learning rate 0.0005
[2019-03-23 08:33:26,851] A3C_AGENT_WORKER-Thread-10 INFO:Local step 9500, global step 152194: loss 2.6685
[2019-03-23 08:33:26,853] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 9500, global step 152194: learning rate 0.0005
[2019-03-23 08:33:27,585] A3C_AGENT_WORKER-Thread-11 INFO:Local step 9500, global step 152567: loss -0.6048
[2019-03-23 08:33:27,587] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 9500, global step 152568: learning rate 0.0005
[2019-03-23 08:33:27,604] A3C_AGENT_WORKER-Thread-17 INFO:Local step 9500, global step 152576: loss -0.8160
[2019-03-23 08:33:27,607] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 9500, global step 152577: learning rate 0.0005
[2019-03-23 08:33:27,664] A3C_AGENT_WORKER-Thread-19 INFO:Local step 9500, global step 152608: loss -0.0024
[2019-03-23 08:33:27,668] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 9500, global step 152610: learning rate 0.0005
[2019-03-23 08:33:32,218] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.6097514e-38 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 08:33:32,223] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3336
[2019-03-23 08:33:32,228] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.76666666666667, 73.33333333333333, 1.0, 2.0, 0.2414069032982528, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 262115.0927234954, 262115.0927234956, 76078.39998957122], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5814600.0000, 
sim time next is 5815200.0000, 
raw observation next is [15.13333333333333, 71.66666666666667, 1.0, 2.0, 0.2009941564286221, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 218225.8456989192, 218225.8456989189, 71954.62758780553], 
processed observation next is [1.0, 0.30434782608695654, 0.32424242424242405, 0.7166666666666667, 1.0, 1.0, 0.001242695535777598, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.080824387295896, 0.08082438729589589, 0.17549909167757446], 
reward next is 0.8245, 
noisyNet noise sample is [array([-0.11801075], dtype=float32), -0.61915416]. 
=============================================
[2019-03-23 08:33:35,418] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.4443364e-27 1.0000000e+00 0.0000000e+00 3.6976072e-30 0.0000000e+00], sum to 1.0000
[2019-03-23 08:33:35,424] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1228
[2019-03-23 08:33:35,428] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 79.0, 1.0, 2.0, 0.3212664556506453, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 352975.1811217814, 352975.1811217811, 114107.4334050491], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5875200.0000, 
sim time next is 5875800.0000, 
raw observation next is [18.88333333333333, 79.83333333333334, 1.0, 2.0, 0.3203435392342162, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 351852.4805354308, 351852.4805354311, 114000.3600562002], 
processed observation next is [1.0, 0.0, 0.4946969696969695, 0.7983333333333335, 1.0, 1.0, 0.15042942404277024, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13031573353164103, 0.13031573353164116, 0.278049658673659], 
reward next is 0.7220, 
noisyNet noise sample is [array([0.23046196], dtype=float32), -0.18728386]. 
=============================================
[2019-03-23 08:33:37,172] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.8761391e-22 1.0000000e+00 3.5816176e-29 9.6303867e-22 1.2025300e-33], sum to 1.0000
[2019-03-23 08:33:37,178] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1104
[2019-03-23 08:33:37,183] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.95, 74.5, 1.0, 2.0, 0.4646550798449726, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 513195.4978170656, 513195.4978170656, 126586.8594365316], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5905800.0000, 
sim time next is 5906400.0000, 
raw observation next is [20.33333333333334, 74.0, 1.0, 2.0, 0.4776459869229858, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 530251.8529132428, 530251.8529132425, 128769.830871021], 
processed observation next is [1.0, 0.34782608695652173, 0.5606060606060609, 0.74, 1.0, 1.0, 0.34705748365373223, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1963895751530529, 0.1963895751530528, 0.3140727582220024], 
reward next is 0.6859, 
noisyNet noise sample is [array([-0.93260956], dtype=float32), 0.10498847]. 
=============================================
[2019-03-23 08:33:37,676] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.5012984e-19 1.0000000e+00 3.2396140e-28 3.0459382e-20 4.7689706e-29], sum to 1.0000
[2019-03-23 08:33:37,681] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5975
[2019-03-23 08:33:37,685] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.7, 46.0, 1.0, 2.0, 0.8898265042848131, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1012271.284584448, 1012271.284584448, 190900.2334416508], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5928000.0000, 
sim time next is 5928600.0000, 
raw observation next is [27.7, 46.0, 1.0, 2.0, 0.9048043931299753, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1029361.294659601, 1029361.294659601, 193397.838142388], 
processed observation next is [1.0, 0.6086956521739131, 0.8954545454545454, 0.46, 1.0, 1.0, 0.881005491412469, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.38124492394800036, 0.38124492394800036, 0.47170204424972684], 
reward next is 0.5283, 
noisyNet noise sample is [array([1.718318], dtype=float32), -0.48004493]. 
=============================================
[2019-03-23 08:33:39,685] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.3289274e-19 1.0000000e+00 3.0604231e-30 7.6244808e-23 1.6916595e-32], sum to 1.0000
[2019-03-23 08:33:39,705] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1667
[2019-03-23 08:33:39,712] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 65.0, 1.0, 2.0, 0.3887114833651545, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 438275.7255137858, 438275.7255137858, 123973.7198941557], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5952600.0000, 
sim time next is 5953200.0000, 
raw observation next is [22.9, 65.33333333333334, 1.0, 2.0, 0.3869448529099225, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 436099.9823482194, 436099.9823482194, 123717.1345186774], 
processed observation next is [1.0, 0.9130434782608695, 0.6772727272727272, 0.6533333333333334, 1.0, 1.0, 0.23368106613740308, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16151851198082198, 0.16151851198082198, 0.30174910858214], 
reward next is 0.6983, 
noisyNet noise sample is [array([1.6727374], dtype=float32), 0.005405056]. 
=============================================
[2019-03-23 08:33:41,171] A3C_AGENT_WORKER-Thread-21 INFO:Local step 10000, global step 159492: loss 0.7734
[2019-03-23 08:33:41,174] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 10000, global step 159492: learning rate 0.0005
[2019-03-23 08:33:41,375] A3C_AGENT_WORKER-Thread-2 INFO:Local step 10000, global step 159602: loss 0.1144
[2019-03-23 08:33:41,377] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 10000, global step 159602: learning rate 0.0005
[2019-03-23 08:33:41,589] A3C_AGENT_WORKER-Thread-12 INFO:Local step 10000, global step 159711: loss 0.0967
[2019-03-23 08:33:41,592] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 10000, global step 159711: learning rate 0.0005
[2019-03-23 08:33:41,598] A3C_AGENT_WORKER-Thread-9 INFO:Local step 10000, global step 159714: loss 0.0763
[2019-03-23 08:33:41,606] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 10000, global step 159714: learning rate 0.0005
[2019-03-23 08:33:41,618] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.1989884e-24 1.0000000e+00 1.0770917e-30 6.0176057e-22 1.3461989e-34], sum to 1.0000
[2019-03-23 08:33:41,626] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2470
[2019-03-23 08:33:41,629] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.95, 79.5, 1.0, 2.0, 0.3607436223865196, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 402695.7314497209, 402695.7314497211, 119552.0278742624], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5967000.0000, 
sim time next is 5967600.0000, 
raw observation next is [19.76666666666667, 80.0, 1.0, 2.0, 0.3572922183232616, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 398221.6522246539, 398221.6522246539, 119000.3302969522], 
processed observation next is [1.0, 0.043478260869565216, 0.534848484848485, 0.8, 1.0, 1.0, 0.19661527290407696, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1474895008239459, 0.1474895008239459, 0.29024470804134683], 
reward next is 0.7098, 
noisyNet noise sample is [array([0.50652784], dtype=float32), -0.83649015]. 
=============================================
[2019-03-23 08:33:41,656] A3C_AGENT_WORKER-Thread-14 INFO:Local step 10000, global step 159749: loss 0.1103
[2019-03-23 08:33:41,658] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 10000, global step 159749: learning rate 0.0005
[2019-03-23 08:33:41,793] A3C_AGENT_WORKER-Thread-3 INFO:Local step 10000, global step 159826: loss 0.2073
[2019-03-23 08:33:41,797] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 10000, global step 159828: learning rate 0.0005
[2019-03-23 08:33:41,827] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.8530584e-23 1.0000000e+00 5.0580141e-33 3.0877218e-23 1.9708281e-33], sum to 1.0000
[2019-03-23 08:33:41,839] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1592
[2019-03-23 08:33:41,840] A3C_AGENT_WORKER-Thread-13 INFO:Local step 10000, global step 159849: loss 0.1631
[2019-03-23 08:33:41,845] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 10000, global step 159851: learning rate 0.0005
[2019-03-23 08:33:41,847] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 76.0, 1.0, 2.0, 0.3533860496250925, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 394507.5856039269, 394507.5856039271, 118967.9620209415], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5990400.0000, 
sim time next is 5991000.0000, 
raw observation next is [20.68333333333334, 75.16666666666667, 1.0, 2.0, 0.3882125077560605, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 433905.679593499, 433905.6795934993, 122075.3536857986], 
processed observation next is [1.0, 0.34782608695652173, 0.5765151515151519, 0.7516666666666667, 1.0, 1.0, 0.23526563469507558, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1607058072568515, 0.16070580725685157, 0.2977447650873137], 
reward next is 0.7023, 
noisyNet noise sample is [array([-0.1560589], dtype=float32), -1.114382]. 
=============================================
[2019-03-23 08:33:41,859] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[67.80631 ]
 [67.80647 ]
 [67.80636 ]
 [67.806496]
 [67.8062  ]], R is [[67.8306427 ]
 [67.86216736]
 [67.89432526]
 [67.9257431 ]
 [67.95442963]].
[2019-03-23 08:33:41,995] A3C_AGENT_WORKER-Thread-15 INFO:Local step 10000, global step 159925: loss 0.0649
[2019-03-23 08:33:41,997] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 10000, global step 159926: learning rate 0.0005
[2019-03-23 08:33:42,030] A3C_AGENT_WORKER-Thread-16 INFO:Local step 10000, global step 159941: loss 0.0932
[2019-03-23 08:33:42,033] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 10000, global step 159943: learning rate 0.0005
[2019-03-23 08:33:42,080] A3C_AGENT_WORKER-Thread-18 INFO:Local step 10000, global step 159970: loss 0.0697
[2019-03-23 08:33:42,082] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 10000, global step 159970: learning rate 0.0005
[2019-03-23 08:33:42,099] A3C_AGENT_WORKER-Thread-20 INFO:Local step 10000, global step 159979: loss 0.0343
[2019-03-23 08:33:42,102] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 10000, global step 159979: learning rate 0.0005
[2019-03-23 08:33:42,321] A3C_AGENT_WORKER-Thread-22 INFO:Local step 10000, global step 160091: loss 0.0098
[2019-03-23 08:33:42,323] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 10000, global step 160093: learning rate 0.0005
[2019-03-23 08:33:42,416] A3C_AGENT_WORKER-Thread-10 INFO:Local step 10000, global step 160142: loss 0.0011
[2019-03-23 08:33:42,420] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 10000, global step 160142: learning rate 0.0005
[2019-03-23 08:33:43,090] A3C_AGENT_WORKER-Thread-11 INFO:Local step 10000, global step 160499: loss 0.0013
[2019-03-23 08:33:43,091] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 10000, global step 160500: learning rate 0.0005
[2019-03-23 08:33:43,132] A3C_AGENT_WORKER-Thread-19 INFO:Local step 10000, global step 160521: loss 0.0137
[2019-03-23 08:33:43,136] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 10000, global step 160522: learning rate 0.0005
[2019-03-23 08:33:43,213] A3C_AGENT_WORKER-Thread-17 INFO:Local step 10000, global step 160564: loss 0.0121
[2019-03-23 08:33:43,216] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 10000, global step 160565: learning rate 0.0005
[2019-03-23 08:33:43,563] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.3345403e-21 1.0000000e+00 3.4443143e-30 3.4752947e-20 2.9256920e-32], sum to 1.0000
[2019-03-23 08:33:43,573] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8286
[2019-03-23 08:33:43,578] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 78.0, 1.0, 2.0, 0.3417950681413912, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 377405.580634076, 377405.580634076, 116315.6854965085], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6037200.0000, 
sim time next is 6037800.0000, 
raw observation next is [19.21666666666667, 77.16666666666667, 1.0, 2.0, 0.3355286349022858, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 369023.6462009157, 369023.6462009157, 115286.492722969], 
processed observation next is [1.0, 0.9130434782608695, 0.5098484848484849, 0.7716666666666667, 1.0, 1.0, 0.16941079362785721, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13667542451885767, 0.13667542451885767, 0.28118656761699756], 
reward next is 0.7188, 
noisyNet noise sample is [array([-0.8466498], dtype=float32), 3.1541138]. 
=============================================
[2019-03-23 08:33:48,415] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.7505089e-23 1.0000000e+00 5.9468268e-34 4.0703894e-25 1.9399965e-36], sum to 1.0000
[2019-03-23 08:33:48,421] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7192
[2019-03-23 08:33:48,428] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 64.33333333333333, 1.0, 2.0, 0.2682923149222408, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 291315.511611458, 291315.5116114577, 91331.52316341303], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6126000.0000, 
sim time next is 6126600.0000, 
raw observation next is [18.9, 64.66666666666667, 1.0, 2.0, 0.2673811894515012, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 290325.9036627324, 290325.9036627327, 90779.46101549163], 
processed observation next is [1.0, 0.9130434782608695, 0.49545454545454537, 0.6466666666666667, 1.0, 1.0, 0.08422648681437647, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10752811246767867, 0.10752811246767877, 0.2214133195499796], 
reward next is 0.7786, 
noisyNet noise sample is [array([0.39594105], dtype=float32), 1.964586]. 
=============================================
[2019-03-23 08:33:53,596] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.8421826e-19 1.0000000e+00 7.5045124e-27 1.2408207e-18 3.9487020e-29], sum to 1.0000
[2019-03-23 08:33:53,601] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2799
[2019-03-23 08:33:53,609] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.71666666666667, 93.5, 1.0, 2.0, 0.3709424311634602, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 416426.4315276836, 416426.4315276839, 121473.0284288981], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6235800.0000, 
sim time next is 6236400.0000, 
raw observation next is [18.63333333333333, 94.0, 1.0, 2.0, 0.3701171870459481, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 415374.5265342877, 415374.5265342874, 121341.7886166451], 
processed observation next is [0.0, 0.17391304347826086, 0.48333333333333317, 0.94, 1.0, 1.0, 0.2126464838074351, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15384241723492137, 0.15384241723492126, 0.2959555819918173], 
reward next is 0.7040, 
noisyNet noise sample is [array([0.9364643], dtype=float32), 0.81412727]. 
=============================================
[2019-03-23 08:33:56,265] A3C_AGENT_WORKER-Thread-21 INFO:Local step 10500, global step 167553: loss 0.2087
[2019-03-23 08:33:56,266] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 10500, global step 167553: learning rate 0.0005
[2019-03-23 08:33:56,289] A3C_AGENT_WORKER-Thread-2 INFO:Local step 10500, global step 167561: loss 0.3061
[2019-03-23 08:33:56,294] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 10500, global step 167561: learning rate 0.0005
[2019-03-23 08:33:56,341] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.1174913e-17 1.0000000e+00 2.1378828e-21 5.8404298e-16 3.4602898e-22], sum to 1.0000
[2019-03-23 08:33:56,350] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4006
[2019-03-23 08:33:56,355] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.9, 54.66666666666667, 1.0, 2.0, 0.5575721078277899, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 631144.1481702137, 631144.148170214, 151963.1424713912], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6282600.0000, 
sim time next is 6283200.0000, 
raw observation next is [29.8, 54.33333333333334, 1.0, 2.0, 0.5534721872453284, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 627216.4749141779, 627216.4749141781, 151179.8962853028], 
processed observation next is [0.0, 0.7391304347826086, 0.990909090909091, 0.5433333333333334, 1.0, 1.0, 0.4418402340566605, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2323023981163622, 0.23230239811636227, 0.368731454354397], 
reward next is 0.6313, 
noisyNet noise sample is [array([-0.23093905], dtype=float32), 1.1632998]. 
=============================================
[2019-03-23 08:33:56,524] A3C_AGENT_WORKER-Thread-9 INFO:Local step 10500, global step 167689: loss 0.0001
[2019-03-23 08:33:56,525] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 10500, global step 167689: learning rate 0.0005
[2019-03-23 08:33:56,538] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.7271100e-30 1.0000000e+00 0.0000000e+00 1.2367975e-28 0.0000000e+00], sum to 1.0000
[2019-03-23 08:33:56,552] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0162
[2019-03-23 08:33:56,562] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.48333333333333, 58.0, 1.0, 2.0, 0.5266876047968141, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 598867.9007472959, 598867.9007472959, 146847.1948342408], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6288600.0000, 
sim time next is 6289200.0000, 
raw observation next is [28.3, 59.0, 1.0, 2.0, 0.5271187211059866, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 599308.8364742039, 599308.8364742039, 146928.7751619645], 
processed observation next is [0.0, 0.8260869565217391, 0.9227272727272727, 0.59, 1.0, 1.0, 0.4088984013824832, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22196623573118662, 0.22196623573118662, 0.3583628662486939], 
reward next is 0.6416, 
noisyNet noise sample is [array([-0.19414647], dtype=float32), 1.0141879]. 
=============================================
[2019-03-23 08:33:56,634] A3C_AGENT_WORKER-Thread-14 INFO:Local step 10500, global step 167746: loss 1.1658
[2019-03-23 08:33:56,636] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 10500, global step 167748: learning rate 0.0005
[2019-03-23 08:33:56,680] A3C_AGENT_WORKER-Thread-3 INFO:Local step 10500, global step 167770: loss 2.7666
[2019-03-23 08:33:56,680] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 10500, global step 167770: learning rate 0.0005
[2019-03-23 08:33:56,712] A3C_AGENT_WORKER-Thread-12 INFO:Local step 10500, global step 167786: loss 0.8295
[2019-03-23 08:33:56,713] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 10500, global step 167786: learning rate 0.0005
[2019-03-23 08:33:56,797] A3C_AGENT_WORKER-Thread-13 INFO:Local step 10500, global step 167833: loss 0.0053
[2019-03-23 08:33:56,801] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 10500, global step 167835: learning rate 0.0005
[2019-03-23 08:33:56,886] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.6583176e-19 1.0000000e+00 8.6277896e-28 1.6440202e-19 6.4690369e-30], sum to 1.0000
[2019-03-23 08:33:56,891] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9868
[2019-03-23 08:33:56,897] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 77.66666666666667, 1.0, 2.0, 0.4868411451647196, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 555407.5148399968, 555407.5148399968, 140139.6675985963], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6306600.0000, 
sim time next is 6307200.0000, 
raw observation next is [23.8, 79.0, 1.0, 2.0, 0.4868620123055888, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 555433.5624498741, 555433.5624498745, 140135.9166551309], 
processed observation next is [0.0, 0.0, 0.7181818181818183, 0.79, 1.0, 1.0, 0.35857751538198596, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20571613424069413, 0.20571613424069424, 0.34179491867105094], 
reward next is 0.6582, 
noisyNet noise sample is [array([-0.7488367], dtype=float32), -1.4095742]. 
=============================================
[2019-03-23 08:33:56,907] A3C_AGENT_WORKER-Thread-15 INFO:Local step 10500, global step 167892: loss 0.0224
[2019-03-23 08:33:56,908] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 10500, global step 167892: learning rate 0.0005
[2019-03-23 08:33:57,096] A3C_AGENT_WORKER-Thread-16 INFO:Local step 10500, global step 167994: loss 0.0019
[2019-03-23 08:33:57,099] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 10500, global step 167995: learning rate 0.0005
[2019-03-23 08:33:57,187] A3C_AGENT_WORKER-Thread-20 INFO:Local step 10500, global step 168047: loss 0.0919
[2019-03-23 08:33:57,189] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 10500, global step 168047: learning rate 0.0005
[2019-03-23 08:33:57,197] A3C_AGENT_WORKER-Thread-18 INFO:Local step 10500, global step 168051: loss 0.1109
[2019-03-23 08:33:57,198] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 10500, global step 168051: learning rate 0.0005
[2019-03-23 08:33:57,413] A3C_AGENT_WORKER-Thread-22 INFO:Local step 10500, global step 168168: loss 0.0336
[2019-03-23 08:33:57,415] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 10500, global step 168170: learning rate 0.0005
[2019-03-23 08:33:57,447] A3C_AGENT_WORKER-Thread-10 INFO:Local step 10500, global step 168187: loss 0.0443
[2019-03-23 08:33:57,451] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 10500, global step 168188: learning rate 0.0005
[2019-03-23 08:33:57,798] A3C_AGENT_WORKER-Thread-19 INFO:Local step 10500, global step 168376: loss 0.0444
[2019-03-23 08:33:57,801] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 10500, global step 168376: learning rate 0.0005
[2019-03-23 08:33:58,123] A3C_AGENT_WORKER-Thread-11 INFO:Local step 10500, global step 168548: loss 0.0291
[2019-03-23 08:33:58,127] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 10500, global step 168548: learning rate 0.0005
[2019-03-23 08:33:58,184] A3C_AGENT_WORKER-Thread-17 INFO:Local step 10500, global step 168582: loss 0.0004
[2019-03-23 08:33:58,187] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 10500, global step 168582: learning rate 0.0005
[2019-03-23 08:33:58,852] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.5868732e-23 1.0000000e+00 6.4656045e-31 1.8207617e-22 3.9588423e-34], sum to 1.0000
[2019-03-23 08:33:58,858] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3311
[2019-03-23 08:33:58,861] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.18333333333334, 75.16666666666667, 1.0, 2.0, 0.5184279949998147, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 590191.739731779, 590191.739731779, 145362.3535513793], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6343800.0000, 
sim time next is 6344400.0000, 
raw observation next is [25.36666666666667, 74.33333333333334, 1.0, 2.0, 0.5205525535038762, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 592479.6745932326, 592479.6745932326, 145716.4507418314], 
processed observation next is [0.0, 0.43478260869565216, 0.7893939393939395, 0.7433333333333334, 1.0, 1.0, 0.4006906918798452, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21943691651601208, 0.21943691651601208, 0.35540597741910096], 
reward next is 0.6446, 
noisyNet noise sample is [array([0.9416874], dtype=float32), -1.4286026]. 
=============================================
[2019-03-23 08:34:02,006] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.1375995e-19 1.0000000e+00 3.6329498e-26 3.2304244e-18 1.0485450e-26], sum to 1.0000
[2019-03-23 08:34:02,023] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4880
[2019-03-23 08:34:02,027] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 76.0, 1.0, 2.0, 0.5226087510795095, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 595047.5758851435, 595047.5758851435, 145801.6241057635], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6388800.0000, 
sim time next is 6389400.0000, 
raw observation next is [25.0, 76.0, 1.0, 2.0, 0.5220521458407239, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 594414.0099000498, 594414.0099000495, 145733.1947896006], 
processed observation next is [0.0, 0.9565217391304348, 0.7727272727272727, 0.76, 1.0, 1.0, 0.4025651823009048, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22015333700001843, 0.22015333700001835, 0.35544681656000143], 
reward next is 0.6446, 
noisyNet noise sample is [array([0.38723955], dtype=float32), -1.0750179]. 
=============================================
[2019-03-23 08:34:05,437] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.2812306e-24 1.0000000e+00 5.3205606e-35 1.0512866e-22 1.1749988e-36], sum to 1.0000
[2019-03-23 08:34:05,442] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3731
[2019-03-23 08:34:05,445] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.43333333333334, 70.66666666666667, 1.0, 2.0, 0.2394102540751626, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 259946.589063178, 259946.5890631783, 78619.22427401014], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6466800.0000, 
sim time next is 6467400.0000, 
raw observation next is [16.35, 71.0, 1.0, 2.0, 0.2356002134253476, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 255808.6396252906, 255808.6396252903, 78094.14150713134], 
processed observation next is [1.0, 0.8695652173913043, 0.37954545454545463, 0.71, 1.0, 1.0, 0.04450026678168448, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09474394060195948, 0.09474394060195937, 0.19047351587105205], 
reward next is 0.8095, 
noisyNet noise sample is [array([-0.95010185], dtype=float32), 1.1178664]. 
=============================================
[2019-03-23 08:34:05,829] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.9797038e-27 1.0000000e+00 9.7775760e-35 8.7125958e-27 1.6569127e-36], sum to 1.0000
[2019-03-23 08:34:05,834] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8379
[2019-03-23 08:34:05,837] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.6, 74.5, 1.0, 2.0, 0.221470124635531, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 240462.7608739539, 240462.7608739536, 75602.30725066227], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6472200.0000, 
sim time next is 6472800.0000, 
raw observation next is [15.5, 75.0, 1.0, 2.0, 0.22006587242528, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 238937.7095639153, 238937.7095639156, 75342.88319929664], 
processed observation next is [1.0, 0.9565217391304348, 0.3409090909090909, 0.75, 1.0, 1.0, 0.025082340531599988, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08849544798663529, 0.0884954479866354, 0.18376312975438205], 
reward next is 0.8162, 
noisyNet noise sample is [array([1.9883546], dtype=float32), -2.0260103]. 
=============================================
[2019-03-23 08:34:10,167] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-23 08:34:10,168] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 08:34:10,168] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:34:10,168] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 08:34:10,170] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 08:34:10,170] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:34:10,170] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:34:10,171] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 08:34:10,171] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 08:34:10,173] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:34:10,174] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:34:10,183] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run8
[2019-03-23 08:34:10,210] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run8
[2019-03-23 08:34:10,210] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run8
[2019-03-23 08:34:10,211] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run8
[2019-03-23 08:34:10,281] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run8
[2019-03-23 08:34:12,545] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06299171], dtype=float32), -0.9456347]
[2019-03-23 08:34:12,547] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [25.15725498, 56.249720235, 1.0, 2.0, 0.4707717788934194, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 533897.69558858, 533897.6955885796, 137879.1148926426]
[2019-03-23 08:34:12,548] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 08:34:12,554] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [8.4065463e-27 1.0000000e+00 1.5715245e-36 2.7710761e-26 0.0000000e+00], sampled 0.9641367764899784
[2019-03-23 08:34:34,155] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06299171], dtype=float32), -0.9456347]
[2019-03-23 08:34:34,159] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.0, 72.0, 1.0, 2.0, 0.2359161566245226, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 256151.7729415429, 256151.7729415432, 81283.6040860624]
[2019-03-23 08:34:34,160] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 08:34:34,163] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [8.3976362e-27 1.0000000e+00 1.5692362e-36 2.7682128e-26 0.0000000e+00], sampled 0.8933873201825395
[2019-03-23 08:34:36,751] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06299171], dtype=float32), -0.9456347]
[2019-03-23 08:34:36,753] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [17.13333333333334, 55.33333333333334, 1.0, 2.0, 0.2447069024933756, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 265685.3077917517, 265685.3077917513, 80194.48611256115]
[2019-03-23 08:34:36,756] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 08:34:36,759] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [8.3956502e-27 1.0000000e+00 1.5687214e-36 2.7675687e-26 0.0000000e+00], sampled 0.6111433143546758
[2019-03-23 08:34:49,404] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06299171], dtype=float32), -0.9456347]
[2019-03-23 08:34:49,404] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.268605245, 73.71435867, 1.0, 2.0, 0.6000331057561571, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 681160.7387158636, 681160.7387158632, 152786.314469394]
[2019-03-23 08:34:49,405] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 08:34:49,406] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [8.4862590e-27 1.0000000e+00 1.5920035e-36 2.7967760e-26 0.0000000e+00], sampled 0.8224648506671244
[2019-03-23 08:35:08,725] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06299171], dtype=float32), -0.9456347]
[2019-03-23 08:35:08,728] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.019949275, 55.58108691, 1.0, 2.0, 0.3674308147213712, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 406556.2153064911, 406556.2153064911, 122940.0198588309]
[2019-03-23 08:35:08,728] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 08:35:08,730] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [8.3916157e-27 1.0000000e+00 1.5676925e-36 2.7662810e-26 0.0000000e+00], sampled 0.23565897109759193
[2019-03-23 08:35:18,958] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06299171], dtype=float32), -0.9456347]
[2019-03-23 08:35:18,962] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.53333333333333, 68.33333333333333, 1.0, 2.0, 0.3762033248881299, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 420095.1604823587, 420095.1604823584, 125209.4262978093]
[2019-03-23 08:35:18,963] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 08:35:18,968] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [8.3957141e-27 1.0000000e+00 1.5687573e-36 2.7676005e-26 0.0000000e+00], sampled 0.7230818113144906
[2019-03-23 08:35:20,957] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06299171], dtype=float32), -0.9456347]
[2019-03-23 08:35:20,958] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.8, 66.0, 1.0, 2.0, 0.4230691653525255, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 480415.6078916605, 480415.6078916602, 133579.724791913]
[2019-03-23 08:35:20,959] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 08:35:20,963] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [8.4018339e-27 1.0000000e+00 1.5703021e-36 2.7695544e-26 0.0000000e+00], sampled 0.4237320424770279
[2019-03-23 08:35:38,174] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06299171], dtype=float32), -0.9456347]
[2019-03-23 08:35:38,175] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.0, 61.0, 1.0, 2.0, 0.3927621369830677, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 440849.3269198445, 440849.3269198445, 127641.0862498947]
[2019-03-23 08:35:38,175] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 08:35:38,177] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [8.4245245e-27 1.0000000e+00 1.5761233e-36 2.7768748e-26 0.0000000e+00], sampled 0.37801638606604415
[2019-03-23 08:35:38,642] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06299171], dtype=float32), -0.9456347]
[2019-03-23 08:35:38,644] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [27.7037785, 63.29294699, 1.0, 2.0, 0.5311266816139024, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 603422.7790907497, 603422.7790907493, 151935.031313266]
[2019-03-23 08:35:38,646] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 08:35:38,648] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [8.4312113e-27 1.0000000e+00 1.5778438e-36 2.7790263e-26 0.0000000e+00], sampled 0.16621100139132583
[2019-03-23 08:35:51,071] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06299171], dtype=float32), -0.9456347]
[2019-03-23 08:35:51,072] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.58333333333334, 79.83333333333333, 1.0, 2.0, 0.3588512527426151, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 398695.6515969171, 398695.6515969167, 122914.2571557829]
[2019-03-23 08:35:51,074] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 08:35:51,077] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [8.3927682e-27 1.0000000e+00 1.5679915e-36 2.7666400e-26 0.0000000e+00], sampled 0.21641742067947667
[2019-03-23 08:35:52,198] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 08:35:52,739] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 08:35:52,814] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 08:35:52,905] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 08:35:52,954] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 08:35:53,970] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 175000, evaluation results [175000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 08:35:55,161] A3C_AGENT_WORKER-Thread-2 INFO:Local step 11000, global step 175606: loss 0.7390
[2019-03-23 08:35:55,167] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 11000, global step 175607: learning rate 0.0005
[2019-03-23 08:35:55,358] A3C_AGENT_WORKER-Thread-21 INFO:Local step 11000, global step 175702: loss 1.0451
[2019-03-23 08:35:55,361] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 11000, global step 175703: learning rate 0.0005
[2019-03-23 08:35:55,494] A3C_AGENT_WORKER-Thread-14 INFO:Local step 11000, global step 175773: loss 0.9027
[2019-03-23 08:35:55,497] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 11000, global step 175773: learning rate 0.0005
[2019-03-23 08:35:55,545] A3C_AGENT_WORKER-Thread-13 INFO:Local step 11000, global step 175796: loss 0.6860
[2019-03-23 08:35:55,548] A3C_AGENT_WORKER-Thread-3 INFO:Local step 11000, global step 175796: loss 0.5196
[2019-03-23 08:35:55,549] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 11000, global step 175796: learning rate 0.0005
[2019-03-23 08:35:55,550] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 11000, global step 175796: learning rate 0.0005
[2019-03-23 08:35:55,561] A3C_AGENT_WORKER-Thread-12 INFO:Local step 11000, global step 175802: loss 0.2611
[2019-03-23 08:35:55,562] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 11000, global step 175802: learning rate 0.0005
[2019-03-23 08:35:55,688] A3C_AGENT_WORKER-Thread-15 INFO:Local step 11000, global step 175869: loss 0.1685
[2019-03-23 08:35:55,690] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 11000, global step 175869: learning rate 0.0005
[2019-03-23 08:35:55,747] A3C_AGENT_WORKER-Thread-16 INFO:Local step 11000, global step 175896: loss 0.0427
[2019-03-23 08:35:55,750] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 11000, global step 175897: learning rate 0.0005
[2019-03-23 08:35:55,796] A3C_AGENT_WORKER-Thread-9 INFO:Local step 11000, global step 175924: loss 0.0003
[2019-03-23 08:35:55,798] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 11000, global step 175924: learning rate 0.0005
[2019-03-23 08:35:55,944] A3C_AGENT_WORKER-Thread-22 INFO:Local step 11000, global step 175998: loss 0.2400
[2019-03-23 08:35:55,948] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 11000, global step 175998: learning rate 0.0005
[2019-03-23 08:35:56,028] A3C_AGENT_WORKER-Thread-18 INFO:Local step 11000, global step 176037: loss 0.2197
[2019-03-23 08:35:56,032] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 11000, global step 176037: learning rate 0.0005
[2019-03-23 08:35:56,062] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.1961900e-15 1.0000000e+00 4.2436506e-21 2.5902134e-15 2.0931100e-23], sum to 1.0000
[2019-03-23 08:35:56,072] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7123
[2019-03-23 08:35:56,075] A3C_AGENT_WORKER-Thread-20 INFO:Local step 11000, global step 176060: loss 0.6964
[2019-03-23 08:35:56,080] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.25, 61.0, 1.0, 2.0, 0.5119881590960506, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 556075.1520864121, 556075.1520864121, 124846.7613608528], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6604200.0000, 
sim time next is 6604800.0000, 
raw observation next is [20.53333333333333, 60.33333333333333, 1.0, 2.0, 0.5303688595424033, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 576050.4333593837, 576050.4333593837, 128990.7296389503], 
processed observation next is [1.0, 0.43478260869565216, 0.5696969696969696, 0.6033333333333333, 1.0, 1.0, 0.4129610744280041, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2133520123553273, 0.2133520123553273, 0.31461153570475686], 
reward next is 0.6854, 
noisyNet noise sample is [array([-0.70426905], dtype=float32), -0.8484911]. 
=============================================
[2019-03-23 08:35:56,082] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 11000, global step 176061: learning rate 0.0005
[2019-03-23 08:35:56,297] A3C_AGENT_WORKER-Thread-10 INFO:Local step 11000, global step 176179: loss 1.0269
[2019-03-23 08:35:56,301] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 11000, global step 176181: learning rate 0.0005
[2019-03-23 08:35:56,556] A3C_AGENT_WORKER-Thread-19 INFO:Local step 11000, global step 176304: loss 0.0144
[2019-03-23 08:35:56,559] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 11000, global step 176305: learning rate 0.0005
[2019-03-23 08:35:56,824] A3C_AGENT_WORKER-Thread-17 INFO:Local step 11000, global step 176447: loss 0.3624
[2019-03-23 08:35:56,825] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 11000, global step 176447: learning rate 0.0005
[2019-03-23 08:35:57,109] A3C_AGENT_WORKER-Thread-11 INFO:Local step 11000, global step 176597: loss 0.2091
[2019-03-23 08:35:57,113] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 11000, global step 176599: learning rate 0.0005
[2019-03-23 08:36:02,293] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.5695981e-23 1.0000000e+00 2.2240687e-32 8.8650895e-23 3.1631589e-34], sum to 1.0000
[2019-03-23 08:36:02,299] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2770
[2019-03-23 08:36:02,305] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.61666666666667, 99.33333333333334, 1.0, 2.0, 0.3656404582900935, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 408297.7944089075, 408297.7944089072, 120012.0383508175], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6732600.0000, 
sim time next is 6733200.0000, 
raw observation next is [17.53333333333333, 98.66666666666667, 1.0, 2.0, 0.3639510070105123, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 405565.9464399148, 405565.9464399145, 119505.8757424804], 
processed observation next is [1.0, 0.9565217391304348, 0.43333333333333324, 0.9866666666666667, 1.0, 1.0, 0.20493875876314036, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15020960979256104, 0.15020960979256093, 0.2914777457133668], 
reward next is 0.7085, 
noisyNet noise sample is [array([-0.41499868], dtype=float32), -1.167385]. 
=============================================
[2019-03-23 08:36:03,708] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.4081956e-23 1.0000000e+00 3.2312181e-30 1.2848005e-21 1.2134286e-32], sum to 1.0000
[2019-03-23 08:36:03,718] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4017
[2019-03-23 08:36:03,725] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.2, 100.0, 1.0, 2.0, 0.3411667141418419, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 378650.0009582135, 378650.0009582135, 117040.6899468316], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6742800.0000, 
sim time next is 6743400.0000, 
raw observation next is [17.2, 98.83333333333334, 1.0, 2.0, 0.3402290725018242, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 377187.617767767, 377187.617767767, 116795.4804489139], 
processed observation next is [1.0, 0.043478260869565216, 0.41818181818181815, 0.9883333333333334, 1.0, 1.0, 0.17528634062728024, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13969911769176555, 0.13969911769176555, 0.28486702548515586], 
reward next is 0.7151, 
noisyNet noise sample is [array([0.11517292], dtype=float32), 0.20413187]. 
=============================================
[2019-03-23 08:36:11,025] A3C_AGENT_WORKER-Thread-21 INFO:Local step 11500, global step 183630: loss 0.0342
[2019-03-23 08:36:11,026] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 11500, global step 183630: learning rate 0.0005
[2019-03-23 08:36:11,197] A3C_AGENT_WORKER-Thread-2 INFO:Local step 11500, global step 183702: loss 0.0000
[2019-03-23 08:36:11,204] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 11500, global step 183705: learning rate 0.0005
[2019-03-23 08:36:11,307] A3C_AGENT_WORKER-Thread-14 INFO:Local step 11500, global step 183750: loss 0.0148
[2019-03-23 08:36:11,309] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 11500, global step 183751: learning rate 0.0005
[2019-03-23 08:36:11,363] A3C_AGENT_WORKER-Thread-3 INFO:Local step 11500, global step 183776: loss 0.0302
[2019-03-23 08:36:11,369] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 11500, global step 183776: learning rate 0.0005
[2019-03-23 08:36:11,510] A3C_AGENT_WORKER-Thread-13 INFO:Local step 11500, global step 183838: loss 0.0024
[2019-03-23 08:36:11,511] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 11500, global step 183838: learning rate 0.0005
[2019-03-23 08:36:11,608] A3C_AGENT_WORKER-Thread-15 INFO:Local step 11500, global step 183882: loss 0.0218
[2019-03-23 08:36:11,610] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 11500, global step 183882: learning rate 0.0005
[2019-03-23 08:36:11,620] A3C_AGENT_WORKER-Thread-12 INFO:Local step 11500, global step 183885: loss 0.0092
[2019-03-23 08:36:11,622] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 11500, global step 183885: learning rate 0.0005
[2019-03-23 08:36:11,641] A3C_AGENT_WORKER-Thread-9 INFO:Local step 11500, global step 183896: loss 0.0283
[2019-03-23 08:36:11,642] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 11500, global step 183896: learning rate 0.0005
[2019-03-23 08:36:11,711] A3C_AGENT_WORKER-Thread-16 INFO:Local step 11500, global step 183934: loss 0.0468
[2019-03-23 08:36:11,713] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 11500, global step 183934: learning rate 0.0005
[2019-03-23 08:36:11,757] A3C_AGENT_WORKER-Thread-18 INFO:Local step 11500, global step 183960: loss 0.0243
[2019-03-23 08:36:11,758] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 11500, global step 183960: learning rate 0.0005
[2019-03-23 08:36:11,849] A3C_AGENT_WORKER-Thread-22 INFO:Local step 11500, global step 184011: loss 0.0017
[2019-03-23 08:36:11,852] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 11500, global step 184012: learning rate 0.0005
[2019-03-23 08:36:12,004] A3C_AGENT_WORKER-Thread-20 INFO:Local step 11500, global step 184094: loss 0.0285
[2019-03-23 08:36:12,006] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 11500, global step 184094: learning rate 0.0005
[2019-03-23 08:36:12,093] A3C_AGENT_WORKER-Thread-10 INFO:Local step 11500, global step 184138: loss 0.0000
[2019-03-23 08:36:12,098] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 11500, global step 184140: learning rate 0.0005
[2019-03-23 08:36:12,361] A3C_AGENT_WORKER-Thread-19 INFO:Local step 11500, global step 184286: loss 0.0010
[2019-03-23 08:36:12,363] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 11500, global step 184288: learning rate 0.0005
[2019-03-23 08:36:12,694] A3C_AGENT_WORKER-Thread-17 INFO:Local step 11500, global step 184465: loss 0.0018
[2019-03-23 08:36:12,696] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 11500, global step 184466: learning rate 0.0005
[2019-03-23 08:36:12,812] A3C_AGENT_WORKER-Thread-11 INFO:Local step 11500, global step 184527: loss 0.0665
[2019-03-23 08:36:12,815] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 11500, global step 184529: learning rate 0.0005
[2019-03-23 08:36:18,213] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.4627717e-20 1.0000000e+00 5.4444298e-27 4.8868745e-20 2.0135248e-29], sum to 1.0000
[2019-03-23 08:36:18,220] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4402
[2019-03-23 08:36:18,224] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.31666666666667, 88.0, 1.0, 2.0, 0.7535156225387926, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 854846.2297129588, 854846.2297129588, 168200.7183863334], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7041000.0000, 
sim time next is 7041600.0000, 
raw observation next is [20.5, 87.0, 1.0, 2.0, 0.7906345334871235, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 897411.2967942395, 897411.2967942395, 173856.2927609374], 
processed observation next is [1.0, 0.5217391304347826, 0.5681818181818182, 0.87, 1.0, 1.0, 0.7382931668589043, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3323745543682369, 0.3323745543682369, 0.4240397384413107], 
reward next is 0.5760, 
noisyNet noise sample is [array([1.4893223], dtype=float32), 2.2376072]. 
=============================================
[2019-03-23 08:36:18,749] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.2944228e-20 1.0000000e+00 6.8147697e-26 1.7688778e-18 1.5893348e-27], sum to 1.0000
[2019-03-23 08:36:18,756] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2669
[2019-03-23 08:36:18,759] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 97.0, 1.0, 2.0, 0.6148395068187661, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 694656.5573967502, 694656.5573967502, 148168.7681163919], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7030200.0000, 
sim time next is 7030800.0000, 
raw observation next is [18.8, 97.0, 1.0, 2.0, 0.6277370178496222, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 709268.5458231678, 709268.5458231678, 149746.0093314253], 
processed observation next is [1.0, 0.391304347826087, 0.49090909090909096, 0.97, 1.0, 1.0, 0.5346712723120277, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.26269205400858064, 0.26269205400858064, 0.36523416910103734], 
reward next is 0.6348, 
noisyNet noise sample is [array([-1.3607554], dtype=float32), 0.6509135]. 
=============================================
[2019-03-23 08:36:26,063] A3C_AGENT_WORKER-Thread-2 INFO:Local step 12000, global step 191624: loss 0.6866
[2019-03-23 08:36:26,065] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 12000, global step 191624: learning rate 0.0005
[2019-03-23 08:36:26,140] A3C_AGENT_WORKER-Thread-21 INFO:Local step 12000, global step 191666: loss 1.0238
[2019-03-23 08:36:26,142] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 12000, global step 191666: learning rate 0.0005
[2019-03-23 08:36:26,267] A3C_AGENT_WORKER-Thread-3 INFO:Local step 12000, global step 191734: loss 2.1747
[2019-03-23 08:36:26,269] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 12000, global step 191735: learning rate 0.0005
[2019-03-23 08:36:26,421] A3C_AGENT_WORKER-Thread-13 INFO:Local step 12000, global step 191814: loss 6.1414
[2019-03-23 08:36:26,423] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 12000, global step 191814: learning rate 0.0005
[2019-03-23 08:36:26,451] A3C_AGENT_WORKER-Thread-14 INFO:Local step 12000, global step 191831: loss 6.8494
[2019-03-23 08:36:26,456] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 12000, global step 191832: learning rate 0.0005
[2019-03-23 08:36:26,556] A3C_AGENT_WORKER-Thread-15 INFO:Local step 12000, global step 191889: loss 8.6439
[2019-03-23 08:36:26,559] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 12000, global step 191890: learning rate 0.0005
[2019-03-23 08:36:26,570] A3C_AGENT_WORKER-Thread-9 INFO:Local step 12000, global step 191892: loss 7.1073
[2019-03-23 08:36:26,575] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 12000, global step 191892: learning rate 0.0005
[2019-03-23 08:36:26,710] A3C_AGENT_WORKER-Thread-18 INFO:Local step 12000, global step 191968: loss 3.5340
[2019-03-23 08:36:26,712] A3C_AGENT_WORKER-Thread-22 INFO:Local step 12000, global step 191968: loss 3.5110
[2019-03-23 08:36:26,713] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 12000, global step 191968: learning rate 0.0005
[2019-03-23 08:36:26,715] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 12000, global step 191968: learning rate 0.0005
[2019-03-23 08:36:26,773] A3C_AGENT_WORKER-Thread-16 INFO:Local step 12000, global step 191999: loss 2.7119
[2019-03-23 08:36:26,774] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 12000, global step 191999: learning rate 0.0005
[2019-03-23 08:36:26,873] A3C_AGENT_WORKER-Thread-12 INFO:Local step 12000, global step 192050: loss 2.7621
[2019-03-23 08:36:26,875] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 12000, global step 192050: learning rate 0.0005
[2019-03-23 08:36:26,947] A3C_AGENT_WORKER-Thread-20 INFO:Local step 12000, global step 192097: loss 2.7106
[2019-03-23 08:36:26,949] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 12000, global step 192097: learning rate 0.0005
[2019-03-23 08:36:26,976] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.02189115e-17 1.00000000e+00 9.13631993e-22 4.88803788e-17
 1.63651451e-23], sum to 1.0000
[2019-03-23 08:36:26,982] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4655
[2019-03-23 08:36:26,988] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 63.0, 1.0, 2.0, 0.4023553263579883, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 436948.3886696388, 436948.3886696385, 102698.8206304366], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7203600.0000, 
sim time next is 7204200.0000, 
raw observation next is [19.18333333333333, 61.33333333333333, 1.0, 2.0, 0.493176023529643, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 535631.8573891624, 535631.8573891624, 113078.9298624251], 
processed observation next is [1.0, 0.391304347826087, 0.5083333333333332, 0.6133333333333333, 1.0, 1.0, 0.36647002941205375, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19838216940339348, 0.19838216940339348, 0.27580226795713436], 
reward next is 0.7242, 
noisyNet noise sample is [array([0.19436006], dtype=float32), 0.4132643]. 
=============================================
[2019-03-23 08:36:27,086] A3C_AGENT_WORKER-Thread-10 INFO:Local step 12000, global step 192170: loss 1.2812
[2019-03-23 08:36:27,090] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 12000, global step 192171: learning rate 0.0005
[2019-03-23 08:36:27,119] A3C_AGENT_WORKER-Thread-19 INFO:Local step 12000, global step 192188: loss 1.6295
[2019-03-23 08:36:27,122] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 12000, global step 192189: learning rate 0.0005
[2019-03-23 08:36:27,620] A3C_AGENT_WORKER-Thread-17 INFO:Local step 12000, global step 192447: loss 0.0959
[2019-03-23 08:36:27,625] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 12000, global step 192448: learning rate 0.0005
[2019-03-23 08:36:27,683] A3C_AGENT_WORKER-Thread-11 INFO:Local step 12000, global step 192487: loss 0.1683
[2019-03-23 08:36:27,684] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 12000, global step 192487: learning rate 0.0005
[2019-03-23 08:36:28,196] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.0019309e-20 1.0000000e+00 4.9491227e-27 2.1987748e-20 1.1904061e-28], sum to 1.0000
[2019-03-23 08:36:28,203] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0820
[2019-03-23 08:36:28,208] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.88333333333334, 53.5, 1.0, 2.0, 0.3037000757149186, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 329774.7840462131, 329774.7840462134, 110816.393410165], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7239000.0000, 
sim time next is 7239600.0000, 
raw observation next is [21.6, 55.0, 1.0, 2.0, 0.3035034145056263, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 329561.1657807234, 329561.1657807237, 110362.9077355718], 
processed observation next is [1.0, 0.8260869565217391, 0.6181818181818183, 0.55, 1.0, 1.0, 0.12937926813203285, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12205969102989755, 0.12205969102989765, 0.2691778237452971], 
reward next is 0.7308, 
noisyNet noise sample is [array([-0.20901932], dtype=float32), -0.7347325]. 
=============================================
[2019-03-23 08:36:32,731] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.1874822e-20 1.0000000e+00 2.0923895e-25 3.7370919e-19 3.9309073e-29], sum to 1.0000
[2019-03-23 08:36:32,741] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5679
[2019-03-23 08:36:32,745] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.1, 59.66666666666666, 1.0, 2.0, 0.3388420539974134, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 373803.8371453615, 373803.8371453612, 115961.3356595036], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7332000.0000, 
sim time next is 7332600.0000, 
raw observation next is [21.95, 60.83333333333334, 1.0, 2.0, 0.340566741900842, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 375963.2602851683, 375963.2602851683, 116189.7925773775], 
processed observation next is [1.0, 0.8695652173913043, 0.634090909090909, 0.6083333333333334, 1.0, 1.0, 0.1757084273760525, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13924565195746974, 0.13924565195746974, 0.2833897379936037], 
reward next is 0.7166, 
noisyNet noise sample is [array([-0.49041575], dtype=float32), -0.36251086]. 
=============================================
[2019-03-23 08:36:40,974] A3C_AGENT_WORKER-Thread-3 INFO:Local step 12500, global step 199599: loss 0.0003
[2019-03-23 08:36:40,978] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 12500, global step 199600: learning rate 0.0005
[2019-03-23 08:36:41,136] A3C_AGENT_WORKER-Thread-21 INFO:Local step 12500, global step 199686: loss 0.0455
[2019-03-23 08:36:41,137] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 12500, global step 199686: learning rate 0.0005
[2019-03-23 08:36:41,239] A3C_AGENT_WORKER-Thread-2 INFO:Local step 12500, global step 199742: loss 0.0474
[2019-03-23 08:36:41,240] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 12500, global step 199742: learning rate 0.0005
[2019-03-23 08:36:41,319] A3C_AGENT_WORKER-Thread-13 INFO:Local step 12500, global step 199784: loss 0.0172
[2019-03-23 08:36:41,322] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 12500, global step 199784: learning rate 0.0005
[2019-03-23 08:36:41,349] A3C_AGENT_WORKER-Thread-9 INFO:Local step 12500, global step 199799: loss 0.0081
[2019-03-23 08:36:41,352] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 12500, global step 199800: learning rate 0.0005
[2019-03-23 08:36:41,404] A3C_AGENT_WORKER-Thread-18 INFO:Local step 12500, global step 199825: loss 0.0013
[2019-03-23 08:36:41,406] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 12500, global step 199826: learning rate 0.0005
[2019-03-23 08:36:41,514] A3C_AGENT_WORKER-Thread-22 INFO:Local step 12500, global step 199886: loss 0.0084
[2019-03-23 08:36:41,517] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 12500, global step 199887: learning rate 0.0005
[2019-03-23 08:36:41,672] A3C_AGENT_WORKER-Thread-12 INFO:Local step 12500, global step 199971: loss 0.0193
[2019-03-23 08:36:41,674] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 12500, global step 199972: learning rate 0.0005
[2019-03-23 08:36:41,686] A3C_AGENT_WORKER-Thread-15 INFO:Local step 12500, global step 199978: loss 0.0460
[2019-03-23 08:36:41,687] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 12500, global step 199978: learning rate 0.0005
[2019-03-23 08:36:41,714] A3C_AGENT_WORKER-Thread-16 INFO:Local step 12500, global step 199995: loss 0.0634
[2019-03-23 08:36:41,715] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 12500, global step 199995: learning rate 0.0005
[2019-03-23 08:36:41,728] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-23 08:36:41,729] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 08:36:41,731] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 08:36:41,732] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:36:41,732] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 08:36:41,733] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 08:36:41,734] A3C_AGENT_WORKER-Thread-14 INFO:Local step 12500, global step 200000: loss 0.0529
[2019-03-23 08:36:41,734] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 08:36:41,733] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:36:41,736] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:36:41,736] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:36:41,735] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:36:41,736] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 12500, global step 200000: learning rate 0.0005
[2019-03-23 08:36:41,756] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run9
[2019-03-23 08:36:41,756] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run9
[2019-03-23 08:36:41,804] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run9
[2019-03-23 08:36:41,828] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run9
[2019-03-23 08:36:41,853] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run9
[2019-03-23 08:36:45,696] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06299171], dtype=float32), -0.9979969]
[2019-03-23 08:36:45,697] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [13.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 205805.1577237288, 205805.1577237285, 71644.80696632239]
[2019-03-23 08:36:45,697] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 08:36:45,700] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [7.3330662e-22 1.0000000e+00 2.1322392e-28 2.3795553e-21 1.5770063e-30], sampled 0.8223086295816247
[2019-03-23 08:36:58,265] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06299171], dtype=float32), -0.9979969]
[2019-03-23 08:36:58,266] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [18.3, 93.0, 1.0, 2.0, 0.3613243180591632, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 402741.1760014818, 402741.1760014814, 123657.7204162094]
[2019-03-23 08:36:58,268] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 08:36:58,270] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [7.3678074e-22 1.0000000e+00 2.1454405e-28 2.3904912e-21 1.5875207e-30], sampled 0.9000193030213062
[2019-03-23 08:37:01,908] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06299171], dtype=float32), -0.9979969]
[2019-03-23 08:37:01,910] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [8.833333333333332, 82.0, 1.0, 2.0, 0.3489662987799926, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 378946.5709675075, 378946.5709675072, 79574.25216722628]
[2019-03-23 08:37:01,911] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 08:37:01,914] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [7.3678074e-22 1.0000000e+00 2.1454405e-28 2.3904912e-21 1.5875207e-30], sampled 0.0496712592708487
[2019-03-23 08:37:43,147] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06299171], dtype=float32), -0.9979969]
[2019-03-23 08:37:43,148] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.14553064, 100.0, 1.0, 2.0, 0.4240590025891018, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 481502.0236089579, 481502.0236089576, 133646.1599789524]
[2019-03-23 08:37:43,149] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 08:37:43,153] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [7.3678074e-22 1.0000000e+00 2.1454405e-28 2.3904912e-21 1.5875207e-30], sampled 0.48657250653075435
[2019-03-23 08:37:52,060] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06299171], dtype=float32), -0.9979969]
[2019-03-23 08:37:52,062] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.54524464, 80.63430147666668, 1.0, 2.0, 0.4446226302331028, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 504850.3269479353, 504850.3269479353, 135677.2716901724]
[2019-03-23 08:37:52,063] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 08:37:52,067] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [7.3678074e-22 1.0000000e+00 2.1454405e-28 2.3904912e-21 1.5875207e-30], sampled 0.15020681355978205
[2019-03-23 08:38:15,059] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06299171], dtype=float32), -0.9979969]
[2019-03-23 08:38:15,061] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.5, 59.0, 1.0, 2.0, 0.2977164880330632, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 323275.305243805, 323275.305243805, 102316.541528238]
[2019-03-23 08:38:15,062] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 08:38:15,066] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [7.3678074e-22 1.0000000e+00 2.1454405e-28 2.3904912e-21 1.5875207e-30], sampled 0.7765283503498845
[2019-03-23 08:38:24,394] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 08:38:24,408] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 08:38:24,439] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 08:38:24,447] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 08:38:24,636] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 08:38:25,652] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 200000, evaluation results [200000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 08:38:25,795] A3C_AGENT_WORKER-Thread-20 INFO:Local step 12500, global step 200070: loss 0.0048
[2019-03-23 08:38:25,801] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 12500, global step 200070: learning rate 0.0005
[2019-03-23 08:38:26,192] A3C_AGENT_WORKER-Thread-19 INFO:Local step 12500, global step 200277: loss 0.0154
[2019-03-23 08:38:26,195] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 12500, global step 200277: learning rate 0.0005
[2019-03-23 08:38:26,243] A3C_AGENT_WORKER-Thread-10 INFO:Local step 12500, global step 200300: loss 0.0264
[2019-03-23 08:38:26,247] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 12500, global step 200301: learning rate 0.0005
[2019-03-23 08:38:26,501] A3C_AGENT_WORKER-Thread-11 INFO:Local step 12500, global step 200423: loss 0.0001
[2019-03-23 08:38:26,503] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 12500, global step 200424: learning rate 0.0005
[2019-03-23 08:38:26,612] A3C_AGENT_WORKER-Thread-17 INFO:Local step 12500, global step 200481: loss 0.0154
[2019-03-23 08:38:26,613] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 12500, global step 200481: learning rate 0.0005
[2019-03-23 08:38:37,911] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.9148316e-24 1.0000000e+00 1.5757503e-29 2.6305825e-22 1.9122044e-33], sum to 1.0000
[2019-03-23 08:38:37,918] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3034
[2019-03-23 08:38:37,921] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.78333333333333, 49.33333333333334, 1.0, 2.0, 0.6294124900742599, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 683700.5284268726, 683700.5284268726, 133856.156561104], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7739400.0000, 
sim time next is 7740000.0000, 
raw observation next is [21.6, 49.0, 1.0, 2.0, 0.6086137424002235, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 661092.4812082924, 661092.4812082924, 129558.0045528009], 
processed observation next is [1.0, 0.6086956521739131, 0.6181818181818183, 0.49, 1.0, 1.0, 0.5107671780002793, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2448490671141824, 0.2448490671141824, 0.31599513305561194], 
reward next is 0.6840, 
noisyNet noise sample is [array([2.5872786], dtype=float32), 0.6668145]. 
=============================================
[2019-03-23 08:38:37,937] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[71.49893]
 [71.44948]
 [71.38443]
 [71.35065]
 [71.3246 ]], R is [[71.47131348]
 [71.43012238]
 [71.37970734]
 [71.32388306]
 [71.28016663]].
[2019-03-23 08:38:40,511] A3C_AGENT_WORKER-Thread-3 INFO:Local step 13000, global step 207565: loss 0.0002
[2019-03-23 08:38:40,515] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 13000, global step 207568: learning rate 0.0005
[2019-03-23 08:38:40,853] A3C_AGENT_WORKER-Thread-2 INFO:Local step 13000, global step 207736: loss 0.0978
[2019-03-23 08:38:40,855] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 13000, global step 207736: learning rate 0.0005
[2019-03-23 08:38:40,861] A3C_AGENT_WORKER-Thread-21 INFO:Local step 13000, global step 207740: loss 0.0498
[2019-03-23 08:38:40,865] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 13000, global step 207741: learning rate 0.0005
[2019-03-23 08:38:41,044] A3C_AGENT_WORKER-Thread-13 INFO:Local step 13000, global step 207833: loss 0.0408
[2019-03-23 08:38:41,048] A3C_AGENT_WORKER-Thread-9 INFO:Local step 13000, global step 207836: loss 0.0252
[2019-03-23 08:38:41,049] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 13000, global step 207834: learning rate 0.0005
[2019-03-23 08:38:41,050] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 13000, global step 207836: learning rate 0.0005
[2019-03-23 08:38:41,107] A3C_AGENT_WORKER-Thread-22 INFO:Local step 13000, global step 207863: loss 0.0184
[2019-03-23 08:38:41,109] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 13000, global step 207863: learning rate 0.0005
[2019-03-23 08:38:41,134] A3C_AGENT_WORKER-Thread-18 INFO:Local step 13000, global step 207877: loss 0.0501
[2019-03-23 08:38:41,136] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 13000, global step 207877: learning rate 0.0005
[2019-03-23 08:38:41,235] A3C_AGENT_WORKER-Thread-14 INFO:Local step 13000, global step 207929: loss 0.0461
[2019-03-23 08:38:41,238] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 13000, global step 207931: learning rate 0.0005
[2019-03-23 08:38:41,264] A3C_AGENT_WORKER-Thread-12 INFO:Local step 13000, global step 207944: loss 0.0265
[2019-03-23 08:38:41,265] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 13000, global step 207944: learning rate 0.0005
[2019-03-23 08:38:41,291] A3C_AGENT_WORKER-Thread-15 INFO:Local step 13000, global step 207956: loss 0.0306
[2019-03-23 08:38:41,292] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 13000, global step 207956: learning rate 0.0005
[2019-03-23 08:38:41,361] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.8955194e-25 1.0000000e+00 1.1532784e-30 8.5693316e-22 7.4799709e-32], sum to 1.0000
[2019-03-23 08:38:41,371] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3872
[2019-03-23 08:38:41,377] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.21666666666667, 83.0, 1.0, 2.0, 0.2260521735392129, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 245439.0082561235, 245439.0082561238, 74843.61648032827], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7791000.0000, 
sim time next is 7791600.0000, 
raw observation next is [14.03333333333333, 85.0, 1.0, 2.0, 0.2120414031151464, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 230223.0367097669, 230223.0367097666, 73722.67349463065], 
processed observation next is [1.0, 0.17391304347826086, 0.27424242424242407, 0.85, 1.0, 1.0, 0.015051753893932998, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08526779137398774, 0.08526779137398763, 0.17981139876739183], 
reward next is 0.8202, 
noisyNet noise sample is [array([-0.9034873], dtype=float32), 0.48413193]. 
=============================================
[2019-03-23 08:38:41,403] A3C_AGENT_WORKER-Thread-16 INFO:Local step 13000, global step 208010: loss 0.0094
[2019-03-23 08:38:41,409] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 13000, global step 208012: learning rate 0.0005
[2019-03-23 08:38:41,528] A3C_AGENT_WORKER-Thread-20 INFO:Local step 13000, global step 208072: loss 0.0197
[2019-03-23 08:38:41,530] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 13000, global step 208074: learning rate 0.0005
[2019-03-23 08:38:41,803] A3C_AGENT_WORKER-Thread-19 INFO:Local step 13000, global step 208215: loss 0.0888
[2019-03-23 08:38:41,807] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 13000, global step 208216: learning rate 0.0005
[2019-03-23 08:38:42,010] A3C_AGENT_WORKER-Thread-10 INFO:Local step 13000, global step 208318: loss 0.2439
[2019-03-23 08:38:42,012] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 13000, global step 208318: learning rate 0.0005
[2019-03-23 08:38:42,268] A3C_AGENT_WORKER-Thread-11 INFO:Local step 13000, global step 208455: loss 0.5722
[2019-03-23 08:38:42,271] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 13000, global step 208456: learning rate 0.0005
[2019-03-23 08:38:42,311] A3C_AGENT_WORKER-Thread-17 INFO:Local step 13000, global step 208473: loss 0.4623
[2019-03-23 08:38:42,313] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 13000, global step 208473: learning rate 0.0005
[2019-03-23 08:38:46,113] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.7184776e-24 1.0000000e+00 3.4529330e-29 2.0460443e-22 5.6663741e-32], sum to 1.0000
[2019-03-23 08:38:46,116] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8451
[2019-03-23 08:38:46,121] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.1, 69.0, 1.0, 2.0, 0.2878780778572651, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 312588.838879297, 312588.8388792973, 103029.1416521234], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7871400.0000, 
sim time next is 7872000.0000, 
raw observation next is [19.2, 68.66666666666666, 1.0, 2.0, 0.284690468266933, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 309126.512494081, 309126.5124940813, 103530.5497759418], 
processed observation next is [1.0, 0.08695652173913043, 0.509090909090909, 0.6866666666666665, 1.0, 1.0, 0.10586308533366624, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1144913009237337, 0.1144913009237338, 0.25251353603888244], 
reward next is 0.7475, 
noisyNet noise sample is [array([-1.3800279], dtype=float32), 1.5361677]. 
=============================================
[2019-03-23 08:38:46,138] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[73.34806]
 [73.34806]
 [73.34806]
 [73.34806]
 [73.34806]], R is [[73.36206818]
 [73.37715912]
 [73.38990784]
 [73.39749146]
 [73.42127991]].
[2019-03-23 08:38:49,211] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:38:49,211] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:38:49,213] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run2
[2019-03-23 08:38:49,309] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:38:49,309] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:38:49,311] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run2
[2019-03-23 08:38:49,494] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:38:49,495] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:38:49,496] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run2
[2019-03-23 08:38:49,557] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:38:49,557] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:38:49,558] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run2
[2019-03-23 08:38:49,650] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:38:49,650] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:38:49,651] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run2
[2019-03-23 08:38:49,719] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:38:49,720] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:38:49,721] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run2
[2019-03-23 08:38:49,745] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:38:49,745] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:38:49,747] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run2
[2019-03-23 08:38:49,776] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:38:49,777] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:38:49,779] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run2
[2019-03-23 08:38:49,808] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:38:49,809] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:38:49,810] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run2
[2019-03-23 08:38:49,841] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:38:49,842] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:38:49,843] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run2
[2019-03-23 08:38:49,907] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:38:49,907] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:38:49,909] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run2
[2019-03-23 08:38:50,018] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:38:50,019] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:38:50,022] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run2
[2019-03-23 08:38:50,117] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:38:50,118] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:38:50,119] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:38:50,119] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:38:50,120] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run2
[2019-03-23 08:38:50,176] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:38:50,176] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:38:50,178] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run2
[2019-03-23 08:38:50,236] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run2
[2019-03-23 08:38:50,297] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:38:50,298] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:38:50,299] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run2
[2019-03-23 08:38:56,184] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.6554310e-25 1.0000000e+00 2.3114960e-29 5.4043337e-25 4.6129851e-34], sum to 1.0000
[2019-03-23 08:38:56,191] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0936
[2019-03-23 08:38:56,199] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.66666666666667, 78.66666666666666, 1.0, 2.0, 0.2007484600982085, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 217959.0254920408, 217959.0254920411, 70429.15427455043], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 106800.0000, 
sim time next is 107400.0000, 
raw observation next is [13.83333333333333, 77.83333333333334, 1.0, 2.0, 0.2024016621083762, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 219754.3652706354, 219754.3652706357, 70701.9818560944], 
processed observation next is [1.0, 0.21739130434782608, 0.265151515151515, 0.7783333333333334, 1.0, 1.0, 0.0030020776354702447, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0813905056557909, 0.08139050565579099, 0.1724438581855961], 
reward next is 0.8276, 
noisyNet noise sample is [array([-2.029658], dtype=float32), 1.4285989]. 
=============================================
[2019-03-23 08:39:01,066] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.1082334e-21 1.0000000e+00 2.2275154e-25 4.3068315e-20 4.6308974e-27], sum to 1.0000
[2019-03-23 08:39:01,075] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1794
[2019-03-23 08:39:01,086] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 94.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 201765.1341610589, 201765.1341610586, 69447.20263092859], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 192600.0000, 
sim time next is 193200.0000, 
raw observation next is [13.0, 94.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 201274.0864340625, 201274.0864340622, 69363.45538772807], 
processed observation next is [0.0, 0.21739130434782608, 0.22727272727272727, 0.94, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07454595793854167, 0.07454595793854155, 0.16917915948226359], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.15248822], dtype=float32), 1.2384273]. 
=============================================
[2019-03-23 08:39:04,883] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.1638244e-22 1.0000000e+00 5.3564830e-28 1.9822264e-20 2.5791101e-31], sum to 1.0000
[2019-03-23 08:39:04,894] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0489
[2019-03-23 08:39:04,902] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 208729.3963538359, 208729.3963538362, 72164.95802243131], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 268200.0000, 
sim time next is 268800.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 208790.9691018552, 208790.9691018555, 72167.47377630377], 
processed observation next is [0.0, 0.08695652173913043, 0.22727272727272727, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07732998855624267, 0.07732998855624278, 0.17601822872269213], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.1877159], dtype=float32), -0.0038343638]. 
=============================================
[2019-03-23 08:39:06,863] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.4544180e-25 1.0000000e+00 5.6973311e-30 2.6167195e-23 1.4648473e-32], sum to 1.0000
[2019-03-23 08:39:06,877] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7429
[2019-03-23 08:39:06,883] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 43.0, 1.0, 2.0, 0.2575128087982589, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 279607.6099690351, 279607.6099690348, 81555.62924856457], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 321000.0000, 
sim time next is 321600.0000, 
raw observation next is [21.0, 43.0, 1.0, 2.0, 0.2567509917761418, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 278780.191373287, 278780.1913732873, 81460.61787389753], 
processed observation next is [0.0, 0.7391304347826086, 0.5909090909090909, 0.43, 1.0, 1.0, 0.07093873972017724, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10325192273084703, 0.10325192273084714, 0.19868443383877446], 
reward next is 0.8013, 
noisyNet noise sample is [array([-1.4458295], dtype=float32), 0.8399593]. 
=============================================
[2019-03-23 08:39:08,087] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.6860715e-21 1.0000000e+00 2.5146570e-26 9.6046048e-20 1.3320369e-29], sum to 1.0000
[2019-03-23 08:39:08,090] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8395
[2019-03-23 08:39:08,095] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 59.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 216489.7353234682, 216489.7353234679, 70181.11067569164], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 338400.0000, 
sim time next is 339000.0000, 
raw observation next is [15.66666666666667, 60.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 213299.8732525351, 213299.8732525348, 69448.32364156614], 
processed observation next is [0.0, 0.9565217391304348, 0.3484848484848486, 0.6033333333333334, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07899995305649447, 0.07899995305649438, 0.16938615522333203], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.13844307], dtype=float32), 0.58491063]. 
=============================================
[2019-03-23 08:39:08,108] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[72.48437]
 [72.48437]
 [72.48437]
 [72.48437]
 [72.48437]], R is [[71.75952148]
 [71.04192352]
 [71.15918732]
 [71.27416992]
 [71.3868103 ]].
[2019-03-23 08:39:08,812] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.5998136e-24 1.0000000e+00 2.1760434e-29 1.7423340e-22 7.7954048e-32], sum to 1.0000
[2019-03-23 08:39:08,818] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8792
[2019-03-23 08:39:08,824] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 67.83333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 174734.2795246785, 174734.2795246785, 61370.13265910796], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 352200.0000, 
sim time next is 352800.0000, 
raw observation next is [13.0, 67.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 174666.2258562792, 174666.2258562795, 61288.40736756568], 
processed observation next is [1.0, 0.08695652173913043, 0.22727272727272727, 0.67, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.06469119476158489, 0.064691194761585, 0.14948392040869676], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.44230264], dtype=float32), -0.5644118]. 
=============================================
[2019-03-23 08:39:15,663] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-23 08:39:15,665] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 08:39:15,666] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 08:39:15,666] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 08:39:15,667] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:39:15,667] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 08:39:15,667] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:39:15,668] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:39:15,671] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:39:15,668] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 08:39:15,674] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:39:15,682] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run10
[2019-03-23 08:39:15,682] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run10
[2019-03-23 08:39:15,739] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run10
[2019-03-23 08:39:15,763] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run10
[2019-03-23 08:39:15,786] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run10
[2019-03-23 08:39:18,179] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.03391918], dtype=float32), -1.0608023]
[2019-03-23 08:39:18,179] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [14.42358278666667, 72.31164743333333, 1.0, 2.0, 0.2107782253029677, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 228840.9567035963, 228840.956703596, 76063.8592988794]
[2019-03-23 08:39:18,181] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 08:39:18,185] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.6711304e-25 1.0000000e+00 3.8922442e-30 2.3890028e-23 4.5411408e-33], sampled 0.37843130142336223
[2019-03-23 08:39:22,595] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.03391918], dtype=float32), -1.0608023]
[2019-03-23 08:39:22,596] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [13.66666666666667, 96.0, 1.0, 2.0, 0.2124579870288766, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 230675.4481465858, 230675.4481465855, 75963.14582182984]
[2019-03-23 08:39:22,597] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 08:39:22,599] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [5.6711304e-25 1.0000000e+00 3.8922442e-30 2.3890028e-23 4.5411408e-33], sampled 0.2085291930574643
[2019-03-23 08:39:26,921] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.03391918], dtype=float32), -1.0608023]
[2019-03-23 08:39:26,922] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [15.97005710666667, 83.77248460333334, 1.0, 2.0, 0.2643586498506361, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 287026.8685762822, 287026.8685762818, 91245.0173472223]
[2019-03-23 08:39:26,923] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 08:39:26,924] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [5.6711304e-25 1.0000000e+00 3.8922442e-30 2.3890028e-23 4.5411408e-33], sampled 0.35424130096991624
[2019-03-23 08:39:41,507] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.03391918], dtype=float32), -1.0608023]
[2019-03-23 08:39:41,511] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [25.86240015, 43.45102227, 1.0, 2.0, 0.3464695312863584, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 385566.5372730313, 385566.5372730309, 122200.3621486268]
[2019-03-23 08:39:41,513] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 08:39:41,516] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.6711304e-25 1.0000000e+00 3.8922442e-30 2.3890028e-23 4.5411408e-33], sampled 0.5214456869996155
[2019-03-23 08:39:41,652] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.03391918], dtype=float32), -1.0608023]
[2019-03-23 08:39:41,653] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.95, 41.00000000000001, 1.0, 2.0, 0.3075176558787556, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 333899.6888554505, 333899.6888554505, 89725.2898334194]
[2019-03-23 08:39:41,655] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 08:39:41,659] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.6711304e-25 1.0000000e+00 3.8922442e-30 2.3890028e-23 4.5411408e-33], sampled 0.3663636320951995
[2019-03-23 08:40:05,335] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.03391918], dtype=float32), -1.0608023]
[2019-03-23 08:40:05,336] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.62838885666667, 80.18572588666667, 1.0, 2.0, 0.2950258521081753, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 321616.7311938096, 321616.7311938092, 115627.0931226743]
[2019-03-23 08:40:05,337] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 08:40:05,339] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.6711304e-25 1.0000000e+00 3.8922442e-30 2.3890028e-23 4.5411408e-33], sampled 0.6137104581632885
[2019-03-23 08:40:11,782] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.03391918], dtype=float32), -1.0608023]
[2019-03-23 08:40:11,784] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [25.61367442666666, 71.31738629666667, 1.0, 2.0, 0.5230686671059507, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 595831.8618189137, 595831.8618189137, 149888.3981031045]
[2019-03-23 08:40:11,786] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 08:40:11,790] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [5.6711304e-25 1.0000000e+00 3.8922442e-30 2.3890028e-23 4.5411408e-33], sampled 0.018839325134929807
[2019-03-23 08:40:33,147] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.03391918], dtype=float32), -1.0608023]
[2019-03-23 08:40:33,148] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [13.32449013666667, 81.43406832000001, 1.0, 2.0, 0.3393184410498621, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 85.40281283076101, 368452.6825651032, 368452.6825651029, 86285.4309684421]
[2019-03-23 08:40:33,149] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 08:40:33,153] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [5.6711304e-25 1.0000000e+00 3.8922442e-30 2.3890028e-23 4.5411408e-33], sampled 0.44211603102254493
[2019-03-23 08:40:35,249] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.03391918], dtype=float32), -1.0608023]
[2019-03-23 08:40:35,250] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.0, 84.0, 1.0, 2.0, 0.3537757848141121, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 392764.3890342282, 392764.3890342282, 122390.9991264068]
[2019-03-23 08:40:35,251] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 08:40:35,255] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.6711304e-25 1.0000000e+00 3.8922442e-30 2.3890028e-23 4.5411408e-33], sampled 0.1854992679523233
[2019-03-23 08:40:39,529] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.03391918], dtype=float32), -1.0608023]
[2019-03-23 08:40:39,530] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.20206975, 61.68559536333333, 1.0, 2.0, 0.2718518831135788, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 295164.6291575938, 295164.6291575938, 94618.95980456489]
[2019-03-23 08:40:39,531] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 08:40:39,534] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.6711304e-25 1.0000000e+00 3.8922442e-30 2.3890028e-23 4.5411408e-33], sampled 0.13570715015050738
[2019-03-23 08:40:58,014] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 08:40:58,229] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 08:40:58,306] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 08:40:58,357] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 08:40:58,563] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 08:40:59,578] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 225000, evaluation results [225000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 08:41:04,101] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.4193300e-22 1.0000000e+00 2.5450742e-27 2.8283908e-21 4.0571733e-29], sum to 1.0000
[2019-03-23 08:41:04,109] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8607
[2019-03-23 08:41:04,116] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 64.0, 1.0, 2.0, 0.6234998885324239, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 695786.7774494581, 695786.7774494584, 145198.9147932624], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 579000.0000, 
sim time next is 579600.0000, 
raw observation next is [22.0, 64.0, 1.0, 2.0, 0.603790769647507, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 673704.3411826974, 673704.3411826978, 142934.9252990455], 
processed observation next is [1.0, 0.7391304347826086, 0.6363636363636364, 0.64, 1.0, 1.0, 0.5047384620593837, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.249520126363962, 0.24952012636396215, 0.3486217690220622], 
reward next is 0.6514, 
noisyNet noise sample is [array([-0.02260164], dtype=float32), 0.58130246]. 
=============================================
[2019-03-23 08:41:05,950] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.1139260e-22 1.0000000e+00 1.6183949e-28 1.9464753e-21 2.1511163e-31], sum to 1.0000
[2019-03-23 08:41:05,963] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1522
[2019-03-23 08:41:05,967] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.5, 82.5, 1.0, 2.0, 0.2921716766551349, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 317252.5105693174, 317252.5105693171, 106335.309973859], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 606600.0000, 
sim time next is 607200.0000, 
raw observation next is [17.33333333333333, 82.33333333333334, 1.0, 2.0, 0.2860197181972941, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 310570.3177734928, 310570.3177734931, 102181.2769859523], 
processed observation next is [1.0, 0.0, 0.42424242424242403, 0.8233333333333335, 1.0, 1.0, 0.10752464774661762, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11502604361981214, 0.11502604361981227, 0.2492226267950056], 
reward next is 0.7508, 
noisyNet noise sample is [array([0.4193351], dtype=float32), 0.0004140564]. 
=============================================
[2019-03-23 08:41:07,226] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.0067912e-26 1.0000000e+00 2.3150964e-29 1.3936944e-24 6.4823981e-31], sum to 1.0000
[2019-03-23 08:41:07,233] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3656
[2019-03-23 08:41:07,238] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333334, 57.00000000000001, 1.0, 2.0, 0.6118054361690319, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 683669.2363886856, 683669.236388686, 144252.224128111], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 645600.0000, 
sim time next is 646200.0000, 
raw observation next is [23.5, 57.0, 1.0, 2.0, 0.5759132811528127, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 644483.5273992941, 644483.5273992941, 140647.6189799323], 
processed observation next is [1.0, 0.4782608695652174, 0.7045454545454546, 0.57, 1.0, 1.0, 0.4698916014410158, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2386976027404793, 0.2386976027404793, 0.3430429731217861], 
reward next is 0.6570, 
noisyNet noise sample is [array([1.5453994], dtype=float32), 1.4819862]. 
=============================================
[2019-03-23 08:41:09,290] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.9028281e-22 1.0000000e+00 9.6108372e-27 1.2044839e-21 5.0501366e-30], sum to 1.0000
[2019-03-23 08:41:09,297] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5894
[2019-03-23 08:41:09,301] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 50.0, 1.0, 2.0, 0.3547630090379331, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 397237.9944031503, 397237.9944031503, 119623.3547072343], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 669600.0000, 
sim time next is 670200.0000, 
raw observation next is [24.83333333333334, 50.66666666666667, 1.0, 2.0, 0.3575860040353778, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 400194.1214829818, 400194.1214829818, 119759.1534581984], 
processed observation next is [1.0, 0.782608695652174, 0.7651515151515155, 0.5066666666666667, 1.0, 1.0, 0.19698250504422227, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14822004499369695, 0.14822004499369695, 0.2920954962395083], 
reward next is 0.7079, 
noisyNet noise sample is [array([0.6976908], dtype=float32), -0.16597816]. 
=============================================
[2019-03-23 08:41:11,425] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.7308558e-24 1.0000000e+00 3.9932063e-29 4.1742524e-24 2.3504652e-32], sum to 1.0000
[2019-03-23 08:41:11,433] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3609
[2019-03-23 08:41:11,439] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.5, 97.0, 1.0, 2.0, 0.284225209023529, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 308621.1580152831, 308621.1580152833, 98590.95506391548], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 703800.0000, 
sim time next is 704400.0000, 
raw observation next is [15.33333333333333, 98.0, 1.0, 2.0, 0.2816552904066159, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 305829.7777264664, 305829.7777264667, 97370.75352339985], 
processed observation next is [1.0, 0.13043478260869565, 0.3333333333333332, 0.98, 1.0, 1.0, 0.10206911300826987, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11327028804683942, 0.11327028804683952, 0.23748964273999965], 
reward next is 0.7625, 
noisyNet noise sample is [array([0.32537347], dtype=float32), 1.8341708]. 
=============================================
[2019-03-23 08:41:15,882] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.3578653e-20 1.0000000e+00 1.9727241e-25 7.3614654e-20 4.8468276e-28], sum to 1.0000
[2019-03-23 08:41:15,888] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2379
[2019-03-23 08:41:15,891] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 88.0, 1.0, 2.0, 0.3977787444844292, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 449464.5214324004, 449464.5214324001, 125329.1618597868], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 786600.0000, 
sim time next is 787200.0000, 
raw observation next is [20.0, 88.0, 1.0, 2.0, 0.3975941826740965, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 449255.6733524305, 449255.6733524302, 125312.1883654285], 
processed observation next is [0.0, 0.08695652173913043, 0.5454545454545454, 0.88, 1.0, 1.0, 0.24699272834262062, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16639099013052983, 0.16639099013052971, 0.3056394838181183], 
reward next is 0.6944, 
noisyNet noise sample is [array([-1.1701113], dtype=float32), 0.5348441]. 
=============================================
[2019-03-23 08:41:18,571] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0778236e-22 1.0000000e+00 4.2822267e-27 1.4899854e-21 4.5347751e-31], sum to 1.0000
[2019-03-23 08:41:18,578] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6016
[2019-03-23 08:41:18,583] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.16666666666667, 57.5, 1.0, 2.0, 0.5235925693644847, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 596267.8682572831, 596267.8682572831, 145843.3060289999], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 841800.0000, 
sim time next is 842400.0000, 
raw observation next is [28.0, 58.0, 1.0, 2.0, 0.5214497811149782, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 593963.3214004837, 593963.3214004834, 145467.1504066659], 
processed observation next is [0.0, 0.782608695652174, 0.9090909090909091, 0.58, 1.0, 1.0, 0.4018122263937227, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21998641533351249, 0.21998641533351235, 0.35479792782113634], 
reward next is 0.6452, 
noisyNet noise sample is [array([1.0180944], dtype=float32), 0.32235396]. 
=============================================
[2019-03-23 08:41:22,000] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.99188625e-24 1.00000000e+00 1.08199445e-26 5.12346654e-22
 3.58701669e-30], sum to 1.0000
[2019-03-23 08:41:22,006] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4376
[2019-03-23 08:41:22,015] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 75.83333333333333, 1.0, 2.0, 0.4667967128452942, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 532525.701771444, 532525.701771444, 136468.9970093922], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 910200.0000, 
sim time next is 910800.0000, 
raw observation next is [23.0, 78.0, 1.0, 2.0, 0.4617241276751574, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 526581.2758948592, 526581.2758948592, 135543.42672837], 
processed observation next is [0.0, 0.5652173913043478, 0.6818181818181818, 0.78, 1.0, 1.0, 0.32715515959394675, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1950301021832812, 0.1950301021832812, 0.33059372372773166], 
reward next is 0.6694, 
noisyNet noise sample is [array([-0.60152775], dtype=float32), 0.1428196]. 
=============================================
[2019-03-23 08:41:22,539] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.7829875e-20 1.0000000e+00 1.4958025e-25 2.2593650e-20 2.9572155e-29], sum to 1.0000
[2019-03-23 08:41:22,546] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3340
[2019-03-23 08:41:22,553] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 88.0, 1.0, 2.0, 0.4375236906570158, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 497789.0445275598, 497789.0445275598, 131471.3767264673], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 930600.0000, 
sim time next is 931200.0000, 
raw observation next is [21.0, 88.0, 1.0, 2.0, 0.4357469089393176, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 495765.5165771325, 495765.5165771325, 131291.0864896584], 
processed observation next is [0.0, 0.782608695652174, 0.5909090909090909, 0.88, 1.0, 1.0, 0.294683636174147, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18361685799153055, 0.18361685799153055, 0.3202221621698985], 
reward next is 0.6798, 
noisyNet noise sample is [array([-0.25204197], dtype=float32), 0.3025166]. 
=============================================
[2019-03-23 08:41:31,373] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.51295516e-22 1.00000000e+00 1.17867244e-26 4.86545709e-23
 3.64664641e-30], sum to 1.0000
[2019-03-23 08:41:31,379] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1615
[2019-03-23 08:41:31,386] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 65.0, 1.0, 2.0, 0.8261371109417002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 933628.8245033798, 933628.8245033798, 176553.068293637], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1094400.0000, 
sim time next is 1095000.0000, 
raw observation next is [23.0, 65.0, 1.0, 2.0, 0.7540034097598788, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 852060.7321222232, 852060.7321222232, 166206.6374669668], 
processed observation next is [1.0, 0.6956521739130435, 0.6818181818181818, 0.65, 1.0, 1.0, 0.6925042621998484, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.31557804893415675, 0.31557804893415675, 0.405382042602358], 
reward next is 0.5946, 
noisyNet noise sample is [array([1.3622586], dtype=float32), -0.8822004]. 
=============================================
[2019-03-23 08:41:31,408] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[70.342255]
 [70.342255]
 [70.342255]
 [70.342255]
 [70.342255]], R is [[70.23345184]
 [70.10050201]
 [69.98506165]
 [69.87878418]
 [69.78694916]].
[2019-03-23 08:41:32,828] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.3675952e-21 1.0000000e+00 1.7092044e-26 3.1676491e-20 2.2872445e-28], sum to 1.0000
[2019-03-23 08:41:32,835] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8104
[2019-03-23 08:41:32,838] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 76.0, 1.0, 2.0, 0.8189185861640287, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 933726.490103601, 933726.4901036014, 182030.4712396182], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1161000.0000, 
sim time next is 1161600.0000, 
raw observation next is [23.33333333333334, 75.33333333333333, 1.0, 2.0, 0.8411577743911002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 959684.2462771804, 959684.2462771804, 186521.4232363807], 
processed observation next is [1.0, 0.43478260869565216, 0.6969696969696972, 0.7533333333333333, 1.0, 1.0, 0.8014472179888751, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.355438609732289, 0.355438609732289, 0.4549303005765383], 
reward next is 0.5451, 
noisyNet noise sample is [array([-0.99413496], dtype=float32), -0.954458]. 
=============================================
[2019-03-23 08:41:37,354] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.6863989e-21 1.0000000e+00 6.4286568e-26 3.5909507e-20 2.0375337e-27], sum to 1.0000
[2019-03-23 08:41:37,358] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5413
[2019-03-23 08:41:37,365] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.66666666666667, 67.16666666666667, 1.0, 2.0, 0.8673765168114526, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344286455, 989254.5330279375, 989254.5330279375, 195670.471973371], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1248600.0000, 
sim time next is 1249200.0000, 
raw observation next is [26.0, 65.0, 1.0, 2.0, 0.9376484810815796, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344353685, 1070040.533254088, 1070040.533254088, 207258.5141275976], 
processed observation next is [1.0, 0.4782608695652174, 0.8181818181818182, 0.65, 1.0, 1.0, 0.9220606013519744, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206266, 0.39631130861262515, 0.39631130861262515, 0.5055085710429209], 
reward next is 0.4945, 
noisyNet noise sample is [array([-0.6987382], dtype=float32), -0.18079172]. 
=============================================
[2019-03-23 08:41:39,491] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.9293514e-12 2.8286415e-08 3.8210316e-12 1.0000000e+00 1.9471378e-12], sum to 1.0000
[2019-03-23 08:41:39,499] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2279
[2019-03-23 08:41:39,503] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.0, 58.66666666666667, 1.0, 2.0, 0.6802952456747683, 1.0, 2.0, 0.6802952456747683, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1535058.436705216, 1535058.436705216, 284569.430929722], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1260600.0000, 
sim time next is 1261200.0000, 
raw observation next is [28.0, 59.33333333333334, 1.0, 2.0, 0.6218232438167246, 1.0, 2.0, 0.6218232438167246, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1401933.804565912, 1401933.804565911, 267453.2982417657], 
processed observation next is [1.0, 0.6086956521739131, 0.9090909090909091, 0.5933333333333334, 1.0, 1.0, 0.5272790547709058, 1.0, 1.0, 0.5272790547709058, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.5192347424318193, 0.5192347424318189, 0.6523251176628432], 
reward next is 0.3477, 
noisyNet noise sample is [array([-1.3198019], dtype=float32), 0.09355177]. 
=============================================
[2019-03-23 08:41:45,039] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.4451545e-25 1.0000000e+00 1.7470732e-29 3.8806958e-22 7.2437860e-31], sum to 1.0000
[2019-03-23 08:41:45,044] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3777
[2019-03-23 08:41:45,055] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 88.0, 1.0, 2.0, 0.4723908245916151, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 538987.4454171299, 538987.4454171297, 137360.7091459497], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1377600.0000, 
sim time next is 1378200.0000, 
raw observation next is [22.0, 88.0, 1.0, 2.0, 0.4718678408199585, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 538390.3324297393, 538390.3324297395, 137302.8325949929], 
processed observation next is [1.0, 0.9565217391304348, 0.6363636363636364, 0.88, 1.0, 1.0, 0.33983480102494806, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19940382682582936, 0.19940382682582947, 0.3348849575487632], 
reward next is 0.6651, 
noisyNet noise sample is [array([1.2864298], dtype=float32), 0.87096435]. 
=============================================
[2019-03-23 08:41:47,118] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.1844313e-25 1.0000000e+00 1.6384514e-30 8.5537857e-22 5.2135760e-34], sum to 1.0000
[2019-03-23 08:41:47,128] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4144
[2019-03-23 08:41:47,135] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 89.0, 1.0, 2.0, 0.5106320915119257, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 581764.8880698587, 581764.8880698587, 144042.1791593184], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1414800.0000, 
sim time next is 1415400.0000, 
raw observation next is [23.0, 89.0, 1.0, 2.0, 0.5113325899784171, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 582533.6119282111, 582533.6119282111, 144153.6722260344], 
processed observation next is [0.0, 0.391304347826087, 0.6818181818181818, 0.89, 1.0, 1.0, 0.38916573747302136, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21575318960304113, 0.21575318960304113, 0.3515943225025229], 
reward next is 0.6484, 
noisyNet noise sample is [array([-0.6600813], dtype=float32), -1.3811756]. 
=============================================
[2019-03-23 08:41:47,367] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 08:41:47,369] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 08:41:47,372] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 08:41:47,372] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:41:47,375] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:41:47,376] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 08:41:47,377] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 08:41:47,380] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:41:47,381] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:41:47,372] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 08:41:47,384] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:41:47,391] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run11
[2019-03-23 08:41:47,412] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run11
[2019-03-23 08:41:47,413] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run11
[2019-03-23 08:41:47,461] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run11
[2019-03-23 08:41:47,462] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run11
[2019-03-23 08:41:57,340] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.03391918], dtype=float32), -1.0505259]
[2019-03-23 08:41:57,340] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.83333333333334, 65.0, 1.0, 2.0, 0.3116228489485725, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 341165.6186382945, 341165.6186382942, 117280.9317078226]
[2019-03-23 08:41:57,342] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 08:41:57,346] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [9.6019471e-24 1.0000000e+00 1.3766034e-28 1.3547020e-22 7.0917649e-31], sampled 0.9056539290827382
[2019-03-23 08:42:08,666] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.03391918], dtype=float32), -1.0505259]
[2019-03-23 08:42:08,667] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.2, 89.33333333333333, 1.0, 2.0, 0.3679001843870383, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 412774.9797130297, 412774.9797130293, 125423.3913487155]
[2019-03-23 08:42:08,668] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 08:42:08,670] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [9.6019471e-24 1.0000000e+00 1.3766034e-28 1.3547020e-22 7.0917649e-31], sampled 0.23707357723135825
[2019-03-23 08:42:19,201] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.03391918], dtype=float32), -1.0505259]
[2019-03-23 08:42:19,203] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [14.55524723666667, 97.00816192833334, 1.0, 2.0, 0.2340117004063367, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 254070.7656484156, 254070.7656484156, 87641.10187269923]
[2019-03-23 08:42:19,204] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 08:42:19,207] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [9.6019471e-24 1.0000000e+00 1.3766034e-28 1.3547020e-22 7.0917649e-31], sampled 0.21515703454970936
[2019-03-23 08:42:23,171] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.03391918], dtype=float32), -1.0505259]
[2019-03-23 08:42:23,173] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [26.470749595, 72.37883411499999, 1.0, 2.0, 0.906555053112312, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 1027371.913522896, 1027371.913522896, 210930.8518488594]
[2019-03-23 08:42:23,174] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 08:42:23,176] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [9.6019471e-24 1.0000000e+00 1.3766034e-28 1.3547020e-22 7.0917649e-31], sampled 0.9869126377093901
[2019-03-23 08:42:30,360] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.03391918], dtype=float32), -1.0505259]
[2019-03-23 08:42:30,361] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [26.793070925, 89.268791015, 1.0, 2.0, 0.6994377857064863, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 785947.4178947022, 785947.4178947022, 177853.4062758518]
[2019-03-23 08:42:30,363] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 08:42:30,366] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [9.6019471e-24 1.0000000e+00 1.3766034e-28 1.3547020e-22 7.0917649e-31], sampled 0.7965595047405043
[2019-03-23 08:42:33,314] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.03391918], dtype=float32), -1.0505259]
[2019-03-23 08:42:33,314] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [25.312568285, 97.34753124333334, 1.0, 2.0, 0.7451298759221964, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 837326.7086743162, 837326.7086743158, 185090.6317728439]
[2019-03-23 08:42:33,315] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 08:42:33,319] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [9.6019471e-24 1.0000000e+00 1.3766034e-28 1.3547020e-22 7.0917649e-31], sampled 0.6597662664710859
[2019-03-23 08:42:34,077] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.03391918], dtype=float32), -1.0505259]
[2019-03-23 08:42:34,078] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.23333333333333, 74.0, 1.0, 2.0, 0.3924334743786946, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 440871.9255952919, 440871.9255952919, 127804.117606563]
[2019-03-23 08:42:34,079] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 08:42:34,084] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [9.6019471e-24 1.0000000e+00 1.3766034e-28 1.3547020e-22 7.0917649e-31], sampled 0.7419038155545647
[2019-03-23 08:43:14,400] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.03391918], dtype=float32), -1.0505259]
[2019-03-23 08:43:14,402] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [15.096953875, 94.579721105, 1.0, 2.0, 0.2558779439694134, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 277816.8312511255, 277816.8312511251, 92401.82212704925]
[2019-03-23 08:43:14,403] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 08:43:14,405] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [9.6019471e-24 1.0000000e+00 1.3766034e-28 1.3547020e-22 7.0917649e-31], sampled 0.820466452678302
[2019-03-23 08:43:28,957] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 08:43:29,514] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 08:43:29,822] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 08:43:29,873] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 08:43:29,927] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 08:43:30,942] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 250000, evaluation results [250000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 08:43:36,974] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.0388763e-23 1.0000000e+00 1.9166129e-28 2.8557315e-22 3.7528120e-31], sum to 1.0000
[2019-03-23 08:43:36,980] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3550
[2019-03-23 08:43:36,984] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 79.0, 1.0, 2.0, 0.5779184727491702, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 651614.8077261326, 651614.8077261323, 155376.9351318718], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1533600.0000, 
sim time next is 1534200.0000, 
raw observation next is [25.66666666666667, 79.66666666666667, 1.0, 2.0, 0.5746964890245674, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 648934.5059074509, 648934.5059074513, 154698.7672449297], 
processed observation next is [0.0, 0.782608695652174, 0.8030303030303032, 0.7966666666666667, 1.0, 1.0, 0.46837061128070917, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2403461132990559, 0.24034611329905603, 0.3773140664510481], 
reward next is 0.6227, 
noisyNet noise sample is [array([0.01098495], dtype=float32), 0.107768886]. 
=============================================
[2019-03-23 08:43:38,183] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.3202766e-27 1.0000000e+00 7.1576453e-31 2.5061653e-24 2.1455320e-34], sum to 1.0000
[2019-03-23 08:43:38,187] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2695
[2019-03-23 08:43:38,191] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.4118452584959689, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 466881.7560643575, 466881.7560643578, 127581.0889667423], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1567800.0000, 
sim time next is 1568400.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4126928449535796, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 467839.4522401394, 467839.4522401397, 127659.1629630177], 
processed observation next is [1.0, 0.13043478260869565, 0.5, 1.0, 1.0, 1.0, 0.26586605619197445, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17327387120005164, 0.17327387120005175, 0.31136381210492126], 
reward next is 0.6886, 
noisyNet noise sample is [array([-0.42967778], dtype=float32), -0.7601893]. 
=============================================
[2019-03-23 08:43:38,681] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.2114710e-25 1.0000000e+00 4.3024748e-30 2.2613189e-23 2.0708242e-31], sum to 1.0000
[2019-03-23 08:43:38,692] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7544
[2019-03-23 08:43:38,696] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.16666666666667, 94.00000000000001, 1.0, 2.0, 0.4128079277421273, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 469285.8974811581, 469285.8974811581, 128678.3041916452], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1577400.0000, 
sim time next is 1578000.0000, 
raw observation next is [20.33333333333334, 94.0, 1.0, 2.0, 0.4128746363218472, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 469758.9252341168, 469758.9252341168, 129049.9719225623], 
processed observation next is [1.0, 0.2608695652173913, 0.5606060606060609, 0.94, 1.0, 1.0, 0.2660932954023089, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17398478712374696, 0.17398478712374696, 0.31475602907942024], 
reward next is 0.6852, 
noisyNet noise sample is [array([0.27929518], dtype=float32), -0.7174711]. 
=============================================
[2019-03-23 08:43:38,724] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[66.15294]
 [66.15294]
 [66.15294]
 [66.15294]
 [66.15294]], R is [[66.17665863]
 [66.20104218]
 [66.22745514]
 [66.25444031]
 [66.2817688 ]].
[2019-03-23 08:43:41,635] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.1668461e-24 1.0000000e+00 7.2761648e-30 2.9380866e-23 6.3380545e-32], sum to 1.0000
[2019-03-23 08:43:41,643] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5973
[2019-03-23 08:43:41,650] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.66666666666667, 74.66666666666667, 1.0, 2.0, 0.4640807395771754, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 529430.5931707681, 529430.5931707685, 136189.176407289], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1624200.0000, 
sim time next is 1624800.0000, 
raw observation next is [23.33333333333333, 75.33333333333334, 1.0, 2.0, 0.4592532968937977, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 523719.6431292801, 523719.6431292804, 135194.9351129419], 
processed observation next is [1.0, 0.8260869565217391, 0.6969696969696968, 0.7533333333333334, 1.0, 1.0, 0.32406662111724704, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19397023819602968, 0.1939702381960298, 0.3297437441779071], 
reward next is 0.6703, 
noisyNet noise sample is [array([0.6023524], dtype=float32), -2.4961996]. 
=============================================
[2019-03-23 08:43:42,084] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.1327385e-29 1.0000000e+00 9.5765754e-36 1.3324158e-25 3.3832154e-37], sum to 1.0000
[2019-03-23 08:43:42,090] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5418
[2019-03-23 08:43:42,095] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.5, 85.5, 1.0, 2.0, 0.3684717033727692, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 412935.8860856364, 412935.8860856362, 120918.6319653113], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1639800.0000, 
sim time next is 1640400.0000, 
raw observation next is [19.33333333333334, 86.33333333333334, 1.0, 2.0, 0.3663989752052724, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 410291.41044786, 410291.41044786, 120594.264465297], 
processed observation next is [1.0, 1.0, 0.5151515151515155, 0.8633333333333334, 1.0, 1.0, 0.2079987190065905, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15195978164735557, 0.15195978164735557, 0.29413235235438295], 
reward next is 0.7059, 
noisyNet noise sample is [array([-0.8945976], dtype=float32), -0.0036515335]. 
=============================================
[2019-03-23 08:43:43,346] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.0922469e-24 1.0000000e+00 4.0494866e-30 8.9610635e-25 1.5587338e-31], sum to 1.0000
[2019-03-23 08:43:43,355] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7412
[2019-03-23 08:43:43,363] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 92.0, 1.0, 2.0, 0.3436711812197031, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 380977.3221764624, 380977.3221764621, 117050.2469174409], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1651200.0000, 
sim time next is 1651800.0000, 
raw observation next is [18.0, 93.0, 1.0, 2.0, 0.3448563690972226, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 382942.9749906102, 382942.9749906102, 117407.8674917293], 
processed observation next is [1.0, 0.08695652173913043, 0.45454545454545453, 0.93, 1.0, 1.0, 0.18107046137152824, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1418307314780038, 0.1418307314780038, 0.28636065241885195], 
reward next is 0.7136, 
noisyNet noise sample is [array([-1.3835475], dtype=float32), -0.09124794]. 
=============================================
[2019-03-23 08:43:50,604] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.5687434e-29 1.0000000e+00 2.5330742e-34 1.0278049e-27 3.2107383e-36], sum to 1.0000
[2019-03-23 08:43:50,613] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6196
[2019-03-23 08:43:50,617] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.83333333333334, 40.0, 1.0, 2.0, 0.4515040989851178, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 490349.7128199452, 490349.7128199452, 97369.25736715167], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1782600.0000, 
sim time next is 1783200.0000, 
raw observation next is [19.66666666666667, 40.0, 1.0, 2.0, 0.4386813281911915, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 476416.8982334274, 476416.8982334274, 95508.77389238345], 
processed observation next is [1.0, 0.6521739130434783, 0.5303030303030305, 0.4, 1.0, 1.0, 0.29835166023898935, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17645070304941754, 0.17645070304941754, 0.2329482290058133], 
reward next is 0.7671, 
noisyNet noise sample is [array([-0.58649087], dtype=float32), 0.42555508]. 
=============================================
[2019-03-23 08:43:54,082] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.9393892e-29 1.0000000e+00 2.4354311e-33 2.7050882e-26 2.0340696e-35], sum to 1.0000
[2019-03-23 08:43:54,085] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6574
[2019-03-23 08:43:54,094] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.16666666666666, 48.5, 1.0, 2.0, 0.2868927200527512, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 311518.5576484286, 311518.5576484288, 90469.9897038277], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1885800.0000, 
sim time next is 1886400.0000, 
raw observation next is [21.0, 49.0, 1.0, 2.0, 0.2850403894458384, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 309506.5896198399, 309506.5896198402, 89793.7334055194], 
processed observation next is [1.0, 0.8695652173913043, 0.5909090909090909, 0.49, 1.0, 1.0, 0.10630048680729802, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11463207022957034, 0.11463207022957045, 0.21900910586712047], 
reward next is 0.7810, 
noisyNet noise sample is [array([-0.2001391], dtype=float32), 1.2495198]. 
=============================================
[2019-03-23 08:44:04,482] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.6022227e-29 1.0000000e+00 1.2056745e-36 2.9282274e-24 0.0000000e+00], sum to 1.0000
[2019-03-23 08:44:04,490] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7992
[2019-03-23 08:44:04,494] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 60.0, 1.0, 2.0, 0.2633868447400624, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 285987.5180604642, 285987.5180604642, 86137.10863042015], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2071800.0000, 
sim time next is 2072400.0000, 
raw observation next is [19.0, 60.0, 1.0, 2.0, 0.2635478106643171, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 286162.3475530308, 286162.3475530305, 86153.99459433836], 
processed observation next is [0.0, 1.0, 0.5, 0.6, 1.0, 1.0, 0.07943476333039635, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10598605464927068, 0.10598605464927055, 0.2101316941325326], 
reward next is 0.7899, 
noisyNet noise sample is [array([0.09126496], dtype=float32), -0.5653862]. 
=============================================
[2019-03-23 08:44:09,200] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.4990821e-27 1.0000000e+00 1.7229332e-32 7.0704506e-24 9.8796737e-34], sum to 1.0000
[2019-03-23 08:44:09,208] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5381
[2019-03-23 08:44:09,218] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.31666666666667, 93.33333333333334, 1.0, 2.0, 0.2364219062444581, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 256701.0479502896, 256701.0479502893, 80111.79371502425], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2182200.0000, 
sim time next is 2182800.0000, 
raw observation next is [14.43333333333333, 92.66666666666667, 1.0, 2.0, 0.2319932922854099, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 251891.3234914352, 251891.3234914352, 79880.04065475283], 
processed observation next is [1.0, 0.2608695652173913, 0.29242424242424225, 0.9266666666666667, 1.0, 1.0, 0.03999161535676237, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09329308277460563, 0.09329308277460563, 0.19482936745061666], 
reward next is 0.8052, 
noisyNet noise sample is [array([-0.71078646], dtype=float32), 1.107046]. 
=============================================
[2019-03-23 08:44:12,596] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.4403161e-26 1.0000000e+00 2.0888889e-32 1.1026581e-25 4.3959835e-35], sum to 1.0000
[2019-03-23 08:44:12,603] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8927
[2019-03-23 08:44:12,609] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 88.0, 1.0, 2.0, 0.2068176744543286, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 224550.0867219673, 224550.086721967, 73866.35059509781], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2259000.0000, 
sim time next is 2259600.0000, 
raw observation next is [14.0, 86.0, 1.0, 2.0, 0.2007183842717476, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 217926.3638899961, 217926.3638899961, 72695.78707766421], 
processed observation next is [1.0, 0.13043478260869565, 0.2727272727272727, 0.86, 1.0, 1.0, 0.0008979803396844815, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08071346810740597, 0.08071346810740597, 0.1773067977504005], 
reward next is 0.8227, 
noisyNet noise sample is [array([0.54456776], dtype=float32), -1.6609684]. 
=============================================
[2019-03-23 08:44:16,772] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.1728418e-28 1.0000000e+00 6.2555631e-34 2.5742342e-24 6.4475624e-35], sum to 1.0000
[2019-03-23 08:44:16,779] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9779
[2019-03-23 08:44:16,783] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 55.0, 1.0, 2.0, 0.2351122037486369, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 255278.6322414817, 255278.6322414814, 74321.59694840123], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2323200.0000, 
sim time next is 2323800.0000, 
raw observation next is [17.0, 55.0, 1.0, 2.0, 0.2348665570534023, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 255011.8456143901, 255011.8456143901, 74295.2465995619], 
processed observation next is [1.0, 0.9130434782608695, 0.4090909090909091, 0.55, 1.0, 1.0, 0.043583196316752844, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09444883170903337, 0.09444883170903337, 0.18120791853551682], 
reward next is 0.8188, 
noisyNet noise sample is [array([0.46418557], dtype=float32), -0.8919022]. 
=============================================
[2019-03-23 08:44:18,754] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-23 08:44:18,755] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 08:44:18,756] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:44:18,756] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 08:44:18,757] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 08:44:18,759] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:44:18,760] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 08:44:18,761] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:44:18,762] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 08:44:18,768] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:44:18,769] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:44:18,783] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run12
[2019-03-23 08:44:18,807] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run12
[2019-03-23 08:44:18,830] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run12
[2019-03-23 08:44:18,831] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run12
[2019-03-23 08:44:18,853] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run12
[2019-03-23 08:44:23,324] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.03391918], dtype=float32), -0.98294777]
[2019-03-23 08:44:23,325] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [14.0, 67.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 196406.3741141818, 196406.3741141821, 65686.70317760974]
[2019-03-23 08:44:23,326] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 08:44:23,328] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [5.8101559e-26 1.0000000e+00 6.4823206e-32 2.1554611e-24 1.7261099e-33], sampled 0.8905663746154863
[2019-03-23 08:44:26,654] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.03391918], dtype=float32), -0.98294777]
[2019-03-23 08:44:26,655] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [24.0, 56.0, 1.0, 2.0, 0.7671979048430845, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 862546.9380088518, 862546.9380088518, 165750.8290552387]
[2019-03-23 08:44:26,655] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 08:44:26,659] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [5.8101559e-26 1.0000000e+00 6.4823206e-32 2.1554611e-24 1.7261099e-33], sampled 0.5629776229842298
[2019-03-23 08:44:30,753] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.03391918], dtype=float32), -0.98294777]
[2019-03-23 08:44:30,756] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [13.0, 94.00000000000001, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 214758.466735268, 214758.4667352683, 71717.11296587366]
[2019-03-23 08:44:30,759] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 08:44:30,761] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [5.8101559e-26 1.0000000e+00 6.4823206e-32 2.1554611e-24 1.7261099e-33], sampled 0.4048923273044014
[2019-03-23 08:44:51,411] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.03391918], dtype=float32), -0.98294777]
[2019-03-23 08:44:51,414] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.757421325, 69.260256905, 1.0, 2.0, 0.4176219418056996, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 473168.5655620944, 473168.5655620941, 132287.7487292279]
[2019-03-23 08:44:51,415] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 08:44:51,421] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [5.8101559e-26 1.0000000e+00 6.4823206e-32 2.1554611e-24 1.7261099e-33], sampled 0.3479067539599947
[2019-03-23 08:46:00,351] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 08:46:00,450] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.03391918], dtype=float32), -0.98294777]
[2019-03-23 08:46:00,451] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.25725155333333, 38.13374460666667, 1.0, 2.0, 0.3611610784161871, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 392164.2015295987, 392164.2015295983, 102350.522091297]
[2019-03-23 08:46:00,452] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 08:46:00,458] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [5.8101559e-26 1.0000000e+00 6.4823206e-32 2.1554611e-24 1.7261099e-33], sampled 0.7261188655180106
[2019-03-23 08:46:00,572] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 08:46:01,080] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 08:46:01,173] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 08:46:01,257] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 08:46:02,272] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 275000, evaluation results [275000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 08:46:03,923] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.5583368e-27 1.0000000e+00 3.9510143e-33 2.3075108e-24 8.7682028e-36], sum to 1.0000
[2019-03-23 08:46:03,929] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1509
[2019-03-23 08:46:03,935] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 46.0, 1.0, 2.0, 0.5372787746925671, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 583560.0166677395, 583560.0166677393, 119806.596611743], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2383200.0000, 
sim time next is 2383800.0000, 
raw observation next is [22.16666666666667, 46.16666666666667, 1.0, 2.0, 0.5660387182255949, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 614817.1016745005, 614817.1016745005, 124485.5853741394], 
processed observation next is [1.0, 0.6086956521739131, 0.6439393939393941, 0.4616666666666667, 1.0, 1.0, 0.45754839778199363, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22771003765722242, 0.22771003765722242, 0.3036233789613156], 
reward next is 0.6964, 
noisyNet noise sample is [array([1.1844869], dtype=float32), -0.6950835]. 
=============================================
[2019-03-23 08:46:07,390] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.6188205e-28 1.0000000e+00 3.7941203e-33 1.6534501e-24 5.4532210e-35], sum to 1.0000
[2019-03-23 08:46:07,402] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6825
[2019-03-23 08:46:07,407] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.16666666666667, 65.66666666666667, 1.0, 2.0, 0.4558909217423739, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 496517.8356629412, 496517.8356629412, 123453.7359152833], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2481000.0000, 
sim time next is 2481600.0000, 
raw observation next is [19.33333333333334, 71.33333333333334, 1.0, 2.0, 0.3172991523584491, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 344598.7391654306, 344598.7391654306, 112385.5189269544], 
processed observation next is [1.0, 0.7391304347826086, 0.5151515151515155, 0.7133333333333334, 1.0, 1.0, 0.14662394044806132, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12762916265386318, 0.12762916265386318, 0.2741110217730595], 
reward next is 0.7259, 
noisyNet noise sample is [array([0.23247126], dtype=float32), -1.6185255]. 
=============================================
[2019-03-23 08:46:14,883] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.4781433e-26 1.0000000e+00 2.6781056e-33 1.0584366e-23 4.9831097e-34], sum to 1.0000
[2019-03-23 08:46:14,892] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2796
[2019-03-23 08:46:14,899] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.9, 72.5, 1.0, 2.0, 0.267123288435319, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 290045.7879480149, 290045.7879480146, 91535.45090957469], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2590200.0000, 
sim time next is 2590800.0000, 
raw observation next is [17.83333333333333, 72.33333333333334, 1.0, 2.0, 0.2650432155680816, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 287786.5507206807, 287786.5507206804, 90486.5588616702], 
processed observation next is [1.0, 1.0, 0.44696969696969674, 0.7233333333333334, 1.0, 1.0, 0.08130401946010196, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10658761137802988, 0.10658761137802977, 0.22069892405285416], 
reward next is 0.7793, 
noisyNet noise sample is [array([0.83003306], dtype=float32), -0.13976073]. 
=============================================
[2019-03-23 08:46:17,836] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.6598393e-24 1.0000000e+00 5.0232927e-31 1.0600443e-24 4.3343959e-32], sum to 1.0000
[2019-03-23 08:46:17,847] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1934
[2019-03-23 08:46:17,849] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.16666666666667, 68.33333333333333, 1.0, 2.0, 0.3752814174004916, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 421948.3084389602, 421948.3084389599, 122166.001295665], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2674200.0000, 
sim time next is 2674800.0000, 
raw observation next is [22.0, 69.0, 1.0, 2.0, 0.3738469103294191, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 420057.4529271345, 420057.4529271342, 121902.7645914659], 
processed observation next is [0.0, 1.0, 0.6363636363636364, 0.69, 1.0, 1.0, 0.21730863791177382, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15557683441745723, 0.1555768344174571, 0.2973238160767461], 
reward next is 0.7027, 
noisyNet noise sample is [array([-1.2444574], dtype=float32), -1.4364991]. 
=============================================
[2019-03-23 08:46:24,767] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.3303944e-25 1.0000000e+00 9.8374136e-32 1.1434730e-25 7.5585888e-33], sum to 1.0000
[2019-03-23 08:46:24,783] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4101
[2019-03-23 08:46:24,786] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 83.0, 1.0, 2.0, 0.3981889232384931, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 450976.4507116894, 450976.4507116897, 126016.5349158226], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2793600.0000, 
sim time next is 2794200.0000, 
raw observation next is [21.33333333333333, 81.33333333333334, 1.0, 2.0, 0.4432685168885356, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 502650.8520909219, 502650.8520909219, 130720.7241244075], 
processed observation next is [1.0, 0.34782608695652173, 0.6060606060606059, 0.8133333333333335, 1.0, 1.0, 0.30408564611066946, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.186166982255897, 0.186166982255897, 0.3188310344497744], 
reward next is 0.6812, 
noisyNet noise sample is [array([-2.5489938], dtype=float32), -0.71563804]. 
=============================================
[2019-03-23 08:46:38,260] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.1111787e-10 9.9999809e-01 8.1735786e-14 1.9449706e-06 1.1117253e-15], sum to 1.0000
[2019-03-23 08:46:38,266] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4298
[2019-03-23 08:46:38,273] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1311038.830367355 W.
[2019-03-23 08:46:38,277] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.0, 74.0, 1.0, 2.0, 0.6699139846554905, 0.0, 2.0, 0.0, 1.0, 2.0, 0.975130078293633, 6.9112, 6.9112, 77.32846344354104, 1311038.830367355, 1311038.830367355, 285572.9059296771], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3076200.0000, 
sim time next is 3076800.0000, 
raw observation next is [25.33333333333333, 74.0, 1.0, 2.0, 0.3677741797485354, 1.0, 1.0, 0.3677741797485354, 1.0, 2.0, 0.7441878270265944, 6.9112, 6.9112, 77.3421103, 1246790.945531606, 1246790.945531606, 289935.0721440303], 
processed observation next is [1.0, 0.6086956521739131, 0.7878787878787876, 0.74, 1.0, 1.0, 0.2097177246856692, 1.0, 0.5, 0.2097177246856692, 1.0, 1.0, 0.6345540386094206, 0.0, 0.0, 0.5085185399722538, 0.46177442427096516, 0.46177442427096516, 0.7071587125464154], 
reward next is 0.2928, 
noisyNet noise sample is [array([-0.05096283], dtype=float32), -0.9489943]. 
=============================================
[2019-03-23 08:46:45,798] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.6189303e-24 1.0000000e+00 4.1134901e-31 1.2111259e-24 1.6692839e-36], sum to 1.0000
[2019-03-23 08:46:45,807] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2774
[2019-03-23 08:46:45,811] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 92.0, 1.0, 2.0, 0.35503182702358, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 393978.255831579, 393978.2558315793, 118097.8651329956], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3212400.0000, 
sim time next is 3213000.0000, 
raw observation next is [18.0, 91.0, 1.0, 2.0, 0.3504877210968989, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 388237.5368471611, 388237.5368471614, 117460.0929715441], 
processed observation next is [0.0, 0.17391304347826086, 0.45454545454545453, 0.91, 1.0, 1.0, 0.18810965137112362, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14379168031376335, 0.1437916803137635, 0.2864880316379124], 
reward next is 0.7135, 
noisyNet noise sample is [array([-0.08924243], dtype=float32), 1.1708912]. 
=============================================
[2019-03-23 08:46:45,826] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[69.60793]
 [69.60793]
 [69.60793]
 [69.60793]
 [69.60793]], R is [[69.62538147]
 [69.64109039]
 [69.65496063]
 [69.66704559]
 [69.67723846]].
[2019-03-23 08:46:49,161] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.8503076e-24 1.0000000e+00 1.7169103e-32 9.0674197e-25 7.2973791e-36], sum to 1.0000
[2019-03-23 08:46:49,172] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1207
[2019-03-23 08:46:49,178] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333333, 49.0, 1.0, 2.0, 0.3196865878238127, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 349058.3293618936, 349058.3293618939, 113198.3235976481], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3264000.0000, 
sim time next is 3264600.0000, 
raw observation next is [23.16666666666667, 49.5, 1.0, 2.0, 0.3179837173470564, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 346802.3557573581, 346802.3557573581, 112938.421336011], 
processed observation next is [0.0, 0.782608695652174, 0.6893939393939396, 0.495, 1.0, 1.0, 0.14747964668382046, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12844531694716965, 0.12844531694716965, 0.27545956423417317], 
reward next is 0.7245, 
noisyNet noise sample is [array([2.769283], dtype=float32), -0.5849718]. 
=============================================
[2019-03-23 08:46:50,088] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-23 08:46:50,089] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 08:46:50,090] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:46:50,091] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 08:46:50,091] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 08:46:50,093] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 08:46:50,094] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 08:46:50,095] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:46:50,092] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:46:50,100] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:46:50,096] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:46:50,110] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run13
[2019-03-23 08:46:50,136] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run13
[2019-03-23 08:46:50,137] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run13
[2019-03-23 08:46:50,180] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run13
[2019-03-23 08:46:50,208] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run13
[2019-03-23 08:46:52,982] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.03391918], dtype=float32), -0.91841394]
[2019-03-23 08:46:52,982] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [23.1227253, 52.90484918, 1.0, 2.0, 0.5130660525247337, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 566800.66522649, 566800.6652264897, 135495.1635939777]
[2019-03-23 08:46:52,984] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 08:46:52,986] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.9525412e-27 1.0000000e+00 6.3476778e-34 1.5231068e-25 2.1117164e-38], sampled 0.13522360456826688
[2019-03-23 08:47:04,977] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.03391918], dtype=float32), -0.91841394]
[2019-03-23 08:47:04,978] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.0, 100.0, 1.0, 2.0, 0.3743380980865998, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 420243.7996661613, 420243.7996661616, 121764.1741673889]
[2019-03-23 08:47:04,979] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 08:47:04,981] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.9525412e-27 1.0000000e+00 6.3476778e-34 1.5231068e-25 2.1117164e-38], sampled 0.2727753101812096
[2019-03-23 08:47:25,751] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.03391918], dtype=float32), -0.91841394]
[2019-03-23 08:47:25,753] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [27.8, 46.0, 1.0, 2.0, 0.4074048792840285, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 462946.690697333, 462946.690697333, 132331.781835768]
[2019-03-23 08:47:25,753] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 08:47:25,758] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.9525412e-27 1.0000000e+00 6.3476778e-34 1.5231068e-25 2.1117164e-38], sampled 0.9037918308568114
[2019-03-23 08:47:29,809] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.03391918], dtype=float32), -0.91841394]
[2019-03-23 08:47:29,810] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [24.0, 50.0, 1.0, 2.0, 0.3363041132401989, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 371879.0548919595, 371879.0548919595, 116111.553489664]
[2019-03-23 08:47:29,814] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 08:47:29,821] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.9525412e-27 1.0000000e+00 6.3476778e-34 1.5231068e-25 2.1117164e-38], sampled 0.6163278959050578
[2019-03-23 08:47:36,156] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.03391918], dtype=float32), -0.91841394]
[2019-03-23 08:47:36,158] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [28.54994077666667, 61.22084491333334, 1.0, 2.0, 0.5845509684123327, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 660681.9080612259, 660681.9080612259, 160136.5681817503]
[2019-03-23 08:47:36,159] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 08:47:36,164] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.9525412e-27 1.0000000e+00 6.3476778e-34 1.5231068e-25 2.1117164e-38], sampled 0.15097355857971628
[2019-03-23 08:47:43,740] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.03391918], dtype=float32), -0.91841394]
[2019-03-23 08:47:43,742] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.634524195, 98.81428143166667, 1.0, 2.0, 0.3346102710894137, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 372277.7758038843, 372277.775803884, 121237.7921410549]
[2019-03-23 08:47:43,744] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 08:47:43,747] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.9525412e-27 1.0000000e+00 6.3476778e-34 1.5231068e-25 2.1117164e-38], sampled 0.1156286255634128
[2019-03-23 08:48:03,410] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.03391918], dtype=float32), -0.91841394]
[2019-03-23 08:48:03,411] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [12.52085048666667, 76.10940006666668, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 172436.7870614722, 172436.7870614726, 65748.7120765917]
[2019-03-23 08:48:03,412] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 08:48:03,415] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.9525412e-27 1.0000000e+00 6.3476778e-34 1.5231068e-25 2.1117164e-38], sampled 0.9692349700547757
[2019-03-23 08:48:15,017] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.03391918], dtype=float32), -0.91841394]
[2019-03-23 08:48:15,019] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.434974125, 70.94269246833333, 1.0, 2.0, 0.3279423320018042, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 361842.3575828771, 361842.3575828767, 119490.0265514376]
[2019-03-23 08:48:15,020] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 08:48:15,022] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.9525412e-27 1.0000000e+00 6.3476778e-34 1.5231068e-25 2.1117164e-38], sampled 0.34846059357356074
[2019-03-23 08:48:31,799] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9069.6376 1657125811.2643 52.0000
[2019-03-23 08:48:32,392] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8519.2938 1760140460.0722 131.0000
[2019-03-23 08:48:32,477] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8660.8850 1701758785.3586 276.0000
[2019-03-23 08:48:32,500] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8600.6142 1681667570.9843 142.0000
[2019-03-23 08:48:32,540] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8866.8828 1664249525.6236 71.0000
[2019-03-23 08:48:33,555] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 300000, evaluation results [300000.0, 8519.293799977639, 1760140460.0722048, 131.0, 9069.637582560634, 1657125811.2643328, 52.0, 8866.882829998503, 1664249525.623554, 71.0, 8660.885006707316, 1701758785.3586307, 276.0, 8600.614212102397, 1681667570.9843318, 142.0]
[2019-03-23 08:48:43,046] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.2996600e-26 1.0000000e+00 1.2917626e-31 1.7903719e-24 6.5401091e-35], sum to 1.0000
[2019-03-23 08:48:43,053] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0649
[2019-03-23 08:48:43,056] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.5318002436040754, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 606776.2708203051, 606776.2708203051, 145290.5053973112], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3472800.0000, 
sim time next is 3473400.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.5266837152223558, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 600936.6641990814, 600936.6641990814, 144668.5141418968], 
processed observation next is [1.0, 0.17391304347826086, 0.5909090909090909, 1.0, 1.0, 1.0, 0.4083546440279447, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22256913488854865, 0.22256913488854865, 0.35285003449243124], 
reward next is 0.6471, 
noisyNet noise sample is [array([0.7421587], dtype=float32), -1.5226282]. 
=============================================
[2019-03-23 08:49:03,192] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.2312187e-29 1.0000000e+00 1.0162640e-36 1.6476109e-27 0.0000000e+00], sum to 1.0000
[2019-03-23 08:49:03,201] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8442
[2019-03-23 08:49:03,207] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.83333333333333, 64.0, 1.0, 2.0, 0.3139866789242876, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 343459.8399460183, 343459.8399460183, 113024.2623585912], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3877800.0000, 
sim time next is 3878400.0000, 
raw observation next is [20.66666666666667, 64.0, 1.0, 2.0, 0.3098770186712216, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 337995.1174186108, 337995.1174186111, 112387.8916355331], 
processed observation next is [0.0, 0.9130434782608695, 0.575757575757576, 0.64, 1.0, 1.0, 0.13734627333902696, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1251833768217077, 0.1251833768217078, 0.2741168088671539], 
reward next is 0.7259, 
noisyNet noise sample is [array([0.05634391], dtype=float32), 0.1398458]. 
=============================================
[2019-03-23 08:49:16,497] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.2344507e-28 1.0000000e+00 1.6224017e-34 2.3965911e-28 0.0000000e+00], sum to 1.0000
[2019-03-23 08:49:16,504] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5326
[2019-03-23 08:49:16,507] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.33333333333333, 100.0, 1.0, 2.0, 0.3564747640241976, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 396904.1222395512, 396904.1222395512, 118760.473071331], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4160400.0000, 
sim time next is 4161000.0000, 
raw observation next is [17.16666666666667, 100.0, 1.0, 2.0, 0.3506536856992221, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 389439.7549645434, 389439.7549645437, 117884.6045559631], 
processed observation next is [1.0, 0.13043478260869565, 0.4166666666666669, 1.0, 1.0, 1.0, 0.18831710712402763, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14423694628316422, 0.14423694628316433, 0.28752342574625145], 
reward next is 0.7125, 
noisyNet noise sample is [array([0.4982621], dtype=float32), -0.9518008]. 
=============================================
[2019-03-23 08:49:16,521] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[72.70707]
 [72.70707]
 [72.70707]
 [72.70707]
 [72.70707]], R is [[72.69247437]
 [72.67589569]
 [72.65783691]
 [72.63717651]
 [72.60845947]].
[2019-03-23 08:49:19,860] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.65738982e-24 1.00000000e+00 1.19265544e-29 2.55674553e-24
 5.78202712e-35], sum to 1.0000
[2019-03-23 08:49:19,868] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8609
[2019-03-23 08:49:19,872] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666667, 67.16666666666667, 1.0, 2.0, 0.7873915622792553, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 889808.635818621, 889808.635818621, 170906.112330412], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4189800.0000, 
sim time next is 4190400.0000, 
raw observation next is [23.0, 65.0, 1.0, 2.0, 0.7973976540788824, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 901112.9020266846, 901112.9020266846, 172338.3461385176], 
processed observation next is [1.0, 0.5217391304347826, 0.6818181818181818, 0.65, 1.0, 1.0, 0.7467470675986029, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3337455192691424, 0.3337455192691424, 0.4203374296061405], 
reward next is 0.5797, 
noisyNet noise sample is [array([-0.48459652], dtype=float32), 0.078729264]. 
=============================================
[2019-03-23 08:49:21,437] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-23 08:49:21,440] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 08:49:21,442] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:49:21,442] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 08:49:21,443] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 08:49:21,444] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:49:21,444] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:49:21,444] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 08:49:21,445] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 08:49:21,448] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:49:21,449] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:49:21,459] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run14
[2019-03-23 08:49:21,484] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run14
[2019-03-23 08:49:21,485] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run14
[2019-03-23 08:49:21,519] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run14
[2019-03-23 08:49:21,573] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run14
[2019-03-23 08:49:42,226] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.03391918], dtype=float32), -0.9145619]
[2019-03-23 08:49:42,228] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.13333333333334, 83.00000000000001, 1.0, 2.0, 0.3744996777639978, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 415874.8987136405, 415874.8987136401, 124093.7062667314]
[2019-03-23 08:49:42,229] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 08:49:42,230] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.6468293e-29 1.0000000e+00 1.2393240e-36 3.7994872e-29 0.0000000e+00], sampled 0.17139439045979232
[2019-03-23 08:49:49,971] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.03391918], dtype=float32), -0.9145619]
[2019-03-23 08:49:49,972] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [15.37330301833333, 98.58772270833335, 1.0, 2.0, 0.2886890070321407, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 313450.3931913793, 313450.3931913789, 103757.7693621785]
[2019-03-23 08:49:49,973] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 08:49:49,978] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.6468293e-29 1.0000000e+00 1.2393240e-36 3.7994872e-29 0.0000000e+00], sampled 0.2795368687544444
[2019-03-23 08:49:59,989] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.03391918], dtype=float32), -0.9145619]
[2019-03-23 08:49:59,990] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.91666666666667, 82.0, 1.0, 2.0, 0.3922569689770138, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 443667.4889677838, 443667.4889677835, 129425.4434224279]
[2019-03-23 08:49:59,991] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 08:49:59,992] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.6468293e-29 1.0000000e+00 1.2393240e-36 3.7994872e-29 0.0000000e+00], sampled 0.41532555780368663
[2019-03-23 08:50:20,618] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.03391918], dtype=float32), -0.9145619]
[2019-03-23 08:50:20,619] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.4, 56.66666666666666, 1.0, 2.0, 0.4126817291381223, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 454354.987470312, 454354.9874703117, 125838.0691009759]
[2019-03-23 08:50:20,620] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 08:50:20,623] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.6468293e-29 1.0000000e+00 1.2393240e-36 3.7994872e-29 0.0000000e+00], sampled 0.4713795795051745
[2019-03-23 08:50:26,921] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.03391918], dtype=float32), -0.9145619]
[2019-03-23 08:50:26,922] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.0, 89.0, 1.0, 2.0, 0.6411453551456632, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 730393.6237119467, 730393.6237119467, 155731.1597524581]
[2019-03-23 08:50:26,925] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 08:50:26,929] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.6468293e-29 1.0000000e+00 1.2393240e-36 3.7994872e-29 0.0000000e+00], sampled 0.5709976366176047
[2019-03-23 08:50:28,046] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.03391918], dtype=float32), -0.9145619]
[2019-03-23 08:50:28,047] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.38455475666667, 69.78260606333333, 1.0, 2.0, 0.3539845648218434, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 389981.4535056236, 389981.4535056236, 121233.3076261378]
[2019-03-23 08:50:28,047] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 08:50:28,049] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.6468293e-29 1.0000000e+00 1.2393240e-36 3.7994872e-29 0.0000000e+00], sampled 0.7938329060068096
[2019-03-23 08:50:28,188] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.03391918], dtype=float32), -0.9145619]
[2019-03-23 08:50:28,190] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [28.0, 53.0, 1.0, 2.0, 0.5394621445075094, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9625212132478903, 6.925632693362449, 6.9112, 77.32840441907973, 1163855.307469378, 1159167.867442788, 261919.3791288894]
[2019-03-23 08:50:28,191] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 08:50:28,194] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [8.1092991e-27 1.0000000e+00 1.3421436e-33 1.7472292e-26 9.1892692e-38], sampled 0.7019930871353889
[2019-03-23 08:50:28,196] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1163855.307469378 W.
[2019-03-23 08:50:46,818] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.03391918], dtype=float32), -0.9145619]
[2019-03-23 08:50:46,819] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.42135859666667, 89.17204358000001, 1.0, 2.0, 0.3114454765636304, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 339666.0388933878, 339666.0388933874, 116797.0247066385]
[2019-03-23 08:50:46,820] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 08:50:46,824] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.6468293e-29 1.0000000e+00 1.2393240e-36 3.7994872e-29 0.0000000e+00], sampled 0.4208469549180721
[2019-03-23 08:51:03,086] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 08:51:03,563] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 08:51:03,565] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 08:51:03,632] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 08:51:03,652] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 08:51:04,665] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 325000, evaluation results [325000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 08:51:05,950] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.5184644e-29 1.0000000e+00 8.2342358e-35 7.8746497e-29 0.0000000e+00], sum to 1.0000
[2019-03-23 08:51:05,957] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9340
[2019-03-23 08:51:05,962] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.23333333333333, 59.0, 1.0, 2.0, 0.8352253745817846, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 945713.7774144367, 945713.7774144367, 178985.9032507522], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4270800.0000, 
sim time next is 4271400.0000, 
raw observation next is [24.35, 58.0, 1.0, 2.0, 0.8410400274532317, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 951894.872806061, 951894.872806061, 179614.3153521117], 
processed observation next is [1.0, 0.43478260869565216, 0.7431818181818183, 0.58, 1.0, 1.0, 0.8013000343165396, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3525536565948374, 0.3525536565948374, 0.43808369598076025], 
reward next is 0.5619, 
noisyNet noise sample is [array([-0.8441946], dtype=float32), -0.77580833]. 
=============================================
[2019-03-23 08:51:07,174] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.7735417e-20 5.0343507e-09 9.7571326e-25 1.0000000e+00 1.1953103e-30], sum to 1.0000
[2019-03-23 08:51:07,186] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0833
[2019-03-23 08:51:07,192] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.06666666666667, 48.66666666666666, 1.0, 2.0, 0.5149156770432581, 1.0, 2.0, 0.5149156770432581, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344281715, 1175782.084309859, 1175782.084309859, 228171.8860274049], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4286400.0000, 
sim time next is 4287000.0000, 
raw observation next is [27.08333333333334, 48.83333333333334, 1.0, 2.0, 0.5166933163480977, 1.0, 2.0, 0.5166933163480977, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344353656, 1179878.017079009, 1179878.017079009, 228794.8439322985], 
processed observation next is [1.0, 0.6086956521739131, 0.8674242424242427, 0.48833333333333345, 1.0, 1.0, 0.39586664543512207, 1.0, 1.0, 0.39586664543512207, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206247, 0.4369918581774107, 0.4369918581774107, 0.5580362047129231], 
reward next is 0.4420, 
noisyNet noise sample is [array([0.22235586], dtype=float32), -1.2231138]. 
=============================================
[2019-03-23 08:51:07,204] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[54.83985 ]
 [54.820618]
 [54.592365]
 [53.981094]
 [59.920517]], R is [[54.57290649]
 [54.47066116]
 [54.3693428 ]
 [53.82564926]
 [53.28739166]].
[2019-03-23 08:51:10,592] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.5356649e-21 1.0000000e+00 5.4532610e-28 1.2783366e-15 1.6579728e-31], sum to 1.0000
[2019-03-23 08:51:10,599] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3090
[2019-03-23 08:51:10,606] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.66666666666667, 90.33333333333334, 1.0, 2.0, 0.4008210139544156, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 452571.3610804717, 452571.3610804714, 125415.8076099842], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4346400.0000, 
sim time next is 4347000.0000, 
raw observation next is [20.0, 88.5, 1.0, 2.0, 0.4074401858708781, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 460515.8393843946, 460515.8393843949, 126293.9109314966], 
processed observation next is [1.0, 0.30434782608695654, 0.5454545454545454, 0.885, 1.0, 1.0, 0.2593002323385976, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17056142199422022, 0.17056142199422034, 0.30803392910121125], 
reward next is 0.6920, 
noisyNet noise sample is [array([2.050109], dtype=float32), 0.076171674]. 
=============================================
[2019-03-23 08:51:10,619] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[61.377575]
 [61.126244]
 [60.978275]
 [60.72824 ]
 [60.515686]], R is [[61.72519302]
 [61.80204773]
 [61.8788414 ]
 [61.9566803 ]
 [62.03538132]].
[2019-03-23 08:51:11,424] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.6778427e-25 1.0000000e+00 4.5272044e-31 4.7372186e-23 2.7584511e-34], sum to 1.0000
[2019-03-23 08:51:11,436] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3188
[2019-03-23 08:51:11,440] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.33333333333334, 57.0, 1.0, 2.0, 0.4778755108594978, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 545262.127360979, 545262.1273609793, 138799.9192051083], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4387200.0000, 
sim time next is 4387800.0000, 
raw observation next is [27.16666666666666, 57.5, 1.0, 2.0, 0.4769958480661154, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 544277.285079412, 544277.2850794124, 138578.4471764099], 
processed observation next is [1.0, 0.782608695652174, 0.871212121212121, 0.575, 1.0, 1.0, 0.3462448100826442, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2015841796590415, 0.20158417965904163, 0.33799621262539004], 
reward next is 0.6620, 
noisyNet noise sample is [array([1.2360193], dtype=float32), -0.660178]. 
=============================================
[2019-03-23 08:51:17,648] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.9685499e-27 1.0000000e+00 2.8268310e-33 4.7985112e-23 3.1092116e-37], sum to 1.0000
[2019-03-23 08:51:17,656] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5733
[2019-03-23 08:51:17,660] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.16666666666666, 93.0, 1.0, 2.0, 0.4704352814619768, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 536627.0455285223, 536627.0455285223, 136723.1388474938], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4485000.0000, 
sim time next is 4485600.0000, 
raw observation next is [21.0, 94.0, 1.0, 2.0, 0.4673550172585716, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 533070.0422720443, 533070.0422720443, 136287.7890894525], 
processed observation next is [0.0, 0.9565217391304348, 0.5909090909090909, 0.94, 1.0, 1.0, 0.33419377157321445, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19743334898964604, 0.19743334898964604, 0.33240924168159147], 
reward next is 0.6676, 
noisyNet noise sample is [array([1.3125241], dtype=float32), 1.2693083]. 
=============================================
[2019-03-23 08:51:23,317] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.8675257e-28 1.0000000e+00 5.6199937e-36 3.8853094e-26 0.0000000e+00], sum to 1.0000
[2019-03-23 08:51:23,324] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6759
[2019-03-23 08:51:23,330] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 82.00000000000001, 1.0, 2.0, 0.2760258367002675, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 299715.2641667186, 299715.2641667186, 95679.2523134933], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4576200.0000, 
sim time next is 4576800.0000, 
raw observation next is [17.0, 82.0, 1.0, 2.0, 0.2751450008708397, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 298758.538390411, 298758.5383904113, 95577.93758790479], 
processed observation next is [0.0, 1.0, 0.4090909090909091, 0.82, 1.0, 1.0, 0.09393125108854962, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11065131051496704, 0.11065131051496714, 0.23311692094610922], 
reward next is 0.7669, 
noisyNet noise sample is [array([-0.43763253], dtype=float32), -0.70328456]. 
=============================================
[2019-03-23 08:51:29,980] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.9136262e-23 1.0000000e+00 2.7856542e-30 5.8256904e-19 2.9857841e-34], sum to 1.0000
[2019-03-23 08:51:29,986] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2294
[2019-03-23 08:51:29,989] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.83333333333333, 69.66666666666667, 1.0, 2.0, 0.434665424523015, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 495061.3547424796, 495061.3547424796, 131735.225174072], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4734600.0000, 
sim time next is 4735200.0000, 
raw observation next is [23.66666666666666, 70.33333333333334, 1.0, 2.0, 0.434577377065234, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 494856.399180078, 494856.399180078, 131606.8745003503], 
processed observation next is [1.0, 0.8260869565217391, 0.7121212121212118, 0.7033333333333335, 1.0, 1.0, 0.2932217213315425, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18328014784447333, 0.18328014784447333, 0.32099237683012266], 
reward next is 0.6790, 
noisyNet noise sample is [array([-0.29941127], dtype=float32), -0.1930615]. 
=============================================
[2019-03-23 08:51:32,218] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.0124234e-25 1.0000000e+00 1.6796534e-33 1.5523028e-22 3.1143293e-36], sum to 1.0000
[2019-03-23 08:51:32,227] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8107
[2019-03-23 08:51:32,232] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 88.0, 1.0, 2.0, 0.4164245419857624, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 465663.3848090976, 465663.3848090976, 124630.8229082895], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4760400.0000, 
sim time next is 4761000.0000, 
raw observation next is [19.0, 88.0, 1.0, 2.0, 0.3913498612772036, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 437522.8580516707, 437522.8580516704, 122392.2566251646], 
processed observation next is [1.0, 0.08695652173913043, 0.5, 0.88, 1.0, 1.0, 0.2391873265965045, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16204550298210027, 0.16204550298210016, 0.2985176990857673], 
reward next is 0.7015, 
noisyNet noise sample is [array([-0.64743054], dtype=float32), -0.12398725]. 
=============================================
[2019-03-23 08:51:32,255] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[68.716866]
 [68.716866]
 [68.716866]
 [68.716866]
 [68.716866]], R is [[68.73119354]
 [68.73990631]
 [68.73699188]
 [68.75709534]
 [68.77703857]].
[2019-03-23 08:51:32,953] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.6653879e-25 1.0000000e+00 7.1530835e-32 3.0723637e-24 2.9621740e-35], sum to 1.0000
[2019-03-23 08:51:32,959] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6098
[2019-03-23 08:51:32,968] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.4151569748086471, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 470474.5270697248, 470474.5270697251, 127785.9610970276], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4777200.0000, 
sim time next is 4777800.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4091054418031276, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 463753.2567464196, 463753.2567464196, 127306.9307077955], 
processed observation next is [1.0, 0.30434782608695654, 0.5, 1.0, 1.0, 1.0, 0.26138180225390945, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1717604654616369, 0.1717604654616369, 0.31050470904340366], 
reward next is 0.6895, 
noisyNet noise sample is [array([-1.4785664], dtype=float32), -0.38528392]. 
=============================================
[2019-03-23 08:51:40,423] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.3709078e-27 1.0000000e+00 1.7215592e-33 2.3319951e-25 2.3629103e-37], sum to 1.0000
[2019-03-23 08:51:40,431] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3402
[2019-03-23 08:51:40,440] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.3761778726220805, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 422318.968476457, 422318.968476457, 121925.8712279834], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4929000.0000, 
sim time next is 4929600.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.3746872933688968, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 420634.8369124052, 420634.8369124052, 121793.4445544095], 
processed observation next is [1.0, 0.043478260869565216, 0.45454545454545453, 1.0, 1.0, 1.0, 0.21835911671112096, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15579068033792787, 0.15579068033792787, 0.29705718184002317], 
reward next is 0.7029, 
noisyNet noise sample is [array([0.4970694], dtype=float32), -0.090458006]. 
=============================================
[2019-03-23 08:51:46,730] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.7615950e-25 1.0000000e+00 1.2173005e-31 2.5591752e-24 1.2198268e-35], sum to 1.0000
[2019-03-23 08:51:46,738] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4288
[2019-03-23 08:51:46,741] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 51.0, 1.0, 2.0, 0.4187490937621848, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 476454.3068576397, 476454.3068576397, 129633.8001365648], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5073000.0000, 
sim time next is 5073600.0000, 
raw observation next is [27.0, 51.00000000000001, 1.0, 2.0, 0.4193318365532141, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 477119.4520995736, 477119.4520995733, 129692.946999538], 
processed observation next is [0.0, 0.7391304347826086, 0.8636363636363636, 0.5100000000000001, 1.0, 1.0, 0.2741647956915176, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17671090818502727, 0.17671090818502713, 0.31632426097448296], 
reward next is 0.6837, 
noisyNet noise sample is [array([1.1545794], dtype=float32), 1.0205047]. 
=============================================
[2019-03-23 08:51:48,556] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.8553699e-25 1.0000000e+00 8.3344299e-31 1.8236760e-20 2.8469693e-34], sum to 1.0000
[2019-03-23 08:51:48,564] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0683
[2019-03-23 08:51:48,571] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 67.66666666666667, 1.0, 2.0, 0.4241659979180609, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 482708.1458490968, 482708.1458490971, 130255.8048657175], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5085600.0000, 
sim time next is 5086200.0000, 
raw observation next is [24.0, 68.33333333333333, 1.0, 2.0, 0.4278296938774243, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 487093.8014950059, 487093.8014950059, 130843.3475600804], 
processed observation next is [0.0, 0.8695652173913043, 0.7272727272727273, 0.6833333333333332, 1.0, 1.0, 0.28478711734678036, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18040511166481701, 0.18040511166481701, 0.3191301160001961], 
reward next is 0.6809, 
noisyNet noise sample is [array([-1.263564], dtype=float32), -1.3179096]. 
=============================================
[2019-03-23 08:51:50,952] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.5207836e-24 1.0000000e+00 2.5330794e-30 1.0350240e-21 9.2110773e-35], sum to 1.0000
[2019-03-23 08:51:50,961] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3102
[2019-03-23 08:51:50,967] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.83333333333334, 78.83333333333333, 1.0, 2.0, 0.4432790299317216, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 505397.1223963806, 505397.1223963806, 133333.4328197665], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5129400.0000, 
sim time next is 5130000.0000, 
raw observation next is [23.0, 78.0, 1.0, 2.0, 0.4447441189722908, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 507124.8563272175, 507124.8563272175, 133585.4404401843], 
processed observation next is [0.0, 0.391304347826087, 0.6818181818181818, 0.78, 1.0, 1.0, 0.3059301487153635, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1878240208619324, 0.1878240208619324, 0.32581814741508364], 
reward next is 0.6742, 
noisyNet noise sample is [array([0.08570955], dtype=float32), 0.8256537]. 
=============================================
[2019-03-23 08:51:50,995] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[65.04577]
 [65.04577]
 [65.04577]
 [65.04577]
 [65.04577]], R is [[65.06948853]
 [65.09358978]
 [65.11792755]
 [65.14241028]
 [65.16725922]].
[2019-03-23 08:51:51,706] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.3270248e-25 1.0000000e+00 9.4557136e-32 7.5204900e-23 1.5438132e-34], sum to 1.0000
[2019-03-23 08:51:51,715] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8999
[2019-03-23 08:51:51,722] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 74.33333333333334, 1.0, 2.0, 0.5397521875720822, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 612308.046105989, 612308.046105989, 149165.4068497861], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5143200.0000, 
sim time next is 5143800.0000, 
raw observation next is [26.5, 72.16666666666667, 1.0, 2.0, 0.5467427257452638, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 619606.4852466645, 619606.4852466645, 150305.0095672178], 
processed observation next is [0.0, 0.5217391304347826, 0.8409090909090909, 0.7216666666666667, 1.0, 1.0, 0.43342840718157977, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22948388342469056, 0.22948388342469056, 0.3665975843102873], 
reward next is 0.6334, 
noisyNet noise sample is [array([-0.6639587], dtype=float32), -0.95583886]. 
=============================================
[2019-03-23 08:51:52,191] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.2760650e-24 1.0000000e+00 1.2129815e-29 1.6987824e-21 9.0081135e-34], sum to 1.0000
[2019-03-23 08:51:52,201] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6288
[2019-03-23 08:51:52,204] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.9, 83.16666666666667, 1.0, 2.0, 0.4777057583214486, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 545100.3667018691, 545100.3667018691, 138521.6781298743], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5177400.0000, 
sim time next is 5178000.0000, 
raw observation next is [22.8, 83.33333333333334, 1.0, 2.0, 0.4748597400632896, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 541854.0985607877, 541854.0985607874, 138048.0076412174], 
processed observation next is [0.0, 0.9565217391304348, 0.6727272727272727, 0.8333333333333335, 1.0, 1.0, 0.343574675079112, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20068670317066212, 0.200686703170662, 0.33670245766150586], 
reward next is 0.6633, 
noisyNet noise sample is [array([0.25939146], dtype=float32), 0.81151056]. 
=============================================
[2019-03-23 08:51:52,227] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[66.698166]
 [66.698166]
 [66.698166]
 [66.698166]
 [66.698166]], R is [[66.69448853]
 [66.68968201]
 [66.68423462]
 [66.67901611]
 [66.67403412]].
[2019-03-23 08:51:52,427] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-23 08:51:52,428] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 08:51:52,429] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:51:52,429] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 08:51:52,430] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 08:51:52,430] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:51:52,431] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 08:51:52,431] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:51:52,432] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:51:52,432] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 08:51:52,435] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:51:52,450] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run15
[2019-03-23 08:51:52,451] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run15
[2019-03-23 08:51:52,497] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run15
[2019-03-23 08:51:52,498] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run15
[2019-03-23 08:51:52,522] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run15
[2019-03-23 08:51:58,321] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.03391918], dtype=float32), -0.9024448]
[2019-03-23 08:51:58,322] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.45421068333334, 63.57171835, 1.0, 2.0, 0.2192936564190387, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 238087.9523789055, 238087.9523789051, 78598.83914202388]
[2019-03-23 08:51:58,324] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 08:51:58,327] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.9289964e-25 1.0000000e+00 8.8030092e-32 2.5263141e-23 6.4140242e-36], sampled 0.8836253458797697
[2019-03-23 08:51:58,485] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.03391918], dtype=float32), -0.9024448]
[2019-03-23 08:51:58,486] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [13.66666666666667, 80.66666666666667, 1.0, 2.0, 0.2018390999985799, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 219134.0201239366, 219134.0201239362, 75388.01350282897]
[2019-03-23 08:51:58,487] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 08:51:58,489] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.9289964e-25 1.0000000e+00 8.8030092e-32 2.5263141e-23 6.4140242e-36], sampled 0.7775462971232271
[2019-03-23 08:52:13,914] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.03391918], dtype=float32), -0.9024448]
[2019-03-23 08:52:13,915] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.0, 46.5, 1.0, 2.0, 0.31112890128825, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 337844.2266906119, 337844.2266906119, 108351.7397812876]
[2019-03-23 08:52:13,917] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 08:52:13,919] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.9289964e-25 1.0000000e+00 8.8030092e-32 2.5263141e-23 6.4140242e-36], sampled 0.07747544218256797
[2019-03-23 08:52:17,947] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.03391918], dtype=float32), -0.9024448]
[2019-03-23 08:52:17,950] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [15.81666666666667, 51.83333333333333, 1.0, 2.0, 0.2242883541686819, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 243511.8130744871, 243511.8130744871, 75650.4607028925]
[2019-03-23 08:52:17,954] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 08:52:17,957] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.9289964e-25 1.0000000e+00 8.8030092e-32 2.5263141e-23 6.4140242e-36], sampled 0.08354854955161117
[2019-03-23 08:52:43,903] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.03391918], dtype=float32), -0.9024448]
[2019-03-23 08:52:43,905] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.11017805, 91.51761679, 1.0, 2.0, 0.3521559900364916, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 391450.4790132452, 391450.4790132448, 122462.7083100007]
[2019-03-23 08:52:43,907] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 08:52:43,911] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.9289964e-25 1.0000000e+00 8.8030092e-32 2.5263141e-23 6.4140242e-36], sampled 0.4361779673095211
[2019-03-23 08:52:53,852] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.03391918], dtype=float32), -0.9024448]
[2019-03-23 08:52:53,853] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.13843852666667, 75.75953324000001, 1.0, 2.0, 0.365078508461831, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 405423.8216473574, 405423.8216473574, 123335.9973854293]
[2019-03-23 08:52:53,855] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 08:52:53,857] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.9289964e-25 1.0000000e+00 8.8030092e-32 2.5263141e-23 6.4140242e-36], sampled 0.8988462514427464
[2019-03-23 08:53:00,224] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.03391918], dtype=float32), -0.9024448]
[2019-03-23 08:53:00,225] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.63333333333333, 58.0, 1.0, 2.0, 0.3712257098113922, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 416239.4332584191, 416239.4332584191, 125575.5435997858]
[2019-03-23 08:53:00,226] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 08:53:00,230] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.9289964e-25 1.0000000e+00 8.8030092e-32 2.5263141e-23 6.4140242e-36], sampled 0.6771950551536773
[2019-03-23 08:53:04,852] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.03391918], dtype=float32), -0.9024448]
[2019-03-23 08:53:04,855] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [17.03097969666667, 56.88444562666666, 1.0, 2.0, 0.2152780899463948, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 233727.3890403282, 233727.3890403282, 77410.0826104755]
[2019-03-23 08:53:04,856] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 08:53:04,859] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.9289964e-25 1.0000000e+00 8.8030092e-32 2.5263141e-23 6.4140242e-36], sampled 0.0989540140447217
[2019-03-23 08:53:10,108] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.03391918], dtype=float32), -0.9024448]
[2019-03-23 08:53:10,112] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [16.8, 69.0, 1.0, 2.0, 0.3477030487469324, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 377546.3046972214, 377546.3046972218, 95074.4450875461]
[2019-03-23 08:53:10,112] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 08:53:10,114] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.9289964e-25 1.0000000e+00 8.8030092e-32 2.5263141e-23 6.4140242e-36], sampled 0.7348305399697254
[2019-03-23 08:53:12,201] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.03391918], dtype=float32), -0.9024448]
[2019-03-23 08:53:12,202] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.03333333333333, 88.66666666666666, 1.0, 2.0, 0.3794628676887502, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 424771.7095000296, 424771.7095000296, 125946.7926988812]
[2019-03-23 08:53:12,204] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 08:53:12,208] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.9289964e-25 1.0000000e+00 8.8030092e-32 2.5263141e-23 6.4140242e-36], sampled 0.4560639542607554
[2019-03-23 08:53:18,134] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.03391918], dtype=float32), -0.9024448]
[2019-03-23 08:53:18,135] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.00817616666667, 85.09033894000001, 1.0, 2.0, 0.5179033777471552, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 577204.9085194486, 577204.9085194482, 137861.4721387214]
[2019-03-23 08:53:18,136] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 08:53:18,138] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.9289964e-25 1.0000000e+00 8.8030092e-32 2.5263141e-23 6.4140242e-36], sampled 0.3228064921633541
[2019-03-23 08:53:27,638] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.03391918], dtype=float32), -0.9024448]
[2019-03-23 08:53:27,639] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.16637465, 93.73573000333334, 1.0, 2.0, 0.2895990428000614, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 314438.7428779536, 314438.7428779539, 108821.790793652]
[2019-03-23 08:53:27,640] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 08:53:27,643] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.9289964e-25 1.0000000e+00 8.8030092e-32 2.5263141e-23 6.4140242e-36], sampled 0.990702291336251
[2019-03-23 08:53:34,128] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 08:53:34,359] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 08:53:34,473] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 08:53:34,481] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 08:53:34,712] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 08:53:35,729] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 350000, evaluation results [350000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 08:53:39,517] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.6526677e-22 1.0000000e+00 1.5451495e-28 6.6216997e-19 1.2083119e-30], sum to 1.0000
[2019-03-23 08:53:39,527] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8089
[2019-03-23 08:53:39,529] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.6249150211595628, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846338128175, 712216.8883571642, 712216.8883571642, 158568.5732668275], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5229000.0000, 
sim time next is 5229600.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.6899946006261096, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344315566, 786958.2313845264, 786958.2313845267, 167182.0625068035], 
processed observation next is [1.0, 0.5217391304347826, 0.6363636363636364, 0.94, 1.0, 1.0, 0.6124932507826369, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129181203, 0.2914660116238986, 0.2914660116238988, 0.40776112806537435], 
reward next is 0.5922, 
noisyNet noise sample is [array([2.0607233], dtype=float32), 1.1911311]. 
=============================================
[2019-03-23 08:53:45,172] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.4227329e-24 1.0000000e+00 2.9270667e-31 9.4015735e-19 2.0309703e-33], sum to 1.0000
[2019-03-23 08:53:45,182] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1382
[2019-03-23 08:53:45,189] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.55, 58.0, 1.0, 2.0, 0.4266002193183771, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 485204.5014636535, 485204.5014636535, 130234.9462516586], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5347800.0000, 
sim time next is 5348400.0000, 
raw observation next is [25.36666666666667, 59.33333333333333, 1.0, 2.0, 0.4313867724052046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 490794.466430725, 490794.4664307253, 130845.4727944333], 
processed observation next is [1.0, 0.9130434782608695, 0.7893939393939395, 0.5933333333333333, 1.0, 1.0, 0.28923346550650575, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18177572830767594, 0.18177572830767605, 0.3191352994986178], 
reward next is 0.6809, 
noisyNet noise sample is [array([0.33199087], dtype=float32), -0.37112218]. 
=============================================
[2019-03-23 08:53:53,758] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.9553464e-27 1.0000000e+00 3.0471135e-34 3.8379834e-24 1.8050698e-37], sum to 1.0000
[2019-03-23 08:53:53,766] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2720
[2019-03-23 08:53:53,769] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.8, 78.5, 1.0, 2.0, 0.4547942372309273, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 518453.9242039738, 518453.9242039738, 134414.4901365256], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5525400.0000, 
sim time next is 5526000.0000, 
raw observation next is [22.7, 79.0, 1.0, 2.0, 0.4558791881559908, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 519652.1754336376, 519652.1754336376, 134469.0918500514], 
processed observation next is [1.0, 1.0, 0.6681818181818181, 0.79, 1.0, 1.0, 0.3198489851949885, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19246376867912504, 0.19246376867912504, 0.3279733947562229], 
reward next is 0.6720, 
noisyNet noise sample is [array([-0.3992027], dtype=float32), -1.6404324]. 
=============================================
[2019-03-23 08:53:53,782] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[68.53045]
 [68.53045]
 [68.53045]
 [68.53045]
 [68.53045]], R is [[68.51717377]
 [68.50415802]
 [68.49125671]
 [68.4781189 ]
 [68.46452332]].
[2019-03-23 08:54:02,360] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.8801732e-28 1.0000000e+00 1.3521927e-37 1.3855474e-23 0.0000000e+00], sum to 1.0000
[2019-03-23 08:54:02,366] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0186
[2019-03-23 08:54:02,369] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.26666666666667, 71.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 198435.6148300456, 198435.6148300456, 65828.42963475618], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5692800.0000, 
sim time next is 5693400.0000, 
raw observation next is [13.0, 73.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 194913.877056291, 194913.8770562907, 65137.40955979777], 
processed observation next is [0.0, 0.9130434782608695, 0.22727272727272727, 0.73, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07219032483566333, 0.07219032483566322, 0.1588717306336531], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.97190386], dtype=float32), -0.09317783]. 
=============================================
[2019-03-23 08:54:06,477] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.8200989e-26 1.0000000e+00 2.3720782e-36 1.0385072e-23 0.0000000e+00], sum to 1.0000
[2019-03-23 08:54:06,483] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6348
[2019-03-23 08:54:06,488] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.78333333333333, 43.33333333333334, 1.0, 2.0, 0.2737883277812601, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 297284.9824468756, 297284.9824468759, 86756.40332568494], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5766600.0000, 
sim time next is 5767200.0000, 
raw observation next is [21.6, 44.0, 1.0, 2.0, 0.2717887232765432, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 295113.1120957817, 295113.1120957817, 86272.35408356365], 
processed observation next is [0.0, 0.782608695652174, 0.6181818181818183, 0.44, 1.0, 1.0, 0.08973590409567897, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1093011526280673, 0.1093011526280673, 0.21042037581356987], 
reward next is 0.7896, 
noisyNet noise sample is [array([-0.04169863], dtype=float32), -1.9884267]. 
=============================================
[2019-03-23 08:54:14,602] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.08015596e-10 5.22678792e-01 1.48765042e-15 4.77321237e-01
 3.06961246e-16], sum to 1.0000
[2019-03-23 08:54:14,607] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0354
[2019-03-23 08:54:14,613] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1096586.476681265 W.
[2019-03-23 08:54:14,618] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.7, 46.0, 1.0, 2.0, 0.4812698650173209, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9338127774668403, 6.962035769393092, 6.9112, 77.32831636444959, 1096586.476681265, 1080076.089956576, 243577.2131896759], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5932800.0000, 
sim time next is 5933400.0000, 
raw observation next is [27.61666666666667, 46.16666666666667, 1.0, 2.0, 0.3449353557910179, 1.0, 1.0, 0.3449353557910179, 1.0, 2.0, 0.6947746506938083, 6.911199999999999, 6.9112, 77.3421103, 1181456.746920599, 1181456.746920599, 268274.1039448862], 
processed observation next is [1.0, 0.6956521739130435, 0.8916666666666668, 0.4616666666666667, 1.0, 1.0, 0.18116919473877238, 1.0, 0.5, 0.18116919473877238, 1.0, 1.0, 0.5639637867054405, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.4375765729335552, 0.4375765729335552, 0.6543270827924054], 
reward next is 0.3457, 
noisyNet noise sample is [array([0.04910959], dtype=float32), -0.11455326]. 
=============================================
[2019-03-23 08:54:19,923] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.3809124e-25 1.0000000e+00 1.2275101e-35 3.9061458e-18 5.3347410e-37], sum to 1.0000
[2019-03-23 08:54:19,930] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7230
[2019-03-23 08:54:19,936] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.45, 77.5, 1.0, 2.0, 0.2741875837665258, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 297718.6354806091, 297718.6354806094, 94223.52150847187], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6046200.0000, 
sim time next is 6046800.0000, 
raw observation next is [17.36666666666667, 78.33333333333333, 1.0, 2.0, 0.2750171712288932, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 298619.6955191426, 298619.6955191426, 94540.1360560606], 
processed observation next is [1.0, 1.0, 0.42575757575757595, 0.7833333333333333, 1.0, 1.0, 0.09377146403611647, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11059988722931208, 0.11059988722931208, 0.23058569769770879], 
reward next is 0.7694, 
noisyNet noise sample is [array([-3.199494], dtype=float32), -0.7021487]. 
=============================================
[2019-03-23 08:54:22,115] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.1605184e-26 1.0000000e+00 1.2241567e-36 3.5231248e-18 0.0000000e+00], sum to 1.0000
[2019-03-23 08:54:22,121] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7503
[2019-03-23 08:54:22,126] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.73333333333333, 56.0, 1.0, 2.0, 0.5341706514943143, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 580182.1446116333, 580182.1446116333, 124006.8917778977], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6090000.0000, 
sim time next is 6090600.0000, 
raw observation next is [20.91666666666667, 55.5, 1.0, 2.0, 0.5271158934589044, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 572515.2029371652, 572515.2029371648, 124113.1219107649], 
processed observation next is [1.0, 0.4782608695652174, 0.5871212121212124, 0.555, 1.0, 1.0, 0.40889486682363047, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21204266775450561, 0.21204266775450548, 0.3027149314896705], 
reward next is 0.6973, 
noisyNet noise sample is [array([-0.26924995], dtype=float32), -0.19820748]. 
=============================================
[2019-03-23 08:54:23,671] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-23 08:54:23,675] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 08:54:23,676] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:54:23,677] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 08:54:23,678] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 08:54:23,679] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 08:54:23,679] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 08:54:23,679] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:54:23,681] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:54:23,681] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:54:23,684] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:54:23,693] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run16
[2019-03-23 08:54:23,693] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run16
[2019-03-23 08:54:23,747] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run16
[2019-03-23 08:54:23,772] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run16
[2019-03-23 08:54:23,794] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run16
[2019-03-23 08:54:30,996] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02404556], dtype=float32), -0.9436335]
[2019-03-23 08:54:30,997] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.83333333333334, 64.0, 1.0, 2.0, 0.665265001974441, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 740635.1209281655, 740635.1209281655, 149382.8284909505]
[2019-03-23 08:54:31,000] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 08:54:31,005] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.3782618e-25 1.0000000e+00 6.2683879e-35 8.9481100e-19 1.4213086e-37], sampled 0.8175313703455164
[2019-03-23 08:54:39,604] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02404556], dtype=float32), -0.9436335]
[2019-03-23 08:54:39,605] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.0, 93.00000000000001, 1.0, 2.0, 0.5074204172716779, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 578789.6671576203, 578789.6671576203, 142773.5759532696]
[2019-03-23 08:54:39,606] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 08:54:39,608] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.3782618e-25 1.0000000e+00 6.2683879e-35 8.9481100e-19 1.4213086e-37], sampled 0.9788593045835905
[2019-03-23 08:54:43,956] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02404556], dtype=float32), -0.9436335]
[2019-03-23 08:54:43,957] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [16.33333333333334, 50.00000000000001, 1.0, 2.0, 0.3633358805096629, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 394556.9981716874, 394556.9981716874, 84854.62031386772]
[2019-03-23 08:54:43,958] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 08:54:43,960] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.3782618e-25 1.0000000e+00 6.2683879e-35 8.9481100e-19 1.4213086e-37], sampled 0.4837471139861218
[2019-03-23 08:54:55,357] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02404556], dtype=float32), -0.9436335]
[2019-03-23 08:54:55,359] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.189754595, 86.621864045, 1.0, 2.0, 0.2650365979269155, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 287763.1255387564, 287763.125538756, 95745.46291992055]
[2019-03-23 08:54:55,360] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 08:54:55,364] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.3782618e-25 1.0000000e+00 6.2683879e-35 8.9481100e-19 1.4213086e-37], sampled 0.285027608958799
[2019-03-23 08:55:05,503] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02404556], dtype=float32), -0.9436335]
[2019-03-23 08:55:05,503] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.3, 90.0, 1.0, 2.0, 0.3473458566536711, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 385609.6461897328, 385609.6461897324, 121879.7703638594]
[2019-03-23 08:55:05,505] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 08:55:05,510] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.3782618e-25 1.0000000e+00 6.2683879e-35 8.9481100e-19 1.4213086e-37], sampled 0.3255556357954211
[2019-03-23 08:55:18,852] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02404556], dtype=float32), -0.9436335]
[2019-03-23 08:55:18,856] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.36666666666667, 87.5, 1.0, 2.0, 0.4961064510403251, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 566032.6555563826, 566032.6555563826, 145057.3973370795]
[2019-03-23 08:55:18,858] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 08:55:18,859] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.3782618e-25 1.0000000e+00 6.2683879e-35 8.9481100e-19 1.4213086e-37], sampled 0.5266197053125924
[2019-03-23 08:55:44,404] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02404556], dtype=float32), -0.9436335]
[2019-03-23 08:55:44,405] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [27.36666666666667, 67.66666666666667, 1.0, 2.0, 0.5630366839088845, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 637517.8861412596, 637517.8861412593, 152618.1391463163]
[2019-03-23 08:55:44,407] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 08:55:44,411] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.3782618e-25 1.0000000e+00 6.2683879e-35 8.9481100e-19 1.4213086e-37], sampled 0.6608403766088665
[2019-03-23 08:56:05,338] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9069.3463 1656245786.1505 45.0000
[2019-03-23 08:56:05,355] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8514.7929 1759898999.4060 122.0000
[2019-03-23 08:56:05,469] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8654.6242 1700657906.9748 264.0000
[2019-03-23 08:56:05,573] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8869.1733 1662931406.4241 57.0000
[2019-03-23 08:56:05,924] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8597.4497 1680572701.0612 132.0000
[2019-03-23 08:56:06,938] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 375000, evaluation results [375000.0, 8514.792927674067, 1759898999.4060256, 122.0, 9069.346257942878, 1656245786.1504614, 45.0, 8869.17331915851, 1662931406.4240904, 57.0, 8654.624156065129, 1700657906.974842, 264.0, 8597.449705623038, 1680572701.0611653, 132.0]
[2019-03-23 08:56:08,604] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.3946869e-25 1.0000000e+00 1.1566459e-35 5.5007577e-18 7.7839703e-38], sum to 1.0000
[2019-03-23 08:56:08,608] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0398
[2019-03-23 08:56:08,612] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.9, 64.66666666666667, 1.0, 2.0, 0.2673811894515012, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 290325.9036627324, 290325.9036627327, 90779.46101549163], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6126600.0000, 
sim time next is 6127200.0000, 
raw observation next is [18.8, 65.0, 1.0, 2.0, 0.2659979321420624, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 288823.4992569625, 288823.4992569622, 90186.4701479191], 
processed observation next is [1.0, 0.9565217391304348, 0.49090909090909096, 0.65, 1.0, 1.0, 0.082497415177578, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10697166639146759, 0.10697166639146749, 0.2199670003607783], 
reward next is 0.7800, 
noisyNet noise sample is [array([-0.026504], dtype=float32), 0.7404967]. 
=============================================
[2019-03-23 08:56:09,838] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.7506996e-24 1.0000000e+00 2.0881558e-32 5.6710858e-18 2.7806769e-36], sum to 1.0000
[2019-03-23 08:56:09,847] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6098
[2019-03-23 08:56:09,850] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.06666666666667, 74.33333333333333, 1.0, 2.0, 0.755864713444824, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 849996.7865096417, 849996.7865096413, 164303.3037164623], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6176400.0000, 
sim time next is 6177000.0000, 
raw observation next is [21.33333333333334, 72.66666666666667, 1.0, 2.0, 0.7366118891635176, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 828456.4476456903, 828456.4476456903, 161776.5093726113], 
processed observation next is [1.0, 0.4782608695652174, 0.6060606060606063, 0.7266666666666667, 1.0, 1.0, 0.6707648614543971, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.30683572135025566, 0.30683572135025566, 0.3945768521283202], 
reward next is 0.6054, 
noisyNet noise sample is [array([-0.8373272], dtype=float32), -1.2634876]. 
=============================================
[2019-03-23 08:56:09,865] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[66.66346]
 [66.66346]
 [66.66346]
 [66.66346]
 [66.66346]], R is [[66.60224915]
 [66.53548431]
 [66.45589447]
 [66.37779236]
 [66.30395508]].
[2019-03-23 08:56:10,415] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.3024650e-24 1.0000000e+00 2.1189762e-33 6.1364123e-21 7.4130875e-36], sum to 1.0000
[2019-03-23 08:56:10,424] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8612
[2019-03-23 08:56:10,428] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.45, 68.5, 1.0, 2.0, 0.6931875519677987, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 782860.1027157068, 782860.1027157065, 157781.0427956097], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6183000.0000, 
sim time next is 6183600.0000, 
raw observation next is [22.53333333333333, 67.66666666666667, 1.0, 2.0, 0.6888310726037716, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 777765.215818324, 777765.215818324, 157121.8637440945], 
processed observation next is [1.0, 0.5652173913043478, 0.6606060606060605, 0.6766666666666667, 1.0, 1.0, 0.6110388407547145, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2880611910438237, 0.2880611910438237, 0.38322405791242564], 
reward next is 0.6168, 
noisyNet noise sample is [array([-0.18496367], dtype=float32), 0.2525115]. 
=============================================
[2019-03-23 08:56:10,430] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.3887909e-22 1.0000000e+00 1.0132255e-28 6.3337700e-19 3.2249593e-32], sum to 1.0000
[2019-03-23 08:56:10,437] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0663
[2019-03-23 08:56:10,443] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.3, 60.0, 1.0, 2.0, 0.7907690574075777, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 889596.4403636695, 889596.4403636693, 169272.0546560945], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6188400.0000, 
sim time next is 6189000.0000, 
raw observation next is [23.2, 60.66666666666666, 1.0, 2.0, 0.8480711552539869, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 954207.6555969612, 954207.6555969614, 177579.8105158625], 
processed observation next is [1.0, 0.6521739130434783, 0.6909090909090909, 0.6066666666666666, 1.0, 1.0, 0.8100889440674836, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3534102428136893, 0.3534102428136894, 0.4331214890630793], 
reward next is 0.5669, 
noisyNet noise sample is [array([-0.66382974], dtype=float32), -0.80554616]. 
=============================================
[2019-03-23 08:56:10,462] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[63.377026]
 [63.377026]
 [63.377026]
 [63.377026]
 [63.377026]], R is [[63.31013107]
 [63.2641716 ]
 [63.21702957]
 [63.16820526]
 [63.11933899]].
[2019-03-23 08:56:17,999] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.0523021e-21 1.0000000e+00 5.5031408e-29 1.7343990e-19 2.5428164e-32], sum to 1.0000
[2019-03-23 08:56:18,006] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8735
[2019-03-23 08:56:18,009] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.9, 78.50000000000001, 1.0, 2.0, 0.4874196832406256, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 556056.0363623926, 556056.0363623928, 140237.6118541698], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6307800.0000, 
sim time next is 6308400.0000, 
raw observation next is [24.0, 78.0, 1.0, 2.0, 0.4882785596330397, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 557016.0738884703, 557016.0738884703, 140387.1176346351], 
processed observation next is [0.0, 0.0, 0.7272727272727273, 0.78, 1.0, 1.0, 0.36034819954129954, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20630224958832233, 0.20630224958832233, 0.3424076039869149], 
reward next is 0.6576, 
noisyNet noise sample is [array([0.31045875], dtype=float32), -0.48813063]. 
=============================================
[2019-03-23 08:56:22,378] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.9620288e-24 1.0000000e+00 2.5850285e-32 2.1346355e-17 4.2562681e-34], sum to 1.0000
[2019-03-23 08:56:22,384] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7728
[2019-03-23 08:56:22,389] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.4, 74.0, 1.0, 2.0, 0.4862861872565398, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 554857.0319315863, 554857.0319315863, 139786.643496403], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6422400.0000, 
sim time next is 6423000.0000, 
raw observation next is [23.93333333333333, 76.83333333333334, 1.0, 2.0, 0.5371093847793537, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 612893.0468344424, 612893.0468344424, 145706.0724052248], 
processed observation next is [1.0, 0.34782608695652173, 0.7242424242424241, 0.7683333333333334, 1.0, 1.0, 0.42138673097419205, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22699742475349718, 0.22699742475349718, 0.3553806644029873], 
reward next is 0.6446, 
noisyNet noise sample is [array([-0.6258698], dtype=float32), -1.0941446]. 
=============================================
[2019-03-23 08:56:22,408] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[63.21863]
 [63.21863]
 [63.21863]
 [63.21863]
 [63.21863]], R is [[63.23106766]
 [63.25781631]
 [63.28382111]
 [63.30368042]
 [63.31212616]].
[2019-03-23 08:56:22,804] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.6886589e-25 1.0000000e+00 6.3536861e-34 6.6836658e-21 4.3397994e-35], sum to 1.0000
[2019-03-23 08:56:22,814] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8956
[2019-03-23 08:56:22,819] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.9, 69.0, 1.0, 2.0, 0.5483562568534754, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 625771.7424893153, 625771.7424893156, 146554.1580502051], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6407400.0000, 
sim time next is 6408000.0000, 
raw observation next is [25.0, 68.0, 1.0, 2.0, 0.5364562278542477, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 612171.8599876841, 612171.8599876844, 144966.6983844604], 
processed observation next is [1.0, 0.17391304347826086, 0.7727272727272727, 0.68, 1.0, 1.0, 0.4205702848178096, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22673031851395706, 0.2267303185139572, 0.35357731313283025], 
reward next is 0.6464, 
noisyNet noise sample is [array([-0.31881803], dtype=float32), 0.3946904]. 
=============================================
[2019-03-23 08:56:22,838] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[63.14482]
 [63.14482]
 [63.14482]
 [63.14482]
 [63.14482]], R is [[63.15980148]
 [63.17075729]
 [63.17970657]
 [63.18701553]
 [63.18710327]].
[2019-03-23 08:56:29,258] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.0351251e-25 1.0000000e+00 4.3520672e-35 6.2257340e-19 4.9989406e-38], sum to 1.0000
[2019-03-23 08:56:29,268] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3346
[2019-03-23 08:56:29,272] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 51.0, 1.0, 2.0, 0.4532876499776428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 492287.6941906651, 492287.6941906651, 106779.5530718124], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6534600.0000, 
sim time next is 6535200.0000, 
raw observation next is [20.5, 51.00000000000001, 1.0, 2.0, 0.4515697544751163, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 490421.0530130503, 490421.0530130503, 106648.6816045663], 
processed observation next is [1.0, 0.6521739130434783, 0.5681818181818182, 0.5100000000000001, 1.0, 1.0, 0.3144621930938954, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18163742704187047, 0.18163742704187047, 0.26011873562089344], 
reward next is 0.7399, 
noisyNet noise sample is [array([0.09386896], dtype=float32), 0.5831381]. 
=============================================
[2019-03-23 08:56:29,683] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.94578480e-27 1.00000000e+00 2.13147294e-37 1.22775645e-23
 1.79101498e-38], sum to 1.0000
[2019-03-23 08:56:29,691] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7118
[2019-03-23 08:56:29,695] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.8, 51.0, 1.0, 2.0, 0.2902056307672351, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 315117.002150027, 315117.002150027, 91297.75034734921], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6543000.0000, 
sim time next is 6543600.0000, 
raw observation next is [20.53333333333333, 52.0, 1.0, 2.0, 0.2885284688965992, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 313295.2854010819, 313295.2854010822, 90397.7689778491], 
processed observation next is [1.0, 0.7391304347826086, 0.5696969696969696, 0.52, 1.0, 1.0, 0.11066058612074901, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11603529088928959, 0.1160352908892897, 0.22048236336060756], 
reward next is 0.7795, 
noisyNet noise sample is [array([0.6044275], dtype=float32), -1.1345347]. 
=============================================
[2019-03-23 08:56:37,354] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.2557361e-24 1.0000000e+00 8.0965083e-33 5.2936324e-21 4.1291539e-36], sum to 1.0000
[2019-03-23 08:56:37,362] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8550
[2019-03-23 08:56:37,366] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.3, 93.0, 1.0, 2.0, 0.6012417502322084, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 672059.046949921, 672059.046949921, 143141.0826568769], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6701400.0000, 
sim time next is 6702000.0000, 
raw observation next is [18.3, 93.0, 1.0, 2.0, 0.5761875217235752, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 644133.031352826, 644133.0313528263, 140400.7630109389], 
processed observation next is [1.0, 0.5652173913043478, 0.4681818181818182, 0.93, 1.0, 1.0, 0.470234402154469, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.23856778938993556, 0.23856778938993567, 0.3424408853925339], 
reward next is 0.6576, 
noisyNet noise sample is [array([0.48481816], dtype=float32), 0.3568694]. 
=============================================
[2019-03-23 08:56:37,393] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[66.12552]
 [66.12552]
 [66.12552]
 [66.12552]
 [66.12552]], R is [[66.1218338 ]
 [66.11149597]
 [66.12152863]
 [66.15326691]
 [66.17482758]].
[2019-03-23 08:56:40,453] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.2988552e-27 1.0000000e+00 1.2465648e-35 1.5132530e-21 1.4252286e-37], sum to 1.0000
[2019-03-23 08:56:40,459] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5684
[2019-03-23 08:56:40,462] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.23333333333333, 81.0, 1.0, 2.0, 0.2751303013826786, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 298742.5724581809, 298742.5724581812, 97076.62968942756], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6762000.0000, 
sim time next is 6762600.0000, 
raw observation next is [17.35, 79.5, 1.0, 2.0, 0.2698975116155123, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 293058.9815521745, 293058.9815521745, 95544.40846179619], 
processed observation next is [1.0, 0.2608695652173913, 0.42500000000000004, 0.795, 1.0, 1.0, 0.08737188951939034, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10854036353784241, 0.10854036353784241, 0.2330351425897468], 
reward next is 0.7670, 
noisyNet noise sample is [array([1.5220197], dtype=float32), -0.7305459]. 
=============================================
[2019-03-23 08:56:40,487] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.11840392e-24 1.00000000e+00 1.51898597e-34 9.29207202e-20
 1.43738865e-36], sum to 1.0000
[2019-03-23 08:56:40,496] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7068
[2019-03-23 08:56:40,499] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.2, 98.0, 1.0, 2.0, 0.3404909071106232, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 376625.4412028857, 376625.441202886, 116474.9839043855], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6741000.0000, 
sim time next is 6741600.0000, 
raw observation next is [17.2, 98.66666666666666, 1.0, 2.0, 0.3403848926309609, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 376943.1858911008, 376943.1858911011, 116639.7528369206], 
processed observation next is [1.0, 0.0, 0.41818181818181815, 0.9866666666666666, 1.0, 1.0, 0.1754811157887011, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13960858736707438, 0.13960858736707446, 0.28448720204126976], 
reward next is 0.7155, 
noisyNet noise sample is [array([0.5312709], dtype=float32), -0.8017917]. 
=============================================
[2019-03-23 08:56:43,860] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.4082347e-26 1.0000000e+00 1.5956844e-33 2.4145869e-20 6.4394933e-37], sum to 1.0000
[2019-03-23 08:56:43,866] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1476
[2019-03-23 08:56:43,870] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.55, 90.0, 1.0, 2.0, 0.3591892210928385, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 400391.3412523658, 400391.3412523661, 119177.1735029978], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6838200.0000, 
sim time next is 6838800.0000, 
raw observation next is [18.46666666666667, 90.0, 1.0, 2.0, 0.3559343535560793, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 396292.8536702554, 396292.8536702554, 118713.3690383988], 
processed observation next is [0.0, 0.13043478260869565, 0.4757575757575758, 0.9, 1.0, 1.0, 0.19491794194509907, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14677513098898348, 0.14677513098898348, 0.28954480253268], 
reward next is 0.7105, 
noisyNet noise sample is [array([0.22648475], dtype=float32), -1.6647592]. 
=============================================
[2019-03-23 08:56:46,190] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.2490623e-23 1.0000000e+00 9.0937183e-31 3.3347352e-19 1.9796289e-33], sum to 1.0000
[2019-03-23 08:56:46,196] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9343
[2019-03-23 08:56:46,201] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.46666666666667, 48.66666666666667, 1.0, 2.0, 0.4588203841969864, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 523415.3144677337, 523415.3144677337, 135588.2698079522], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6882000.0000, 
sim time next is 6882600.0000, 
raw observation next is [28.38333333333333, 48.33333333333333, 1.0, 2.0, 0.4540866544966037, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 517897.8167064764, 517897.8167064764, 134794.4048403315], 
processed observation next is [0.0, 0.6521739130434783, 0.9265151515151513, 0.4833333333333333, 1.0, 1.0, 0.3176083181207546, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19181400618758385, 0.19181400618758385, 0.32876684107397924], 
reward next is 0.6712, 
noisyNet noise sample is [array([1.4177507], dtype=float32), 0.8612482]. 
=============================================
[2019-03-23 08:56:54,801] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-23 08:56:54,804] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 08:56:54,805] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 08:56:54,806] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:56:54,807] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:56:54,806] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 08:56:54,807] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 08:56:54,812] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:56:54,808] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 08:56:54,815] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:56:54,816] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:56:54,825] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run17
[2019-03-23 08:56:54,850] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run17
[2019-03-23 08:56:54,873] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run17
[2019-03-23 08:56:54,874] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run17
[2019-03-23 08:56:54,920] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run17
[2019-03-23 08:57:07,102] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02404556], dtype=float32), -0.90983164]
[2019-03-23 08:57:07,104] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.8, 71.0, 1.0, 2.0, 0.4585037980658374, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 522470.3030319216, 522470.3030319216, 138878.8008039563]
[2019-03-23 08:57:07,104] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 08:57:07,107] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.4350759e-22 1.0000000e+00 1.7992122e-30 2.9730790e-18 1.1189550e-32], sampled 0.5104167912353883
[2019-03-23 08:57:11,480] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02404556], dtype=float32), -0.90983164]
[2019-03-23 08:57:11,482] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [24.07316980666667, 90.54390589, 1.0, 2.0, 0.5966573486022992, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 673066.5493469635, 673066.5493469632, 162139.2774402969]
[2019-03-23 08:57:11,482] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 08:57:11,485] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.4350759e-22 1.0000000e+00 1.7992122e-30 2.9730790e-18 1.1189550e-32], sampled 0.20296929616853
[2019-03-23 08:57:23,355] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02404556], dtype=float32), -0.90983164]
[2019-03-23 08:57:23,356] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.59554205, 91.77685211, 1.0, 2.0, 0.284802464166749, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 309229.4087962581, 309229.4087962577, 113214.4891384105]
[2019-03-23 08:57:23,357] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 08:57:23,360] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.4350759e-22 1.0000000e+00 1.7992122e-30 2.9730790e-18 1.1189550e-32], sampled 0.4707634307599947
[2019-03-23 08:57:33,384] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02404556], dtype=float32), -0.90983164]
[2019-03-23 08:57:33,388] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [18.5, 85.0, 1.0, 2.0, 0.3446204319594842, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 380252.1988571711, 380252.1988571711, 120742.9940779268]
[2019-03-23 08:57:33,388] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 08:57:33,392] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.4350759e-22 1.0000000e+00 1.7992122e-30 2.9730790e-18 1.1189550e-32], sampled 0.8117939588698082
[2019-03-23 08:57:41,008] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02404556], dtype=float32), -0.90983164]
[2019-03-23 08:57:41,010] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.05429941833333, 69.01459090833333, 1.0, 2.0, 0.8948968295712505, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 1020618.05288791, 1020618.05288791, 199285.8060476191]
[2019-03-23 08:57:41,011] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 08:57:41,015] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.4350759e-22 1.0000000e+00 1.7992122e-30 2.9730790e-18 1.1189550e-32], sampled 0.8393012124406468
[2019-03-23 08:57:42,459] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02404556], dtype=float32), -0.90983164]
[2019-03-23 08:57:42,462] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.33333333333334, 57.0, 1.0, 2.0, 0.3263903732071055, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 359124.8409203329, 359124.8409203329, 114672.8464183704]
[2019-03-23 08:57:42,464] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 08:57:42,467] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.4350759e-22 1.0000000e+00 1.7992122e-30 2.9730790e-18 1.1189550e-32], sampled 0.7979419173195336
[2019-03-23 08:57:43,507] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02404556], dtype=float32), -0.90983164]
[2019-03-23 08:57:43,509] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.8, 60.0, 1.0, 2.0, 0.3911564110817293, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 440846.7633778015, 440846.7633778015, 128417.6641848759]
[2019-03-23 08:57:43,509] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 08:57:43,512] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.4350759e-22 1.0000000e+00 1.7992122e-30 2.9730790e-18 1.1189550e-32], sampled 0.10867782928680636
[2019-03-23 08:58:11,046] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02404556], dtype=float32), -0.90983164]
[2019-03-23 08:58:11,048] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [25.8, 64.5, 1.0, 2.0, 0.5624421481454537, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9709314682468632, 6.911454769433899, 6.9112, 77.3284593023033, 1190054.937651573, 1189972.19375481, 266558.662731933]
[2019-03-23 08:58:11,049] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 08:58:11,053] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [6.2219971e-22 1.0000000e+00 1.0399193e-29 1.8122498e-17 7.1337907e-32], sampled 0.11038500660032013
[2019-03-23 08:58:11,055] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1190054.937651573 W.
[2019-03-23 08:58:12,791] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02404556], dtype=float32), -0.90983164]
[2019-03-23 08:58:12,792] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.17995514666667, 54.06094468666666, 1.0, 2.0, 0.2977843094395589, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 323328.4728053833, 323328.4728053833, 104661.1219551037]
[2019-03-23 08:58:12,793] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 08:58:12,795] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.4350759e-22 1.0000000e+00 1.7992122e-30 2.9730790e-18 1.1189550e-32], sampled 0.5945179773373661
[2019-03-23 08:58:13,853] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02404556], dtype=float32), -0.90983164]
[2019-03-23 08:58:13,857] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.26340670666666, 90.03182949333333, 1.0, 2.0, 0.3487017847104228, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 386775.3041854192, 386775.3041854192, 121847.3829277666]
[2019-03-23 08:58:13,858] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 08:58:13,861] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.4350759e-22 1.0000000e+00 1.7992122e-30 2.9730790e-18 1.1189550e-32], sampled 0.46125312451133826
[2019-03-23 08:58:36,680] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 08:58:36,798] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 08:58:36,828] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 08:58:36,875] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 08:58:36,939] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 08:58:37,954] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 400000, evaluation results [400000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 08:58:41,305] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.6092018e-23 1.0000000e+00 1.9697262e-30 3.4251725e-22 1.5973637e-35], sum to 1.0000
[2019-03-23 08:58:41,315] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1587
[2019-03-23 08:58:41,324] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 85.5, 1.0, 2.0, 0.5369004969420935, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 601344.9405726404, 601344.9405726404, 136691.7714356001], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7119000.0000, 
sim time next is 7119600.0000, 
raw observation next is [19.6, 85.0, 1.0, 2.0, 0.5585348005266492, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 626593.5384592247, 626593.5384592247, 139441.98028907], 
processed observation next is [1.0, 0.391304347826087, 0.5272727272727273, 0.85, 1.0, 1.0, 0.44816850065831143, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23207168091082397, 0.23207168091082397, 0.3401023909489512], 
reward next is 0.6599, 
noisyNet noise sample is [array([-0.8316029], dtype=float32), -0.6503361]. 
=============================================
[2019-03-23 08:58:47,029] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.8753559e-24 1.0000000e+00 1.0127144e-30 7.2585848e-16 3.5560397e-35], sum to 1.0000
[2019-03-23 08:58:47,040] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6032
[2019-03-23 08:58:47,048] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.2, 43.0, 1.0, 2.0, 0.7769438036243806, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 848690.1001563616, 848690.1001563616, 157597.0674374535], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7222800.0000, 
sim time next is 7223400.0000, 
raw observation next is [24.1, 43.0, 1.0, 2.0, 0.775811861860537, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 846300.0514270619, 846300.0514270623, 157087.6442674761], 
processed observation next is [1.0, 0.6086956521739131, 0.7318181818181819, 0.43, 1.0, 1.0, 0.7197648273256713, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3134444634915044, 0.3134444634915045, 0.38314059577433196], 
reward next is 0.6169, 
noisyNet noise sample is [array([2.591563], dtype=float32), 0.53725326]. 
=============================================
[2019-03-23 08:58:47,500] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.8623562e-25 1.0000000e+00 1.0996675e-32 9.8611589e-17 1.5522037e-35], sum to 1.0000
[2019-03-23 08:58:47,508] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2165
[2019-03-23 08:58:47,512] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.23333333333333, 56.33333333333334, 1.0, 2.0, 0.298231520409854, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 323834.7391068159, 323834.7391068159, 107184.2036219408], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7240800.0000, 
sim time next is 7241400.0000, 
raw observation next is [21.05, 57.0, 1.0, 2.0, 0.2962144992622573, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 321643.8321067133, 321643.8321067133, 105705.9918090616], 
processed observation next is [1.0, 0.8260869565217391, 0.5931818181818183, 0.57, 1.0, 1.0, 0.1202681240778216, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11912734522470864, 0.11912734522470864, 0.2578194922172234], 
reward next is 0.7422, 
noisyNet noise sample is [array([-1.4942946], dtype=float32), 1.6931435]. 
=============================================
[2019-03-23 08:58:47,818] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.6151710e-26 1.0000000e+00 2.6110995e-35 7.8445124e-23 3.7469768e-38], sum to 1.0000
[2019-03-23 08:58:47,825] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7199
[2019-03-23 08:58:47,831] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.01666666666667, 47.5, 1.0, 2.0, 0.3227348043717687, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 350451.2208084617, 350451.2208084614, 112741.8211606803], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7236600.0000, 
sim time next is 7237200.0000, 
raw observation next is [22.73333333333333, 49.0, 1.0, 2.0, 0.3195554447608329, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 346997.5864928535, 346997.5864928532, 112521.3836337097], 
processed observation next is [1.0, 0.782608695652174, 0.6696969696969696, 0.49, 1.0, 1.0, 0.14944430595104113, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12851762462698277, 0.12851762462698266, 0.274442399106609], 
reward next is 0.7256, 
noisyNet noise sample is [array([-0.27232745], dtype=float32), -0.92281854]. 
=============================================
[2019-03-23 08:58:50,215] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.1103619e-24 1.0000000e+00 8.4860590e-36 1.0547377e-21 5.3610344e-38], sum to 1.0000
[2019-03-23 08:58:50,224] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5666
[2019-03-23 08:58:50,228] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.71666666666667, 61.33333333333334, 1.0, 2.0, 0.5360039006260932, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 582174.4955555925, 582174.4955555925, 130179.1458779238], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7293000.0000, 
sim time next is 7293600.0000, 
raw observation next is [21.1, 61.0, 1.0, 2.0, 0.5559321823547516, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 606522.7279608664, 606522.7279608664, 132899.5700824411], 
processed observation next is [1.0, 0.43478260869565216, 0.5954545454545456, 0.61, 1.0, 1.0, 0.44491522794343946, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2246380473929135, 0.2246380473929135, 0.3241452928840027], 
reward next is 0.6759, 
noisyNet noise sample is [array([-0.15141878], dtype=float32), 0.68316287]. 
=============================================
[2019-03-23 08:58:55,555] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.7408031e-21 1.0000000e+00 2.6248923e-27 4.5560398e-13 1.0176525e-29], sum to 1.0000
[2019-03-23 08:58:55,563] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5372
[2019-03-23 08:58:55,569] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1354185.202616141 W.
[2019-03-23 08:58:55,577] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.8, 51.66666666666667, 1.0, 2.0, 0.7075961254345148, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9748368717853805, 6.911199999999999, 6.9112, 77.32846344354104, 1354185.202616141, 1354185.202616141, 290851.7913059953], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7395600.0000, 
sim time next is 7396200.0000, 
raw observation next is [28.8, 52.0, 1.0, 2.0, 0.4126574986373316, 1.0, 1.0, 0.4126574986373316, 1.0, 2.0, 0.8355908626924544, 6.9112, 6.9112, 77.3421103, 1402727.589353803, 1402727.589353803, 309321.4678285046], 
processed observation next is [1.0, 0.6086956521739131, 0.9454545454545454, 0.52, 1.0, 1.0, 0.26582187329666446, 1.0, 0.5, 0.26582187329666446, 1.0, 1.0, 0.7651298038463634, 0.0, 0.0, 0.5085185399722538, 0.5195287367977048, 0.5195287367977048, 0.7544426044597674], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.6745063], dtype=float32), -2.1542544]. 
=============================================
[2019-03-23 08:58:59,084] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.5208625e-27 1.0000000e+00 1.3696641e-34 5.8905285e-23 2.8036287e-37], sum to 1.0000
[2019-03-23 08:58:59,094] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8741
[2019-03-23 08:58:59,103] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.28333333333333, 96.16666666666666, 1.0, 2.0, 0.3471579296017412, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 383645.496059674, 383645.4960596737, 116846.6853969327], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7437000.0000, 
sim time next is 7437600.0000, 
raw observation next is [17.2, 96.0, 1.0, 2.0, 0.3428748564774772, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 378254.8459998831, 378254.8459998831, 116266.0097450388], 
processed observation next is [0.0, 0.08695652173913043, 0.41818181818181815, 0.96, 1.0, 1.0, 0.17859357059684644, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1400943874073641, 0.1400943874073641, 0.2835756335244849], 
reward next is 0.7164, 
noisyNet noise sample is [array([0.85404044], dtype=float32), -0.5814073]. 
=============================================
[2019-03-23 08:59:04,769] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.5788882e-24 1.0000000e+00 9.9928536e-34 2.7840613e-22 8.0707742e-37], sum to 1.0000
[2019-03-23 08:59:04,776] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0231
[2019-03-23 08:59:04,780] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.26666666666667, 92.0, 1.0, 2.0, 0.460239315604153, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 524960.9808319473, 524960.9808319473, 135547.2667711537], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7530000.0000, 
sim time next is 7530600.0000, 
raw observation next is [21.18333333333334, 92.5, 1.0, 2.0, 0.4593236260660226, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 523895.3618772153, 523895.3618772156, 135401.2178089599], 
processed observation next is [0.0, 0.13043478260869565, 0.5992424242424246, 0.925, 1.0, 1.0, 0.32415453258252824, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19403531921378345, 0.19403531921378356, 0.3302468727047802], 
reward next is 0.6698, 
noisyNet noise sample is [array([1.749318], dtype=float32), -1.2019308]. 
=============================================
[2019-03-23 08:59:08,852] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.9749371e-22 1.0000000e+00 1.7195338e-30 8.2663731e-19 4.1550937e-31], sum to 1.0000
[2019-03-23 08:59:08,856] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5264
[2019-03-23 08:59:08,860] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.13333333333333, 63.16666666666666, 1.0, 2.0, 0.4786599455821028, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 546182.4150497423, 546182.4150497423, 138720.069494863], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7668600.0000, 
sim time next is 7669200.0000, 
raw observation next is [25.66666666666667, 66.33333333333334, 1.0, 2.0, 0.4825231763733956, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 550566.6557370136, 550566.6557370136, 139332.1029391244], 
processed observation next is [1.0, 0.782608695652174, 0.8030303030303032, 0.6633333333333334, 1.0, 1.0, 0.35315397046674446, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20391357619889391, 0.20391357619889391, 0.33983439741249855], 
reward next is 0.6602, 
noisyNet noise sample is [array([-0.4823322], dtype=float32), -0.80029064]. 
=============================================
[2019-03-23 08:59:14,450] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.7250601e-29 1.0000000e+00 0.0000000e+00 6.2253286e-27 0.0000000e+00], sum to 1.0000
[2019-03-23 08:59:14,459] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0944
[2019-03-23 08:59:14,466] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.31666666666667, 64.16666666666666, 1.0, 2.0, 0.5693184755325924, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 619152.7825665998, 619152.7825665998, 133606.6788435992], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7725000.0000, 
sim time next is 7725600.0000, 
raw observation next is [20.5, 63.0, 1.0, 2.0, 0.5725455457118394, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 622777.9667844238, 622777.9667844238, 133958.6089821036], 
processed observation next is [1.0, 0.43478260869565216, 0.5681818181818182, 0.63, 1.0, 1.0, 0.46568193213979914, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23065850621645326, 0.23065850621645326, 0.32672831459049656], 
reward next is 0.6733, 
noisyNet noise sample is [array([0.28392437], dtype=float32), -0.8602659]. 
=============================================
[2019-03-23 08:59:16,537] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.3285161e-29 1.0000000e+00 0.0000000e+00 2.4011483e-28 0.0000000e+00], sum to 1.0000
[2019-03-23 08:59:16,542] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1015
[2019-03-23 08:59:16,547] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.66666666666666, 70.33333333333333, 1.0, 2.0, 0.4729330119715943, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 513634.5788824979, 513634.5788824979, 118141.8521598151], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7807200.0000, 
sim time next is 7807800.0000, 
raw observation next is [19.03333333333333, 69.16666666666667, 1.0, 2.0, 0.4838147584736224, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 525459.2178772574, 525459.2178772574, 121792.8132015129], 
processed observation next is [1.0, 0.34782608695652173, 0.5015151515151515, 0.6916666666666668, 1.0, 1.0, 0.35476844809202795, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19461452513972496, 0.19461452513972496, 0.2970556419549095], 
reward next is 0.7029, 
noisyNet noise sample is [array([-1.5840558], dtype=float32), 1.2964981]. 
=============================================
[2019-03-23 08:59:19,004] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.1591445e-27 1.0000000e+00 1.2623839e-37 4.5004795e-24 0.0000000e+00], sum to 1.0000
[2019-03-23 08:59:19,009] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3552
[2019-03-23 08:59:19,013] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 76.0, 1.0, 2.0, 0.3082437440001524, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 334746.1256407203, 334746.1256407206, 111761.4001888464], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7858800.0000, 
sim time next is 7859400.0000, 
raw observation next is [18.9, 74.16666666666667, 1.0, 2.0, 0.3070137356438394, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 333374.1774605141, 333374.1774605138, 111664.4701163704], 
processed observation next is [1.0, 1.0, 0.49545454545454537, 0.7416666666666667, 1.0, 1.0, 0.1337671695547992, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12347191757796819, 0.12347191757796806, 0.2723523661374888], 
reward next is 0.7276, 
noisyNet noise sample is [array([-0.89246833], dtype=float32), 0.26277423]. 
=============================================
[2019-03-23 08:59:20,634] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.0709054e-29 1.0000000e+00 5.2581853e-38 9.3941187e-26 0.0000000e+00], sum to 1.0000
[2019-03-23 08:59:20,635] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5915
[2019-03-23 08:59:20,640] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 63.0, 1.0, 2.0, 0.2907687224831483, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 315728.6283707261, 315728.6283707264, 110579.0774119911], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7848000.0000, 
sim time next is 7848600.0000, 
raw observation next is [20.41666666666667, 63.0, 1.0, 2.0, 0.2952012468427277, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 320543.2316946902, 320543.2316946905, 110871.5361170397], 
processed observation next is [1.0, 0.8695652173913043, 0.5643939393939396, 0.63, 1.0, 1.0, 0.1190015585534096, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11871971544247785, 0.11871971544247796, 0.2704183807732675], 
reward next is 0.7296, 
noisyNet noise sample is [array([1.061666], dtype=float32), -1.1656215]. 
=============================================
[2019-03-23 08:59:23,520] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:59:23,520] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:59:23,536] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run3
[2019-03-23 08:59:24,248] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:59:24,249] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:59:24,250] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run3
[2019-03-23 08:59:24,381] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:59:24,381] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:59:24,382] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run3
[2019-03-23 08:59:24,411] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:59:24,412] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:59:24,412] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:59:24,412] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:59:24,414] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run3
[2019-03-23 08:59:24,438] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run3
[2019-03-23 08:59:24,488] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:59:24,489] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:59:24,490] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run3
[2019-03-23 08:59:24,513] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:59:24,514] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:59:24,516] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run3
[2019-03-23 08:59:24,565] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:59:24,565] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:59:24,566] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run3
[2019-03-23 08:59:24,605] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:59:24,605] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:59:24,607] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run3
[2019-03-23 08:59:24,662] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:59:24,662] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:59:24,664] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run3
[2019-03-23 08:59:24,741] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:59:24,741] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:59:24,743] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run3
[2019-03-23 08:59:24,819] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:59:24,819] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:59:24,821] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run3
[2019-03-23 08:59:24,905] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:59:24,905] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:59:24,907] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run3
[2019-03-23 08:59:25,050] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:59:25,050] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:59:25,052] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run3
[2019-03-23 08:59:25,069] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:59:25,069] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:59:25,069] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:59:25,070] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:59:25,122] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run3
[2019-03-23 08:59:25,199] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run3
[2019-03-23 08:59:28,163] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-23 08:59:28,165] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 08:59:28,166] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 08:59:28,166] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:59:28,167] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 08:59:28,168] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:59:28,168] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:59:28,169] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 08:59:28,169] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 08:59:28,171] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:59:28,171] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:59:28,185] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run18
[2019-03-23 08:59:28,218] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run18
[2019-03-23 08:59:28,219] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run18
[2019-03-23 08:59:28,265] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run18
[2019-03-23 08:59:28,266] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run18
[2019-03-23 08:59:30,143] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.93769664]
[2019-03-23 08:59:30,143] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [16.0, 77.0, 1.0, 2.0, 0.2359224788248526, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 256158.6392338118, 256158.6392338116, 79570.88931210655]
[2019-03-23 08:59:30,144] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 08:59:30,147] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [5.4802335e-25 1.0000000e+00 1.6231391e-33 2.5014507e-21 1.2410988e-35], sampled 0.2712101037889465
[2019-03-23 08:59:30,537] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.93769664]
[2019-03-23 08:59:30,538] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.83333333333334, 31.0, 1.0, 2.0, 0.3539911472399951, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 384376.2925695114, 384376.292569511, 93712.05954012816]
[2019-03-23 08:59:30,539] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 08:59:30,541] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.4802335e-25 1.0000000e+00 1.6231391e-33 2.5014507e-21 1.2410988e-35], sampled 0.2945170435904273
[2019-03-23 08:59:33,596] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.93769664]
[2019-03-23 08:59:33,597] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.81666666666667, 71.83333333333334, 1.0, 2.0, 0.3417143597725935, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 374420.0178291542, 374420.0178291538, 119552.1641954329]
[2019-03-23 08:59:33,597] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 08:59:33,601] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.4802335e-25 1.0000000e+00 1.6231391e-33 2.5014507e-21 1.2410988e-35], sampled 0.9104063055043641
[2019-03-23 08:59:41,830] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.93769664]
[2019-03-23 08:59:41,832] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.0, 94.0, 1.0, 2.0, 0.3422080924567411, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 380780.5437010573, 380780.5437010573, 117529.040144386]
[2019-03-23 08:59:41,832] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 08:59:41,835] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [5.4802335e-25 1.0000000e+00 1.6231391e-33 2.5014507e-21 1.2410988e-35], sampled 0.26676593181272557
[2019-03-23 08:59:46,776] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.93769664]
[2019-03-23 08:59:46,777] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.16099922333333, 95.51145689666667, 1.0, 2.0, 0.5172561467734789, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 589319.4978061431, 589319.4978061428, 149077.6003098418]
[2019-03-23 08:59:46,778] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 08:59:46,780] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [5.4802335e-25 1.0000000e+00 1.6231391e-33 2.5014507e-21 1.2410988e-35], sampled 0.2655071407379598
[2019-03-23 08:59:52,052] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.93769664]
[2019-03-23 08:59:52,054] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.11691505, 70.32699026, 1.0, 2.0, 0.2436705680677888, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 264559.8821299202, 264559.8821299198, 86274.80072105491]
[2019-03-23 08:59:52,055] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 08:59:52,057] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.4802335e-25 1.0000000e+00 1.6231391e-33 2.5014507e-21 1.2410988e-35], sampled 0.707843906817077
[2019-03-23 08:59:54,335] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.93769664]
[2019-03-23 08:59:54,337] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [16.88333333333334, 54.33333333333334, 1.0, 2.0, 0.2338984490868361, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 253947.7806529719, 253947.7806529715, 78379.59525801962]
[2019-03-23 08:59:54,337] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 08:59:54,340] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.4802335e-25 1.0000000e+00 1.6231391e-33 2.5014507e-21 1.2410988e-35], sampled 0.9753563788525996
[2019-03-23 09:00:01,216] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.93769664]
[2019-03-23 09:00:01,218] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.69779758, 98.92376384, 1.0, 2.0, 0.4662449148172604, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 530265.170736513, 530265.1707365126, 138587.6233888003]
[2019-03-23 09:00:01,220] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 09:00:01,222] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.4802335e-25 1.0000000e+00 1.6231391e-33 2.5014507e-21 1.2410988e-35], sampled 0.7836476722227866
[2019-03-23 09:00:03,514] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.93769664]
[2019-03-23 09:00:03,515] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.809040965, 100.0, 1.0, 2.0, 0.5503588825667747, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 622620.1457068422, 622620.1457068422, 155422.2850214546]
[2019-03-23 09:00:03,516] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 09:00:03,518] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.4802335e-25 1.0000000e+00 1.6231391e-33 2.5014507e-21 1.2410988e-35], sampled 0.9110987099648725
[2019-03-23 09:00:23,947] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.93769664]
[2019-03-23 09:00:23,948] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.16666666666667, 86.33333333333334, 1.0, 2.0, 0.4696338967727576, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 535804.2429377061, 535804.2429377061, 136910.4971092708]
[2019-03-23 09:00:23,948] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 09:00:23,952] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [5.4802335e-25 1.0000000e+00 1.6231391e-33 2.5014507e-21 1.2410988e-35], sampled 0.8490006700859948
[2019-03-23 09:00:54,315] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.93769664]
[2019-03-23 09:00:54,316] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.06666666666667, 87.83333333333333, 1.0, 2.0, 0.5664503349741439, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 645521.2318044009, 645521.2318044009, 155072.3747120036]
[2019-03-23 09:00:54,317] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 09:00:54,322] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.4802335e-25 1.0000000e+00 1.6231391e-33 2.5014507e-21 1.2410988e-35], sampled 0.8008842352772585
[2019-03-23 09:00:57,299] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.93769664]
[2019-03-23 09:00:57,300] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [26.68700838666667, 65.1218777, 1.0, 2.0, 0.5411062751101133, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 615845.4554876068, 615845.4554876068, 152541.2494386149]
[2019-03-23 09:00:57,302] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 09:00:57,305] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.4802335e-25 1.0000000e+00 1.6231391e-33 2.5014507e-21 1.2410988e-35], sampled 0.7603774106083909
[2019-03-23 09:01:01,504] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.93769664]
[2019-03-23 09:01:01,505] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.1, 51.0, 1.0, 2.0, 0.3840654567631807, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 417043.3889990438, 417043.3889990442, 118792.8406624929]
[2019-03-23 09:01:01,506] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 09:01:01,510] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.4802335e-25 1.0000000e+00 1.6231391e-33 2.5014507e-21 1.2410988e-35], sampled 0.5833718194307829
[2019-03-23 09:01:09,841] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 09:01:09,932] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 09:01:10,036] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 09:01:10,062] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 09:01:10,101] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 09:01:11,114] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 425000, evaluation results [425000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 09:01:13,357] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.9346214e-24 1.0000000e+00 5.4538030e-35 5.8523238e-21 6.0208633e-38], sum to 1.0000
[2019-03-23 09:01:13,368] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2785
[2019-03-23 09:01:13,373] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 77.0, 1.0, 2.0, 0.2292064699319111, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 248864.7016678198, 248864.7016678198, 78834.05167137709], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 86400.0000, 
sim time next is 87000.0000, 
raw observation next is [16.0, 77.0, 1.0, 2.0, 0.2291025372818392, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 248751.8262234036, 248751.8262234039, 78813.02835690317], 
processed observation next is [1.0, 0.0, 0.36363636363636365, 0.77, 1.0, 1.0, 0.036378171602299, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09213030600866799, 0.09213030600866812, 0.19222689843147114], 
reward next is 0.8078, 
noisyNet noise sample is [array([-0.29328823], dtype=float32), 0.10000314]. 
=============================================
[2019-03-23 09:01:13,393] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[79.839676]
 [79.839676]
 [79.839676]
 [79.839676]
 [79.839676]], R is [[79.84905243]
 [79.858284  ]
 [79.86708069]
 [79.87518311]
 [79.88286591]].
[2019-03-23 09:01:16,086] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.16622554e-26 1.00000000e+00 9.27315810e-36 6.48716758e-25
 0.00000000e+00], sum to 1.0000
[2019-03-23 09:01:16,095] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1275
[2019-03-23 09:01:16,100] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 60.0, 1.0, 2.0, 0.547124263701848, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 594260.1343014175, 594260.1343014175, 124566.3775410043], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 124200.0000, 
sim time next is 124800.0000, 
raw observation next is [19.66666666666667, 61.33333333333333, 1.0, 2.0, 0.5304534901168133, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 576142.4077882548, 576142.4077882548, 121657.2350191322], 
processed observation next is [1.0, 0.43478260869565216, 0.5303030303030305, 0.6133333333333333, 1.0, 1.0, 0.4130668626460166, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2133860769586129, 0.2133860769586129, 0.29672496346129806], 
reward next is 0.7033, 
noisyNet noise sample is [array([2.0776055], dtype=float32), 0.69910914]. 
=============================================
[2019-03-23 09:01:31,223] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.5694241e-29 1.0000000e+00 0.0000000e+00 1.3265183e-24 0.0000000e+00], sum to 1.0000
[2019-03-23 09:01:31,230] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4388
[2019-03-23 09:01:31,233] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.5, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 215000.0977599508, 215000.0977599508, 74315.11057784565], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 423000.0000, 
sim time next is 423600.0000, 
raw observation next is [14.33333333333333, 90.0, 1.0, 2.0, 0.2011668168460657, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 218413.3507778091, 218413.3507778091, 74934.44187954202], 
processed observation next is [1.0, 0.9130434782608695, 0.28787878787878773, 0.9, 1.0, 1.0, 0.0014585210575820962, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08089383362141078, 0.08089383362141078, 0.18276693141351713], 
reward next is 0.8172, 
noisyNet noise sample is [array([-1.1399288], dtype=float32), -1.2956257]. 
=============================================
[2019-03-23 09:01:34,130] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.6241712e-27 1.0000000e+00 0.0000000e+00 1.4359349e-23 0.0000000e+00], sum to 1.0000
[2019-03-23 09:01:34,140] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4038
[2019-03-23 09:01:34,145] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 100.0, 1.0, 2.0, 0.3681233474996012, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 399757.9849311399, 399757.9849311399, 95971.25747050457], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 471600.0000, 
sim time next is 472200.0000, 
raw observation next is [14.0, 100.0, 1.0, 2.0, 0.3989033388670831, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 433197.9416390546, 433197.9416390546, 99172.37076848646], 
processed observation next is [1.0, 0.4782608695652174, 0.2727272727272727, 1.0, 1.0, 1.0, 0.2486291735838539, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16044368208853876, 0.16044368208853876, 0.2418838311426499], 
reward next is 0.7581, 
noisyNet noise sample is [array([-1.0052265], dtype=float32), -0.5122232]. 
=============================================
[2019-03-23 09:01:38,577] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.6006972e-24 1.0000000e+00 1.9050918e-32 1.8246274e-22 2.7829902e-36], sum to 1.0000
[2019-03-23 09:01:38,587] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8349
[2019-03-23 09:01:38,590] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.5, 78.0, 1.0, 2.0, 0.5128874074495675, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 558800.7929176929, 558800.7929176929, 128573.0938578495], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 559800.0000, 
sim time next is 560400.0000, 
raw observation next is [18.66666666666667, 76.33333333333334, 1.0, 2.0, 0.5194565124913156, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 565482.9186434641, 565482.9186434641, 129033.7905753916], 
processed observation next is [1.0, 0.4782608695652174, 0.4848484848484851, 0.7633333333333334, 1.0, 1.0, 0.3993206406141445, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20943811801609782, 0.20943811801609782, 0.3147165623790039], 
reward next is 0.6853, 
noisyNet noise sample is [array([1.1535485], dtype=float32), 0.8401286]. 
=============================================
[2019-03-23 09:01:44,863] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.9858008e-26 1.0000000e+00 1.0343028e-34 3.4274189e-23 1.4000802e-36], sum to 1.0000
[2019-03-23 09:01:44,871] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5982
[2019-03-23 09:01:44,875] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 55.5, 1.0, 2.0, 0.3521409941850666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 392303.5166022091, 392303.5166022094, 118511.1596713064], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 678600.0000, 
sim time next is 679200.0000, 
raw observation next is [23.33333333333333, 56.0, 1.0, 2.0, 0.3492236493022419, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 388684.3046509746, 388684.3046509749, 118121.1073178294], 
processed observation next is [1.0, 0.8695652173913043, 0.6969696969696968, 0.56, 1.0, 1.0, 0.18652956162780238, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14395714987073133, 0.14395714987073147, 0.28810026175080344], 
reward next is 0.7119, 
noisyNet noise sample is [array([0.51243794], dtype=float32), 0.112595335]. 
=============================================
[2019-03-23 09:01:46,046] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.8366930e-26 1.0000000e+00 8.7243337e-35 9.6025015e-23 4.0624535e-37], sum to 1.0000
[2019-03-23 09:01:46,052] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0705
[2019-03-23 09:01:46,060] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.16666666666667, 99.0, 1.0, 2.0, 0.2789813954717266, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 302925.4780108476, 302925.4780108473, 96180.25258200047], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 705000.0000, 
sim time next is 705600.0000, 
raw observation next is [15.0, 100.0, 1.0, 2.0, 0.2791171322559056, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 303072.9105749211, 303072.9105749211, 95311.11836341786], 
processed observation next is [1.0, 0.17391304347826086, 0.3181818181818182, 1.0, 1.0, 1.0, 0.09889641531988201, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11224922613885967, 0.11224922613885967, 0.23246614234979965], 
reward next is 0.7675, 
noisyNet noise sample is [array([0.33656406], dtype=float32), -0.9842858]. 
=============================================
[2019-03-23 09:01:47,008] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.4300826e-25 1.0000000e+00 1.6143899e-32 1.7312375e-21 2.4705287e-34], sum to 1.0000
[2019-03-23 09:01:47,014] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3142
[2019-03-23 09:01:47,018] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 71.66666666666667, 1.0, 2.0, 0.7471297209053299, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 840995.185845597, 840995.1858455972, 163527.8305545574], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 721200.0000, 
sim time next is 721800.0000, 
raw observation next is [22.0, 71.0, 1.0, 2.0, 0.8468238960547527, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 956052.2134577098, 956052.2134577098, 179100.4940338221], 
processed observation next is [1.0, 0.34782608695652173, 0.6363636363636364, 0.71, 1.0, 1.0, 0.8085298700684409, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.35409341239174436, 0.35409341239174436, 0.4368304732532246], 
reward next is 0.5632, 
noisyNet noise sample is [array([0.6287092], dtype=float32), 0.39403766]. 
=============================================
[2019-03-23 09:01:47,073] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.9780998e-23 1.0000000e+00 4.6879271e-30 8.8344875e-19 5.8916731e-31], sum to 1.0000
[2019-03-23 09:01:47,081] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2768
[2019-03-23 09:01:47,090] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 69.0, 1.0, 2.0, 0.7493087616036567, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 852538.7797764511, 852538.7797764511, 169523.354152688], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 725400.0000, 
sim time next is 726000.0000, 
raw observation next is [23.66666666666667, 69.0, 1.0, 2.0, 0.8367092919089806, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 952833.2077909847, 952833.2077909844, 183408.7702277178], 
processed observation next is [1.0, 0.391304347826087, 0.7121212121212124, 0.69, 1.0, 1.0, 0.7958866148862256, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.35290118807073506, 0.35290118807073495, 0.4473384639700434], 
reward next is 0.5527, 
noisyNet noise sample is [array([-0.21463104], dtype=float32), 0.39728647]. 
=============================================
[2019-03-23 09:01:47,108] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[57.526997]
 [57.366856]
 [57.203808]
 [57.389233]
 [57.762344]], R is [[57.48886871]
 [57.50051117]
 [57.51041794]
 [57.49636841]
 [57.47392654]].
[2019-03-23 09:01:51,363] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.8668290e-25 1.0000000e+00 9.7926237e-34 1.2647548e-23 2.7079239e-36], sum to 1.0000
[2019-03-23 09:01:51,372] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5110
[2019-03-23 09:01:51,380] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.16666666666667, 78.16666666666667, 1.0, 2.0, 0.5858179457401738, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 660274.8810161555, 660274.8810161555, 156508.2493927491], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 814200.0000, 
sim time next is 814800.0000, 
raw observation next is [26.33333333333334, 77.33333333333334, 1.0, 2.0, 0.5886526091625662, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 663213.6661824071, 663213.6661824071, 156955.2717430598], 
processed observation next is [0.0, 0.43478260869565216, 0.8333333333333336, 0.7733333333333334, 1.0, 1.0, 0.48581576145320776, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2456346911786693, 0.2456346911786693, 0.38281773595868246], 
reward next is 0.6172, 
noisyNet noise sample is [array([-1.5748321], dtype=float32), 0.2574474]. 
=============================================
[2019-03-23 09:01:59,224] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-23 09:01:59,225] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 09:01:59,225] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:01:59,226] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 09:01:59,227] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 09:01:59,227] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 09:01:59,228] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 09:01:59,228] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:01:59,232] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:01:59,234] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:01:59,238] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:01:59,250] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run19
[2019-03-23 09:01:59,277] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run19
[2019-03-23 09:01:59,302] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run19
[2019-03-23 09:01:59,327] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run19
[2019-03-23 09:01:59,351] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run19
[2019-03-23 09:02:06,472] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.896237]
[2019-03-23 09:02:06,473] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.0, 64.0, 1.0, 2.0, 0.5582022916123487, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 613924.2630447859, 613924.2630447857, 134711.4952280321]
[2019-03-23 09:02:06,473] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 09:02:06,475] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.3212774e-27 1.0000000e+00 8.9584156e-36 5.7915052e-25 2.1217614e-38], sampled 0.5020893578724318
[2019-03-23 09:02:14,367] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.896237]
[2019-03-23 09:02:14,368] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.33333333333334, 91.33333333333334, 1.0, 2.0, 0.3847633780911808, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 433651.0500676756, 433651.0500676759, 127856.1328087867]
[2019-03-23 09:02:14,369] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 09:02:14,372] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.3212774e-27 1.0000000e+00 8.9584156e-36 5.7915052e-25 2.1217614e-38], sampled 0.29984131512890566
[2019-03-23 09:02:24,205] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.896237]
[2019-03-23 09:02:24,206] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.16666666666667, 77.0, 1.0, 2.0, 0.4872025684478129, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 529140.6369261009, 529140.6369261009, 113794.8034126491]
[2019-03-23 09:02:24,208] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 09:02:24,213] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.3212774e-27 1.0000000e+00 8.9584156e-36 5.7915052e-25 2.1217614e-38], sampled 0.6404943645165219
[2019-03-23 09:02:36,148] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.896237]
[2019-03-23 09:02:36,150] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.1, 90.0, 1.0, 2.0, 0.4492795601193716, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 511847.2485426993, 511847.2485426993, 137766.9902756794]
[2019-03-23 09:02:36,150] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 09:02:36,152] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.3212774e-27 1.0000000e+00 8.9584156e-36 5.7915052e-25 2.1217614e-38], sampled 0.9873288325273952
[2019-03-23 09:03:09,673] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.896237]
[2019-03-23 09:03:09,674] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.68078835, 80.57202111, 1.0, 2.0, 0.3628690913639669, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 399786.1267488321, 399786.1267488317, 121923.8037729885]
[2019-03-23 09:03:09,676] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 09:03:09,680] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.3212774e-27 1.0000000e+00 8.9584156e-36 5.7915052e-25 2.1217614e-38], sampled 0.2098195493558439
[2019-03-23 09:03:40,309] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 09:03:40,481] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 09:03:40,587] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 09:03:40,646] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 09:03:40,687] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 09:03:41,702] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 450000, evaluation results [450000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 09:03:43,813] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.4058347e-29 1.0000000e+00 0.0000000e+00 1.0316943e-26 0.0000000e+00], sum to 1.0000
[2019-03-23 09:03:43,823] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8049
[2019-03-23 09:03:43,829] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 100.0, 1.0, 2.0, 0.2569811516298904, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 279030.1705997995, 279030.1705997993, 84144.53296872637], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1015200.0000, 
sim time next is 1015800.0000, 
raw observation next is [14.0, 99.00000000000001, 1.0, 2.0, 0.2544552948523932, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 276286.8159499725, 276286.8159499723, 83346.77965551271], 
processed observation next is [1.0, 0.782608695652174, 0.2727272727272727, 0.9900000000000001, 1.0, 1.0, 0.0680691185654915, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10232845035184167, 0.1023284503518416, 0.2032848284280798], 
reward next is 0.7967, 
noisyNet noise sample is [array([-1.2910997], dtype=float32), -0.73241615]. 
=============================================
[2019-03-23 09:03:44,944] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.995947e-33 1.000000e+00 0.000000e+00 8.816747e-26 0.000000e+00], sum to 1.0000
[2019-03-23 09:03:44,955] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7357
[2019-03-23 09:03:44,959] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 94.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 202495.4020050424, 202495.4020050421, 69576.66574738975], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1036800.0000, 
sim time next is 1037400.0000, 
raw observation next is [12.83333333333333, 95.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 201216.0152936898, 201216.0152936901, 69204.17813505032], 
processed observation next is [1.0, 0.0, 0.21969696969696956, 0.95, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.074524450108774, 0.07452445010877412, 0.1687906783781715], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.44270763], dtype=float32), -0.14709993]. 
=============================================
[2019-03-23 09:03:51,225] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.3360794e-26 1.0000000e+00 1.6899422e-34 3.5033060e-24 1.4953712e-37], sum to 1.0000
[2019-03-23 09:03:51,233] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0830
[2019-03-23 09:03:51,239] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666667, 76.66666666666667, 1.0, 2.0, 0.7726376527021245, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 880168.168433759, 880168.1684337594, 173986.6026329839], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1160400.0000, 
sim time next is 1161000.0000, 
raw observation next is [23.0, 76.0, 1.0, 2.0, 0.8189185861640287, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 933726.490103601, 933726.4901036014, 182030.4712396182], 
processed observation next is [1.0, 0.43478260869565216, 0.6818181818181818, 0.76, 1.0, 1.0, 0.7736482327050359, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3458246259642967, 0.3458246259642968, 0.44397675912102], 
reward next is 0.5560, 
noisyNet noise sample is [array([1.1241549], dtype=float32), -0.9872692]. 
=============================================
[2019-03-23 09:03:51,257] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[68.29625]
 [68.29625]
 [68.29625]
 [68.29625]
 [68.29625]], R is [[68.16931915]
 [68.06327057]
 [67.97872925]
 [67.90627289]
 [67.81681824]].
[2019-03-23 09:03:52,459] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.9400635e-13 1.0000000e+00 2.6983910e-17 3.5510657e-12 2.0769376e-18], sum to 1.0000
[2019-03-23 09:03:52,465] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5369
[2019-03-23 09:03:52,471] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1238658.552524566 W.
[2019-03-23 09:03:52,476] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.0, 64.0, 1.0, 2.0, 0.3659848041481443, 1.0, 2.0, 0.3659848041481443, 1.0, 2.0, 0.7401473774774333, 6.911199999999998, 6.9112, 77.3421103, 1238658.552524566, 1238658.552524567, 289822.6194280752], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1179000.0000, 
sim time next is 1179600.0000, 
raw observation next is [27.0, 64.66666666666667, 1.0, 2.0, 0.5483631193628805, 1.0, 2.0, 0.5483631193628805, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1238281.167397595, 1238281.167397595, 246689.2992390515], 
processed observation next is [1.0, 0.6521739130434783, 0.8636363636363636, 0.6466666666666667, 1.0, 1.0, 0.4354538992036006, 1.0, 1.0, 0.4354538992036006, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.4586226545917019, 0.4586226545917019, 0.6016812176562232], 
reward next is 0.3983, 
noisyNet noise sample is [array([-1.8898432], dtype=float32), -0.7348412]. 
=============================================
[2019-03-23 09:03:55,484] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.6463808e-26 1.0000000e+00 9.1648129e-35 2.8383424e-23 7.6146850e-38], sum to 1.0000
[2019-03-23 09:03:55,489] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7780
[2019-03-23 09:03:55,494] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.5122453889389036, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 584240.5456047223, 584240.5456047223, 143448.974963424], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1238400.0000, 
sim time next is 1239000.0000, 
raw observation next is [22.0, 94.00000000000001, 1.0, 2.0, 0.554328965555607, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 632201.486129259, 632201.486129259, 148689.1735017248], 
processed observation next is [1.0, 0.34782608695652173, 0.6363636363636364, 0.9400000000000002, 1.0, 1.0, 0.44291120694450864, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23414869856639223, 0.23414869856639223, 0.3626565207359142], 
reward next is 0.6373, 
noisyNet noise sample is [array([-0.42294204], dtype=float32), -1.6746019]. 
=============================================
[2019-03-23 09:03:55,503] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[66.7162]
 [66.7162]
 [66.7162]
 [66.7162]
 [66.7162]], R is [[66.68638611]
 [66.66964722]
 [66.65882111]
 [66.64792633]
 [66.63454437]].
[2019-03-23 09:03:56,620] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.8028836e-21 1.0000000e+00 8.6590138e-28 1.5328923e-19 7.6032216e-30], sum to 1.0000
[2019-03-23 09:03:56,631] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5285
[2019-03-23 09:03:56,639] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1339043.525784758 W.
[2019-03-23 09:03:56,642] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.33333333333333, 60.33333333333333, 1.0, 2.0, 0.6950045690214781, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9760093458881072, 6.911199999999999, 6.9112, 77.32846344354104, 1339043.525784758, 1339043.525784759, 290124.4995221699], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1258800.0000, 
sim time next is 1259400.0000, 
raw observation next is [27.66666666666667, 59.16666666666666, 1.0, 2.0, 0.6292307470951735, 1.0, 1.0, 0.6292307470951735, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1424820.319251725, 1424820.319251724, 267921.089385599], 
processed observation next is [1.0, 0.5652173913043478, 0.8939393939393941, 0.5916666666666666, 1.0, 1.0, 0.5365384338689668, 1.0, 0.5, 0.5365384338689668, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.5277112293524907, 0.5277112293524904, 0.6534660716721927], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.6088294], dtype=float32), 0.5998568]. 
=============================================
[2019-03-23 09:04:01,551] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.1158334e-11 4.1618710e-04 3.8871806e-16 9.9958378e-01 1.5327117e-17], sum to 1.0000
[2019-03-23 09:04:01,558] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2616
[2019-03-23 09:04:01,564] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.2554251688320565, 1.0, 2.0, 0.2554251688320565, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 581521.165779402, 581521.165779402, 181007.801306062], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1371600.0000, 
sim time next is 1372200.0000, 
raw observation next is [22.0, 93.00000000000001, 1.0, 2.0, 0.2541307345559024, 1.0, 2.0, 0.2541307345559024, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 578789.6671576203, 578789.6671576203, 180579.2744650653], 
processed observation next is [1.0, 0.9130434782608695, 0.6363636363636364, 0.9300000000000002, 1.0, 1.0, 0.06766341819487799, 1.0, 1.0, 0.06766341819487799, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2143665433917112, 0.2143665433917112, 0.4404372547928422], 
reward next is 0.5596, 
noisyNet noise sample is [array([-1.9977728], dtype=float32), 0.26213333]. 
=============================================
[2019-03-23 09:04:07,145] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.0491193e-21 1.0000000e+00 2.0753024e-29 2.4169626e-14 5.2313744e-31], sum to 1.0000
[2019-03-23 09:04:07,154] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4339
[2019-03-23 09:04:07,160] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.16666666666667, 99.0, 1.0, 2.0, 0.4480995387800268, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 510800.9225733961, 510800.9225733964, 133683.7454875029], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1457400.0000, 
sim time next is 1458000.0000, 
raw observation next is [20.0, 100.0, 1.0, 2.0, 0.4459115402703866, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 508224.5579430277, 508224.5579430277, 133334.8105631761], 
processed observation next is [0.0, 0.9130434782608695, 0.5454545454545454, 1.0, 1.0, 1.0, 0.3073894253379832, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18823131775667692, 0.18823131775667692, 0.32520685503213687], 
reward next is 0.6748, 
noisyNet noise sample is [array([-0.46827352], dtype=float32), 0.9348]. 
=============================================
[2019-03-23 09:04:07,173] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[65.59812]
 [65.59812]
 [65.59812]
 [65.59812]
 [65.59812]], R is [[65.61693573]
 [65.63471222]
 [65.65143585]
 [65.66707611]
 [65.68160248]].
[2019-03-23 09:04:09,688] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.4441401e-18 1.0000000e+00 1.9609662e-26 5.6111638e-15 6.2302433e-28], sum to 1.0000
[2019-03-23 09:04:09,698] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7559
[2019-03-23 09:04:09,707] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.33333333333334, 68.66666666666667, 1.0, 2.0, 0.6045385617996863, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 679340.870090878, 679340.8700908776, 159529.7587206731], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1513200.0000, 
sim time next is 1513800.0000, 
raw observation next is [28.5, 68.0, 1.0, 2.0, 0.6058329928889745, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 680796.4859539928, 680796.4859539928, 159711.6817583812], 
processed observation next is [0.0, 0.5217391304347826, 0.9318181818181818, 0.68, 1.0, 1.0, 0.5072912411112181, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.25214684664962694, 0.25214684664962694, 0.3895406872155639], 
reward next is 0.6105, 
noisyNet noise sample is [array([1.4203762], dtype=float32), 0.2910027]. 
=============================================
[2019-03-23 09:04:17,656] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.3745275e-23 1.0000000e+00 3.6513356e-31 7.1773284e-17 1.4289162e-34], sum to 1.0000
[2019-03-23 09:04:17,664] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7106
[2019-03-23 09:04:17,671] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.5, 83.0, 1.0, 2.0, 0.6470200401942398, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 713791.1280329049, 713791.1280329049, 144848.2073124284], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1679400.0000, 
sim time next is 1680000.0000, 
raw observation next is [18.66666666666667, 81.33333333333334, 1.0, 2.0, 0.6101186935569594, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 672564.3133418888, 672564.3133418888, 140610.0202335841], 
processed observation next is [1.0, 0.43478260869565216, 0.4848484848484851, 0.8133333333333335, 1.0, 1.0, 0.5126483669461992, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2490978938303292, 0.2490978938303292, 0.34295126886240024], 
reward next is 0.6570, 
noisyNet noise sample is [array([-1.558321], dtype=float32), 0.6831153]. 
=============================================
[2019-03-23 09:04:17,688] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[65.74025]
 [65.74025]
 [65.74025]
 [65.74025]
 [65.74025]], R is [[65.73989105]
 [65.72920227]
 [65.72577667]
 [65.70527649]
 [65.71863556]].
[2019-03-23 09:04:21,639] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.8478766e-25 1.0000000e+00 1.4981556e-32 2.7621624e-23 3.5786686e-36], sum to 1.0000
[2019-03-23 09:04:21,648] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0957
[2019-03-23 09:04:21,652] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [8.5, 84.0, 1.0, 2.0, 0.3421907114532287, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 371586.0704050267, 371586.070405027, 78956.60495387542], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1747800.0000, 
sim time next is 1748400.0000, 
raw observation next is [8.666666666666668, 83.0, 1.0, 2.0, 0.3453730981471897, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 375043.1677610659, 375043.1677610659, 79193.31962710316], 
processed observation next is [1.0, 0.21739130434782608, 0.030303030303030356, 0.83, 1.0, 1.0, 0.1817163726839871, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13890487694854292, 0.13890487694854292, 0.19315443811488575], 
reward next is 0.8068, 
noisyNet noise sample is [array([0.52933306], dtype=float32), 0.5459632]. 
=============================================
[2019-03-23 09:04:21,803] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.4041570e-26 1.0000000e+00 3.9668675e-35 1.2354911e-21 2.7751969e-37], sum to 1.0000
[2019-03-23 09:04:21,819] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4325
[2019-03-23 09:04:21,827] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [9.666666666666668, 77.66666666666667, 1.0, 2.0, 0.3608267642820844, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 391831.1780391597, 391831.1780391594, 80966.35128004105], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1750800.0000, 
sim time next is 1751400.0000, 
raw observation next is [10.0, 76.0, 1.0, 2.0, 0.3676511423142717, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 399244.9903222329, 399244.9903222332, 81759.2464690666], 
processed observation next is [1.0, 0.2608695652173913, 0.09090909090909091, 0.76, 1.0, 1.0, 0.20956392789283962, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14786851493416034, 0.14786851493416045, 0.19941279626601607], 
reward next is 0.8006, 
noisyNet noise sample is [array([0.03876454], dtype=float32), -0.27395493]. 
=============================================
[2019-03-23 09:04:22,159] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.9426135e-27 1.0000000e+00 5.2426481e-36 4.0691379e-22 0.0000000e+00], sum to 1.0000
[2019-03-23 09:04:22,166] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4471
[2019-03-23 09:04:22,174] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [10.0, 76.0, 1.0, 2.0, 0.3676511423142717, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 399244.9903222329, 399244.9903222332, 81759.2464690666], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1751400.0000, 
sim time next is 1752000.0000, 
raw observation next is [10.33333333333333, 74.33333333333333, 1.0, 2.0, 0.3716242395018065, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 403561.3033840813, 403561.303384081, 82287.06323041476], 
processed observation next is [1.0, 0.2608695652173913, 0.10606060606060592, 0.7433333333333333, 1.0, 1.0, 0.21453029937725812, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1494671494015116, 0.14946714940151148, 0.2007001542205238], 
reward next is 0.7993, 
noisyNet noise sample is [array([-0.41914025], dtype=float32), -1.138575]. 
=============================================
[2019-03-23 09:04:22,186] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[84.00571]
 [84.00571]
 [84.00571]
 [84.00571]
 [84.00571]], R is [[83.96495819]
 [83.92590332]
 [83.88916779]
 [83.85542297]
 [83.82434082]].
[2019-03-23 09:04:24,985] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.0802568e-26 1.0000000e+00 4.5023603e-35 2.6441557e-21 7.0908471e-38], sum to 1.0000
[2019-03-23 09:04:24,992] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3709
[2019-03-23 09:04:25,001] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.66666666666667, 64.33333333333333, 1.0, 2.0, 0.200303200491539, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 217475.4848199889, 217475.4848199886, 69516.88564728231], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1813200.0000, 
sim time next is 1813800.0000, 
raw observation next is [14.33333333333333, 65.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 213336.9895967257, 213336.9895967254, 68667.84087212075], 
processed observation next is [1.0, 1.0, 0.28787878787878773, 0.6566666666666667, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07901369985063915, 0.07901369985063904, 0.16748253871248964], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.4556831], dtype=float32), -0.93169606]. 
=============================================
[2019-03-23 09:04:29,742] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-23 09:04:29,744] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 09:04:29,744] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 09:04:29,745] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 09:04:29,745] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:04:29,746] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:04:29,746] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 09:04:29,748] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 09:04:29,747] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:04:29,749] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:04:29,751] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:04:29,763] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run20
[2019-03-23 09:04:29,786] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run20
[2019-03-23 09:04:29,786] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run20
[2019-03-23 09:04:29,812] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run20
[2019-03-23 09:04:29,863] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run20
[2019-03-23 09:04:36,243] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.84319156]
[2019-03-23 09:04:36,244] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [17.1, 57.0, 1.0, 2.0, 0.2678014590931382, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 290765.795930357, 290765.7959303566, 82605.26385616121]
[2019-03-23 09:04:36,246] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 09:04:36,248] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.4470249e-26 1.0000000e+00 6.4780346e-35 4.6403166e-22 1.7877463e-37], sampled 0.8684255196412194
[2019-03-23 09:04:47,930] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.84319156]
[2019-03-23 09:04:47,934] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.06666666666667, 87.0, 1.0, 2.0, 0.4381413947939674, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 498301.96813501, 498301.96813501, 135707.8527579265]
[2019-03-23 09:04:47,934] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 09:04:47,936] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.4470249e-26 1.0000000e+00 6.4780346e-35 4.6403166e-22 1.7877463e-37], sampled 0.2328604214031944
[2019-03-23 09:04:49,750] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.84319156]
[2019-03-23 09:04:49,751] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [11.45430077, 63.33882088666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 197318.3965723085, 197318.3965723082, 68538.48517046886]
[2019-03-23 09:04:49,751] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 09:04:49,754] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.4470249e-26 1.0000000e+00 6.4780346e-35 4.6403166e-22 1.7877463e-37], sampled 0.3167334897092422
[2019-03-23 09:04:59,161] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.84319156]
[2019-03-23 09:04:59,165] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.71289462833333, 53.51641790166666, 1.0, 2.0, 0.3097977954611489, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 336376.1351583672, 336376.1351583676, 112594.4848825461]
[2019-03-23 09:04:59,167] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 09:04:59,170] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.4470249e-26 1.0000000e+00 6.4780346e-35 4.6403166e-22 1.7877463e-37], sampled 0.0014218651218351752
[2019-03-23 09:05:14,737] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.84319156]
[2019-03-23 09:05:14,739] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [28.96433822, 64.084641, 1.0, 2.0, 0.8145206016204538, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 916627.9919724787, 916627.9919724783, 196436.5552555469]
[2019-03-23 09:05:14,740] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 09:05:14,743] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.4470249e-26 1.0000000e+00 6.4780346e-35 4.6403166e-22 1.7877463e-37], sampled 0.5568229067673027
[2019-03-23 09:05:39,672] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.84319156]
[2019-03-23 09:05:39,673] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [25.93333333333333, 61.83333333333334, 1.0, 2.0, 0.6813967517846352, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 777530.5171053564, 777530.5171053561, 167851.2163962756]
[2019-03-23 09:05:39,675] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 09:05:39,680] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.4470249e-26 1.0000000e+00 6.4780346e-35 4.6403166e-22 1.7877463e-37], sampled 0.49257023338873773
[2019-03-23 09:05:56,391] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.84319156]
[2019-03-23 09:05:56,391] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.38333333333333, 62.16666666666666, 1.0, 2.0, 0.398555450110225, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 449012.4688915425, 449012.4688915421, 128987.6912738162]
[2019-03-23 09:05:56,392] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 09:05:56,395] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.4470249e-26 1.0000000e+00 6.4780346e-35 4.6403166e-22 1.7877463e-37], sampled 0.6540215956131001
[2019-03-23 09:06:10,928] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 09:06:10,944] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 09:06:11,193] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 09:06:11,211] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 09:06:11,299] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 09:06:12,315] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 475000, evaluation results [475000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 09:06:12,830] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.5816922e-24 1.0000000e+00 9.7323999e-35 1.3430590e-20 7.6966382e-36], sum to 1.0000
[2019-03-23 09:06:12,841] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1252
[2019-03-23 09:06:12,848] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.3592023996607954, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 403051.4319507862, 403051.4319507864, 120391.1450816176], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1915200.0000, 
sim time next is 1915800.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.4158905945458277, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 466944.0533472759, 466944.0533472757, 125439.7126391795], 
processed observation next is [1.0, 0.17391304347826086, 0.45454545454545453, 1.0, 1.0, 1.0, 0.2698632431822846, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17294224198047256, 0.17294224198047248, 0.3059505186321451], 
reward next is 0.6940, 
noisyNet noise sample is [array([-2.7074542], dtype=float32), -1.8551872]. 
=============================================
[2019-03-23 09:06:16,588] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.5647773e-30 1.0000000e+00 1.4332698e-38 4.9804353e-17 0.0000000e+00], sum to 1.0000
[2019-03-23 09:06:16,597] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7370
[2019-03-23 09:06:16,607] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.5, 62.0, 1.0, 2.0, 0.2601335005053269, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 282453.9853835198, 282453.9853835196, 84691.84510582272], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1992600.0000, 
sim time next is 1993200.0000, 
raw observation next is [18.33333333333334, 62.66666666666667, 1.0, 2.0, 0.2573277988460951, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 279406.6683137975, 279406.6683137972, 84026.98504326218], 
processed observation next is [0.0, 0.043478260869565216, 0.46969696969696995, 0.6266666666666667, 1.0, 1.0, 0.07165974855761884, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10348395122733241, 0.1034839512273323, 0.20494386595917605], 
reward next is 0.7951, 
noisyNet noise sample is [array([0.53027874], dtype=float32), -0.80037713]. 
=============================================
[2019-03-23 09:06:16,692] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.6967013e-26 1.0000000e+00 9.3537663e-37 4.1700251e-21 1.3203050e-37], sum to 1.0000
[2019-03-23 09:06:16,698] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9244
[2019-03-23 09:06:16,702] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 68.0, 1.0, 2.0, 0.2846998381492299, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 309136.6898619929, 309136.6898619926, 99028.53620547839], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2019600.0000, 
sim time next is 2020200.0000, 
raw observation next is [19.33333333333334, 66.0, 1.0, 2.0, 0.2857289041529442, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 310254.4408793982, 310254.4408793985, 99806.5143336671], 
processed observation next is [0.0, 0.391304347826087, 0.5151515151515155, 0.66, 1.0, 1.0, 0.10716113019118026, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11490905217755489, 0.114909052177555, 0.2434305227650417], 
reward next is 0.7566, 
noisyNet noise sample is [array([0.3181143], dtype=float32), -0.9258554]. 
=============================================
[2019-03-23 09:06:17,066] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.3639218e-28 1.0000000e+00 6.9634663e-38 1.6008179e-18 0.0000000e+00], sum to 1.0000
[2019-03-23 09:06:17,076] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4427
[2019-03-23 09:06:17,079] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 72.0, 1.0, 2.0, 0.23736251342592, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 257722.6065076809, 257722.6065076809, 81463.80475235176], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2004000.0000, 
sim time next is 2004600.0000, 
raw observation next is [17.0, 72.0, 1.0, 2.0, 0.2367273186361458, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 257032.7447809586, 257032.7447809589, 81392.60520600394], 
processed observation next is [0.0, 0.17391304347826086, 0.4090909090909091, 0.72, 1.0, 1.0, 0.04590914829518223, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09519731288183651, 0.09519731288183662, 0.19851854928293644], 
reward next is 0.8015, 
noisyNet noise sample is [array([0.875155], dtype=float32), -0.20362025]. 
=============================================
[2019-03-23 09:06:25,240] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.306058e-24 1.000000e+00 2.302964e-32 6.962547e-20 4.646344e-35], sum to 1.0000
[2019-03-23 09:06:25,250] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3806
[2019-03-23 09:06:25,253] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 70.5, 1.0, 2.0, 0.3118846206712691, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 341343.4787616638, 341343.4787616635, 112944.7074465485], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2158200.0000, 
sim time next is 2158800.0000, 
raw observation next is [19.33333333333334, 76.33333333333333, 1.0, 2.0, 0.3165190654116865, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 347341.5382224728, 347341.5382224731, 113610.7446882643], 
processed observation next is [0.0, 1.0, 0.5151515151515155, 0.7633333333333333, 1.0, 1.0, 0.1456488317646081, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12864501415647142, 0.12864501415647153, 0.2770993772884495], 
reward next is 0.7229, 
noisyNet noise sample is [array([0.16229422], dtype=float32), 0.7963517]. 
=============================================
[2019-03-23 09:06:25,460] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0807534e-25 1.0000000e+00 3.0512613e-37 3.1657960e-23 9.5038528e-38], sum to 1.0000
[2019-03-23 09:06:25,471] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7998
[2019-03-23 09:06:25,476] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 69.0, 1.0, 2.0, 0.4085360737322472, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 462954.4756001709, 462954.4756001712, 127149.094878632], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2148600.0000, 
sim time next is 2149200.0000, 
raw observation next is [23.0, 69.0, 1.0, 2.0, 0.4084961744728546, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 462910.4397048434, 462910.4397048437, 127146.1388577161], 
processed observation next is [0.0, 0.9130434782608695, 0.6818181818181818, 0.69, 1.0, 1.0, 0.26062021809106817, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17144831100179383, 0.17144831100179395, 0.31011253379930753], 
reward next is 0.6899, 
noisyNet noise sample is [array([1.2401193], dtype=float32), 0.9664021]. 
=============================================
[2019-03-23 09:06:30,903] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.5154678e-28 1.0000000e+00 3.5036189e-36 1.3227733e-25 0.0000000e+00], sum to 1.0000
[2019-03-23 09:06:30,911] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8794
[2019-03-23 09:06:30,916] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.83333333333333, 81.16666666666667, 1.0, 2.0, 0.2054229217181034, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 223035.4016051156, 223035.4016051153, 71551.96925056205], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2265000.0000, 
sim time next is 2265600.0000, 
raw observation next is [13.66666666666667, 80.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 212884.5506741005, 212884.5506741002, 70011.9054292216], 
processed observation next is [1.0, 0.21739130434782608, 0.25757575757575774, 0.8033333333333335, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07884612987929648, 0.07884612987929637, 0.17076074494932098], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0713782], dtype=float32), -1.2535301]. 
=============================================
[2019-03-23 09:06:36,427] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.1556325e-31 1.0000000e+00 0.0000000e+00 2.6548624e-26 0.0000000e+00], sum to 1.0000
[2019-03-23 09:06:36,435] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2250
[2019-03-23 09:06:36,441] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333334, 50.66666666666666, 1.0, 2.0, 0.2960218531902059, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 321434.5786803224, 321434.5786803224, 95334.4898168836], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2396400.0000, 
sim time next is 2397000.0000, 
raw observation next is [21.16666666666666, 51.83333333333334, 1.0, 2.0, 0.2947813684592929, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 320087.1581899276, 320087.1581899276, 95577.84068954122], 
processed observation next is [1.0, 0.7391304347826086, 0.5984848484848482, 0.5183333333333334, 1.0, 1.0, 0.11847671057411614, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1185507993296028, 0.1185507993296028, 0.23311668460863713], 
reward next is 0.7669, 
noisyNet noise sample is [array([0.2936677], dtype=float32), 0.8111825]. 
=============================================
[2019-03-23 09:06:36,459] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[75.69889]
 [75.69889]
 [75.69889]
 [75.69889]
 [75.69889]], R is [[75.70879364]
 [75.71918488]
 [75.72991943]
 [75.73714447]
 [75.72267914]].
[2019-03-23 09:06:37,699] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0870025e-22 1.0000000e+00 2.2423773e-31 4.6079027e-19 5.3820457e-35], sum to 1.0000
[2019-03-23 09:06:37,704] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8728
[2019-03-23 09:06:37,708] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 73.66666666666667, 1.0, 2.0, 0.2464109841329698, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 267549.9243910878, 267549.9243910878, 83561.92161660483], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2418000.0000, 
sim time next is 2418600.0000, 
raw observation next is [17.0, 72.83333333333333, 1.0, 2.0, 0.2423164511456874, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 263102.9298525996, 263102.9298525993, 82522.90646564662], 
processed observation next is [1.0, 1.0, 0.4090909090909091, 0.7283333333333333, 1.0, 1.0, 0.05289556393210923, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0974455295750369, 0.09744552957503677, 0.20127538162352834], 
reward next is 0.7987, 
noisyNet noise sample is [array([-1.9222633], dtype=float32), -0.9364929]. 
=============================================
[2019-03-23 09:06:37,797] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.0621732e-22 1.0000000e+00 1.3869121e-30 1.4996725e-15 1.5747563e-32], sum to 1.0000
[2019-03-23 09:06:37,806] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2868
[2019-03-23 09:06:37,814] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666667, 44.66666666666667, 1.0, 2.0, 0.6223880682586324, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 676064.9289623055, 676064.9289623053, 132770.0615431599], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2391600.0000, 
sim time next is 2392200.0000, 
raw observation next is [22.5, 45.0, 1.0, 2.0, 0.5961418675233071, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 647536.1724759445, 647536.1724759445, 128952.4893959363], 
processed observation next is [1.0, 0.6956521739130435, 0.6590909090909091, 0.45, 1.0, 1.0, 0.49517733440413386, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2398282120281276, 0.2398282120281276, 0.3145182668193568], 
reward next is 0.6855, 
noisyNet noise sample is [array([-0.15626867], dtype=float32), 0.44838354]. 
=============================================
[2019-03-23 09:06:38,002] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.3555123e-24 1.0000000e+00 2.1284061e-33 1.9144606e-17 4.4246999e-36], sum to 1.0000
[2019-03-23 09:06:38,014] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3027
[2019-03-23 09:06:38,019] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.5, 66.0, 1.0, 2.0, 0.2605537877118847, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 282910.4676285228, 282910.4676285231, 88213.56264299844], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2410200.0000, 
sim time next is 2410800.0000, 
raw observation next is [18.33333333333334, 66.66666666666666, 1.0, 2.0, 0.2614933597116897, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 283930.9569043775, 283930.9569043775, 87784.89079884066], 
processed observation next is [1.0, 0.9130434782608695, 0.46969696969696995, 0.6666666666666665, 1.0, 1.0, 0.0768666996396121, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10515961366828797, 0.10515961366828797, 0.2141094897532699], 
reward next is 0.7859, 
noisyNet noise sample is [array([-1.9057173], dtype=float32), -2.1391675]. 
=============================================
[2019-03-23 09:06:43,015] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.8704504e-29 1.0000000e+00 0.0000000e+00 4.5881653e-21 0.0000000e+00], sum to 1.0000
[2019-03-23 09:06:43,019] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0531
[2019-03-23 09:06:43,028] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 95.0, 1.0, 2.0, 0.2083818060919715, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 226248.7209504766, 226248.7209504764, 73209.14329792274], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2497800.0000, 
sim time next is 2498400.0000, 
raw observation next is [13.0, 94.0, 1.0, 2.0, 0.2045086593826978, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 222042.5259886779, 222042.5259886782, 72580.9921374485], 
processed observation next is [1.0, 0.9565217391304348, 0.22727272727272727, 0.94, 1.0, 1.0, 0.005635824228372235, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08223797258839922, 0.08223797258839932, 0.1770268100913378], 
reward next is 0.8230, 
noisyNet noise sample is [array([-1.5870817], dtype=float32), 0.713547]. 
=============================================
[2019-03-23 09:06:43,547] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.9874523e-29 1.0000000e+00 4.7937201e-37 1.2903334e-25 0.0000000e+00], sum to 1.0000
[2019-03-23 09:06:43,554] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7747
[2019-03-23 09:06:43,558] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.2117675755686463, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 229925.6593646847, 229925.6593646847, 74844.63825667983], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2508000.0000, 
sim time next is 2508600.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.2114252186914986, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 229553.8592647158, 229553.8592647155, 74824.4430869508], 
processed observation next is [1.0, 0.0, 0.22727272727272727, 1.0, 1.0, 1.0, 0.014281523364373244, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08501994787582066, 0.08501994787582055, 0.18249864167548976], 
reward next is 0.8175, 
noisyNet noise sample is [array([-0.8098755], dtype=float32), -0.6405787]. 
=============================================
[2019-03-23 09:06:44,237] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.2253071e-30 1.0000000e+00 0.0000000e+00 1.7323703e-25 0.0000000e+00], sum to 1.0000
[2019-03-23 09:06:44,250] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9041
[2019-03-23 09:06:44,263] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.2070240402884255, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 224774.1979985542, 224774.1979985544, 74355.59735226765], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2530200.0000, 
sim time next is 2530800.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.2087625751082085, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 226662.2339009699, 226662.2339009699, 74529.20109226811], 
processed observation next is [1.0, 0.30434782608695654, 0.22727272727272727, 1.0, 1.0, 1.0, 0.010953218885260615, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08394897551887774, 0.08394897551887774, 0.1817785392494344], 
reward next is 0.8182, 
noisyNet noise sample is [array([-0.53227776], dtype=float32), -0.6475581]. 
=============================================
[2019-03-23 09:06:48,575] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.5250330e-26 1.0000000e+00 2.5763600e-36 9.7983959e-23 5.9535785e-38], sum to 1.0000
[2019-03-23 09:06:48,584] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8174
[2019-03-23 09:06:48,588] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.13333333333333, 96.0, 1.0, 2.0, 0.2927701363924898, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 317902.5561637745, 317902.5561637745, 109571.290003023], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2605200.0000, 
sim time next is 2605800.0000, 
raw observation next is [16.06666666666667, 98.0, 1.0, 2.0, 0.2966953167558924, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 322166.0996132002, 322166.0996132002, 110971.1713547505], 
processed observation next is [0.0, 0.13043478260869565, 0.3666666666666668, 0.98, 1.0, 1.0, 0.12086914594486547, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11932077763451858, 0.11932077763451858, 0.270661393548172], 
reward next is 0.7293, 
noisyNet noise sample is [array([-0.533183], dtype=float32), 0.92014426]. 
=============================================
[2019-03-23 09:06:50,360] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0686488e-22 1.0000000e+00 1.4177113e-32 5.5937373e-18 4.6287441e-34], sum to 1.0000
[2019-03-23 09:06:50,370] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5312
[2019-03-23 09:06:50,373] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 45.0, 1.0, 2.0, 0.3856018309964432, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 435384.9120590008, 435384.9120590008, 124043.59398757], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2656800.0000, 
sim time next is 2657400.0000, 
raw observation next is [26.83333333333333, 45.5, 1.0, 2.0, 0.3862984705280091, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 436043.294777774, 436043.2947777743, 124032.1987508481], 
processed observation next is [0.0, 0.782608695652174, 0.8560606060606059, 0.455, 1.0, 1.0, 0.23287308816001134, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16149751658436073, 0.16149751658436085, 0.3025175579288978], 
reward next is 0.6975, 
noisyNet noise sample is [array([-0.46788248], dtype=float32), 0.51834154]. 
=============================================
[2019-03-23 09:06:51,670] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.6886116e-25 1.0000000e+00 2.6170257e-33 1.0043677e-19 5.1961378e-36], sum to 1.0000
[2019-03-23 09:06:51,676] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4645
[2019-03-23 09:06:51,681] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.8, 100.0, 1.0, 2.0, 0.3313047244367166, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 365277.1143717992, 365277.1143717992, 115316.5295712463], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2700000.0000, 
sim time next is 2700600.0000, 
raw observation next is [16.83333333333334, 100.0, 1.0, 2.0, 0.3324344190060424, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 366795.3674812024, 366795.3674812021, 115505.2731566442], 
processed observation next is [0.0, 0.2608695652173913, 0.40151515151515177, 1.0, 1.0, 1.0, 0.165543023757553, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13585013610414903, 0.13585013610414892, 0.2817201784308395], 
reward next is 0.7183, 
noisyNet noise sample is [array([-0.78998137], dtype=float32), -0.91378725]. 
=============================================
[2019-03-23 09:06:59,915] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.8576176e-18 1.0000000e+00 9.3550770e-24 3.4527335e-15 1.6547735e-26], sum to 1.0000
[2019-03-23 09:06:59,923] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8448
[2019-03-23 09:06:59,932] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1557602.906340658 W.
[2019-03-23 09:06:59,939] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.16666666666666, 51.16666666666666, 1.0, 2.0, 0.4599050209431292, 1.0, 2.0, 0.4599050209431292, 1.0, 1.0, 0.9302550158236493, 6.9112, 6.9112, 83.26111830642255, 1557602.906340658, 1557602.906340658, 338614.1370802132], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2823000.0000, 
sim time next is 2823600.0000, 
raw observation next is [29.13333333333333, 51.33333333333334, 1.0, 2.0, 0.8090347102774956, 0.0, 1.0, 0.0, 1.0, 2.0, 0.976893986228351, 6.911200000000001, 6.9112, 77.32846344354104, 1468179.279785672, 1468179.279785672, 309086.8324538447], 
processed observation next is [1.0, 0.6956521739130435, 0.9606060606060605, 0.5133333333333334, 1.0, 1.0, 0.7612933878468694, 0.0, 0.5, -0.25, 1.0, 1.0, 0.9669914088976442, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.543770103624323, 0.543770103624323, 0.7538703230581578], 
reward next is 0.2461, 
noisyNet noise sample is [array([0.18819366], dtype=float32), 0.8755322]. 
=============================================
[2019-03-23 09:07:00,607] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-23 09:07:00,610] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 09:07:00,610] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:07:00,611] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 09:07:00,611] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 09:07:00,611] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:07:00,612] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:07:00,613] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 09:07:00,614] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:07:00,614] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 09:07:00,615] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:07:00,619] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run21
[2019-03-23 09:07:00,619] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run21
[2019-03-23 09:07:00,620] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run21
[2019-03-23 09:07:00,620] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run21
[2019-03-23 09:07:00,714] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run21
[2019-03-23 09:07:03,603] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.8196473]
[2019-03-23 09:07:03,605] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [16.0, 77.0, 1.0, 2.0, 0.2291025372818392, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 248751.8262234036, 248751.8262234039, 78813.02835690317]
[2019-03-23 09:07:03,607] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 09:07:03,609] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.1664046e-24 1.0000000e+00 4.2840759e-33 1.4272213e-20 1.6182163e-35], sampled 0.4708922345565528
[2019-03-23 09:07:08,496] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.8196473]
[2019-03-23 09:07:08,496] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [13.59197047666667, 96.44102817666668, 1.0, 2.0, 0.2165957409731902, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 95.55338769695034, 235158.2423949359, 235158.2423949352, 80845.85483332015]
[2019-03-23 09:07:08,498] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 09:07:08,501] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.1664046e-24 1.0000000e+00 4.2840759e-33 1.4272213e-20 1.6182163e-35], sampled 0.6345432074913616
[2019-03-23 09:07:39,746] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.8196473]
[2019-03-23 09:07:39,748] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.15, 86.5, 1.0, 2.0, 0.4149917480335316, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 468742.038515121, 468742.038515121, 131147.2160308987]
[2019-03-23 09:07:39,749] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 09:07:39,752] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.1664046e-24 1.0000000e+00 4.2840759e-33 1.4272213e-20 1.6182163e-35], sampled 0.6631181718456114
[2019-03-23 09:08:03,193] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.8196473]
[2019-03-23 09:08:03,194] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.13271991333333, 72.59395474666667, 1.0, 2.0, 0.2978244038454229, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 323372.0182516641, 323372.0182516637, 101812.2578531405]
[2019-03-23 09:08:03,195] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 09:08:03,201] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.1664046e-24 1.0000000e+00 4.2840759e-33 1.4272213e-20 1.6182163e-35], sampled 0.3510650004925573
[2019-03-23 09:08:12,604] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.8196473]
[2019-03-23 09:08:12,606] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.1, 60.0, 1.0, 2.0, 0.2576748204016271, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 279768.2253106991, 279768.2253106994, 90645.5578682481]
[2019-03-23 09:08:12,607] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 09:08:12,609] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.1664046e-24 1.0000000e+00 4.2840759e-33 1.4272213e-20 1.6182163e-35], sampled 0.3994210169309773
[2019-03-23 09:08:43,062] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 09:08:43,249] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 09:08:43,286] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 09:08:43,307] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 09:08:43,332] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 09:08:44,346] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 500000, evaluation results [500000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 09:08:44,878] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.9782147e-22 1.0000000e+00 2.0400883e-31 4.9639238e-21 1.1570884e-33], sum to 1.0000
[2019-03-23 09:08:44,887] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9734
[2019-03-23 09:08:44,893] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333334, 86.33333333333334, 1.0, 2.0, 0.5194618011662034, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 591519.8802593278, 591519.8802593278, 140669.4037643631], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2864400.0000, 
sim time next is 2865000.0000, 
raw observation next is [21.16666666666666, 87.16666666666667, 1.0, 2.0, 0.4843002462373882, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 551287.7203528247, 551287.7203528247, 136594.2224163358], 
processed observation next is [1.0, 0.13043478260869565, 0.5984848484848482, 0.8716666666666667, 1.0, 1.0, 0.3553753077967352, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20418063716771284, 0.20418063716771284, 0.3331566400398434], 
reward next is 0.6668, 
noisyNet noise sample is [array([0.55898756], dtype=float32), 1.188205]. 
=============================================
[2019-03-23 09:08:44,908] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[64.05078]
 [64.05078]
 [64.05078]
 [64.05078]
 [64.05078]], R is [[64.07711792]
 [64.09325409]
 [64.09628296]
 [64.10868073]
 [64.10987091]].
[2019-03-23 09:08:45,769] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.0563003e-24 1.0000000e+00 1.0067311e-33 1.2063916e-22 7.2496318e-35], sum to 1.0000
[2019-03-23 09:08:45,778] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9297
[2019-03-23 09:08:45,781] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 88.0, 1.0, 2.0, 0.4238502852571249, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 482199.2471648498, 482199.2471648498, 130078.3477696952], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2871000.0000, 
sim time next is 2871600.0000, 
raw observation next is [21.0, 88.0, 1.0, 2.0, 0.4219262756220962, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 480006.6243122802, 480006.6243122802, 129885.383497385], 
processed observation next is [1.0, 0.21739130434782608, 0.5909090909090909, 0.88, 1.0, 1.0, 0.27740784452762024, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17778023122677045, 0.17778023122677045, 0.31679361828630487], 
reward next is 0.6832, 
noisyNet noise sample is [array([1.5935726], dtype=float32), -0.7762001]. 
=============================================
[2019-03-23 09:08:54,624] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.0345109e-26 1.0000000e+00 8.7624896e-35 1.4870490e-22 3.4663654e-38], sum to 1.0000
[2019-03-23 09:08:54,631] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6657
[2019-03-23 09:08:54,635] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 100.0, 1.0, 2.0, 0.3370639663936751, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 366197.7028297465, 366197.7028297468, 113812.6999178434], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3039600.0000, 
sim time next is 3040200.0000, 
raw observation next is [16.0, 100.0, 1.0, 2.0, 0.3363142610545858, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 365353.8274558698, 365353.8274558698, 113749.582951278], 
processed observation next is [1.0, 0.17391304347826086, 0.36363636363636365, 1.0, 1.0, 1.0, 0.17039282631823222, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13531623239106289, 0.13531623239106289, 0.277438007198239], 
reward next is 0.7226, 
noisyNet noise sample is [array([1.6022506], dtype=float32), 1.8564067]. 
=============================================
[2019-03-23 09:08:56,288] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.9679420e-26 1.0000000e+00 1.1759479e-31 7.5362313e-22 1.7866454e-33], sum to 1.0000
[2019-03-23 09:08:56,298] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3478
[2019-03-23 09:08:56,311] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1307706.772387185 W.
[2019-03-23 09:08:56,315] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.4, 72.0, 1.0, 2.0, 0.5815076054198531, 1.0, 2.0, 0.5815076054198531, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1307706.772387185, 1307706.772387185, 256831.8000866529], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3084000.0000, 
sim time next is 3084600.0000, 
raw observation next is [26.5, 71.5, 1.0, 2.0, 0.5814133738885859, 1.0, 2.0, 0.5814133738885859, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1307494.617883715, 1307494.617883715, 256806.0749598554], 
processed observation next is [1.0, 0.6956521739130435, 0.8409090909090909, 0.715, 1.0, 1.0, 0.4767667173607324, 1.0, 1.0, 0.4767667173607324, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.48425726588285745, 0.48425726588285745, 0.6263562803898912], 
reward next is 0.3736, 
noisyNet noise sample is [array([-0.5589681], dtype=float32), -0.64583284]. 
=============================================
[2019-03-23 09:08:59,160] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.6784122e-24 1.0000000e+00 8.4512423e-34 1.3215422e-18 3.4273065e-35], sum to 1.0000
[2019-03-23 09:08:59,167] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7147
[2019-03-23 09:08:59,173] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666666, 74.66666666666667, 1.0, 2.0, 0.5043304353681127, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 573467.8227407665, 573467.8227407665, 138201.4302227301], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3138000.0000, 
sim time next is 3138600.0000, 
raw observation next is [22.83333333333334, 73.83333333333333, 1.0, 2.0, 0.4949179404190522, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 562864.3869574672, 562864.3869574672, 137265.3712495546], 
processed observation next is [1.0, 0.30434782608695654, 0.6742424242424245, 0.7383333333333333, 1.0, 1.0, 0.3686474255238152, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2084682914657286, 0.2084682914657286, 0.3347935884135478], 
reward next is 0.6652, 
noisyNet noise sample is [array([-0.08967934], dtype=float32), -1.034853]. 
=============================================
[2019-03-23 09:09:00,326] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.8308832e-25 1.0000000e+00 7.8947000e-32 1.9015482e-25 9.0913808e-34], sum to 1.0000
[2019-03-23 09:09:00,332] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7278
[2019-03-23 09:09:00,335] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 75.5, 1.0, 2.0, 0.4469136545208308, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 509019.1656226801, 509019.1656226801, 132992.2734390685], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3177000.0000, 
sim time next is 3177600.0000, 
raw observation next is [23.0, 76.33333333333334, 1.0, 2.0, 0.4480302405945374, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 510504.3152792876, 510504.3152792876, 133369.6614618178], 
processed observation next is [1.0, 0.782608695652174, 0.6818181818181818, 0.7633333333333334, 1.0, 1.0, 0.3100378007431717, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18907567232566205, 0.18907567232566205, 0.3252918572239458], 
reward next is 0.6747, 
noisyNet noise sample is [array([0.32544616], dtype=float32), 0.8253023]. 
=============================================
[2019-03-23 09:09:00,471] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.7733993e-19 1.0000000e+00 1.6919358e-26 5.6750297e-16 8.8241024e-29], sum to 1.0000
[2019-03-23 09:09:00,479] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3348
[2019-03-23 09:09:00,489] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 83.83333333333334, 1.0, 2.0, 0.881640646716464, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1005429.352885828, 1005429.352885828, 198291.9846403073], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3156600.0000, 
sim time next is 3157200.0000, 
raw observation next is [24.0, 83.0, 1.0, 2.0, 0.9119690561403211, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1038628.273782022, 1038628.273782022, 205032.9488803367], 
processed observation next is [1.0, 0.5652173913043478, 0.7272727272727273, 0.83, 1.0, 1.0, 0.8899613201754014, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3846771384377859, 0.3846771384377859, 0.5000803631227725], 
reward next is 0.4999, 
noisyNet noise sample is [array([0.13807203], dtype=float32), -1.355609]. 
=============================================
[2019-03-23 09:09:11,661] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.2180431e-30 1.0000000e+00 1.2229513e-38 5.7450349e-24 0.0000000e+00], sum to 1.0000
[2019-03-23 09:09:11,668] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5867
[2019-03-23 09:09:11,674] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.83333333333333, 95.0, 1.0, 2.0, 0.3436018676141079, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 381941.3996080966, 381941.3996080969, 117473.2862846886], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3394200.0000, 
sim time next is 3394800.0000, 
raw observation next is [18.0, 94.0, 1.0, 2.0, 0.3450961898347979, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 383922.187497608, 383922.1874976083, 117724.6482429373], 
processed observation next is [1.0, 0.30434782608695654, 0.45454545454545453, 0.94, 1.0, 1.0, 0.18137023729349736, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14219340277689185, 0.14219340277689196, 0.28713328839740804], 
reward next is 0.7129, 
noisyNet noise sample is [array([-1.0482252], dtype=float32), -0.31177938]. 
=============================================
[2019-03-23 09:09:26,856] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.7261119e-23 1.0000000e+00 8.2094118e-31 1.5246562e-21 1.8960790e-33], sum to 1.0000
[2019-03-23 09:09:26,861] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8866
[2019-03-23 09:09:26,864] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 74.0, 1.0, 2.0, 0.4608097382047587, 1.0, 2.0, 0.4608097382047587, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1044754.465808889, 1044754.465808888, 223561.3822855654], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3673200.0000, 
sim time next is 3673800.0000, 
raw observation next is [25.5, 72.0, 1.0, 2.0, 0.834977854615002, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 950435.9605058804, 950435.9605058804, 191818.2851888698], 
processed observation next is [1.0, 0.5217391304347826, 0.7954545454545454, 0.72, 1.0, 1.0, 0.7937223182687525, 0.0, 0.5, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.35201331870588165, 0.35201331870588165, 0.46784947607041416], 
reward next is 0.5322, 
noisyNet noise sample is [array([0.6763372], dtype=float32), -1.2219584]. 
=============================================
[2019-03-23 09:09:28,532] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.2978915e-22 1.0000000e+00 3.3585657e-29 7.8937846e-20 1.8506609e-31], sum to 1.0000
[2019-03-23 09:09:28,532] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2002
[2019-03-23 09:09:28,539] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 89.0, 1.0, 2.0, 0.5241098123302486, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 597083.8918890228, 597083.8918890228, 145712.6422273233], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3715200.0000, 
sim time next is 3715800.0000, 
raw observation next is [22.83333333333334, 89.83333333333334, 1.0, 2.0, 0.522841143220128, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 595746.3977184803, 595746.3977184803, 145455.8039794979], 
processed observation next is [1.0, 0.0, 0.6742424242424245, 0.8983333333333334, 1.0, 1.0, 0.40355142902515995, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22064681396980754, 0.22064681396980754, 0.3547702536085315], 
reward next is 0.6452, 
noisyNet noise sample is [array([-0.86789185], dtype=float32), 0.00843355]. 
=============================================
[2019-03-23 09:09:31,106] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.8268304e-26 1.0000000e+00 2.0928290e-32 2.7043067e-24 7.7440210e-37], sum to 1.0000
[2019-03-23 09:09:31,114] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9884
[2019-03-23 09:09:31,120] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1201466.642509323 W.
[2019-03-23 09:09:31,125] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.16666666666666, 68.33333333333333, 1.0, 2.0, 0.3508379912143985, 1.0, 1.0, 0.3508379912143985, 1.0, 1.0, 0.7088478423549097, 6.9112, 6.9112, 77.3421103, 1201466.642509323, 1201466.642509323, 273715.7599973686], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3751800.0000, 
sim time next is 3752400.0000, 
raw observation next is [24.33333333333333, 67.66666666666667, 1.0, 2.0, 0.3541471904546583, 1.0, 2.0, 0.3541471904546583, 1.0, 2.0, 0.7164322897743537, 6.9112, 6.9112, 77.3421103, 1211973.294191585, 1211973.294191585, 276781.73445389], 
processed observation next is [1.0, 0.43478260869565216, 0.7424242424242422, 0.6766666666666667, 1.0, 1.0, 0.19268398806832288, 1.0, 1.0, 0.19268398806832288, 1.0, 1.0, 0.5949032711062197, 0.0, 0.0, 0.5085185399722538, 0.44887899784873514, 0.44887899784873514, 0.6750774011070488], 
reward next is 0.3249, 
noisyNet noise sample is [array([1.7846318], dtype=float32), -0.44345406]. 
=============================================
[2019-03-23 09:09:32,324] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.5636762e-25 1.0000000e+00 5.7599558e-32 5.1960110e-24 5.7459482e-34], sum to 1.0000
[2019-03-23 09:09:32,333] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2146
[2019-03-23 09:09:32,339] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 56.66666666666667, 1.0, 2.0, 0.2546623891940382, 1.0, 2.0, 0.2546623891940382, 1.0, 2.0, 0.5144153937763047, 6.911199999999999, 6.9112, 77.3421103, 871895.3668891581, 871895.3668891584, 239799.1519442114], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3759600.0000, 
sim time next is 3760200.0000, 
raw observation next is [26.0, 56.0, 1.0, 2.0, 0.6410260660848316, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 730653.0655017779, 730653.0655017779, 156194.4201995653], 
processed observation next is [1.0, 0.5217391304347826, 0.8181818181818182, 0.56, 1.0, 1.0, 0.5512825826060395, 0.0, 0.5, -0.25, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.27061224648214, 0.27061224648214, 0.3809620004867446], 
reward next is 0.6190, 
noisyNet noise sample is [array([-0.50719124], dtype=float32), -2.2447872]. 
=============================================
[2019-03-23 09:09:32,917] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-23 09:09:32,919] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 09:09:32,919] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:09:32,920] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 09:09:32,921] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 09:09:32,923] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 09:09:32,925] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:09:32,920] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 09:09:32,925] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:09:32,926] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:09:32,927] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:09:32,936] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run22
[2019-03-23 09:09:32,937] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run22
[2019-03-23 09:09:32,983] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run22
[2019-03-23 09:09:33,016] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run22
[2019-03-23 09:09:33,043] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run22
[2019-03-23 09:09:41,139] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.8503927]
[2019-03-23 09:09:41,140] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [25.74006606, 34.90316623, 1.0, 2.0, 0.3324862521629289, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 361018.4916492196, 361018.4916492193, 117468.0903798063]
[2019-03-23 09:09:41,142] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 09:09:41,144] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [8.7896805e-26 1.0000000e+00 7.1624147e-34 1.7008622e-23 1.6583797e-36], sampled 0.8971071002102788
[2019-03-23 09:10:17,944] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.8503927]
[2019-03-23 09:10:17,946] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.8, 83.33333333333334, 1.0, 2.0, 0.4867594333468761, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 555378.1656934883, 555378.1656934883, 143633.4722196421]
[2019-03-23 09:10:17,947] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 09:10:17,950] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [8.7896805e-26 1.0000000e+00 7.1624147e-34 1.7008622e-23 1.6583797e-36], sampled 0.287457845294562
[2019-03-23 09:10:19,575] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.8503927]
[2019-03-23 09:10:19,577] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.68333333333333, 77.16666666666667, 1.0, 2.0, 0.3812363760428005, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 427624.6554440922, 427624.6554440918, 126503.2514735462]
[2019-03-23 09:10:19,578] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 09:10:19,581] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [8.7896805e-26 1.0000000e+00 7.1624147e-34 1.7008622e-23 1.6583797e-36], sampled 0.8857266816325412
[2019-03-23 09:10:20,162] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.8503927]
[2019-03-23 09:10:20,163] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.0, 69.0, 1.0, 2.0, 0.3514755221482306, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 389980.7751934227, 389980.7751934224, 122116.2045187983]
[2019-03-23 09:10:20,164] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 09:10:20,169] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [8.7896805e-26 1.0000000e+00 7.1624147e-34 1.7008622e-23 1.6583797e-36], sampled 0.9807784174519507
[2019-03-23 09:10:22,759] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.8503927]
[2019-03-23 09:10:22,760] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.0, 81.0, 1.0, 2.0, 0.4094800247495148, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 463162.2001062285, 463162.2001062285, 131018.7459449124]
[2019-03-23 09:10:22,761] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 09:10:22,764] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [8.7896805e-26 1.0000000e+00 7.1624147e-34 1.7008622e-23 1.6583797e-36], sampled 0.885452539815177
[2019-03-23 09:10:26,335] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.8503927]
[2019-03-23 09:10:26,336] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.3, 90.0, 1.0, 2.0, 0.4808896934560999, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 548562.0276471031, 548562.0276471027, 143749.0713962083]
[2019-03-23 09:10:26,337] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 09:10:26,340] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [8.7896805e-26 1.0000000e+00 7.1624147e-34 1.7008622e-23 1.6583797e-36], sampled 0.6703729943272231
[2019-03-23 09:10:49,902] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.8503927]
[2019-03-23 09:10:49,904] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.837843975, 86.227390555, 1.0, 2.0, 0.322864101124991, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 350567.5703344854, 350567.5703344854, 109559.6207742804]
[2019-03-23 09:10:49,905] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 09:10:49,910] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [8.7896805e-26 1.0000000e+00 7.1624147e-34 1.7008622e-23 1.6583797e-36], sampled 0.5890727360001808
[2019-03-23 09:11:06,233] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.8503927]
[2019-03-23 09:11:06,236] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.13511167, 77.52526012, 1.0, 2.0, 0.6231443636174726, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 91.65462704684154, 701718.0159889078, 701718.0159889081, 151797.0000097586]
[2019-03-23 09:11:06,237] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 09:11:06,239] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [8.7896805e-26 1.0000000e+00 7.1624147e-34 1.7008622e-23 1.6583797e-36], sampled 0.311842953097199
[2019-03-23 09:11:13,366] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 09:11:13,615] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 09:11:13,740] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 09:11:13,963] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 09:11:14,033] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 09:11:15,049] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 525000, evaluation results [525000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 09:11:19,387] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.0017608e-26 1.0000000e+00 4.1463807e-33 1.6775398e-26 1.4626778e-36], sum to 1.0000
[2019-03-23 09:11:19,398] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6871
[2019-03-23 09:11:19,407] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 57.66666666666666, 1.0, 2.0, 0.346009517716915, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 384878.0177143632, 384878.0177143629, 117770.4225019575], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3862200.0000, 
sim time next is 3862800.0000, 
raw observation next is [23.0, 57.0, 1.0, 2.0, 0.3428234960435284, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 380750.8517801742, 380750.8517801742, 117276.5092325533], 
processed observation next is [0.0, 0.7391304347826086, 0.6818181818181818, 0.57, 1.0, 1.0, 0.1785293700544105, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1410188339926571, 0.1410188339926571, 0.2860402664208617], 
reward next is 0.7140, 
noisyNet noise sample is [array([-1.0853106], dtype=float32), -0.09400376]. 
=============================================
[2019-03-23 09:11:20,665] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.1651533e-29 1.0000000e+00 8.8856881e-35 6.3923180e-26 0.0000000e+00], sum to 1.0000
[2019-03-23 09:11:20,675] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9659
[2019-03-23 09:11:20,681] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.25, 81.0, 1.0, 2.0, 0.2696518106823413, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 292792.1152899305, 292792.1152899302, 96526.00521144077], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3904200.0000, 
sim time next is 3904800.0000, 
raw observation next is [17.16666666666666, 81.33333333333334, 1.0, 2.0, 0.268146327420212, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 291156.9489101655, 291156.9489101658, 95777.29397225968], 
processed observation next is [0.0, 0.17391304347826086, 0.4166666666666664, 0.8133333333333335, 1.0, 1.0, 0.08518290927526498, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10783590700376501, 0.10783590700376512, 0.23360315602990164], 
reward next is 0.7664, 
noisyNet noise sample is [array([2.0755548], dtype=float32), 0.60713]. 
=============================================
[2019-03-23 09:11:21,709] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.7537256e-27 1.0000000e+00 3.4528169e-35 7.1808904e-24 2.4601599e-38], sum to 1.0000
[2019-03-23 09:11:21,719] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9288
[2019-03-23 09:11:21,722] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 77.0, 1.0, 2.0, 0.2807665859427075, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 304864.4932518947, 304864.4932518947, 101571.9620143177], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3897600.0000, 
sim time next is 3898200.0000, 
raw observation next is [18.0, 77.0, 1.0, 2.0, 0.2807091101047064, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 304802.0647644539, 304802.0647644539, 101571.1596409499], 
processed observation next is [0.0, 0.08695652173913043, 0.45454545454545453, 0.77, 1.0, 1.0, 0.10088638763088298, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11288965361646441, 0.11288965361646441, 0.2477345357096339], 
reward next is 0.7523, 
noisyNet noise sample is [array([-0.43408418], dtype=float32), -0.014651817]. 
=============================================
[2019-03-23 09:11:29,396] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.1527635e-26 1.0000000e+00 4.8004959e-35 4.4914754e-24 2.7619649e-36], sum to 1.0000
[2019-03-23 09:11:29,405] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6196
[2019-03-23 09:11:29,412] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 100.0, 1.0, 2.0, 0.30588027435917, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 332143.2399115372, 332143.2399115369, 111588.839162521], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4061400.0000, 
sim time next is 4062000.0000, 
raw observation next is [16.0, 100.0, 1.0, 2.0, 0.3059268126916925, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 332193.5273246546, 332193.5273246549, 111591.8855501155], 
processed observation next is [1.0, 0.0, 0.36363636363636365, 1.0, 1.0, 1.0, 0.13240851586461558, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12303463974987208, 0.1230346397498722, 0.2721753306100378], 
reward next is 0.7278, 
noisyNet noise sample is [array([1.1822096], dtype=float32), 0.73253936]. 
=============================================
[2019-03-23 09:11:29,427] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[69.99874]
 [69.99874]
 [69.99874]
 [69.99874]
 [69.99874]], R is [[70.02657318]
 [70.05413818]
 [70.08119965]
 [70.1072464 ]
 [70.13227844]].
[2019-03-23 09:11:32,889] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.3987547e-26 1.0000000e+00 2.5186404e-34 6.2502854e-21 1.1337849e-36], sum to 1.0000
[2019-03-23 09:11:32,898] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4464
[2019-03-23 09:11:32,902] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 78.0, 1.0, 2.0, 0.8697955568366578, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 989368.5760312235, 989368.5760312235, 187568.9011136238], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4120200.0000, 
sim time next is 4120800.0000, 
raw observation next is [22.0, 78.0, 1.0, 2.0, 0.8789356742713679, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 999797.2242921592, 999797.2242921594, 189061.949737734], 
processed observation next is [1.0, 0.6956521739130435, 0.6363636363636364, 0.78, 1.0, 1.0, 0.8486695928392098, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3702952682563553, 0.37029526825635534, 0.46112670667739997], 
reward next is 0.5389, 
noisyNet noise sample is [array([-0.5294118], dtype=float32), -1.2556125]. 
=============================================
[2019-03-23 09:11:33,813] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.8882877e-29 1.0000000e+00 9.3248070e-36 3.7975859e-23 0.0000000e+00], sum to 1.0000
[2019-03-23 09:11:33,822] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6843
[2019-03-23 09:11:33,830] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.5, 97.0, 1.0, 2.0, 0.3842472208977088, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 432301.5592585017, 432301.559258502, 123080.0084221991], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4134600.0000, 
sim time next is 4135200.0000, 
raw observation next is [18.33333333333334, 98.0, 1.0, 2.0, 0.3837876212881342, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 431518.7293759552, 431518.7293759552, 122904.6229171995], 
processed observation next is [1.0, 0.8695652173913043, 0.46969696969696995, 0.98, 1.0, 1.0, 0.22973452661016774, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15982175162072415, 0.15982175162072415, 0.29976737296877926], 
reward next is 0.7002, 
noisyNet noise sample is [array([0.64278716], dtype=float32), 1.6968341]. 
=============================================
[2019-03-23 09:11:36,854] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.7857928e-21 1.0000000e+00 5.8670725e-30 4.5715158e-21 3.8845438e-31], sum to 1.0000
[2019-03-23 09:11:36,861] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6329
[2019-03-23 09:11:36,865] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.33333333333333, 85.5, 1.0, 2.0, 0.3641662861324883, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 407150.983673771, 407150.983673771, 120114.7412731171], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4225800.0000, 
sim time next is 4226400.0000, 
raw observation next is [19.0, 88.0, 1.0, 2.0, 0.3632247883867044, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 405960.2554352916, 405960.2554352913, 119974.8684751069], 
processed observation next is [1.0, 0.9565217391304348, 0.5, 0.88, 1.0, 1.0, 0.2040309854833805, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15035565016121913, 0.15035565016121902, 0.29262163042709], 
reward next is 0.7074, 
noisyNet noise sample is [array([-0.19935964], dtype=float32), 0.17247905]. 
=============================================
[2019-03-23 09:11:37,429] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.4525732e-27 1.0000000e+00 3.3187578e-34 3.9634842e-25 6.9508637e-37], sum to 1.0000
[2019-03-23 09:11:37,436] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6872
[2019-03-23 09:11:37,440] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333334, 73.0, 1.0, 2.0, 0.3844906782220136, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 431805.3185267684, 431805.3185267684, 122715.1479238668], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4218000.0000, 
sim time next is 4218600.0000, 
raw observation next is [21.16666666666666, 73.0, 1.0, 2.0, 0.378727191226867, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 424544.932875402, 424544.9328754023, 121838.807441044], 
processed observation next is [1.0, 0.8260869565217391, 0.5984848484848482, 0.73, 1.0, 1.0, 0.22340898903358372, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15723886402792667, 0.15723886402792678, 0.2971678230269366], 
reward next is 0.7028, 
noisyNet noise sample is [array([-0.8102362], dtype=float32), 0.29878277]. 
=============================================
[2019-03-23 09:11:43,536] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.0906490e-26 1.0000000e+00 9.0073489e-36 8.4352455e-24 1.2398483e-37], sum to 1.0000
[2019-03-23 09:11:43,537] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0437
[2019-03-23 09:11:43,540] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.5, 94.0, 1.0, 2.0, 0.3864839696130355, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 432829.0669179867, 432829.0669179867, 122313.5165214459], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4343400.0000, 
sim time next is 4344000.0000, 
raw observation next is [18.66666666666667, 94.0, 1.0, 2.0, 0.389265114785499, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 436823.5125136708, 436823.5125136708, 122964.8118921362], 
processed observation next is [1.0, 0.2608695652173913, 0.4848484848484851, 0.94, 1.0, 1.0, 0.23658139348187376, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16178648611617436, 0.16178648611617436, 0.2999141753466737], 
reward next is 0.7001, 
noisyNet noise sample is [array([0.5057185], dtype=float32), -0.14086302]. 
=============================================
[2019-03-23 09:11:43,556] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[67.299995]
 [67.299995]
 [67.299995]
 [67.299995]
 [67.299995]], R is [[67.32709503]
 [67.35549927]
 [67.38480377]
 [67.41295624]
 [67.45069885]].
[2019-03-23 09:11:43,750] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.9579373e-26 1.0000000e+00 2.0737063e-34 2.1528440e-20 2.8608017e-37], sum to 1.0000
[2019-03-23 09:11:43,756] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9588
[2019-03-23 09:11:43,762] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 94.0, 1.0, 2.0, 0.3960666193696721, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 446102.7050707072, 446102.7050707072, 124382.0525247961], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4345200.0000, 
sim time next is 4345800.0000, 
raw observation next is [19.33333333333334, 92.16666666666667, 1.0, 2.0, 0.4007372324115107, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 451971.2740533173, 451971.2740533173, 125126.0474606362], 
processed observation next is [1.0, 0.30434782608695654, 0.5151515151515155, 0.9216666666666667, 1.0, 1.0, 0.25092154051438836, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1673967681678953, 0.1673967681678953, 0.3051854816113078], 
reward next is 0.6948, 
noisyNet noise sample is [array([0.39795187], dtype=float32), -0.10907274]. 
=============================================
[2019-03-23 09:11:47,740] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.4993142e-24 1.0000000e+00 1.7882274e-33 1.2399069e-19 1.2485826e-35], sum to 1.0000
[2019-03-23 09:11:47,750] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0774
[2019-03-23 09:11:47,753] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 74.0, 1.0, 2.0, 0.468714417457864, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 534800.426693026, 534800.426693026, 137007.194379862], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4444200.0000, 
sim time next is 4444800.0000, 
raw observation next is [24.0, 74.0, 1.0, 2.0, 0.470540942097966, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 536885.8649978008, 536885.8649978008, 137208.9191908331], 
processed observation next is [0.0, 0.43478260869565216, 0.7272727272727273, 0.74, 1.0, 1.0, 0.33817617762245744, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19884661666585216, 0.19884661666585216, 0.33465590046544663], 
reward next is 0.6653, 
noisyNet noise sample is [array([0.13603798], dtype=float32), 1.1696898]. 
=============================================
[2019-03-23 09:11:50,365] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.1733344e-27 1.0000000e+00 5.3234845e-35 2.8508976e-23 0.0000000e+00], sum to 1.0000
[2019-03-23 09:11:50,375] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2008
[2019-03-23 09:11:50,381] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 80.5, 1.0, 2.0, 0.4780033534584129, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 545401.8148420979, 545401.8148420979, 138014.8854261381], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4476600.0000, 
sim time next is 4477200.0000, 
raw observation next is [23.0, 79.66666666666667, 1.0, 2.0, 0.4749819198278054, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 541890.5315922427, 541890.5315922427, 137432.8325566737], 
processed observation next is [0.0, 0.8260869565217391, 0.6818181818181818, 0.7966666666666667, 1.0, 1.0, 0.34372739978475675, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20070019688601579, 0.20070019688601579, 0.33520203062603343], 
reward next is 0.6648, 
noisyNet noise sample is [array([-0.73694235], dtype=float32), -1.6788708]. 
=============================================
[2019-03-23 09:11:50,868] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.08438991e-26 1.00000000e+00 1.35044740e-34 1.13096306e-23
 9.40783248e-38], sum to 1.0000
[2019-03-23 09:11:50,876] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3675
[2019-03-23 09:11:50,878] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.66666666666667, 94.0, 1.0, 2.0, 0.4553378588981704, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 518974.290113049, 518974.290113049, 134322.613904694], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4497600.0000, 
sim time next is 4498200.0000, 
raw observation next is [20.5, 94.0, 1.0, 2.0, 0.4499717501016298, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 512566.4781352606, 512566.4781352606, 133382.0111200084], 
processed observation next is [0.0, 0.043478260869565216, 0.5681818181818182, 0.94, 1.0, 1.0, 0.3124646876270372, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1898394363463928, 0.1898394363463928, 0.3253219783414839], 
reward next is 0.6747, 
noisyNet noise sample is [array([-0.28961042], dtype=float32), 0.9510472]. 
=============================================
[2019-03-23 09:11:51,265] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.8367257e-27 1.0000000e+00 5.8835559e-34 5.7660220e-25 1.4638883e-37], sum to 1.0000
[2019-03-23 09:11:51,273] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6033
[2019-03-23 09:11:51,278] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.4108307524719665, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 465714.7829021846, 465714.7829021843, 127473.5912206645], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4512000.0000, 
sim time next is 4512600.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4102723363730022, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 465080.7400785494, 465080.7400785494, 127420.1688710968], 
processed observation next is [0.0, 0.21739130434782608, 0.5, 1.0, 1.0, 1.0, 0.2628404204662527, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1722521259550183, 0.1722521259550183, 0.31078089968560196], 
reward next is 0.6892, 
noisyNet noise sample is [array([-0.15891092], dtype=float32), 1.5144308]. 
=============================================
[2019-03-23 09:11:52,369] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.7820591e-24 1.0000000e+00 1.8700756e-33 1.9041187e-24 1.9468020e-36], sum to 1.0000
[2019-03-23 09:11:52,376] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1256
[2019-03-23 09:11:52,383] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.4098430832789998, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 464593.2439358046, 464593.2439358046, 127379.0569858848], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4513200.0000, 
sim time next is 4513800.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4104279738055529, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 465256.892634132, 465256.892634132, 127434.6689618438], 
processed observation next is [0.0, 0.21739130434782608, 0.5, 1.0, 1.0, 1.0, 0.2630349672569411, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17231736764227112, 0.17231736764227112, 0.3108162657605946], 
reward next is 0.6892, 
noisyNet noise sample is [array([-0.3360964], dtype=float32), 0.23241016]. 
=============================================
[2019-03-23 09:11:54,478] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.7674791e-27 1.0000000e+00 1.3839240e-33 2.5962174e-23 3.8867553e-37], sum to 1.0000
[2019-03-23 09:11:54,492] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1308
[2019-03-23 09:11:54,497] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.83333333333333, 62.33333333333334, 1.0, 2.0, 0.3947118286507442, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 446507.3845521062, 446507.3845521065, 125357.2879931465], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4549800.0000, 
sim time next is 4550400.0000, 
raw observation next is [24.0, 61.0, 1.0, 2.0, 0.3928323945068219, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 444171.1683943663, 444171.1683943666, 125057.320835738], 
processed observation next is [0.0, 0.6956521739130435, 0.7272727272727273, 0.61, 1.0, 1.0, 0.24104049313352735, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1645078401460616, 0.1645078401460617, 0.30501785569692197], 
reward next is 0.6950, 
noisyNet noise sample is [array([-1.5115509], dtype=float32), 0.1626599]. 
=============================================
[2019-03-23 09:12:01,304] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.2904261e-25 1.0000000e+00 2.2085176e-35 5.1486796e-23 8.7179660e-38], sum to 1.0000
[2019-03-23 09:12:01,311] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8639
[2019-03-23 09:12:01,315] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 88.0, 1.0, 2.0, 0.2033944833552235, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 220832.5497463337, 220832.5497463337, 73508.93495731181], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4681800.0000, 
sim time next is 4682400.0000, 
raw observation next is [14.0, 88.0, 1.0, 2.0, 0.2020576372338743, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 219380.7615362569, 219380.7615362566, 73352.30860109697], 
processed observation next is [1.0, 0.17391304347826086, 0.2727272727272727, 0.88, 1.0, 1.0, 0.0025720465423428526, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08125213390231738, 0.08125213390231727, 0.1789080697587731], 
reward next is 0.8211, 
noisyNet noise sample is [array([1.1949303], dtype=float32), -0.810754]. 
=============================================
[2019-03-23 09:12:03,254] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-23 09:12:03,256] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 09:12:03,257] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:12:03,258] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 09:12:03,260] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:12:03,260] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 09:12:03,261] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:12:03,261] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 09:12:03,262] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 09:12:03,265] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:12:03,267] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:12:03,275] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run23
[2019-03-23 09:12:03,301] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run23
[2019-03-23 09:12:03,302] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run23
[2019-03-23 09:12:03,350] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run23
[2019-03-23 09:12:03,352] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run23
[2019-03-23 09:12:07,046] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.823783]
[2019-03-23 09:12:07,047] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [16.93333333333334, 60.00000000000001, 1.0, 2.0, 0.2443036347900591, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 265247.3718607881, 265247.3718607877, 81112.44189513718]
[2019-03-23 09:12:07,047] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 09:12:07,051] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.4930734e-24 1.0000000e+00 5.7038495e-32 2.9441127e-22 2.2685032e-34], sampled 0.9917354728983585
[2019-03-23 09:12:20,323] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.823783]
[2019-03-23 09:12:20,324] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.0, 100.0, 1.0, 2.0, 0.4504728830951305, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 513477.1154204404, 513477.1154204407, 133885.5646368802]
[2019-03-23 09:12:20,325] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 09:12:20,328] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.4930734e-24 1.0000000e+00 5.7038495e-32 2.9441127e-22 2.2685032e-34], sampled 0.8183792119104963
[2019-03-23 09:12:24,406] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.823783]
[2019-03-23 09:12:24,407] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [12.5, 91.0, 1.0, 2.0, 0.4384379172198824, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 476152.4194818587, 476152.4194818587, 94518.8340625178]
[2019-03-23 09:12:24,408] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 09:12:24,412] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.4930734e-24 1.0000000e+00 5.7038495e-32 2.9441127e-22 2.2685032e-34], sampled 0.8770087102244728
[2019-03-23 09:12:25,218] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.823783]
[2019-03-23 09:12:25,219] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.0, 90.0, 1.0, 2.0, 0.4005415812715564, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 453444.5774144678, 453444.5774144674, 130438.3802546984]
[2019-03-23 09:12:25,220] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 09:12:25,223] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.4930734e-24 1.0000000e+00 5.7038495e-32 2.9441127e-22 2.2685032e-34], sampled 0.33553872602707446
[2019-03-23 09:12:39,373] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.823783]
[2019-03-23 09:12:39,374] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.46037268166667, 65.02719479833334, 1.0, 2.0, 0.4969629384811529, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 550883.8195246012, 550883.8195246012, 134633.9975218797]
[2019-03-23 09:12:39,376] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 09:12:39,379] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.4930734e-24 1.0000000e+00 5.7038495e-32 2.9441127e-22 2.2685032e-34], sampled 0.002805227223933171
[2019-03-23 09:12:50,182] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.823783]
[2019-03-23 09:12:50,184] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.55, 65.5, 1.0, 2.0, 0.3519416936217365, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 390586.6136605112, 390586.6136605112, 122188.8334215929]
[2019-03-23 09:12:50,184] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 09:12:50,187] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.4930734e-24 1.0000000e+00 5.7038495e-32 2.9441127e-22 2.2685032e-34], sampled 0.5029062385785026
[2019-03-23 09:12:50,376] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.823783]
[2019-03-23 09:12:50,379] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.750371905, 76.375794025, 1.0, 2.0, 0.3249393095490021, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 358942.5786651337, 358942.5786651337, 119430.843439724]
[2019-03-23 09:12:50,380] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 09:12:50,385] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.4930734e-24 1.0000000e+00 5.7038495e-32 2.9441127e-22 2.2685032e-34], sampled 0.324654732506065
[2019-03-23 09:12:55,144] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.823783]
[2019-03-23 09:12:55,146] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [15.52371075666667, 99.84553070000001, 1.0, 2.0, 0.3244843344824503, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 352327.3440920977, 352327.3440920981, 112608.273779492]
[2019-03-23 09:12:55,147] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 09:12:55,149] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.4930734e-24 1.0000000e+00 5.7038495e-32 2.9441127e-22 2.2685032e-34], sampled 0.6790784787814846
[2019-03-23 09:12:55,410] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.823783]
[2019-03-23 09:12:55,411] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.15, 79.0, 1.0, 2.0, 0.5238887924048583, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 597233.4607290818, 597233.4607290818, 149485.0483172321]
[2019-03-23 09:12:55,412] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 09:12:55,415] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.4930734e-24 1.0000000e+00 5.7038495e-32 2.9441127e-22 2.2685032e-34], sampled 0.8404600663908657
[2019-03-23 09:12:55,701] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.823783]
[2019-03-23 09:12:55,703] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.0, 94.0, 1.0, 2.0, 0.3832407976131949, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 431681.2738447824, 431681.2738447824, 123260.037591858]
[2019-03-23 09:12:55,704] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 09:12:55,706] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.4930734e-24 1.0000000e+00 5.7038495e-32 2.9441127e-22 2.2685032e-34], sampled 0.8199503647265519
[2019-03-23 09:13:09,964] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.823783]
[2019-03-23 09:13:09,964] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [27.7, 64.33333333333334, 1.0, 2.0, 0.8576098177053382, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9816960162959669, 6.911200000000001, 6.9112, 77.32846344354104, 1517624.602623265, 1517624.602623265, 322302.210803256]
[2019-03-23 09:13:09,965] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 09:13:09,966] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.4930734e-24 1.0000000e+00 5.7038495e-32 2.9441127e-22 2.2685032e-34], sampled 0.9173440776162208
[2019-03-23 09:13:09,968] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1517624.602623265 W.
[2019-03-23 09:13:30,469] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.823783]
[2019-03-23 09:13:30,470] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.6, 76.66666666666667, 1.0, 2.0, 0.3207690153621643, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 348292.0557918848, 348292.0557918848, 116913.4711487732]
[2019-03-23 09:13:30,474] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 09:13:30,480] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.4930734e-24 1.0000000e+00 5.7038495e-32 2.9441127e-22 2.2685032e-34], sampled 0.03215057511899988
[2019-03-23 09:13:42,156] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.823783]
[2019-03-23 09:13:42,158] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.45516322, 55.84583932, 1.0, 2.0, 0.3384564659635075, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 367503.0202731399, 367503.0202731396, 118041.1751367361]
[2019-03-23 09:13:42,159] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 09:13:42,162] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.4930734e-24 1.0000000e+00 5.7038495e-32 2.9441127e-22 2.2685032e-34], sampled 0.10163150284036526
[2019-03-23 09:13:43,668] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 09:13:43,901] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 09:13:44,287] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 09:13:44,305] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 09:13:44,311] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 09:13:45,325] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 550000, evaluation results [550000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 09:13:46,656] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.2840140e-25 1.0000000e+00 4.3231624e-34 7.3884902e-23 1.4476395e-37], sum to 1.0000
[2019-03-23 09:13:46,662] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2883
[2019-03-23 09:13:46,669] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 88.0, 1.0, 2.0, 0.3631303394337053, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 405833.5393905484, 405833.5393905484, 119957.6590568011], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4758000.0000, 
sim time next is 4758600.0000, 
raw observation next is [19.0, 88.0, 1.0, 2.0, 0.3626766045012074, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 405324.367637117, 405324.3676371168, 119919.4738540799], 
processed observation next is [1.0, 0.043478260869565216, 0.5, 0.88, 1.0, 1.0, 0.20334575562650925, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15012013616189518, 0.15012013616189512, 0.29248652159531685], 
reward next is 0.7075, 
noisyNet noise sample is [array([1.1136154], dtype=float32), -0.20091107]. 
=============================================
[2019-03-23 09:13:50,661] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.3236860e-26 1.0000000e+00 1.3264622e-32 5.6906614e-23 6.4076173e-36], sum to 1.0000
[2019-03-23 09:13:50,669] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9735
[2019-03-23 09:13:50,681] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 94.0, 1.0, 2.0, 0.4584146713378101, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 522853.4984641196, 522853.4984641196, 135293.59213965], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4833600.0000, 
sim time next is 4834200.0000, 
raw observation next is [21.0, 94.0, 1.0, 2.0, 0.4575363539416665, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 521850.6426261462, 521850.6426261465, 135198.4198459811], 
processed observation next is [1.0, 0.9565217391304348, 0.5909090909090909, 0.94, 1.0, 1.0, 0.32192044242708306, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19327801578746157, 0.19327801578746168, 0.3297522435267831], 
reward next is 0.6702, 
noisyNet noise sample is [array([-0.21570104], dtype=float32), -1.7585223]. 
=============================================
[2019-03-23 09:13:56,073] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.5722569e-26 1.0000000e+00 1.2137740e-35 4.7291922e-27 1.9595493e-37], sum to 1.0000
[2019-03-23 09:13:56,079] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0035
[2019-03-23 09:13:56,083] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.16666666666667, 99.0, 1.0, 2.0, 0.3537028632409793, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 392024.791997204, 392024.7919972037, 117800.658323981], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4938600.0000, 
sim time next is 4939200.0000, 
raw observation next is [17.0, 100.0, 1.0, 2.0, 0.3492402483905765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 386673.2163324216, 386673.2163324219, 117290.8920068568], 
processed observation next is [1.0, 0.17391304347826086, 0.4090909090909091, 1.0, 1.0, 1.0, 0.1865503104882206, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14321230234534132, 0.14321230234534144, 0.2860753463581873], 
reward next is 0.7139, 
noisyNet noise sample is [array([0.4121633], dtype=float32), 0.14029714]. 
=============================================
[2019-03-23 09:14:06,027] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.2926722e-27 1.0000000e+00 1.5540505e-37 5.3440970e-27 4.3225271e-38], sum to 1.0000
[2019-03-23 09:14:06,033] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8201
[2019-03-23 09:14:06,038] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.16666666666667, 81.33333333333334, 1.0, 2.0, 0.4321557188523262, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 492225.4812296815, 492225.4812296818, 131509.1027836364], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5093400.0000, 
sim time next is 5094000.0000, 
raw observation next is [22.0, 83.0, 1.0, 2.0, 0.4343683393135458, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 494853.9342894226, 494853.9342894226, 131864.178794653], 
processed observation next is [0.0, 1.0, 0.6363636363636364, 0.83, 1.0, 1.0, 0.2929604241419322, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18327923492200837, 0.18327923492200837, 0.32161994827964147], 
reward next is 0.6784, 
noisyNet noise sample is [array([-1.3140885], dtype=float32), 0.33759645]. 
=============================================
[2019-03-23 09:14:06,051] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[66.09367]
 [66.09367]
 [66.09367]
 [66.09367]
 [66.09367]], R is [[66.11112976]
 [66.12926483]
 [66.14805603]
 [66.16751099]
 [66.18767548]].
[2019-03-23 09:14:08,191] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.00092995e-25 1.00000000e+00 3.98019742e-32 1.53282991e-24
 1.18009775e-35], sum to 1.0000
[2019-03-23 09:14:08,201] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8010
[2019-03-23 09:14:08,206] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.16666666666667, 78.0, 1.0, 2.0, 0.4654792641437596, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 531004.2848767013, 531004.2848767013, 136274.4534781997], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5169000.0000, 
sim time next is 5169600.0000, 
raw observation next is [23.0, 78.0, 1.0, 2.0, 0.4588233498149162, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 523258.6840499657, 523258.6840499657, 135207.232910274], 
processed observation next is [0.0, 0.8695652173913043, 0.6818181818181818, 0.78, 1.0, 1.0, 0.3235291872686452, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1937995126110984, 0.1937995126110984, 0.32977373880554633], 
reward next is 0.6702, 
noisyNet noise sample is [array([-0.43318897], dtype=float32), -1.2415074]. 
=============================================
[2019-03-23 09:14:09,836] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.5189906e-28 1.0000000e+00 6.4238894e-37 1.5864101e-26 1.9179928e-38], sum to 1.0000
[2019-03-23 09:14:09,843] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3260
[2019-03-23 09:14:09,851] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 83.0, 1.0, 2.0, 0.4412704759960847, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 502755.9283099325, 502755.9283099325, 132614.7566862504], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5184600.0000, 
sim time next is 5185200.0000, 
raw observation next is [22.0, 83.0, 1.0, 2.0, 0.4404041906871755, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 501764.9781219977, 501764.9781219977, 132521.1973821438], 
processed observation next is [1.0, 0.0, 0.6363636363636364, 0.83, 1.0, 1.0, 0.30050523835896936, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18583888078592506, 0.18583888078592506, 0.3232224326393751], 
reward next is 0.6768, 
noisyNet noise sample is [array([0.39502254], dtype=float32), 0.07532089]. 
=============================================
[2019-03-23 09:14:11,601] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.8036147e-25 1.0000000e+00 3.0489172e-33 2.5503093e-22 1.3154256e-34], sum to 1.0000
[2019-03-23 09:14:11,619] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1912
[2019-03-23 09:14:11,624] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 88.5, 1.0, 2.0, 0.8072304215933338, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 921475.5291335761, 921475.5291335761, 183070.0347987501], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5214600.0000, 
sim time next is 5215200.0000, 
raw observation next is [21.66666666666667, 90.33333333333334, 1.0, 2.0, 0.8169610223539685, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 932576.3018310582, 932576.3018310582, 184349.4468426277], 
processed observation next is [1.0, 0.34782608695652173, 0.6212121212121214, 0.9033333333333334, 1.0, 1.0, 0.7712012779424606, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3453986303077993, 0.3453986303077993, 0.4496327971771407], 
reward next is 0.5504, 
noisyNet noise sample is [array([-1.6632166], dtype=float32), 1.8849031]. 
=============================================
[2019-03-23 09:14:14,035] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.6050685e-32 1.0000000e+00 3.4578601e-38 1.4703240e-30 0.0000000e+00], sum to 1.0000
[2019-03-23 09:14:14,042] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7821
[2019-03-23 09:14:14,048] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.01666666666667, 100.0, 1.0, 2.0, 0.4889945972144421, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 557894.0362499807, 557894.0362499804, 140303.0975449777], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5267400.0000, 
sim time next is 5268000.0000, 
raw observation next is [20.93333333333334, 100.0, 1.0, 2.0, 0.4850366772313476, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 553424.0663068227, 553424.0663068227, 139674.2190693858], 
processed observation next is [1.0, 1.0, 0.5878787878787882, 1.0, 1.0, 1.0, 0.35629584653918445, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20497187640993433, 0.20497187640993433, 0.340668826998502], 
reward next is 0.6593, 
noisyNet noise sample is [array([0.7511431], dtype=float32), -1.1328686]. 
=============================================
[2019-03-23 09:14:14,062] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[68.535225]
 [68.535225]
 [68.535225]
 [68.535225]
 [68.535225]], R is [[68.50920868]
 [68.48191833]
 [68.45336914]
 [68.42370605]
 [68.393013  ]].
[2019-03-23 09:14:17,585] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.6277547e-21 1.0000000e+00 9.9058515e-29 1.8233491e-20 5.1309561e-30], sum to 1.0000
[2019-03-23 09:14:17,594] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7020
[2019-03-23 09:14:17,598] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.1, 54.0, 1.0, 2.0, 0.4210021116400395, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 478378.1768656651, 478378.1768656651, 129285.0406540036], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5345400.0000, 
sim time next is 5346000.0000, 
raw observation next is [26.1, 54.0, 1.0, 2.0, 0.4188533316751809, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 475932.556197922, 475932.556197922, 129072.9868929396], 
processed observation next is [1.0, 0.9130434782608695, 0.8227272727272728, 0.54, 1.0, 1.0, 0.2735666645939761, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17627131711034147, 0.17627131711034147, 0.31481216315351124], 
reward next is 0.6852, 
noisyNet noise sample is [array([-2.2503793], dtype=float32), 0.76175356]. 
=============================================
[2019-03-23 09:14:17,616] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[51.560078]
 [51.560078]
 [51.560078]
 [51.560078]
 [51.560078]], R is [[51.72966003]
 [51.89703369]
 [52.06216049]
 [52.22527313]
 [52.38685608]].
[2019-03-23 09:14:24,562] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.1020047e-25 1.0000000e+00 8.7656408e-33 4.6258799e-21 1.1887053e-34], sum to 1.0000
[2019-03-23 09:14:24,570] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2242
[2019-03-23 09:14:24,577] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1165742.265883505 W.
[2019-03-23 09:14:24,581] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.23333333333333, 76.66666666666666, 1.0, 2.0, 0.9956294139663969, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.002231540776014, 6.9112, 77.32828281800357, 1165742.265883505, 1136177.152415463, 218304.2961322994], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5481600.0000, 
sim time next is 5482200.0000, 
raw observation next is [24.61666666666667, 75.33333333333334, 1.0, 2.0, 0.5477078580728221, 1.0, 1.0, 0.5477078580728221, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.3284087418987, 1244415.099856319, 1244415.099856319, 243885.2550910682], 
processed observation next is [1.0, 0.43478260869565216, 0.7553030303030305, 0.7533333333333334, 1.0, 1.0, 0.43463482259102754, 1.0, 0.5, 0.43463482259102754, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084284532614828, 0.4608944814282663, 0.4608944814282663, 0.5948420855879712], 
reward next is 0.4052, 
noisyNet noise sample is [array([-0.19768189], dtype=float32), 1.247081]. 
=============================================
[2019-03-23 09:14:26,695] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.3366170e-23 1.0000000e+00 1.2752334e-31 3.4887147e-25 9.9992600e-34], sum to 1.0000
[2019-03-23 09:14:26,702] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1823
[2019-03-23 09:14:26,705] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.33333333333334, 58.00000000000001, 1.0, 2.0, 0.4918127134501564, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 561071.2110116729, 561071.2110116729, 140739.7032051233], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5509200.0000, 
sim time next is 5509800.0000, 
raw observation next is [27.15, 58.5, 1.0, 2.0, 0.4866346816660133, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 555213.6905209704, 555213.6905209702, 139989.2334989726], 
processed observation next is [1.0, 0.782608695652174, 0.8704545454545454, 0.585, 1.0, 1.0, 0.3582933520825166, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.205634700192952, 0.2056347001929519, 0.34143715487554294], 
reward next is 0.6586, 
noisyNet noise sample is [array([0.3832591], dtype=float32), 0.120769404]. 
=============================================
[2019-03-23 09:14:27,953] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.5738278e-29 1.0000000e+00 9.6699549e-38 1.3750094e-26 0.0000000e+00], sum to 1.0000
[2019-03-23 09:14:27,966] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8796
[2019-03-23 09:14:27,971] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 93.0, 1.0, 2.0, 0.4207316437082938, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 477614.1585766813, 477614.1585766813, 128899.1751771813], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5547000.0000, 
sim time next is 5547600.0000, 
raw observation next is [20.0, 93.0, 1.0, 2.0, 0.4205589934641715, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 477415.7067656251, 477415.7067656251, 128880.6403929763], 
processed observation next is [1.0, 0.21739130434782608, 0.5454545454545454, 0.93, 1.0, 1.0, 0.27569874183021437, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1768206321354167, 0.1768206321354167, 0.3143430253487227], 
reward next is 0.6857, 
noisyNet noise sample is [array([1.4630816], dtype=float32), -1.015593]. 
=============================================
[2019-03-23 09:14:28,178] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.2243557e-23 1.0000000e+00 9.5112081e-32 1.3891324e-20 4.2267373e-35], sum to 1.0000
[2019-03-23 09:14:28,182] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9429
[2019-03-23 09:14:28,186] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 93.0, 1.0, 2.0, 0.4205589934641715, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 477415.7067656251, 477415.7067656251, 128880.6403929763], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5547600.0000, 
sim time next is 5548200.0000, 
raw observation next is [20.08333333333334, 92.5, 1.0, 2.0, 0.4279802564110227, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 485904.5644636375, 485904.5644636375, 129649.9669244974], 
processed observation next is [1.0, 0.21739130434782608, 0.5492424242424245, 0.925, 1.0, 1.0, 0.2849753205137784, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17996465350505092, 0.17996465350505092, 0.3162194315231644], 
reward next is 0.6838, 
noisyNet noise sample is [array([-0.6201329], dtype=float32), -1.4669099]. 
=============================================
[2019-03-23 09:14:29,279] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.9769427e-22 1.0000000e+00 2.9549375e-29 2.0436605e-19 6.1031579e-32], sum to 1.0000
[2019-03-23 09:14:29,284] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5631
[2019-03-23 09:14:29,289] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.16666666666667, 92.0, 1.0, 2.0, 0.4165408001200906, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 472974.0394364214, 472974.0394364214, 128585.1290687598], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5548800.0000, 
sim time next is 5549400.0000, 
raw observation next is [20.25, 91.5, 1.0, 2.0, 0.4138982131295499, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 470031.5191800321, 470031.5191800324, 128376.5311259326], 
processed observation next is [1.0, 0.21739130434782608, 0.5568181818181818, 0.915, 1.0, 1.0, 0.2673727664119373, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17408574784445632, 0.17408574784445646, 0.31311349055105514], 
reward next is 0.6869, 
noisyNet noise sample is [array([1.9547408], dtype=float32), 0.40100265]. 
=============================================
[2019-03-23 09:14:31,100] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.2987501e-21 1.0000000e+00 3.3300656e-29 3.6023281e-18 5.0755913e-30], sum to 1.0000
[2019-03-23 09:14:31,105] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3519
[2019-03-23 09:14:31,112] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 92.5, 1.0, 2.0, 0.3925075496852522, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 443177.1012022761, 443177.1012022761, 124658.9178786978], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5615400.0000, 
sim time next is 5616000.0000, 
raw observation next is [19.4, 93.0, 1.0, 2.0, 0.3945933573752975, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 445773.5756164278, 445773.5756164278, 124986.3211270023], 
processed observation next is [0.0, 0.0, 0.5181818181818181, 0.93, 1.0, 1.0, 0.24324169671912185, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16510132430238067, 0.16510132430238067, 0.30484468567561535], 
reward next is 0.6952, 
noisyNet noise sample is [array([0.20116656], dtype=float32), -0.96954566]. 
=============================================
[2019-03-23 09:14:31,126] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[54.619038]
 [54.619038]
 [54.619038]
 [54.619038]
 [54.619038]], R is [[54.76800156]
 [54.91627502]
 [55.06379318]
 [55.21043015]
 [55.35610199]].
[2019-03-23 09:14:33,248] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.5007728e-29 1.0000000e+00 1.0317909e-37 1.5687182e-25 0.0000000e+00], sum to 1.0000
[2019-03-23 09:14:33,254] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3287
[2019-03-23 09:14:33,259] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.18333333333333, 96.16666666666666, 1.0, 2.0, 0.3049890157795872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 331174.8649201381, 331174.8649201384, 111526.4342166994], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5647800.0000, 
sim time next is 5648400.0000, 
raw observation next is [16.1, 96.0, 1.0, 2.0, 0.301172453081669, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 327029.2250260085, 327029.2250260088, 109585.0841047266], 
processed observation next is [0.0, 0.391304347826087, 0.3681818181818182, 0.96, 1.0, 1.0, 0.12646556635208625, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12112193519481797, 0.12112193519481806, 0.26728069293835754], 
reward next is 0.7327, 
noisyNet noise sample is [array([0.9526919], dtype=float32), 0.1752151]. 
=============================================
[2019-03-23 09:14:33,831] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 09:14:33,832] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 09:14:33,833] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:14:33,833] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 09:14:33,835] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 09:14:33,835] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:14:33,838] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 09:14:33,837] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 09:14:33,842] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:14:33,840] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:14:33,843] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:14:33,865] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run24
[2019-03-23 09:14:33,888] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run24
[2019-03-23 09:14:33,913] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run24
[2019-03-23 09:14:33,914] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run24
[2019-03-23 09:14:33,937] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run24
[2019-03-23 09:15:05,796] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.8849735]
[2019-03-23 09:15:05,797] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.8, 82.0, 1.0, 2.0, 0.4372772297667574, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 497515.7316624434, 497515.7316624434, 135806.4377533683]
[2019-03-23 09:15:05,799] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 09:15:05,802] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [6.7875441e-29 1.0000000e+00 6.1268861e-38 2.2179245e-26 0.0000000e+00], sampled 0.47397608910171585
[2019-03-23 09:15:06,996] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.8849735]
[2019-03-23 09:15:06,997] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.0, 78.83333333333333, 1.0, 2.0, 0.4674376969662648, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 533189.4610160324, 533189.4610160324, 136355.9693005353]
[2019-03-23 09:15:06,998] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 09:15:07,003] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [6.7875441e-29 1.0000000e+00 6.1268861e-38 2.2179245e-26 0.0000000e+00], sampled 0.8619602171925584
[2019-03-23 09:15:55,311] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.8849735]
[2019-03-23 09:15:55,312] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.06666666666667, 95.33333333333334, 1.0, 2.0, 0.6834428178958118, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 765757.4943209735, 765757.4943209735, 153570.9900295718]
[2019-03-23 09:15:55,314] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 09:15:55,318] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [6.7875441e-29 1.0000000e+00 6.1268861e-38 2.2179245e-26 0.0000000e+00], sampled 0.6809046399838934
[2019-03-23 09:16:06,551] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.8849735]
[2019-03-23 09:16:06,552] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [12.5, 86.0, 1.0, 2.0, 0.3309238478638498, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 73.25608018679945, 359354.2052670437, 359354.205267044, 79608.42313774547]
[2019-03-23 09:16:06,553] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 09:16:06,559] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [6.7875441e-29 1.0000000e+00 6.1268861e-38 2.2179245e-26 0.0000000e+00], sampled 0.9540638939247746
[2019-03-23 09:16:13,738] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 09:16:14,239] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 09:16:14,414] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 09:16:14,566] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 09:16:14,597] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 09:16:15,609] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 575000, evaluation results [575000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 09:16:20,853] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.1344382e-21 1.0000000e+00 4.8545621e-28 9.1649176e-20 1.3067958e-30], sum to 1.0000
[2019-03-23 09:16:20,862] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1824
[2019-03-23 09:16:20,877] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.96666666666667, 42.66666666666667, 1.0, 2.0, 0.2757069897808853, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 299368.9462176558, 299368.9462176558, 87227.64018173213], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5766000.0000, 
sim time next is 5766600.0000, 
raw observation next is [21.78333333333333, 43.33333333333334, 1.0, 2.0, 0.2737883277812601, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 297284.9824468756, 297284.9824468759, 86756.40332568494], 
processed observation next is [0.0, 0.7391304347826086, 0.6265151515151515, 0.4333333333333334, 1.0, 1.0, 0.09223540972657512, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11010554905439837, 0.11010554905439848, 0.21160098372118277], 
reward next is 0.7884, 
noisyNet noise sample is [array([-0.10000021], dtype=float32), 0.7518263]. 
=============================================
[2019-03-23 09:16:22,361] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.1744338e-29 1.0000000e+00 2.8681791e-36 3.4487319e-30 0.0000000e+00], sum to 1.0000
[2019-03-23 09:16:22,369] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0700197e-29 1.0000000e+00 0.0000000e+00 1.5953273e-23 0.0000000e+00], sum to 1.0000
[2019-03-23 09:16:22,372] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8374
[2019-03-23 09:16:22,379] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0763
[2019-03-23 09:16:22,380] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 81.5, 1.0, 2.0, 0.3629273424178603, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 394113.1749814787, 394113.1749814787, 85691.16614391125], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5797800.0000, 
sim time next is 5798400.0000, 
raw observation next is [12.9, 81.0, 1.0, 2.0, 0.3578041610633465, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 388547.5430676473, 388547.5430676473, 84920.06824422709], 
processed observation next is [1.0, 0.08695652173913043, 0.22272727272727275, 0.81, 1.0, 1.0, 0.19725520132918312, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14390649743246198, 0.14390649743246198, 0.20712211766884656], 
reward next is 0.7929, 
noisyNet noise sample is [array([0.0924058], dtype=float32), -0.74717635]. 
=============================================
[2019-03-23 09:16:22,386] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.5, 70.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 214761.4136587094, 214761.4136587097, 71460.52794240239], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5815800.0000, 
sim time next is 5816400.0000, 
raw observation next is [15.86666666666667, 68.33333333333333, 1.0, 2.0, 0.2005355490297918, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 217727.8093963733, 217727.8093963735, 72197.15840289826], 
processed observation next is [1.0, 0.30434782608695654, 0.35757575757575777, 0.6833333333333332, 1.0, 1.0, 0.0006694362872397205, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0806399294060642, 0.08063992940606425, 0.17609063025097138], 
reward next is 0.8239, 
noisyNet noise sample is [array([-1.1393404], dtype=float32), -1.4530578]. 
=============================================
[2019-03-23 09:16:28,620] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.1833872e-26 1.0000000e+00 9.4162843e-35 6.3569254e-22 3.8044316e-37], sum to 1.0000
[2019-03-23 09:16:28,628] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2702
[2019-03-23 09:16:28,636] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.86666666666667, 64.0, 1.0, 2.0, 0.6714110526212647, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 761898.2864375802, 761898.2864375802, 157194.519573323], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5912400.0000, 
sim time next is 5913000.0000, 
raw observation next is [24.15, 63.0, 1.0, 2.0, 0.6754525330341429, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 766963.0789225155, 766963.0789225152, 158062.9995277061], 
processed observation next is [1.0, 0.43478260869565216, 0.734090909090909, 0.63, 1.0, 1.0, 0.5943156662926785, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.28406039960093166, 0.28406039960093155, 0.3855195110431856], 
reward next is 0.6145, 
noisyNet noise sample is [array([-1.0965095], dtype=float32), 0.68452495]. 
=============================================
[2019-03-23 09:16:28,644] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.6524562e-25 1.0000000e+00 6.5791449e-35 1.1576909e-22 1.6327187e-36], sum to 1.0000
[2019-03-23 09:16:28,649] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[69.894684]
 [69.894684]
 [69.894684]
 [69.894684]
 [69.894684]], R is [[69.81021881]
 [69.72871399]
 [69.63404846]
 [69.52708435]
 [69.42992401]].
[2019-03-23 09:16:28,656] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7455
[2019-03-23 09:16:28,662] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.15, 63.0, 1.0, 2.0, 0.6754525330341429, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 766963.0789225155, 766963.0789225152, 158062.9995277061], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5913000.0000, 
sim time next is 5913600.0000, 
raw observation next is [24.43333333333333, 62.0, 1.0, 2.0, 0.7110039358398923, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 807897.455366777, 807897.4553667767, 163248.0598391758], 
processed observation next is [1.0, 0.43478260869565216, 0.7469696969696968, 0.62, 1.0, 1.0, 0.6387549197998654, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.29922127976547297, 0.29922127976547286, 0.3981659996077459], 
reward next is 0.6018, 
noisyNet noise sample is [array([-0.18369485], dtype=float32), 0.5242085]. 
=============================================
[2019-03-23 09:16:29,011] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.9271093e-25 1.0000000e+00 7.4924141e-34 2.4671051e-23 2.8356722e-36], sum to 1.0000
[2019-03-23 09:16:29,019] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7302
[2019-03-23 09:16:29,029] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1082765.067759395 W.
[2019-03-23 09:16:29,035] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.7, 46.0, 1.0, 2.0, 0.3161300920269883, 1.0, 2.0, 0.3161300920269883, 1.0, 1.0, 0.6371896590135978, 6.911199999999999, 6.9112, 77.3421103, 1082765.067759395, 1082765.067759396, 258169.9626147925], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5932800.0000, 
sim time next is 5933400.0000, 
raw observation next is [27.61666666666667, 46.16666666666667, 1.0, 2.0, 0.5517478644515135, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9596599683934608, 6.918326272693262, 6.9112, 77.32844468395014, 1177357.138930493, 1175042.671878685, 256984.3449835102], 
processed observation next is [1.0, 0.6956521739130435, 0.8916666666666668, 0.4616666666666667, 1.0, 1.0, 0.4396848305643918, 0.0, 0.5, -0.25, 1.0, 1.0, 0.9423713834192297, 0.0007126272693262159, 0.0, 0.5084286895777593, 0.4360581996038863, 0.43520098958469816, 0.6267910853256347], 
reward next is 0.3376, 
noisyNet noise sample is [array([-0.40309143], dtype=float32), 1.5315896]. 
=============================================
[2019-03-23 09:16:29,395] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.8577973e-25 1.0000000e+00 6.0941255e-34 7.1017020e-23 1.6888651e-35], sum to 1.0000
[2019-03-23 09:16:29,407] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8699
[2019-03-23 09:16:29,409] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.9460126e-26 1.0000000e+00 3.0905445e-34 8.5031189e-25 9.6903802e-37], sum to 1.0000
[2019-03-23 09:16:29,410] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.26666666666667, 53.66666666666667, 1.0, 2.0, 0.5628267027525216, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.328463443541, 640206.7508944831, 640206.7508944831, 145019.7491981916], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5920800.0000, 
sim time next is 5921400.0000, 
raw observation next is [26.18333333333334, 53.83333333333333, 1.0, 2.0, 0.5657377083904859, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 643371.2593676709, 643371.2593676709, 145235.5310907398], 
processed observation next is [1.0, 0.5217391304347826, 0.8265151515151519, 0.5383333333333333, 1.0, 1.0, 0.4571721354881073, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23828565161765589, 0.23828565161765589, 0.35423300266034097], 
reward next is 0.6458, 
noisyNet noise sample is [array([-0.64850724], dtype=float32), -1.0543959]. 
=============================================
[2019-03-23 09:16:29,415] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7924
[2019-03-23 09:16:29,421] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.18333333333334, 53.83333333333333, 1.0, 2.0, 0.5657377034408299, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 643371.259367616, 643371.259367616, 145235.5353048422], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5921400.0000, 
sim time next is 5922000.0000, 
raw observation next is [26.1, 54.0, 1.0, 2.0, 0.6127165179168178, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 696720.3893834555, 696720.3893834555, 150856.3935973761], 
processed observation next is [1.0, 0.5652173913043478, 0.8227272727272728, 0.54, 1.0, 1.0, 0.5158956473960222, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2580445886605391, 0.2580445886605391, 0.36794242340823435], 
reward next is 0.6321, 
noisyNet noise sample is [array([-0.35713893], dtype=float32), -0.7954848]. 
=============================================
[2019-03-23 09:16:29,437] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[60.12737]
 [60.12737]
 [60.12737]
 [60.12737]
 [60.12737]], R is [[60.15815735]
 [60.20234299]
 [60.24661255]
 [60.28844452]
 [60.31072998]].
[2019-03-23 09:16:46,997] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.9367186e-26 1.0000000e+00 4.5912164e-34 3.0080304e-27 8.4877702e-37], sum to 1.0000
[2019-03-23 09:16:47,004] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3456
[2019-03-23 09:16:47,011] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.33333333333334, 65.0, 1.0, 2.0, 0.5303177893912231, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 602414.6830748884, 602414.6830748884, 147606.7978033309], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6265200.0000, 
sim time next is 6265800.0000, 
raw observation next is [27.7, 63.0, 1.0, 2.0, 0.5308039224285933, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 602961.6500184381, 602961.6500184379, 147670.2308377319], 
processed observation next is [0.0, 0.5217391304347826, 0.8954545454545454, 0.63, 1.0, 1.0, 0.4135049030357416, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22331912963645856, 0.22331912963645847, 0.3601712947261754], 
reward next is 0.6398, 
noisyNet noise sample is [array([0.552869], dtype=float32), 0.03423427]. 
=============================================
[2019-03-23 09:16:47,773] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.4330480e-24 1.0000000e+00 5.0744634e-32 1.1962006e-21 1.9493390e-33], sum to 1.0000
[2019-03-23 09:16:47,781] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4962
[2019-03-23 09:16:47,788] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.4, 75.0, 1.0, 2.0, 0.4865634296742667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 555093.126277018, 555093.1262770178, 140100.7429755303], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6305400.0000, 
sim time next is 6306000.0000, 
raw observation next is [24.2, 76.33333333333333, 1.0, 2.0, 0.486715783787588, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 555264.5444125591, 555264.5444125589, 140125.0009931829], 
processed observation next is [0.0, 1.0, 0.7363636363636363, 0.7633333333333333, 1.0, 1.0, 0.358394729734485, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2056535349676145, 0.2056535349676144, 0.3417682951053242], 
reward next is 0.6582, 
noisyNet noise sample is [array([-0.23414606], dtype=float32), 0.026229424]. 
=============================================
[2019-03-23 09:16:47,808] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[64.289825]
 [64.289825]
 [64.289825]
 [64.289825]
 [64.289825]], R is [[64.30516052]
 [64.32040405]
 [64.33552551]
 [64.35049438]
 [64.3651886 ]].
[2019-03-23 09:16:52,583] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.0692129e-24 1.0000000e+00 5.7774030e-33 1.7148916e-20 1.1480964e-34], sum to 1.0000
[2019-03-23 09:16:52,592] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4946
[2019-03-23 09:16:52,594] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 63.0, 1.0, 2.0, 0.5566576726741328, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 631169.8408765283, 631169.8408765281, 151464.6630192412], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6363000.0000, 
sim time next is 6363600.0000, 
raw observation next is [28.1, 62.33333333333333, 1.0, 2.0, 0.5550341871386186, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 629433.2856455931, 629433.2856455933, 151212.7632846793], 
processed observation next is [0.0, 0.6521739130434783, 0.9136363636363637, 0.6233333333333333, 1.0, 1.0, 0.44379273392327323, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.23312343912799743, 0.23312343912799752, 0.3688116177675105], 
reward next is 0.6312, 
noisyNet noise sample is [array([-1.3619354], dtype=float32), 1.3798285]. 
=============================================
[2019-03-23 09:16:55,558] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.7138655e-25 1.0000000e+00 5.2148316e-33 1.0109695e-23 4.0227939e-35], sum to 1.0000
[2019-03-23 09:16:55,562] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4085
[2019-03-23 09:16:55,566] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.4, 74.0, 1.0, 2.0, 0.4862861872565398, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 554857.0319315863, 554857.0319315863, 139786.643496403], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6422400.0000, 
sim time next is 6423000.0000, 
raw observation next is [23.93333333333333, 76.83333333333334, 1.0, 2.0, 0.5371093847793537, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 612893.0468344424, 612893.0468344424, 145706.0724052248], 
processed observation next is [1.0, 0.34782608695652173, 0.7242424242424241, 0.7683333333333334, 1.0, 1.0, 0.42138673097419205, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22699742475349718, 0.22699742475349718, 0.3553806644029873], 
reward next is 0.6446, 
noisyNet noise sample is [array([-0.3060908], dtype=float32), 0.042495802]. 
=============================================
[2019-03-23 09:16:55,602] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[62.630386]
 [62.630386]
 [62.630386]
 [62.630386]
 [62.630386]], R is [[62.64870071]
 [62.6812706 ]
 [62.7130394 ]
 [62.73860931]
 [62.75270844]].
[2019-03-23 09:17:01,715] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.963213e-32 1.000000e+00 0.000000e+00 7.504132e-29 0.000000e+00], sum to 1.0000
[2019-03-23 09:17:01,724] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7513
[2019-03-23 09:17:01,730] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.41666666666667, 48.5, 1.0, 2.0, 0.562697743071198, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 611185.9362566015, 611185.9362566015, 122212.1300585798], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6540600.0000, 
sim time next is 6541200.0000, 
raw observation next is [21.6, 48.0, 1.0, 2.0, 0.5918044673325569, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 642821.7224539116, 642821.7224539116, 126078.1651311931], 
processed observation next is [1.0, 0.7391304347826086, 0.6181818181818183, 0.48, 1.0, 1.0, 0.48975558416569603, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23808211942737464, 0.23808211942737464, 0.3075077198321783], 
reward next is 0.6925, 
noisyNet noise sample is [array([1.5333228], dtype=float32), 0.080970116]. 
=============================================
[2019-03-23 09:17:03,813] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.7968482e-26 1.0000000e+00 1.9920285e-34 9.3359019e-23 3.0773888e-36], sum to 1.0000
[2019-03-23 09:17:03,821] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9211
[2019-03-23 09:17:03,827] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.03333333333333, 83.66666666666666, 1.0, 2.0, 0.2157777058408246, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 234280.6882257441, 234280.6882257441, 76541.46298161396], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6594600.0000, 
sim time next is 6595200.0000, 
raw observation next is [15.5, 81.0, 1.0, 2.0, 0.2224167895274722, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 241490.8641678469, 241490.8641678472, 77881.63002415113], 
processed observation next is [1.0, 0.34782608695652173, 0.3409090909090909, 0.81, 1.0, 1.0, 0.028020986909340247, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08944106080290626, 0.08944106080290637, 0.18995519518085643], 
reward next is 0.8100, 
noisyNet noise sample is [array([1.8575455], dtype=float32), 0.8324039]. 
=============================================
[2019-03-23 09:17:03,970] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-23 09:17:03,974] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 09:17:03,975] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:17:03,977] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 09:17:03,977] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:17:03,978] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 09:17:03,978] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 09:17:03,979] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:17:03,979] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:17:03,979] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 09:17:03,980] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:17:03,993] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run25
[2019-03-23 09:17:04,016] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run25
[2019-03-23 09:17:04,048] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run25
[2019-03-23 09:17:04,075] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run25
[2019-03-23 09:17:04,076] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run25
[2019-03-23 09:17:05,349] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.9481832]
[2019-03-23 09:17:05,350] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.33333333333334, 81.33333333333334, 1.0, 2.0, 0.8112725979908038, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 921555.8633433699, 921555.8633433699, 177445.6787898057]
[2019-03-23 09:17:05,352] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 09:17:05,354] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.5198535e-25 1.0000000e+00 3.0136031e-33 4.0376855e-23 9.0182816e-36], sampled 0.9852189010549474
[2019-03-23 09:17:09,875] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.9481832]
[2019-03-23 09:17:09,876] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [11.44920707, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 177370.4146117835, 177370.4146117835, 67922.2450203509]
[2019-03-23 09:17:09,877] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 09:17:09,880] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.5198535e-25 1.0000000e+00 3.0136031e-33 4.0376855e-23 9.0182816e-36], sampled 0.4377408280223569
[2019-03-23 09:17:13,062] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.9481832]
[2019-03-23 09:17:13,064] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [13.98333333333333, 74.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 211374.5500954687, 211374.5500954687, 73658.45612283565]
[2019-03-23 09:17:13,065] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 09:17:13,067] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.5198535e-25 1.0000000e+00 3.0136031e-33 4.0376855e-23 9.0182816e-36], sampled 0.15052109081715148
[2019-03-23 09:17:28,629] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.9481832]
[2019-03-23 09:17:28,629] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.76666666666667, 38.0, 1.0, 2.0, 0.3052633773269734, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 95.55338769695034, 331451.3400986727, 331451.340098672, 93912.40959643359]
[2019-03-23 09:17:28,630] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 09:17:28,633] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.5198535e-25 1.0000000e+00 3.0136031e-33 4.0376855e-23 9.0182816e-36], sampled 0.9627076025311265
[2019-03-23 09:17:28,722] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.9481832]
[2019-03-23 09:17:28,722] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [15.08333333333333, 88.66666666666667, 1.0, 2.0, 0.2420915940632858, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 262858.7180223242, 262858.7180223242, 82062.48784461642]
[2019-03-23 09:17:28,723] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 09:17:28,724] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.5198535e-25 1.0000000e+00 3.0136031e-33 4.0376855e-23 9.0182816e-36], sampled 0.3595437563601268
[2019-03-23 09:17:57,275] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.9481832]
[2019-03-23 09:17:57,276] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [29.86822271666666, 45.57372923333334, 1.0, 2.0, 0.7546946063853093, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 861274.8983930392, 861274.8983930392, 179719.7717172774]
[2019-03-23 09:17:57,276] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 09:17:57,282] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.5198535e-25 1.0000000e+00 3.0136031e-33 4.0376855e-23 9.0182816e-36], sampled 0.739135404287035
[2019-03-23 09:17:57,632] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.9481832]
[2019-03-23 09:17:57,633] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.06666666666667, 83.66666666666666, 1.0, 2.0, 0.5444590957176855, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 619211.6717280447, 619211.6717280447, 153259.2867391706]
[2019-03-23 09:17:57,634] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 09:17:57,637] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.5198535e-25 1.0000000e+00 3.0136031e-33 4.0376855e-23 9.0182816e-36], sampled 0.9565775651723866
[2019-03-23 09:17:58,093] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.9481832]
[2019-03-23 09:17:58,094] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.6, 80.33333333333334, 1.0, 2.0, 0.5371857949719604, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 610880.5368950946, 610880.5368950942, 152378.4443841743]
[2019-03-23 09:17:58,095] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 09:17:58,098] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.5198535e-25 1.0000000e+00 3.0136031e-33 4.0376855e-23 9.0182816e-36], sampled 0.923420831446429
[2019-03-23 09:18:02,667] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.9481832]
[2019-03-23 09:18:02,668] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.0, 94.0, 1.0, 2.0, 0.4367853189075134, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8842289259769016, 6.911199999999999, 6.9112, 77.3284448718039, 995482.3985982698, 995482.39859827, 239542.5208431712]
[2019-03-23 09:18:02,669] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 09:18:02,672] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.5198535e-25 1.0000000e+00 3.0136031e-33 4.0376855e-23 9.0182816e-36], sampled 0.7845937697900726
[2019-03-23 09:18:34,334] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.9481832]
[2019-03-23 09:18:34,335] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.33333333333334, 78.33333333333334, 1.0, 2.0, 0.5659779906120725, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 645763.9646560154, 645763.964656015, 152637.4858750561]
[2019-03-23 09:18:34,336] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 09:18:34,341] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.5198535e-25 1.0000000e+00 3.0136031e-33 4.0376855e-23 9.0182816e-36], sampled 0.8236091184558286
[2019-03-23 09:18:44,949] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 09:18:44,975] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 09:18:45,105] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 09:18:45,125] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 09:18:45,147] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 09:18:46,166] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 600000, evaluation results [600000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 09:18:59,995] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0103462e-28 1.0000000e+00 1.0192490e-37 2.2702006e-26 0.0000000e+00], sum to 1.0000
[2019-03-23 09:19:00,009] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1503
[2019-03-23 09:19:00,014] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.73333333333333, 51.33333333333333, 1.0, 2.0, 0.4483185407266065, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 511277.345659726, 511277.3456597257, 134103.2364093869], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6874800.0000, 
sim time next is 6875400.0000, 
raw observation next is [28.01666666666667, 50.16666666666667, 1.0, 2.0, 0.4489230770831815, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 511995.1692648393, 511995.1692648393, 134225.3021221694], 
processed observation next is [0.0, 0.5652173913043478, 0.909848484848485, 0.5016666666666667, 1.0, 1.0, 0.31115384635397686, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.189627840468459, 0.189627840468459, 0.32737878566382783], 
reward next is 0.6726, 
noisyNet noise sample is [array([-0.7743365], dtype=float32), 0.13581288]. 
=============================================
[2019-03-23 09:19:03,462] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.0733499e-27 1.0000000e+00 1.7870662e-35 5.6879672e-24 2.5012205e-37], sum to 1.0000
[2019-03-23 09:19:03,470] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2513
[2019-03-23 09:19:03,477] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 90.0, 1.0, 2.0, 0.3734225184289738, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 418722.3849495394, 418722.3849495394, 121447.6801483327], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6925200.0000, 
sim time next is 6925800.0000, 
raw observation next is [18.9, 90.0, 1.0, 2.0, 0.3713057975886481, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 415842.4556389913, 415842.4556389913, 121030.2956738246], 
processed observation next is [0.0, 0.13043478260869565, 0.49545454545454537, 0.9, 1.0, 1.0, 0.21413224698581013, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15401572431073754, 0.15401572431073754, 0.2951958431068893], 
reward next is 0.7048, 
noisyNet noise sample is [array([-1.0413727], dtype=float32), 2.3963552]. 
=============================================
[2019-03-23 09:19:06,230] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.9194912e-25 1.0000000e+00 1.5840640e-33 9.9411099e-26 1.7204414e-35], sum to 1.0000
[2019-03-23 09:19:06,232] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7314
[2019-03-23 09:19:06,240] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.1, 56.66666666666667, 1.0, 2.0, 0.5097602823928854, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 580993.9911681822, 580993.9911681825, 143712.1417489722], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6967200.0000, 
sim time next is 6967800.0000, 
raw observation next is [28.0, 57.0, 1.0, 2.0, 0.5077266587197536, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 578725.3312198841, 578725.3312198845, 143413.3084323728], 
processed observation next is [0.0, 0.6521739130434783, 0.9090909090909091, 0.57, 1.0, 1.0, 0.384658323399692, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21434271526662374, 0.21434271526662388, 0.3497885571521288], 
reward next is 0.6502, 
noisyNet noise sample is [array([0.48091403], dtype=float32), 1.2500927]. 
=============================================
[2019-03-23 09:19:14,005] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.75101914e-26 1.00000000e+00 2.08103771e-33 1.10002914e-23
 4.78398578e-36], sum to 1.0000
[2019-03-23 09:19:14,016] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7406
[2019-03-23 09:19:14,021] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.83333333333333, 70.66666666666667, 1.0, 2.0, 0.7012188591395021, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 790043.8865358015, 790043.8865358018, 157840.1666906551], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7123800.0000, 
sim time next is 7124400.0000, 
raw observation next is [22.2, 68.0, 1.0, 2.0, 0.7103365014447159, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 800136.7178523237, 800136.7178523237, 158934.3629023109], 
processed observation next is [1.0, 0.4782608695652174, 0.6454545454545454, 0.68, 1.0, 1.0, 0.6379206268058948, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2963469325378977, 0.2963469325378977, 0.38764478756661197], 
reward next is 0.6124, 
noisyNet noise sample is [array([0.15159762], dtype=float32), 0.55066824]. 
=============================================
[2019-03-23 09:19:16,410] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.5088321e-33 1.0000000e+00 0.0000000e+00 1.1326892e-32 0.0000000e+00], sum to 1.0000
[2019-03-23 09:19:16,416] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5972
[2019-03-23 09:19:16,423] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.5, 78.0, 1.0, 2.0, 0.220767808806341, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 239700.0285763683, 239700.0285763683, 76508.2122914095], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7171200.0000, 
sim time next is 7171800.0000, 
raw observation next is [15.41666666666667, 77.83333333333333, 1.0, 2.0, 0.2191348962369152, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 237926.6499096643, 237926.649909664, 75998.97051359413], 
processed observation next is [1.0, 0.0, 0.33712121212121227, 0.7783333333333333, 1.0, 1.0, 0.023918620296143993, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08812098144802381, 0.0881209814480237, 0.18536334271608326], 
reward next is 0.8146, 
noisyNet noise sample is [array([-0.8753966], dtype=float32), -2.028587]. 
=============================================
[2019-03-23 09:19:17,779] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.9030323e-28 1.0000000e+00 1.4876058e-36 1.4884493e-24 3.3066196e-38], sum to 1.0000
[2019-03-23 09:19:17,789] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2236
[2019-03-23 09:19:17,792] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.56666666666667, 59.66666666666667, 1.0, 2.0, 0.5111637878817245, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 555179.2834337, 555179.2834337003, 116417.7965653], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7204800.0000, 
sim time next is 7205400.0000, 
raw observation next is [19.95, 58.0, 1.0, 2.0, 0.5212743237659514, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 566166.8167573907, 566166.8167573905, 118516.8138258004], 
processed observation next is [1.0, 0.391304347826087, 0.5431818181818181, 0.58, 1.0, 1.0, 0.4015929047074392, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2096914136138484, 0.20969141361384833, 0.28906539957512295], 
reward next is 0.7109, 
noisyNet noise sample is [array([0.17455143], dtype=float32), -0.30312592]. 
=============================================
[2019-03-23 09:19:20,197] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.1373516e-29 1.0000000e+00 0.0000000e+00 9.5494417e-27 0.0000000e+00], sum to 1.0000
[2019-03-23 09:19:20,205] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4146
[2019-03-23 09:19:20,209] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.8, 87.0, 1.0, 2.0, 0.2106262290411179, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 228686.1563698546, 228686.1563698546, 73426.83876367976], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7268400.0000, 
sim time next is 7269000.0000, 
raw observation next is [13.9, 85.33333333333333, 1.0, 2.0, 0.2096210281071027, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 227594.5101849722, 227594.5101849719, 73131.82829662437], 
processed observation next is [1.0, 0.13043478260869565, 0.2681818181818182, 0.8533333333333333, 1.0, 1.0, 0.012026285133878364, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08429426303147118, 0.08429426303147107, 0.17837031291859604], 
reward next is 0.8216, 
noisyNet noise sample is [array([0.07531482], dtype=float32), -0.7713396]. 
=============================================
[2019-03-23 09:19:20,221] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[76.63159]
 [76.63159]
 [76.63159]
 [76.63159]
 [76.63159]], R is [[76.68692017]
 [76.74095917]
 [76.79296112]
 [76.84189606]
 [76.88687897]].
[2019-03-23 09:19:23,661] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.579032e-26 1.000000e+00 9.252664e-36 9.262003e-25 3.669825e-38], sum to 1.0000
[2019-03-23 09:19:23,667] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2802
[2019-03-23 09:19:23,671] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.73333333333333, 70.33333333333334, 1.0, 2.0, 0.3487040961512775, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 386491.0120990074, 386491.0120990074, 117413.457650272], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7338000.0000, 
sim time next is 7338600.0000, 
raw observation next is [20.55, 71.5, 1.0, 2.0, 0.3487961044847705, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 386515.8965156064, 386515.8965156067, 117389.7122426689], 
processed observation next is [1.0, 0.9565217391304348, 0.5704545454545454, 0.715, 1.0, 1.0, 0.1859951306059631, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14315403574652089, 0.143154035746521, 0.2863163713235827], 
reward next is 0.7137, 
noisyNet noise sample is [array([-0.23320667], dtype=float32), -1.022696]. 
=============================================
[2019-03-23 09:19:27,255] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.9913549e-24 1.0000000e+00 4.0929810e-33 2.7146363e-21 8.8928471e-34], sum to 1.0000
[2019-03-23 09:19:27,260] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3557
[2019-03-23 09:19:27,266] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1106951.863570428 W.
[2019-03-23 09:19:27,273] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.9, 53.0, 1.0, 2.0, 0.4898341614027309, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9457629359730455, 6.95642660580944, 6.9112, 77.32835249514788, 1106951.863570428, 1092263.208122423, 253673.6611836612], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7388400.0000, 
sim time next is 7389000.0000, 
raw observation next is [28.0, 53.0, 1.0, 2.0, 0.2814708495513262, 1.0, 1.0, 0.2814708495513262, 1.0, 2.0, 0.570008025494302, 6.9112, 6.9112, 77.3421103, 961472.5587970726, 961472.5587970726, 251787.2633459741], 
processed observation next is [1.0, 0.5217391304347826, 0.9090909090909091, 0.53, 1.0, 1.0, 0.1018385619391577, 1.0, 0.5, 0.1018385619391577, 1.0, 1.0, 0.3857257507061457, 0.0, 0.0, 0.5085185399722538, 0.35610094770261946, 0.35610094770261946, 0.6141152764535953], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.0208962], dtype=float32), 0.17774141]. 
=============================================
[2019-03-23 09:19:27,286] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[61.148335]
 [61.148335]
 [61.148335]
 [61.148335]
 [61.148335]], R is [[60.53684998]
 [59.93148041]
 [59.33216476]
 [59.05888748]
 [58.77895737]].
[2019-03-23 09:19:28,289] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.1696157e-24 1.0000000e+00 4.9517994e-29 1.6129901e-20 1.6715248e-31], sum to 1.0000
[2019-03-23 09:19:28,294] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1427
[2019-03-23 09:19:28,296] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.18333333333333, 64.0, 1.0, 2.0, 0.3847825963293612, 1.0, 2.0, 0.3847825963293612, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 873643.2926080634, 873643.2926080631, 206271.2767074213], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7405800.0000, 
sim time next is 7406400.0000, 
raw observation next is [25.16666666666667, 68.0, 1.0, 2.0, 0.4791869891025243, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 546665.2274309531, 546665.2274309531, 139279.3609998073], 
processed observation next is [1.0, 0.7391304347826086, 0.7803030303030305, 0.68, 1.0, 1.0, 0.34898373637815533, 0.0, 0.5, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20246860275220485, 0.20246860275220485, 0.3397057585361154], 
reward next is 0.6603, 
noisyNet noise sample is [array([-1.4491241], dtype=float32), 1.3434638]. 
=============================================
[2019-03-23 09:19:28,476] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.3982835e-20 1.0000000e+00 1.5810436e-28 1.8418835e-18 1.1872265e-29], sum to 1.0000
[2019-03-23 09:19:28,479] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5575
[2019-03-23 09:19:28,483] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 93.0, 1.0, 2.0, 0.4092739602873797, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 462638.2189586698, 462638.2189586696, 126492.4488556196], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7419600.0000, 
sim time next is 7420200.0000, 
raw observation next is [19.3, 92.5, 1.0, 2.0, 0.4059416205827326, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 458220.8881089672, 458220.8881089675, 125808.5622193922], 
processed observation next is [1.0, 0.9130434782608695, 0.5136363636363637, 0.925, 1.0, 1.0, 0.2574270257284157, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16971144004035824, 0.16971144004035835, 0.3068501517546151], 
reward next is 0.6931, 
noisyNet noise sample is [array([-1.0537802], dtype=float32), -1.7995368]. 
=============================================
[2019-03-23 09:19:31,799] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.5624280e-27 1.0000000e+00 7.4570819e-35 6.7513275e-25 9.6861247e-38], sum to 1.0000
[2019-03-23 09:19:31,804] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7203
[2019-03-23 09:19:31,808] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.51666666666667, 62.33333333333334, 1.0, 2.0, 0.5280904886860722, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 600745.1867841142, 600745.1867841142, 146852.4504387899], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7476600.0000, 
sim time next is 7477200.0000, 
raw observation next is [27.7, 61.0, 1.0, 2.0, 0.5247285183301829, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 597097.079304521, 597097.079304521, 146322.166227733], 
processed observation next is [0.0, 0.5652173913043478, 0.8954545454545454, 0.61, 1.0, 1.0, 0.4059106479127285, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22114706640908185, 0.22114706640908185, 0.35688333226276336], 
reward next is 0.6431, 
noisyNet noise sample is [array([0.88970643], dtype=float32), -1.2813946]. 
=============================================
[2019-03-23 09:19:34,574] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-23 09:19:34,576] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 09:19:34,576] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 09:19:34,577] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:19:34,578] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 09:19:34,578] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:19:34,579] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 09:19:34,581] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:19:34,581] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 09:19:34,581] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:19:34,583] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:19:34,601] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run26
[2019-03-23 09:19:34,626] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run26
[2019-03-23 09:19:34,627] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run26
[2019-03-23 09:19:34,650] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run26
[2019-03-23 09:19:34,698] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run26
[2019-03-23 09:19:43,975] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.97613084]
[2019-03-23 09:19:43,976] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.53333333333333, 41.66666666666667, 1.0, 2.0, 0.4464364768607993, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 484797.2433503641, 484797.2433503641, 112104.8802239811]
[2019-03-23 09:19:43,978] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 09:19:43,981] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.4640699e-27 1.0000000e+00 1.5116268e-35 9.6017595e-25 3.1138508e-38], sampled 0.39578931573596376
[2019-03-23 09:19:55,277] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.97613084]
[2019-03-23 09:19:55,278] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.00014954666667, 49.61324027, 1.0, 2.0, 0.2271229799194147, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 95.55338769695034, 246590.0221479209, 246590.0221479202, 75787.3838287633]
[2019-03-23 09:19:55,279] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 09:19:55,282] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.4640699e-27 1.0000000e+00 1.5116268e-35 9.6017595e-25 3.1138508e-38], sampled 0.7615972508329185
[2019-03-23 09:19:57,393] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.97613084]
[2019-03-23 09:19:57,393] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.5, 60.0, 1.0, 2.0, 0.3281450021759595, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 359318.3571911933, 359318.3571911933, 114161.313310633]
[2019-03-23 09:19:57,395] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 09:19:57,398] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.4640699e-27 1.0000000e+00 1.5116268e-35 9.6017595e-25 3.1138508e-38], sampled 0.4351403870404975
[2019-03-23 09:20:00,198] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.97613084]
[2019-03-23 09:20:00,198] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [11.76830502333333, 98.322601725, 1.0, 2.0, 0.2167932259645756, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 235372.6940542871, 235372.6940542871, 76250.65875615802]
[2019-03-23 09:20:00,199] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 09:20:00,201] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.4640699e-27 1.0000000e+00 1.5116268e-35 9.6017595e-25 3.1138508e-38], sampled 0.37712962736071187
[2019-03-23 09:20:10,515] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.97613084]
[2019-03-23 09:20:10,517] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.93858769333333, 86.32014530000001, 1.0, 2.0, 0.4287524430577632, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 486988.0678428477, 486988.0678428477, 134228.5701726649]
[2019-03-23 09:20:10,518] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 09:20:10,521] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.4640699e-27 1.0000000e+00 1.5116268e-35 9.6017595e-25 3.1138508e-38], sampled 0.26488734307901085
[2019-03-23 09:20:16,398] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.97613084]
[2019-03-23 09:20:16,400] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [25.87244215666666, 63.35066519, 1.0, 2.0, 0.4867367086458778, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 555343.8413361349, 555343.8413361349, 143513.7248473853]
[2019-03-23 09:20:16,401] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 09:20:16,403] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.4640699e-27 1.0000000e+00 1.5116268e-35 9.6017595e-25 3.1138508e-38], sampled 0.521288971706301
[2019-03-23 09:20:45,442] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.97613084]
[2019-03-23 09:20:45,444] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [15.65, 89.5, 1.0, 2.0, 0.2578592775808333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 279968.544754822, 279968.544754822, 92922.36022272328]
[2019-03-23 09:20:45,445] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 09:20:45,449] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.4640699e-27 1.0000000e+00 1.5116268e-35 9.6017595e-25 3.1138508e-38], sampled 0.42631077659794137
[2019-03-23 09:21:14,809] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 09:21:14,878] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.97613084]
[2019-03-23 09:21:14,880] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.6, 61.0, 1.0, 2.0, 0.4342544559893649, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 477995.1181320222, 477995.1181320222, 127628.9570778303]
[2019-03-23 09:21:14,881] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 09:21:14,884] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.4640699e-27 1.0000000e+00 1.5116268e-35 9.6017595e-25 3.1138508e-38], sampled 0.31009258238706994
[2019-03-23 09:21:15,068] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 09:21:15,116] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 09:21:15,209] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 09:21:15,247] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 09:21:16,261] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 625000, evaluation results [625000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 09:21:18,369] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.0710945e-22 1.0000000e+00 3.2215057e-31 3.2376011e-20 7.1998654e-33], sum to 1.0000
[2019-03-23 09:21:18,381] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3722
[2019-03-23 09:21:18,387] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 96.0, 1.0, 2.0, 0.4331055467954581, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 492667.332601408, 492667.332601408, 130939.0202515509], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7608000.0000, 
sim time next is 7608600.0000, 
raw observation next is [20.0, 96.0, 1.0, 2.0, 0.4329996114758449, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 492546.1759293742, 492546.1759293745, 130927.8472504584], 
processed observation next is [1.0, 0.043478260869565216, 0.5454545454545454, 0.96, 1.0, 1.0, 0.2912495143448061, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18242450960347192, 0.18242450960347203, 0.3193362128059961], 
reward next is 0.6807, 
noisyNet noise sample is [array([-0.10396501], dtype=float32), -1.0354172]. 
=============================================
[2019-03-23 09:21:22,509] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.1522992e-23 1.0000000e+00 1.3303497e-31 2.4728928e-21 2.3334628e-33], sum to 1.0000
[2019-03-23 09:21:22,516] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9061
[2019-03-23 09:21:22,524] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1201985.843554805 W.
[2019-03-23 09:21:22,527] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.46666666666667, 54.33333333333333, 1.0, 2.0, 0.5302901413222743, 1.0, 2.0, 0.5302901413222743, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.3284634016458, 1201985.843554805, 1201985.843554805, 240592.0463190146], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7656000.0000, 
sim time next is 7656600.0000, 
raw observation next is [28.38333333333333, 54.66666666666667, 1.0, 2.0, 0.556698641100511, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9727687113004128, 6.915923860632338, 6.9112, 77.32845185490775, 1181796.568015534, 1180262.354931731, 269475.179762894], 
processed observation next is [1.0, 0.6086956521739131, 0.9265151515151513, 0.5466666666666667, 1.0, 1.0, 0.44587330137563874, 0.0, 0.5, -0.25, 1.0, 0.5, 0.9610981590005898, 0.0004723860632338095, 0.0, 0.5084287367262645, 0.4377024325983459, 0.43713420553027077, 0.6572565360070586], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.0081391], dtype=float32), 0.56560403]. 
=============================================
[2019-03-23 09:21:32,315] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.1565089e-28 1.0000000e+00 7.5535574e-37 3.6520935e-28 3.7902195e-38], sum to 1.0000
[2019-03-23 09:21:32,323] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7214
[2019-03-23 09:21:32,327] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.2, 66.0, 1.0, 2.0, 0.2812109115149653, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 305347.1062927122, 305347.1062927125, 97498.09123523139], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7863600.0000, 
sim time next is 7864200.0000, 
raw observation next is [19.1, 66.5, 1.0, 2.0, 0.2781426360040095, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 302014.4477021217, 302014.4477021214, 96807.5708909484], 
processed observation next is [1.0, 0.0, 0.5045454545454546, 0.665, 1.0, 1.0, 0.09767829500501188, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11185720285263766, 0.11185720285263756, 0.23611602656328876], 
reward next is 0.7639, 
noisyNet noise sample is [array([-0.21032588], dtype=float32), -0.39433804]. 
=============================================
[2019-03-23 09:21:37,190] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:21:37,191] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:21:37,214] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run4
[2019-03-23 09:21:37,484] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:21:37,485] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:21:37,504] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run4
[2019-03-23 09:21:37,780] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:21:37,781] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:21:37,785] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run4
[2019-03-23 09:21:38,200] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:21:38,201] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:21:38,202] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run4
[2019-03-23 09:21:38,313] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:21:38,313] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:21:38,314] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run4
[2019-03-23 09:21:38,576] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:21:38,576] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:21:38,578] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run4
[2019-03-23 09:21:38,596] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:21:38,597] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:21:38,601] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run4
[2019-03-23 09:21:38,621] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:21:38,621] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:21:38,626] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run4
[2019-03-23 09:21:38,705] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:21:38,706] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:21:38,709] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run4
[2019-03-23 09:21:38,709] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:21:38,709] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:21:38,710] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run4
[2019-03-23 09:21:38,812] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:21:38,812] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:21:38,814] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run4
[2019-03-23 09:21:38,846] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:21:38,846] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:21:38,849] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run4
[2019-03-23 09:21:38,880] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:21:38,881] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:21:38,883] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run4
[2019-03-23 09:21:38,921] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:21:38,921] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:21:38,923] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run4
[2019-03-23 09:21:38,962] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:21:38,963] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:21:38,965] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run4
[2019-03-23 09:21:39,003] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:21:39,004] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:21:39,006] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run4
[2019-03-23 09:21:39,297] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.6504360e-28 1.0000000e+00 5.1088095e-37 1.2712193e-27 0.0000000e+00], sum to 1.0000
[2019-03-23 09:21:39,297] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3411
[2019-03-23 09:21:39,320] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.2, 92.0, 1.0, 2.0, 0.3388304157663543, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 370374.5747171245, 370374.5747171245, 114710.5160800163], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 12000.0000, 
sim time next is 12600.0000, 
raw observation next is [17.15, 94.0, 1.0, 2.0, 0.3412905856755625, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 374197.0404064208, 374197.0404064211, 115291.5377216183], 
processed observation next is [1.0, 0.13043478260869565, 0.41590909090909084, 0.94, 1.0, 1.0, 0.17661323209445307, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13859149644682253, 0.13859149644682264, 0.28119887249175196], 
reward next is 0.7188, 
noisyNet noise sample is [array([0.84032583], dtype=float32), -0.3158785]. 
=============================================
[2019-03-23 09:21:41,497] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.6485110e-30 1.0000000e+00 1.7487997e-37 2.3474001e-25 0.0000000e+00], sum to 1.0000
[2019-03-23 09:21:41,506] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3094
[2019-03-23 09:21:41,510] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.83333333333333, 95.0, 1.0, 2.0, 0.3657822884346946, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 406866.275000817, 406866.2750008167, 119343.6929902378], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 18600.0000, 
sim time next is 19200.0000, 
raw observation next is [17.66666666666667, 96.0, 1.0, 2.0, 0.3554738781628841, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 395055.3200971914, 395055.3200971914, 118372.8525196534], 
processed observation next is [1.0, 0.21739130434782608, 0.4393939393939396, 0.96, 1.0, 1.0, 0.19434234770360512, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.146316785221182, 0.146316785221182, 0.28871427443817904], 
reward next is 0.7113, 
noisyNet noise sample is [array([-1.065473], dtype=float32), -1.918858]. 
=============================================
[2019-03-23 09:21:47,610] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.9708091e-27 1.0000000e+00 9.3679474e-36 1.9047508e-24 3.6243315e-38], sum to 1.0000
[2019-03-23 09:21:47,615] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1903
[2019-03-23 09:21:47,620] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 38.5, 1.0, 2.0, 0.6701915350130709, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 728030.0278762782, 728030.0278762782, 132763.0217126779], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 143400.0000, 
sim time next is 144000.0000, 
raw observation next is [23.0, 38.0, 1.0, 2.0, 0.684321446331434, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 743391.1127446236, 743391.1127446236, 133954.4976473619], 
processed observation next is [1.0, 0.6956521739130435, 0.6818181818181818, 0.38, 1.0, 1.0, 0.6054018079142924, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.275330041757268, 0.275330041757268, 0.3267182869447851], 
reward next is 0.6733, 
noisyNet noise sample is [array([-1.5250865], dtype=float32), 0.362247]. 
=============================================
[2019-03-23 09:21:47,644] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[71.73529]
 [71.73529]
 [71.73529]
 [71.73529]
 [71.73529]], R is [[71.69121552]
 [71.65048981]
 [71.60799408]
 [71.55838776]
 [71.50263977]].
[2019-03-23 09:21:47,982] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.7581203e-27 1.0000000e+00 3.4366392e-36 1.6934300e-23 2.1565724e-38], sum to 1.0000
[2019-03-23 09:21:47,990] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6310
[2019-03-23 09:21:47,994] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333334, 45.5, 1.0, 2.0, 0.2843232260115502, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 308727.6218938261, 308727.6218938258, 83720.9906388569], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 154200.0000, 
sim time next is 154800.0000, 
raw observation next is [20.0, 46.0, 1.0, 2.0, 0.280414866948642, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 304482.4670239609, 304482.4670239612, 82547.61964000101], 
processed observation next is [1.0, 0.8260869565217391, 0.5454545454545454, 0.46, 1.0, 1.0, 0.10051858368580247, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11277128408294848, 0.11277128408294859, 0.20133565765853906], 
reward next is 0.7987, 
noisyNet noise sample is [array([-0.37267342], dtype=float32), -0.6470518]. 
=============================================
[2019-03-23 09:21:49,241] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.8332551e-25 1.0000000e+00 9.6284445e-36 3.9242163e-26 2.0041589e-38], sum to 1.0000
[2019-03-23 09:21:49,249] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3362
[2019-03-23 09:21:49,253] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.0, 98.0, 1.0, 2.0, 0.2597595617670253, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 282047.8434864808, 282047.8434864808, 90879.1670368199], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 249600.0000, 
sim time next is 250200.0000, 
raw observation next is [15.0, 97.0, 1.0, 2.0, 0.2568880097113039, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 278929.0080905815, 278929.0080905817, 89540.55562876145], 
processed observation next is [0.0, 0.9130434782608695, 0.3181818181818182, 0.97, 1.0, 1.0, 0.07111001213912983, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10330704003354871, 0.10330704003354878, 0.21839159909454012], 
reward next is 0.7816, 
noisyNet noise sample is [array([1.2595327], dtype=float32), -0.81931865]. 
=============================================
[2019-03-23 09:21:51,740] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.4368788e-27 1.0000000e+00 3.3678297e-36 2.0760261e-26 0.0000000e+00], sum to 1.0000
[2019-03-23 09:21:51,750] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1558
[2019-03-23 09:21:51,755] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.25, 76.16666666666666, 1.0, 2.0, 0.2489607101078072, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 270319.1539068859, 270319.1539068859, 87840.07146596775], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 226200.0000, 
sim time next is 226800.0000, 
raw observation next is [17.5, 75.0, 1.0, 2.0, 0.2529844093067958, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 274689.2817076968, 274689.2817076966, 89200.8423852974], 
processed observation next is [0.0, 0.6521739130434783, 0.4318181818181818, 0.75, 1.0, 1.0, 0.0662305116334947, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10173677100285067, 0.1017367710028506, 0.21756303020804243], 
reward next is 0.7824, 
noisyNet noise sample is [array([1.3463442], dtype=float32), 2.7592015]. 
=============================================
[2019-03-23 09:21:51,909] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.2487012e-29 1.0000000e+00 2.2875644e-38 3.3114761e-25 0.0000000e+00], sum to 1.0000
[2019-03-23 09:21:51,922] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1221
[2019-03-23 09:21:51,926] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.25, 76.16666666666666, 1.0, 2.0, 0.2489607101078072, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 270319.1539068859, 270319.1539068859, 87840.07146596775], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 226200.0000, 
sim time next is 226800.0000, 
raw observation next is [17.5, 75.0, 1.0, 2.0, 0.2529844093067958, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 274689.2817076968, 274689.2817076966, 89200.8423852974], 
processed observation next is [0.0, 0.6521739130434783, 0.4318181818181818, 0.75, 1.0, 1.0, 0.0662305116334947, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10173677100285067, 0.1017367710028506, 0.21756303020804243], 
reward next is 0.7824, 
noisyNet noise sample is [array([-0.3399812], dtype=float32), 0.07042948]. 
=============================================
[2019-03-23 09:21:57,435] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.03074506e-26 1.00000000e+00 1.04327764e-35 1.56954865e-27
 2.22296876e-37], sum to 1.0000
[2019-03-23 09:21:57,443] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1701
[2019-03-23 09:21:57,449] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 67.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 199014.4117936186, 199014.4117936183, 66107.10499285215], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 342000.0000, 
sim time next is 342600.0000, 
raw observation next is [14.0, 67.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 196406.3741141818, 196406.3741141821, 65686.70317760974], 
processed observation next is [0.0, 1.0, 0.2727272727272727, 0.67, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07274310152377103, 0.07274310152377116, 0.1602114711649018], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.14627154], dtype=float32), 1.2300068]. 
=============================================
[2019-03-23 09:21:58,144] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.5463695e-29 1.0000000e+00 9.1411609e-38 1.2941285e-26 0.0000000e+00], sum to 1.0000
[2019-03-23 09:21:58,151] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0899
[2019-03-23 09:21:58,156] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 67.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 174666.2258562792, 174666.2258562795, 61288.40736756568], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 352800.0000, 
sim time next is 353400.0000, 
raw observation next is [12.83333333333333, 68.5, 1.0, 2.0, 0.3378055041285752, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 366822.362548205, 366822.362548205, 79954.6606167643], 
processed observation next is [1.0, 0.08695652173913043, 0.21969696969696956, 0.685, 1.0, 1.0, 0.17225688016071897, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13586013427711296, 0.13586013427711296, 0.1950113673579617], 
reward next is 0.8050, 
noisyNet noise sample is [array([0.45314083], dtype=float32), 1.3177594]. 
=============================================
[2019-03-23 09:22:00,443] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.7393235e-27 1.0000000e+00 5.5767876e-37 3.1929357e-25 1.3582977e-38], sum to 1.0000
[2019-03-23 09:22:00,444] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4218
[2019-03-23 09:22:00,453] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.66666666666667, 69.33333333333334, 1.0, 2.0, 0.22803021967248, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 247587.2435087689, 247587.2435087686, 77700.76909946692], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 411600.0000, 
sim time next is 412200.0000, 
raw observation next is [16.5, 70.0, 1.0, 2.0, 0.2241103095192878, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 243330.0774192893, 243330.0774192893, 76999.47041655997], 
processed observation next is [1.0, 0.782608695652174, 0.38636363636363635, 0.7, 1.0, 1.0, 0.03013788689910972, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09012225089603307, 0.09012225089603307, 0.18780358638185357], 
reward next is 0.8122, 
noisyNet noise sample is [array([1.7326121], dtype=float32), -0.7828623]. 
=============================================
[2019-03-23 09:22:01,105] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.9387530e-29 1.0000000e+00 6.3976455e-38 3.5892413e-26 0.0000000e+00], sum to 1.0000
[2019-03-23 09:22:01,112] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4995
[2019-03-23 09:22:01,122] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.16666666666667, 92.0, 1.0, 2.0, 0.2041997106052938, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 221707.0125621005, 221707.0125621002, 75397.84862086344], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 424200.0000, 
sim time next is 424800.0000, 
raw observation next is [14.0, 94.0, 1.0, 2.0, 0.2062216659253001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 223902.8278710161, 223902.8278710164, 75753.00406392151], 
processed observation next is [1.0, 0.9565217391304348, 0.2727272727272727, 0.94, 1.0, 1.0, 0.007777082406625127, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08292697328556152, 0.08292697328556163, 0.18476342454615002], 
reward next is 0.8152, 
noisyNet noise sample is [array([1.1912099], dtype=float32), 0.97308755]. 
=============================================
[2019-03-23 09:22:06,489] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-23 09:22:06,493] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 09:22:06,494] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:22:06,497] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 09:22:06,498] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:22:06,499] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 09:22:06,500] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 09:22:06,500] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:22:06,500] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 09:22:06,501] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:22:06,502] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:22:06,518] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run27
[2019-03-23 09:22:06,545] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run27
[2019-03-23 09:22:06,567] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run27
[2019-03-23 09:22:06,593] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run27
[2019-03-23 09:22:06,616] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run27
[2019-03-23 09:22:12,575] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.9654788]
[2019-03-23 09:22:12,576] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [13.42208799166667, 99.91867169333334, 1.0, 2.0, 0.2878758175262484, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 83.28217095436138, 312579.2023483856, 312579.2023483853, 86388.9445050787]
[2019-03-23 09:22:12,576] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 09:22:12,579] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.5753776e-29 1.0000000e+00 0.0000000e+00 5.6997096e-27 0.0000000e+00], sampled 0.42988664664298115
[2019-03-23 09:22:21,329] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.9654788]
[2019-03-23 09:22:21,329] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [30.29308921666667, 59.57137931833334, 1.0, 2.0, 0.8943317876677453, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 1005130.099651511, 1005130.09965151, 211020.7285273497]
[2019-03-23 09:22:21,331] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 09:22:21,333] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.5753776e-29 1.0000000e+00 0.0000000e+00 5.6997096e-27 0.0000000e+00], sampled 0.15005119726912408
[2019-03-23 09:23:10,437] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.9654788]
[2019-03-23 09:23:10,438] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [25.36666666666667, 52.33333333333334, 1.0, 2.0, 0.3862838059337003, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 435905.5167142866, 435905.5167142862, 128289.6436420067]
[2019-03-23 09:23:10,439] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 09:23:10,442] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.4628783e-29 1.0000000e+00 0.0000000e+00 5.3299880e-27 0.0000000e+00], sampled 0.03876473099431188
[2019-03-23 09:23:15,019] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.9654788]
[2019-03-23 09:23:15,021] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [26.05, 70.5, 1.0, 2.0, 0.6178311253504899, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9774182813751788, 6.9112, 6.9112, 77.32846344354104, 1250162.720725191, 1250162.720725191, 280335.8062771651]
[2019-03-23 09:23:15,024] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 09:23:15,027] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.5753776e-29 1.0000000e+00 0.0000000e+00 5.6997096e-27 0.0000000e+00], sampled 0.7995199569226468
[2019-03-23 09:23:15,029] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1250162.720725191 W.
[2019-03-23 09:23:34,407] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.9654788]
[2019-03-23 09:23:34,409] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.01512129666666, 69.882925625, 1.0, 2.0, 0.451807857487412, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 514892.6731535426, 514892.6731535426, 138252.0364777288]
[2019-03-23 09:23:34,411] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 09:23:34,413] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.5041766e-29 1.0000000e+00 0.0000000e+00 5.4666562e-27 0.0000000e+00], sampled 0.8694105048221873
[2019-03-23 09:23:37,146] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05308744], dtype=float32), -0.9654788]
[2019-03-23 09:23:37,146] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [12.25411543166667, 99.15077298166668, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 199373.1519674725, 199373.1519674725, 72947.85260173302]
[2019-03-23 09:23:37,146] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 09:23:37,149] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.5753776e-29 1.0000000e+00 0.0000000e+00 5.6997096e-27 0.0000000e+00], sampled 0.46856879528916484
[2019-03-23 09:23:47,065] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 09:23:47,082] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 09:23:47,405] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 09:23:47,433] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 09:23:47,463] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 09:23:48,479] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 650000, evaluation results [650000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 09:23:50,788] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.6581648e-27 1.0000000e+00 3.6051838e-35 1.0844169e-24 4.1875557e-38], sum to 1.0000
[2019-03-23 09:23:50,796] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8624
[2019-03-23 09:23:50,802] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.33333333333334, 72.33333333333334, 1.0, 2.0, 0.5072438633807063, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 552683.3196189082, 552683.3196189086, 128065.5569140423], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 562200.0000, 
sim time next is 562800.0000, 
raw observation next is [19.66666666666667, 71.66666666666667, 1.0, 2.0, 0.4219672453892512, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 461386.3418357777, 461386.3418357777, 121211.7907193146], 
processed observation next is [1.0, 0.5217391304347826, 0.5303030303030305, 0.7166666666666667, 1.0, 1.0, 0.27745905673656396, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1708838303095473, 0.1708838303095473, 0.29563851394954777], 
reward next is 0.7044, 
noisyNet noise sample is [array([0.934669], dtype=float32), -1.4214456]. 
=============================================
[2019-03-23 09:23:51,203] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.3731800e-26 1.0000000e+00 3.0404487e-34 1.1788709e-25 3.0189359e-37], sum to 1.0000
[2019-03-23 09:23:51,213] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3244
[2019-03-23 09:23:51,217] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.66666666666666, 69.66666666666666, 1.0, 2.0, 0.4387985076635441, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 485206.3983308713, 485206.3983308713, 124488.1987649726], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 564600.0000, 
sim time next is 565200.0000, 
raw observation next is [21.0, 69.0, 1.0, 2.0, 0.417846430219965, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 463593.6369610956, 463593.6369610953, 123259.2362675948], 
processed observation next is [1.0, 0.5652173913043478, 0.5909090909090909, 0.69, 1.0, 1.0, 0.2723080377749562, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17170134702262801, 0.1717013470226279, 0.3006322835794995], 
reward next is 0.6994, 
noisyNet noise sample is [array([-0.8351619], dtype=float32), -0.08084379]. 
=============================================
[2019-03-23 09:23:54,831] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.5792971e-26 1.0000000e+00 3.8285867e-36 2.2154577e-24 0.0000000e+00], sum to 1.0000
[2019-03-23 09:23:54,839] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4709
[2019-03-23 09:23:54,843] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.33333333333333, 82.16666666666667, 1.0, 2.0, 0.3170558481303215, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 346190.7959199703, 346190.79591997, 113016.1398265437], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 634200.0000, 
sim time next is 634800.0000, 
raw observation next is [18.66666666666667, 81.33333333333334, 1.0, 2.0, 0.3911539761514409, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 429134.2506353831, 429134.2506353831, 119213.3460155438], 
processed observation next is [1.0, 0.34782608695652173, 0.4848484848484851, 0.8133333333333335, 1.0, 1.0, 0.23894247018930106, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1589386113464382, 0.1589386113464382, 0.29076425857449706], 
reward next is 0.7092, 
noisyNet noise sample is [array([-1.3244135], dtype=float32), -0.78046256]. 
=============================================
[2019-03-23 09:24:11,738] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.0967342e-25 1.0000000e+00 7.4828173e-34 5.0884510e-20 7.1915373e-36], sum to 1.0000
[2019-03-23 09:24:11,748] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7421
[2019-03-23 09:24:11,752] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.4423012313262797, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 501435.6547635713, 501435.6547635715, 130543.9262153073], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 961800.0000, 
sim time next is 962400.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.418998825165494, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 475011.7512734497, 475011.75127345, 128275.307096027], 
processed observation next is [1.0, 0.13043478260869565, 0.5, 1.0, 1.0, 1.0, 0.2737485314568675, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1759302782494258, 0.17593027824942592, 0.31286660267323657], 
reward next is 0.6871, 
noisyNet noise sample is [array([1.7424251], dtype=float32), 1.1277567]. 
=============================================
[2019-03-23 09:24:27,909] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.6788020e-12 1.2018714e-02 2.9587471e-18 9.8798126e-01 6.6214040e-19], sum to 1.0000
[2019-03-23 09:24:27,917] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9544
[2019-03-23 09:24:27,923] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.0, 86.66666666666667, 1.0, 2.0, 0.512233412175835, 1.0, 2.0, 0.512233412175835, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1168031.347274306, 1168031.347274306, 232093.1939112252], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1354800.0000, 
sim time next is 1355400.0000, 
raw observation next is [22.0, 88.5, 1.0, 2.0, 0.4847530759121619, 1.0, 2.0, 0.4847530759121619, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1104785.188045299, 1104785.188045299, 226063.9774355822], 
processed observation next is [1.0, 0.6956521739130435, 0.6363636363636364, 0.885, 1.0, 1.0, 0.3559413448902023, 1.0, 1.0, 0.3559413448902023, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.40917969927603665, 0.40917969927603665, 0.5513755547209322], 
reward next is 0.4486, 
noisyNet noise sample is [array([-0.19167642], dtype=float32), -1.1548809]. 
=============================================
[2019-03-23 09:24:28,795] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.3807113e-14 9.9999702e-01 4.7486284e-20 3.0218664e-06 1.2040445e-20], sum to 1.0000
[2019-03-23 09:24:28,802] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1147
[2019-03-23 09:24:28,806] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 99.0, 1.0, 2.0, 0.3755751157538223, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 420952.8584054097, 420952.8584054097, 121543.8638144675], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1288200.0000, 
sim time next is 1288800.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.379020977697854, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 425362.2683634814, 425362.2683634817, 122097.4033469578], 
processed observation next is [1.0, 0.9565217391304348, 0.45454545454545453, 1.0, 1.0, 1.0, 0.22377622212231746, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1575415808753635, 0.15754158087536357, 0.29779854474867756], 
reward next is 0.7022, 
noisyNet noise sample is [array([-0.4771136], dtype=float32), 0.55250037]. 
=============================================
[2019-03-23 09:24:36,899] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 09:24:36,901] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 09:24:36,901] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:24:36,902] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 09:24:36,903] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:24:36,904] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 09:24:36,905] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 09:24:36,906] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:24:36,906] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 09:24:36,911] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:24:36,909] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:24:36,924] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run28
[2019-03-23 09:24:36,946] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run28
[2019-03-23 09:24:36,946] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run28
[2019-03-23 09:24:36,969] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run28
[2019-03-23 09:24:36,991] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run28
[2019-03-23 09:24:51,230] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -0.97813636]
[2019-03-23 09:24:51,231] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.58333333333333, 83.33333333333333, 1.0, 2.0, 0.51263146269465, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 583104.8815229152, 583104.8815229149, 143652.2858477023]
[2019-03-23 09:24:51,232] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 09:24:51,236] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.668333e-28 1.000000e+00 0.000000e+00 5.505372e-27 0.000000e+00], sampled 0.836104804083503
[2019-03-23 09:25:01,472] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -0.97813636]
[2019-03-23 09:25:01,473] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [23.97300292, 52.4676558, 1.0, 2.0, 0.3384831700510967, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 376109.0694651676, 376109.0694651672, 121334.3494283854]
[2019-03-23 09:25:01,473] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 09:25:01,477] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.668333e-28 1.000000e+00 0.000000e+00 5.505372e-27 0.000000e+00], sampled 0.6009030669635115
[2019-03-23 09:25:07,252] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -0.97813636]
[2019-03-23 09:25:07,254] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.05, 84.0, 1.0, 2.0, 0.3907518780335804, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 439547.1220947665, 439547.1220947665, 127939.5515052369]
[2019-03-23 09:25:07,256] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 09:25:07,259] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.668333e-28 1.000000e+00 0.000000e+00 5.505372e-27 0.000000e+00], sampled 0.22385909754686106
[2019-03-23 09:25:34,591] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -0.97813636]
[2019-03-23 09:25:34,591] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.6, 60.0, 1.0, 2.0, 0.3502390704498082, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 380300.8637678134, 380300.8637678134, 116274.9976105259]
[2019-03-23 09:25:34,593] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 09:25:34,597] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.668333e-28 1.000000e+00 0.000000e+00 5.505372e-27 0.000000e+00], sampled 0.6197830181157924
[2019-03-23 09:25:59,424] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -0.97813636]
[2019-03-23 09:25:59,425] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.63333333333333, 68.33333333333333, 1.0, 2.0, 0.4264810999395732, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 484809.2398262252, 484809.2398262252, 134338.635802795]
[2019-03-23 09:25:59,427] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 09:25:59,430] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.668333e-28 1.000000e+00 0.000000e+00 5.505372e-27 0.000000e+00], sampled 0.45210729680899564
[2019-03-23 09:26:03,011] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -0.97813636]
[2019-03-23 09:26:03,012] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.8, 78.66666666666667, 1.0, 2.0, 0.3878256249345046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 436296.4399790509, 436296.4399790505, 127703.3141046593]
[2019-03-23 09:26:03,013] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 09:26:03,016] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.668333e-28 1.000000e+00 0.000000e+00 5.505372e-27 0.000000e+00], sampled 0.8032101204324498
[2019-03-23 09:26:17,634] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 09:26:17,764] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 09:26:17,823] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 09:26:17,840] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 09:26:17,866] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 09:26:18,880] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 675000, evaluation results [675000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 09:26:23,233] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.9055065e-24 1.0000000e+00 4.4723212e-34 1.5007030e-22 1.3369359e-34], sum to 1.0000
[2019-03-23 09:26:23,238] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0534
[2019-03-23 09:26:23,243] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333333, 83.0, 1.0, 2.0, 0.4965509512334489, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 566346.8054052695, 566346.8054052695, 141573.2120683968], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1539600.0000, 
sim time next is 1540200.0000, 
raw observation next is [23.16666666666667, 83.0, 1.0, 2.0, 0.4891800873698863, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 558084.0526273035, 558084.0526273035, 140388.4168040972], 
processed observation next is [0.0, 0.8260869565217391, 0.6893939393939396, 0.83, 1.0, 1.0, 0.3614751092123578, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20669779726937168, 0.20669779726937168, 0.34241077269292003], 
reward next is 0.6576, 
noisyNet noise sample is [array([0.38715973], dtype=float32), -1.610686]. 
=============================================
[2019-03-23 09:26:29,171] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.4082398e-26 1.0000000e+00 0.0000000e+00 4.5331976e-25 0.0000000e+00], sum to 1.0000
[2019-03-23 09:26:29,178] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0057
[2019-03-23 09:26:29,182] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.33333333333334, 92.0, 1.0, 2.0, 0.3488675110717922, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 388906.0977973274, 388906.0977973277, 118359.1589334113], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1658400.0000, 
sim time next is 1659000.0000, 
raw observation next is [18.16666666666666, 93.0, 1.0, 2.0, 0.3512995376539663, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 391337.1687496797, 391337.16874968, 118431.7305430492], 
processed observation next is [1.0, 0.17391304347826086, 0.4621212121212119, 0.93, 1.0, 1.0, 0.1891244220674579, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.144939692129511, 0.1449396921295111, 0.2888578793732907], 
reward next is 0.7111, 
noisyNet noise sample is [array([1.2209511], dtype=float32), 0.89549136]. 
=============================================
[2019-03-23 09:26:29,199] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[73.07891]
 [73.07891]
 [73.07891]
 [73.07891]
 [73.07891]], R is [[73.05925751]
 [73.03998566]
 [73.02108765]
 [73.0012207 ]
 [72.97846985]].
[2019-03-23 09:26:35,164] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.2325290e-30 1.0000000e+00 0.0000000e+00 4.6259865e-28 0.0000000e+00], sum to 1.0000
[2019-03-23 09:26:35,175] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6342
[2019-03-23 09:26:35,181] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.5, 49.5, 1.0, 2.0, 0.3608962534057521, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 391906.6684983022, 391906.6684983019, 84686.04556575506], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1769400.0000, 
sim time next is 1770000.0000, 
raw observation next is [16.66666666666666, 49.0, 1.0, 2.0, 0.3689517004482865, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 400657.8929108842, 400657.8929108842, 85557.7210653655], 
processed observation next is [1.0, 0.4782608695652174, 0.39393939393939365, 0.49, 1.0, 1.0, 0.2111896255603581, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14839181218921638, 0.14839181218921638, 0.208677368452111], 
reward next is 0.7913, 
noisyNet noise sample is [array([1.0110705], dtype=float32), 1.1579655]. 
=============================================
[2019-03-23 09:26:35,201] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[83.75201]
 [83.75201]
 [83.75201]
 [83.75201]
 [83.75201]], R is [[83.70581055]
 [83.66220093]
 [83.6186142 ]
 [83.57322693]
 [83.53633881]].
[2019-03-23 09:26:39,088] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.2379058e-30 1.0000000e+00 0.0000000e+00 2.8659252e-29 0.0000000e+00], sum to 1.0000
[2019-03-23 09:26:39,093] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7329
[2019-03-23 09:26:39,096] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 49.33333333333334, 1.0, 2.0, 0.5858321488432034, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 636330.3056642283, 636330.3056642283, 130740.3354084022], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1858200.0000, 
sim time next is 1858800.0000, 
raw observation next is [22.0, 48.66666666666667, 1.0, 2.0, 0.4561850206927661, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 495435.9528430178, 495435.9528430181, 116123.2581151474], 
processed observation next is [1.0, 0.5217391304347826, 0.6363636363636364, 0.4866666666666667, 1.0, 1.0, 0.3202312758659576, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18349479734926585, 0.18349479734926596, 0.28322745881743266], 
reward next is 0.7168, 
noisyNet noise sample is [array([-1.1362774], dtype=float32), -1.6051372]. 
=============================================
[2019-03-23 09:26:45,541] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.2513254e-16 1.0000000e+00 9.7813340e-22 9.2672054e-16 1.0508937e-22], sum to 1.0000
[2019-03-23 09:26:45,548] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6374
[2019-03-23 09:26:45,557] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 54.66666666666667, 1.0, 2.0, 0.4014958427009069, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846333770014, 454521.7442934667, 454521.7442934667, 126189.763626071], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1963200.0000, 
sim time next is 1963800.0000, 
raw observation next is [25.0, 53.5, 1.0, 2.0, 0.3785701061249154, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344288588, 426971.4169360349, 426971.4169360346, 123151.2811610203], 
processed observation next is [1.0, 0.7391304347826086, 0.7727272727272727, 0.535, 1.0, 1.0, 0.2232126326561442, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129163465, 0.15813756182816108, 0.15813756182816097, 0.30036897844151295], 
reward next is 0.6996, 
noisyNet noise sample is [array([0.14413278], dtype=float32), 3.353021]. 
=============================================
[2019-03-23 09:26:49,218] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.2912627e-27 1.0000000e+00 0.0000000e+00 3.9288278e-27 0.0000000e+00], sum to 1.0000
[2019-03-23 09:26:49,223] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2887
[2019-03-23 09:26:49,226] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.86666666666667, 47.33333333333334, 1.0, 2.0, 0.3208288661562785, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 351415.6619376311, 351415.6619376308, 113677.3886475386], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2049000.0000, 
sim time next is 2049600.0000, 
raw observation next is [23.73333333333333, 47.66666666666667, 1.0, 2.0, 0.3193632143274435, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 349454.782411821, 349454.7824118212, 113444.0349339265], 
processed observation next is [0.0, 0.7391304347826086, 0.715151515151515, 0.47666666666666674, 1.0, 1.0, 0.14920401790930438, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12942769718956335, 0.1294276971895634, 0.27669276813152804], 
reward next is 0.7233, 
noisyNet noise sample is [array([1.7959273], dtype=float32), -1.4706973]. 
=============================================
[2019-03-23 09:26:49,622] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.2610935e-29 1.0000000e+00 0.0000000e+00 1.0795326e-27 0.0000000e+00], sum to 1.0000
[2019-03-23 09:26:49,628] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5980
[2019-03-23 09:26:49,633] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 50.0, 1.0, 2.0, 0.3062407257859033, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 333129.9888656656, 333129.9888656659, 111820.5866665606], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2035800.0000, 
sim time next is 2036400.0000, 
raw observation next is [23.0, 51.0, 1.0, 2.0, 0.3055668565939638, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 333443.2306736806, 333443.2306736803, 112146.1514458017], 
processed observation next is [0.0, 0.5652173913043478, 0.6818181818181818, 0.51, 1.0, 1.0, 0.13195857074245476, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12349749284210393, 0.12349749284210382, 0.27352719864829683], 
reward next is 0.7265, 
noisyNet noise sample is [array([1.4416988], dtype=float32), -1.208078]. 
=============================================
[2019-03-23 09:26:56,502] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0818153e-29 1.0000000e+00 0.0000000e+00 2.7080561e-30 0.0000000e+00], sum to 1.0000
[2019-03-23 09:26:56,511] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6100
[2019-03-23 09:26:56,522] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.33333333333333, 94.66666666666667, 1.0, 2.0, 0.2474882752024005, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 268719.9565244907, 268719.9565244907, 82236.35379335395], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2179200.0000, 
sim time next is 2179800.0000, 
raw observation next is [14.3, 94.5, 1.0, 2.0, 0.2415230832847394, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 262241.2727842501, 262241.2727842499, 81192.73327289162], 
processed observation next is [1.0, 0.21739130434782608, 0.2863636363636364, 0.945, 1.0, 1.0, 0.051903854105924234, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09712639732750003, 0.09712639732749997, 0.1980310567631503], 
reward next is 0.8020, 
noisyNet noise sample is [array([1.0028181], dtype=float32), -0.4653996]. 
=============================================
[2019-03-23 09:27:02,220] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.3416914e-28 1.0000000e+00 0.0000000e+00 4.0238138e-24 0.0000000e+00], sum to 1.0000
[2019-03-23 09:27:02,227] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2623
[2019-03-23 09:27:02,233] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.66666666666667, 67.66666666666667, 1.0, 2.0, 0.2166278798551651, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 235203.9880210163, 235203.988021016, 73242.09776223404], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2334000.0000, 
sim time next is 2334600.0000, 
raw observation next is [15.5, 67.5, 1.0, 2.0, 0.2145460954086768, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 232943.1467367666, 232943.1467367663, 72673.57749083692], 
processed observation next is [1.0, 0.0, 0.3409090909090909, 0.675, 1.0, 1.0, 0.018182619260845995, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08627523953213577, 0.08627523953213567, 0.17725262802643152], 
reward next is 0.8227, 
noisyNet noise sample is [array([-1.4319015], dtype=float32), 0.056277305]. 
=============================================
[2019-03-23 09:27:07,451] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-23 09:27:07,453] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 09:27:07,454] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:27:07,455] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 09:27:07,456] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:27:07,461] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 09:27:07,462] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:27:07,462] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 09:27:07,463] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 09:27:07,464] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:27:07,465] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:27:07,475] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run29
[2019-03-23 09:27:07,499] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run29
[2019-03-23 09:27:07,521] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run29
[2019-03-23 09:27:07,543] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run29
[2019-03-23 09:27:07,573] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run29
[2019-03-23 09:27:16,983] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.0106492]
[2019-03-23 09:27:16,984] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.7091202, 71.76471870833333, 1.0, 2.0, 0.43789557582194, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 497300.9852551699, 497300.9852551695, 135074.1636093881]
[2019-03-23 09:27:16,985] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 09:27:16,988] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [7.6974923e-28 1.0000000e+00 1.6155308e-38 3.0122232e-26 0.0000000e+00], sampled 0.1753165559918044
[2019-03-23 09:27:19,999] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.0106492]
[2019-03-23 09:27:20,001] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [12.267850875, 86.105884825, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 190760.5931818841, 190760.5931818841, 69534.21571823134]
[2019-03-23 09:27:20,001] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 09:27:20,005] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [7.6974923e-28 1.0000000e+00 1.6155308e-38 3.0122232e-26 0.0000000e+00], sampled 0.7058299216353214
[2019-03-23 09:27:31,635] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.0106492]
[2019-03-23 09:27:31,636] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.11666666666667, 56.66666666666666, 1.0, 2.0, 0.333773464072854, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 370746.0305815987, 370746.0305815987, 116599.1862178985]
[2019-03-23 09:27:31,638] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 09:27:31,640] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [7.6974923e-28 1.0000000e+00 1.6155308e-38 3.0122232e-26 0.0000000e+00], sampled 0.8358326623446397
[2019-03-23 09:28:03,562] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.0106492]
[2019-03-23 09:28:03,563] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.4, 89.0, 1.0, 2.0, 0.680098033483945, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 766362.6788058187, 766362.6788058187, 159560.1399671465]
[2019-03-23 09:28:03,567] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 09:28:03,570] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [7.6974923e-28 1.0000000e+00 1.6155308e-38 3.0122232e-26 0.0000000e+00], sampled 0.25423837077334244
[2019-03-23 09:28:04,299] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.0106492]
[2019-03-23 09:28:04,302] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.7, 59.0, 1.0, 2.0, 0.3794909865969472, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 422101.3177642873, 422101.3177642873, 124779.2884611369]
[2019-03-23 09:28:04,305] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 09:28:04,307] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [7.6974923e-28 1.0000000e+00 1.6155308e-38 3.0122232e-26 0.0000000e+00], sampled 0.9834307043788664
[2019-03-23 09:28:35,109] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.0106492]
[2019-03-23 09:28:35,110] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [16.11666666666667, 93.0, 1.0, 2.0, 0.2868139835647946, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 311414.0180748524, 311414.0180748521, 106306.9533702028]
[2019-03-23 09:28:35,110] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 09:28:35,113] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [7.6974923e-28 1.0000000e+00 1.6155308e-38 3.0122232e-26 0.0000000e+00], sampled 0.3851708116185587
[2019-03-23 09:28:48,144] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 09:28:48,175] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 09:28:48,321] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 09:28:48,379] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 09:28:48,410] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 09:28:49,427] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 700000, evaluation results [700000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 09:28:51,582] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.3594346e-28 1.0000000e+00 0.0000000e+00 2.3139644e-23 0.0000000e+00], sum to 1.0000
[2019-03-23 09:28:51,590] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9738
[2019-03-23 09:28:51,594] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 94.0, 1.0, 2.0, 0.2217817749476316, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 240801.2211759981, 240801.2211759978, 77442.02389081357], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2434800.0000, 
sim time next is 2435400.0000, 
raw observation next is [14.0, 94.0, 1.0, 2.0, 0.2211579799187426, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 240123.763871711, 240123.7638717113, 77349.74147539794], 
processed observation next is [1.0, 0.17391304347826086, 0.2727272727272727, 0.94, 1.0, 1.0, 0.02644747489842822, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08893472735989297, 0.08893472735989308, 0.18865790603755594], 
reward next is 0.8113, 
noisyNet noise sample is [array([0.45706195], dtype=float32), -0.2290808]. 
=============================================
[2019-03-23 09:28:58,165] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.1150714e-22 1.0000000e+00 9.2369942e-31 1.6584603e-23 4.1875547e-31], sum to 1.0000
[2019-03-23 09:28:58,171] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5236
[2019-03-23 09:28:58,175] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 53.0, 1.0, 2.0, 0.6208490541245784, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 674392.0250198649, 674392.0250198647, 138564.6289199984], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2557800.0000, 
sim time next is 2558400.0000, 
raw observation next is [22.33333333333333, 52.0, 1.0, 2.0, 0.6519092432692415, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 709231.5832140058, 709231.5832140058, 142168.290461645], 
processed observation next is [1.0, 0.6086956521739131, 0.6515151515151513, 0.52, 1.0, 1.0, 0.5648865540865519, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2626783641533355, 0.2626783641533355, 0.3467519279552317], 
reward next is 0.6532, 
noisyNet noise sample is [array([0.38566953], dtype=float32), -0.17572162]. 
=============================================
[2019-03-23 09:29:12,186] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.3373120e-10 9.5858413e-01 6.4497117e-16 4.1415866e-02 8.9900657e-16], sum to 1.0000
[2019-03-23 09:29:12,194] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7814
[2019-03-23 09:29:12,202] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1470529.291150362 W.
[2019-03-23 09:29:12,208] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.1, 51.5, 1.0, 2.0, 0.4340425668476734, 1.0, 2.0, 0.4340425668476734, 1.0, 1.0, 0.8780433346742733, 6.9112, 6.9112, 77.3421103, 1470529.291150362, 1470529.291150362, 321736.5994651277], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2824200.0000, 
sim time next is 2824800.0000, 
raw observation next is [29.06666666666667, 51.66666666666667, 1.0, 2.0, 0.7224488920889407, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9766884954477345, 6.911199999999999, 6.9112, 77.32846344354104, 1369780.524144867, 1369780.524144867, 294954.4059761181], 
processed observation next is [1.0, 0.6956521739130435, 0.9575757575757577, 0.5166666666666667, 1.0, 1.0, 0.6530611151111759, 0.0, 0.5, -0.25, 1.0, 1.0, 0.9666978506396209, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.5073261200536544, 0.5073261200536544, 0.719400990185654], 
reward next is 0.2806, 
noisyNet noise sample is [array([-0.81573796], dtype=float32), -0.70610243]. 
=============================================
[2019-03-23 09:29:15,880] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.1687411e-14 1.0000000e+00 2.1273498e-19 2.9118235e-14 3.6765283e-20], sum to 1.0000
[2019-03-23 09:29:15,885] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8532
[2019-03-23 09:29:15,892] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1249573.346651973 W.
[2019-03-23 09:29:15,898] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.0, 73.33333333333334, 1.0, 2.0, 0.3704570534963003, 1.0, 2.0, 0.3704570534963003, 1.0, 2.0, 0.7492436111239541, 6.911199999999999, 6.9112, 77.3421103, 1249573.346651973, 1249573.346651973, 293467.9131285158], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2970600.0000, 
sim time next is 2971200.0000, 
raw observation next is [26.0, 72.66666666666667, 1.0, 2.0, 0.3814508404308318, 1.0, 2.0, 0.3814508404308318, 1.0, 2.0, 0.7711956353047289, 6.911199999999998, 6.9112, 77.3421103, 1286698.148778423, 1286698.148778424, 298324.4949939903], 
processed observation next is [1.0, 0.391304347826087, 0.8181818181818182, 0.7266666666666667, 1.0, 1.0, 0.2268135505385397, 1.0, 1.0, 0.2268135505385397, 1.0, 1.0, 0.6731366218638984, -1.7763568394002506e-16, 0.0, 0.5085185399722538, 0.47655486991793444, 0.4765548699179348, 0.7276207194975373], 
reward next is 0.2724, 
noisyNet noise sample is [array([-0.14569758], dtype=float32), 0.5090504]. 
=============================================
[2019-03-23 09:29:24,558] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.9323206e-23 1.0000000e+00 1.0029865e-32 2.2749871e-25 4.7173378e-34], sum to 1.0000
[2019-03-23 09:29:24,566] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7705
[2019-03-23 09:29:24,572] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 75.5, 1.0, 2.0, 0.522640321774871, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 594168.044033017, 594168.044033017, 140124.3819162897], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3137400.0000, 
sim time next is 3138000.0000, 
raw observation next is [22.66666666666666, 74.66666666666667, 1.0, 2.0, 0.5043304353681127, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 573467.8227407665, 573467.8227407665, 138201.4302227301], 
processed observation next is [1.0, 0.30434782608695654, 0.6666666666666664, 0.7466666666666667, 1.0, 1.0, 0.3804130442101409, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21239548990398757, 0.21239548990398757, 0.3370766590798295], 
reward next is 0.6629, 
noisyNet noise sample is [array([0.09092242], dtype=float32), -0.122258365]. 
=============================================
[2019-03-23 09:29:24,589] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[59.52106 ]
 [59.650143]
 [59.755383]
 [59.827145]
 [59.784332]], R is [[59.53722763]
 [59.60009003]
 [59.66718292]
 [59.74094772]
 [59.82269287]].
[2019-03-23 09:29:28,867] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.8263858e-19 1.0000000e+00 5.2832064e-27 6.8698572e-22 1.8082553e-28], sum to 1.0000
[2019-03-23 09:29:28,874] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5862
[2019-03-23 09:29:28,879] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333334, 71.66666666666667, 1.0, 2.0, 0.7919189105924569, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846330961404, 902795.1180794466, 902795.1180794466, 177670.8958001919], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3144000.0000, 
sim time next is 3144600.0000, 
raw observation next is [23.5, 71.0, 1.0, 2.0, 0.8145791183423591, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344271202, 928186.1682629092, 928186.1682629092, 180591.079023302], 
processed observation next is [1.0, 0.391304347826087, 0.7045454545454546, 0.71, 1.0, 1.0, 0.7682238979279488, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129152034, 0.34377265491218856, 0.34377265491218856, 0.44046604639829756], 
reward next is 0.5595, 
noisyNet noise sample is [array([0.23668166], dtype=float32), -1.2610352]. 
=============================================
[2019-03-23 09:29:33,922] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.5998738e-31 1.0000000e+00 0.0000000e+00 5.2297329e-33 0.0000000e+00], sum to 1.0000
[2019-03-23 09:29:33,930] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9598
[2019-03-23 09:29:33,935] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 50.0, 1.0, 2.0, 0.3351726012929923, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 370557.0261069332, 370557.0261069332, 115998.2899956653], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3250800.0000, 
sim time next is 3251400.0000, 
raw observation next is [24.0, 50.0, 1.0, 2.0, 0.3363041132401989, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 371879.0548919595, 371879.0548919595, 116111.553489664], 
processed observation next is [0.0, 0.6521739130434783, 0.7272727272727273, 0.5, 1.0, 1.0, 0.17038014155024858, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13773298329331832, 0.13773298329331832, 0.2831989109504], 
reward next is 0.7168, 
noisyNet noise sample is [array([-0.6627166], dtype=float32), 0.6742358]. 
=============================================
[2019-03-23 09:29:34,004] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.2306226e-30 1.0000000e+00 0.0000000e+00 1.9562878e-27 0.0000000e+00], sum to 1.0000
[2019-03-23 09:29:34,010] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7012
[2019-03-23 09:29:34,014] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 47.5, 1.0, 2.0, 0.3356642524511483, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 368730.3874761776, 368730.3874761773, 115133.2096522929], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3257400.0000, 
sim time next is 3258000.0000, 
raw observation next is [24.0, 47.0, 1.0, 2.0, 0.3322793713874142, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 364450.3851630457, 364450.385163046, 114678.5565438237], 
processed observation next is [0.0, 0.7391304347826086, 0.7272727272727273, 0.47, 1.0, 1.0, 0.16534921423426774, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13498162413446138, 0.1349816241344615, 0.2797037964483505], 
reward next is 0.7203, 
noisyNet noise sample is [array([-0.05953803], dtype=float32), 0.7123422]. 
=============================================
[2019-03-23 09:29:34,029] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[75.33925]
 [75.33925]
 [75.33925]
 [75.33925]
 [75.33925]], R is [[75.30615234]
 [75.27227783]
 [75.23796844]
 [75.20361328]
 [75.16912842]].
[2019-03-23 09:29:38,102] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-23 09:29:38,106] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 09:29:38,109] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:29:38,110] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 09:29:38,113] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 09:29:38,113] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:29:38,115] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 09:29:38,116] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 09:29:38,117] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:29:38,116] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:29:38,119] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:29:38,127] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run30
[2019-03-23 09:29:38,152] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run30
[2019-03-23 09:29:38,175] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run30
[2019-03-23 09:29:38,196] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run30
[2019-03-23 09:29:38,217] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run30
[2019-03-23 09:29:50,675] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.0528697]
[2019-03-23 09:29:50,676] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [12.15059355666667, 99.25545599166668, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 201667.378187564, 201667.3781875637, 73134.90400601573]
[2019-03-23 09:29:50,676] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 09:29:50,679] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.34641725e-30 1.00000000e+00 0.00000000e+00 3.47571251e-31
 0.00000000e+00], sampled 0.6450935642213781
[2019-03-23 09:29:53,948] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.0528697]
[2019-03-23 09:29:53,949] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.33333333333334, 88.66666666666667, 1.0, 2.0, 0.4941582030936226, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.328463443541, 563754.6374123773, 563754.6374123773, 140992.6039130336]
[2019-03-23 09:29:53,951] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 09:29:53,952] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.1066230e-17 1.0000000e+00 1.3837726e-23 1.3895532e-17 1.6681227e-24], sampled 0.6308068363787854
[2019-03-23 09:29:54,472] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.0528697]
[2019-03-23 09:29:54,473] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.87404507, 100.0, 1.0, 2.0, 0.5910968167634192, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 667660.3317195725, 667660.3317195722, 161147.5821344834]
[2019-03-23 09:29:54,475] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 09:29:54,478] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.6649598e-26 1.0000000e+00 8.0468307e-36 1.4622166e-26 3.1817060e-37], sampled 0.09586120821347166
[2019-03-23 09:30:32,020] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.0528697]
[2019-03-23 09:30:32,020] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.0, 94.0, 1.0, 2.0, 0.4320873064960606, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 491014.4479761011, 491014.4479761011, 130404.7890287598]
[2019-03-23 09:30:32,021] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 09:30:32,023] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0597354e-27 1.0000000e+00 4.2165048e-38 3.0986995e-28 0.0000000e+00], sampled 0.07405039316571527
[2019-03-23 09:31:17,559] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 09:31:17,941] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 09:31:17,942] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 09:31:17,969] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 09:31:18,104] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 09:31:19,121] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 725000, evaluation results [725000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 09:31:22,217] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.9047337e-26 1.0000000e+00 2.3375766e-35 2.7586349e-23 1.6117460e-37], sum to 1.0000
[2019-03-23 09:31:22,224] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7662
[2019-03-23 09:31:22,229] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.33333333333334, 98.0, 1.0, 2.0, 0.3418434499230469, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 378974.9681550421, 378974.9681550418, 116918.9692738403], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3392400.0000, 
sim time next is 3393000.0000, 
raw observation next is [17.5, 97.0, 1.0, 2.0, 0.3415281862663875, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 378970.2503164883, 378970.2503164883, 117035.3158096838], 
processed observation next is [1.0, 0.2608695652173913, 0.4318181818181818, 0.97, 1.0, 1.0, 0.17691023283298432, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14035935196906976, 0.14035935196906976, 0.2854519897797166], 
reward next is 0.7145, 
noisyNet noise sample is [array([-0.8899209], dtype=float32), 0.6073426]. 
=============================================
[2019-03-23 09:31:22,255] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[66.22421 ]
 [66.307724]
 [66.43184 ]
 [66.48284 ]
 [66.53944 ]], R is [[66.21134949]
 [66.2640686 ]
 [66.31499481]
 [66.37012482]
 [66.4264679 ]].
[2019-03-23 09:31:28,146] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.6560231e-16 1.0000000e+00 4.4961426e-22 5.5125929e-15 7.8380513e-23], sum to 1.0000
[2019-03-23 09:31:28,152] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7892
[2019-03-23 09:31:28,157] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1209476.27579961 W.
[2019-03-23 09:31:28,162] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.0, 89.0, 1.0, 2.0, 0.9983474268935462, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.136755239642454, 6.9112, 77.32801589658256, 1209476.27579961, 1136220.971341768, 221957.2850497792], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3492000.0000, 
sim time next is 3492600.0000, 
raw observation next is [23.5, 86.5, 1.0, 2.0, 0.6687939332788359, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9767097582417058, 6.9112, 6.9112, 77.32832790531567, 1308681.804335142, 1308681.804335142, 286928.1231939491], 
processed observation next is [1.0, 0.43478260869565216, 0.7045454545454546, 0.865, 1.0, 1.0, 0.5859924165985447, 0.0, 1.0, -0.25, 1.0, 0.5, 0.9667282260595799, 0.0, 0.0, 0.5084279217670483, 0.48469696456857114, 0.48469696456857114, 0.6998246907169491], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.1864667], dtype=float32), 1.5715119]. 
=============================================
[2019-03-23 09:31:33,499] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.5810106e-24 1.0000000e+00 1.8709319e-33 1.4591376e-23 2.3541675e-35], sum to 1.0000
[2019-03-23 09:31:33,504] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0738
[2019-03-23 09:31:33,508] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.16666666666667, 82.16666666666667, 1.0, 2.0, 0.4904825884409209, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 559657.7154331133, 559657.7154331133, 140215.1722066588], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3613800.0000, 
sim time next is 3614400.0000, 
raw observation next is [23.0, 83.0, 1.0, 2.0, 0.491958692099859, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 561359.2457679696, 561359.2457679696, 140281.0212448878], 
processed observation next is [1.0, 0.8695652173913043, 0.6818181818181818, 0.83, 1.0, 1.0, 0.3649483651248237, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20791083176591468, 0.20791083176591468, 0.34214883230460436], 
reward next is 0.6579, 
noisyNet noise sample is [array([-0.3787474], dtype=float32), 0.847225]. 
=============================================
[2019-03-23 09:31:33,690] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.3847985e-21 1.0000000e+00 1.1510155e-29 3.3826992e-22 1.6085377e-32], sum to 1.0000
[2019-03-23 09:31:33,704] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3856
[2019-03-23 09:31:33,709] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.16666666666667, 92.16666666666667, 1.0, 2.0, 0.4981186681571018, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 568164.6064969926, 568164.6064969926, 141702.3586824746], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3617400.0000, 
sim time next is 3618000.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.5011765768550561, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 571582.2040059218, 571582.2040059218, 142189.820914198], 
processed observation next is [1.0, 0.9130434782608695, 0.6363636363636364, 0.94, 1.0, 1.0, 0.3764707210688201, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21169711259478588, 0.21169711259478588, 0.34680444125414145], 
reward next is 0.6532, 
noisyNet noise sample is [array([1.9312896], dtype=float32), 0.41618985]. 
=============================================
[2019-03-23 09:31:33,722] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[53.459625]
 [53.479126]
 [53.42045 ]
 [53.33116 ]
 [53.458565]], R is [[53.55200195]
 [53.67086792]
 [53.78963089]
 [53.90801239]
 [54.02570343]].
[2019-03-23 09:31:43,432] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.4876664e-27 1.0000000e+00 5.1465393e-38 2.4472348e-22 0.0000000e+00], sum to 1.0000
[2019-03-23 09:31:43,438] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2470
[2019-03-23 09:31:43,444] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.33333333333333, 92.0, 1.0, 2.0, 0.3335091822995002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 365792.3634065549, 365792.3634065552, 114765.8611823734], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3796800.0000, 
sim time next is 3797400.0000, 
raw observation next is [17.16666666666667, 93.0, 1.0, 2.0, 0.3331910555174638, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 365070.8397355153, 365070.8397355153, 114607.8449930145], 
processed observation next is [1.0, 0.9565217391304348, 0.4166666666666669, 0.93, 1.0, 1.0, 0.16648881939682975, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13521142212426493, 0.13521142212426493, 0.2795313292512549], 
reward next is 0.7205, 
noisyNet noise sample is [array([-0.9699562], dtype=float32), -0.58847314]. 
=============================================
[2019-03-23 09:31:44,363] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.2714077e-27 1.0000000e+00 3.4931676e-37 8.0611399e-23 0.0000000e+00], sum to 1.0000
[2019-03-23 09:31:44,375] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7368
[2019-03-23 09:31:44,381] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 92.0, 1.0, 2.0, 0.3189354972125077, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 347652.2570987027, 347652.2570987024, 112938.8183833055], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3813600.0000, 
sim time next is 3814200.0000, 
raw observation next is [17.0, 91.0, 1.0, 2.0, 0.315364517071785, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 342988.0075399734, 342988.0075399734, 112421.1669580742], 
processed observation next is [0.0, 0.13043478260869565, 0.4090909090909091, 0.91, 1.0, 1.0, 0.1442056463397312, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12703259538517533, 0.12703259538517533, 0.27419796819042486], 
reward next is 0.7258, 
noisyNet noise sample is [array([1.6214793], dtype=float32), 0.349217]. 
=============================================
[2019-03-23 09:31:48,239] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.1212832e-28 1.0000000e+00 2.7910676e-38 8.7813267e-28 0.0000000e+00], sum to 1.0000
[2019-03-23 09:31:48,250] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6147
[2019-03-23 09:31:48,257] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 77.0, 1.0, 2.0, 0.2795576581333694, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 303551.3947370687, 303551.3947370687, 101443.4320590335], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3888600.0000, 
sim time next is 3889200.0000, 
raw observation next is [18.0, 77.0, 1.0, 2.0, 0.2806036211566654, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 304687.4859344885, 304687.4859344882, 101557.9776574354], 
processed observation next is [0.0, 0.0, 0.45454545454545453, 0.77, 1.0, 1.0, 0.1007545264458317, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1128472170127735, 0.11284721701277341, 0.24770238453033025], 
reward next is 0.7523, 
noisyNet noise sample is [array([-0.3594558], dtype=float32), -1.0848469]. 
=============================================
[2019-03-23 09:31:49,749] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.7439506e-29 1.0000000e+00 0.0000000e+00 2.0716908e-26 0.0000000e+00], sum to 1.0000
[2019-03-23 09:31:49,760] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5696
[2019-03-23 09:31:49,769] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 82.00000000000001, 1.0, 2.0, 0.2650344677281015, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 287777.0494190891, 287777.0494190888, 94310.67219771128], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3906600.0000, 
sim time next is 3907200.0000, 
raw observation next is [17.0, 82.0, 1.0, 2.0, 0.2646596631740437, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 287369.9626880857, 287369.962688086, 94266.2656004541], 
processed observation next is [0.0, 0.21739130434782608, 0.4090909090909091, 0.82, 1.0, 1.0, 0.08082457896755463, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10643331951410581, 0.10643331951410591, 0.22991772097671734], 
reward next is 0.7701, 
noisyNet noise sample is [array([1.0079453], dtype=float32), -1.2644355]. 
=============================================
[2019-03-23 09:31:50,427] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.6932247e-29 1.0000000e+00 0.0000000e+00 9.2506760e-31 0.0000000e+00], sum to 1.0000
[2019-03-23 09:31:50,435] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9218
[2019-03-23 09:31:50,440] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.33333333333333, 49.0, 1.0, 2.0, 0.3263963829251046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 361296.1780651273, 361296.1780651273, 115519.1846385189], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3930000.0000, 
sim time next is 3930600.0000, 
raw observation next is [24.66666666666667, 48.0, 1.0, 2.0, 0.3293996194495492, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 365257.0409152881, 365257.0409152881, 116003.0478077656], 
processed observation next is [0.0, 0.4782608695652174, 0.7575757575757578, 0.48, 1.0, 1.0, 0.16174952431193648, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13528038552418079, 0.13528038552418079, 0.28293426294576973], 
reward next is 0.7171, 
noisyNet noise sample is [array([0.321417], dtype=float32), 1.6159996]. 
=============================================
[2019-03-23 09:31:56,526] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.0448865e-27 1.0000000e+00 3.8037644e-37 1.0397707e-25 0.0000000e+00], sum to 1.0000
[2019-03-23 09:31:56,534] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3787
[2019-03-23 09:31:56,545] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 94.0, 1.0, 2.0, 0.3275885088858099, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 358442.2080257083, 358442.2080257086, 114025.8127584549], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4054800.0000, 
sim time next is 4055400.0000, 
raw observation next is [17.0, 94.0, 1.0, 2.0, 0.3240118310928842, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 354511.8315758604, 354511.8315758601, 113763.892294335], 
processed observation next is [1.0, 0.9565217391304348, 0.4090909090909091, 0.94, 1.0, 1.0, 0.1550147888661052, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13130067836142978, 0.13130067836142967, 0.27747290803496344], 
reward next is 0.7225, 
noisyNet noise sample is [array([-1.5936263], dtype=float32), 0.3502566]. 
=============================================
[2019-03-23 09:32:05,478] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.7603594e-26 1.0000000e+00 9.5650705e-37 3.1883352e-25 0.0000000e+00], sum to 1.0000
[2019-03-23 09:32:05,488] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4764
[2019-03-23 09:32:05,492] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 88.0, 1.0, 2.0, 0.3663709583762091, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 409443.1887203194, 409443.1887203197, 120219.0619601315], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4231200.0000, 
sim time next is 4231800.0000, 
raw observation next is [19.0, 88.0, 1.0, 2.0, 0.3652085544423602, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 408142.5329265399, 408142.5329265399, 120122.5013125982], 
processed observation next is [1.0, 1.0, 0.5, 0.88, 1.0, 1.0, 0.20651069305295025, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15116390108390365, 0.15116390108390365, 0.29298171051853217], 
reward next is 0.7070, 
noisyNet noise sample is [array([-0.31109732], dtype=float32), 0.7837516]. 
=============================================
[2019-03-23 09:32:07,805] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-23 09:32:07,806] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 09:32:07,807] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 09:32:07,809] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 09:32:07,809] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:32:07,809] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 09:32:07,810] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 09:32:07,811] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:32:07,809] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:32:07,812] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:32:07,812] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:32:07,831] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run31
[2019-03-23 09:32:07,832] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run31
[2019-03-23 09:32:07,832] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run31
[2019-03-23 09:32:07,880] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run31
[2019-03-23 09:32:07,940] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run31
[2019-03-23 09:32:13,903] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.0782202]
[2019-03-23 09:32:13,904] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [12.2, 90.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 197219.0821004152, 197219.0821004152, 71036.34230790756]
[2019-03-23 09:32:13,905] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 09:32:13,907] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.0508536e-26 1.0000000e+00 1.1552563e-36 7.9273505e-25 0.0000000e+00], sampled 0.9287647359727977
[2019-03-23 09:32:18,932] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.0782202]
[2019-03-23 09:32:18,933] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [25.5, 48.33333333333334, 1.0, 2.0, 0.3699100732681319, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 415133.7616496325, 415133.7616496321, 125642.63196826]
[2019-03-23 09:32:18,933] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 09:32:18,936] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.0508536e-26 1.0000000e+00 1.1552563e-36 7.9273505e-25 0.0000000e+00], sampled 0.586368624964753
[2019-03-23 09:32:21,269] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.0782202]
[2019-03-23 09:32:21,270] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.99404956, 76.73921909, 1.0, 2.0, 0.4055641658185022, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 456272.3955963892, 456272.3955963892, 129291.8402022765]
[2019-03-23 09:32:21,272] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 09:32:21,274] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.0508536e-26 1.0000000e+00 1.1552563e-36 7.9273505e-25 0.0000000e+00], sampled 0.9838834043367012
[2019-03-23 09:32:26,728] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.0782202]
[2019-03-23 09:32:26,730] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [15.3, 75.33333333333334, 1.0, 2.0, 0.2393239831903002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 259839.654514331, 259839.6545143306, 81426.7252842136]
[2019-03-23 09:32:26,731] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 09:32:26,733] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.0508536e-26 1.0000000e+00 1.1552563e-36 7.9273505e-25 0.0000000e+00], sampled 0.7372988231933972
[2019-03-23 09:32:37,086] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.0782202]
[2019-03-23 09:32:37,087] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [28.2, 57.0, 1.0, 2.0, 0.4328296820818145, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8526513090031157, 6.944865731442352, 6.9112, 95.55320902365817, 984602.5100232285, 971091.6615947577, 241178.7683891152]
[2019-03-23 09:32:37,088] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 09:32:37,092] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.9351888e-23 1.0000000e+00 1.3644877e-31 2.6008407e-20 2.9743706e-34], sampled 0.7114896983529017
[2019-03-23 09:32:52,691] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.0782202]
[2019-03-23 09:32:52,692] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.8213618, 65.70116449666668, 1.0, 2.0, 0.4228742305016239, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 470611.2126193884, 470611.2126193881, 128585.9974168824]
[2019-03-23 09:32:52,694] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 09:32:52,697] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.0511040e-26 1.0000000e+00 1.1554590e-36 7.9282577e-25 0.0000000e+00], sampled 0.853715792516248
[2019-03-23 09:32:55,286] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.0782202]
[2019-03-23 09:32:55,287] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.9, 55.0, 1.0, 2.0, 0.3927627159145725, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 443364.5483101628, 443364.5483101625, 128952.5456790185]
[2019-03-23 09:32:55,288] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 09:32:55,291] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.0508536e-26 1.0000000e+00 1.1552563e-36 7.9273505e-25 0.0000000e+00], sampled 0.36971516179292485
[2019-03-23 09:33:20,928] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.0782202]
[2019-03-23 09:33:20,930] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.91821557, 79.543334415, 1.0, 2.0, 0.331754375588461, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 364786.7230561906, 364786.7230561903, 119292.2366193156]
[2019-03-23 09:33:20,931] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 09:33:20,934] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.0508536e-26 1.0000000e+00 1.1552563e-36 7.9273505e-25 0.0000000e+00], sampled 0.8785614024869925
[2019-03-23 09:33:28,237] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.0782202]
[2019-03-23 09:33:28,238] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.87317820666667, 95.70343658666667, 1.0, 2.0, 0.5221297769779046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 595656.1207505441, 595656.1207505438, 147132.2987306742]
[2019-03-23 09:33:28,239] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 09:33:28,243] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.0852806e-26 1.0000000e+00 1.1825171e-36 8.0532325e-25 0.0000000e+00], sampled 0.5969487875711131
[2019-03-23 09:33:34,895] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.0782202]
[2019-03-23 09:33:34,899] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.697455555, 98.07150061, 1.0, 2.0, 0.4692483960253454, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 535311.3911511152, 535311.3911511152, 141186.9637277388]
[2019-03-23 09:33:34,901] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 09:33:34,906] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.0508536e-26 1.0000000e+00 1.1552563e-36 7.9273505e-25 0.0000000e+00], sampled 0.7153575040869017
[2019-03-23 09:33:35,968] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.0782202]
[2019-03-23 09:33:35,969] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.8, 97.0, 1.0, 2.0, 0.4065275333712762, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 458774.851544758, 458774.8515447577, 125802.5659645272]
[2019-03-23 09:33:35,969] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 09:33:35,971] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.0693686e-26 1.0000000e+00 1.1699001e-36 7.9951048e-25 0.0000000e+00], sampled 0.31771838502683813
[2019-03-23 09:33:47,726] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 09:33:48,155] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 09:33:48,292] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 09:33:48,316] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 09:33:48,353] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 09:33:49,368] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 750000, evaluation results [750000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 09:33:53,934] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.7082840e-16 1.0000000e+00 1.1588927e-22 6.3143867e-15 1.4526167e-24], sum to 1.0000
[2019-03-23 09:33:53,940] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8841
[2019-03-23 09:33:53,947] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.66666666666667, 90.33333333333334, 1.0, 2.0, 0.4008210139544156, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 452571.3610804717, 452571.3610804714, 125415.8076099842], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4346400.0000, 
sim time next is 4347000.0000, 
raw observation next is [20.0, 88.5, 1.0, 2.0, 0.4074401858708781, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 460515.8393843946, 460515.8393843949, 126293.9109314966], 
processed observation next is [1.0, 0.30434782608695654, 0.5454545454545454, 0.885, 1.0, 1.0, 0.2593002323385976, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17056142199422022, 0.17056142199422034, 0.30803392910121125], 
reward next is 0.6920, 
noisyNet noise sample is [array([-0.10913308], dtype=float32), -2.4042969]. 
=============================================
[2019-03-23 09:33:53,962] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[41.661793]
 [41.77331 ]
 [41.922855]
 [42.030155]
 [42.18382 ]], R is [[41.79310226]
 [42.06927872]
 [42.34339905]
 [42.61659241]
 [42.88869476]].
[2019-03-23 09:33:55,538] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.0774916e-25 1.0000000e+00 3.1648243e-34 1.5761645e-22 3.8722946e-38], sum to 1.0000
[2019-03-23 09:33:55,547] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5010
[2019-03-23 09:33:55,554] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 58.0, 1.0, 2.0, 0.4764709938433758, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 543689.9863066991, 543689.9863066991, 138394.0136003332], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4388400.0000, 
sim time next is 4389000.0000, 
raw observation next is [26.83333333333333, 59.16666666666667, 1.0, 2.0, 0.4801127651828922, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 547844.1225472562, 547844.1225472562, 138851.6601585994], 
processed observation next is [1.0, 0.8260869565217391, 0.8560606060606059, 0.5916666666666667, 1.0, 1.0, 0.3501409564786152, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20290523057305784, 0.20290523057305784, 0.3386625857526815], 
reward next is 0.6613, 
noisyNet noise sample is [array([-1.2827059], dtype=float32), 2.3663497]. 
=============================================
[2019-03-23 09:33:55,569] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[64.87092]
 [64.87092]
 [64.87092]
 [64.87092]
 [64.87092]], R is [[64.86838531]
 [64.88215637]
 [64.89533997]
 [64.90784454]
 [64.91975403]].
[2019-03-23 09:33:58,804] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.8105929e-29 1.0000000e+00 0.0000000e+00 2.0496717e-27 0.0000000e+00], sum to 1.0000
[2019-03-23 09:33:58,814] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2603
[2019-03-23 09:33:58,823] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 70.0, 1.0, 2.0, 0.5225109563582991, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 594881.3005703798, 594881.3005703798, 145831.6221109789], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4453200.0000, 
sim time next is 4453800.0000, 
raw observation next is [25.83333333333334, 70.66666666666667, 1.0, 2.0, 0.5232435374464531, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 595782.0606361036, 595782.0606361036, 145870.3612189721], 
processed observation next is [0.0, 0.5652173913043478, 0.8106060606060609, 0.7066666666666667, 1.0, 1.0, 0.4040544218080664, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22066002245781616, 0.22066002245781616, 0.3557813688267612], 
reward next is 0.6442, 
noisyNet noise sample is [array([1.4890165], dtype=float32), 1.1794658]. 
=============================================
[2019-03-23 09:34:04,392] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.5093565e-27 1.0000000e+00 4.5509317e-36 1.9167044e-24 0.0000000e+00], sum to 1.0000
[2019-03-23 09:34:04,400] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9823
[2019-03-23 09:34:04,406] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666667, 73.0, 1.0, 2.0, 0.4193948231185016, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 476367.6687076163, 476367.6687076163, 128979.2088886736], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4540200.0000, 
sim time next is 4540800.0000, 
raw observation next is [22.33333333333334, 73.0, 1.0, 2.0, 0.4111909817504058, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 466085.6192302086, 466085.6192302089, 127481.2326137172], 
processed observation next is [0.0, 0.5652173913043478, 0.6515151515151518, 0.73, 1.0, 1.0, 0.2639887271880072, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17262430341859578, 0.1726243034185959, 0.3109298356432127], 
reward next is 0.6891, 
noisyNet noise sample is [array([0.7894467], dtype=float32), -1.2627324]. 
=============================================
[2019-03-23 09:34:06,316] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.5230708e-24 1.0000000e+00 8.9941140e-32 5.4033495e-23 2.8820672e-34], sum to 1.0000
[2019-03-23 09:34:06,323] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2539
[2019-03-23 09:34:06,326] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 95.0, 1.0, 2.0, 0.2243494969158671, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 243589.8426306355, 243589.8426306352, 78139.47833202117], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4596600.0000, 
sim time next is 4597200.0000, 
raw observation next is [14.0, 94.0, 1.0, 2.0, 0.2209322005950106, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 239878.5620027322, 239878.5620027325, 77376.19655660752], 
processed observation next is [1.0, 0.21739130434782608, 0.2727272727272727, 0.94, 1.0, 1.0, 0.026165250743763226, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08884391185286378, 0.08884391185286389, 0.18872243062587202], 
reward next is 0.8113, 
noisyNet noise sample is [array([-1.0075344], dtype=float32), 1.2939773]. 
=============================================
[2019-03-23 09:34:17,966] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.7519562e-22 1.0000000e+00 9.9588959e-29 1.8883266e-18 1.7174343e-32], sum to 1.0000
[2019-03-23 09:34:17,972] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4300
[2019-03-23 09:34:17,977] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 99.0, 1.0, 2.0, 0.6562152728558059, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 748911.8448260283, 748911.8448260286, 161159.9983364608], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4798200.0000, 
sim time next is 4798800.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.696145695574248, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 794429.1991245543, 794429.1991245543, 167179.0051708645], 
processed observation next is [1.0, 0.5652173913043478, 0.5909090909090909, 1.0, 1.0, 1.0, 0.62018211946781, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2942330367127979, 0.2942330367127979, 0.40775367114844996], 
reward next is 0.5922, 
noisyNet noise sample is [array([0.4454591], dtype=float32), -1.1645464]. 
=============================================
[2019-03-23 09:34:20,051] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.8664974e-26 1.0000000e+00 1.5709184e-37 2.9876366e-22 0.0000000e+00], sum to 1.0000
[2019-03-23 09:34:20,060] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9281
[2019-03-23 09:34:20,064] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.16666666666667, 99.0, 1.0, 2.0, 0.4087508347989057, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 463591.7428906097, 463591.7428906097, 127441.2571388826], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4855800.0000, 
sim time next is 4856400.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4063285830699455, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 460656.1243476302, 460656.1243476305, 127080.6610766647], 
processed observation next is [1.0, 0.21739130434782608, 0.5, 1.0, 1.0, 1.0, 0.2579107288374319, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1706133793880112, 0.1706133793880113, 0.30995283189430417], 
reward next is 0.6900, 
noisyNet noise sample is [array([-0.37478787], dtype=float32), -0.9143852]. 
=============================================
[2019-03-23 09:34:21,801] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.3200149e-26 1.0000000e+00 1.2555710e-34 1.5030118e-22 7.8764202e-37], sum to 1.0000
[2019-03-23 09:34:21,809] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0970
[2019-03-23 09:34:21,812] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 83.0, 1.0, 2.0, 0.4634142747169198, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 525323.444834123, 525323.444834123, 132626.7417556417], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4884600.0000, 
sim time next is 4885200.0000, 
raw observation next is [21.0, 83.0, 1.0, 2.0, 0.5158446731092655, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 584825.3995219395, 584825.3995219395, 138180.628165716], 
processed observation next is [1.0, 0.5652173913043478, 0.5909090909090909, 0.83, 1.0, 1.0, 0.39480584138658187, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21660199982294054, 0.21660199982294054, 0.3370259223554049], 
reward next is 0.6630, 
noisyNet noise sample is [array([-0.84745777], dtype=float32), -1.6174575]. 
=============================================
[2019-03-23 09:34:21,907] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.7222249e-23 1.0000000e+00 1.0937519e-32 6.9532576e-20 1.4715764e-36], sum to 1.0000
[2019-03-23 09:34:21,916] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9198
[2019-03-23 09:34:21,923] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 76.33333333333334, 1.0, 2.0, 0.8346573625723921, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 949749.3659881642, 949749.3659881642, 182358.611699206], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4893600.0000, 
sim time next is 4894200.0000, 
raw observation next is [22.5, 75.5, 1.0, 2.0, 0.8329676146656159, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 948003.3184229999, 948003.3184229999, 182261.2097861601], 
processed observation next is [1.0, 0.6521739130434783, 0.6590909090909091, 0.755, 1.0, 1.0, 0.7912095183320197, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.35111234015666665, 0.35111234015666665, 0.4445395360638051], 
reward next is 0.5555, 
noisyNet noise sample is [array([-0.6620923], dtype=float32), 0.1459617]. 
=============================================
[2019-03-23 09:34:25,057] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.6071618e-27 1.0000000e+00 2.6406064e-37 4.3649106e-24 0.0000000e+00], sum to 1.0000
[2019-03-23 09:34:25,066] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9642
[2019-03-23 09:34:25,070] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 94.00000000000001, 1.0, 2.0, 0.3418571505819424, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 374109.7031152737, 374109.7031152737, 115080.8846231113], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4954200.0000, 
sim time next is 4954800.0000, 
raw observation next is [17.0, 94.0, 1.0, 2.0, 0.4006557242413041, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 438673.1984432286, 438673.1984432283, 119675.6506247765], 
processed observation next is [1.0, 0.34782608695652173, 0.4090909090909091, 0.94, 1.0, 1.0, 0.2508196553016301, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16247155497897356, 0.16247155497897345, 0.2918918307921378], 
reward next is 0.7081, 
noisyNet noise sample is [array([-1.8567276], dtype=float32), -0.1017199]. 
=============================================
[2019-03-23 09:34:25,475] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.2185021e-24 1.0000000e+00 2.0123381e-33 1.4722981e-17 1.9503784e-35], sum to 1.0000
[2019-03-23 09:34:25,481] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2065
[2019-03-23 09:34:25,485] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 73.0, 1.0, 2.0, 0.5302694695999763, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 576339.0588510075, 576339.0588510075, 129762.0975925982], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4964400.0000, 
sim time next is 4965000.0000, 
raw observation next is [19.0, 73.0, 1.0, 2.0, 0.6194325974834399, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 673381.6183565282, 673381.6183565286, 138578.1517523695], 
processed observation next is [1.0, 0.4782608695652174, 0.5, 0.73, 1.0, 1.0, 0.5242907468542999, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.24940059939130674, 0.24940059939130688, 0.33799549207895], 
reward next is 0.6620, 
noisyNet noise sample is [array([0.97921294], dtype=float32), 0.75633824]. 
=============================================
[2019-03-23 09:34:25,499] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[66.16908 ]
 [66.05157 ]
 [66.033875]
 [66.02237 ]
 [66.00641 ]], R is [[66.10382843]
 [66.126297  ]
 [66.13697052]
 [66.14751434]
 [66.15840912]].
[2019-03-23 09:34:31,505] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.5536755e-27 1.0000000e+00 3.3568869e-37 8.6351781e-25 3.1086526e-38], sum to 1.0000
[2019-03-23 09:34:31,512] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6771
[2019-03-23 09:34:31,518] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 83.0, 1.0, 2.0, 0.401303556315889, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 454755.1831054394, 454755.1831054394, 126470.9205580385], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5109000.0000, 
sim time next is 5109600.0000, 
raw observation next is [21.0, 83.0, 1.0, 2.0, 0.401599997068757, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 455095.7677011748, 455095.7677011751, 126501.6253037097], 
processed observation next is [0.0, 0.13043478260869565, 0.5909090909090909, 0.83, 1.0, 1.0, 0.2519999963359462, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16855398803747212, 0.16855398803747226, 0.30854054952124316], 
reward next is 0.6915, 
noisyNet noise sample is [array([-0.86115324], dtype=float32), 0.5223734]. 
=============================================
[2019-03-23 09:34:33,466] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.9907433e-27 1.0000000e+00 1.2589257e-38 8.5085374e-25 0.0000000e+00], sum to 1.0000
[2019-03-23 09:34:33,475] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8993
[2019-03-23 09:34:33,480] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.16666666666667, 82.16666666666667, 1.0, 2.0, 0.4380832557152411, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 499183.8046331533, 499183.8046331533, 132366.9780835424], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5127000.0000, 
sim time next is 5127600.0000, 
raw observation next is [22.33333333333334, 81.33333333333334, 1.0, 2.0, 0.4405094203863841, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 502031.8750374049, 502031.8750374049, 132728.6578790347], 
processed observation next is [0.0, 0.34782608695652173, 0.6515151515151518, 0.8133333333333335, 1.0, 1.0, 0.30063677548298007, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18593773149533513, 0.18593773149533513, 0.3237284338513041], 
reward next is 0.6763, 
noisyNet noise sample is [array([1.0485317], dtype=float32), 0.57557255]. 
=============================================
[2019-03-23 09:34:33,997] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.5451210e-28 1.0000000e+00 0.0000000e+00 4.1578334e-25 0.0000000e+00], sum to 1.0000
[2019-03-23 09:34:34,004] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6598
[2019-03-23 09:34:34,012] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.16666666666666, 74.0, 1.0, 2.0, 0.4615923300512149, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 526702.0508976564, 526702.050897656, 136481.0637562475], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5134200.0000, 
sim time next is 5134800.0000, 
raw observation next is [24.33333333333333, 74.0, 1.0, 2.0, 0.4667924187861602, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 532635.7434217234, 532635.7434217231, 137374.8339301947], 
processed observation next is [0.0, 0.43478260869565216, 0.7424242424242422, 0.74, 1.0, 1.0, 0.3334905234827002, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19727249756360124, 0.19727249756360116, 0.3350605705614505], 
reward next is 0.6649, 
noisyNet noise sample is [array([-0.17932059], dtype=float32), 0.28106904]. 
=============================================
[2019-03-23 09:34:38,028] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-23 09:34:38,030] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 09:34:38,032] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:34:38,033] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 09:34:38,034] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:34:38,034] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 09:34:38,034] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 09:34:38,035] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:34:38,035] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 09:34:38,036] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:34:38,039] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:34:38,051] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run32
[2019-03-23 09:34:38,075] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run32
[2019-03-23 09:34:38,099] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run32
[2019-03-23 09:34:38,130] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run32
[2019-03-23 09:34:38,131] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run32
[2019-03-23 09:34:46,202] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.1094528]
[2019-03-23 09:34:46,203] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.83933241, 54.07262177, 1.0, 2.0, 0.3562379890056557, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 386816.7792121614, 386816.7792121617, 119442.7944745883]
[2019-03-23 09:34:46,204] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 09:34:46,206] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.0615364e-26 1.0000000e+00 1.0494280e-36 2.3993414e-23 0.0000000e+00], sampled 0.5449051155473019
[2019-03-23 09:34:58,708] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.1094528]
[2019-03-23 09:34:58,709] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.13333333333333, 65.33333333333333, 1.0, 2.0, 0.722226938235516, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 821911.5794462501, 821911.5794462501, 170288.9032268362]
[2019-03-23 09:34:58,710] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 09:34:58,716] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.5643611e-26 1.0000000e+00 1.8289349e-36 4.3215378e-23 0.0000000e+00], sampled 0.02739807062632993
[2019-03-23 09:35:01,328] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.1094528]
[2019-03-23 09:35:01,330] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [15.74822146, 74.55881213, 1.0, 2.0, 0.2251707210915657, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 244470.0013211958, 244470.0013211954, 80991.63399048052]
[2019-03-23 09:35:01,330] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 09:35:01,333] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.09715676e-26 1.00000000e+00 1.09863378e-36 2.48222799e-23
 0.00000000e+00], sampled 0.8940708194701078
[2019-03-23 09:35:15,083] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.1094528]
[2019-03-23 09:35:15,085] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.88794281, 82.4283929, 1.0, 2.0, 0.3776079426129908, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 423331.8401748994, 423331.8401748994, 126086.0328391363]
[2019-03-23 09:35:15,086] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 09:35:15,087] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.1121497e-26 1.0000000e+00 1.1195505e-36 2.5181647e-23 0.0000000e+00], sampled 0.6200591526963638
[2019-03-23 09:35:22,239] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.1094528]
[2019-03-23 09:35:22,240] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.16666666666667, 88.0, 1.0, 2.0, 0.6973431387264672, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 794213.9119341365, 794213.9119341362, 173632.1424101411]
[2019-03-23 09:35:22,240] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 09:35:22,244] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.5519029e-26 1.0000000e+00 1.8207347e-36 4.6440863e-23 0.0000000e+00], sampled 0.3912688576294243
[2019-03-23 09:35:39,811] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.1094528]
[2019-03-23 09:35:39,814] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.1, 59.33333333333334, 1.0, 2.0, 0.2990162270961952, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 324666.4265860296, 324666.4265860293, 115432.9520253553]
[2019-03-23 09:35:39,814] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 09:35:39,820] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.0716512e-26 1.0000000e+00 1.0633305e-36 2.4226931e-23 0.0000000e+00], sampled 0.9300301691510428
[2019-03-23 09:35:59,116] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.1094528]
[2019-03-23 09:35:59,117] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [17.94336914, 48.16011613, 1.0, 2.0, 0.2747177086470565, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 298276.9866020316, 298276.9866020312, 82492.22547825183]
[2019-03-23 09:35:59,118] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 09:35:59,123] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.09715676e-26 1.00000000e+00 1.09863378e-36 2.48222799e-23
 0.00000000e+00], sampled 0.04344641601547461
[2019-03-23 09:36:12,898] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.1094528]
[2019-03-23 09:36:12,900] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.2, 67.0, 1.0, 2.0, 0.2970932028263771, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 95.55338769695034, 323303.824226727, 323303.8242267263, 115562.2210904666]
[2019-03-23 09:36:12,900] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 09:36:12,904] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.0920459e-26 1.0000000e+00 1.0915321e-36 2.4702692e-23 0.0000000e+00], sampled 0.7814614220941319
[2019-03-23 09:36:18,072] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 09:36:18,161] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 09:36:18,180] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 09:36:18,198] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 09:36:18,422] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 09:36:19,436] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 775000, evaluation results [775000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 09:36:24,695] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.1348485e-15 1.0000000e+00 1.1466422e-21 8.2360242e-13 3.8474548e-23], sum to 1.0000
[2019-03-23 09:36:24,702] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6282
[2019-03-23 09:36:24,706] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.55, 67.5, 1.0, 2.0, 0.7220951068539286, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 820715.8729440436, 820715.8729440436, 164944.4124537868], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5301000.0000, 
sim time next is 5301600.0000, 
raw observation next is [23.83333333333333, 65.66666666666666, 1.0, 2.0, 0.7434285544159923, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 845077.1383972933, 845077.1383972936, 168025.0993045166], 
processed observation next is [1.0, 0.34782608695652173, 0.7196969696969695, 0.6566666666666666, 1.0, 1.0, 0.6792856930199903, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.31299153273973823, 0.3129915327397384, 0.4098173153768698], 
reward next is 0.5902, 
noisyNet noise sample is [array([-0.627111], dtype=float32), -0.27972624]. 
=============================================
[2019-03-23 09:36:24,927] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.3467960e-08 3.1646021e-05 6.8517775e-11 9.9996841e-01 4.6004671e-12], sum to 1.0000
[2019-03-23 09:36:24,940] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8762
[2019-03-23 09:36:24,943] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.21666666666667, 53.33333333333334, 1.0, 2.0, 0.5683726846329133, 1.0, 2.0, 0.5683726846329133, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1283606.526645015, 1283606.526645015, 251982.2994165552], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5316600.0000, 
sim time next is 5317200.0000, 
raw observation next is [29.4, 53.0, 1.0, 2.0, 0.4772924466122322, 1.0, 2.0, 0.4772924466122322, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1077956.970535707, 1077956.970535707, 228780.2430868943], 
processed observation next is [1.0, 0.5652173913043478, 0.9727272727272727, 0.53, 1.0, 1.0, 0.3466155582652902, 1.0, 1.0, 0.3466155582652902, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3992433224206322, 0.3992433224206322, 0.5580005928948641], 
reward next is 0.4420, 
noisyNet noise sample is [array([1.1584517], dtype=float32), 0.93298554]. 
=============================================
[2019-03-23 09:36:26,106] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.8230608e-14 1.0000000e+00 4.6000544e-18 3.8047671e-10 8.3772490e-21], sum to 1.0000
[2019-03-23 09:36:26,112] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0936
[2019-03-23 09:36:26,116] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.05, 87.0, 1.0, 2.0, 0.4914333024727628, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 559138.0881158841, 559138.0881158841, 137103.0313572795], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5369400.0000, 
sim time next is 5370000.0000, 
raw observation next is [20.86666666666667, 87.0, 1.0, 2.0, 0.46835357624055, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 532349.9456685305, 532349.9456685305, 134181.7734272006], 
processed observation next is [1.0, 0.13043478260869565, 0.5848484848484851, 0.87, 1.0, 1.0, 0.3354419703006875, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1971666465439002, 0.1971666465439002, 0.32727261811512337], 
reward next is 0.6727, 
noisyNet noise sample is [array([-0.8779564], dtype=float32), 0.1426642]. 
=============================================
[2019-03-23 09:36:26,136] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[35.544083]
 [35.47393 ]
 [35.635883]
 [35.83346 ]
 [35.64671 ]], R is [[36.10784531]
 [36.41237259]
 [36.71115875]
 [37.00146484]
 [37.29491425]].
[2019-03-23 09:36:31,901] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.1003394e-24 1.0000000e+00 4.3036336e-33 3.0426417e-19 0.0000000e+00], sum to 1.0000
[2019-03-23 09:36:31,911] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0012
[2019-03-23 09:36:31,923] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 93.0, 1.0, 2.0, 0.3773205449656123, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 423709.0887135759, 423709.0887135762, 122076.1106427811], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5443800.0000, 
sim time next is 5444400.0000, 
raw observation next is [18.8, 93.0, 1.0, 2.0, 0.3764856460970122, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 422760.5403993007, 422760.5403993009, 121999.2319490961], 
processed observation next is [1.0, 0.0, 0.49090909090909096, 0.93, 1.0, 1.0, 0.2206070576212652, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1565779779256669, 0.15657797792566702, 0.29755910231486854], 
reward next is 0.7024, 
noisyNet noise sample is [array([-0.54619694], dtype=float32), 0.54267603]. 
=============================================
[2019-03-23 09:36:32,385] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.2338043e-22 1.0000000e+00 1.6346182e-30 6.0082621e-17 1.9304688e-33], sum to 1.0000
[2019-03-23 09:36:32,390] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8790
[2019-03-23 09:36:32,400] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1257839.916014106 W.
[2019-03-23 09:36:32,403] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.55, 71.5, 1.0, 2.0, 0.3712156344558217, 1.0, 2.0, 0.3712156344558217, 1.0, 2.0, 0.7510292161495155, 6.9112, 6.9112, 77.3421103, 1257839.916014106, 1257839.916014106, 291659.3695780764], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5484600.0000, 
sim time next is 5485200.0000, 
raw observation next is [25.73333333333333, 70.66666666666667, 1.0, 2.0, 0.3737259849603285, 1.0, 2.0, 0.3737259849603285, 1.0, 2.0, 0.7559796468911757, 6.9112, 6.9112, 77.3421103, 1265721.944023801, 1265721.944023801, 292984.5444901702], 
processed observation next is [1.0, 0.4782608695652174, 0.8060606060606059, 0.7066666666666667, 1.0, 1.0, 0.2171574812004106, 1.0, 1.0, 0.2171574812004106, 1.0, 1.0, 0.6513994955588225, 0.0, 0.0, 0.5085185399722538, 0.4687859051940004, 0.4687859051940004, 0.7145964499760249], 
reward next is 0.2854, 
noisyNet noise sample is [array([1.166422], dtype=float32), -1.0110148]. 
=============================================
[2019-03-23 09:36:33,116] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.7688240e-29 1.0000000e+00 0.0000000e+00 1.7968701e-26 0.0000000e+00], sum to 1.0000
[2019-03-23 09:36:33,123] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4601
[2019-03-23 09:36:33,129] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.2, 91.66666666666666, 1.0, 2.0, 0.3266550761551892, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 357410.055713587, 357410.0557135867, 113954.584086342], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5460600.0000, 
sim time next is 5461200.0000, 
raw observation next is [17.2, 90.0, 1.0, 2.0, 0.3203618277270365, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 349246.3897203763, 349246.3897203763, 113052.1303451766], 
processed observation next is [1.0, 0.21739130434782608, 0.41818181818181815, 0.9, 1.0, 1.0, 0.15045228465879557, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12935051471125047, 0.12935051471125047, 0.27573690328091854], 
reward next is 0.7243, 
noisyNet noise sample is [array([0.35289124], dtype=float32), -0.34452426]. 
=============================================
[2019-03-23 09:36:34,979] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.8222475e-10 9.9999905e-01 1.2956373e-13 9.1693670e-07 5.2045800e-15], sum to 1.0000
[2019-03-23 09:36:34,985] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2366
[2019-03-23 09:36:34,991] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.43333333333334, 85.0, 1.0, 2.0, 0.4352765804092055, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 495334.3388219048, 495334.3388219045, 131344.7725281279], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5530800.0000, 
sim time next is 5531400.0000, 
raw observation next is [21.35, 85.5, 1.0, 2.0, 0.4341929123115352, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 494058.7690488191, 494058.7690488191, 131194.5307691459], 
processed observation next is [1.0, 0.0, 0.6068181818181819, 0.855, 1.0, 1.0, 0.29274114038941895, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1829847292773404, 0.1829847292773404, 0.31998666041255097], 
reward next is 0.6800, 
noisyNet noise sample is [array([0.3562949], dtype=float32), -1.2680359]. 
=============================================
[2019-03-23 09:36:36,763] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.4335039e-24 1.0000000e+00 9.6837166e-32 2.6481329e-21 2.4260447e-35], sum to 1.0000
[2019-03-23 09:36:36,772] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3159
[2019-03-23 09:36:36,779] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.7, 79.0, 1.0, 2.0, 0.4558791881559908, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 519652.1754336376, 519652.1754336376, 134469.0918500514], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5526000.0000, 
sim time next is 5526600.0000, 
raw observation next is [22.51666666666667, 79.83333333333334, 1.0, 2.0, 0.454017921860086, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 517446.5025543025, 517446.5025543023, 134151.7791173873], 
processed observation next is [1.0, 1.0, 0.659848484848485, 0.7983333333333335, 1.0, 1.0, 0.3175224023251075, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19164685279788982, 0.19164685279788973, 0.3271994612619203], 
reward next is 0.6728, 
noisyNet noise sample is [array([-0.48802894], dtype=float32), -0.9979952]. 
=============================================
[2019-03-23 09:36:37,880] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.2009424e-21 1.0000000e+00 5.3354549e-29 2.2110088e-16 3.9689340e-31], sum to 1.0000
[2019-03-23 09:36:37,887] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7532
[2019-03-23 09:36:37,892] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.63333333333333, 86.0, 1.0, 2.0, 0.4735974077863012, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 539598.274622302, 539598.274622302, 136007.1439640746], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5557200.0000, 
sim time next is 5557800.0000, 
raw observation next is [21.91666666666666, 85.0, 1.0, 2.0, 0.4819242261284669, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 549357.0145560117, 549357.0145560119, 137269.8572336963], 
processed observation next is [1.0, 0.30434782608695654, 0.6325757575757573, 0.85, 1.0, 1.0, 0.35240528266058363, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20346556094667098, 0.20346556094667106, 0.3348045298382836], 
reward next is 0.6652, 
noisyNet noise sample is [array([1.3250325], dtype=float32), 0.62737274]. 
=============================================
[2019-03-23 09:36:38,591] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.4724893e-20 1.0000000e+00 7.7385968e-27 3.0654193e-18 2.3024140e-29], sum to 1.0000
[2019-03-23 09:36:38,600] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6067
[2019-03-23 09:36:38,606] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.7, 82.0, 1.0, 2.0, 0.4393059081814666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 499921.5128512738, 499921.5128512738, 131751.1010450535], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5597400.0000, 
sim time next is 5598000.0000, 
raw observation next is [20.5, 87.0, 1.0, 2.0, 0.4245287692319579, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 481669.434549061, 481669.434549061, 129077.6790257556], 
processed observation next is [1.0, 0.8260869565217391, 0.5681818181818182, 0.87, 1.0, 1.0, 0.28066096153994735, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1783960868700226, 0.1783960868700226, 0.3148236073798917], 
reward next is 0.6852, 
noisyNet noise sample is [array([-1.2140493], dtype=float32), -0.5001432]. 
=============================================
[2019-03-23 09:36:38,623] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[52.08488 ]
 [52.943405]
 [54.1185  ]
 [54.444054]
 [55.011032]], R is [[52.5737114 ]
 [52.72663116]
 [52.87194061]
 [53.00978851]
 [53.14087677]].
[2019-03-23 09:36:44,000] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.0650579e-27 1.0000000e+00 1.5590026e-37 4.4995467e-19 0.0000000e+00], sum to 1.0000
[2019-03-23 09:36:44,011] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5507
[2019-03-23 09:36:44,014] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.5, 83.0, 1.0, 2.0, 0.2300987668679725, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 249833.7765943584, 249833.7765943587, 79808.73876209544], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5668800.0000, 
sim time next is 5669400.0000, 
raw observation next is [15.5, 82.0, 1.0, 2.0, 0.2261814881183015, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 245579.4486429417, 245579.4486429417, 78871.39301942098], 
processed observation next is [0.0, 0.6086956521739131, 0.3409090909090909, 0.82, 1.0, 1.0, 0.03272686014787685, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09095535134923766, 0.09095535134923766, 0.19236925126688045], 
reward next is 0.8076, 
noisyNet noise sample is [array([0.43400618], dtype=float32), 1.7139378]. 
=============================================
[2019-03-23 09:36:49,922] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.6188666e-28 1.0000000e+00 0.0000000e+00 9.4526698e-20 0.0000000e+00], sum to 1.0000
[2019-03-23 09:36:49,933] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9162
[2019-03-23 09:36:49,937] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.96666666666667, 60.0, 1.0, 2.0, 0.2160776379385588, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 234606.4180994516, 234606.4180994513, 73760.75076979672], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5780400.0000, 
sim time next is 5781000.0000, 
raw observation next is [16.78333333333333, 61.0, 1.0, 2.0, 0.213809530154092, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 232143.2311165889, 232143.2311165886, 73442.35144947366], 
processed observation next is [0.0, 0.9130434782608695, 0.3992424242424242, 0.61, 1.0, 1.0, 0.01726191269261497, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08597897448762552, 0.08597897448762541, 0.17912768646213087], 
reward next is 0.8209, 
noisyNet noise sample is [array([-0.01889459], dtype=float32), 0.03530481]. 
=============================================
[2019-03-23 09:36:49,957] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[79.05887]
 [79.05887]
 [79.05887]
 [79.05887]
 [79.05887]], R is [[79.08914948]
 [79.1183548 ]
 [79.14651489]
 [79.17372894]
 [79.20018005]].
[2019-03-23 09:36:54,210] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.7618028e-24 1.0000000e+00 3.5018854e-34 7.7049188e-22 9.1715886e-37], sum to 1.0000
[2019-03-23 09:36:54,219] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5985
[2019-03-23 09:36:54,221] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.6, 44.16666666666666, 1.0, 2.0, 0.5961758204130166, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 664373.8071816183, 664373.8071816183, 141754.7760420842], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5843400.0000, 
sim time next is 5844000.0000, 
raw observation next is [25.7, 43.33333333333334, 1.0, 2.0, 0.6137031151895298, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 683239.1108491528, 683239.1108491528, 143445.1455991582], 
processed observation next is [1.0, 0.6521739130434783, 0.8045454545454546, 0.4333333333333334, 1.0, 1.0, 0.5171288939869122, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.25305152253672325, 0.25305152253672325, 0.3498662087784346], 
reward next is 0.6501, 
noisyNet noise sample is [array([0.72886246], dtype=float32), -0.021385556]. 
=============================================
[2019-03-23 09:36:54,237] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[72.31633 ]
 [72.226685]
 [72.226555]
 [72.399506]
 [72.57878 ]], R is [[72.26039124]
 [72.19204712]
 [72.11196136]
 [72.02069855]
 [71.94114685]].
[2019-03-23 09:36:59,489] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.3298096e-27 1.0000000e+00 1.0949185e-36 4.0807207e-21 0.0000000e+00], sum to 1.0000
[2019-03-23 09:36:59,497] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0195
[2019-03-23 09:36:59,502] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.3, 90.0, 1.0, 2.0, 0.3452596873042789, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 383344.676788314, 383344.6767883142, 117419.8922196493], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5976000.0000, 
sim time next is 5976600.0000, 
raw observation next is [18.2, 90.0, 1.0, 2.0, 0.344855891585025, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 382433.5273235979, 382433.5273235976, 117199.0718558518], 
processed observation next is [1.0, 0.17391304347826086, 0.4636363636363636, 0.9, 1.0, 1.0, 0.18106986448128123, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1416420471568881, 0.141642047156888, 0.28585139477037025], 
reward next is 0.7141, 
noisyNet noise sample is [array([-0.58147514], dtype=float32), -0.6758948]. 
=============================================
[2019-03-23 09:37:04,952] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.3578317e-28 1.0000000e+00 2.7102269e-37 1.2121023e-22 0.0000000e+00], sum to 1.0000
[2019-03-23 09:37:04,961] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8024
[2019-03-23 09:37:04,965] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.53333333333333, 82.0, 1.0, 2.0, 0.2892139203131828, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 314039.8151719425, 314039.8151719428, 105295.7856772825], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6158400.0000, 
sim time next is 6159000.0000, 
raw observation next is [17.61666666666667, 81.5, 1.0, 2.0, 0.2903901295510009, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 315317.4033332423, 315317.4033332421, 105864.9882800749], 
processed observation next is [1.0, 0.2608695652173913, 0.4371212121212123, 0.815, 1.0, 1.0, 0.11298766193875112, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1167842234567564, 0.11678422345675633, 0.2582072884879876], 
reward next is 0.7418, 
noisyNet noise sample is [array([-1.7987063], dtype=float32), -0.87884307]. 
=============================================
[2019-03-23 09:37:04,975] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[73.997215]
 [74.02668 ]
 [74.03142 ]
 [74.034004]
 [74.049706]], R is [[73.97718811]
 [73.98059845]
 [73.98535156]
 [73.99123383]
 [73.9981308 ]].
[2019-03-23 09:37:08,098] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-23 09:37:08,100] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 09:37:08,101] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:37:08,101] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 09:37:08,102] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 09:37:08,102] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:37:08,102] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:37:08,103] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 09:37:08,104] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 09:37:08,104] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:37:08,105] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:37:08,119] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run33
[2019-03-23 09:37:08,147] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run33
[2019-03-23 09:37:08,148] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run33
[2019-03-23 09:37:08,149] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run33
[2019-03-23 09:37:08,242] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run33
[2019-03-23 09:37:22,208] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.1208987]
[2019-03-23 09:37:22,209] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [30.9609917, 65.07158764, 1.0, 2.0, 0.9195380059409796, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 1033483.48943279, 1033483.48943279, 215772.8244666329]
[2019-03-23 09:37:22,210] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 09:37:22,212] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.7864145e-28 1.0000000e+00 5.4507792e-38 1.8957558e-23 0.0000000e+00], sampled 0.6621636457773208
[2019-03-23 09:37:47,574] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.1208987]
[2019-03-23 09:37:47,576] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.0, 78.0, 1.0, 2.0, 0.7676562901952988, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 872918.2309250328, 872918.2309250328, 171746.4472320341]
[2019-03-23 09:37:47,576] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 09:37:47,579] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [5.2493137e-28 1.0000000e+00 6.1774371e-38 2.0495663e-23 0.0000000e+00], sampled 0.4795760276451291
[2019-03-23 09:37:55,554] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.1208987]
[2019-03-23 09:37:55,556] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.13333333333333, 59.33333333333334, 1.0, 2.0, 0.5701339017308776, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 650364.8566286435, 650364.8566286435, 154596.8884608084]
[2019-03-23 09:37:55,560] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 09:37:55,562] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.7864145e-28 1.0000000e+00 5.4507792e-38 1.8957558e-23 0.0000000e+00], sampled 0.12416719821800448
[2019-03-23 09:38:05,840] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.1208987]
[2019-03-23 09:38:05,842] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.21130899166667, 96.78111118666668, 1.0, 2.0, 0.5057521832422339, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 576026.5562853238, 576026.5562853235, 147867.2379498179]
[2019-03-23 09:38:05,843] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 09:38:05,846] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.7864145e-28 1.0000000e+00 5.4507792e-38 1.8957558e-23 0.0000000e+00], sampled 0.31405004139662285
[2019-03-23 09:38:06,291] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.1208987]
[2019-03-23 09:38:06,292] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.33333333333334, 94.0, 1.0, 2.0, 0.8297784087676588, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 945303.3328201764, 945303.332820176, 182718.845317171]
[2019-03-23 09:38:06,294] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 09:38:06,299] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [5.0880614e-28 1.0000000e+00 5.9215516e-38 1.9961322e-23 0.0000000e+00], sampled 0.30405215091644366
[2019-03-23 09:38:47,833] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 09:38:48,330] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 09:38:48,370] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 09:38:48,411] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 09:38:48,597] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 09:38:49,613] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 800000, evaluation results [800000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 09:39:04,754] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.6869836e-25 1.0000000e+00 2.7267717e-34 3.3821882e-19 2.5040297e-35], sum to 1.0000
[2019-03-23 09:39:04,759] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1940
[2019-03-23 09:39:04,764] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.3, 89.0, 1.0, 2.0, 0.646039650909571, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 718375.9740513447, 718375.9740513447, 146798.5213958317], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6448800.0000, 
sim time next is 6449400.0000, 
raw observation next is [18.3, 88.5, 1.0, 2.0, 0.6513345234242524, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 723612.7389809107, 723612.7389809107, 147164.0318502174], 
processed observation next is [1.0, 0.6521739130434783, 0.4681818181818182, 0.885, 1.0, 1.0, 0.5641681542803154, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.26800471814107807, 0.26800471814107807, 0.35893666304931077], 
reward next is 0.6411, 
noisyNet noise sample is [array([0.32719412], dtype=float32), -0.21600181]. 
=============================================
[2019-03-23 09:39:04,958] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.4920364e-24 1.0000000e+00 8.9530949e-34 4.1917910e-23 8.0794610e-37], sum to 1.0000
[2019-03-23 09:39:04,965] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1616
[2019-03-23 09:39:04,976] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 93.0, 1.0, 2.0, 0.8292254701608349, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 943112.9787324889, 943112.9787324893, 181110.3766425508], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6429600.0000, 
sim time next is 6430200.0000, 
raw observation next is [20.0, 93.0, 1.0, 2.0, 0.7777490435514968, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 884177.3869120008, 884177.3869120008, 173039.4733729227], 
processed observation next is [1.0, 0.43478260869565216, 0.5454545454545454, 0.93, 1.0, 1.0, 0.7221863044393708, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.327473106263704, 0.327473106263704, 0.42204749603151875], 
reward next is 0.5780, 
noisyNet noise sample is [array([2.6687744], dtype=float32), 0.12424596]. 
=============================================
[2019-03-23 09:39:05,137] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.3210500e-23 1.0000000e+00 2.0769387e-32 6.6225958e-23 5.3453163e-36], sum to 1.0000
[2019-03-23 09:39:05,147] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1709
[2019-03-23 09:39:05,155] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.15, 66.0, 1.0, 2.0, 0.3003556463926924, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 326141.9950388982, 326141.9950388982, 98959.6737322989], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6460200.0000, 
sim time next is 6460800.0000, 
raw observation next is [18.86666666666667, 65.66666666666666, 1.0, 2.0, 0.2872581013100562, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 311915.4291495817, 311915.429149582, 94112.24844525776], 
processed observation next is [1.0, 0.782608695652174, 0.4939393939393941, 0.6566666666666666, 1.0, 1.0, 0.10907262663757022, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11552423301836359, 0.1155242330183637, 0.22954206937867747], 
reward next is 0.7705, 
noisyNet noise sample is [array([-0.81198907], dtype=float32), 0.14504594]. 
=============================================
[2019-03-23 09:39:06,858] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.8117748e-30 1.0000000e+00 0.0000000e+00 7.1768809e-27 0.0000000e+00], sum to 1.0000
[2019-03-23 09:39:06,865] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7764
[2019-03-23 09:39:06,873] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.08333333333333, 79.16666666666667, 1.0, 2.0, 0.2124394687062468, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 230655.3371811942, 230655.3371811945, 74759.3558747121], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6479400.0000, 
sim time next is 6480000.0000, 
raw observation next is [15.0, 80.0, 1.0, 2.0, 0.2110733395491242, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 229171.7182660994, 229171.7182660994, 74644.74873682116], 
processed observation next is [1.0, 0.0, 0.3181818181818182, 0.8, 1.0, 1.0, 0.013841674436405223, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08487841417262941, 0.08487841417262941, 0.18206036277273455], 
reward next is 0.8179, 
noisyNet noise sample is [array([0.48365495], dtype=float32), -0.53554994]. 
=============================================
[2019-03-23 09:39:06,885] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[82.05324]
 [82.05324]
 [82.05324]
 [82.05324]
 [82.05324]], R is [[82.05063629]
 [82.04779053]
 [82.04452515]
 [82.04079437]
 [82.03690338]].
[2019-03-23 09:39:09,156] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.9560007e-26 1.0000000e+00 1.6206009e-35 5.6189621e-22 1.2010919e-38], sum to 1.0000
[2019-03-23 09:39:09,165] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7089
[2019-03-23 09:39:09,170] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.61666666666667, 58.66666666666666, 1.0, 2.0, 0.4480957039537811, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 486646.2203065782, 486646.2203065782, 102926.6476983468], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6515400.0000, 
sim time next is 6516000.0000, 
raw observation next is [18.8, 57.0, 1.0, 2.0, 0.4353145576061355, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 472758.7386672294, 472758.7386672294, 101307.8654451065], 
processed observation next is [1.0, 0.43478260869565216, 0.49090909090909096, 0.57, 1.0, 1.0, 0.2941431970076694, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1750958291360109, 0.1750958291360109, 0.2470923547441622], 
reward next is 0.7529, 
noisyNet noise sample is [array([-1.0944726], dtype=float32), 0.5812186]. 
=============================================
[2019-03-23 09:39:09,184] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[75.47783]
 [75.47783]
 [75.47783]
 [75.47783]
 [75.47783]], R is [[75.47596741]
 [75.47016907]
 [75.46563721]
 [75.46405029]
 [75.4624176 ]].
[2019-03-23 09:39:12,450] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.7857193e-25 1.0000000e+00 2.6640940e-34 1.3594017e-23 2.4634117e-36], sum to 1.0000
[2019-03-23 09:39:12,460] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3938
[2019-03-23 09:39:12,463] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.9, 83.66666666666667, 1.0, 2.0, 0.2156678900026798, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 234161.4269562853, 234161.426956285, 73499.67647677577], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6574800.0000, 
sim time next is 6575400.0000, 
raw observation next is [13.65, 85.0, 1.0, 2.0, 0.2039882763124563, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 221477.3984381277, 221477.3984381274, 72031.9151744705], 
processed observation next is [1.0, 0.08695652173913043, 0.25681818181818183, 0.85, 1.0, 1.0, 0.00498534539057037, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08202866608819545, 0.08202866608819533, 0.17568759798651343], 
reward next is 0.8243, 
noisyNet noise sample is [array([-0.62472796], dtype=float32), 0.23392084]. 
=============================================
[2019-03-23 09:39:32,347] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.3906874e-25 1.0000000e+00 6.9107662e-34 2.0874290e-19 7.6220743e-36], sum to 1.0000
[2019-03-23 09:39:32,354] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0337
[2019-03-23 09:39:32,357] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.3, 56.0, 1.0, 2.0, 0.5081465758516105, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 579064.7920513038, 579064.792051304, 143614.0761174029], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6964800.0000, 
sim time next is 6965400.0000, 
raw observation next is [28.3, 56.0, 1.0, 2.0, 0.508051994714292, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 578956.9676306039, 578956.9676306037, 143602.7794921375], 
processed observation next is [0.0, 0.6086956521739131, 0.9227272727272727, 0.56, 1.0, 1.0, 0.38506499339286493, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21442850652985332, 0.21442850652985324, 0.3502506816881402], 
reward next is 0.6497, 
noisyNet noise sample is [array([1.2394695], dtype=float32), -0.51994866]. 
=============================================
[2019-03-23 09:39:35,554] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.1115542e-24 1.0000000e+00 1.2467236e-32 3.9828603e-22 2.9281998e-35], sum to 1.0000
[2019-03-23 09:39:35,560] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1134
[2019-03-23 09:39:35,572] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.58333333333334, 92.0, 1.0, 2.0, 0.7925385257758075, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 897533.2819415214, 897533.2819415214, 172776.3358130408], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7038600.0000, 
sim time next is 7039200.0000, 
raw observation next is [19.76666666666667, 91.0, 1.0, 2.0, 0.7458193517026545, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 845024.2655108388, 845024.2655108388, 166397.9680006571], 
processed observation next is [1.0, 0.4782608695652174, 0.534848484848485, 0.91, 1.0, 1.0, 0.682274189628318, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.31297195018919954, 0.31297195018919954, 0.4058487024406271], 
reward next is 0.5942, 
noisyNet noise sample is [array([2.1294034], dtype=float32), -0.20075434]. 
=============================================
[2019-03-23 09:39:38,329] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-23 09:39:38,330] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 09:39:38,332] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 09:39:38,333] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 09:39:38,334] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:39:38,333] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 09:39:38,334] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 09:39:38,335] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:39:38,338] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:39:38,336] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:39:38,340] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:39:38,356] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run34
[2019-03-23 09:39:38,380] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run34
[2019-03-23 09:39:38,402] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run34
[2019-03-23 09:39:38,403] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run34
[2019-03-23 09:39:38,462] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run34
[2019-03-23 09:39:46,685] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.1629938]
[2019-03-23 09:39:46,687] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.83333333333333, 57.0, 1.0, 2.0, 0.7182409835795099, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 807100.9776707469, 807100.9776707469, 159028.7748944714]
[2019-03-23 09:39:46,687] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 09:39:46,690] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.5415536e-28 1.0000000e+00 6.2655810e-38 1.2258932e-24 0.0000000e+00], sampled 0.5149329388451551
[2019-03-23 09:40:08,963] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.1629938]
[2019-03-23 09:40:08,963] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.62939344, 85.5359092, 1.0, 2.0, 0.3609391994674201, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 400400.6625431615, 400400.6625431615, 122830.4850456586]
[2019-03-23 09:40:08,965] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 09:40:08,968] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [5.3003017e-28 1.0000000e+00 1.0925356e-37 1.7243539e-24 0.0000000e+00], sampled 0.009424982723014175
[2019-03-23 09:40:10,479] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.1629938]
[2019-03-23 09:40:10,480] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [29.16666666666666, 51.16666666666666, 1.0, 2.0, 0.7391104408199858, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9753322206868836, 6.9112, 6.9112, 77.32846344354104, 1389786.271442304, 1389786.271442304, 296181.5406877315]
[2019-03-23 09:40:10,482] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 09:40:10,484] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0263670e-27 1.0000000e+00 2.6852201e-37 3.0686155e-24 0.0000000e+00], sampled 0.10254120401104816
[2019-03-23 09:40:10,484] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1389786.271442304 W.
[2019-03-23 09:40:17,169] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.1629938]
[2019-03-23 09:40:17,170] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.0, 58.5, 1.0, 2.0, 0.3211547369683667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 352650.4772615879, 352650.4772615876, 114024.1889680502]
[2019-03-23 09:40:17,171] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 09:40:17,173] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [5.3003017e-28 1.0000000e+00 1.0925356e-37 1.7243539e-24 0.0000000e+00], sampled 0.4833902742461509
[2019-03-23 09:40:25,028] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.1629938]
[2019-03-23 09:40:25,029] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.56666666666667, 57.66666666666666, 1.0, 2.0, 0.3942794790993687, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 445514.7525006339, 445514.7525006336, 129343.5319717506]
[2019-03-23 09:40:25,030] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 09:40:25,034] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.3003017e-28 1.0000000e+00 1.0925356e-37 1.7243539e-24 0.0000000e+00], sampled 0.07489142559885953
[2019-03-23 09:40:52,377] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.1629938]
[2019-03-23 09:40:52,379] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [12.5, 88.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 95.55338769695034, 199678.1114773427, 199678.111477342, 71681.80511323731]
[2019-03-23 09:40:52,380] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 09:40:52,384] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.3003017e-28 1.0000000e+00 1.0925356e-37 1.7243539e-24 0.0000000e+00], sampled 0.4142257383765845
[2019-03-23 09:40:56,100] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.1629938]
[2019-03-23 09:40:56,101] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.33333333333334, 77.66666666666667, 1.0, 2.0, 0.3606074200709195, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 403026.1594744007, 403026.1594744007, 119756.4429313161]
[2019-03-23 09:40:56,102] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 09:40:56,106] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [5.3003017e-28 1.0000000e+00 1.0925356e-37 1.7243539e-24 0.0000000e+00], sampled 0.8635508121275168
[2019-03-23 09:41:04,671] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.1629938]
[2019-03-23 09:41:04,671] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [24.42669175666667, 66.04847632, 1.0, 2.0, 0.4582666829767451, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 522147.941601255, 522147.941601255, 138782.0705679392]
[2019-03-23 09:41:04,675] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 09:41:04,677] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [5.3003017e-28 1.0000000e+00 1.0925356e-37 1.7243539e-24 0.0000000e+00], sampled 0.2255556670323582
[2019-03-23 09:41:15,644] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.1629938]
[2019-03-23 09:41:15,645] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [16.56666666666667, 69.0, 1.0, 2.0, 0.2213514481780961, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 240322.5513058035, 240322.5513058035, 80955.1334961879]
[2019-03-23 09:41:15,647] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 09:41:15,651] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.3003017e-28 1.0000000e+00 1.0925356e-37 1.7243539e-24 0.0000000e+00], sampled 0.9273115062766739
[2019-03-23 09:41:16,348] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.1629938]
[2019-03-23 09:41:16,349] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [17.2, 77.5, 1.0, 2.0, 0.2686666535970601, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 291705.4099955334, 291705.4099955337, 95559.93623211252]
[2019-03-23 09:41:16,351] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 09:41:16,355] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.3003017e-28 1.0000000e+00 1.0925356e-37 1.7243539e-24 0.0000000e+00], sampled 0.13245565537103876
[2019-03-23 09:41:18,698] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 09:41:18,703] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 09:41:18,723] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 09:41:18,729] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 09:41:18,907] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 09:41:19,924] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 825000, evaluation results [825000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 09:41:24,716] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.5805222e-24 1.0000000e+00 7.9465060e-35 3.8941947e-20 2.5267215e-36], sum to 1.0000
[2019-03-23 09:41:24,724] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6281
[2019-03-23 09:41:24,728] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.2, 89.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 197834.2120703247, 197834.2120703244, 66568.43328194931], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7189200.0000, 
sim time next is 7189800.0000, 
raw observation next is [12.2, 89.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 205602.467274468, 205602.4672744683, 67787.06539418963], 
processed observation next is [1.0, 0.21739130434782608, 0.1909090909090909, 0.89, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07614906195350667, 0.07614906195350678, 0.1653343058394869], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2156827], dtype=float32), -0.29340917]. 
=============================================
[2019-03-23 09:41:29,964] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.2469351e-30 1.0000000e+00 0.0000000e+00 4.1232658e-29 0.0000000e+00], sum to 1.0000
[2019-03-23 09:41:29,973] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3993
[2019-03-23 09:41:29,983] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.2, 84.0, 1.0, 2.0, 0.3254962055730878, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 356549.4765200301, 356549.4765200301, 114018.8652687374], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7351200.0000, 
sim time next is 7351800.0000, 
raw observation next is [18.11666666666667, 84.5, 1.0, 2.0, 0.4271445400128229, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 468020.4962022584, 468020.4962022584, 121963.5328921492], 
processed observation next is [1.0, 0.08695652173913043, 0.459848484848485, 0.845, 1.0, 1.0, 0.28393067501602864, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17334092451935496, 0.17334092451935496, 0.29747203144426637], 
reward next is 0.7025, 
noisyNet noise sample is [array([-1.8589522], dtype=float32), 0.024776695]. 
=============================================
[2019-03-23 09:41:30,647] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0055673e-27 1.0000000e+00 2.3718972e-36 2.9141992e-23 0.0000000e+00], sum to 1.0000
[2019-03-23 09:41:30,658] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1771
[2019-03-23 09:41:30,664] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.06666666666667, 63.00000000000001, 1.0, 2.0, 0.307221576558607, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 333599.9411713788, 333599.9411713788, 87749.07930025653], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7287600.0000, 
sim time next is 7288200.0000, 
raw observation next is [18.25, 63.0, 1.0, 2.0, 0.369010245791535, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 400721.4955984231, 400721.4955984228, 95264.66234054175], 
processed observation next is [1.0, 0.34782608695652173, 0.4659090909090909, 0.63, 1.0, 1.0, 0.21126280723941876, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1484153687401567, 0.1484153687401566, 0.2323528349769311], 
reward next is 0.7676, 
noisyNet noise sample is [array([1.9925088], dtype=float32), 0.85645056]. 
=============================================
[2019-03-23 09:41:37,608] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.8880363e-16 9.9999785e-01 1.3500178e-25 2.1129752e-06 3.3521733e-28], sum to 1.0000
[2019-03-23 09:41:37,616] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2326
[2019-03-23 09:41:37,621] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.43333333333333, 92.33333333333334, 1.0, 2.0, 0.3687074003219359, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 411824.6662205631, 411824.6662205628, 120309.9391483292], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7428000.0000, 
sim time next is 7428600.0000, 
raw observation next is [18.25, 93.5, 1.0, 2.0, 0.3680678100825186, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 410835.2274674218, 410835.2274674221, 120136.0020352815], 
processed observation next is [1.0, 1.0, 0.4659090909090909, 0.935, 1.0, 1.0, 0.21008476260314823, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15216119535830436, 0.15216119535830447, 0.2930146391104427], 
reward next is 0.7070, 
noisyNet noise sample is [array([0.23079175], dtype=float32), 2.0877059]. 
=============================================
[2019-03-23 09:41:42,337] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.6818555e-27 1.0000000e+00 1.1177289e-35 6.2985318e-23 1.3860451e-37], sum to 1.0000
[2019-03-23 09:41:42,345] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5158
[2019-03-23 09:41:42,350] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.16666666666667, 77.0, 1.0, 2.0, 0.4540702527579162, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 517799.1518909076, 517799.1518909076, 134630.9719019252], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7514400.0000, 
sim time next is 7515000.0000, 
raw observation next is [23.1, 77.5, 1.0, 2.0, 0.4543448689714211, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 518119.3596316642, 518119.3596316642, 134673.250671391], 
processed observation next is [0.0, 1.0, 0.6863636363636364, 0.775, 1.0, 1.0, 0.31793108621427635, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19189605912283858, 0.19189605912283858, 0.32847134310095366], 
reward next is 0.6715, 
noisyNet noise sample is [array([-0.6564479], dtype=float32), -1.5077702]. 
=============================================
[2019-03-23 09:41:42,373] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[67.0419]
 [67.0419]
 [67.0419]
 [67.0419]
 [67.0419]], R is [[67.04301453]
 [67.04421234]
 [67.04559326]
 [67.04692841]
 [67.04777527]].
[2019-03-23 09:41:53,542] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.0343097e-27 1.0000000e+00 9.4050023e-37 1.1503755e-20 0.0000000e+00], sum to 1.0000
[2019-03-23 09:41:53,550] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7489
[2019-03-23 09:41:53,554] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.53333333333333, 98.0, 1.0, 2.0, 0.3496518477356731, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 388875.1636323118, 388875.1636323121, 118034.4490336663], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7710000.0000, 
sim time next is 7710600.0000, 
raw observation next is [17.61666666666667, 97.5, 1.0, 2.0, 0.3526599579392409, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 392399.0233894542, 392399.0233894542, 118347.2111955393], 
processed observation next is [1.0, 0.21739130434782608, 0.4371212121212123, 0.975, 1.0, 1.0, 0.19082494742405107, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14533297162572376, 0.14533297162572376, 0.2886517346232666], 
reward next is 0.7113, 
noisyNet noise sample is [array([-0.365167], dtype=float32), -0.0050686607]. 
=============================================
[2019-03-23 09:41:56,645] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.2004725e-25 1.0000000e+00 1.9920418e-36 5.7455759e-19 2.3623594e-38], sum to 1.0000
[2019-03-23 09:41:56,649] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8271
[2019-03-23 09:41:56,656] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.66666666666667, 95.0, 1.0, 2.0, 0.2070919302726856, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 224847.925879746, 224847.9258797458, 74990.62167117377], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7798800.0000, 
sim time next is 7799400.0000, 
raw observation next is [13.85, 94.5, 1.0, 2.0, 0.2107672027969843, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 228839.2537800013, 228839.2537800013, 75827.8236372432], 
processed observation next is [1.0, 0.2608695652173913, 0.2659090909090909, 0.945, 1.0, 1.0, 0.01345900349623036, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08475527917777827, 0.08475527917777827, 0.18494591131034926], 
reward next is 0.8151, 
noisyNet noise sample is [array([-0.6518519], dtype=float32), 1.6223416]. 
=============================================
[2019-03-23 09:42:01,519] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.2073415e-27 1.0000000e+00 3.2029365e-34 6.2861667e-24 0.0000000e+00], sum to 1.0000
[2019-03-23 09:42:01,523] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3276
[2019-03-23 09:42:01,528] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 73.0, 1.0, 2.0, 0.3111378750129052, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 339271.0056614226, 339271.0056614229, 112440.0600696868], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7880400.0000, 
sim time next is 7881000.0000, 
raw observation next is [19.4, 73.5, 1.0, 2.0, 0.3245507954692912, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 354322.4599145605, 354322.4599145603, 113525.4845451868], 
processed observation next is [1.0, 0.21739130434782608, 0.5181818181818181, 0.735, 1.0, 1.0, 0.155688494336614, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13123054070909648, 0.1312305407090964, 0.27689142571996783], 
reward next is 0.7231, 
noisyNet noise sample is [array([1.742566], dtype=float32), 0.15245692]. 
=============================================
[2019-03-23 09:42:01,546] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[69.91289 ]
 [69.89259 ]
 [69.87727 ]
 [69.869446]
 [69.85864 ]], R is [[69.93341827]
 [69.95983887]
 [69.98621368]
 [70.01243591]
 [70.03846741]].
[2019-03-23 09:42:01,998] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.33315124e-20 1.00000000e+00 1.16648232e-28 1.91243679e-19
 2.00135568e-30], sum to 1.0000
[2019-03-23 09:42:02,007] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9857
[2019-03-23 09:42:02,011] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.8, 94.0, 1.0, 2.0, 0.6683084471073812, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 758929.8686067357, 758929.8686067355, 157184.9101617298], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7900800.0000, 
sim time next is 7901400.0000, 
raw observation next is [19.9, 93.5, 1.0, 2.0, 0.6971573207888463, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 791991.4431105884, 791991.4431105884, 161233.011724761], 
processed observation next is [1.0, 0.43478260869565216, 0.5409090909090909, 0.935, 1.0, 1.0, 0.6214466509860578, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2933301641150327, 0.2933301641150327, 0.39325124810917317], 
reward next is 0.6067, 
noisyNet noise sample is [array([-0.04817553], dtype=float32), 1.4089565]. 
=============================================
[2019-03-23 09:42:02,358] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:42:02,358] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:42:02,375] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run5
[2019-03-23 09:42:03,394] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.3370670e-24 1.0000000e+00 1.1514611e-33 7.7609032e-23 2.3614788e-36], sum to 1.0000
[2019-03-23 09:42:03,402] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1545
[2019-03-23 09:42:03,405] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.3, 94.0, 1.0, 2.0, 0.4331662932333079, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 492917.1106442205, 492917.1106442205, 131117.6843526312], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7939200.0000, 
sim time next is 7939800.0000, 
raw observation next is [20.2, 94.5, 1.0, 2.0, 0.4315654349683655, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 490998.2215414611, 490998.2215414614, 130863.5122796603], 
processed observation next is [1.0, 0.9130434782608695, 0.5545454545454546, 0.945, 1.0, 1.0, 0.28945679371045685, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18185119316350412, 0.18185119316350423, 0.3191792982430739], 
reward next is 0.6808, 
noisyNet noise sample is [array([0.51326126], dtype=float32), -1.0524501]. 
=============================================
[2019-03-23 09:42:04,281] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:42:04,281] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:42:04,285] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run5
[2019-03-23 09:42:04,782] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:42:04,783] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:42:04,785] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run5
[2019-03-23 09:42:04,807] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:42:04,808] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:42:04,812] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run5
[2019-03-23 09:42:04,877] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:42:04,877] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:42:04,881] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run5
[2019-03-23 09:42:04,911] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:42:04,912] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:42:04,916] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run5
[2019-03-23 09:42:04,980] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:42:04,980] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:42:04,982] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run5
[2019-03-23 09:42:05,013] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:42:05,015] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:42:05,017] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run5
[2019-03-23 09:42:05,083] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:42:05,083] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:42:05,084] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run5
[2019-03-23 09:42:05,116] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:42:05,117] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:42:05,119] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run5
[2019-03-23 09:42:05,149] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:42:05,150] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:42:05,151] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:42:05,154] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:42:05,156] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run5
[2019-03-23 09:42:05,193] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run5
[2019-03-23 09:42:05,226] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:42:05,227] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:42:05,228] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run5
[2019-03-23 09:42:05,261] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:42:05,262] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:42:05,321] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:42:05,321] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:42:05,322] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run5
[2019-03-23 09:42:05,424] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:42:05,425] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:42:05,426] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run5
[2019-03-23 09:42:05,500] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run5
[2019-03-23 09:42:10,083] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-23 09:42:10,085] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 09:42:10,087] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:42:10,088] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 09:42:10,090] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 09:42:10,092] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 09:42:10,092] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:42:10,093] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 09:42:10,095] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:42:10,099] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:42:10,097] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:42:10,110] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run35
[2019-03-23 09:42:10,135] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run35
[2019-03-23 09:42:10,135] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run35
[2019-03-23 09:42:10,136] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run35
[2019-03-23 09:42:10,203] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run35
[2019-03-23 09:42:18,841] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.1735547]
[2019-03-23 09:42:18,842] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [15.0, 100.0, 1.0, 2.0, 0.2791171322559056, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 303072.9105749211, 303072.9105749211, 95311.11836341786]
[2019-03-23 09:42:18,844] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 09:42:18,847] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.9380262e-26 1.0000000e+00 3.8486644e-35 4.8573507e-24 1.7355083e-37], sampled 0.33613353079972264
[2019-03-23 09:42:27,694] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.1735547]
[2019-03-23 09:42:27,695] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.8, 74.0, 1.0, 2.0, 0.4751518063769863, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 541980.8443692374, 541980.8443692371, 141620.2013625949]
[2019-03-23 09:42:27,696] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 09:42:27,699] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.9380262e-26 1.0000000e+00 3.8486644e-35 4.8573507e-24 1.7355083e-37], sampled 0.37868959080218967
[2019-03-23 09:42:29,317] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.1735547]
[2019-03-23 09:42:29,317] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.66666666666667, 45.33333333333334, 1.0, 2.0, 0.3629063045463979, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 400015.9660062429, 400015.9660062426, 121998.3833254381]
[2019-03-23 09:42:29,320] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 09:42:29,323] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.9380262e-26 1.0000000e+00 3.8486644e-35 4.8573507e-24 1.7355083e-37], sampled 0.6925571028098649
[2019-03-23 09:42:40,545] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.1735547]
[2019-03-23 09:42:40,546] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [26.9, 53.66666666666667, 1.0, 2.0, 0.4557949917310629, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 519386.2936322378, 519386.2936322378, 138598.5020745229]
[2019-03-23 09:42:40,547] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 09:42:40,550] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.9380262e-26 1.0000000e+00 3.8486644e-35 4.8573507e-24 1.7355083e-37], sampled 0.5355474538118097
[2019-03-23 09:43:00,080] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.1735547]
[2019-03-23 09:43:00,081] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.0, 100.0, 1.0, 2.0, 0.3697203145882876, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 415037.1744666042, 415037.1744666042, 121361.1408152434]
[2019-03-23 09:43:00,082] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 09:43:00,091] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.9380262e-26 1.0000000e+00 3.8486644e-35 4.8573507e-24 1.7355083e-37], sampled 0.15562562516955147
[2019-03-23 09:43:08,430] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.1735547]
[2019-03-23 09:43:08,437] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.86666666666667, 69.16666666666667, 1.0, 2.0, 0.3039970932944301, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 330890.8426545996, 330890.8426545993, 116053.3236541134]
[2019-03-23 09:43:08,441] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 09:43:08,445] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.9380262e-26 1.0000000e+00 3.8486644e-35 4.8573507e-24 1.7355083e-37], sampled 0.64489835932294
[2019-03-23 09:43:12,254] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.1735547]
[2019-03-23 09:43:12,255] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.15, 43.5, 1.0, 2.0, 0.2992309321466066, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 324899.6124713562, 324899.6124713566, 104689.6066319536]
[2019-03-23 09:43:12,258] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 09:43:12,260] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.9380262e-26 1.0000000e+00 3.8486644e-35 4.8573507e-24 1.7355083e-37], sampled 0.8366485057348506
[2019-03-23 09:43:17,901] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.1735547]
[2019-03-23 09:43:17,903] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [14.92816165, 88.18446138333334, 1.0, 2.0, 0.5403757591850502, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 586858.2319831286, 586858.2319831286, 117898.1114636468]
[2019-03-23 09:43:17,906] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 09:43:17,908] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.2478605e-25 1.0000000e+00 2.6934212e-34 1.8516995e-23 1.3828822e-36], sampled 0.1602602111821393
[2019-03-23 09:43:18,400] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.1735547]
[2019-03-23 09:43:18,402] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.77725676, 80.067799455, 1.0, 2.0, 0.3429400938068133, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 380955.1576363678, 380955.1576363675, 121636.6628990146]
[2019-03-23 09:43:18,403] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 09:43:18,406] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.9380262e-26 1.0000000e+00 3.8486644e-35 4.8573507e-24 1.7355083e-37], sampled 0.2801856508132019
[2019-03-23 09:43:50,583] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 09:43:50,720] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 09:43:50,790] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 09:43:50,892] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 09:43:50,927] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 09:43:51,944] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 850000, evaluation results [850000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 09:43:54,566] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.43039227e-28 1.00000000e+00 1.11537663e-37 1.04896106e-26
 1.35376628e-38], sum to 1.0000
[2019-03-23 09:43:54,573] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6154
[2019-03-23 09:43:54,582] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.33333333333334, 61.0, 1.0, 2.0, 0.558385320047562, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 606498.9851044539, 606498.9851044535, 121430.8318941774], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 126600.0000, 
sim time next is 127200.0000, 
raw observation next is [19.66666666666667, 58.0, 1.0, 2.0, 0.4741563524772419, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 514963.9062736907, 514963.9062736907, 111697.1032793081], 
processed observation next is [1.0, 0.4782608695652174, 0.5303030303030305, 0.58, 1.0, 1.0, 0.3426954405965524, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1907273726939595, 0.1907273726939595, 0.27243195921782465], 
reward next is 0.7276, 
noisyNet noise sample is [array([-0.5187868], dtype=float32), 0.4466672]. 
=============================================
[2019-03-23 09:43:54,744] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.8708458e-26 1.0000000e+00 1.8881024e-34 3.2480707e-25 5.1246757e-38], sum to 1.0000
[2019-03-23 09:43:54,752] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5364
[2019-03-23 09:43:54,756] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.66666666666667, 57.33333333333334, 1.0, 2.0, 0.5498721338203982, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 597246.5728082303, 597246.5728082306, 127306.498930408], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 123000.0000, 
sim time next is 123600.0000, 
raw observation next is [20.33333333333334, 58.66666666666667, 1.0, 2.0, 0.5385215164031564, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 584910.6204400784, 584910.6204400782, 124836.0925055811], 
processed observation next is [1.0, 0.43478260869565216, 0.5606060606060609, 0.5866666666666667, 1.0, 1.0, 0.42315189550394544, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21663356312595497, 0.2166335631259549, 0.30447827440385633], 
reward next is 0.6955, 
noisyNet noise sample is [array([-0.0398656], dtype=float32), -0.69821346]. 
=============================================
[2019-03-23 09:43:55,166] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.14423873e-27 1.00000000e+00 5.33850434e-38 1.03987146e-22
 0.00000000e+00], sum to 1.0000
[2019-03-23 09:43:55,175] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4851
[2019-03-23 09:43:55,181] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.83333333333333, 84.0, 1.0, 2.0, 0.2251813371626175, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 244493.2489930602, 244493.2489930602, 81686.58615447975], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 291000.0000, 
sim time next is 291600.0000, 
raw observation next is [16.0, 82.0, 1.0, 2.0, 0.2228300450979721, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 241939.6714088528, 241939.6714088531, 81064.57508724737], 
processed observation next is [0.0, 0.391304347826087, 0.36363636363636365, 0.82, 1.0, 1.0, 0.02853755637246512, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08960728570698252, 0.08960728570698262, 0.19771847582255456], 
reward next is 0.8023, 
noisyNet noise sample is [array([0.45106328], dtype=float32), 0.67022806]. 
=============================================
[2019-03-23 09:43:56,423] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.9581161e-28 1.0000000e+00 0.0000000e+00 2.9752852e-22 0.0000000e+00], sum to 1.0000
[2019-03-23 09:43:56,430] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3075
[2019-03-23 09:43:56,438] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 38.0, 1.0, 2.0, 0.684321446331434, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 743391.1127446236, 743391.1127446236, 133954.4976473619], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 144000.0000, 
sim time next is 144600.0000, 
raw observation next is [22.83333333333334, 38.83333333333334, 1.0, 2.0, 0.7397146832756409, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 803615.5814688783, 803615.5814688783, 141086.7272145629], 
processed observation next is [1.0, 0.6956521739130435, 0.6742424242424245, 0.3883333333333334, 1.0, 1.0, 0.6746433540945512, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.297635400544029, 0.297635400544029, 0.3441139688160071], 
reward next is 0.6559, 
noisyNet noise sample is [array([-0.2692223], dtype=float32), 0.96711093]. 
=============================================
[2019-03-23 09:44:04,558] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.3721838e-31 1.0000000e+00 0.0000000e+00 8.0390704e-28 0.0000000e+00], sum to 1.0000
[2019-03-23 09:44:04,564] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1643
[2019-03-23 09:44:04,568] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.83333333333334, 43.0, 1.0, 2.0, 0.2636250327880191, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 286246.2206358277, 286246.2206358277, 85685.65607338877], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 312600.0000, 
sim time next is 313200.0000, 
raw observation next is [22.0, 43.0, 1.0, 2.0, 0.2652367225590281, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 287996.7247408383, 287996.724740838, 86743.81612920883], 
processed observation next is [0.0, 0.6521739130434783, 0.6363636363636364, 0.43, 1.0, 1.0, 0.08154590319878509, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10666545360771788, 0.10666545360771777, 0.21157028324197277], 
reward next is 0.7884, 
noisyNet noise sample is [array([0.12995486], dtype=float32), -0.8722809]. 
=============================================
[2019-03-23 09:44:04,809] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.2219116e-31 1.0000000e+00 0.0000000e+00 6.3802621e-25 0.0000000e+00], sum to 1.0000
[2019-03-23 09:44:04,816] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0967
[2019-03-23 09:44:04,824] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 43.0, 1.0, 2.0, 0.2575128087982589, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 279607.6099690351, 279607.6099690348, 81555.62924856457], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 321000.0000, 
sim time next is 321600.0000, 
raw observation next is [21.0, 43.0, 1.0, 2.0, 0.2567509917761418, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 278780.191373287, 278780.1913732873, 81460.61787389753], 
processed observation next is [0.0, 0.7391304347826086, 0.5909090909090909, 0.43, 1.0, 1.0, 0.07093873972017724, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10325192273084703, 0.10325192273084714, 0.19868443383877446], 
reward next is 0.8013, 
noisyNet noise sample is [array([-0.35630912], dtype=float32), 1.0744112]. 
=============================================
[2019-03-23 09:44:12,512] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.6583005e-25 1.0000000e+00 6.1899521e-34 3.0427645e-22 3.7018580e-36], sum to 1.0000
[2019-03-23 09:44:12,522] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3439
[2019-03-23 09:44:12,530] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.2322523078341357, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 252172.6276719162, 252172.6276719159, 77146.6226580023], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 462600.0000, 
sim time next is 463200.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.2577871581723156, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 279905.5844561803, 279905.58445618, 79486.81044573913], 
processed observation next is [1.0, 0.34782608695652173, 0.22727272727272727, 1.0, 1.0, 1.0, 0.07223394771539451, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10366873498377048, 0.10366873498377037, 0.19387026937985155], 
reward next is 0.8061, 
noisyNet noise sample is [array([-0.09006611], dtype=float32), 1.6859915]. 
=============================================
[2019-03-23 09:44:13,061] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.4081085e-27 1.0000000e+00 2.5725187e-37 1.1997914e-23 0.0000000e+00], sum to 1.0000
[2019-03-23 09:44:13,068] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5860
[2019-03-23 09:44:13,080] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 100.0, 1.0, 2.0, 0.3577936425960275, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 388536.1162651173, 388536.1162651173, 95039.00212984484], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 470400.0000, 
sim time next is 471000.0000, 
raw observation next is [14.0, 100.0, 1.0, 2.0, 0.3546586635958422, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 385130.4242560574, 385130.4242560574, 94655.02230446624], 
processed observation next is [1.0, 0.43478260869565216, 0.2727272727272727, 1.0, 1.0, 1.0, 0.19332332949480271, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14264089787261386, 0.14264089787261386, 0.23086590805967375], 
reward next is 0.7691, 
noisyNet noise sample is [array([-1.2305883], dtype=float32), 0.13378526]. 
=============================================
[2019-03-23 09:44:13,093] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[76.30621]
 [76.30871]
 [76.30456]
 [76.29205]
 [76.24449]], R is [[76.30026245]
 [76.30545807]
 [76.30810547]
 [76.3095932 ]
 [76.30638123]].
[2019-03-23 09:44:13,228] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0937018e-32 1.0000000e+00 0.0000000e+00 1.4070939e-29 0.0000000e+00], sum to 1.0000
[2019-03-23 09:44:13,235] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4339
[2019-03-23 09:44:13,239] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 100.0, 1.0, 2.0, 0.313404721939422, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 340316.3271703373, 340316.3271703373, 90647.7345542318], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 477000.0000, 
sim time next is 477600.0000, 
raw observation next is [14.0, 100.0, 1.0, 2.0, 0.2993241504293452, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 325021.5680474159, 325021.5680474162, 88910.4186647534], 
processed observation next is [1.0, 0.5217391304347826, 0.2727272727272727, 1.0, 1.0, 1.0, 0.12415518803668146, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12037835853607995, 0.12037835853608009, 0.21685467967013022], 
reward next is 0.7831, 
noisyNet noise sample is [array([-0.05290736], dtype=float32), 0.95011675]. 
=============================================
[2019-03-23 09:44:16,726] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.1077585e-29 1.0000000e+00 6.3175176e-38 9.0663242e-30 0.0000000e+00], sum to 1.0000
[2019-03-23 09:44:16,738] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0766
[2019-03-23 09:44:16,744] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 94.0, 1.0, 2.0, 0.2015758133604072, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 218857.5114871263, 218857.5114871266, 75505.5842151246], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 543000.0000, 
sim time next is 543600.0000, 
raw observation next is [14.0, 94.0, 1.0, 2.0, 0.2055634235367516, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 223187.9847190177, 223187.9847190177, 75666.34748615496], 
processed observation next is [1.0, 0.30434782608695654, 0.2727272727272727, 0.94, 1.0, 1.0, 0.006954279420939499, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08266221656259914, 0.08266221656259914, 0.18455206703940236], 
reward next is 0.8154, 
noisyNet noise sample is [array([0.6362606], dtype=float32), -0.45224375]. 
=============================================
[2019-03-23 09:44:17,098] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.1988953e-28 1.0000000e+00 1.0764676e-37 1.0611027e-27 0.0000000e+00], sum to 1.0000
[2019-03-23 09:44:17,106] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5570
[2019-03-23 09:44:17,112] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.0, 91.0, 1.0, 2.0, 0.2389143278624151, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 259407.9792752028, 259407.9792752028, 82701.80064403206], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 545400.0000, 
sim time next is 546000.0000, 
raw observation next is [15.33333333333333, 90.0, 1.0, 2.0, 0.2466345958742678, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 267792.7860287336, 267792.7860287333, 85033.05979170196], 
processed observation next is [1.0, 0.30434782608695654, 0.3333333333333332, 0.9, 1.0, 1.0, 0.05829324484283475, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0991825133439754, 0.09918251334397529, 0.20739770680902916], 
reward next is 0.7926, 
noisyNet noise sample is [array([-1.1306952], dtype=float32), 0.31440753]. 
=============================================
[2019-03-23 09:44:17,130] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[77.041405]
 [77.04079 ]
 [77.0328  ]
 [77.01861 ]
 [76.93481 ]], R is [[77.04675293]
 [77.0745697 ]
 [77.10625458]
 [77.14000702]
 [77.18405151]].
[2019-03-23 09:44:19,689] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0784130e-27 1.0000000e+00 2.3737076e-36 4.9660539e-25 2.2296685e-38], sum to 1.0000
[2019-03-23 09:44:19,697] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6281
[2019-03-23 09:44:19,701] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 58.0, 1.0, 2.0, 0.4686481820045671, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 534760.148857882, 534760.1488578822, 137498.1726850664], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 756600.0000, 
sim time next is 757200.0000, 
raw observation next is [27.0, 58.0, 1.0, 2.0, 0.4736916066623215, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 540518.1528773602, 540518.1528773599, 138059.2991020852], 
processed observation next is [1.0, 0.782608695652174, 0.8636363636363636, 0.58, 1.0, 1.0, 0.34211450832790186, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20019190847309637, 0.20019190847309626, 0.33672999780996393], 
reward next is 0.6633, 
noisyNet noise sample is [array([-1.6289352], dtype=float32), -0.09349693]. 
=============================================
[2019-03-23 09:44:22,509] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.4107711e-26 1.0000000e+00 9.1573737e-34 2.1030243e-25 5.6886023e-37], sum to 1.0000
[2019-03-23 09:44:22,512] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3839
[2019-03-23 09:44:22,517] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.66666666666667, 57.0, 1.0, 2.0, 0.6642506108662153, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 744868.7339409532, 744868.7339409534, 151489.3091425096], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 646800.0000, 
sim time next is 647400.0000, 
raw observation next is [23.83333333333333, 57.0, 1.0, 2.0, 0.7182409835795099, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 807100.9776707469, 807100.9776707469, 159028.7748944714], 
processed observation next is [1.0, 0.4782608695652174, 0.7196969696969695, 0.57, 1.0, 1.0, 0.6478012294743873, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2989262880262025, 0.2989262880262025, 0.3878750607182229], 
reward next is 0.6121, 
noisyNet noise sample is [array([-0.10466113], dtype=float32), 1.3859321]. 
=============================================
[2019-03-23 09:44:23,603] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.6873000e-28 1.0000000e+00 3.6099300e-36 7.5618746e-26 0.0000000e+00], sum to 1.0000
[2019-03-23 09:44:23,607] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8744
[2019-03-23 09:44:23,615] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333333, 56.0, 1.0, 2.0, 0.3492236493022419, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 388684.3046509746, 388684.3046509749, 118121.1073178294], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 679200.0000, 
sim time next is 679800.0000, 
raw observation next is [23.16666666666667, 56.5, 1.0, 2.0, 0.3471248248355241, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 385969.9181482865, 385969.9181482865, 117795.481864375], 
processed observation next is [1.0, 0.8695652173913043, 0.6893939393939396, 0.565, 1.0, 1.0, 0.1839060310444051, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14295182153640243, 0.14295182153640243, 0.2873060533277439], 
reward next is 0.7127, 
noisyNet noise sample is [array([-0.76589644], dtype=float32), 0.05320876]. 
=============================================
[2019-03-23 09:44:24,567] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.2263076e-27 1.0000000e+00 5.2320992e-36 9.3814465e-25 1.5433625e-38], sum to 1.0000
[2019-03-23 09:44:24,572] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4190
[2019-03-23 09:44:24,585] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 88.0, 1.0, 2.0, 0.3333330801523554, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 367016.7922733523, 367016.7922733523, 115277.9347688607], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 694800.0000, 
sim time next is 695400.0000, 
raw observation next is [17.83333333333333, 89.00000000000001, 1.0, 2.0, 0.3312722588496904, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 364391.1046602378, 364391.1046602378, 114991.4136295862], 
processed observation next is [1.0, 0.043478260869565216, 0.44696969696969674, 0.8900000000000001, 1.0, 1.0, 0.164090323562113, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13495966839268067, 0.13495966839268067, 0.28046686251118585], 
reward next is 0.7195, 
noisyNet noise sample is [array([0.7460081], dtype=float32), 0.07050188]. 
=============================================
[2019-03-23 09:44:26,417] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.72630117e-25 1.00000000e+00 1.46863445e-33 3.96492472e-23
 3.35937545e-35], sum to 1.0000
[2019-03-23 09:44:26,426] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1043
[2019-03-23 09:44:26,429] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333334, 69.0, 1.0, 2.0, 0.7576516386901531, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 861406.9707307076, 861406.9707307076, 170187.0684992617], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 724800.0000, 
sim time next is 725400.0000, 
raw observation next is [23.5, 69.0, 1.0, 2.0, 0.7493087616036567, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 852538.7797764511, 852538.7797764511, 169523.354152688], 
processed observation next is [1.0, 0.391304347826087, 0.7045454545454546, 0.69, 1.0, 1.0, 0.6866359520045708, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3157551036209078, 0.3157551036209078, 0.41347159549436097], 
reward next is 0.5865, 
noisyNet noise sample is [array([0.03641568], dtype=float32), 2.3534377]. 
=============================================
[2019-03-23 09:44:31,590] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.6927778e-25 1.0000000e+00 2.4629633e-34 3.2567870e-21 9.5074984e-34], sum to 1.0000
[2019-03-23 09:44:31,599] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4994
[2019-03-23 09:44:31,604] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 88.5, 1.0, 2.0, 0.4082270318469771, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 461663.2579130239, 461663.2579130237, 126520.4756696958], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 865800.0000, 
sim time next is 866400.0000, 
raw observation next is [19.66666666666667, 90.33333333333334, 1.0, 2.0, 0.4046431637875781, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 457171.7438285849, 457171.7438285852, 125928.0887092646], 
processed observation next is [0.0, 0.0, 0.5303030303030305, 0.9033333333333334, 1.0, 1.0, 0.2558039547344726, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16932286808466107, 0.16932286808466118, 0.30714167977869417], 
reward next is 0.6929, 
noisyNet noise sample is [array([0.675324], dtype=float32), -1.5480937]. 
=============================================
[2019-03-23 09:44:40,473] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-23 09:44:40,474] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 09:44:40,475] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 09:44:40,476] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:44:40,477] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:44:40,477] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 09:44:40,478] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 09:44:40,477] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 09:44:40,479] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:44:40,479] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:44:40,480] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:44:40,497] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run36
[2019-03-23 09:44:40,520] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run36
[2019-03-23 09:44:40,521] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run36
[2019-03-23 09:44:40,521] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run36
[2019-03-23 09:44:40,592] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run36
[2019-03-23 09:44:45,892] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.1907133]
[2019-03-23 09:44:45,892] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [17.69349484, 45.96112801666667, 1.0, 2.0, 0.2884229622430727, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 81.48738405640546, 313175.5387513865, 313175.5387513865, 80202.93851233275]
[2019-03-23 09:44:45,893] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 09:44:45,896] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.1620416e-27 1.0000000e+00 5.7257876e-37 1.9635645e-25 0.0000000e+00], sampled 0.9627535116206604
[2019-03-23 09:45:24,793] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.1907133]
[2019-03-23 09:45:24,797] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [23.91284344166667, 97.06003005833333, 1.0, 2.0, 0.6163766252772148, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 692559.0624097983, 692559.0624097983, 165501.7825566202]
[2019-03-23 09:45:24,797] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 09:45:24,800] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.1620416e-27 1.0000000e+00 5.7257876e-37 1.9635645e-25 0.0000000e+00], sampled 0.26603038259581535
[2019-03-23 09:45:29,406] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.1907133]
[2019-03-23 09:45:29,407] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.16666666666666, 81.33333333333334, 1.0, 2.0, 0.7602140683213003, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 862411.5124458702, 862411.5124458702, 169126.5195634704]
[2019-03-23 09:45:29,410] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 09:45:29,413] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.1620416e-27 1.0000000e+00 5.7257876e-37 1.9635645e-25 0.0000000e+00], sampled 0.07182867276662619
[2019-03-23 09:46:02,268] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.1907133]
[2019-03-23 09:46:02,269] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.35259093, 59.73212649, 1.0, 2.0, 0.2999164489379207, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 325644.1360380337, 325644.1360380337, 85296.25108938092]
[2019-03-23 09:46:02,269] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 09:46:02,271] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.1620416e-27 1.0000000e+00 5.7257876e-37 1.9635645e-25 0.0000000e+00], sampled 0.8020505117468879
[2019-03-23 09:46:14,775] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.1907133]
[2019-03-23 09:46:14,776] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [12.43333333333333, 87.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 192330.6624294611, 192330.6624294608, 70240.23109357986]
[2019-03-23 09:46:14,777] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 09:46:14,781] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.1620416e-27 1.0000000e+00 5.7257876e-37 1.9635645e-25 0.0000000e+00], sampled 0.41496879386066554
[2019-03-23 09:46:17,110] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.1907133]
[2019-03-23 09:46:17,112] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [26.10778578166667, 57.04371065833333, 1.0, 2.0, 0.5680386108212959, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 647133.5691473447, 647133.5691473447, 151035.8601596075]
[2019-03-23 09:46:17,114] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 09:46:17,116] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.1620416e-27 1.0000000e+00 5.7257876e-37 1.9635645e-25 0.0000000e+00], sampled 0.7746672012491571
[2019-03-23 09:46:20,539] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 09:46:20,795] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 09:46:20,852] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.1907133]
[2019-03-23 09:46:20,853] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.2, 64.5, 1.0, 2.0, 0.4514228084717621, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 509520.8022895074, 509520.8022895074, 134425.2988986471]
[2019-03-23 09:46:20,854] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 09:46:20,855] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.1620416e-27 1.0000000e+00 5.7257876e-37 1.9635645e-25 0.0000000e+00], sampled 0.9058678102873838
[2019-03-23 09:46:20,954] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 09:46:20,956] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 09:46:21,057] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 09:46:22,074] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 875000, evaluation results [875000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 09:46:40,426] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.9343221e-09 9.9986291e-01 5.1036503e-14 1.3706680e-04 6.4545689e-15], sum to 1.0000
[2019-03-23 09:46:40,437] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2297
[2019-03-23 09:46:40,452] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1302118.821946709 W.
[2019-03-23 09:46:40,457] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.5, 86.0, 1.0, 2.0, 0.5764350002164457, 1.0, 1.0, 0.5764350002164457, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1302118.821946709, 1302118.821946709, 254086.1680621775], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1351800.0000, 
sim time next is 1352400.0000, 
raw observation next is [23.0, 85.0, 1.0, 2.0, 0.5357519018141592, 1.0, 2.0, 0.5357519018141592, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1215522.603652842, 1215522.603652842, 241550.7656757409], 
processed observation next is [1.0, 0.6521739130434783, 0.6818181818181818, 0.85, 1.0, 1.0, 0.41968987726769896, 1.0, 1.0, 0.41968987726769896, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.45019355690846, 0.45019355690846, 0.5891482089652217], 
reward next is 0.4109, 
noisyNet noise sample is [array([0.52930045], dtype=float32), -0.90168744]. 
=============================================
[2019-03-23 09:46:45,085] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.3648084e-27 1.0000000e+00 4.1161814e-35 2.3998088e-30 8.8765312e-37], sum to 1.0000
[2019-03-23 09:46:45,092] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1280
[2019-03-23 09:46:45,096] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.66666666666667, 71.33333333333333, 1.0, 2.0, 0.5525698692352616, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 625958.6804504768, 625958.6804504768, 151148.3730338269], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1431600.0000, 
sim time next is 1432200.0000, 
raw observation next is [26.83333333333333, 70.66666666666667, 1.0, 2.0, 0.554393193316128, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 627771.7281847723, 627771.7281847723, 151472.9324099374], 
processed observation next is [0.0, 0.5652173913043478, 0.8560606060606059, 0.7066666666666667, 1.0, 1.0, 0.44299149164516, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23250804747584158, 0.23250804747584158, 0.36944617660960344], 
reward next is 0.6306, 
noisyNet noise sample is [array([-0.9894143], dtype=float32), -1.168254]. 
=============================================
[2019-03-23 09:46:47,467] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.6490197e-26 1.0000000e+00 3.6223883e-35 3.2476849e-26 7.3544130e-37], sum to 1.0000
[2019-03-23 09:46:47,469] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8875
[2019-03-23 09:46:47,472] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333333, 100.0, 1.0, 2.0, 0.4601351417582162, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 524891.4523747523, 524891.452374752, 135660.4526133507], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1482000.0000, 
sim time next is 1482600.0000, 
raw observation next is [20.16666666666667, 100.0, 1.0, 2.0, 0.4530413880047688, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 516629.9743332791, 516629.9743332791, 134530.3673872733], 
processed observation next is [0.0, 0.13043478260869565, 0.5530303030303032, 1.0, 1.0, 1.0, 0.3163017350059609, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19134443493825154, 0.19134443493825154, 0.3281228472860324], 
reward next is 0.6719, 
noisyNet noise sample is [array([0.43382847], dtype=float32), 0.9571049]. 
=============================================
[2019-03-23 09:46:53,788] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.2818891e-11 9.9906188e-01 2.0578060e-17 9.3817245e-04 5.0633773e-19], sum to 1.0000
[2019-03-23 09:46:53,800] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6659
[2019-03-23 09:46:53,807] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.83333333333333, 78.83333333333333, 1.0, 2.0, 0.3859280345789154, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 434749.4948977792, 434749.4948977792, 123517.6759024467], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1635000.0000, 
sim time next is 1635600.0000, 
raw observation next is [20.66666666666667, 79.66666666666667, 1.0, 2.0, 0.3824803475799071, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 430619.7361191568, 430619.7361191568, 123084.7603103914], 
processed observation next is [1.0, 0.9565217391304348, 0.575757575757576, 0.7966666666666667, 1.0, 1.0, 0.22810043447488387, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15948879115524325, 0.15948879115524325, 0.3002067324643693], 
reward next is 0.6998, 
noisyNet noise sample is [array([-1.5467185], dtype=float32), -1.2501646]. 
=============================================
[2019-03-23 09:47:02,712] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.9745654e-26 1.0000000e+00 8.1377715e-36 5.1917367e-22 2.9101222e-38], sum to 1.0000
[2019-03-23 09:47:02,727] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5978
[2019-03-23 09:47:02,732] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.1, 41.0, 1.0, 2.0, 0.43548986285746, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 472949.2156477051, 472949.2156477051, 94320.78793338496], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1787400.0000, 
sim time next is 1788000.0000, 
raw observation next is [19.13333333333333, 41.33333333333334, 1.0, 2.0, 0.4184257361666913, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 454408.6302365446, 454408.6302365446, 92781.05536625537], 
processed observation next is [1.0, 0.6956521739130435, 0.5060606060606059, 0.41333333333333344, 1.0, 1.0, 0.2730321702083641, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1682994926802017, 0.1682994926802017, 0.22629525699086675], 
reward next is 0.7737, 
noisyNet noise sample is [array([0.5525621], dtype=float32), -1.3356584]. 
=============================================
[2019-03-23 09:47:02,754] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[74.0278  ]
 [74.06137 ]
 [74.11341 ]
 [74.09578 ]
 [74.143166]], R is [[74.02695465]
 [74.056633  ]
 [74.08612823]
 [74.11177063]
 [74.14238739]].
[2019-03-23 09:47:03,241] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.8262995e-27 1.0000000e+00 6.0076284e-37 5.8597165e-29 0.0000000e+00], sum to 1.0000
[2019-03-23 09:47:03,248] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2922
[2019-03-23 09:47:03,252] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.16666666666667, 42.66666666666666, 1.0, 2.0, 0.3193248065549847, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 346747.0527106086, 346747.0527106083, 83766.36830863659], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1789800.0000, 
sim time next is 1790400.0000, 
raw observation next is [19.13333333333333, 43.33333333333334, 1.0, 2.0, 0.2734933868142997, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 296964.6317178563, 296964.6317178563, 79040.6590197684], 
processed observation next is [1.0, 0.7391304347826086, 0.5060606060606059, 0.4333333333333334, 1.0, 1.0, 0.0918667335178746, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10998690063624307, 0.10998690063624307, 0.1927820951701668], 
reward next is 0.8072, 
noisyNet noise sample is [array([-0.46803072], dtype=float32), 0.11504749]. 
=============================================
[2019-03-23 09:47:04,638] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0287016e-30 1.0000000e+00 0.0000000e+00 6.4727036e-26 0.0000000e+00], sum to 1.0000
[2019-03-23 09:47:04,647] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4272
[2019-03-23 09:47:04,654] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.0, 63.0, 1.0, 2.0, 0.2039200223960056, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 221403.2758436803, 221403.2758436801, 70055.96774573112], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1812600.0000, 
sim time next is 1813200.0000, 
raw observation next is [14.66666666666667, 64.33333333333333, 1.0, 2.0, 0.200303200491539, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 217475.4848199889, 217475.4848199886, 69516.88564728231], 
processed observation next is [1.0, 1.0, 0.30303030303030315, 0.6433333333333333, 1.0, 1.0, 0.00037900061442372457, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08054647585925515, 0.08054647585925503, 0.16955337962751782], 
reward next is 0.8304, 
noisyNet noise sample is [array([-0.3217164], dtype=float32), 0.5748642]. 
=============================================
[2019-03-23 09:47:09,450] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.1525271e-08 3.0807243e-04 1.2641408e-12 9.9969196e-01 1.1110661e-13], sum to 1.0000
[2019-03-23 09:47:09,455] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1745
[2019-03-23 09:47:09,459] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.66666666666667, 92.0, 1.0, 2.0, 0.3333430776425758, 1.0, 2.0, 0.3333430776425758, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 760668.8413801303, 760668.8413801303, 189808.2192663249], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1930800.0000, 
sim time next is 1931400.0000, 
raw observation next is [21.0, 91.0, 1.0, 2.0, 0.3948897361302192, 1.0, 2.0, 0.3948897361302192, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 901537.3552347531, 901537.3552347531, 202911.151892255], 
processed observation next is [1.0, 0.34782608695652173, 0.5909090909090909, 0.91, 1.0, 1.0, 0.243612170162774, 1.0, 1.0, 0.243612170162774, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3339027241610197, 0.3339027241610197, 0.49490524851769513], 
reward next is 0.5051, 
noisyNet noise sample is [array([-0.07943017], dtype=float32), -0.42087537]. 
=============================================
[2019-03-23 09:47:09,920] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.0039210e-18 1.0000000e+00 1.3586805e-24 2.2581202e-16 2.6823687e-26], sum to 1.0000
[2019-03-23 09:47:09,925] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8052
[2019-03-23 09:47:09,933] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 86.33333333333334, 1.0, 2.0, 0.9306752778173751, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1062535.344570402, 1062535.344570402, 204161.6130763192], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1933800.0000, 
sim time next is 1934400.0000, 
raw observation next is [22.66666666666667, 84.66666666666667, 1.0, 2.0, 0.8637557374643156, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 986033.7537988808, 986033.7537988808, 192951.8291163731], 
processed observation next is [1.0, 0.391304347826087, 0.6666666666666669, 0.8466666666666667, 1.0, 1.0, 0.8296946718303944, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3651976865921781, 0.3651976865921781, 0.47061421735700754], 
reward next is 0.5294, 
noisyNet noise sample is [array([0.32263643], dtype=float32), -0.3742516]. 
=============================================
[2019-03-23 09:47:10,824] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-23 09:47:10,827] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 09:47:10,828] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 09:47:10,828] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:47:10,828] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:47:10,829] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 09:47:10,830] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 09:47:10,830] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:47:10,831] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 09:47:10,832] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:47:10,834] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:47:10,844] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run37
[2019-03-23 09:47:10,845] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run37
[2019-03-23 09:47:10,845] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run37
[2019-03-23 09:47:10,894] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run37
[2019-03-23 09:47:10,894] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run37
[2019-03-23 09:47:29,851] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.1846727]
[2019-03-23 09:47:29,852] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [24.622590145, 79.80193424166667, 1.0, 2.0, 0.5208571856371725, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 592694.8675939942, 592694.8675939942, 150104.4700333873]
[2019-03-23 09:47:29,853] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 09:47:29,855] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.9508154e-22 1.0000000e+00 2.6825780e-30 2.2101684e-21 4.9954102e-32], sampled 0.5447695787316509
[2019-03-23 09:47:37,490] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.1846727]
[2019-03-23 09:47:37,493] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.72143561666667, 55.967056, 1.0, 2.0, 0.2660817170859069, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 288898.1349623483, 288898.1349623483, 86737.76269709696]
[2019-03-23 09:47:37,493] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 09:47:37,495] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.8326458e-26 1.0000000e+00 9.7106265e-36 2.6796289e-25 8.4885106e-38], sampled 0.2121870034947605
[2019-03-23 09:47:44,016] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.1846727]
[2019-03-23 09:47:44,018] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [26.0, 74.0, 1.0, 2.0, 0.8085418932204419, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9812040442931477, 6.911199999999999, 6.9112, 77.32846344354104, 1462759.003505243, 1462759.003505244, 313282.9421791308]
[2019-03-23 09:47:44,019] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 09:47:44,021] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [7.3481689e-12 1.0000000e+00 7.2751302e-17 2.6198908e-08 1.0716030e-17], sampled 0.6476213902465349
[2019-03-23 09:47:44,022] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1462759.003505243 W.
[2019-03-23 09:47:52,271] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.1846727]
[2019-03-23 09:47:52,272] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.83333333333334, 86.66666666666667, 1.0, 2.0, 0.4374209569771983, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 496683.8510438908, 496683.8510438905, 134968.1167576949]
[2019-03-23 09:47:52,273] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 09:47:52,276] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.9215005e-23 1.0000000e+00 1.1917356e-31 2.2435083e-22 1.8209945e-33], sampled 0.7193251833355115
[2019-03-23 09:47:55,043] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.1846727]
[2019-03-23 09:47:55,044] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.3, 86.5, 1.0, 2.0, 0.4762325035106033, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 543353.134932545, 543353.1349325447, 142333.5864098273]
[2019-03-23 09:47:55,045] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 09:47:55,047] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [7.3980234e-23 1.0000000e+00 7.2930284e-31 8.4820092e-22 1.2491229e-32], sampled 0.9956893336466649
[2019-03-23 09:48:02,633] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.1846727]
[2019-03-23 09:48:02,636] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [26.974953455, 41.65917796, 1.0, 2.0, 0.38607195674086, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 432769.0694722962, 432769.0694722958, 126787.7670327435]
[2019-03-23 09:48:02,637] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 09:48:02,641] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.7482844e-24 1.0000000e+00 4.6788264e-33 2.1700734e-23 5.8826777e-35], sampled 0.7430293701929659
[2019-03-23 09:48:04,983] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.1846727]
[2019-03-23 09:48:04,986] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.8, 87.33333333333333, 1.0, 2.0, 0.5157411610168494, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 588187.06208937, 588187.0620893696, 148125.7337531748]
[2019-03-23 09:48:04,987] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 09:48:04,990] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.3962220e-23 1.0000000e+00 2.5631621e-31 3.9336215e-22 4.1091572e-33], sampled 0.033582324057782054
[2019-03-23 09:48:19,370] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.1846727]
[2019-03-23 09:48:19,371] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.31724921, 100.0, 1.0, 2.0, 0.5419046544101608, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 617977.018393886, 617977.018393886, 151405.5999407971]
[2019-03-23 09:48:19,373] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 09:48:19,375] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.1229434e-19 1.0000000e+00 1.2052024e-26 1.5040989e-18 3.9850822e-28], sampled 0.4809407384135137
[2019-03-23 09:48:25,420] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.1846727]
[2019-03-23 09:48:25,421] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [18.1, 75.0, 1.0, 2.0, 0.2750912564086191, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 298682.6699018823, 298682.6699018819, 103082.4097435624]
[2019-03-23 09:48:25,422] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 09:48:25,425] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.3710716e-23 1.0000000e+00 1.5807336e-31 2.7608680e-22 2.4585806e-33], sampled 0.6930864026086444
[2019-03-23 09:48:28,798] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.1846727]
[2019-03-23 09:48:28,798] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.2, 87.0, 1.0, 2.0, 0.3664221819150462, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 95.55338769695034, 409812.1779298657, 409812.177929865, 124685.3865277431]
[2019-03-23 09:48:28,799] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 09:48:28,802] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.5439633e-23 1.0000000e+00 1.7376997e-31 2.9591104e-22 2.7187858e-33], sampled 0.6629247390475649
[2019-03-23 09:48:34,680] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.1846727]
[2019-03-23 09:48:34,682] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.98669240666667, 97.56474695833334, 1.0, 2.0, 0.4656173955834139, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 530296.2746857445, 530296.2746857442, 139276.7534490915]
[2019-03-23 09:48:34,682] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 09:48:34,687] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.11885457e-21 1.00000000e+00 2.77851325e-29 1.26074895e-20
 6.03682224e-31], sampled 0.3792248363650109
[2019-03-23 09:48:51,260] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 09:48:51,465] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 09:48:51,499] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 09:48:51,551] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 09:48:51,563] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 09:48:52,577] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 900000, evaluation results [900000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 09:49:00,390] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.5487591e-30 1.0000000e+00 0.0000000e+00 8.2646137e-25 0.0000000e+00], sum to 1.0000
[2019-03-23 09:49:00,396] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9415
[2019-03-23 09:49:00,404] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 88.0, 1.0, 2.0, 0.2029675318088641, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 220368.8884161468, 220368.8884161471, 73447.52474071286], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2088000.0000, 
sim time next is 2088600.0000, 
raw observation next is [14.0, 88.00000000000001, 1.0, 2.0, 0.2016221439570108, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 218907.825463869, 218907.8254638687, 73294.00724760194], 
processed observation next is [0.0, 0.17391304347826086, 0.2727272727272727, 0.8800000000000001, 1.0, 1.0, 0.0020276799462634956, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08107697239402556, 0.08107697239402545, 0.1787658713356145], 
reward next is 0.8212, 
noisyNet noise sample is [array([-0.23070148], dtype=float32), 0.14103463]. 
=============================================
[2019-03-23 09:49:04,019] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.5503613e-27 1.0000000e+00 0.0000000e+00 2.0703140e-28 0.0000000e+00], sum to 1.0000
[2019-03-23 09:49:04,022] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2715
[2019-03-23 09:49:04,028] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 88.0, 1.0, 2.0, 0.3042870864071345, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 330412.4101245691, 330412.4101245691, 110409.7253532273], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2164800.0000, 
sim time next is 2165400.0000, 
raw observation next is [17.0, 88.0, 1.0, 2.0, 0.3032969092368858, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 329336.8547555919, 329336.8547555922, 110322.604075456], 
processed observation next is [1.0, 0.043478260869565216, 0.4090909090909091, 0.88, 1.0, 1.0, 0.1291211365461072, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12197661287244144, 0.12197661287244155, 0.26907952213525854], 
reward next is 0.7309, 
noisyNet noise sample is [array([0.5808777], dtype=float32), 1.1889665]. 
=============================================
[2019-03-23 09:49:04,138] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.5077398e-27 1.0000000e+00 2.0453097e-38 2.7999678e-26 0.0000000e+00], sum to 1.0000
[2019-03-23 09:49:04,143] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7121
[2019-03-23 09:49:04,153] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 53.0, 1.0, 2.0, 0.3092356003032097, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 335787.6461436261, 335787.6461436264, 111813.885186939], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2153400.0000, 
sim time next is 2154000.0000, 
raw observation next is [22.0, 53.0, 1.0, 2.0, 0.3035255726471639, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 329585.23449695, 329585.2344969503, 111427.4679995431], 
processed observation next is [0.0, 0.9565217391304348, 0.6363636363636364, 0.53, 1.0, 1.0, 0.12940696580895486, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12206860536924075, 0.12206860536924084, 0.2717743121940076], 
reward next is 0.7282, 
noisyNet noise sample is [array([0.75522226], dtype=float32), 0.4545449]. 
=============================================
[2019-03-23 09:49:04,166] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[69.986176]
 [69.986176]
 [69.986176]
 [69.986176]
 [69.986176]], R is [[70.01454926]
 [70.04168701]
 [70.06661987]
 [70.08529663]
 [70.09750366]].
[2019-03-23 09:49:08,491] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.5188418e-30 1.0000000e+00 0.0000000e+00 2.6351831e-29 0.0000000e+00], sum to 1.0000
[2019-03-23 09:49:08,504] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0433
[2019-03-23 09:49:08,511] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.66666666666667, 89.00000000000001, 1.0, 2.0, 0.3661023170055977, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 408312.4279375998, 408312.4279376001, 119830.8436945617], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2236200.0000, 
sim time next is 2236800.0000, 
raw observation next is [18.33333333333334, 90.0, 1.0, 2.0, 0.3620586376727502, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 402596.5531961287, 402596.553196129, 118989.8332839525], 
processed observation next is [1.0, 0.9130434782608695, 0.46969696969696995, 0.9, 1.0, 1.0, 0.20257329709093774, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1491098345170847, 0.14910983451708482, 0.29021910557061587], 
reward next is 0.7098, 
noisyNet noise sample is [array([-1.0662919], dtype=float32), -0.8800996]. 
=============================================
[2019-03-23 09:49:09,054] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.8199366e-28 1.0000000e+00 0.0000000e+00 8.4376954e-23 0.0000000e+00], sum to 1.0000
[2019-03-23 09:49:09,059] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1482
[2019-03-23 09:49:09,064] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.33333333333333, 77.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 206034.2047042501, 206034.2047042501, 67788.9275718799], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2269200.0000, 
sim time next is 2269800.0000, 
raw observation next is [13.5, 77.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 207823.1936411183, 207823.1936411186, 68288.34416198186], 
processed observation next is [1.0, 0.2608695652173913, 0.25, 0.77, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07697155320041418, 0.0769715532004143, 0.16655693698044358], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.55336875], dtype=float32), 0.34794557]. 
=============================================
[2019-03-23 09:49:14,956] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.7608881e-16 1.0000000e+00 5.3742388e-24 1.5956998e-14 3.5748272e-25], sum to 1.0000
[2019-03-23 09:49:14,963] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5083
[2019-03-23 09:49:14,974] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 49.0, 1.0, 2.0, 0.4775696281607517, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 518672.9180760542, 518672.9180760542, 105329.8919374796], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2373000.0000, 
sim time next is 2373600.0000, 
raw observation next is [20.0, 49.0, 1.0, 2.0, 0.4514325599324419, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 490271.9796547513, 490271.9796547513, 102623.3222844337], 
processed observation next is [1.0, 0.4782608695652174, 0.5454545454545454, 0.49, 1.0, 1.0, 0.31429069991555236, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18158221468694494, 0.18158221468694494, 0.2503007860595944], 
reward next is 0.7497, 
noisyNet noise sample is [array([-1.4144915], dtype=float32), -1.0672289]. 
=============================================
[2019-03-23 09:49:17,991] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0497937e-26 1.0000000e+00 0.0000000e+00 1.1803976e-23 0.0000000e+00], sum to 1.0000
[2019-03-23 09:49:17,999] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9824
[2019-03-23 09:49:18,006] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 77.0, 1.0, 2.0, 0.259028703786805, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 281254.0458667957, 281254.0458667957, 87685.01118951743], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2415600.0000, 
sim time next is 2416200.0000, 
raw observation next is [17.0, 76.16666666666667, 1.0, 2.0, 0.2576306340543195, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 279735.5815171089, 279735.5815171092, 86801.78106687662], 
processed observation next is [1.0, 1.0, 0.4090909090909091, 0.7616666666666667, 1.0, 1.0, 0.07203829256789938, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10360577093226256, 0.10360577093226266, 0.21171166113872344], 
reward next is 0.7883, 
noisyNet noise sample is [array([0.6059824], dtype=float32), 0.25770247]. 
=============================================
[2019-03-23 09:49:18,783] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.30504738e-31 1.00000000e+00 0.00000000e+00 1.09109395e-23
 0.00000000e+00], sum to 1.0000
[2019-03-23 09:49:18,796] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6562
[2019-03-23 09:49:18,800] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.1, 66.5, 1.0, 2.0, 0.6804198229405338, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 754768.7277530954, 754768.7277530957, 150147.7745642266], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2475000.0000, 
sim time next is 2475600.0000, 
raw observation next is [21.13333333333333, 65.66666666666667, 1.0, 2.0, 0.7064636004481782, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 782754.51855059, 782754.51855059, 152943.88373817], 
processed observation next is [1.0, 0.6521739130434783, 0.5969696969696968, 0.6566666666666667, 1.0, 1.0, 0.6330795005602227, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.289909080944663, 0.289909080944663, 0.3730338627760244], 
reward next is 0.6270, 
noisyNet noise sample is [array([0.94421834], dtype=float32), -0.43691182]. 
=============================================
[2019-03-23 09:49:25,372] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.8351741e-29 1.0000000e+00 0.0000000e+00 5.7559754e-26 0.0000000e+00], sum to 1.0000
[2019-03-23 09:49:25,380] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5390
[2019-03-23 09:49:25,390] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 58.0, 1.0, 2.0, 0.5845194556135614, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 634903.5281961357, 634903.528196136, 134871.5362588854], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2554200.0000, 
sim time next is 2554800.0000, 
raw observation next is [21.0, 57.33333333333333, 1.0, 2.0, 0.6174705260361412, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 670719.5948914159, 670719.5948914161, 138212.8249504156], 
processed observation next is [1.0, 0.5652173913043478, 0.5909090909090909, 0.5733333333333333, 1.0, 1.0, 0.5218381575451764, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.24841466477459848, 0.24841466477459856, 0.3371044510985747], 
reward next is 0.6629, 
noisyNet noise sample is [array([-1.4171795], dtype=float32), -0.5010185]. 
=============================================
[2019-03-23 09:49:25,998] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.8400277e-27 1.0000000e+00 4.7831989e-37 3.5825314e-30 1.5051970e-38], sum to 1.0000
[2019-03-23 09:49:25,999] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1628
[2019-03-23 09:49:26,002] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 51.5, 1.0, 2.0, 0.3077902368861069, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 334217.6394587437, 334217.6394587437, 111717.6878319394], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2568600.0000, 
sim time next is 2569200.0000, 
raw observation next is [22.33333333333334, 52.0, 1.0, 2.0, 0.3065669142208783, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 332888.8255321025, 332888.8255321022, 111634.119800804], 
processed observation next is [1.0, 0.7391304347826086, 0.6515151515151518, 0.52, 1.0, 1.0, 0.13320864277609784, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12329215760448241, 0.1232921576044823, 0.2722783409775707], 
reward next is 0.7277, 
noisyNet noise sample is [array([-0.3149427], dtype=float32), 0.41262496]. 
=============================================
[2019-03-23 09:49:26,543] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0142619e-28 1.0000000e+00 0.0000000e+00 1.5215474e-29 0.0000000e+00], sum to 1.0000
[2019-03-23 09:49:26,551] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3985
[2019-03-23 09:49:26,555] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.9, 94.0, 1.0, 2.0, 0.3148060980130679, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 343657.9039482377, 343657.9039482374, 112831.2465945915], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2599200.0000, 
sim time next is 2599800.0000, 
raw observation next is [16.81666666666667, 93.00000000000001, 1.0, 2.0, 0.3129092295128519, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 340723.7022249435, 340723.7022249432, 112393.5521589766], 
processed observation next is [0.0, 0.08695652173913043, 0.4007575757575759, 0.9300000000000002, 1.0, 1.0, 0.14113653689106484, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1261939637870161, 0.126193963787016, 0.2741306150218941], 
reward next is 0.7259, 
noisyNet noise sample is [array([1.9893796], dtype=float32), 1.0898516]. 
=============================================
[2019-03-23 09:49:29,025] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.7541121e-25 1.0000000e+00 5.7837037e-35 3.0151273e-29 3.0739964e-37], sum to 1.0000
[2019-03-23 09:49:29,033] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7188
[2019-03-23 09:49:29,039] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.66666666666666, 63.0, 1.0, 2.0, 0.3856553894711949, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 436041.9658796682, 436041.9658796682, 124401.4356588352], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2627400.0000, 
sim time next is 2628000.0000, 
raw observation next is [24.0, 61.0, 1.0, 2.0, 0.3853148165211973, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 435637.7025837762, 435637.7025837759, 124359.191404723], 
processed observation next is [0.0, 0.43478260869565216, 0.7272727272727273, 0.61, 1.0, 1.0, 0.23164352065149663, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16134729725325045, 0.16134729725325034, 0.30331510098712927], 
reward next is 0.6967, 
noisyNet noise sample is [array([0.01860946], dtype=float32), -0.033949908]. 
=============================================
[2019-03-23 09:49:29,051] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[71.88312]
 [71.88312]
 [71.88312]
 [71.88312]
 [71.88312]], R is [[71.86096191]
 [71.83892822]
 [71.81712341]
 [71.79564667]
 [71.77459717]].
[2019-03-23 09:49:34,219] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.5569625e-24 1.0000000e+00 1.3843252e-33 1.2813353e-21 7.1556106e-35], sum to 1.0000
[2019-03-23 09:49:34,225] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5516
[2019-03-23 09:49:34,231] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 61.0, 1.0, 2.0, 0.4487587750084653, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 511894.2983125809, 511894.2983125812, 134412.0168013951], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2746800.0000, 
sim time next is 2747400.0000, 
raw observation next is [25.5, 65.66666666666667, 1.0, 2.0, 0.4578397183139886, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 522406.1303428798, 522406.1303428798, 135954.1926720357], 
processed observation next is [0.0, 0.8260869565217391, 0.7954545454545454, 0.6566666666666667, 1.0, 1.0, 0.3222996478924857, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19348375197884438, 0.19348375197884438, 0.33159559188301385], 
reward next is 0.6684, 
noisyNet noise sample is [array([0.86383873], dtype=float32), 1.2103213]. 
=============================================
[2019-03-23 09:49:41,336] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 09:49:41,340] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 09:49:41,341] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 09:49:41,342] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 09:49:41,350] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 09:49:41,350] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:49:41,342] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:49:41,354] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:49:41,352] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:49:41,351] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 09:49:41,357] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:49:41,368] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run38
[2019-03-23 09:49:41,388] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run38
[2019-03-23 09:49:41,412] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run38
[2019-03-23 09:49:41,442] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run38
[2019-03-23 09:49:41,471] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run38
[2019-03-23 09:50:00,945] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.2170733]
[2019-03-23 09:50:00,947] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.96259879333333, 87.48628812999999, 1.0, 2.0, 0.3184984038807546, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 345825.908985348, 345825.9089853476, 115205.2609086285]
[2019-03-23 09:50:00,948] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 09:50:00,950] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0247630e-27 1.0000000e+00 1.0710117e-37 3.9334315e-27 0.0000000e+00], sampled 0.11954236369695148
[2019-03-23 09:50:23,149] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.2170733]
[2019-03-23 09:50:23,151] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.05, 89.5, 1.0, 2.0, 0.4082619630035658, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 462184.0802995147, 462184.0802995147, 131155.6803447096]
[2019-03-23 09:50:23,151] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 09:50:23,155] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.0247630e-27 1.0000000e+00 1.0710117e-37 3.9334315e-27 0.0000000e+00], sampled 0.6407819357303668
[2019-03-23 09:50:43,581] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.2170733]
[2019-03-23 09:50:43,582] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [24.33333333333333, 63.83333333333334, 1.0, 2.0, 0.4185759729005124, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 475827.4721132774, 475827.4721132774, 129223.0133811333]
[2019-03-23 09:50:43,585] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 09:50:43,587] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0247630e-27 1.0000000e+00 1.0710117e-37 3.9334315e-27 0.0000000e+00], sampled 0.13881207019299613
[2019-03-23 09:50:43,889] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.2170733]
[2019-03-23 09:50:43,890] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [25.756617175, 41.40897374166667, 1.0, 2.0, 0.3424772404674919, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 378906.0546877193, 378906.0546877189, 120976.0543586943]
[2019-03-23 09:50:43,892] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 09:50:43,895] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.0247630e-27 1.0000000e+00 1.0710117e-37 3.9334315e-27 0.0000000e+00], sampled 0.8228731113879525
[2019-03-23 09:50:47,380] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.2170733]
[2019-03-23 09:50:47,382] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.6, 71.0, 1.0, 2.0, 0.3759690903514478, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 421948.2101772898, 421948.2101772898, 126164.8341871946]
[2019-03-23 09:50:47,383] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 09:50:47,386] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.0247630e-27 1.0000000e+00 1.0710117e-37 3.9334315e-27 0.0000000e+00], sampled 0.3899202695894225
[2019-03-23 09:51:22,018] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 09:51:22,063] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 09:51:22,114] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 09:51:22,140] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 09:51:22,175] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 09:51:23,190] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 925000, evaluation results [925000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 09:51:24,030] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.1389680e-16 1.0000000e+00 1.1908457e-22 1.3111756e-14 4.1676355e-23], sum to 1.0000
[2019-03-23 09:51:24,039] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4296
[2019-03-23 09:51:24,040] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1195468.510919613 W.
[2019-03-23 09:51:24,045] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.5, 68.0, 1.0, 2.0, 0.57572393906725, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9865530188920543, 6.911199999999999, 6.9112, 77.32846344354104, 1195468.510919613, 1195468.510919613, 281328.2871181355], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2896200.0000, 
sim time next is 2896800.0000, 
raw observation next is [28.66666666666666, 67.33333333333334, 1.0, 2.0, 0.5007233465652303, 1.0, 1.0, 0.5007233465652303, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1125856.852834049, 1125856.852834049, 235690.647716556], 
processed observation next is [1.0, 0.5217391304347826, 0.9393939393939391, 0.6733333333333335, 1.0, 1.0, 0.37590418320653785, 1.0, 0.5, 0.37590418320653785, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.4169840195681663, 0.4169840195681663, 0.5748552383330634], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.3836879], dtype=float32), 0.07905397]. 
=============================================
[2019-03-23 09:51:25,329] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.31164107e-17 1.23644974e-11 2.48285866e-26 1.00000000e+00
 2.34338173e-26], sum to 1.0000
[2019-03-23 09:51:25,341] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5259
[2019-03-23 09:51:25,346] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.2491142991880488, 1.0, 2.0, 0.2491142991880488, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 567152.2124550561, 567152.2124550561, 179979.8474260597], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2958600.0000, 
sim time next is 2959200.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.2478842407307851, 1.0, 2.0, 0.2478842407307851, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 564380.2545456493, 564380.2545456489, 179752.9684886233], 
processed observation next is [1.0, 0.2608695652173913, 0.6363636363636364, 0.94, 1.0, 1.0, 0.05985530091348137, 1.0, 1.0, 0.05985530091348137, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20902972390579602, 0.2090297239057959, 0.43842187436249586], 
reward next is 0.5616, 
noisyNet noise sample is [array([-1.5227066], dtype=float32), -0.21316919]. 
=============================================
[2019-03-23 09:51:26,003] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.6638647e-14 9.9999893e-01 1.8795234e-23 1.1014736e-06 5.0257969e-24], sum to 1.0000
[2019-03-23 09:51:26,011] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6060
[2019-03-23 09:51:26,015] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 100.0, 1.0, 2.0, 0.5424654067527567, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 616998.4353120333, 616998.4353120333, 148713.5707557048], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2933400.0000, 
sim time next is 2934000.0000, 
raw observation next is [22.0, 100.0, 1.0, 2.0, 0.5405277575656929, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 614794.7891199238, 614794.7891199238, 148468.7633735881], 
processed observation next is [1.0, 1.0, 0.6363636363636364, 1.0, 1.0, 1.0, 0.42565969695711614, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22770177374811995, 0.22770177374811995, 0.36211893505753195], 
reward next is 0.6379, 
noisyNet noise sample is [array([1.1959141], dtype=float32), -0.4473935]. 
=============================================
[2019-03-23 09:51:26,030] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[52.553684]
 [52.516975]
 [52.295307]
 [52.034   ]
 [52.17326 ]], R is [[52.70235443]
 [52.81261444]
 [52.92130661]
 [53.02892685]
 [53.13536835]].
[2019-03-23 09:51:31,439] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.3183894e-17 1.0000000e+00 1.4345333e-23 4.3867622e-16 1.5502478e-24], sum to 1.0000
[2019-03-23 09:51:31,446] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8516
[2019-03-23 09:51:31,454] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.66666666666667, 96.0, 1.0, 2.0, 0.3488696436877894, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 381154.2609815258, 381154.2609815258, 115379.6994436346], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3036000.0000, 
sim time next is 3036600.0000, 
raw observation next is [16.5, 97.0, 1.0, 2.0, 0.341854782242722, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 372991.3119761181, 372991.3119761181, 114691.8855290559], 
processed observation next is [1.0, 0.13043478260869565, 0.38636363636363635, 0.97, 1.0, 1.0, 0.17731847780340246, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1381449303615252, 0.1381449303615252, 0.27973630616842904], 
reward next is 0.7203, 
noisyNet noise sample is [array([-0.8990751], dtype=float32), -0.74777555]. 
=============================================
[2019-03-23 09:51:32,737] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.6426156e-19 1.0000000e+00 1.0229546e-27 6.2241226e-18 6.1600080e-28], sum to 1.0000
[2019-03-23 09:51:32,744] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6830
[2019-03-23 09:51:32,748] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 70.66666666666667, 1.0, 2.0, 0.2669519026627595, 1.0, 1.0, 0.2669519026627595, 1.0, 2.0, 0.5396050515658579, 6.911199999999999, 6.9112, 77.3421103, 913787.4736439192, 913787.4736439195, 244264.3723171352], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3068400.0000, 
sim time next is 3069000.0000, 
raw observation next is [24.0, 71.5, 1.0, 2.0, 0.665579761974145, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 759573.7987672556, 759573.7987672556, 161292.1202142405], 
processed observation next is [1.0, 0.5217391304347826, 0.7272727272727273, 0.715, 1.0, 1.0, 0.5819747024676812, 0.0, 0.5, -0.25, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.28132362917305764, 0.28132362917305764, 0.3933954151566842], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.6837996], dtype=float32), -1.7410581]. 
=============================================
[2019-03-23 09:51:32,767] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[50.826874]
 [50.3379  ]
 [52.599586]
 [52.98533 ]
 [52.977158]], R is [[53.3923111 ]
 [53.26261902]
 [53.08459091]
 [53.05508041]
 [53.04481888]].
[2019-03-23 09:51:34,053] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.9700196e-13 1.0000000e+00 1.2283123e-18 1.7645092e-12 4.5621999e-19], sum to 1.0000
[2019-03-23 09:51:34,065] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7201
[2019-03-23 09:51:34,072] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.66666666666667, 70.83333333333334, 1.0, 2.0, 0.3689565124633162, 0.0, 2.0, 0.0, 1.0, 2.0, 0.746797972867962, 6.911199999999999, 6.9112, 77.32846344354104, 834347.6020949483, 834347.6020949485, 217709.8626664959], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3085800.0000, 
sim time next is 3086400.0000, 
raw observation next is [26.73333333333334, 70.66666666666667, 1.0, 2.0, 0.5579054686257255, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 631844.1318253498, 631844.1318253498, 151897.6129977392], 
processed observation next is [1.0, 0.7391304347826086, 0.8515151515151519, 0.7066666666666667, 1.0, 1.0, 0.4473818357821569, 0.0, 1.0, -0.25, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2340163451204999, 0.2340163451204999, 0.3704819829213151], 
reward next is 0.6295, 
noisyNet noise sample is [array([1.1713514], dtype=float32), -0.9991815]. 
=============================================
[2019-03-23 09:51:36,819] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.3440536e-27 1.0000000e+00 1.0410626e-36 5.3935776e-27 3.3470779e-38], sum to 1.0000
[2019-03-23 09:51:36,829] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7478
[2019-03-23 09:51:36,836] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 85.0, 1.0, 2.0, 0.263912115739684, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 286558.0294907942, 286558.0294907945, 87953.47931529071], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3288600.0000, 
sim time next is 3289200.0000, 
raw observation next is [16.0, 84.0, 1.0, 2.0, 0.2601984691702262, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 282524.5491070371, 282524.5491070371, 86706.98612504752], 
processed observation next is [0.0, 0.043478260869565216, 0.36363636363636365, 0.84, 1.0, 1.0, 0.07524808646278275, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10463872189149521, 0.10463872189149521, 0.21148045396353055], 
reward next is 0.7885, 
noisyNet noise sample is [array([-2.7411346], dtype=float32), 0.19208954]. 
=============================================
[2019-03-23 09:51:41,926] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.669722e-30 1.000000e+00 0.000000e+00 3.014559e-32 0.000000e+00], sum to 1.0000
[2019-03-23 09:51:41,932] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9843
[2019-03-23 09:51:41,934] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 50.0, 1.0, 2.0, 0.33871403506857, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 374560.7746593205, 374560.7746593202, 116300.577616051], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3252600.0000, 
sim time next is 3253200.0000, 
raw observation next is [24.0, 50.0, 1.0, 2.0, 0.3394591249521024, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 375388.7571360982, 375388.7571360982, 116358.7081522852], 
processed observation next is [0.0, 0.6521739130434783, 0.7272727272727273, 0.5, 1.0, 1.0, 0.17432390619012797, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13903287301336972, 0.13903287301336972, 0.2838017272006956], 
reward next is 0.7162, 
noisyNet noise sample is [array([-0.06847623], dtype=float32), -1.2614747]. 
=============================================
[2019-03-23 09:51:45,535] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.7379592e-30 1.0000000e+00 0.0000000e+00 3.8785904e-24 0.0000000e+00], sum to 1.0000
[2019-03-23 09:51:45,541] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3162
[2019-03-23 09:51:45,546] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 82.0, 1.0, 2.0, 0.2459268968709782, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 267024.1642873026, 267024.1642873029, 83593.34736744473], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3292800.0000, 
sim time next is 3293400.0000, 
raw observation next is [16.0, 82.0, 1.0, 2.0, 0.245885718260522, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 266979.4408262461, 266979.4408262458, 83581.5155763218], 
processed observation next is [0.0, 0.08695652173913043, 0.36363636363636365, 0.82, 1.0, 1.0, 0.05735714782565248, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09888127438009114, 0.09888127438009105, 0.20385735506419952], 
reward next is 0.7961, 
noisyNet noise sample is [array([-1.0898274], dtype=float32), -0.21481916]. 
=============================================
[2019-03-23 09:51:47,371] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.5061792e-23 1.0000000e+00 2.6437879e-32 4.1116061e-24 3.8849251e-33], sum to 1.0000
[2019-03-23 09:51:47,381] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9205
[2019-03-23 09:51:47,387] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 88.0, 1.0, 2.0, 0.3348004279490039, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 368512.9462213423, 368512.9462213423, 115341.8733745889], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3375600.0000, 
sim time next is 3376200.0000, 
raw observation next is [18.0, 88.0, 1.0, 2.0, 0.3358244572849747, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 369647.3685958107, 369647.368595811, 115420.5526834254], 
processed observation next is [1.0, 0.043478260869565216, 0.45454545454545453, 0.88, 1.0, 1.0, 0.16978057160621832, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13690643281326323, 0.13690643281326334, 0.28151354313030585], 
reward next is 0.7185, 
noisyNet noise sample is [array([-0.9054459], dtype=float32), -1.3442295]. 
=============================================
[2019-03-23 09:51:49,909] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.6610912e-19 1.0000000e+00 4.4111869e-27 2.4286362e-21 2.1602650e-27], sum to 1.0000
[2019-03-23 09:51:49,918] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9864
[2019-03-23 09:51:49,924] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.33333333333334, 100.0, 1.0, 2.0, 0.3135006462454879, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 342420.2984204175, 342420.2984204172, 112807.7018313236], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3388800.0000, 
sim time next is 3389400.0000, 
raw observation next is [16.5, 100.0, 1.0, 2.0, 0.3164152365354022, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 346719.2564076243, 346719.2564076246, 113415.3675595431], 
processed observation next is [1.0, 0.21739130434782608, 0.38636363636363635, 1.0, 1.0, 1.0, 0.14551904566925275, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1284145394102312, 0.12841453941023132, 0.27662284770620266], 
reward next is 0.7234, 
noisyNet noise sample is [array([-1.0530089], dtype=float32), 0.35533738]. 
=============================================
[2019-03-23 09:51:52,363] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.0555360e-20 1.0000000e+00 6.0947483e-28 2.2006639e-19 1.2693578e-28], sum to 1.0000
[2019-03-23 09:51:52,371] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2578
[2019-03-23 09:51:52,375] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 74.0, 1.0, 2.0, 0.5556546435645889, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 630376.7551433728, 630376.7551433728, 151196.2891559933], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3435600.0000, 
sim time next is 3436200.0000, 
raw observation next is [26.0, 74.0, 1.0, 2.0, 0.5554558912005375, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 630147.921337049, 630147.9213370492, 151171.8961315116], 
processed observation next is [1.0, 0.782608695652174, 0.8181818181818182, 0.74, 1.0, 1.0, 0.44431986400067186, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.23338811901372183, 0.23338811901372195, 0.36871194178417466], 
reward next is 0.6313, 
noisyNet noise sample is [array([0.04365204], dtype=float32), -1.2297112]. 
=============================================
[2019-03-23 09:51:55,420] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.3096583e-18 1.0000000e+00 9.1106907e-25 7.2844850e-18 5.7669646e-26], sum to 1.0000
[2019-03-23 09:51:55,427] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3770
[2019-03-23 09:51:55,432] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4744171683529863, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 541279.4947560871, 541279.4947560871, 138562.0723861099], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3477000.0000, 
sim time next is 3477600.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.4751109119481226, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 542071.4042292545, 542071.4042292545, 138640.078868052], 
processed observation next is [1.0, 0.2608695652173913, 0.5909090909090909, 1.0, 1.0, 1.0, 0.34388863993515323, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20076718675157573, 0.20076718675157573, 0.33814653382451704], 
reward next is 0.6619, 
noisyNet noise sample is [array([1.9450908], dtype=float32), -1.2323334]. 
=============================================
[2019-03-23 09:51:57,841] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.0612694e-25 1.0000000e+00 1.8177169e-35 2.3819118e-25 1.0152609e-35], sum to 1.0000
[2019-03-23 09:51:57,846] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7729
[2019-03-23 09:51:57,852] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 89.0, 1.0, 2.0, 0.5223466996184175, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 595080.9271535518, 595080.9271535518, 145491.7435886508], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3540000.0000, 
sim time next is 3540600.0000, 
raw observation next is [23.0, 89.0, 1.0, 2.0, 0.5226518324929192, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 595428.6334743914, 595428.6334743917, 145528.9886103775], 
processed observation next is [1.0, 1.0, 0.6818181818181818, 0.89, 1.0, 1.0, 0.403314790616149, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22052912350903386, 0.22052912350903395, 0.35494875270823784], 
reward next is 0.6451, 
noisyNet noise sample is [array([0.6001534], dtype=float32), -1.5676358]. 
=============================================
[2019-03-23 09:51:58,310] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.8836683e-22 1.0000000e+00 1.9013619e-30 3.6483330e-21 1.7602290e-32], sum to 1.0000
[2019-03-23 09:51:58,315] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5104
[2019-03-23 09:51:58,318] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 89.0, 1.0, 2.0, 0.5189884464408479, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 591256.3298592609, 591256.3298592612, 145080.7507151718], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3547200.0000, 
sim time next is 3547800.0000, 
raw observation next is [23.0, 89.0, 1.0, 2.0, 0.5192652251157119, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 591571.8758107092, 591571.8758107089, 145114.254923316], 
processed observation next is [1.0, 0.043478260869565216, 0.6818181818181818, 0.89, 1.0, 1.0, 0.39908153139463987, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21910069474470711, 0.21910069474470698, 0.35393720713003907], 
reward next is 0.6461, 
noisyNet noise sample is [array([0.27333426], dtype=float32), 1.57781]. 
=============================================
[2019-03-23 09:52:01,295] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.9858117e-24 1.0000000e+00 3.6915269e-33 3.9114867e-24 1.6956708e-33], sum to 1.0000
[2019-03-23 09:52:01,302] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6262
[2019-03-23 09:52:01,304] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 83.0, 1.0, 2.0, 0.5232949773537692, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 595627.0434995425, 595627.0434995425, 146034.3542176244], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3607200.0000, 
sim time next is 3607800.0000, 
raw observation next is [24.0, 82.16666666666667, 1.0, 2.0, 0.5181408430915521, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 590086.3562937574, 590086.3562937574, 145154.2160270762], 
processed observation next is [1.0, 0.782608695652174, 0.7272727272727273, 0.8216666666666668, 1.0, 1.0, 0.39767605386444005, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21855050233102127, 0.21855050233102127, 0.35403467323677124], 
reward next is 0.6460, 
noisyNet noise sample is [array([-0.89805245], dtype=float32), 0.55297637]. 
=============================================
[2019-03-23 09:52:04,864] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.9142097e-12 9.9999988e-01 3.4414475e-17 6.8849381e-08 2.8164760e-18], sum to 1.0000
[2019-03-23 09:52:04,870] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8908
[2019-03-23 09:52:04,877] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1309531.610259302 W.
[2019-03-23 09:52:04,881] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.16666666666666, 64.66666666666667, 1.0, 2.0, 0.3874264151992389, 1.0, 1.0, 0.3874264151992389, 1.0, 2.0, 0.7831063470837573, 6.911199999999999, 6.9112, 77.3421103, 1309531.610259302, 1309531.610259302, 299993.0067582027], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3676200.0000, 
sim time next is 3676800.0000, 
raw observation next is [27.33333333333334, 63.33333333333334, 1.0, 2.0, 0.4220975718429933, 1.0, 2.0, 0.4220975718429933, 1.0, 2.0, 0.8525623746972022, 6.911199999999998, 6.9112, 77.3421103, 1423978.796300792, 1423978.796300793, 317467.8715659112], 
processed observation next is [1.0, 0.5652173913043478, 0.878787878787879, 0.6333333333333334, 1.0, 1.0, 0.27762196480374157, 1.0, 1.0, 0.27762196480374157, 1.0, 1.0, 0.7893748209960031, -1.7763568394002506e-16, 0.0, 0.5085185399722538, 0.5273995541854785, 0.5273995541854789, 0.7743118818680762], 
reward next is 0.2257, 
noisyNet noise sample is [array([-0.39813012], dtype=float32), -1.4329932]. 
=============================================
[2019-03-23 09:52:11,772] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-23 09:52:11,774] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 09:52:11,774] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:52:11,775] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 09:52:11,778] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:52:11,779] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 09:52:11,780] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 09:52:11,781] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:52:11,779] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 09:52:11,782] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:52:11,783] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:52:11,793] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run39
[2019-03-23 09:52:11,823] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run39
[2019-03-23 09:52:11,850] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run39
[2019-03-23 09:52:11,893] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run39
[2019-03-23 09:52:11,926] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run39
[2019-03-23 09:52:23,311] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.2417704]
[2019-03-23 09:52:23,312] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [28.48333333333333, 40.0, 1.0, 2.0, 0.3950104159129337, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 446830.668567387, 446830.6685673866, 129706.3975303906]
[2019-03-23 09:52:23,313] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 09:52:23,317] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.8371797e-28 1.0000000e+00 0.0000000e+00 3.6897240e-26 0.0000000e+00], sampled 0.4865169089191377
[2019-03-23 09:52:26,767] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.2417704]
[2019-03-23 09:52:26,769] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.96666666666667, 61.0, 1.0, 2.0, 0.5830556491524403, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 662706.1046681036, 662706.1046681033, 158490.4153605126]
[2019-03-23 09:52:26,770] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 09:52:26,772] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.8371797e-28 1.0000000e+00 0.0000000e+00 3.6897240e-26 0.0000000e+00], sampled 0.6141149914074795
[2019-03-23 09:52:29,004] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.2417704]
[2019-03-23 09:52:29,005] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.24876659666667, 93.47436728500001, 1.0, 2.0, 0.4936282536103305, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 563218.5439124468, 563218.5439124465, 144400.214569818]
[2019-03-23 09:52:29,006] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 09:52:29,009] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.8371797e-28 1.0000000e+00 0.0000000e+00 3.6897240e-26 0.0000000e+00], sampled 0.18975141786153238
[2019-03-23 09:53:01,622] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.2417704]
[2019-03-23 09:53:01,622] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.33333333333333, 100.0, 1.0, 2.0, 0.3564747640241976, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 396904.1222395512, 396904.1222395512, 118760.473071331]
[2019-03-23 09:53:01,623] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 09:53:01,626] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.8371797e-28 1.0000000e+00 0.0000000e+00 3.6897240e-26 0.0000000e+00], sampled 0.8673138966957058
[2019-03-23 09:53:04,011] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.2417704]
[2019-03-23 09:53:04,012] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [29.63333333333333, 59.33333333333334, 1.0, 2.0, 0.4781002844102351, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8842920424378983, 7.025118402244601, 6.9112, 95.55294678533767, 1074726.023237109, 1029008.019321403, 256453.522994199]
[2019-03-23 09:53:04,013] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 09:53:04,017] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.4160231e-27 1.0000000e+00 2.0924075e-38 2.3749345e-25 0.0000000e+00], sampled 0.5705851024546224
[2019-03-23 09:53:11,683] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.0486857], dtype=float32), -1.2417704]
[2019-03-23 09:53:11,684] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.63333333333334, 90.0, 1.0, 2.0, 0.4665736477421961, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 530500.2794526052, 530500.2794526048, 138498.2463497221]
[2019-03-23 09:53:11,687] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 09:53:11,690] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.8371797e-28 1.0000000e+00 0.0000000e+00 3.6897240e-26 0.0000000e+00], sampled 0.10325987341676468
[2019-03-23 09:53:51,974] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 09:53:52,134] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 09:53:52,276] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 09:53:52,284] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 09:53:52,392] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 09:53:53,408] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 950000, evaluation results [950000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 09:53:55,974] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.5970898e-27 1.0000000e+00 2.3596395e-38 3.0468949e-25 0.0000000e+00], sum to 1.0000
[2019-03-23 09:53:55,986] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7511
[2019-03-23 09:53:55,994] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 64.0, 1.0, 2.0, 0.317895014338307, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 348449.51259999, 348449.5125999897, 113559.8008318022], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3875400.0000, 
sim time next is 3876000.0000, 
raw observation next is [21.0, 64.0, 1.0, 2.0, 0.3209324258062214, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 351790.5640273239, 351790.5640273236, 113780.418993058], 
processed observation next is [0.0, 0.8695652173913043, 0.5909090909090909, 0.64, 1.0, 1.0, 0.1511655322577767, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13029280149160144, 0.13029280149160133, 0.27751321705623905], 
reward next is 0.7225, 
noisyNet noise sample is [array([0.69521224], dtype=float32), 0.17338446]. 
=============================================
[2019-03-23 09:53:56,013] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[73.885]
 [73.885]
 [73.885]
 [73.885]
 [73.885]], R is [[73.86865234]
 [73.8529892 ]
 [73.83786774]
 [73.82279205]
 [73.80782318]].
[2019-03-23 09:54:05,865] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.6948654e-30 1.0000000e+00 0.0000000e+00 4.3102425e-31 0.0000000e+00], sum to 1.0000
[2019-03-23 09:54:05,868] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7808
[2019-03-23 09:54:05,874] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.16666666666667, 99.00000000000001, 1.0, 2.0, 0.3516400976062439, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 389463.2478584729, 389463.2478584726, 117530.0724514668], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4086600.0000, 
sim time next is 4087200.0000, 
raw observation next is [17.33333333333334, 98.0, 1.0, 2.0, 0.3403055623643219, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 377261.516177143, 377261.5161771433, 116797.3221164114], 
processed observation next is [1.0, 0.30434782608695654, 0.42424242424242453, 0.98, 1.0, 1.0, 0.17538195295540238, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13972648747301594, 0.13972648747301605, 0.284871517357101], 
reward next is 0.7151, 
noisyNet noise sample is [array([-2.2049177], dtype=float32), 0.74213713]. 
=============================================
[2019-03-23 09:54:05,939] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.1214655e-27 1.0000000e+00 1.8970301e-37 9.3692696e-21 0.0000000e+00], sum to 1.0000
[2019-03-23 09:54:05,944] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8947
[2019-03-23 09:54:05,952] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 94.0, 1.0, 2.0, 0.3275885088858099, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 358442.2080257083, 358442.2080257086, 114025.8127584549], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4054800.0000, 
sim time next is 4055400.0000, 
raw observation next is [17.0, 94.0, 1.0, 2.0, 0.3240118310928842, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 354511.8315758604, 354511.8315758601, 113763.892294335], 
processed observation next is [1.0, 0.9565217391304348, 0.4090909090909091, 0.94, 1.0, 1.0, 0.1550147888661052, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13130067836142978, 0.13130067836142967, 0.27747290803496344], 
reward next is 0.7225, 
noisyNet noise sample is [array([0.11102016], dtype=float32), 2.0829494]. 
=============================================
[2019-03-23 09:54:07,186] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.8412631e-29 1.0000000e+00 0.0000000e+00 6.2977533e-26 0.0000000e+00], sum to 1.0000
[2019-03-23 09:54:07,192] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4815
[2019-03-23 09:54:07,196] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 100.0, 1.0, 2.0, 0.3042378045027081, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 330358.87882311, 330358.87882311, 111477.8571030486], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4066800.0000, 
sim time next is 4067400.0000, 
raw observation next is [16.0, 100.0, 1.0, 2.0, 0.3039271497422139, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 330021.4375829161, 330021.4375829158, 111456.920695162], 
processed observation next is [1.0, 0.043478260869565216, 0.36363636363636365, 1.0, 1.0, 1.0, 0.12990893717776736, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12223016206774671, 0.1222301620677466, 0.2718461480369805], 
reward next is 0.7282, 
noisyNet noise sample is [array([1.2234472], dtype=float32), -0.094563805]. 
=============================================
[2019-03-23 09:54:10,062] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.1566264e-23 1.0000000e+00 3.8102239e-31 6.5031450e-26 1.1146606e-32], sum to 1.0000
[2019-03-23 09:54:10,073] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5872
[2019-03-23 09:54:10,083] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.83333333333334, 73.83333333333334, 1.0, 2.0, 0.827882781854829, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 942637.6356048082, 942637.6356048082, 181884.8839131138], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4115400.0000, 
sim time next is 4116000.0000, 
raw observation next is [22.66666666666667, 74.66666666666667, 1.0, 2.0, 0.8236366890080998, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 937609.1277136558, 937609.127713656, 181034.9654553139], 
processed observation next is [1.0, 0.6521739130434783, 0.6666666666666669, 0.7466666666666667, 1.0, 1.0, 0.7795458612601247, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3472626398939466, 0.3472626398939467, 0.44154869623247295], 
reward next is 0.5585, 
noisyNet noise sample is [array([-0.9727659], dtype=float32), 0.039683957]. 
=============================================
[2019-03-23 09:54:10,097] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[56.077015]
 [55.95753 ]
 [56.334633]
 [56.688797]
 [57.090122]], R is [[56.21804428]
 [56.21224213]
 [56.19083023]
 [56.18312073]
 [56.18476486]].
[2019-03-23 09:54:11,415] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.3114728e-26 1.0000000e+00 7.4405613e-38 4.8062713e-26 3.9178503e-38], sum to 1.0000
[2019-03-23 09:54:11,423] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9796
[2019-03-23 09:54:11,428] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.66666666666667, 100.0, 1.0, 2.0, 0.3683748671773764, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 412103.2570936999, 412103.2570936996, 120574.1936335087], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4159200.0000, 
sim time next is 4159800.0000, 
raw observation next is [17.5, 100.0, 1.0, 2.0, 0.3596732418667672, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 401428.1944279697, 401428.19442797, 119432.740347049], 
processed observation next is [1.0, 0.13043478260869565, 0.4318181818181818, 1.0, 1.0, 1.0, 0.19959155233345896, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14867710904739617, 0.14867710904739628, 0.2912993667001195], 
reward next is 0.7087, 
noisyNet noise sample is [array([-1.8084534], dtype=float32), -0.849894]. 
=============================================
[2019-03-23 09:54:12,140] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.2778893e-28 1.0000000e+00 0.0000000e+00 3.4179608e-26 0.0000000e+00], sum to 1.0000
[2019-03-23 09:54:12,149] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7093
[2019-03-23 09:54:12,153] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 94.00000000000001, 1.0, 2.0, 0.3464444955020998, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 385483.458429406, 385483.458429406, 117856.3115876496], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4173000.0000, 
sim time next is 4173600.0000, 
raw observation next is [18.0, 94.0, 1.0, 2.0, 0.3446527835278663, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 383500.6045159469, 383500.6045159469, 117720.2350107526], 
processed observation next is [1.0, 0.30434782608695654, 0.45454545454545453, 0.94, 1.0, 1.0, 0.18081597940983288, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14203726093183217, 0.14203726093183217, 0.28712252441646974], 
reward next is 0.7129, 
noisyNet noise sample is [array([1.634018], dtype=float32), -1.0675075]. 
=============================================
[2019-03-23 09:54:17,495] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.7150747e-26 1.0000000e+00 4.7276734e-36 5.5327682e-25 1.8182697e-37], sum to 1.0000
[2019-03-23 09:54:17,502] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8705
[2019-03-23 09:54:17,505] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.41666666666667, 81.33333333333333, 1.0, 2.0, 0.4559162884085881, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 519761.450702538, 519761.4507025382, 134576.89105694], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4407000.0000, 
sim time next is 4407600.0000, 
raw observation next is [22.33333333333334, 81.66666666666667, 1.0, 2.0, 0.4544456249962053, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 518032.8025996123, 518032.802599612, 134341.3759065451], 
processed observation next is [0.0, 0.0, 0.6515151515151518, 0.8166666666666668, 1.0, 1.0, 0.3180570312452566, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19186400096281936, 0.19186400096281925, 0.327661892454988], 
reward next is 0.6723, 
noisyNet noise sample is [array([-0.5645074], dtype=float32), 0.73493034]. 
=============================================
[2019-03-23 09:54:22,227] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0853319e-07 9.9979717e-01 2.2289748e-11 2.0271828e-04 6.1828194e-12], sum to 1.0000
[2019-03-23 09:54:22,233] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0843
[2019-03-23 09:54:22,239] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1178901.667987926 W.
[2019-03-23 09:54:22,242] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.5, 67.16666666666667, 1.0, 2.0, 0.5527805302271624, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9679406601877079, 6.917490450284019, 6.9112, 77.32844776882897, 1178901.667987926, 1176858.65881176, 265153.4625418028], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4355400.0000, 
sim time next is 4356000.0000, 
raw observation next is [26.0, 65.0, 1.0, 2.0, 0.5277464761832774, 1.0, 1.0, 0.5277464761832774, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32845966355707, 1200588.782183487, 1200588.782183487, 237989.6236044127], 
processed observation next is [1.0, 0.43478260869565216, 0.8181818181818182, 0.65, 1.0, 1.0, 0.40968309522909674, 1.0, 0.5, 0.40968309522909674, 0.0, 0.5, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084287880675447, 0.44466251191981, 0.44466251191981, 0.5804624965961286], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.00954843], dtype=float32), -0.1949312]. 
=============================================
[2019-03-23 09:54:22,262] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[24.015402]
 [24.67185 ]
 [24.849966]
 [24.748   ]
 [24.745966]], R is [[23.71696472]
 [23.80162811]
 [24.04865837]
 [24.33446503]
 [24.60695457]].
[2019-03-23 09:54:30,544] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.2301044e-22 1.0000000e+00 2.9277434e-34 4.3241500e-20 1.9238588e-34], sum to 1.0000
[2019-03-23 09:54:30,549] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0323
[2019-03-23 09:54:30,554] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333334, 90.0, 1.0, 2.0, 0.4642651323973427, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 529447.7540651866, 529447.7540651866, 135750.5078783084], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4531200.0000, 
sim time next is 4531800.0000, 
raw observation next is [21.16666666666666, 89.0, 1.0, 2.0, 0.4530210675113022, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 516204.9339574765, 516204.9339574765, 133903.6831965887], 
processed observation next is [0.0, 0.43478260869565216, 0.5984848484848482, 0.89, 1.0, 1.0, 0.3162763343891277, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19118701257684315, 0.19118701257684315, 0.32659434925997244], 
reward next is 0.6734, 
noisyNet noise sample is [array([1.3822547], dtype=float32), -1.871853]. 
=============================================
[2019-03-23 09:54:31,007] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.1302901e-26 1.0000000e+00 0.0000000e+00 3.5532952e-23 1.5583657e-38], sum to 1.0000
[2019-03-23 09:54:31,012] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0613
[2019-03-23 09:54:31,016] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.5000855555840359, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 570316.6669871402, 570316.6669871402, 142096.0399269016], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4528200.0000, 
sim time next is 4528800.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.5011842725540635, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 571569.7665009546, 571569.7665009544, 142225.7567633785], 
processed observation next is [0.0, 0.43478260869565216, 0.6363636363636364, 0.94, 1.0, 1.0, 0.37648034069257935, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21169250611146467, 0.2116925061114646, 0.34689208966677687], 
reward next is 0.6531, 
noisyNet noise sample is [array([-0.97689956], dtype=float32), -0.57151896]. 
=============================================
[2019-03-23 09:54:37,221] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.618740e-28 1.000000e+00 0.000000e+00 5.217462e-24 0.000000e+00], sum to 1.0000
[2019-03-23 09:54:37,230] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7875
[2019-03-23 09:54:37,233] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.66666666666667, 72.83333333333333, 1.0, 2.0, 0.2363250227101606, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 256595.826460557, 256595.8264605567, 80259.45643157132], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4693800.0000, 
sim time next is 4694400.0000, 
raw observation next is [17.0, 72.0, 1.0, 2.0, 0.2336334996180063, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 253672.6755889918, 253672.6755889918, 81136.87205663043], 
processed observation next is [1.0, 0.34782608695652173, 0.4090909090909091, 0.72, 1.0, 1.0, 0.04204187452250787, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09395284281073771, 0.09395284281073771, 0.19789480989422056], 
reward next is 0.8021, 
noisyNet noise sample is [array([-1.2620509], dtype=float32), -0.14324655]. 
=============================================
[2019-03-23 09:54:42,194] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-23 09:54:42,198] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 09:54:42,199] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:54:42,200] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 09:54:42,201] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 09:54:42,202] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 09:54:42,204] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:54:42,205] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:54:42,203] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 09:54:42,207] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:54:42,211] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:54:42,217] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run40
[2019-03-23 09:54:42,241] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run40
[2019-03-23 09:54:42,242] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run40
[2019-03-23 09:54:42,242] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run40
[2019-03-23 09:54:42,317] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run40
[2019-03-23 09:54:43,399] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.0097086], dtype=float32), -1.1498592]
[2019-03-23 09:54:43,399] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [13.23333333333333, 90.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 212430.736480528, 212430.736480528, 75420.96493119498]
[2019-03-23 09:54:43,399] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 09:54:43,400] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.9666741e-28 1.0000000e+00 0.0000000e+00 2.4541958e-25 0.0000000e+00], sampled 0.1719946078140311
[2019-03-23 09:54:56,144] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.0097086], dtype=float32), -1.1498592]
[2019-03-23 09:54:56,145] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [24.28307278666667, 74.30784300666667, 1.0, 2.0, 0.4936332353863936, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 563182.9031854458, 563182.9031854453, 144073.7550979445]
[2019-03-23 09:54:56,146] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 09:54:56,150] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.9666741e-28 1.0000000e+00 0.0000000e+00 2.4541958e-25 0.0000000e+00], sampled 0.2851024349464901
[2019-03-23 09:55:16,468] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.0097086], dtype=float32), -1.1498592]
[2019-03-23 09:55:16,471] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [28.0, 55.0, 1.0, 2.0, 0.4670195758425635, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 532736.6740654517, 532736.6740654517, 138017.7002296184]
[2019-03-23 09:55:16,472] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 09:55:16,478] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.5287827e-28 1.0000000e+00 0.0000000e+00 2.8621511e-25 0.0000000e+00], sampled 0.7022979211688959
[2019-03-23 09:55:25,115] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.0097086], dtype=float32), -1.1498592]
[2019-03-23 09:55:25,117] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.0, 80.0, 1.0, 2.0, 0.4839244238144017, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 552058.5810477599, 552058.5810477599, 142797.8973332984]
[2019-03-23 09:55:25,119] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 09:55:25,121] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.9666741e-28 1.0000000e+00 0.0000000e+00 2.4541958e-25 0.0000000e+00], sampled 0.0640789685019465
[2019-03-23 09:55:25,367] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.0097086], dtype=float32), -1.1498592]
[2019-03-23 09:55:25,368] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.33333333333334, 87.16666666666667, 1.0, 2.0, 0.6268618190735313, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9767009792468863, 6.9112, 6.9112, 77.32846344354104, 1260956.438444222, 1260956.438444222, 280935.3874644056]
[2019-03-23 09:55:25,369] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 09:55:25,373] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [6.0863735e-24 1.0000000e+00 2.3905836e-35 4.8499197e-19 3.0259951e-35], sampled 0.47584101933640954
[2019-03-23 09:55:25,374] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1260956.438444222 W.
[2019-03-23 09:55:35,674] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.0097086], dtype=float32), -1.1498592]
[2019-03-23 09:55:35,674] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [25.63717307, 71.6906002, 1.0, 2.0, 0.5193730078976511, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 591446.9594663258, 591446.9594663258, 149590.0286124825]
[2019-03-23 09:55:35,677] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 09:55:35,679] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.9666741e-28 1.0000000e+00 0.0000000e+00 2.4541958e-25 0.0000000e+00], sampled 0.1524687758843123
[2019-03-23 09:55:45,028] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.0097086], dtype=float32), -1.1498592]
[2019-03-23 09:55:45,029] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [26.03705858333333, 84.59302892000001, 1.0, 2.0, 0.6424698580322458, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 721894.9655703289, 721894.9655703285, 169262.6510905196]
[2019-03-23 09:55:45,030] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 09:55:45,033] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.796668e-28 1.000000e+00 0.000000e+00 4.478966e-25 0.000000e+00], sampled 0.29852755202611614
[2019-03-23 09:56:22,293] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.0097086], dtype=float32), -1.1498592]
[2019-03-23 09:56:22,294] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [17.7, 66.33333333333334, 1.0, 2.0, 0.2641200336565232, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 286767.729720457, 286767.7297204566, 88664.349529079]
[2019-03-23 09:56:22,295] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 09:56:22,297] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.9666741e-28 1.0000000e+00 0.0000000e+00 2.4541958e-25 0.0000000e+00], sampled 0.3779510968338957
[2019-03-23 09:56:22,336] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 09:56:22,390] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 09:56:22,420] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 09:56:22,434] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 09:56:22,519] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 09:56:23,536] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 975000, evaluation results [975000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 09:56:26,938] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.1589491e-25 1.0000000e+00 5.1699998e-36 9.6441943e-25 2.9530549e-37], sum to 1.0000
[2019-03-23 09:56:26,946] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0354
[2019-03-23 09:56:26,953] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 94.0, 1.0, 2.0, 0.4164204203540771, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 473055.7746579333, 473055.7746579333, 128745.8150565035], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4852200.0000, 
sim time next is 4852800.0000, 
raw observation next is [20.0, 94.0, 1.0, 2.0, 0.4151323981914386, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 471591.2130769755, 471591.2130769755, 128620.524663655], 
processed observation next is [1.0, 0.17391304347826086, 0.5454545454545454, 0.94, 1.0, 1.0, 0.26891549773929824, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17466341225073168, 0.17466341225073168, 0.31370859674062196], 
reward next is 0.6863, 
noisyNet noise sample is [array([-0.68875945], dtype=float32), 0.031543043]. 
=============================================
[2019-03-23 09:56:26,974] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.2313955e-23 1.0000000e+00 9.5299068e-33 7.1440395e-22 8.3934470e-33], sum to 1.0000
[2019-03-23 09:56:26,980] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0441
[2019-03-23 09:56:26,985] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.8720952089246371, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 994625.8353080269, 994625.8353080269, 196509.9610301362], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4813200.0000, 
sim time next is 4813800.0000, 
raw observation next is [21.83333333333334, 95.0, 1.0, 2.0, 0.6211904356259378, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 708457.5876892589, 708457.5876892589, 157472.398808044], 
processed observation next is [1.0, 0.7391304347826086, 0.628787878787879, 0.95, 1.0, 1.0, 0.5264880445324222, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.26239169914416993, 0.26239169914416993, 0.38407902148303413], 
reward next is 0.6159, 
noisyNet noise sample is [array([0.38357595], dtype=float32), 0.45165983]. 
=============================================
[2019-03-23 09:56:28,300] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.3872749e-28 1.0000000e+00 0.0000000e+00 2.9672658e-26 0.0000000e+00], sum to 1.0000
[2019-03-23 09:56:28,308] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2079
[2019-03-23 09:56:28,314] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.4063285830699455, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 460656.1243476302, 460656.1243476305, 127080.6610766647], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4856400.0000, 
sim time next is 4857000.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4022800354439833, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 456011.2451555084, 456011.2451555084, 126663.7130292491], 
processed observation next is [1.0, 0.21739130434782608, 0.5, 1.0, 1.0, 1.0, 0.25285004430497904, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1688930537612994, 0.1688930537612994, 0.3089358854371929], 
reward next is 0.6911, 
noisyNet noise sample is [array([0.4221309], dtype=float32), 1.0335114]. 
=============================================
[2019-03-23 09:56:28,325] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[68.39261 ]
 [68.37828 ]
 [68.379654]
 [68.38011 ]
 [68.383446]], R is [[68.419487  ]
 [68.42533875]
 [68.4302597 ]
 [68.43419647]
 [68.4376297 ]].
[2019-03-23 09:56:29,876] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.1945208e-24 1.0000000e+00 1.5973689e-36 2.4080145e-24 4.3424114e-37], sum to 1.0000
[2019-03-23 09:56:29,886] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6553
[2019-03-23 09:56:29,891] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 83.0, 1.0, 2.0, 0.886954844273999, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1011448.076831095, 1011448.076831095, 193156.3005196558], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4888800.0000, 
sim time next is 4889400.0000, 
raw observation next is [22.0, 82.16666666666667, 1.0, 2.0, 0.9122416741472431, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1040238.859719652, 1040238.859719652, 197318.6827937914], 
processed observation next is [1.0, 0.6086956521739131, 0.6363636363636364, 0.8216666666666668, 1.0, 1.0, 0.8903020926840538, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.38527365174801925, 0.38527365174801925, 0.48126507998485707], 
reward next is 0.5187, 
noisyNet noise sample is [array([0.6888768], dtype=float32), -0.20191973]. 
=============================================
[2019-03-23 09:56:33,241] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.3990629e-29 1.0000000e+00 0.0000000e+00 2.6971075e-30 0.0000000e+00], sum to 1.0000
[2019-03-23 09:56:33,254] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6740
[2019-03-23 09:56:33,259] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.66666666666667, 96.0, 1.0, 2.0, 0.327735000234902, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 357945.4721860556, 357945.4721860558, 113802.943448309], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4944000.0000, 
sim time next is 4944600.0000, 
raw observation next is [16.5, 97.0, 1.0, 2.0, 0.3211924896347289, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 350340.691357076, 350340.691357076, 113176.7399572323], 
processed observation next is [1.0, 0.21739130434782608, 0.38636363636363635, 0.97, 1.0, 1.0, 0.1514906120434111, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12975581161373184, 0.12975581161373184, 0.2760408291639812], 
reward next is 0.7240, 
noisyNet noise sample is [array([-0.28647044], dtype=float32), 1.6692182]. 
=============================================
[2019-03-23 09:56:35,407] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.5532463e-29 1.0000000e+00 0.0000000e+00 2.5634555e-31 0.0000000e+00], sum to 1.0000
[2019-03-23 09:56:35,410] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0968
[2019-03-23 09:56:35,415] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 73.0, 1.0, 2.0, 0.5502950834710594, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 598010.20701436, 598010.2070143598, 131625.6306443458], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4975200.0000, 
sim time next is 4975800.0000, 
raw observation next is [19.16666666666667, 72.16666666666667, 1.0, 2.0, 0.513983495063739, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 558715.9498196769, 558715.9498196769, 128281.1610654023], 
processed observation next is [1.0, 0.6086956521739131, 0.5075757575757578, 0.7216666666666667, 1.0, 1.0, 0.39247936882967366, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20693183326654702, 0.20693183326654702, 0.31288088064732267], 
reward next is 0.6871, 
noisyNet noise sample is [array([-0.12739968], dtype=float32), 0.108053766]. 
=============================================
[2019-03-23 09:56:42,568] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.5350875e-26 1.0000000e+00 3.1279229e-38 5.3616074e-23 2.4869954e-38], sum to 1.0000
[2019-03-23 09:56:42,573] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7819
[2019-03-23 09:56:42,579] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.83333333333334, 78.83333333333333, 1.0, 2.0, 0.4432790299317216, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 505397.1223963806, 505397.1223963806, 133333.4328197665], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5129400.0000, 
sim time next is 5130000.0000, 
raw observation next is [23.0, 78.0, 1.0, 2.0, 0.4447441189722908, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 507124.8563272175, 507124.8563272175, 133585.4404401843], 
processed observation next is [0.0, 0.391304347826087, 0.6818181818181818, 0.78, 1.0, 1.0, 0.3059301487153635, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1878240208619324, 0.1878240208619324, 0.32581814741508364], 
reward next is 0.6742, 
noisyNet noise sample is [array([-0.39675584], dtype=float32), 1.1478007]. 
=============================================
[2019-03-23 09:56:42,605] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[69.870415]
 [69.870415]
 [69.870415]
 [69.870415]
 [69.870415]], R is [[69.84589386]
 [69.82223511]
 [69.79928589]
 [69.77695465]
 [69.75545502]].
[2019-03-23 09:56:42,937] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.7568323e-27 1.0000000e+00 0.0000000e+00 4.1944240e-26 4.4232776e-38], sum to 1.0000
[2019-03-23 09:56:42,945] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1210
[2019-03-23 09:56:42,951] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 83.0, 1.0, 2.0, 0.3991831469852676, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 452355.8931000904, 452355.8931000904, 126276.5005001043], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5119200.0000, 
sim time next is 5119800.0000, 
raw observation next is [21.16666666666667, 83.0, 1.0, 2.0, 0.4015564066534231, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 455439.5695801688, 455439.5695801688, 126771.0639023163], 
processed observation next is [0.0, 0.2608695652173913, 0.5984848484848487, 0.83, 1.0, 1.0, 0.25194550831677887, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1686813220667292, 0.1686813220667292, 0.3091977168349178], 
reward next is 0.6908, 
noisyNet noise sample is [array([-0.12413372], dtype=float32), 1.5995914]. 
=============================================
[2019-03-23 09:56:44,607] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.3993856e-30 1.0000000e+00 0.0000000e+00 2.6130666e-32 0.0000000e+00], sum to 1.0000
[2019-03-23 09:56:44,616] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6861
[2019-03-23 09:56:44,621] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 66.0, 1.0, 2.0, 0.569840193407648, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 643488.9393767784, 643488.9393767788, 154039.1739219615], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5148000.0000, 
sim time next is 5148600.0000, 
raw observation next is [28.0, 66.0, 1.0, 2.0, 0.5705860777866308, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 644271.5165632213, 644271.516563221, 154154.7116479899], 
processed observation next is [0.0, 0.6086956521739131, 0.9090909090909091, 0.66, 1.0, 1.0, 0.4632325972332885, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2386190802086005, 0.23861908020860037, 0.37598710158046317], 
reward next is 0.6240, 
noisyNet noise sample is [array([-0.89060485], dtype=float32), 0.2720763]. 
=============================================
[2019-03-23 09:56:51,954] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.659761e-31 1.000000e+00 0.000000e+00 6.017765e-30 0.000000e+00], sum to 1.0000
[2019-03-23 09:56:51,961] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6992
[2019-03-23 09:56:51,968] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.5, 75.5, 1.0, 2.0, 0.3290955144071448, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 361754.8270166305, 361754.8270166308, 114741.3072704639], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5279400.0000, 
sim time next is 5280000.0000, 
raw observation next is [19.43333333333333, 76.33333333333334, 1.0, 2.0, 0.3236192461992649, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 355942.9634118532, 355942.9634118529, 114421.1672054083], 
processed observation next is [1.0, 0.08695652173913043, 0.5196969696969695, 0.7633333333333334, 1.0, 1.0, 0.15452405774908112, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13183072718957525, 0.13183072718957514, 0.2790760175741666], 
reward next is 0.7209, 
noisyNet noise sample is [array([0.45449632], dtype=float32), -1.3401004]. 
=============================================
[2019-03-23 09:56:51,985] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[67.34904 ]
 [67.331825]
 [67.271324]
 [67.30758 ]
 [67.24908 ]], R is [[67.3832016 ]
 [67.42951965]
 [67.47151184]
 [67.50424194]
 [67.55131531]].
[2019-03-23 09:56:52,879] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.5639764e-12 1.0000000e+00 6.1282079e-19 4.0737311e-09 3.3997303e-18], sum to 1.0000
[2019-03-23 09:56:52,887] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2718
[2019-03-23 09:56:52,890] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.4, 53.0, 1.0, 2.0, 0.3186949257778118, 1.0, 2.0, 0.3186949257778118, 1.0, 1.0, 0.6444099349185446, 6.9112, 6.9112, 77.3421103, 1077997.31786859, 1077997.31786859, 270409.5681987579], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5317200.0000, 
sim time next is 5317800.0000, 
raw observation next is [29.4, 53.0, 1.0, 2.0, 0.8486487739809594, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 963939.3681572548, 963939.3681572548, 195337.278682972], 
processed observation next is [1.0, 0.5652173913043478, 0.9727272727272727, 0.53, 1.0, 1.0, 0.8108109674761993, 0.0, 0.5, -0.25, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.35701458079898324, 0.35701458079898324, 0.47643238703163904], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.95487], dtype=float32), 1.9811294]. 
=============================================
[2019-03-23 09:56:57,862] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.1141596e-16 1.0000000e+00 1.4175702e-25 9.4097476e-09 3.6927814e-25], sum to 1.0000
[2019-03-23 09:56:57,870] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0903
[2019-03-23 09:56:57,876] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.25, 63.0, 1.0, 2.0, 0.4334237678442869, 1.0, 2.0, 0.4334237678442869, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 974402.1431409891, 974402.1431409891, 219682.0101878433], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5401800.0000, 
sim time next is 5402400.0000, 
raw observation next is [28.43333333333333, 63.0, 1.0, 2.0, 0.8677981557130499, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 979367.9215573488, 979367.9215573486, 200930.7042692597], 
processed observation next is [1.0, 0.5217391304347826, 0.9287878787878786, 0.63, 1.0, 1.0, 0.8347476946413124, 0.0, 0.5, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.36272885983605513, 0.362728859836055, 0.490074888461609], 
reward next is 0.5099, 
noisyNet noise sample is [array([-0.41639182], dtype=float32), -2.02674]. 
=============================================
[2019-03-23 09:57:00,405] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.9030788e-29 1.0000000e+00 0.0000000e+00 2.6137526e-26 0.0000000e+00], sum to 1.0000
[2019-03-23 09:57:00,416] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6621
[2019-03-23 09:57:00,420] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.2, 92.0, 1.0, 2.0, 0.3295657894598234, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 360245.6699801909, 360245.6699801909, 114040.1667386363], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5466000.0000, 
sim time next is 5466600.0000, 
raw observation next is [17.2, 93.0, 1.0, 2.0, 0.3332596685183787, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 365048.0657648138, 365048.0657648138, 114578.0097195225], 
processed observation next is [1.0, 0.2608695652173913, 0.41818181818181815, 0.93, 1.0, 1.0, 0.16657458564797334, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13520298732030142, 0.13520298732030142, 0.2794585602915183], 
reward next is 0.7205, 
noisyNet noise sample is [array([0.11354457], dtype=float32), -0.7307131]. 
=============================================
[2019-03-23 09:57:03,964] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.8721104e-28 1.0000000e+00 0.0000000e+00 1.0422850e-24 0.0000000e+00], sum to 1.0000
[2019-03-23 09:57:03,973] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5424
[2019-03-23 09:57:03,976] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.8, 78.5, 1.0, 2.0, 0.4547942372309273, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 518453.9242039738, 518453.9242039738, 134414.4901365256], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5525400.0000, 
sim time next is 5526000.0000, 
raw observation next is [22.7, 79.0, 1.0, 2.0, 0.4558791881559908, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 519652.1754336376, 519652.1754336376, 134469.0918500514], 
processed observation next is [1.0, 1.0, 0.6681818181818181, 0.79, 1.0, 1.0, 0.3198489851949885, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19246376867912504, 0.19246376867912504, 0.3279733947562229], 
reward next is 0.6720, 
noisyNet noise sample is [array([-1.5674194], dtype=float32), -0.6869154]. 
=============================================
[2019-03-23 09:57:03,990] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[66.43109]
 [66.471  ]
 [66.50316]
 [66.5169 ]
 [66.50018]], R is [[66.4147644 ]
 [66.42277527]
 [66.43068695]
 [66.43815613]
 [66.44496155]].
[2019-03-23 09:57:06,941] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.4346104e-22 1.0000000e+00 7.5014019e-32 7.8467428e-19 9.6166854e-31], sum to 1.0000
[2019-03-23 09:57:06,948] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9941
[2019-03-23 09:57:06,952] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 92.5, 1.0, 2.0, 0.3925075496852522, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 443177.1012022761, 443177.1012022761, 124658.9178786978], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5615400.0000, 
sim time next is 5616000.0000, 
raw observation next is [19.4, 93.0, 1.0, 2.0, 0.3945933573752975, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 445773.5756164278, 445773.5756164278, 124986.3211270023], 
processed observation next is [0.0, 0.0, 0.5181818181818181, 0.93, 1.0, 1.0, 0.24324169671912185, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16510132430238067, 0.16510132430238067, 0.30484468567561535], 
reward next is 0.6952, 
noisyNet noise sample is [array([0.616379], dtype=float32), -0.13625239]. 
=============================================
[2019-03-23 09:57:06,974] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[48.66513]
 [48.72005]
 [48.77488]
 [48.80161]
 [48.79594]], R is [[50.27833939]
 [50.47150803]
 [50.66347504]
 [50.85411453]
 [51.04335022]].
[2019-03-23 09:57:07,336] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.4893481e-11 1.0000000e+00 1.4359392e-17 2.0252766e-10 4.1925236e-17], sum to 1.0000
[2019-03-23 09:57:07,341] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4414
[2019-03-23 09:57:07,350] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.2, 55.33333333333334, 1.0, 2.0, 0.341555593583266, 1.0, 1.0, 0.341555593583266, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 775862.4057260957, 775862.4057260953, 197438.7766467303], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5591400.0000, 
sim time next is 5592000.0000, 
raw observation next is [28.1, 55.66666666666667, 1.0, 2.0, 0.4828187552671818, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 550211.8725048996, 550211.8725048993, 140612.8252881565], 
processed observation next is [1.0, 0.7391304347826086, 0.9136363636363637, 0.5566666666666668, 1.0, 1.0, 0.35352344408397723, 0.0, 0.5, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20378217500181467, 0.20378217500181456, 0.34295811045891833], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2793409], dtype=float32), -0.8574447]. 
=============================================
[2019-03-23 09:57:07,365] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[28.438427]
 [27.35681 ]
 [27.392532]
 [27.30018 ]
 [27.25396 ]], R is [[40.47198105]
 [40.06726074]
 [39.66658783]
 [39.26992416]
 [39.12080765]].
[2019-03-23 09:57:07,799] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.40221607e-21 1.00000000e+00 5.87011081e-32 1.14350374e-17
 3.48031463e-32], sum to 1.0000
[2019-03-23 09:57:07,805] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2124
[2019-03-23 09:57:07,812] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333334, 89.0, 1.0, 2.0, 0.4160490669173017, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 471783.3866344009, 471783.3866344009, 128074.1713010382], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5599200.0000, 
sim time next is 5599800.0000, 
raw observation next is [20.25, 90.0, 1.0, 2.0, 0.4163995186048168, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 472304.7218239384, 472304.7218239384, 128194.8988262555], 
processed observation next is [1.0, 0.8260869565217391, 0.5568181818181818, 0.9, 1.0, 1.0, 0.27049939825602093, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17492767474960683, 0.17492767474960683, 0.3126704849420866], 
reward next is 0.6873, 
noisyNet noise sample is [array([-0.8002034], dtype=float32), 1.4012971]. 
=============================================
[2019-03-23 09:57:08,828] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.4684150e-32 1.0000000e+00 0.0000000e+00 1.0614973e-31 0.0000000e+00], sum to 1.0000
[2019-03-23 09:57:08,839] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8191
[2019-03-23 09:57:08,844] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.6, 44.66666666666667, 1.0, 2.0, 0.2635062868501601, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 286117.247396831, 286117.2473968313, 85982.3348165472], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5754000.0000, 
sim time next is 5754600.0000, 
raw observation next is [21.6, 44.0, 1.0, 2.0, 0.2637696549332583, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 286403.298783711, 286403.298783711, 85351.95854995919], 
processed observation next is [0.0, 0.6086956521739131, 0.6181818181818183, 0.44, 1.0, 1.0, 0.07971206866657289, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10607529584581889, 0.10607529584581889, 0.20817550865843706], 
reward next is 0.7918, 
noisyNet noise sample is [array([0.14232363], dtype=float32), 1.0752066]. 
=============================================
[2019-03-23 09:57:12,287] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-23 09:57:12,288] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 09:57:12,289] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 09:57:12,290] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:57:12,292] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:57:12,293] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 09:57:12,294] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 09:57:12,294] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:57:12,295] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 09:57:12,295] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:57:12,296] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:57:12,310] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run41
[2019-03-23 09:57:12,310] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run41
[2019-03-23 09:57:12,358] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run41
[2019-03-23 09:57:12,392] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run41
[2019-03-23 09:57:12,418] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run41
[2019-03-23 09:57:22,675] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.04747579], dtype=float32), -1.1214595]
[2019-03-23 09:57:22,679] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [23.87777505333333, 72.39017788333334, 1.0, 2.0, 0.4618741179850703, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 526750.777354606, 526750.7773546056, 139979.0380847257]
[2019-03-23 09:57:22,681] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 09:57:22,686] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.1486934e-32 1.0000000e+00 0.0000000e+00 4.4735883e-32 0.0000000e+00], sampled 0.6511322743276186
[2019-03-23 09:57:22,994] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.04747579], dtype=float32), -1.1214595]
[2019-03-23 09:57:22,996] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.5, 91.0, 1.0, 2.0, 0.3952701920089222, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 446126.8595394962, 446126.8595394962, 124811.5071765359]
[2019-03-23 09:57:22,996] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 09:57:22,999] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.1486934e-32 1.0000000e+00 0.0000000e+00 4.4735883e-32 0.0000000e+00], sampled 0.9041313415272489
[2019-03-23 09:57:31,340] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.04747579], dtype=float32), -1.1214595]
[2019-03-23 09:57:31,341] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.5, 87.5, 1.0, 2.0, 0.4045832666824972, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 458707.5683844024, 458707.568384402, 131273.1276527514]
[2019-03-23 09:57:31,343] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 09:57:31,345] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.1486934e-32 1.0000000e+00 0.0000000e+00 4.4735883e-32 0.0000000e+00], sampled 0.12816337198124073
[2019-03-23 09:57:57,416] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.04747579], dtype=float32), -1.1214595]
[2019-03-23 09:57:57,417] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.8, 82.0, 1.0, 2.0, 0.6866260922915788, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 778686.81860315, 778686.8186031496, 173882.6690109437]
[2019-03-23 09:57:57,419] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 09:57:57,423] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.4935793e-32 1.0000000e+00 0.0000000e+00 5.7900926e-32 0.0000000e+00], sampled 0.16137192708657755
[2019-03-23 09:58:00,673] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.04747579], dtype=float32), -1.1214595]
[2019-03-23 09:58:00,675] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [25.3, 64.33333333333334, 1.0, 2.0, 0.7094692554182448, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 809446.8922734698, 809446.8922734695, 171365.0535266029]
[2019-03-23 09:58:00,677] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 09:58:00,682] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.9574848e-32 1.0000000e+00 0.0000000e+00 7.5530296e-32 0.0000000e+00], sampled 0.5558738424518888
[2019-03-23 09:58:16,460] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.04747579], dtype=float32), -1.1214595]
[2019-03-23 09:58:16,461] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [24.86120046666667, 78.35718009000001, 1.0, 2.0, 0.533563785896441, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 606474.8378899114, 606474.8378899114, 152087.6641764478]
[2019-03-23 09:58:16,463] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 09:58:16,467] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.1486934e-32 1.0000000e+00 0.0000000e+00 4.4735883e-32 0.0000000e+00], sampled 0.9337030529102045
[2019-03-23 09:58:28,911] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.04747579], dtype=float32), -1.1214595]
[2019-03-23 09:58:28,912] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.96250432, 47.82415348, 1.0, 2.0, 0.2831928673660388, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 307481.3130013939, 307481.3130013939, 85308.56196381258]
[2019-03-23 09:58:28,914] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 09:58:28,915] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.1486934e-32 1.0000000e+00 0.0000000e+00 4.4735883e-32 0.0000000e+00], sampled 0.41267609552295637
[2019-03-23 09:58:44,128] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.04747579], dtype=float32), -1.1214595]
[2019-03-23 09:58:44,129] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.9, 55.0, 1.0, 2.0, 0.2873839799123245, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 312033.0636655788, 312033.0636655785, 93802.68180833773]
[2019-03-23 09:58:44,129] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 09:58:44,134] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.1486934e-32 1.0000000e+00 0.0000000e+00 4.4735883e-32 0.0000000e+00], sampled 0.46649597089073425
[2019-03-23 09:58:53,247] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 09:58:53,289] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 09:58:53,383] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 09:58:53,423] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 09:58:53,600] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 09:58:54,617] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 1000000, evaluation results [1000000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 09:58:59,683] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.3095104e-35 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 09:58:59,690] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1847
[2019-03-23 09:58:59,697] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [11.7, 85.5, 1.0, 2.0, 0.3873213602115488, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 420614.7941214015, 420614.7941214018, 86617.23026855558], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5806200.0000, 
sim time next is 5806800.0000, 
raw observation next is [11.6, 86.0, 1.0, 2.0, 0.3852732637807905, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 418389.690119029, 418389.6901190293, 86332.38850884326], 
processed observation next is [1.0, 0.21739130434782608, 0.1636363636363636, 0.86, 1.0, 1.0, 0.23159157972598812, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15495914448852927, 0.15495914448852938, 0.21056680124108113], 
reward next is 0.7894, 
noisyNet noise sample is [array([-1.7336569], dtype=float32), -0.7767926]. 
=============================================
[2019-03-23 09:59:04,983] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.3527142e-29 1.0000000e+00 0.0000000e+00 1.1241415e-30 0.0000000e+00], sum to 1.0000
[2019-03-23 09:59:04,990] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8679
[2019-03-23 09:59:04,996] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.2, 77.5, 1.0, 2.0, 0.2510245094914703, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 272560.6354090575, 272560.6354090578, 89076.4345601983], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5898600.0000, 
sim time next is 5899200.0000, 
raw observation next is [17.2, 78.33333333333333, 1.0, 2.0, 0.2528572661735423, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 274551.1913258678, 274551.1913258681, 90238.10431588006], 
processed observation next is [1.0, 0.2608695652173913, 0.41818181818181815, 0.7833333333333333, 1.0, 1.0, 0.06607158271692788, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10168562641698807, 0.10168562641698818, 0.220092937355805], 
reward next is 0.7799, 
noisyNet noise sample is [array([1.2689178], dtype=float32), -0.17134844]. 
=============================================
[2019-03-23 09:59:15,130] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.8359038e-33 1.0000000e+00 0.0000000e+00 1.2121135e-34 0.0000000e+00], sum to 1.0000
[2019-03-23 09:59:15,138] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1268
[2019-03-23 09:59:15,142] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.06666666666667, 74.66666666666667, 1.0, 2.0, 0.2244057218486411, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 243650.9047374635, 243650.9047374635, 77441.49270844988], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6075600.0000, 
sim time next is 6076200.0000, 
raw observation next is [16.33333333333334, 73.33333333333333, 1.0, 2.0, 0.2269563209088796, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 246420.9463877398, 246420.9463877395, 78096.67774736996], 
processed observation next is [1.0, 0.30434782608695654, 0.37878787878787906, 0.7333333333333333, 1.0, 1.0, 0.033695401136099486, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09126701718064437, 0.09126701718064426, 0.19047970182285356], 
reward next is 0.8095, 
noisyNet noise sample is [array([0.4762263], dtype=float32), 0.49092177]. 
=============================================
[2019-03-23 09:59:23,574] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.9360827e-31 1.0000000e+00 0.0000000e+00 2.9575863e-30 0.0000000e+00], sum to 1.0000
[2019-03-23 09:59:23,583] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8137
[2019-03-23 09:59:23,588] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 87.0, 1.0, 2.0, 0.3626325598574005, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 406549.3812729654, 406549.3812729654, 120506.9317881197], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6246000.0000, 
sim time next is 6246600.0000, 
raw observation next is [19.58333333333334, 87.0, 1.0, 2.0, 0.3654235692588972, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 410395.2384618672, 410395.2384618675, 121089.1819631911], 
processed observation next is [0.0, 0.30434782608695654, 0.5265151515151518, 0.87, 1.0, 1.0, 0.20677946157362145, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15199823646735822, 0.15199823646735833, 0.29533946820290513], 
reward next is 0.7047, 
noisyNet noise sample is [array([-0.49082768], dtype=float32), 1.0479832]. 
=============================================
[2019-03-23 09:59:26,926] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.459645e-29 1.000000e+00 0.000000e+00 4.240700e-31 0.000000e+00], sum to 1.0000
[2019-03-23 09:59:26,935] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0727
[2019-03-23 09:59:26,942] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.8, 68.0, 1.0, 2.0, 0.5052230432535578, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 576102.039094069, 576102.039094069, 142817.8681479], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6298200.0000, 
sim time next is 6298800.0000, 
raw observation next is [25.7, 68.33333333333334, 1.0, 2.0, 0.5014713845905128, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 571875.7857047151, 571875.7857047151, 142293.9393949432], 
processed observation next is [0.0, 0.9130434782608695, 0.8045454545454546, 0.6833333333333335, 1.0, 1.0, 0.3768392307381409, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21180584655730186, 0.21180584655730186, 0.3470583887681542], 
reward next is 0.6529, 
noisyNet noise sample is [array([0.27248943], dtype=float32), -0.5158154]. 
=============================================
[2019-03-23 09:59:28,881] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.7468374e-25 1.0000000e+00 2.9675872e-38 1.0355037e-25 1.1865567e-36], sum to 1.0000
[2019-03-23 09:59:28,889] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3830
[2019-03-23 09:59:28,896] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.28333333333333, 66.66666666666667, 1.0, 2.0, 0.5522087845604828, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 626359.9015990634, 626359.9015990634, 150794.4714093819], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6354600.0000, 
sim time next is 6355200.0000, 
raw observation next is [27.36666666666667, 66.33333333333334, 1.0, 2.0, 0.5539903120637266, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 628285.1024123046, 628285.102412305, 151063.382587102], 
processed observation next is [0.0, 0.5652173913043478, 0.8803030303030305, 0.6633333333333334, 1.0, 1.0, 0.4424878900796582, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.23269818607863132, 0.23269818607863146, 0.36844727460268784], 
reward next is 0.6316, 
noisyNet noise sample is [array([0.1698462], dtype=float32), 1.3972121]. 
=============================================
[2019-03-23 09:59:29,530] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.2190974e-29 1.0000000e+00 0.0000000e+00 3.0844765e-28 0.0000000e+00], sum to 1.0000
[2019-03-23 09:59:29,536] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3255
[2019-03-23 09:59:29,541] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.2, 61.66666666666667, 1.0, 2.0, 0.5508626755974927, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 624865.2773616904, 624865.2773616904, 150607.5355136922], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6369000.0000, 
sim time next is 6369600.0000, 
raw observation next is [28.1, 62.33333333333334, 1.0, 2.0, 0.551713557900195, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 625723.7353605523, 625723.7353605523, 150760.5163607362], 
processed observation next is [0.0, 0.7391304347826086, 0.9136363636363637, 0.6233333333333334, 1.0, 1.0, 0.43964194737524376, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23174953161501938, 0.23174953161501938, 0.3677085764896005], 
reward next is 0.6323, 
noisyNet noise sample is [array([1.9357852], dtype=float32), -0.36969003]. 
=============================================
[2019-03-23 09:59:33,259] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.6631316e-28 1.0000000e+00 0.0000000e+00 3.5665711e-26 0.0000000e+00], sum to 1.0000
[2019-03-23 09:59:33,268] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7420
[2019-03-23 09:59:33,272] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 100.0, 1.0, 2.0, 0.6097885262460946, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 691052.5057331504, 691052.5057331506, 148806.3325736996], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6440400.0000, 
sim time next is 6441000.0000, 
raw observation next is [18.61666666666667, 98.83333333333334, 1.0, 2.0, 0.5807513542124927, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 656658.1016849974, 656658.1016849971, 144452.3683523719], 
processed observation next is [1.0, 0.5652173913043478, 0.48257575757575777, 0.9883333333333334, 1.0, 1.0, 0.4759391927656158, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.24320670432777683, 0.2432067043277767, 0.3523228496399315], 
reward next is 0.6477, 
noisyNet noise sample is [array([2.0537438], dtype=float32), -0.84934646]. 
=============================================
[2019-03-23 09:59:33,300] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[64.094734]
 [64.06023 ]
 [63.934082]
 [63.719933]
 [63.46396 ]], R is [[64.14594269]
 [64.14154053]
 [64.14385223]
 [64.13500977]
 [64.10359955]].
[2019-03-23 09:59:38,617] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.5886874e-33 1.0000000e+00 0.0000000e+00 2.4530882e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 09:59:38,624] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6708
[2019-03-23 09:59:38,628] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.85, 57.0, 1.0, 2.0, 0.4354777136278563, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 472936.0149650419, 472936.0149650422, 101430.6818355551], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6521400.0000, 
sim time next is 6522000.0000, 
raw observation next is [19.03333333333333, 56.0, 1.0, 2.0, 0.4356150627007775, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 473085.2509115625, 473085.2509115622, 101607.3928971337], 
processed observation next is [1.0, 0.4782608695652174, 0.5015151515151515, 0.56, 1.0, 1.0, 0.2945188283759718, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17521675959687502, 0.17521675959687488, 0.24782290950520414], 
reward next is 0.7522, 
noisyNet noise sample is [array([2.5034282], dtype=float32), -1.0547091]. 
=============================================
[2019-03-23 09:59:38,643] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[76.92429 ]
 [76.886116]
 [76.81913 ]
 [76.76479 ]
 [76.7306  ]], R is [[76.93488312]
 [76.91814423]
 [76.90345764]
 [76.8861618 ]
 [76.86521149]].
[2019-03-23 09:59:39,686] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.6773429e-32 1.0000000e+00 0.0000000e+00 1.3110556e-29 0.0000000e+00], sum to 1.0000
[2019-03-23 09:59:39,691] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9353
[2019-03-23 09:59:39,693] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.2, 93.66666666666666, 1.0, 2.0, 0.6518664969328933, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 728779.9248950768, 728779.9248950768, 149041.7657164647], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6693000.0000, 
sim time next is 6693600.0000, 
raw observation next is [18.1, 94.33333333333334, 1.0, 2.0, 0.6693770697184795, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 748370.1171846767, 748370.117184677, 151145.9321541288], 
processed observation next is [1.0, 0.4782608695652174, 0.45909090909090916, 0.9433333333333335, 1.0, 1.0, 0.5867213371480994, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.27717411747580617, 0.27717411747580634, 0.36864861501007024], 
reward next is 0.6314, 
noisyNet noise sample is [array([-1.1485684], dtype=float32), 0.35647523]. 
=============================================
[2019-03-23 09:59:40,601] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.7947073e-24 1.0000000e+00 1.3491086e-34 3.7557041e-24 4.6763438e-34], sum to 1.0000
[2019-03-23 09:59:40,608] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3735
[2019-03-23 09:59:40,611] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [11.36666666666667, 96.16666666666666, 1.0, 2.0, 0.2122514696788721, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 230451.1696041961, 230451.1696041961, 70384.52555809863], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6588600.0000, 
sim time next is 6589200.0000, 
raw observation next is [11.63333333333333, 96.33333333333333, 1.0, 2.0, 0.2020562219494882, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 219379.2245679525, 219379.2245679522, 70204.03694048793], 
processed observation next is [1.0, 0.2608695652173913, 0.16515151515151497, 0.9633333333333333, 1.0, 1.0, 0.0025702774368602244, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08125156465479723, 0.0812515646547971, 0.17122935839143397], 
reward next is 0.8288, 
noisyNet noise sample is [array([0.45804203], dtype=float32), -0.46700963]. 
=============================================
[2019-03-23 09:59:43,188] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-23 09:59:43,192] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 09:59:43,192] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 09:59:43,193] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:59:43,193] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 09:59:43,193] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:59:43,195] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:59:43,195] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 09:59:43,197] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:59:43,197] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 09:59:43,199] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:59:43,211] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run42
[2019-03-23 09:59:43,211] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run42
[2019-03-23 09:59:43,258] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run42
[2019-03-23 09:59:43,280] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run42
[2019-03-23 09:59:43,310] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run42
[2019-03-23 09:59:45,073] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.04747579], dtype=float32), -1.1507008]
[2019-03-23 09:59:45,073] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.0, 37.16666666666667, 1.0, 2.0, 0.2970565488652951, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 322538.072341237, 322538.0723412366, 86727.66994797597]
[2019-03-23 09:59:45,075] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 09:59:45,078] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.8131004e-32 1.0000000e+00 0.0000000e+00 1.0069472e-31 0.0000000e+00], sampled 0.5487357692311265
[2019-03-23 09:59:56,726] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.04747579], dtype=float32), -1.1507008]
[2019-03-23 09:59:56,727] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.86666666666667, 86.0, 1.0, 2.0, 0.4319315049201921, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 490423.0485683306, 490423.0485683306, 134403.8509852756]
[2019-03-23 09:59:56,727] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 09:59:56,729] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [7.2340106e-31 1.0000000e+00 0.0000000e+00 4.0681591e-30 0.0000000e+00], sampled 0.1326639298762562
[2019-03-23 10:00:24,521] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.04747579], dtype=float32), -1.1507008]
[2019-03-23 10:00:24,522] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [25.81666666666667, 70.83333333333334, 1.0, 2.0, 0.6771757072561994, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 770936.9823725099, 770936.9823725099, 170897.9111834402]
[2019-03-23 10:00:24,523] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 10:00:24,528] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.2109762e-30 1.0000000e+00 0.0000000e+00 1.6090251e-29 0.0000000e+00], sampled 0.9905775837585005
[2019-03-23 10:00:33,602] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.04747579], dtype=float32), -1.1507008]
[2019-03-23 10:00:33,602] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [26.03333333333333, 67.0, 1.0, 2.0, 0.5170655484794257, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 589440.5643561084, 589440.5643561081, 148676.3315607735]
[2019-03-23 10:00:33,604] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 10:00:33,607] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.9753398e-31 1.0000000e+00 0.0000000e+00 1.6405778e-30 0.0000000e+00], sampled 0.1477289139803506
[2019-03-23 10:00:45,267] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.04747579], dtype=float32), -1.1507008]
[2019-03-23 10:00:45,268] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.3, 65.0, 1.0, 2.0, 0.3175899723398709, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 350466.2891714875, 350466.2891714872, 118748.7926854877]
[2019-03-23 10:00:45,268] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 10:00:45,271] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [9.5458530e-31 1.0000000e+00 0.0000000e+00 5.4276456e-30 0.0000000e+00], sampled 0.10927225954652797
[2019-03-23 10:01:22,858] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 10:01:23,007] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 10:01:23,168] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 10:01:23,211] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 10:01:23,302] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 10:01:24,319] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1025000, evaluation results [1025000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 10:01:29,079] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.5264723e-28 1.0000000e+00 0.0000000e+00 1.5795562e-26 0.0000000e+00], sum to 1.0000
[2019-03-23 10:01:29,088] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1153
[2019-03-23 10:01:29,096] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 98.5, 1.0, 2.0, 0.3605811069330362, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 402295.0730565768, 402295.0730565765, 119442.8916730439], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6730200.0000, 
sim time next is 6730800.0000, 
raw observation next is [17.7, 99.0, 1.0, 2.0, 0.360103989840759, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 402058.101427612, 402058.101427612, 119534.1366885196], 
processed observation next is [1.0, 0.9130434782608695, 0.44090909090909086, 0.99, 1.0, 1.0, 0.2001299873009487, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1489104079361526, 0.1489104079361526, 0.2915466748500478], 
reward next is 0.7085, 
noisyNet noise sample is [array([-1.8865504], dtype=float32), 0.12879843]. 
=============================================
[2019-03-23 10:01:29,229] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.423177e-28 1.000000e+00 0.000000e+00 1.788301e-27 0.000000e+00], sum to 1.0000
[2019-03-23 10:01:29,242] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4529
[2019-03-23 10:01:29,246] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.61666666666667, 99.33333333333334, 1.0, 2.0, 0.3656404582900935, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 408297.7944089075, 408297.7944089072, 120012.0383508175], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6732600.0000, 
sim time next is 6733200.0000, 
raw observation next is [17.53333333333333, 98.66666666666667, 1.0, 2.0, 0.3639510070105123, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 405565.9464399148, 405565.9464399145, 119505.8757424804], 
processed observation next is [1.0, 0.9565217391304348, 0.43333333333333324, 0.9866666666666667, 1.0, 1.0, 0.20493875876314036, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15020960979256104, 0.15020960979256093, 0.2914777457133668], 
reward next is 0.7085, 
noisyNet noise sample is [array([0.22108121], dtype=float32), 0.21545483]. 
=============================================
[2019-03-23 10:01:34,168] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.7388567e-30 1.0000000e+00 0.0000000e+00 2.9830382e-28 0.0000000e+00], sum to 1.0000
[2019-03-23 10:01:34,179] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0246
[2019-03-23 10:01:34,183] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.7, 69.0, 1.0, 2.0, 0.4021821297798428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 454801.1626765824, 454801.1626765827, 125946.167351568], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6813600.0000, 
sim time next is 6814200.0000, 
raw observation next is [22.7, 68.5, 1.0, 2.0, 0.4017955728742271, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 454082.5362992217, 454082.5362992217, 125742.2466711423], 
processed observation next is [1.0, 0.8695652173913043, 0.6681818181818181, 0.685, 1.0, 1.0, 0.2522444660927839, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1681787171478599, 0.1681787171478599, 0.30668840651498125], 
reward next is 0.6933, 
noisyNet noise sample is [array([-0.42999062], dtype=float32), -0.2743506]. 
=============================================
[2019-03-23 10:01:35,669] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.8288151e-28 1.0000000e+00 0.0000000e+00 2.6644828e-32 0.0000000e+00], sum to 1.0000
[2019-03-23 10:01:35,680] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8739
[2019-03-23 10:01:35,687] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 90.0, 1.0, 2.0, 0.3643242209615317, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 407375.2116061769, 407375.2116061769, 120149.3297011645], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6832800.0000, 
sim time next is 6833400.0000, 
raw observation next is [18.8, 90.0, 1.0, 2.0, 0.3645833174941722, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 407635.7258040743, 407635.7258040743, 120157.5184335035], 
processed observation next is [0.0, 0.08695652173913043, 0.49090909090909096, 0.9, 1.0, 1.0, 0.20572914686771526, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15097619474224974, 0.15097619474224974, 0.29306711813049635], 
reward next is 0.7069, 
noisyNet noise sample is [array([0.8878584], dtype=float32), 1.2103752]. 
=============================================
[2019-03-23 10:01:40,514] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.3156045e-27 1.0000000e+00 2.3757524e-38 7.7361727e-28 2.3824683e-38], sum to 1.0000
[2019-03-23 10:01:40,523] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5200
[2019-03-23 10:01:40,530] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.11666666666666, 69.66666666666666, 1.0, 2.0, 0.4355580452611355, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 496402.610885185, 496402.610885185, 132243.0088695563], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6947400.0000, 
sim time next is 6948000.0000, 
raw observation next is [24.4, 69.0, 1.0, 2.0, 0.4413547675680303, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 503238.5092441817, 503238.5092441817, 133196.8240824229], 
processed observation next is [0.0, 0.43478260869565216, 0.7454545454545454, 0.69, 1.0, 1.0, 0.3016934594600379, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1863846330534006, 0.1863846330534006, 0.3248703026400559], 
reward next is 0.6751, 
noisyNet noise sample is [array([0.6867942], dtype=float32), -0.10828229]. 
=============================================
[2019-03-23 10:01:40,547] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[66.937965]
 [66.9404  ]
 [66.94178 ]
 [66.94242 ]
 [66.942604]], R is [[66.93930817]
 [66.94737244]
 [66.95758057]
 [66.96987152]
 [66.98435974]].
[2019-03-23 10:01:47,506] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.7912144e-28 1.0000000e+00 0.0000000e+00 9.5486454e-26 0.0000000e+00], sum to 1.0000
[2019-03-23 10:01:47,516] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9510
[2019-03-23 10:01:47,519] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.76666666666667, 81.66666666666667, 1.0, 2.0, 0.2114928874608049, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 229627.3476306786, 229627.3476306783, 72022.00114777617], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7197000.0000, 
sim time next is 7197600.0000, 
raw observation next is [14.23333333333334, 80.33333333333334, 1.0, 2.0, 0.2053363532496375, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 222941.3894189167, 222941.3894189167, 72288.75906017995], 
processed observation next is [1.0, 0.30434782608695654, 0.2833333333333336, 0.8033333333333335, 1.0, 1.0, 0.0066704415620468666, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08257088496996914, 0.08257088496996914, 0.17631404648824378], 
reward next is 0.8237, 
noisyNet noise sample is [array([0.31330776], dtype=float32), -0.1384275]. 
=============================================
[2019-03-23 10:02:06,229] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.035996e-30 1.000000e+00 0.000000e+00 6.510941e-33 0.000000e+00], sum to 1.0000
[2019-03-23 10:02:06,236] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8918
[2019-03-23 10:02:06,247] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.35, 84.0, 1.0, 2.0, 0.4338924431152239, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 493163.3772065852, 493163.3772065855, 130665.3377138555], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7410600.0000, 
sim time next is 7411200.0000, 
raw observation next is [21.43333333333334, 84.0, 1.0, 2.0, 0.4361137375290173, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 495909.0396405181, 495909.0396405184, 131076.616344183], 
processed observation next is [1.0, 0.782608695652174, 0.6106060606060609, 0.84, 1.0, 1.0, 0.29514217191127157, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18367001468167335, 0.18367001468167346, 0.31969906425410494], 
reward next is 0.6803, 
noisyNet noise sample is [array([-0.55264664], dtype=float32), 0.8624793]. 
=============================================
[2019-03-23 10:02:13,193] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-23 10:02:13,195] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 10:02:13,196] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:02:13,198] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 10:02:13,199] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 10:02:13,199] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:02:13,199] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:02:13,200] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 10:02:13,201] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 10:02:13,202] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:02:13,204] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:02:13,220] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run43
[2019-03-23 10:02:13,244] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run43
[2019-03-23 10:02:13,245] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run43
[2019-03-23 10:02:13,293] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run43
[2019-03-23 10:02:13,318] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run43
[2019-03-23 10:02:26,991] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.04120212], dtype=float32), -1.1697389]
[2019-03-23 10:02:26,993] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.11666666666667, 77.83333333333334, 1.0, 2.0, 0.5117681107674512, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 583669.453280245, 583669.453280245, 147624.0986576037]
[2019-03-23 10:02:26,994] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 10:02:26,997] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.3284037e-29 1.0000000e+00 0.0000000e+00 3.5770026e-29 0.0000000e+00], sampled 0.4807703626596779
[2019-03-23 10:02:45,449] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.04120212], dtype=float32), -1.1697389]
[2019-03-23 10:02:45,450] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [27.9, 45.0, 1.0, 2.0, 0.8251063839769596, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 938173.7172835247, 938173.7172835243, 184714.0258511913]
[2019-03-23 10:02:45,450] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 10:02:45,453] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.3889829e-29 1.0000000e+00 0.0000000e+00 3.7384987e-29 0.0000000e+00], sampled 0.6829694629104678
[2019-03-23 10:02:54,324] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.04120212], dtype=float32), -1.1697389]
[2019-03-23 10:02:54,325] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [28.47739817, 59.12074236, 1.0, 2.0, 0.6593191591855875, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9355334656792286, 6.973895605257182, 6.9112, 95.55313977627017, 1294211.697954381, 1269050.497837892, 285916.859989501]
[2019-03-23 10:02:54,328] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 10:02:54,331] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.1796324e-29 1.0000000e+00 0.0000000e+00 5.8370946e-29 0.0000000e+00], sampled 0.21009112976103406
[2019-03-23 10:02:54,331] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1294211.697954381 W.
[2019-03-23 10:03:06,380] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.04120212], dtype=float32), -1.1697389]
[2019-03-23 10:03:06,381] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.2, 91.00000000000001, 1.0, 2.0, 0.5065500676099041, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 577811.0751801614, 577811.075180161, 146801.9909047505]
[2019-03-23 10:03:06,383] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 10:03:06,386] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.4012767e-29 1.0000000e+00 0.0000000e+00 3.7714439e-29 0.0000000e+00], sampled 0.6135162263858424
[2019-03-23 10:03:15,427] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.04120212], dtype=float32), -1.1697389]
[2019-03-23 10:03:15,428] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [17.8, 63.0, 1.0, 2.0, 0.2430276843461598, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 263861.732263945, 263861.7322639447, 84807.81335342661]
[2019-03-23 10:03:15,429] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 10:03:15,432] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.1630827e-29 1.0000000e+00 0.0000000e+00 3.1348774e-29 0.0000000e+00], sampled 0.5366180572813212
[2019-03-23 10:03:28,765] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.04120212], dtype=float32), -1.1697389]
[2019-03-23 10:03:28,766] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.3, 51.0, 1.0, 2.0, 0.4847866725113905, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 540401.3113267398, 540401.3113267395, 134639.9515052232]
[2019-03-23 10:03:28,767] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 10:03:28,770] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.1911459e-29 1.0000000e+00 0.0000000e+00 3.2100269e-29 0.0000000e+00], sampled 0.5588510543162959
[2019-03-23 10:03:52,420] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 10:03:53,044] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 10:03:53,181] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 10:03:53,285] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 10:03:53,397] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 10:03:54,411] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 1050000, evaluation results [1050000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 10:03:56,483] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.5369431e-26 1.0000000e+00 4.8202150e-38 1.9987753e-24 0.0000000e+00], sum to 1.0000
[2019-03-23 10:03:56,493] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3426
[2019-03-23 10:03:56,497] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 95.0, 1.0, 2.0, 0.4371515542969703, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 496928.5729396286, 496928.5729396286, 131040.9995464398], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7616400.0000, 
sim time next is 7617000.0000, 
raw observation next is [20.0, 95.5, 1.0, 2.0, 0.4389087130852167, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 499087.3857786334, 499087.3857786331, 131356.4341926656], 
processed observation next is [1.0, 0.13043478260869565, 0.5454545454545454, 0.955, 1.0, 1.0, 0.2986358913565208, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1848471799180124, 0.18484717991801228, 0.3203815468113795], 
reward next is 0.6796, 
noisyNet noise sample is [array([1.2360086], dtype=float32), 0.10620508]. 
=============================================
[2019-03-23 10:03:56,512] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[67.56002 ]
 [67.559494]
 [67.542114]
 [67.54642 ]
 [67.589714]], R is [[67.56668091]
 [67.5714035 ]
 [67.57771301]
 [67.58392334]
 [67.58422852]].
[2019-03-23 10:03:59,028] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0576625e-14 1.0000000e+00 5.1370092e-22 1.1412961e-14 6.5962298e-21], sum to 1.0000
[2019-03-23 10:03:59,031] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8599
[2019-03-23 10:03:59,036] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1119438.420224976 W.
[2019-03-23 10:03:59,044] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.86666666666667, 79.33333333333334, 1.0, 2.0, 0.5010298646887396, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9506809927491983, 6.949669399886349, 6.9112, 77.32836889210243, 1119438.420224976, 1106944.361254004, 256625.8313137206], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7636800.0000, 
sim time next is 7637400.0000, 
raw observation next is [24.15, 78.0, 1.0, 2.0, 0.5028028958125367, 1.0, 1.0, 0.5028028958125367, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32844032695334, 1142787.724440373, 1142787.724440373, 232383.660034434], 
processed observation next is [1.0, 0.391304347826087, 0.734090909090909, 0.78, 1.0, 1.0, 0.3785036197656708, 1.0, 0.5, 0.3785036197656708, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.508428660930834, 0.4232547127556937, 0.4232547127556937, 0.5667894147181317], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.41055214], dtype=float32), 0.38856447]. 
=============================================
[2019-03-23 10:04:04,132] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.4294841e-28 1.0000000e+00 0.0000000e+00 1.1774456e-26 0.0000000e+00], sum to 1.0000
[2019-03-23 10:04:04,141] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5316
[2019-03-23 10:04:04,144] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.21666666666667, 83.0, 1.0, 2.0, 0.2260521735392129, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 245439.0082561235, 245439.0082561238, 74843.61648032827], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7791000.0000, 
sim time next is 7791600.0000, 
raw observation next is [14.03333333333333, 85.0, 1.0, 2.0, 0.2120414031151464, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 230223.0367097669, 230223.0367097666, 73722.67349463065], 
processed observation next is [1.0, 0.17391304347826086, 0.27424242424242407, 0.85, 1.0, 1.0, 0.015051753893932998, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08526779137398774, 0.08526779137398763, 0.17981139876739183], 
reward next is 0.8202, 
noisyNet noise sample is [array([0.6652147], dtype=float32), 0.16913067]. 
=============================================
[2019-03-23 10:04:08,939] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:04:08,940] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:04:08,997] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run6
[2019-03-23 10:04:12,037] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.9968378e-24 1.0000000e+00 1.2244609e-35 1.7071210e-24 3.8725052e-36], sum to 1.0000
[2019-03-23 10:04:12,042] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7946
[2019-03-23 10:04:12,050] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1090475.931941521 W.
[2019-03-23 10:04:12,054] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.28333333333333, 92.0, 1.0, 2.0, 0.955268977014084, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1090475.931941521, 1090475.931941521, 207177.8813731366], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7913400.0000, 
sim time next is 7914000.0000, 
raw observation next is [21.46666666666667, 91.0, 1.0, 2.0, 0.5077435351172658, 0.0, 2.0, 0.0, 1.0, 1.0, 0.949000623841442, 6.94511023246047, 6.9112, 77.32837978447304, 1127863.252977299, 1116849.914973311, 253820.3881585383], 
processed observation next is [1.0, 0.6086956521739131, 0.6121212121212122, 0.91, 1.0, 1.0, 0.3846794188965822, 0.0, 1.0, -0.25, 1.0, 0.5, 0.9271437483449173, 0.003391023246047009, 0.0, 0.5084282628685939, 0.417727130732333, 0.4136481166567818, 0.6190741174598495], 
reward next is 0.2114, 
noisyNet noise sample is [array([0.1226519], dtype=float32), 0.6694177]. 
=============================================
[2019-03-23 10:04:12,066] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[63.28841 ]
 [63.598263]
 [63.504173]
 [63.671608]
 [64.093185]], R is [[62.21981049]
 [62.09230423]
 [62.00558472]
 [61.9121933 ]
 [61.82512283]].
[2019-03-23 10:04:13,201] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:04:13,202] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:04:13,276] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run6
[2019-03-23 10:04:14,426] A3C_AGENT_WORKER-Thread-9 INFO:Local step 66500, global step 1060105: loss 0.0520
[2019-03-23 10:04:14,427] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 66500, global step 1060105: learning rate 0.0005
[2019-03-23 10:04:14,482] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:04:14,482] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:04:14,486] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run6
[2019-03-23 10:04:14,544] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:04:14,544] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:04:14,555] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run6
[2019-03-23 10:04:14,614] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:04:14,615] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:04:14,622] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run6
[2019-03-23 10:04:14,658] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:04:14,659] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:04:14,660] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:04:14,661] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:04:14,672] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run6
[2019-03-23 10:04:14,696] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run6
[2019-03-23 10:04:14,719] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:04:14,719] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:04:14,728] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run6
[2019-03-23 10:04:14,756] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:04:14,756] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:04:14,761] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run6
[2019-03-23 10:04:14,792] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:04:14,793] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:04:14,806] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run6
[2019-03-23 10:04:14,944] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:04:14,944] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:04:14,947] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run6
[2019-03-23 10:04:14,983] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:04:14,983] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:04:14,988] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run6
[2019-03-23 10:04:15,045] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:04:15,045] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:04:15,048] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run6
[2019-03-23 10:04:15,076] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:04:15,077] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:04:15,080] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run6
[2019-03-23 10:04:15,132] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:04:15,133] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:04:15,136] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run6
[2019-03-23 10:04:15,178] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:04:15,178] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:04:15,181] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run6
[2019-03-23 10:04:17,422] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.7223322e-28 1.0000000e+00 0.0000000e+00 1.6370719e-21 0.0000000e+00], sum to 1.0000
[2019-03-23 10:04:17,430] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3308
[2019-03-23 10:04:17,433] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.43333333333333, 90.0, 1.0, 2.0, 0.3628178413964365, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 397494.8465193326, 397494.8465193328, 116801.206827912], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 9600.0000, 
sim time next is 10200.0000, 
raw observation next is [17.36666666666667, 89.0, 1.0, 2.0, 0.3641677532786219, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 397633.168108004, 397633.168108004, 116443.2067967597], 
processed observation next is [1.0, 0.08695652173913043, 0.42575757575757595, 0.89, 1.0, 1.0, 0.20520969159827734, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14727154374370519, 0.14727154374370519, 0.28400782145551146], 
reward next is 0.7160, 
noisyNet noise sample is [array([-0.7115079], dtype=float32), -0.874014]. 
=============================================
[2019-03-23 10:04:19,352] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.3924689e-21 1.0000000e+00 7.8640675e-33 2.0406923e-19 3.7752238e-32], sum to 1.0000
[2019-03-23 10:04:19,360] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6301
[2019-03-23 10:04:19,366] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.83333333333334, 74.66666666666667, 1.0, 2.0, 0.402120755202325, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 454671.9551113236, 454671.9551113239, 125904.3890549549], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 64200.0000, 
sim time next is 64800.0000, 
raw observation next is [22.0, 73.0, 1.0, 2.0, 0.4039180383609439, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 456430.36293256, 456430.3629325603, 125907.1308270399], 
processed observation next is [1.0, 0.782608695652174, 0.6363636363636364, 0.73, 1.0, 1.0, 0.25489754795117986, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1690482825676148, 0.16904828256761492, 0.30709056299278026], 
reward next is 0.6929, 
noisyNet noise sample is [array([1.7132809], dtype=float32), 0.5503989]. 
=============================================
[2019-03-23 10:04:20,228] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.8916057e-31 1.0000000e+00 0.0000000e+00 4.3552315e-31 0.0000000e+00], sum to 1.0000
[2019-03-23 10:04:20,238] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7373
[2019-03-23 10:04:20,243] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.5, 73.66666666666667, 1.0, 2.0, 0.3144831358267037, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 341487.7540462222, 341487.7540462222, 106673.2232230525], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 76200.0000, 
sim time next is 76800.0000, 
raw observation next is [18.0, 74.33333333333334, 1.0, 2.0, 0.3037962725112994, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 329879.2754178653, 329879.2754178656, 99311.67459121472], 
processed observation next is [1.0, 0.9130434782608695, 0.45454545454545453, 0.7433333333333334, 1.0, 1.0, 0.12974534063912427, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1221775094140242, 0.12217750941402429, 0.24222359656393833], 
reward next is 0.7578, 
noisyNet noise sample is [array([-0.22497989], dtype=float32), -0.4558888]. 
=============================================
[2019-03-23 10:04:20,960] A3C_AGENT_WORKER-Thread-13 INFO:Local step 66500, global step 1062644: loss 0.0005
[2019-03-23 10:04:20,961] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 66500, global step 1062644: learning rate 0.0005
[2019-03-23 10:04:24,113] A3C_AGENT_WORKER-Thread-21 INFO:Local step 66500, global step 1064242: loss 0.0814
[2019-03-23 10:04:24,115] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 66500, global step 1064242: learning rate 0.0005
[2019-03-23 10:04:24,115] A3C_AGENT_WORKER-Thread-16 INFO:Local step 66500, global step 1064243: loss 0.0487
[2019-03-23 10:04:24,119] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 66500, global step 1064245: learning rate 0.0005
[2019-03-23 10:04:24,251] A3C_AGENT_WORKER-Thread-15 INFO:Local step 66500, global step 1064313: loss 0.0997
[2019-03-23 10:04:24,258] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 66500, global step 1064314: learning rate 0.0005
[2019-03-23 10:04:24,381] A3C_AGENT_WORKER-Thread-17 INFO:Local step 66500, global step 1064377: loss 0.0400
[2019-03-23 10:04:24,384] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 66500, global step 1064378: learning rate 0.0005
[2019-03-23 10:04:24,408] A3C_AGENT_WORKER-Thread-22 INFO:Local step 66500, global step 1064390: loss 0.0130
[2019-03-23 10:04:24,409] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 66500, global step 1064390: learning rate 0.0005
[2019-03-23 10:04:24,440] A3C_AGENT_WORKER-Thread-2 INFO:Local step 66500, global step 1064403: loss 0.0240
[2019-03-23 10:04:24,441] A3C_AGENT_WORKER-Thread-3 INFO:Local step 66500, global step 1064403: loss 0.0209
[2019-03-23 10:04:24,446] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 66500, global step 1064403: learning rate 0.0005
[2019-03-23 10:04:24,446] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 66500, global step 1064404: learning rate 0.0005
[2019-03-23 10:04:24,486] A3C_AGENT_WORKER-Thread-14 INFO:Local step 66500, global step 1064424: loss 0.0381
[2019-03-23 10:04:24,489] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 66500, global step 1064425: learning rate 0.0005
[2019-03-23 10:04:24,545] A3C_AGENT_WORKER-Thread-12 INFO:Local step 66500, global step 1064456: loss 0.0129
[2019-03-23 10:04:24,549] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 66500, global step 1064456: learning rate 0.0005
[2019-03-23 10:04:24,664] A3C_AGENT_WORKER-Thread-20 INFO:Local step 66500, global step 1064515: loss 0.0065
[2019-03-23 10:04:24,666] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 66500, global step 1064515: learning rate 0.0005
[2019-03-23 10:04:24,769] A3C_AGENT_WORKER-Thread-19 INFO:Local step 66500, global step 1064568: loss 0.0065
[2019-03-23 10:04:24,770] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 66500, global step 1064568: learning rate 0.0005
[2019-03-23 10:04:25,004] A3C_AGENT_WORKER-Thread-10 INFO:Local step 66500, global step 1064686: loss 0.0134
[2019-03-23 10:04:25,006] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 66500, global step 1064686: learning rate 0.0005
[2019-03-23 10:04:25,028] A3C_AGENT_WORKER-Thread-18 INFO:Local step 66500, global step 1064697: loss 0.0052
[2019-03-23 10:04:25,029] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 66500, global step 1064697: learning rate 0.0005
[2019-03-23 10:04:25,136] A3C_AGENT_WORKER-Thread-11 INFO:Local step 66500, global step 1064750: loss 0.0003
[2019-03-23 10:04:25,138] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 66500, global step 1064750: learning rate 0.0005
[2019-03-23 10:04:29,002] A3C_AGENT_WORKER-Thread-9 INFO:Local step 67000, global step 1066693: loss 0.2234
[2019-03-23 10:04:29,003] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 67000, global step 1066693: learning rate 0.0005
[2019-03-23 10:04:33,277] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.1084929e-34 1.0000000e+00 0.0000000e+00 1.7763566e-33 0.0000000e+00], sum to 1.0000
[2019-03-23 10:04:33,283] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8668
[2019-03-23 10:04:33,287] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.66666666666667, 43.0, 1.0, 2.0, 0.2545316319539786, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 276369.7261021505, 276369.7261021507, 80156.00039763679], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 325200.0000, 
sim time next is 325800.0000, 
raw observation next is [20.5, 43.0, 1.0, 2.0, 0.2521818090964079, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 273817.576857555, 273817.576857555, 79426.41671779373], 
processed observation next is [0.0, 0.782608695652174, 0.5681818181818182, 0.43, 1.0, 1.0, 0.06522726137050988, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10141391735465001, 0.10141391735465001, 0.19372296760437496], 
reward next is 0.8063, 
noisyNet noise sample is [array([-1.5861707], dtype=float32), -2.1009588]. 
=============================================
[2019-03-23 10:04:33,789] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.2239111e-33 1.0000000e+00 0.0000000e+00 1.6075509e-31 0.0000000e+00], sum to 1.0000
[2019-03-23 10:04:33,790] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6860
[2019-03-23 10:04:33,799] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.5, 55.5, 1.0, 2.0, 0.2177762435374522, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 236451.1283717442, 236451.1283717444, 73715.87976087574], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 333000.0000, 
sim time next is 333600.0000, 
raw observation next is [17.33333333333333, 56.66666666666666, 1.0, 2.0, 0.2153722544235782, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 233840.3634458004, 233840.3634458004, 73490.12858807364], 
processed observation next is [0.0, 0.8695652173913043, 0.42424242424242403, 0.5666666666666665, 1.0, 1.0, 0.019215318029472753, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08660754201696312, 0.08660754201696312, 0.1792442160684723], 
reward next is 0.8208, 
noisyNet noise sample is [array([0.89189684], dtype=float32), -1.9582769]. 
=============================================
[2019-03-23 10:04:36,248] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.9939765e-32 1.0000000e+00 0.0000000e+00 1.2333877e-26 0.0000000e+00], sum to 1.0000
[2019-03-23 10:04:36,258] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0270
[2019-03-23 10:04:36,263] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.83333333333333, 54.66666666666666, 1.0, 2.0, 0.3090602567545784, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 335597.1812884035, 335597.1812884032, 83481.95215294138], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 384600.0000, 
sim time next is 385200.0000, 
raw observation next is [18.0, 52.0, 1.0, 2.0, 0.3044332598277835, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 330571.1875753448, 330571.1875753445, 82488.69958588106], 
processed observation next is [1.0, 0.4782608695652174, 0.45454545454545453, 0.52, 1.0, 1.0, 0.1305415747847294, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12243377317605364, 0.12243377317605353, 0.20119195020946598], 
reward next is 0.7988, 
noisyNet noise sample is [array([1.5887785], dtype=float32), -1.0518698]. 
=============================================
[2019-03-23 10:04:36,561] A3C_AGENT_WORKER-Thread-13 INFO:Local step 67000, global step 1070733: loss 0.0175
[2019-03-23 10:04:36,564] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 67000, global step 1070734: learning rate 0.0005
[2019-03-23 10:04:36,596] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.8258737e-32 1.0000000e+00 0.0000000e+00 4.5728526e-31 0.0000000e+00], sum to 1.0000
[2019-03-23 10:04:36,603] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6262
[2019-03-23 10:04:36,606] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 58.0, 1.0, 2.0, 0.3857302730052026, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 418886.1956699531, 418886.1956699534, 97621.5353858297], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 401400.0000, 
sim time next is 402000.0000, 
raw observation next is [19.0, 58.66666666666667, 1.0, 2.0, 0.3880111625603052, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 421364.2152126575, 421364.2152126572, 98429.66559663616], 
processed observation next is [1.0, 0.6521739130434783, 0.5, 0.5866666666666667, 1.0, 1.0, 0.2350139532003815, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15606082044913241, 0.15606082044913228, 0.24007235511374672], 
reward next is 0.7599, 
noisyNet noise sample is [array([1.3361425], dtype=float32), -2.1142123]. 
=============================================
[2019-03-23 10:04:36,629] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[78.90972]
 [78.90972]
 [78.90972]
 [78.90972]
 [78.90972]], R is [[78.88054657]
 [78.85364532]
 [78.82952118]
 [78.80688477]
 [78.78902435]].
[2019-03-23 10:04:39,102] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.8044525e-27 1.0000000e+00 0.0000000e+00 2.0618031e-27 0.0000000e+00], sum to 1.0000
[2019-03-23 10:04:39,111] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8359
[2019-03-23 10:04:39,120] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.5501713774884758, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 597571.7977349275, 597571.7977349275, 111369.0579195077], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 447000.0000, 
sim time next is 447600.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.5435294941309048, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 590353.296759208, 590353.296759208, 110642.0932898388], 
processed observation next is [1.0, 0.17391304347826086, 0.22727272727272727, 1.0, 1.0, 1.0, 0.42941186766363093, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21864936917007702, 0.21864936917007702, 0.26985876412155807], 
reward next is 0.7301, 
noisyNet noise sample is [array([1.7636467], dtype=float32), 0.0059031313]. 
=============================================
[2019-03-23 10:04:39,315] A3C_AGENT_WORKER-Thread-21 INFO:Local step 67000, global step 1072209: loss 0.0618
[2019-03-23 10:04:39,317] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 67000, global step 1072210: learning rate 0.0005
[2019-03-23 10:04:39,325] A3C_AGENT_WORKER-Thread-16 INFO:Local step 67000, global step 1072212: loss 0.0908
[2019-03-23 10:04:39,329] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 67000, global step 1072212: learning rate 0.0005
[2019-03-23 10:04:39,569] A3C_AGENT_WORKER-Thread-17 INFO:Local step 67000, global step 1072344: loss 0.0379
[2019-03-23 10:04:39,572] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 67000, global step 1072344: learning rate 0.0005
[2019-03-23 10:04:39,605] A3C_AGENT_WORKER-Thread-15 INFO:Local step 67000, global step 1072366: loss 0.0753
[2019-03-23 10:04:39,606] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 67000, global step 1072366: learning rate 0.0005
[2019-03-23 10:04:39,667] A3C_AGENT_WORKER-Thread-2 INFO:Local step 67000, global step 1072387: loss 0.0735
[2019-03-23 10:04:39,669] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 67000, global step 1072389: learning rate 0.0005
[2019-03-23 10:04:39,678] A3C_AGENT_WORKER-Thread-12 INFO:Local step 67000, global step 1072396: loss 0.0686
[2019-03-23 10:04:39,679] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 67000, global step 1072396: learning rate 0.0005
[2019-03-23 10:04:39,763] A3C_AGENT_WORKER-Thread-3 INFO:Local step 67000, global step 1072442: loss 0.0694
[2019-03-23 10:04:39,767] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 67000, global step 1072442: learning rate 0.0005
[2019-03-23 10:04:39,772] A3C_AGENT_WORKER-Thread-14 INFO:Local step 67000, global step 1072446: loss 0.0264
[2019-03-23 10:04:39,774] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 67000, global step 1072446: learning rate 0.0005
[2019-03-23 10:04:39,825] A3C_AGENT_WORKER-Thread-20 INFO:Local step 67000, global step 1072469: loss 0.0016
[2019-03-23 10:04:39,826] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 67000, global step 1072469: learning rate 0.0005
[2019-03-23 10:04:39,926] A3C_AGENT_WORKER-Thread-22 INFO:Local step 67000, global step 1072529: loss 0.0202
[2019-03-23 10:04:39,928] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 67000, global step 1072530: learning rate 0.0005
[2019-03-23 10:04:39,973] A3C_AGENT_WORKER-Thread-19 INFO:Local step 67000, global step 1072550: loss 0.0105
[2019-03-23 10:04:39,975] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 67000, global step 1072551: learning rate 0.0005
[2019-03-23 10:04:40,144] A3C_AGENT_WORKER-Thread-11 INFO:Local step 67000, global step 1072637: loss 0.0019
[2019-03-23 10:04:40,147] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 67000, global step 1072637: learning rate 0.0005
[2019-03-23 10:04:40,156] A3C_AGENT_WORKER-Thread-10 INFO:Local step 67000, global step 1072640: loss 0.0006
[2019-03-23 10:04:40,160] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 67000, global step 1072641: learning rate 0.0005
[2019-03-23 10:04:40,393] A3C_AGENT_WORKER-Thread-18 INFO:Local step 67000, global step 1072768: loss 0.0050
[2019-03-23 10:04:40,397] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 67000, global step 1072768: learning rate 0.0005
[2019-03-23 10:04:44,102] A3C_AGENT_WORKER-Thread-9 INFO:Local step 67500, global step 1074740: loss 1.5464
[2019-03-23 10:04:44,105] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 67500, global step 1074741: learning rate 0.0005
[2019-03-23 10:04:44,582] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-23 10:04:44,583] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 10:04:44,585] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:04:44,586] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 10:04:44,587] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 10:04:44,587] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 10:04:44,588] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 10:04:44,589] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:04:44,589] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:04:44,590] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:04:44,591] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:04:44,607] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run44
[2019-03-23 10:04:44,633] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run44
[2019-03-23 10:04:44,633] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run44
[2019-03-23 10:04:44,634] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run44
[2019-03-23 10:04:44,706] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run44
[2019-03-23 10:05:03,787] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.04205054], dtype=float32), -1.1466056]
[2019-03-23 10:05:03,787] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.0, 94.0, 1.0, 2.0, 0.582519420993091, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 649919.6377623884, 649919.6377623882, 140565.2928551696]
[2019-03-23 10:05:03,789] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:05:03,793] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.4206530e-29 1.0000000e+00 0.0000000e+00 5.1645213e-28 0.0000000e+00], sampled 0.4230288576660378
[2019-03-23 10:05:09,932] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.04205054], dtype=float32), -1.1466056]
[2019-03-23 10:05:09,933] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [15.37237055333333, 79.64125145333334, 1.0, 2.0, 0.2129188225453452, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 231165.4402431843, 231165.4402431843, 80405.5920753647]
[2019-03-23 10:05:09,934] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 10:05:09,936] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.4305835e-29 1.0000000e+00 0.0000000e+00 5.1949302e-28 0.0000000e+00], sampled 0.25861452946497554
[2019-03-23 10:05:13,190] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.04205054], dtype=float32), -1.1466056]
[2019-03-23 10:05:13,191] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [13.0, 100.0, 1.0, 2.0, 0.2059740838538673, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 223633.956658017, 223633.9566580167, 74265.64503753342]
[2019-03-23 10:05:13,192] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:05:13,195] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.368127e-29 1.000000e+00 0.000000e+00 4.979401e-28 0.000000e+00], sampled 0.7528805330303803
[2019-03-23 10:05:44,159] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.04205054], dtype=float32), -1.1466056]
[2019-03-23 10:05:44,161] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.06666666666667, 56.0, 1.0, 2.0, 0.7595504927493028, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 866800.0972203597, 866800.0972203597, 179407.7203732145]
[2019-03-23 10:05:44,162] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 10:05:44,165] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.5918208e-29 1.0000000e+00 0.0000000e+00 5.7492764e-28 0.0000000e+00], sampled 0.3702063324596614
[2019-03-23 10:05:53,605] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.04205054], dtype=float32), -1.1466056]
[2019-03-23 10:05:53,607] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.2, 70.0, 1.0, 2.0, 0.409849350460035, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 462235.1115265402, 462235.1115265402, 130277.7612478961]
[2019-03-23 10:05:53,608] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 10:05:53,611] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.0940380e-29 1.0000000e+00 0.0000000e+00 7.4586447e-28 0.0000000e+00], sampled 0.6308138638159374
[2019-03-23 10:06:09,114] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.04205054], dtype=float32), -1.1466056]
[2019-03-23 10:06:09,115] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.68646636666666, 87.75971967333334, 1.0, 2.0, 0.3827146059715547, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 431119.3491692535, 431119.3491692535, 127555.5229815912]
[2019-03-23 10:06:09,116] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 10:06:09,118] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.0847924e-29 1.0000000e+00 0.0000000e+00 7.4275544e-28 0.0000000e+00], sampled 0.8876211712188606
[2019-03-23 10:06:24,637] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 10:06:24,716] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 10:06:24,793] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 10:06:24,968] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 10:06:25,002] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 10:06:26,019] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 1075000, evaluation results [1075000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 10:06:26,415] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.2938053e-29 1.0000000e+00 0.0000000e+00 4.3346878e-27 0.0000000e+00], sum to 1.0000
[2019-03-23 10:06:26,424] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2075
[2019-03-23 10:06:26,427] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 69.0, 1.0, 2.0, 0.4454684337838318, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 507457.4713057235, 507457.4713057235, 132944.0150970208], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 772200.0000, 
sim time next is 772800.0000, 
raw observation next is [24.0, 69.0, 1.0, 2.0, 0.4439931461398561, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 505774.9920237183, 505774.9920237183, 132790.3793027496], 
processed observation next is [1.0, 0.9565217391304348, 0.7272727272727273, 0.69, 1.0, 1.0, 0.30499143267482004, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18732407111989566, 0.18732407111989566, 0.3238789739091454], 
reward next is 0.6761, 
noisyNet noise sample is [array([0.33890173], dtype=float32), -0.5255434]. 
=============================================
[2019-03-23 10:06:31,934] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.1963342e-21 1.0000000e+00 6.2422206e-32 5.1828746e-21 2.0984890e-32], sum to 1.0000
[2019-03-23 10:06:31,941] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1584
[2019-03-23 10:06:31,945] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 56.5, 1.0, 2.0, 0.7756056923280478, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 872814.4078998428, 872814.4078998425, 167300.1339616278], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 654600.0000, 
sim time next is 655200.0000, 
raw observation next is [24.0, 57.0, 1.0, 2.0, 0.796444198646806, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 897092.1816251711, 897092.1816251714, 170623.8742592807], 
processed observation next is [1.0, 0.6086956521739131, 0.7272727272727273, 0.57, 1.0, 1.0, 0.7455552483085076, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3322563635648782, 0.3322563635648783, 0.4161557908762944], 
reward next is 0.5838, 
noisyNet noise sample is [array([2.0762804], dtype=float32), -0.2668135]. 
=============================================
[2019-03-23 10:06:33,382] A3C_AGENT_WORKER-Thread-13 INFO:Local step 67500, global step 1078723: loss 0.5431
[2019-03-23 10:06:33,385] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 67500, global step 1078724: learning rate 0.0005
[2019-03-23 10:06:36,351] A3C_AGENT_WORKER-Thread-16 INFO:Local step 67500, global step 1080219: loss 30.4964
[2019-03-23 10:06:36,355] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 67500, global step 1080221: learning rate 0.0005
[2019-03-23 10:06:36,368] A3C_AGENT_WORKER-Thread-21 INFO:Local step 67500, global step 1080228: loss 46.1581
[2019-03-23 10:06:36,369] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 67500, global step 1080228: learning rate 0.0005
[2019-03-23 10:06:36,596] A3C_AGENT_WORKER-Thread-2 INFO:Local step 67500, global step 1080338: loss 15.6678
[2019-03-23 10:06:36,599] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 67500, global step 1080339: learning rate 0.0005
[2019-03-23 10:06:36,693] A3C_AGENT_WORKER-Thread-17 INFO:Local step 67500, global step 1080387: loss 20.8628
[2019-03-23 10:06:36,694] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 67500, global step 1080387: learning rate 0.0005
[2019-03-23 10:06:36,733] A3C_AGENT_WORKER-Thread-12 INFO:Local step 67500, global step 1080407: loss 23.9204
[2019-03-23 10:06:36,733] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 67500, global step 1080407: learning rate 0.0005
[2019-03-23 10:06:36,831] A3C_AGENT_WORKER-Thread-14 INFO:Local step 67500, global step 1080458: loss 27.3035
[2019-03-23 10:06:36,832] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 67500, global step 1080459: learning rate 0.0005
[2019-03-23 10:06:36,875] A3C_AGENT_WORKER-Thread-15 INFO:Local step 67500, global step 1080478: loss 16.9302
[2019-03-23 10:06:36,876] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 67500, global step 1080478: learning rate 0.0005
[2019-03-23 10:06:36,880] A3C_AGENT_WORKER-Thread-22 INFO:Local step 67500, global step 1080479: loss 17.8221
[2019-03-23 10:06:36,883] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 67500, global step 1080479: learning rate 0.0005
[2019-03-23 10:06:36,904] A3C_AGENT_WORKER-Thread-3 INFO:Local step 67500, global step 1080489: loss 16.0379
[2019-03-23 10:06:36,904] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 67500, global step 1080490: learning rate 0.0005
[2019-03-23 10:06:36,944] A3C_AGENT_WORKER-Thread-19 INFO:Local step 67500, global step 1080510: loss 14.5541
[2019-03-23 10:06:36,945] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 67500, global step 1080510: learning rate 0.0005
[2019-03-23 10:06:36,956] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.3277962e-18 1.0000000e+00 9.1267219e-26 8.7372024e-17 8.8218611e-26], sum to 1.0000
[2019-03-23 10:06:36,963] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1571
[2019-03-23 10:06:36,970] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1445792.781044923 W.
[2019-03-23 10:06:36,977] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.0, 55.0, 1.0, 2.0, 0.4251262066524682, 1.0, 1.0, 0.4251262066524682, 1.0, 2.0, 0.8609168720097642, 6.911199999999999, 6.9112, 77.3421103, 1445792.781044923, 1445792.781044924, 315152.4214945653], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 748800.0000, 
sim time next is 749400.0000, 
raw observation next is [28.0, 55.0, 1.0, 2.0, 0.6598291822046468, 1.0, 2.0, 0.6598291822046468, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1495894.005447197, 1495894.005447197, 276297.513696353], 
processed observation next is [1.0, 0.6956521739130435, 0.9090909090909091, 0.55, 1.0, 1.0, 0.5747864777558085, 1.0, 1.0, 0.5747864777558085, 0.0, 0.5, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.5540348168322952, 0.5540348168322952, 0.6738963748691537], 
reward next is 0.3261, 
noisyNet noise sample is [array([-0.03256219], dtype=float32), 0.17423582]. 
=============================================
[2019-03-23 10:06:37,021] A3C_AGENT_WORKER-Thread-20 INFO:Local step 67500, global step 1080546: loss 16.3688
[2019-03-23 10:06:37,022] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 67500, global step 1080546: learning rate 0.0005
[2019-03-23 10:06:37,068] A3C_AGENT_WORKER-Thread-10 INFO:Local step 67500, global step 1080574: loss 10.5277
[2019-03-23 10:06:37,071] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 67500, global step 1080574: learning rate 0.0005
[2019-03-23 10:06:37,390] A3C_AGENT_WORKER-Thread-18 INFO:Local step 67500, global step 1080735: loss 11.7211
[2019-03-23 10:06:37,392] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 67500, global step 1080735: learning rate 0.0005
[2019-03-23 10:06:37,399] A3C_AGENT_WORKER-Thread-11 INFO:Local step 67500, global step 1080735: loss 6.5295
[2019-03-23 10:06:37,403] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 67500, global step 1080737: learning rate 0.0005
[2019-03-23 10:06:41,286] A3C_AGENT_WORKER-Thread-9 INFO:Local step 68000, global step 1082714: loss 0.7733
[2019-03-23 10:06:41,288] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 68000, global step 1082715: learning rate 0.0005
[2019-03-23 10:06:45,125] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.3303192e-31 1.0000000e+00 0.0000000e+00 3.5128948e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 10:06:45,131] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6283
[2019-03-23 10:06:45,140] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.83333333333334, 78.83333333333333, 1.0, 2.0, 0.4504015419912961, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 513535.2155846438, 513535.2155846435, 134101.8529067592], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 899400.0000, 
sim time next is 900000.0000, 
raw observation next is [23.0, 78.0, 1.0, 2.0, 0.4515830109197326, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 514939.8020370846, 514939.8020370843, 134327.4099053543], 
processed observation next is [0.0, 0.43478260869565216, 0.6818181818181818, 0.78, 1.0, 1.0, 0.3144787636496657, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19071844519892023, 0.19071844519892012, 0.32762782903744947], 
reward next is 0.6724, 
noisyNet noise sample is [array([0.09557455], dtype=float32), -1.5294682]. 
=============================================
[2019-03-23 10:06:45,159] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[66.651794]
 [66.651794]
 [66.651794]
 [66.651794]
 [66.651794]], R is [[66.65764618]
 [66.66399384]
 [66.67092896]
 [66.6789093 ]
 [66.68782806]].
[2019-03-23 10:06:45,597] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.3362195e-29 1.0000000e+00 0.0000000e+00 4.0827334e-34 0.0000000e+00], sum to 1.0000
[2019-03-23 10:06:45,606] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9767
[2019-03-23 10:06:45,610] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 78.0, 1.0, 2.0, 0.4231974679517042, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 480636.8573269019, 480636.8573269019, 129309.6454204881], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 919800.0000, 
sim time next is 920400.0000, 
raw observation next is [22.0, 78.0, 1.0, 2.0, 0.4227674882667433, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 480146.7714569061, 480146.7714569064, 129266.4646967753], 
processed observation next is [0.0, 0.6521739130434783, 0.6363636363636364, 0.78, 1.0, 1.0, 0.2784593603334291, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17783213757663188, 0.177832137576632, 0.31528406023603733], 
reward next is 0.6847, 
noisyNet noise sample is [array([-0.44790307], dtype=float32), -0.964235]. 
=============================================
[2019-03-23 10:06:49,052] A3C_AGENT_WORKER-Thread-13 INFO:Local step 68000, global step 1086561: loss 1.4378
[2019-03-23 10:06:49,054] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 68000, global step 1086561: learning rate 0.0005
[2019-03-23 10:06:50,125] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.7268623e-31 1.0000000e+00 0.0000000e+00 7.5329930e-27 0.0000000e+00], sum to 1.0000
[2019-03-23 10:06:50,138] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9279
[2019-03-23 10:06:50,145] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 100.0, 1.0, 2.0, 0.259269368958273, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 281515.4363706367, 281515.436370637, 84518.53193451435], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1013400.0000, 
sim time next is 1014000.0000, 
raw observation next is [14.0, 100.0, 1.0, 2.0, 0.2551380096505537, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 277028.3168055111, 277028.3168055114, 83994.27218043951], 
processed observation next is [1.0, 0.7391304347826086, 0.2727272727272727, 1.0, 1.0, 1.0, 0.06892251206319214, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10260308029833744, 0.10260308029833756, 0.20486407848887686], 
reward next is 0.7951, 
noisyNet noise sample is [array([-0.6798957], dtype=float32), 0.54722965]. 
=============================================
[2019-03-23 10:06:50,163] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[70.75396]
 [70.75686]
 [70.75673]
 [70.76955]
 [70.76917]], R is [[70.84107208]
 [70.92651367]
 [71.00710297]
 [71.06880951]
 [71.09381866]].
[2019-03-23 10:06:52,280] A3C_AGENT_WORKER-Thread-16 INFO:Local step 68000, global step 1088187: loss 1.0987
[2019-03-23 10:06:52,283] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 68000, global step 1088187: learning rate 0.0005
[2019-03-23 10:06:52,367] A3C_AGENT_WORKER-Thread-21 INFO:Local step 68000, global step 1088229: loss 1.0942
[2019-03-23 10:06:52,370] A3C_AGENT_WORKER-Thread-2 INFO:Local step 68000, global step 1088233: loss 1.0312
[2019-03-23 10:06:52,371] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 68000, global step 1088233: learning rate 0.0005
[2019-03-23 10:06:52,373] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 68000, global step 1088233: learning rate 0.0005
[2019-03-23 10:06:52,591] A3C_AGENT_WORKER-Thread-12 INFO:Local step 68000, global step 1088341: loss 1.1579
[2019-03-23 10:06:52,594] A3C_AGENT_WORKER-Thread-17 INFO:Local step 68000, global step 1088343: loss 1.1169
[2019-03-23 10:06:52,595] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 68000, global step 1088343: learning rate 0.0005
[2019-03-23 10:06:52,596] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 68000, global step 1088343: learning rate 0.0005
[2019-03-23 10:06:52,707] A3C_AGENT_WORKER-Thread-15 INFO:Local step 68000, global step 1088398: loss 2.5260
[2019-03-23 10:06:52,711] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 68000, global step 1088398: learning rate 0.0005
[2019-03-23 10:06:52,728] A3C_AGENT_WORKER-Thread-14 INFO:Local step 68000, global step 1088409: loss 2.4929
[2019-03-23 10:06:52,729] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 68000, global step 1088409: learning rate 0.0005
[2019-03-23 10:06:52,788] A3C_AGENT_WORKER-Thread-3 INFO:Local step 68000, global step 1088440: loss 2.0596
[2019-03-23 10:06:52,790] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 68000, global step 1088440: learning rate 0.0005
[2019-03-23 10:06:52,864] A3C_AGENT_WORKER-Thread-22 INFO:Local step 68000, global step 1088474: loss 2.2361
[2019-03-23 10:06:52,865] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 68000, global step 1088474: learning rate 0.0005
[2019-03-23 10:06:52,945] A3C_AGENT_WORKER-Thread-20 INFO:Local step 68000, global step 1088519: loss 1.8919
[2019-03-23 10:06:52,947] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 68000, global step 1088519: learning rate 0.0005
[2019-03-23 10:06:52,963] A3C_AGENT_WORKER-Thread-10 INFO:Local step 68000, global step 1088528: loss 1.7410
[2019-03-23 10:06:52,967] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 68000, global step 1088529: learning rate 0.0005
[2019-03-23 10:06:53,142] A3C_AGENT_WORKER-Thread-19 INFO:Local step 68000, global step 1088618: loss 0.8871
[2019-03-23 10:06:53,144] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 68000, global step 1088618: learning rate 0.0005
[2019-03-23 10:06:53,455] A3C_AGENT_WORKER-Thread-11 INFO:Local step 68000, global step 1088778: loss 1.1983
[2019-03-23 10:06:53,458] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 68000, global step 1088780: learning rate 0.0005
[2019-03-23 10:06:53,596] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.947682e-29 1.000000e+00 0.000000e+00 3.636315e-28 0.000000e+00], sum to 1.0000
[2019-03-23 10:06:53,604] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1829
[2019-03-23 10:06:53,609] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.33333333333334, 75.5, 1.0, 2.0, 0.4091800497393276, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 444363.2641616008, 444363.2641616008, 105025.7545481388], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1069800.0000, 
sim time next is 1070400.0000, 
raw observation next is [17.66666666666667, 74.0, 1.0, 2.0, 0.3974719264517249, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 431642.7775009277, 431642.7775009274, 105228.7258692915], 
processed observation next is [1.0, 0.391304347826087, 0.4393939393939396, 0.74, 1.0, 1.0, 0.2468399080646561, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15986769537071396, 0.15986769537071385, 0.2566554289494915], 
reward next is 0.7433, 
noisyNet noise sample is [array([0.5068278], dtype=float32), -0.30798152]. 
=============================================
[2019-03-23 10:06:53,644] A3C_AGENT_WORKER-Thread-18 INFO:Local step 68000, global step 1088875: loss 2.7651
[2019-03-23 10:06:53,646] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 68000, global step 1088875: learning rate 0.0005
[2019-03-23 10:06:55,951] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.5336031e-30 1.0000000e+00 0.0000000e+00 3.6869709e-31 0.0000000e+00], sum to 1.0000
[2019-03-23 10:06:55,957] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3433
[2019-03-23 10:06:55,960] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 78.0, 1.0, 2.0, 0.3222315399782553, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 353213.3054859326, 353213.3054859323, 113872.8093290945], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1117200.0000, 
sim time next is 1117800.0000, 
raw observation next is [19.0, 78.0, 1.0, 2.0, 0.3227288209908218, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 353757.5924028367, 353757.5924028367, 113908.115792367], 
processed observation next is [1.0, 0.9565217391304348, 0.5, 0.78, 1.0, 1.0, 0.1534110262385272, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13102133051956916, 0.13102133051956916, 0.27782467266430977], 
reward next is 0.7222, 
noisyNet noise sample is [array([-0.48400584], dtype=float32), 0.20392606]. 
=============================================
[2019-03-23 10:06:57,919] A3C_AGENT_WORKER-Thread-9 INFO:Local step 68500, global step 1090974: loss -145.3445
[2019-03-23 10:06:57,922] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 68500, global step 1090974: learning rate 0.0005
[2019-03-23 10:06:58,855] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.7952120e-26 1.0000000e+00 6.4015305e-37 2.9259078e-22 2.6530773e-36], sum to 1.0000
[2019-03-23 10:06:58,861] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9037
[2019-03-23 10:06:58,866] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1344485.586930007 W.
[2019-03-23 10:06:58,869] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.0, 62.66666666666667, 1.0, 2.0, 0.5938177971111164, 1.0, 1.0, 0.5938177971111164, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1344485.586930007, 1344485.586930006, 257964.0314553073], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1176600.0000, 
sim time next is 1177200.0000, 
raw observation next is [27.0, 62.0, 1.0, 2.0, 0.7022544001216008, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9764047884824272, 6.9112, 6.9112, 77.32846344354104, 1347008.58051536, 1347008.58051536, 291598.0341030867], 
processed observation next is [1.0, 0.6521739130434783, 0.8636363636363636, 0.62, 1.0, 1.0, 0.6278180001520008, 0.0, 0.5, -0.25, 1.0, 0.5, 0.966292554974896, 0.0, 0.0, 0.5084288129206541, 0.49889206685754073, 0.49889206685754073, 0.7112147173246016], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.75478137], dtype=float32), 1.4578304]. 
=============================================
[2019-03-23 10:07:01,084] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.1183599e-29 1.0000000e+00 0.0000000e+00 4.7824518e-29 0.0000000e+00], sum to 1.0000
[2019-03-23 10:07:01,089] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6836
[2019-03-23 10:07:01,092] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333334, 87.0, 1.0, 2.0, 0.515773136226442, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 587462.9347323087, 587462.9347323087, 144805.3694075597], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1419600.0000, 
sim time next is 1420200.0000, 
raw observation next is [23.5, 86.0, 1.0, 2.0, 0.5164032882466165, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 588108.2530948699, 588108.2530948701, 144942.5219597276], 
processed observation next is [0.0, 0.43478260869565216, 0.7045454545454546, 0.86, 1.0, 1.0, 0.3955041103082706, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2178178715166185, 0.21781787151661858, 0.353518346243238], 
reward next is 0.6465, 
noisyNet noise sample is [array([-1.2829734], dtype=float32), -0.14355206]. 
=============================================
[2019-03-23 10:07:03,758] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.7012792e-10 9.9999428e-01 1.7220373e-16 5.7416210e-06 8.2054829e-16], sum to 1.0000
[2019-03-23 10:07:03,768] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2027
[2019-03-23 10:07:03,775] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1623440.190011781 W.
[2019-03-23 10:07:03,780] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.0, 59.33333333333333, 1.0, 2.0, 0.4811375293936537, 1.0, 2.0, 0.4811375293936537, 1.0, 2.0, 0.973220187135308, 6.911199999999998, 6.9112, 77.3421103, 1623440.190011781, 1623440.190011781, 349672.8308711771], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1266000.0000, 
sim time next is 1266600.0000, 
raw observation next is [28.0, 58.66666666666666, 1.0, 2.0, 0.4782352220276107, 1.0, 2.0, 0.4782352220276107, 1.0, 2.0, 0.96672433558524, 6.911199999999999, 6.9112, 77.3421103, 1613633.353044285, 1613633.353044285, 347693.5256352289], 
processed observation next is [1.0, 0.6521739130434783, 0.9090909090909091, 0.5866666666666666, 1.0, 1.0, 0.34779402753451333, 1.0, 1.0, 0.34779402753451333, 1.0, 1.0, 0.9524633365503428, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.5976419826089945, 0.5976419826089945, 0.8480329893542168], 
reward next is 0.1520, 
noisyNet noise sample is [array([-0.69559836], dtype=float32), -1.1841161]. 
=============================================
[2019-03-23 10:07:05,023] A3C_AGENT_WORKER-Thread-13 INFO:Local step 68500, global step 1094687: loss 3.6367
[2019-03-23 10:07:05,025] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 68500, global step 1094687: learning rate 0.0005
[2019-03-23 10:07:07,718] A3C_AGENT_WORKER-Thread-16 INFO:Local step 68500, global step 1096117: loss -37.5568
[2019-03-23 10:07:07,719] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 68500, global step 1096117: learning rate 0.0005
[2019-03-23 10:07:07,885] A3C_AGENT_WORKER-Thread-2 INFO:Local step 68500, global step 1096204: loss -110.2798
[2019-03-23 10:07:07,888] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 68500, global step 1096204: learning rate 0.0005
[2019-03-23 10:07:08,101] A3C_AGENT_WORKER-Thread-17 INFO:Local step 68500, global step 1096318: loss -226.8068
[2019-03-23 10:07:08,102] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 68500, global step 1096318: learning rate 0.0005
[2019-03-23 10:07:08,202] A3C_AGENT_WORKER-Thread-15 INFO:Local step 68500, global step 1096370: loss -96.8165
[2019-03-23 10:07:08,203] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 68500, global step 1096370: learning rate 0.0005
[2019-03-23 10:07:08,238] A3C_AGENT_WORKER-Thread-21 INFO:Local step 68500, global step 1096389: loss -105.5002
[2019-03-23 10:07:08,240] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 68500, global step 1096391: learning rate 0.0005
[2019-03-23 10:07:08,275] A3C_AGENT_WORKER-Thread-12 INFO:Local step 68500, global step 1096408: loss -213.1228
[2019-03-23 10:07:08,277] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 68500, global step 1096408: learning rate 0.0005
[2019-03-23 10:07:08,292] A3C_AGENT_WORKER-Thread-3 INFO:Local step 68500, global step 1096414: loss -78.9302
[2019-03-23 10:07:08,293] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 68500, global step 1096414: learning rate 0.0005
[2019-03-23 10:07:08,390] A3C_AGENT_WORKER-Thread-10 INFO:Local step 68500, global step 1096471: loss -70.3326
[2019-03-23 10:07:08,392] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 68500, global step 1096471: learning rate 0.0005
[2019-03-23 10:07:08,418] A3C_AGENT_WORKER-Thread-14 INFO:Local step 68500, global step 1096481: loss 21.7432
[2019-03-23 10:07:08,419] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 68500, global step 1096481: learning rate 0.0005
[2019-03-23 10:07:08,492] A3C_AGENT_WORKER-Thread-20 INFO:Local step 68500, global step 1096520: loss -86.4132
[2019-03-23 10:07:08,498] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 68500, global step 1096521: learning rate 0.0005
[2019-03-23 10:07:08,563] A3C_AGENT_WORKER-Thread-22 INFO:Local step 68500, global step 1096561: loss 29.3544
[2019-03-23 10:07:08,565] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 68500, global step 1096561: learning rate 0.0005
[2019-03-23 10:07:08,789] A3C_AGENT_WORKER-Thread-19 INFO:Local step 68500, global step 1096680: loss -117.5712
[2019-03-23 10:07:08,793] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 68500, global step 1096681: learning rate 0.0005
[2019-03-23 10:07:09,044] A3C_AGENT_WORKER-Thread-11 INFO:Local step 68500, global step 1096813: loss -112.6280
[2019-03-23 10:07:09,046] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 68500, global step 1096813: learning rate 0.0005
[2019-03-23 10:07:09,199] A3C_AGENT_WORKER-Thread-18 INFO:Local step 68500, global step 1096896: loss -156.8632
[2019-03-23 10:07:09,201] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 68500, global step 1096896: learning rate 0.0005
[2019-03-23 10:07:12,933] A3C_AGENT_WORKER-Thread-9 INFO:Local step 69000, global step 1098883: loss 0.0416
[2019-03-23 10:07:12,934] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 69000, global step 1098883: learning rate 0.0005
[2019-03-23 10:07:14,573] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.0079158e-27 1.0000000e+00 0.0000000e+00 7.1637153e-22 0.0000000e+00], sum to 1.0000
[2019-03-23 10:07:14,592] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8568
[2019-03-23 10:07:14,597] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.91666666666667, 67.16666666666666, 1.0, 2.0, 0.4458920869386437, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 484705.3270421228, 484705.3270421231, 122316.9655155373], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1687800.0000, 
sim time next is 1688400.0000, 
raw observation next is [20.1, 66.0, 1.0, 2.0, 0.4489745472747571, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 488190.2820966896, 488190.2820966899, 122617.3074822302], 
processed observation next is [1.0, 0.5652173913043478, 0.55, 0.66, 1.0, 1.0, 0.31121818409344637, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18081121559136654, 0.18081121559136665, 0.2990666036151956], 
reward next is 0.7009, 
noisyNet noise sample is [array([0.527557], dtype=float32), 1.5034894]. 
=============================================
[2019-03-23 10:07:15,044] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-23 10:07:15,046] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 10:07:15,048] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 10:07:15,049] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:07:15,049] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:07:15,050] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 10:07:15,052] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:07:15,051] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 10:07:15,053] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 10:07:15,057] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:07:15,058] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:07:15,072] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run45
[2019-03-23 10:07:15,096] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run45
[2019-03-23 10:07:15,134] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run45
[2019-03-23 10:07:15,134] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run45
[2019-03-23 10:07:15,168] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run45
[2019-03-23 10:07:24,298] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.04205054], dtype=float32), -1.151352]
[2019-03-23 10:07:24,300] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.65, 44.0, 1.0, 2.0, 0.3749243067629506, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 407113.9680770574, 407113.9680770571, 108409.2475498419]
[2019-03-23 10:07:24,300] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 10:07:24,302] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.5923570e-27 1.0000000e+00 0.0000000e+00 1.8278912e-26 0.0000000e+00], sampled 0.22881960074406404
[2019-03-23 10:07:42,019] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.04205054], dtype=float32), -1.151352]
[2019-03-23 10:07:42,020] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.35, 46.33333333333333, 1.0, 2.0, 0.3005253967519842, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 326305.5006238171, 326305.5006238167, 90332.15564250715]
[2019-03-23 10:07:42,020] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 10:07:42,023] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.5704590e-27 1.0000000e+00 0.0000000e+00 1.8035725e-26 0.0000000e+00], sampled 0.5620987218911639
[2019-03-23 10:08:17,670] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.04205054], dtype=float32), -1.151352]
[2019-03-23 10:08:17,672] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.3, 65.0, 1.0, 2.0, 0.3175899723398709, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 350466.2891714875, 350466.2891714872, 118748.7926854877]
[2019-03-23 10:08:17,673] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 10:08:17,678] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.6027475e-27 1.0000000e+00 0.0000000e+00 1.8393974e-26 0.0000000e+00], sampled 0.6180095508652838
[2019-03-23 10:08:44,471] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.04205054], dtype=float32), -1.151352]
[2019-03-23 10:08:44,472] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.5, 86.0, 1.0, 2.0, 0.4976500712830422, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 567810.8495262727, 567810.8495262727, 145036.7049851094]
[2019-03-23 10:08:44,473] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 10:08:44,477] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.5532525e-27 1.0000000e+00 0.0000000e+00 1.7845742e-26 0.0000000e+00], sampled 0.45575847054180607
[2019-03-23 10:08:54,830] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 10:08:54,876] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 10:08:54,956] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 10:08:55,146] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 10:08:55,160] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 10:08:56,176] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 1100000, evaluation results [1100000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 10:08:56,259] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.9743162e-25 1.0000000e+00 2.9051435e-37 4.5557502e-18 1.9071384e-36], sum to 1.0000
[2019-03-23 10:08:56,268] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1962
[2019-03-23 10:08:56,277] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4765984820293427, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 543768.5033822703, 543768.5033822703, 138811.1484243009], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1492800.0000, 
sim time next is 1493400.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.4765180593572917, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 543676.6504687758, 543676.6504687758, 138802.2671335917], 
processed observation next is [0.0, 0.2608695652173913, 0.5909090909090909, 1.0, 1.0, 1.0, 0.34564757419661457, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20136172239584288, 0.20136172239584288, 0.33854211495997977], 
reward next is 0.6615, 
noisyNet noise sample is [array([-0.08589312], dtype=float32), -1.7374573]. 
=============================================
[2019-03-23 10:08:59,679] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.3824916e-29 1.0000000e+00 0.0000000e+00 1.5381680e-29 0.0000000e+00], sum to 1.0000
[2019-03-23 10:08:59,686] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0522
[2019-03-23 10:08:59,690] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 88.0, 1.0, 2.0, 0.4299925501624713, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 489298.0302683457, 489298.0302683457, 130793.2300743123], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1551600.0000, 
sim time next is 1552200.0000, 
raw observation next is [20.83333333333333, 89.00000000000001, 1.0, 2.0, 0.4263842959443394, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 485042.3021190444, 485042.3021190444, 130290.827284428], 
processed observation next is [0.0, 1.0, 0.5833333333333331, 0.8900000000000001, 1.0, 1.0, 0.28298036993042425, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17964529708112756, 0.17964529708112756, 0.3177825055717756], 
reward next is 0.6822, 
noisyNet noise sample is [array([1.9997079], dtype=float32), 1.0988204]. 
=============================================
[2019-03-23 10:09:00,175] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.758517e-28 1.000000e+00 0.000000e+00 1.508136e-28 0.000000e+00], sum to 1.0000
[2019-03-23 10:09:00,182] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7909
[2019-03-23 10:09:00,187] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.33333333333334, 47.0, 1.0, 2.0, 0.3481940090577254, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 378107.6064939222, 378107.6064939222, 84455.7626070683], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1772400.0000, 
sim time next is 1773000.0000, 
raw observation next is [17.5, 46.5, 1.0, 2.0, 0.3146512884248362, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 341670.4100276342, 341670.4100276345, 81136.03194166592], 
processed observation next is [1.0, 0.5217391304347826, 0.4318181818181818, 0.465, 1.0, 1.0, 0.14331411053104523, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12654459630653117, 0.1265445963065313, 0.19789276083333152], 
reward next is 0.8021, 
noisyNet noise sample is [array([0.05158434], dtype=float32), -0.54044086]. 
=============================================
[2019-03-23 10:09:00,204] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[72.44706]
 [72.3688 ]
 [72.39842]
 [72.37576]
 [72.36449]], R is [[72.60455322]
 [72.6725235 ]
 [72.72498322]
 [72.78671265]
 [72.84817505]].
[2019-03-23 10:09:00,330] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0062307e-28 1.0000000e+00 0.0000000e+00 1.1755493e-30 0.0000000e+00], sum to 1.0000
[2019-03-23 10:09:00,339] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5857
[2019-03-23 10:09:00,346] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333333, 92.0, 1.0, 2.0, 0.4165012491460964, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 473455.3239697435, 473455.3239697432, 129009.8827993868], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1561200.0000, 
sim time next is 1561800.0000, 
raw observation next is [20.16666666666667, 93.0, 1.0, 2.0, 0.4147860820772069, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 471380.1023011341, 471380.1023011344, 128736.9658541422], 
processed observation next is [1.0, 0.043478260869565216, 0.5530303030303032, 0.93, 1.0, 1.0, 0.2684826025965086, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17458522307449412, 0.17458522307449423, 0.31399259964424925], 
reward next is 0.6860, 
noisyNet noise sample is [array([1.3712546], dtype=float32), 1.0043898]. 
=============================================
[2019-03-23 10:09:00,833] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.3930148e-28 1.0000000e+00 0.0000000e+00 2.0029550e-27 0.0000000e+00], sum to 1.0000
[2019-03-23 10:09:00,841] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3511
[2019-03-23 10:09:00,848] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.83333333333334, 95.0, 1.0, 2.0, 0.5099828593899987, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 579380.6536630861, 579380.6536630865, 138402.8237227538], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1563000.0000, 
sim time next is 1563600.0000, 
raw observation next is [19.66666666666667, 96.0, 1.0, 2.0, 0.4459215454587965, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 506410.3185480995, 506410.3185480995, 131528.2622077425], 
processed observation next is [1.0, 0.08695652173913043, 0.5303030303030305, 0.96, 1.0, 1.0, 0.30740193182349557, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18755937724003685, 0.18755937724003685, 0.32080063953107923], 
reward next is 0.6792, 
noisyNet noise sample is [array([-1.1749246], dtype=float32), -0.35812458]. 
=============================================
[2019-03-23 10:09:01,286] A3C_AGENT_WORKER-Thread-13 INFO:Local step 69000, global step 1102590: loss 0.0452
[2019-03-23 10:09:01,289] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 69000, global step 1102591: learning rate 0.0005
[2019-03-23 10:09:02,659] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.8887941e-17 1.0000000e+00 2.4379798e-24 3.8439350e-15 3.9587718e-24], sum to 1.0000
[2019-03-23 10:09:02,668] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2042
[2019-03-23 10:09:02,676] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1193501.65689629 W.
[2019-03-23 10:09:02,680] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.0, 62.0, 1.0, 2.0, 0.3511494316424325, 1.0, 1.0, 0.3511494316424325, 1.0, 2.0, 0.7110529382316795, 6.9112, 6.9112, 77.3421103, 1193501.65689629, 1193501.65689629, 281557.3167013858], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1610400.0000, 
sim time next is 1611000.0000, 
raw observation next is [27.0, 62.0, 1.0, 2.0, 0.5488059359916994, 1.0, 2.0, 0.5488059359916994, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846340010937, 1243359.387215502, 1243359.387215502, 245580.4531170698], 
processed observation next is [1.0, 0.6521739130434783, 0.8636363636363636, 0.62, 1.0, 1.0, 0.43600741998962417, 1.0, 1.0, 0.43600741998962417, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288126350942, 0.46050347674648223, 0.46050347674648223, 0.5989767149196824], 
reward next is 0.4010, 
noisyNet noise sample is [array([0.58928955], dtype=float32), 0.00028322794]. 
=============================================
[2019-03-23 10:09:02,696] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[41.340183]
 [41.60632 ]
 [40.726616]
 [40.39391 ]
 [40.619984]], R is [[42.01575851]
 [41.90887451]
 [41.77994537]
 [41.36214447]
 [41.30671692]].
[2019-03-23 10:09:04,252] A3C_AGENT_WORKER-Thread-16 INFO:Local step 69000, global step 1104087: loss 0.0045
[2019-03-23 10:09:04,254] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 69000, global step 1104089: learning rate 0.0005
[2019-03-23 10:09:04,298] A3C_AGENT_WORKER-Thread-2 INFO:Local step 69000, global step 1104114: loss 0.0123
[2019-03-23 10:09:04,300] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 69000, global step 1104114: learning rate 0.0005
[2019-03-23 10:09:04,678] A3C_AGENT_WORKER-Thread-21 INFO:Local step 69000, global step 1104298: loss 0.0037
[2019-03-23 10:09:04,679] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 69000, global step 1104298: learning rate 0.0005
[2019-03-23 10:09:04,800] A3C_AGENT_WORKER-Thread-10 INFO:Local step 69000, global step 1104359: loss 0.0050
[2019-03-23 10:09:04,803] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 69000, global step 1104359: learning rate 0.0005
[2019-03-23 10:09:04,824] A3C_AGENT_WORKER-Thread-3 INFO:Local step 69000, global step 1104371: loss 0.0050
[2019-03-23 10:09:04,827] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 69000, global step 1104371: learning rate 0.0005
[2019-03-23 10:09:04,833] A3C_AGENT_WORKER-Thread-17 INFO:Local step 69000, global step 1104372: loss 0.0178
[2019-03-23 10:09:04,835] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 69000, global step 1104373: learning rate 0.0005
[2019-03-23 10:09:04,851] A3C_AGENT_WORKER-Thread-12 INFO:Local step 69000, global step 1104380: loss 0.0086
[2019-03-23 10:09:04,852] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 69000, global step 1104380: learning rate 0.0005
[2019-03-23 10:09:04,886] A3C_AGENT_WORKER-Thread-15 INFO:Local step 69000, global step 1104397: loss 0.0148
[2019-03-23 10:09:04,887] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 69000, global step 1104397: learning rate 0.0005
[2019-03-23 10:09:05,076] A3C_AGENT_WORKER-Thread-20 INFO:Local step 69000, global step 1104495: loss 0.0028
[2019-03-23 10:09:05,082] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 69000, global step 1104497: learning rate 0.0005
[2019-03-23 10:09:05,097] A3C_AGENT_WORKER-Thread-14 INFO:Local step 69000, global step 1104505: loss 0.0021
[2019-03-23 10:09:05,099] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 69000, global step 1104508: learning rate 0.0005
[2019-03-23 10:09:05,349] A3C_AGENT_WORKER-Thread-22 INFO:Local step 69000, global step 1104629: loss 0.0008
[2019-03-23 10:09:05,351] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 69000, global step 1104630: learning rate 0.0005
[2019-03-23 10:09:05,474] A3C_AGENT_WORKER-Thread-19 INFO:Local step 69000, global step 1104694: loss 0.0004
[2019-03-23 10:09:05,475] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 69000, global step 1104694: learning rate 0.0005
[2019-03-23 10:09:05,639] A3C_AGENT_WORKER-Thread-11 INFO:Local step 69000, global step 1104775: loss 0.0018
[2019-03-23 10:09:05,641] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 69000, global step 1104776: learning rate 0.0005
[2019-03-23 10:09:05,783] A3C_AGENT_WORKER-Thread-18 INFO:Local step 69000, global step 1104848: loss 0.0025
[2019-03-23 10:09:05,787] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 69000, global step 1104849: learning rate 0.0005
[2019-03-23 10:09:08,606] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.1716955e-30 1.0000000e+00 0.0000000e+00 2.2459785e-26 0.0000000e+00], sum to 1.0000
[2019-03-23 10:09:08,617] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3227
[2019-03-23 10:09:08,620] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.66666666666667, 50.0, 1.0, 2.0, 0.2517339530356603, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 273331.1606441266, 273331.1606441269, 75881.696431994], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1707600.0000, 
sim time next is 1708200.0000, 
raw observation next is [17.5, 50.5, 1.0, 2.0, 0.2489060489384469, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 270259.7868428361, 270259.7868428361, 75466.98465493109], 
processed observation next is [1.0, 0.782608695652174, 0.4318181818181818, 0.505, 1.0, 1.0, 0.061132561173058604, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10009621734919856, 0.10009621734919856, 0.18406581623153925], 
reward next is 0.8159, 
noisyNet noise sample is [array([1.3243831], dtype=float32), 2.4673343]. 
=============================================
[2019-03-23 10:09:10,052] A3C_AGENT_WORKER-Thread-9 INFO:Local step 69500, global step 1106980: loss -105.4642
[2019-03-23 10:09:10,053] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 69500, global step 1106980: learning rate 0.0005
[2019-03-23 10:09:17,323] A3C_AGENT_WORKER-Thread-13 INFO:Local step 69500, global step 1110663: loss -171.5541
[2019-03-23 10:09:17,323] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 69500, global step 1110663: learning rate 0.0005
[2019-03-23 10:09:20,198] A3C_AGENT_WORKER-Thread-16 INFO:Local step 69500, global step 1112130: loss -77.6496
[2019-03-23 10:09:20,200] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 69500, global step 1112131: learning rate 0.0005
[2019-03-23 10:09:20,267] A3C_AGENT_WORKER-Thread-2 INFO:Local step 69500, global step 1112161: loss -184.4812
[2019-03-23 10:09:20,269] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 69500, global step 1112163: learning rate 0.0005
[2019-03-23 10:09:20,528] A3C_AGENT_WORKER-Thread-21 INFO:Local step 69500, global step 1112297: loss 6.5139
[2019-03-23 10:09:20,529] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 69500, global step 1112297: learning rate 0.0005
[2019-03-23 10:09:20,611] A3C_AGENT_WORKER-Thread-12 INFO:Local step 69500, global step 1112336: loss -178.5451
[2019-03-23 10:09:20,613] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 69500, global step 1112336: learning rate 0.0005
[2019-03-23 10:09:20,630] A3C_AGENT_WORKER-Thread-10 INFO:Local step 69500, global step 1112344: loss 74.2616
[2019-03-23 10:09:20,631] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 69500, global step 1112344: learning rate 0.0005
[2019-03-23 10:09:20,713] A3C_AGENT_WORKER-Thread-3 INFO:Local step 69500, global step 1112386: loss -139.1436
[2019-03-23 10:09:20,717] A3C_AGENT_WORKER-Thread-17 INFO:Local step 69500, global step 1112387: loss -23.0712
[2019-03-23 10:09:20,720] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 69500, global step 1112387: learning rate 0.0005
[2019-03-23 10:09:20,721] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 69500, global step 1112387: learning rate 0.0005
[2019-03-23 10:09:20,780] A3C_AGENT_WORKER-Thread-15 INFO:Local step 69500, global step 1112418: loss -25.3533
[2019-03-23 10:09:20,782] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 69500, global step 1112420: learning rate 0.0005
[2019-03-23 10:09:20,871] A3C_AGENT_WORKER-Thread-20 INFO:Local step 69500, global step 1112465: loss -92.7911
[2019-03-23 10:09:20,873] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 69500, global step 1112465: learning rate 0.0005
[2019-03-23 10:09:20,988] A3C_AGENT_WORKER-Thread-14 INFO:Local step 69500, global step 1112524: loss -59.6527
[2019-03-23 10:09:20,989] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 69500, global step 1112524: learning rate 0.0005
[2019-03-23 10:09:21,229] A3C_AGENT_WORKER-Thread-19 INFO:Local step 69500, global step 1112647: loss 0.5223
[2019-03-23 10:09:21,230] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 69500, global step 1112647: learning rate 0.0005
[2019-03-23 10:09:21,321] A3C_AGENT_WORKER-Thread-22 INFO:Local step 69500, global step 1112693: loss -78.1977
[2019-03-23 10:09:21,325] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 69500, global step 1112694: learning rate 0.0005
[2019-03-23 10:09:21,336] A3C_AGENT_WORKER-Thread-11 INFO:Local step 69500, global step 1112698: loss -20.1399
[2019-03-23 10:09:21,338] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 69500, global step 1112699: learning rate 0.0005
[2019-03-23 10:09:21,588] A3C_AGENT_WORKER-Thread-18 INFO:Local step 69500, global step 1112826: loss 7.6150
[2019-03-23 10:09:21,593] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 69500, global step 1112826: learning rate 0.0005
[2019-03-23 10:09:23,817] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.4718962e-31 1.0000000e+00 0.0000000e+00 2.0809488e-27 0.0000000e+00], sum to 1.0000
[2019-03-23 10:09:23,827] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7212
[2019-03-23 10:09:23,832] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.33333333333334, 72.33333333333334, 1.0, 2.0, 0.2432332257318237, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 264098.6177918887, 264098.6177918889, 84198.06651399643], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2013600.0000, 
sim time next is 2014200.0000, 
raw observation next is [17.5, 72.5, 1.0, 2.0, 0.2490714870810189, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 270439.4679242345, 270439.4679242348, 86110.7577729502], 
processed observation next is [0.0, 0.30434782608695654, 0.4318181818181818, 0.725, 1.0, 1.0, 0.061339358851273604, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10016276589786463, 0.10016276589786474, 0.21002623847061022], 
reward next is 0.7900, 
noisyNet noise sample is [array([0.07894581], dtype=float32), -1.5010395]. 
=============================================
[2019-03-23 10:09:25,647] A3C_AGENT_WORKER-Thread-9 INFO:Local step 70000, global step 1114875: loss 0.1161
[2019-03-23 10:09:25,649] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 70000, global step 1114875: learning rate 0.0005
[2019-03-23 10:09:27,352] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.23056135e-29 1.00000000e+00 0.00000000e+00 1.20995359e-23
 0.00000000e+00], sum to 1.0000
[2019-03-23 10:09:27,358] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2104
[2019-03-23 10:09:27,362] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 62.0, 1.0, 2.0, 0.2644885912613343, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 287184.1563457995, 287184.1563457995, 88203.91022268523], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2068200.0000, 
sim time next is 2068800.0000, 
raw observation next is [19.0, 61.33333333333334, 1.0, 2.0, 0.2640895725558325, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 286750.7704217014, 286750.7704217017, 87476.38076381951], 
processed observation next is [0.0, 0.9565217391304348, 0.5, 0.6133333333333334, 1.0, 1.0, 0.0801119656947906, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1062039890450746, 0.1062039890450747, 0.21335702625321834], 
reward next is 0.7866, 
noisyNet noise sample is [array([0.18223935], dtype=float32), -0.1476437]. 
=============================================
[2019-03-23 10:09:29,688] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.8697169e-29 1.0000000e+00 0.0000000e+00 1.1137474e-31 0.0000000e+00], sum to 1.0000
[2019-03-23 10:09:29,696] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0564
[2019-03-23 10:09:29,703] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.33333333333334, 80.33333333333334, 1.0, 2.0, 0.3314305745561528, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 359897.2767207163, 359897.2767207163, 93196.49994033045], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2190000.0000, 
sim time next is 2190600.0000, 
raw observation next is [16.5, 79.5, 1.0, 2.0, 0.4021192355134698, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 436691.8844410813, 436691.884441081, 101304.149529934], 
processed observation next is [1.0, 0.34782608695652173, 0.38636363636363635, 0.795, 1.0, 1.0, 0.2526490443918372, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16173773497817825, 0.16173773497817817, 0.2470832915364244], 
reward next is 0.7529, 
noisyNet noise sample is [array([0.12049615], dtype=float32), 0.7477907]. 
=============================================
[2019-03-23 10:09:33,003] A3C_AGENT_WORKER-Thread-13 INFO:Local step 70000, global step 1118680: loss 0.0451
[2019-03-23 10:09:33,004] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 70000, global step 1118680: learning rate 0.0005
[2019-03-23 10:09:35,578] A3C_AGENT_WORKER-Thread-16 INFO:Local step 70000, global step 1120048: loss 0.0684
[2019-03-23 10:09:35,581] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 70000, global step 1120049: learning rate 0.0005
[2019-03-23 10:09:35,655] A3C_AGENT_WORKER-Thread-2 INFO:Local step 70000, global step 1120084: loss 0.0992
[2019-03-23 10:09:35,656] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 70000, global step 1120085: learning rate 0.0005
[2019-03-23 10:09:35,917] A3C_AGENT_WORKER-Thread-21 INFO:Local step 70000, global step 1120226: loss 0.0687
[2019-03-23 10:09:35,923] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 70000, global step 1120226: learning rate 0.0005
[2019-03-23 10:09:36,045] A3C_AGENT_WORKER-Thread-12 INFO:Local step 70000, global step 1120290: loss 0.0615
[2019-03-23 10:09:36,047] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 70000, global step 1120290: learning rate 0.0005
[2019-03-23 10:09:36,065] A3C_AGENT_WORKER-Thread-17 INFO:Local step 70000, global step 1120300: loss 0.0706
[2019-03-23 10:09:36,066] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 70000, global step 1120301: learning rate 0.0005
[2019-03-23 10:09:36,225] A3C_AGENT_WORKER-Thread-10 INFO:Local step 70000, global step 1120385: loss 0.0584
[2019-03-23 10:09:36,227] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 70000, global step 1120386: learning rate 0.0005
[2019-03-23 10:09:36,229] A3C_AGENT_WORKER-Thread-15 INFO:Local step 70000, global step 1120386: loss 0.0622
[2019-03-23 10:09:36,233] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 70000, global step 1120387: learning rate 0.0005
[2019-03-23 10:09:36,302] A3C_AGENT_WORKER-Thread-20 INFO:Local step 70000, global step 1120422: loss 0.0663
[2019-03-23 10:09:36,304] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 70000, global step 1120422: learning rate 0.0005
[2019-03-23 10:09:36,323] A3C_AGENT_WORKER-Thread-3 INFO:Local step 70000, global step 1120432: loss 0.0553
[2019-03-23 10:09:36,326] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 70000, global step 1120432: learning rate 0.0005
[2019-03-23 10:09:36,400] A3C_AGENT_WORKER-Thread-14 INFO:Local step 70000, global step 1120475: loss 0.0267
[2019-03-23 10:09:36,402] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 70000, global step 1120475: learning rate 0.0005
[2019-03-23 10:09:36,795] A3C_AGENT_WORKER-Thread-11 INFO:Local step 70000, global step 1120691: loss 0.0781
[2019-03-23 10:09:36,797] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 70000, global step 1120691: learning rate 0.0005
[2019-03-23 10:09:36,876] A3C_AGENT_WORKER-Thread-22 INFO:Local step 70000, global step 1120730: loss 0.0901
[2019-03-23 10:09:36,878] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 70000, global step 1120730: learning rate 0.0005
[2019-03-23 10:09:36,893] A3C_AGENT_WORKER-Thread-19 INFO:Local step 70000, global step 1120739: loss 0.0885
[2019-03-23 10:09:36,895] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 70000, global step 1120740: learning rate 0.0005
[2019-03-23 10:09:37,272] A3C_AGENT_WORKER-Thread-18 INFO:Local step 70000, global step 1120938: loss 0.1053
[2019-03-23 10:09:37,274] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 70000, global step 1120938: learning rate 0.0005
[2019-03-23 10:09:38,538] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.5872889e-31 1.0000000e+00 0.0000000e+00 4.3002104e-30 0.0000000e+00], sum to 1.0000
[2019-03-23 10:09:38,547] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0288
[2019-03-23 10:09:38,551] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 51.0, 1.0, 2.0, 0.5130285871090096, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 557205.8184282902, 557205.8184282904, 110966.5127910866], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2302200.0000, 
sim time next is 2302800.0000, 
raw observation next is [20.0, 50.33333333333333, 1.0, 2.0, 0.5228840051378889, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 567916.1463327453, 567916.1463327456, 111550.416167501], 
processed observation next is [1.0, 0.6521739130434783, 0.5454545454545454, 0.5033333333333333, 1.0, 1.0, 0.4036050064223611, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21033931345657234, 0.21033931345657242, 0.2720741857743927], 
reward next is 0.7279, 
noisyNet noise sample is [array([0.11614124], dtype=float32), -0.57372606]. 
=============================================
[2019-03-23 10:09:40,829] A3C_AGENT_WORKER-Thread-9 INFO:Local step 70500, global step 1122848: loss 0.1604
[2019-03-23 10:09:40,832] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 70500, global step 1122848: learning rate 0.0005
[2019-03-23 10:09:42,141] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.0950880e-25 1.0000000e+00 2.1038549e-36 1.5866674e-22 4.1817813e-36], sum to 1.0000
[2019-03-23 10:09:42,151] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0963
[2019-03-23 10:09:42,158] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 49.0, 1.0, 2.0, 0.4667003388226684, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 506861.9803661583, 506861.9803661583, 104115.627542079], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2372400.0000, 
sim time next is 2373000.0000, 
raw observation next is [20.0, 49.0, 1.0, 2.0, 0.4775696281607517, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 518672.9180760542, 518672.9180760542, 105329.8919374796], 
processed observation next is [1.0, 0.4782608695652174, 0.5454545454545454, 0.49, 1.0, 1.0, 0.3469620352009396, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19210108076890897, 0.19210108076890897, 0.2569021754572673], 
reward next is 0.7431, 
noisyNet noise sample is [array([-1.145261], dtype=float32), -0.5121488]. 
=============================================
[2019-03-23 10:09:42,180] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[62.78769 ]
 [62.670723]
 [62.568333]
 [62.517277]
 [62.50767 ]], R is [[63.00806808]
 [63.12404633]
 [63.24131393]
 [63.35653687]
 [63.46886063]].
[2019-03-23 10:09:44,868] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-23 10:09:44,869] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 10:09:44,870] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 10:09:44,871] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 10:09:44,872] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 10:09:44,873] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:09:44,871] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:09:44,874] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:09:44,874] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:09:44,873] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 10:09:44,879] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:09:44,892] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run46
[2019-03-23 10:09:44,914] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run46
[2019-03-23 10:09:44,941] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run46
[2019-03-23 10:09:44,966] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run46
[2019-03-23 10:09:44,966] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run46
[2019-03-23 10:09:50,166] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05607907], dtype=float32), -1.1137753]
[2019-03-23 10:09:50,168] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [11.72075866666667, 70.82731225, 1.0, 2.0, 0.423158292809701, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 459509.1780818999, 459509.1780818995, 92609.8428441525]
[2019-03-23 10:09:50,169] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 10:09:50,172] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [7.8231515e-29 1.0000000e+00 0.0000000e+00 2.4854932e-26 0.0000000e+00], sampled 0.20579068545328438
[2019-03-23 10:10:07,229] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05607907], dtype=float32), -1.1137753]
[2019-03-23 10:10:07,230] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.77646888, 94.16816386, 1.0, 2.0, 0.4558266163803923, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 511677.5897461965, 511677.5897461965, 133442.5614774244]
[2019-03-23 10:10:07,232] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 10:10:07,234] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [9.9792794e-29 1.0000000e+00 0.0000000e+00 3.4521875e-26 0.0000000e+00], sampled 0.9916175396453252
[2019-03-23 10:10:14,022] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05607907], dtype=float32), -1.1137753]
[2019-03-23 10:10:14,023] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [13.52409298666667, 97.07276516666667, 1.0, 2.0, 0.2117991775106749, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 229949.6118744037, 229949.6118744041, 80163.30630450533]
[2019-03-23 10:10:14,024] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 10:10:14,025] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.5341290e-29 1.0000000e+00 0.0000000e+00 1.6196627e-26 0.0000000e+00], sampled 0.15581167215856495
[2019-03-23 10:10:14,689] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05607907], dtype=float32), -1.1137753]
[2019-03-23 10:10:14,691] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.9, 72.0, 1.0, 2.0, 0.49731318368585, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 567266.1491282447, 567266.1491282443, 145733.3388876191]
[2019-03-23 10:10:14,691] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 10:10:14,696] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [7.0082650e-30 1.0000000e+00 0.0000000e+00 1.9717817e-27 0.0000000e+00], sampled 0.8905367837434989
[2019-03-23 10:10:28,918] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05607907], dtype=float32), -1.1137753]
[2019-03-23 10:10:28,920] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.46513905, 88.29725228666666, 1.0, 2.0, 0.57401662880072, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 648736.8483827064, 648736.848382706, 158733.2233744541]
[2019-03-23 10:10:28,921] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 10:10:28,925] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [8.3869988e-29 1.0000000e+00 0.0000000e+00 2.7295512e-26 0.0000000e+00], sampled 0.1729665203306252
[2019-03-23 10:10:33,693] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05607907], dtype=float32), -1.1137753]
[2019-03-23 10:10:33,695] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.53333333333333, 85.66666666666667, 1.0, 2.0, 0.366576199283602, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 410926.7844450901, 410926.7844450898, 125136.9788026505]
[2019-03-23 10:10:33,696] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 10:10:33,699] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.8290394e-29 1.0000000e+00 0.0000000e+00 1.7248456e-26 0.0000000e+00], sampled 0.49773221213490526
[2019-03-23 10:10:49,112] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05607907], dtype=float32), -1.1137753]
[2019-03-23 10:10:49,113] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [23.33029487, 91.641171875, 1.0, 2.0, 0.7892950670228636, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 897352.1195377811, 897352.1195377811, 189053.4980272193]
[2019-03-23 10:10:49,114] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 10:10:49,122] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.9241804e-28 1.0000000e+00 0.0000000e+00 8.8715371e-26 0.0000000e+00], sampled 0.8652897731812271
[2019-03-23 10:10:51,250] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05607907], dtype=float32), -1.1137753]
[2019-03-23 10:10:51,251] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.4, 93.0, 1.0, 2.0, 0.4011768618370395, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 453295.7035078321, 453295.7035078324, 125634.2256420175]
[2019-03-23 10:10:51,254] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:10:51,256] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.1335425e-29 1.0000000e+00 0.0000000e+00 3.1789076e-27 0.0000000e+00], sampled 0.6203328509160659
[2019-03-23 10:10:52,837] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05607907], dtype=float32), -1.1137753]
[2019-03-23 10:10:52,841] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.0, 93.0, 1.0, 2.0, 0.4207316437082938, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 477614.1585766813, 477614.1585766813, 128899.1751771813]
[2019-03-23 10:10:52,842] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:10:52,845] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [8.935887e-29 1.000000e+00 0.000000e+00 2.973475e-26 0.000000e+00], sampled 0.13710455022840273
[2019-03-23 10:11:01,131] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05607907], dtype=float32), -1.1137753]
[2019-03-23 10:11:01,132] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [15.893226605, 86.59672515833334, 1.0, 2.0, 0.2525184654924736, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 274168.4803201051, 274168.4803201051, 91692.26228926299]
[2019-03-23 10:11:01,133] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 10:11:01,138] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.8307214e-29 1.0000000e+00 0.0000000e+00 5.1230430e-27 0.0000000e+00], sampled 0.2944995002884825
[2019-03-23 10:11:13,486] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05607907], dtype=float32), -1.1137753]
[2019-03-23 10:11:13,489] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [14.52337031, 89.69863439, 1.0, 2.0, 0.2525084470575178, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 274157.6004601846, 274157.6004601843, 85800.31616603851]
[2019-03-23 10:11:13,490] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 10:11:13,492] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [7.7183606e-30 1.0000000e+00 0.0000000e+00 2.1559181e-27 0.0000000e+00], sampled 0.7982175177535754
[2019-03-23 10:11:17,851] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05607907], dtype=float32), -1.1137753]
[2019-03-23 10:11:17,852] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.95, 44.83333333333334, 1.0, 2.0, 0.2919221958196861, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 316961.8242197639, 316961.8242197643, 96002.285849925]
[2019-03-23 10:11:17,852] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 10:11:17,856] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [7.1504716e-30 1.0000000e+00 0.0000000e+00 2.0085327e-27 0.0000000e+00], sampled 0.5588476151826998
[2019-03-23 10:11:24,158] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 10:11:24,732] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 10:11:24,805] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 10:11:24,829] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 10:11:24,987] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 10:11:26,003] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1125000, evaluation results [1125000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 10:11:28,231] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.4227489e-27 1.0000000e+00 0.0000000e+00 7.9058746e-26 3.5782981e-37], sum to 1.0000
[2019-03-23 10:11:28,239] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8687
[2019-03-23 10:11:28,242] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.66666666666667, 78.66666666666666, 1.0, 2.0, 0.4725365177796893, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 513203.7342950111, 513203.7342950111, 119515.8381264249], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2464800.0000, 
sim time next is 2465400.0000, 
raw observation next is [17.83333333333333, 77.83333333333334, 1.0, 2.0, 0.4291229649206205, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 466031.3447116601, 466031.3447116601, 115646.5139881578], 
processed observation next is [1.0, 0.5217391304347826, 0.44696969696969674, 0.7783333333333334, 1.0, 1.0, 0.2864037061507756, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1726042017450593, 0.1726042017450593, 0.28206466826379956], 
reward next is 0.7179, 
noisyNet noise sample is [array([-1.5501153], dtype=float32), 1.1944987]. 
=============================================
[2019-03-23 10:11:29,273] A3C_AGENT_WORKER-Thread-13 INFO:Local step 70500, global step 1126679: loss 0.2328
[2019-03-23 10:11:29,281] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 70500, global step 1126681: learning rate 0.0005
[2019-03-23 10:11:30,062] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.0904559e-33 1.0000000e+00 0.0000000e+00 1.2861586e-29 0.0000000e+00], sum to 1.0000
[2019-03-23 10:11:30,073] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3322
[2019-03-23 10:11:30,081] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 95.0, 1.0, 2.0, 0.2042893737309218, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 221804.3852573591, 221804.3852573594, 72761.33354599858], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2499000.0000, 
sim time next is 2499600.0000, 
raw observation next is [13.0, 96.0, 1.0, 2.0, 0.2060379061125575, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 223703.266864894, 223703.2668648943, 73163.60176546552], 
processed observation next is [1.0, 0.9565217391304348, 0.22727272727272727, 0.96, 1.0, 1.0, 0.007547382640696876, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0828530618018126, 0.0828530618018127, 0.17844780918406222], 
reward next is 0.8216, 
noisyNet noise sample is [array([0.01888148], dtype=float32), 0.071945734]. 
=============================================
[2019-03-23 10:11:32,045] A3C_AGENT_WORKER-Thread-16 INFO:Local step 70500, global step 1128074: loss 0.3327
[2019-03-23 10:11:32,047] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 70500, global step 1128074: learning rate 0.0005
[2019-03-23 10:11:32,060] A3C_AGENT_WORKER-Thread-2 INFO:Local step 70500, global step 1128081: loss 0.3054
[2019-03-23 10:11:32,064] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 70500, global step 1128082: learning rate 0.0005
[2019-03-23 10:11:32,365] A3C_AGENT_WORKER-Thread-17 INFO:Local step 70500, global step 1128234: loss 0.2411
[2019-03-23 10:11:32,367] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 70500, global step 1128234: learning rate 0.0005
[2019-03-23 10:11:32,389] A3C_AGENT_WORKER-Thread-21 INFO:Local step 70500, global step 1128242: loss 0.2551
[2019-03-23 10:11:32,395] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 70500, global step 1128246: learning rate 0.0005
[2019-03-23 10:11:32,541] A3C_AGENT_WORKER-Thread-15 INFO:Local step 70500, global step 1128324: loss 0.2005
[2019-03-23 10:11:32,544] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 70500, global step 1128326: learning rate 0.0005
[2019-03-23 10:11:32,595] A3C_AGENT_WORKER-Thread-12 INFO:Local step 70500, global step 1128351: loss 0.1985
[2019-03-23 10:11:32,599] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 70500, global step 1128351: learning rate 0.0005
[2019-03-23 10:11:32,661] A3C_AGENT_WORKER-Thread-10 INFO:Local step 70500, global step 1128383: loss 0.1720
[2019-03-23 10:11:32,666] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 70500, global step 1128384: learning rate 0.0005
[2019-03-23 10:11:32,768] A3C_AGENT_WORKER-Thread-14 INFO:Local step 70500, global step 1128435: loss 0.1550
[2019-03-23 10:11:32,770] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 70500, global step 1128435: learning rate 0.0005
[2019-03-23 10:11:32,799] A3C_AGENT_WORKER-Thread-3 INFO:Local step 70500, global step 1128451: loss 0.2091
[2019-03-23 10:11:32,802] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 70500, global step 1128451: learning rate 0.0005
[2019-03-23 10:11:33,095] A3C_AGENT_WORKER-Thread-20 INFO:Local step 70500, global step 1128596: loss 0.1724
[2019-03-23 10:11:33,099] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 70500, global step 1128596: learning rate 0.0005
[2019-03-23 10:11:33,231] A3C_AGENT_WORKER-Thread-11 INFO:Local step 70500, global step 1128662: loss 0.1823
[2019-03-23 10:11:33,234] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 70500, global step 1128663: learning rate 0.0005
[2019-03-23 10:11:33,237] A3C_AGENT_WORKER-Thread-22 INFO:Local step 70500, global step 1128666: loss 0.2340
[2019-03-23 10:11:33,238] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 70500, global step 1128666: learning rate 0.0005
[2019-03-23 10:11:33,418] A3C_AGENT_WORKER-Thread-19 INFO:Local step 70500, global step 1128755: loss 0.1872
[2019-03-23 10:11:33,420] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 70500, global step 1128756: learning rate 0.0005
[2019-03-23 10:11:33,997] A3C_AGENT_WORKER-Thread-18 INFO:Local step 70500, global step 1129050: loss 0.3347
[2019-03-23 10:11:34,001] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 70500, global step 1129050: learning rate 0.0005
[2019-03-23 10:11:36,587] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.0273096e-27 1.0000000e+00 1.5728423e-38 4.1743117e-26 5.8278787e-38], sum to 1.0000
[2019-03-23 10:11:36,593] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5447
[2019-03-23 10:11:36,599] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.5, 88.5, 1.0, 2.0, 0.3338938955737646, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 370318.3907756082, 370318.3907756082, 116375.8580819256], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2619000.0000, 
sim time next is 2619600.0000, 
raw observation next is [19.0, 86.66666666666666, 1.0, 2.0, 0.3428297752092589, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 381828.784877916, 381828.784877916, 117731.3007562408], 
processed observation next is [0.0, 0.30434782608695654, 0.5, 0.8666666666666666, 1.0, 1.0, 0.1785372190115736, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1414180684733022, 0.1414180684733022, 0.2871495140396117], 
reward next is 0.7129, 
noisyNet noise sample is [array([0.20753202], dtype=float32), 1.1852583]. 
=============================================
[2019-03-23 10:11:37,856] A3C_AGENT_WORKER-Thread-9 INFO:Local step 71000, global step 1130989: loss 0.5711
[2019-03-23 10:11:37,858] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 71000, global step 1130990: learning rate 0.0005
[2019-03-23 10:11:42,390] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.4428987e-25 1.0000000e+00 3.2206112e-37 3.0355564e-20 3.2060629e-36], sum to 1.0000
[2019-03-23 10:11:42,400] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3380
[2019-03-23 10:11:42,404] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.66666666666667, 52.00000000000001, 1.0, 2.0, 0.4230729683726505, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 481165.9070706815, 481165.9070706818, 129862.643162159], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2740800.0000, 
sim time next is 2741400.0000, 
raw observation next is [26.5, 52.5, 1.0, 2.0, 0.4204319402320742, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 478022.4163276669, 478022.4163276669, 129478.174774643], 
processed observation next is [0.0, 0.7391304347826086, 0.8409090909090909, 0.525, 1.0, 1.0, 0.2755399252900927, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17704533938061737, 0.17704533938061737, 0.3158004262796171], 
reward next is 0.6842, 
noisyNet noise sample is [array([-1.6924983], dtype=float32), 0.6729253]. 
=============================================
[2019-03-23 10:11:44,474] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.8822342e-25 1.0000000e+00 1.6005774e-36 6.6405566e-23 8.8155590e-36], sum to 1.0000
[2019-03-23 10:11:44,481] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2496
[2019-03-23 10:11:44,486] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333333, 81.33333333333333, 1.0, 2.0, 0.3798900532086876, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 427161.1984018616, 427161.1984018616, 122579.0453969613], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2767200.0000, 
sim time next is 2767800.0000, 
raw observation next is [20.16666666666667, 82.16666666666667, 1.0, 2.0, 0.3775236999719042, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 424233.878948661, 424233.8789486613, 122240.3701069593], 
processed observation next is [1.0, 0.0, 0.5530303030303032, 0.8216666666666668, 1.0, 1.0, 0.22190462496488025, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15712365886987442, 0.15712365886987456, 0.29814724416331534], 
reward next is 0.7019, 
noisyNet noise sample is [array([-0.165142], dtype=float32), 1.8687232]. 
=============================================
[2019-03-23 10:11:45,380] A3C_AGENT_WORKER-Thread-13 INFO:Local step 71000, global step 1134735: loss 0.1775
[2019-03-23 10:11:45,381] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 71000, global step 1134735: learning rate 0.0005
[2019-03-23 10:11:47,819] A3C_AGENT_WORKER-Thread-16 INFO:Local step 71000, global step 1135973: loss 0.0550
[2019-03-23 10:11:47,823] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 71000, global step 1135973: learning rate 0.0005
[2019-03-23 10:11:47,860] A3C_AGENT_WORKER-Thread-2 INFO:Local step 71000, global step 1135993: loss 0.0253
[2019-03-23 10:11:47,864] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 71000, global step 1135996: learning rate 0.0005
[2019-03-23 10:11:48,243] A3C_AGENT_WORKER-Thread-21 INFO:Local step 71000, global step 1136178: loss 0.1454
[2019-03-23 10:11:48,247] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 71000, global step 1136179: learning rate 0.0005
[2019-03-23 10:11:48,390] A3C_AGENT_WORKER-Thread-15 INFO:Local step 71000, global step 1136253: loss 0.1243
[2019-03-23 10:11:48,391] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 71000, global step 1136253: learning rate 0.0005
[2019-03-23 10:11:48,414] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.6813816e-22 1.0000000e+00 8.5844325e-33 8.5987373e-22 8.3744137e-34], sum to 1.0000
[2019-03-23 10:11:48,424] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4946
[2019-03-23 10:11:48,431] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 88.0, 1.0, 2.0, 0.4508753187143489, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 513007.0155125057, 513007.0155125054, 132851.5677507168], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2866800.0000, 
sim time next is 2867400.0000, 
raw observation next is [21.0, 88.0, 1.0, 2.0, 0.4407160951387935, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 501420.6203256934, 501420.6203256931, 131792.4081106793], 
processed observation next is [1.0, 0.17391304347826086, 0.5909090909090909, 0.88, 1.0, 1.0, 0.30089511892349186, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18571134086136792, 0.1857113408613678, 0.3214448978309251], 
reward next is 0.6786, 
noisyNet noise sample is [array([-0.5186979], dtype=float32), 1.3727095]. 
=============================================
[2019-03-23 10:11:48,456] A3C_AGENT_WORKER-Thread-12 INFO:Local step 71000, global step 1136289: loss 0.1203
[2019-03-23 10:11:48,461] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 71000, global step 1136291: learning rate 0.0005
[2019-03-23 10:11:48,532] A3C_AGENT_WORKER-Thread-17 INFO:Local step 71000, global step 1136321: loss 0.1027
[2019-03-23 10:11:48,534] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 71000, global step 1136322: learning rate 0.0005
[2019-03-23 10:11:48,681] A3C_AGENT_WORKER-Thread-14 INFO:Local step 71000, global step 1136399: loss 0.0379
[2019-03-23 10:11:48,685] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 71000, global step 1136401: learning rate 0.0005
[2019-03-23 10:11:48,693] A3C_AGENT_WORKER-Thread-3 INFO:Local step 71000, global step 1136404: loss 0.0550
[2019-03-23 10:11:48,695] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 71000, global step 1136405: learning rate 0.0005
[2019-03-23 10:11:48,740] A3C_AGENT_WORKER-Thread-10 INFO:Local step 71000, global step 1136429: loss 0.0239
[2019-03-23 10:11:48,741] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 71000, global step 1136429: learning rate 0.0005
[2019-03-23 10:11:48,991] A3C_AGENT_WORKER-Thread-20 INFO:Local step 71000, global step 1136555: loss 0.0450
[2019-03-23 10:11:48,994] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 71000, global step 1136556: learning rate 0.0005
[2019-03-23 10:11:49,052] A3C_AGENT_WORKER-Thread-22 INFO:Local step 71000, global step 1136586: loss 0.0454
[2019-03-23 10:11:49,056] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 71000, global step 1136588: learning rate 0.0005
[2019-03-23 10:11:49,120] A3C_AGENT_WORKER-Thread-11 INFO:Local step 71000, global step 1136618: loss 0.0361
[2019-03-23 10:11:49,123] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 71000, global step 1136618: learning rate 0.0005
[2019-03-23 10:11:49,307] A3C_AGENT_WORKER-Thread-19 INFO:Local step 71000, global step 1136716: loss 0.0255
[2019-03-23 10:11:49,308] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 71000, global step 1136717: learning rate 0.0005
[2019-03-23 10:11:49,974] A3C_AGENT_WORKER-Thread-18 INFO:Local step 71000, global step 1137054: loss 0.0523
[2019-03-23 10:11:49,976] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 71000, global step 1137054: learning rate 0.0005
[2019-03-23 10:11:50,836] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.3318733e-06 9.8305804e-01 7.2707645e-10 1.6934590e-02 9.1142954e-10], sum to 1.0000
[2019-03-23 10:11:50,849] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3053
[2019-03-23 10:11:50,858] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1530863.215720703 W.
[2019-03-23 10:11:50,863] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.16666666666666, 73.33333333333334, 1.0, 2.0, 0.6806062630215411, 1.0, 2.0, 0.6806062630215411, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1530863.215720703, 1530863.215720703, 285758.439457991], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2891400.0000, 
sim time next is 2892000.0000, 
raw observation next is [27.33333333333334, 72.66666666666667, 1.0, 2.0, 0.7243636913228509, 1.0, 2.0, 0.7243636913228509, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1629426.881115078, 1629426.881115078, 299569.5761865542], 
processed observation next is [1.0, 0.4782608695652174, 0.878787878787879, 0.7266666666666667, 1.0, 1.0, 0.6554546141535635, 1.0, 1.0, 0.6554546141535635, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.6034914374500289, 0.6034914374500289, 0.7306575028940346], 
reward next is 0.2693, 
noisyNet noise sample is [array([-0.22698142], dtype=float32), 0.47406864]. 
=============================================
[2019-03-23 10:11:50,885] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[18.53365 ]
 [17.955019]
 [17.308952]
 [17.742252]
 [17.50006 ]], R is [[18.67463303]
 [18.79091454]
 [18.60300636]
 [18.5965519 ]
 [18.70773697]].
[2019-03-23 10:11:51,723] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.9316189e-17 1.0000000e+00 6.8770281e-26 8.0716305e-16 9.6563749e-26], sum to 1.0000
[2019-03-23 10:11:51,728] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8199
[2019-03-23 10:11:51,733] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 89.0, 1.0, 2.0, 0.5226026560933636, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 595377.4989722532, 595377.4989722532, 145518.4978041883], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3109800.0000, 
sim time next is 3110400.0000, 
raw observation next is [23.0, 89.0, 1.0, 2.0, 0.5211429732521016, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 593714.8035230673, 593714.8035230673, 145339.8717623487], 
processed observation next is [1.0, 0.0, 0.6818181818181818, 0.89, 1.0, 1.0, 0.4014287165651269, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2198943716752101, 0.2198943716752101, 0.3544874921032895], 
reward next is 0.6455, 
noisyNet noise sample is [array([0.26132542], dtype=float32), 0.44751683]. 
=============================================
[2019-03-23 10:11:54,312] A3C_AGENT_WORKER-Thread-9 INFO:Local step 71500, global step 1139242: loss 106.8867
[2019-03-23 10:11:54,316] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 71500, global step 1139242: learning rate 0.0005
[2019-03-23 10:12:01,309] A3C_AGENT_WORKER-Thread-13 INFO:Local step 71500, global step 1142781: loss 72.2806
[2019-03-23 10:12:01,311] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 71500, global step 1142781: learning rate 0.0005
[2019-03-23 10:12:03,801] A3C_AGENT_WORKER-Thread-16 INFO:Local step 71500, global step 1144088: loss 62.2714
[2019-03-23 10:12:03,803] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 71500, global step 1144088: learning rate 0.0005
[2019-03-23 10:12:03,816] A3C_AGENT_WORKER-Thread-2 INFO:Local step 71500, global step 1144090: loss 128.7172
[2019-03-23 10:12:03,818] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 71500, global step 1144091: learning rate 0.0005
[2019-03-23 10:12:03,969] A3C_AGENT_WORKER-Thread-21 INFO:Local step 71500, global step 1144171: loss 108.7533
[2019-03-23 10:12:03,971] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 71500, global step 1144172: learning rate 0.0005
[2019-03-23 10:12:04,147] A3C_AGENT_WORKER-Thread-17 INFO:Local step 71500, global step 1144266: loss 111.5834
[2019-03-23 10:12:04,149] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 71500, global step 1144267: learning rate 0.0005
[2019-03-23 10:12:04,199] A3C_AGENT_WORKER-Thread-12 INFO:Local step 71500, global step 1144296: loss 97.9519
[2019-03-23 10:12:04,201] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 71500, global step 1144296: learning rate 0.0005
[2019-03-23 10:12:04,373] A3C_AGENT_WORKER-Thread-14 INFO:Local step 71500, global step 1144385: loss 294.6991
[2019-03-23 10:12:04,377] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 71500, global step 1144387: learning rate 0.0005
[2019-03-23 10:12:04,417] A3C_AGENT_WORKER-Thread-15 INFO:Local step 71500, global step 1144411: loss 170.4145
[2019-03-23 10:12:04,418] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 71500, global step 1144411: learning rate 0.0005
[2019-03-23 10:12:04,466] A3C_AGENT_WORKER-Thread-3 INFO:Local step 71500, global step 1144431: loss 151.4336
[2019-03-23 10:12:04,468] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 71500, global step 1144431: learning rate 0.0005
[2019-03-23 10:12:04,510] A3C_AGENT_WORKER-Thread-22 INFO:Local step 71500, global step 1144456: loss 109.0864
[2019-03-23 10:12:04,512] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 71500, global step 1144457: learning rate 0.0005
[2019-03-23 10:12:04,545] A3C_AGENT_WORKER-Thread-10 INFO:Local step 71500, global step 1144478: loss 267.5903
[2019-03-23 10:12:04,549] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 71500, global step 1144478: learning rate 0.0005
[2019-03-23 10:12:04,579] A3C_AGENT_WORKER-Thread-20 INFO:Local step 71500, global step 1144492: loss 82.7857
[2019-03-23 10:12:04,580] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 71500, global step 1144492: learning rate 0.0005
[2019-03-23 10:12:04,677] A3C_AGENT_WORKER-Thread-11 INFO:Local step 71500, global step 1144547: loss 40.2070
[2019-03-23 10:12:04,678] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 71500, global step 1144547: learning rate 0.0005
[2019-03-23 10:12:05,031] A3C_AGENT_WORKER-Thread-19 INFO:Local step 71500, global step 1144734: loss 57.0425
[2019-03-23 10:12:05,033] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 71500, global step 1144734: learning rate 0.0005
[2019-03-23 10:12:05,779] A3C_AGENT_WORKER-Thread-18 INFO:Local step 71500, global step 1145131: loss 278.2838
[2019-03-23 10:12:05,781] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 71500, global step 1145132: learning rate 0.0005
[2019-03-23 10:12:09,676] A3C_AGENT_WORKER-Thread-9 INFO:Local step 72000, global step 1147205: loss 1.0718
[2019-03-23 10:12:09,677] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 72000, global step 1147206: learning rate 0.0005
[2019-03-23 10:12:14,888] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-23 10:12:14,889] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 10:12:14,890] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:12:14,892] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 10:12:14,892] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 10:12:14,894] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 10:12:14,893] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 10:12:14,896] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:12:14,896] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:12:14,896] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:12:14,896] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:12:14,912] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run47
[2019-03-23 10:12:14,913] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run47
[2019-03-23 10:12:14,936] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run47
[2019-03-23 10:12:14,985] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run47
[2019-03-23 10:12:15,010] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run47
[2019-03-23 10:12:23,011] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05753305], dtype=float32), -1.1474555]
[2019-03-23 10:12:23,012] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [15.19415263, 98.03086888333333, 1.0, 2.0, 0.2496838845055441, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 271090.1786181117, 271090.1786181114, 96304.57715848165]
[2019-03-23 10:12:23,013] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 10:12:23,015] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.5565282e-25 1.0000000e+00 1.4283091e-37 1.1909821e-22 3.7391681e-37], sampled 0.23738066768607313
[2019-03-23 10:12:28,449] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05753305], dtype=float32), -1.1474555]
[2019-03-23 10:12:28,450] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.6, 87.0, 1.0, 2.0, 0.4174412891676789, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 473419.9837176921, 473419.9837176921, 132584.863173074]
[2019-03-23 10:12:28,451] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 10:12:28,452] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.7213899e-24 1.0000000e+00 5.1227655e-36 1.0024107e-21 1.2815313e-35], sampled 0.0450406957634929
[2019-03-23 10:12:30,530] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05753305], dtype=float32), -1.1474555]
[2019-03-23 10:12:30,531] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [26.5, 79.5, 1.0, 2.0, 0.7703426974985307, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9865530188920543, 6.9112, 6.9112, 77.32846344354104, 1414551.532455161, 1414551.532455161, 311049.0697873369]
[2019-03-23 10:12:30,531] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:12:30,533] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [8.65254909e-19 1.00000000e+00 1.49777665e-27 1.29854598e-16
 2.93373519e-27], sampled 0.6233818092621382
[2019-03-23 10:12:30,535] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1414551.532455161 W.
[2019-03-23 10:12:46,306] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05753305], dtype=float32), -1.1474555]
[2019-03-23 10:12:46,307] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [25.66666666666667, 63.83333333333334, 1.0, 2.0, 0.4617208446161577, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 526798.1428257277, 526798.1428257277, 136156.1590223736]
[2019-03-23 10:12:46,308] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:12:46,311] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.2053358e-27 1.0000000e+00 0.0000000e+00 2.7510879e-24 0.0000000e+00], sampled 0.31941171803244195
[2019-03-23 10:12:48,399] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05753305], dtype=float32), -1.1474555]
[2019-03-23 10:12:48,401] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [26.10583884, 68.36272041, 1.0, 2.0, 0.5055837898267255, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 576059.4542972493, 576059.454297249, 147634.9072658017]
[2019-03-23 10:12:48,401] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 10:12:48,406] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.5127420e-25 1.0000000e+00 1.3688837e-37 1.1612736e-22 3.5855127e-37], sampled 0.952755451571602
[2019-03-23 10:13:16,986] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05753305], dtype=float32), -1.1474555]
[2019-03-23 10:13:16,989] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [25.2, 52.0, 1.0, 2.0, 0.3743716090247106, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 421629.8123652431, 421629.8123652434, 126779.4008930903]
[2019-03-23 10:13:16,989] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 10:13:16,991] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [9.4864068e-28 1.0000000e+00 0.0000000e+00 1.3049018e-24 0.0000000e+00], sampled 0.6935706900128498
[2019-03-23 10:13:29,428] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05753305], dtype=float32), -1.1474555]
[2019-03-23 10:13:29,430] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.2, 69.0, 1.0, 2.0, 0.279946801324995, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 303955.9521787011, 303955.9521787011, 108471.4811063042]
[2019-03-23 10:13:29,432] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 10:13:29,436] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.9433994e-26 1.0000000e+00 1.1953692e-38 2.7268807e-23 3.2290362e-38], sampled 0.02704886610829893
[2019-03-23 10:13:31,446] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05753305], dtype=float32), -1.1474555]
[2019-03-23 10:13:31,447] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [29.4, 55.0, 1.0, 2.0, 0.5448050239259676, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 618383.2286838716, 618383.2286838712, 149663.1861793263]
[2019-03-23 10:13:31,448] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:13:31,455] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0229629e-26 1.0000000e+00 0.0000000e+00 1.0700067e-23 0.0000000e+00], sampled 0.24217243180945836
[2019-03-23 10:13:33,887] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05753305], dtype=float32), -1.1474555]
[2019-03-23 10:13:33,889] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [25.08254229666667, 70.48216046, 1.0, 2.0, 0.473066770826751, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 539612.7583813667, 539612.7583813667, 142924.1647455822]
[2019-03-23 10:13:33,890] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 10:13:33,894] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.5403202e-25 1.0000000e+00 1.4062082e-37 1.1799930e-22 3.6820404e-37], sampled 0.8317858328852389
[2019-03-23 10:13:38,502] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05753305], dtype=float32), -1.1474555]
[2019-03-23 10:13:38,503] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [24.4, 61.0, 1.0, 2.0, 0.414443931478621, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 469992.1372704514, 469992.1372704517, 127941.1951450777]
[2019-03-23 10:13:38,503] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:13:38,507] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.1190988e-27 1.0000000e+00 0.0000000e+00 1.5099984e-24 0.0000000e+00], sampled 0.8985530429028472
[2019-03-23 10:13:53,796] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 10:13:53,798] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 10:13:54,133] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 10:13:54,168] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 10:13:54,171] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 10:13:55,188] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 1150000, evaluation results [1150000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 10:13:56,851] A3C_AGENT_WORKER-Thread-13 INFO:Local step 72000, global step 1150838: loss 0.6112
[2019-03-23 10:13:56,853] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 72000, global step 1150838: learning rate 0.0005
[2019-03-23 10:13:58,756] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.1948622e-20 1.0000000e+00 2.5542631e-29 4.6561987e-17 3.1982932e-29], sum to 1.0000
[2019-03-23 10:13:58,766] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8087
[2019-03-23 10:13:58,769] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.66666666666667, 66.0, 1.0, 2.0, 0.510793761011205, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 580946.8985998866, 580946.8985998866, 144801.3386448562], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3432000.0000, 
sim time next is 3432600.0000, 
raw observation next is [26.5, 68.0, 1.0, 2.0, 0.4956855245441871, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 563975.7963369762, 563975.7963369762, 142851.2358144871], 
processed observation next is [1.0, 0.7391304347826086, 0.8409090909090909, 0.68, 1.0, 1.0, 0.3696069056802338, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20887992456925045, 0.20887992456925045, 0.3484176483280173], 
reward next is 0.6516, 
noisyNet noise sample is [array([0.26261887], dtype=float32), 0.73239374]. 
=============================================
[2019-03-23 10:13:59,115] A3C_AGENT_WORKER-Thread-16 INFO:Local step 72000, global step 1151978: loss 0.6470
[2019-03-23 10:13:59,121] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 72000, global step 1151979: learning rate 0.0005
[2019-03-23 10:13:59,292] A3C_AGENT_WORKER-Thread-2 INFO:Local step 72000, global step 1152067: loss 0.6429
[2019-03-23 10:13:59,295] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 72000, global step 1152069: learning rate 0.0005
[2019-03-23 10:13:59,360] A3C_AGENT_WORKER-Thread-21 INFO:Local step 72000, global step 1152102: loss 0.5882
[2019-03-23 10:13:59,361] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 72000, global step 1152102: learning rate 0.0005
[2019-03-23 10:13:59,630] A3C_AGENT_WORKER-Thread-17 INFO:Local step 72000, global step 1152239: loss 0.5664
[2019-03-23 10:13:59,632] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 72000, global step 1152239: learning rate 0.0005
[2019-03-23 10:13:59,731] A3C_AGENT_WORKER-Thread-12 INFO:Local step 72000, global step 1152289: loss 0.5455
[2019-03-23 10:13:59,736] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 72000, global step 1152290: learning rate 0.0005
[2019-03-23 10:13:59,803] A3C_AGENT_WORKER-Thread-15 INFO:Local step 72000, global step 1152329: loss 0.4985
[2019-03-23 10:13:59,804] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 72000, global step 1152329: learning rate 0.0005
[2019-03-23 10:13:59,830] A3C_AGENT_WORKER-Thread-14 INFO:Local step 72000, global step 1152341: loss 0.4914
[2019-03-23 10:13:59,832] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 72000, global step 1152341: learning rate 0.0005
[2019-03-23 10:13:59,940] A3C_AGENT_WORKER-Thread-3 INFO:Local step 72000, global step 1152398: loss 0.5066
[2019-03-23 10:13:59,942] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 72000, global step 1152399: learning rate 0.0005
[2019-03-23 10:13:59,971] A3C_AGENT_WORKER-Thread-22 INFO:Local step 72000, global step 1152415: loss 0.5167
[2019-03-23 10:13:59,973] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 72000, global step 1152416: learning rate 0.0005
[2019-03-23 10:14:00,126] A3C_AGENT_WORKER-Thread-20 INFO:Local step 72000, global step 1152493: loss 0.4231
[2019-03-23 10:14:00,130] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 72000, global step 1152495: learning rate 0.0005
[2019-03-23 10:14:00,141] A3C_AGENT_WORKER-Thread-10 INFO:Local step 72000, global step 1152504: loss 0.4537
[2019-03-23 10:14:00,144] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 72000, global step 1152504: learning rate 0.0005
[2019-03-23 10:14:00,316] A3C_AGENT_WORKER-Thread-11 INFO:Local step 72000, global step 1152590: loss 0.3820
[2019-03-23 10:14:00,318] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 72000, global step 1152590: learning rate 0.0005
[2019-03-23 10:14:00,655] A3C_AGENT_WORKER-Thread-19 INFO:Local step 72000, global step 1152758: loss 0.4221
[2019-03-23 10:14:00,657] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 72000, global step 1152759: learning rate 0.0005
[2019-03-23 10:14:01,286] A3C_AGENT_WORKER-Thread-18 INFO:Local step 72000, global step 1153076: loss 0.3004
[2019-03-23 10:14:01,288] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 72000, global step 1153078: learning rate 0.0005
[2019-03-23 10:14:03,359] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.87479963e-18 1.00000000e+00 1.14281386e-26 2.63153390e-16
 6.69405563e-27], sum to 1.0000
[2019-03-23 10:14:03,367] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9293
[2019-03-23 10:14:03,373] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.66666666666667, 68.66666666666667, 1.0, 2.0, 0.5397563810762451, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 613209.8646372193, 613209.8646372193, 148759.2155908675], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3525600.0000, 
sim time next is 3526200.0000, 
raw observation next is [26.5, 70.0, 1.0, 2.0, 0.5430370740690766, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 616724.7380282981, 616724.7380282981, 149278.6837660782], 
processed observation next is [1.0, 0.8260869565217391, 0.8409090909090909, 0.7, 1.0, 1.0, 0.42879634258634575, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22841656964011042, 0.22841656964011042, 0.3640943506489712], 
reward next is 0.6359, 
noisyNet noise sample is [array([1.7447037], dtype=float32), 0.7953656]. 
=============================================
[2019-03-23 10:14:05,756] A3C_AGENT_WORKER-Thread-9 INFO:Local step 72500, global step 1155358: loss -140.1953
[2019-03-23 10:14:05,759] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 72500, global step 1155358: learning rate 0.0005
[2019-03-23 10:14:06,370] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.3955124e-13 1.0000000e+00 2.5148565e-20 5.4722871e-13 2.9606038e-20], sum to 1.0000
[2019-03-23 10:14:06,380] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7847
[2019-03-23 10:14:06,387] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1497939.302089261 W.
[2019-03-23 10:14:06,391] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.5, 91.5, 1.0, 2.0, 0.8415435258797079, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9827157897568284, 6.9112, 6.9112, 77.32846344354104, 1497939.302089261, 1497939.302089261, 320424.0438048337], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3583800.0000, 
sim time next is 3584400.0000, 
raw observation next is [23.33333333333333, 92.33333333333334, 1.0, 2.0, 0.4314900889617376, 1.0, 1.0, 0.4314900889617376, 1.0, 2.0, 0.8730681717877474, 6.911199999999999, 6.9112, 77.3421103, 1455705.904276397, 1455705.904276398, 323000.7830108552], 
processed observation next is [1.0, 0.4782608695652174, 0.6969696969696968, 0.9233333333333335, 1.0, 1.0, 0.28936261120217194, 1.0, 0.5, 0.28936261120217194, 1.0, 1.0, 0.8186688168396393, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.5391503349171841, 0.5391503349171844, 0.7878067878313542], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.9394583], dtype=float32), -1.9531131]. 
=============================================
[2019-03-23 10:14:08,432] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0882892e-21 1.0000000e+00 1.6045803e-30 6.8767079e-20 1.2289048e-30], sum to 1.0000
[2019-03-23 10:14:08,442] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4998
[2019-03-23 10:14:08,449] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.83333333333334, 95.0, 1.0, 2.0, 0.5102092250132598, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 581905.7689154734, 581905.7689154734, 143226.3036591802], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3622200.0000, 
sim time next is 3622800.0000, 
raw observation next is [21.66666666666667, 96.0, 1.0, 2.0, 0.5072100393825066, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 578534.530526586, 578534.530526586, 142778.244785209], 
processed observation next is [1.0, 0.9565217391304348, 0.6212121212121214, 0.96, 1.0, 1.0, 0.38401254922813327, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21427204834318, 0.21427204834318, 0.34823962142733905], 
reward next is 0.6518, 
noisyNet noise sample is [array([-0.44768175], dtype=float32), 1.220022]. 
=============================================
[2019-03-23 10:14:12,760] A3C_AGENT_WORKER-Thread-13 INFO:Local step 72500, global step 1158878: loss -259.5333
[2019-03-23 10:14:12,768] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 72500, global step 1158880: learning rate 0.0005
[2019-03-23 10:14:13,664] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.781093e-28 1.000000e+00 0.000000e+00 4.674311e-19 0.000000e+00], sum to 1.0000
[2019-03-23 10:14:13,672] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1354
[2019-03-23 10:14:13,675] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 82.00000000000001, 1.0, 2.0, 0.2642558217303212, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 286931.3384812826, 286931.3384812829, 94219.10772467071], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3910200.0000, 
sim time next is 3910800.0000, 
raw observation next is [17.0, 82.0, 1.0, 2.0, 0.2640019069780849, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 286655.5543171617, 286655.5543171617, 94194.81369049005], 
processed observation next is [0.0, 0.2608695652173913, 0.4090909090909091, 0.82, 1.0, 1.0, 0.08000238372260611, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10616872382117098, 0.10616872382117098, 0.22974344802558547], 
reward next is 0.7703, 
noisyNet noise sample is [array([-0.2078351], dtype=float32), -0.23680727]. 
=============================================
[2019-03-23 10:14:13,853] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.0983219e-16 1.0000000e+00 1.0764002e-25 1.1687017e-11 8.6734744e-25], sum to 1.0000
[2019-03-23 10:14:13,861] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4220
[2019-03-23 10:14:13,871] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.5087071850284235, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 580155.9233511458, 580155.9233511458, 143108.8101858191], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3720600.0000, 
sim time next is 3721200.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.5101756125998816, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 581831.3105664831, 581831.3105664831, 143283.1387480297], 
processed observation next is [1.0, 0.043478260869565216, 0.6363636363636364, 0.94, 1.0, 1.0, 0.38771951574985203, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21549307798758632, 0.21549307798758632, 0.3494710701171456], 
reward next is 0.6505, 
noisyNet noise sample is [array([-0.6502987], dtype=float32), -0.91140294]. 
=============================================
[2019-03-23 10:14:13,938] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.9659027e-14 1.0000000e+00 2.6711304e-23 4.8009092e-12 7.7535056e-23], sum to 1.0000
[2019-03-23 10:14:13,944] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0891
[2019-03-23 10:14:13,947] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.16666666666666, 94.0, 1.0, 2.0, 0.4812145515677529, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 549041.1296014724, 549041.1296014724, 138251.5296473828], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3732600.0000, 
sim time next is 3733200.0000, 
raw observation next is [21.0, 94.0, 1.0, 2.0, 0.4754028129007819, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 542284.2853985296, 542284.2853985296, 137235.1021736541], 
processed observation next is [1.0, 0.21739130434782608, 0.5909090909090909, 0.94, 1.0, 1.0, 0.3442535161259773, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20084603162908504, 0.20084603162908504, 0.3347197613991563], 
reward next is 0.6653, 
noisyNet noise sample is [array([0.00596558], dtype=float32), 0.42834443]. 
=============================================
[2019-03-23 10:14:15,084] A3C_AGENT_WORKER-Thread-16 INFO:Local step 72500, global step 1160024: loss 0.0015
[2019-03-23 10:14:15,085] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 72500, global step 1160024: learning rate 0.0005
[2019-03-23 10:14:15,248] A3C_AGENT_WORKER-Thread-21 INFO:Local step 72500, global step 1160108: loss -110.1723
[2019-03-23 10:14:15,250] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 72500, global step 1160108: learning rate 0.0005
[2019-03-23 10:14:15,298] A3C_AGENT_WORKER-Thread-2 INFO:Local step 72500, global step 1160132: loss -153.8672
[2019-03-23 10:14:15,301] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 72500, global step 1160132: learning rate 0.0005
[2019-03-23 10:14:15,560] A3C_AGENT_WORKER-Thread-17 INFO:Local step 72500, global step 1160267: loss -119.7795
[2019-03-23 10:14:15,561] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 72500, global step 1160267: learning rate 0.0005
[2019-03-23 10:14:15,716] A3C_AGENT_WORKER-Thread-12 INFO:Local step 72500, global step 1160344: loss -258.5062
[2019-03-23 10:14:15,719] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 72500, global step 1160346: learning rate 0.0005
[2019-03-23 10:14:15,758] A3C_AGENT_WORKER-Thread-15 INFO:Local step 72500, global step 1160369: loss -177.5487
[2019-03-23 10:14:15,761] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 72500, global step 1160369: learning rate 0.0005
[2019-03-23 10:14:15,766] A3C_AGENT_WORKER-Thread-14 INFO:Local step 72500, global step 1160371: loss -70.0014
[2019-03-23 10:14:15,768] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 72500, global step 1160371: learning rate 0.0005
[2019-03-23 10:14:15,815] A3C_AGENT_WORKER-Thread-22 INFO:Local step 72500, global step 1160394: loss -165.3734
[2019-03-23 10:14:15,819] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 72500, global step 1160396: learning rate 0.0005
[2019-03-23 10:14:15,861] A3C_AGENT_WORKER-Thread-3 INFO:Local step 72500, global step 1160420: loss -248.4431
[2019-03-23 10:14:15,863] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 72500, global step 1160420: learning rate 0.0005
[2019-03-23 10:14:15,975] A3C_AGENT_WORKER-Thread-20 INFO:Local step 72500, global step 1160477: loss -105.6838
[2019-03-23 10:14:15,978] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 72500, global step 1160479: learning rate 0.0005
[2019-03-23 10:14:15,984] A3C_AGENT_WORKER-Thread-10 INFO:Local step 72500, global step 1160481: loss -95.4322
[2019-03-23 10:14:15,986] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 72500, global step 1160481: learning rate 0.0005
[2019-03-23 10:14:16,111] A3C_AGENT_WORKER-Thread-11 INFO:Local step 72500, global step 1160543: loss -25.4273
[2019-03-23 10:14:16,112] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 72500, global step 1160543: learning rate 0.0005
[2019-03-23 10:14:16,465] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.4646693e-16 1.0000000e+00 1.1902490e-25 1.4429765e-09 1.2179220e-25], sum to 1.0000
[2019-03-23 10:14:16,472] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1899
[2019-03-23 10:14:16,480] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1177640.97249496 W.
[2019-03-23 10:14:16,486] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.0, 71.0, 1.0, 2.0, 0.5157097587820011, 1.0, 2.0, 0.5157097587820011, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846329648655, 1177640.97249496, 1177640.97249496, 228649.4389124701], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3769800.0000, 
sim time next is 3770400.0000, 
raw observation next is [23.0, 69.0, 1.0, 2.0, 0.4765989960506082, 1.0, 2.0, 0.4765989960506082, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344263076, 1087860.606525934, 1087860.606525934, 218243.3162242656], 
processed observation next is [1.0, 0.6521739130434783, 0.6818181818181818, 0.69, 1.0, 1.0, 0.3457487450632602, 1.0, 1.0, 0.3457487450632602, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129146691, 0.40291133575034593, 0.40291133575034593, 0.5323007712786966], 
reward next is 0.4677, 
noisyNet noise sample is [array([1.3274076], dtype=float32), -0.8099507]. 
=============================================
[2019-03-23 10:14:16,681] A3C_AGENT_WORKER-Thread-19 INFO:Local step 72500, global step 1160834: loss -139.4771
[2019-03-23 10:14:16,686] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 72500, global step 1160835: learning rate 0.0005
[2019-03-23 10:14:17,072] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.9884467e-25 1.0000000e+00 1.7661559e-38 4.1176734e-20 6.2260302e-38], sum to 1.0000
[2019-03-23 10:14:17,081] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4770
[2019-03-23 10:14:17,088] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 61.33333333333334, 1.0, 2.0, 0.3502664164082464, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 385923.1959674479, 385923.1959674479, 116645.7701272556], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3777600.0000, 
sim time next is 3778200.0000, 
raw observation next is [21.5, 62.0, 1.0, 2.0, 0.3388404739919929, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 372731.1374586791, 372731.1374586794, 115556.7777223817], 
processed observation next is [1.0, 0.7391304347826086, 0.6136363636363636, 0.62, 1.0, 1.0, 0.1735505924899911, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1380485694291404, 0.1380485694291405, 0.2818457993228822], 
reward next is 0.7182, 
noisyNet noise sample is [array([-1.2032063], dtype=float32), -1.1741129]. 
=============================================
[2019-03-23 10:14:17,224] A3C_AGENT_WORKER-Thread-18 INFO:Local step 72500, global step 1161100: loss -219.8423
[2019-03-23 10:14:17,229] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 72500, global step 1161101: learning rate 0.0005
[2019-03-23 10:14:21,264] A3C_AGENT_WORKER-Thread-9 INFO:Local step 73000, global step 1163145: loss 0.0013
[2019-03-23 10:14:21,270] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 73000, global step 1163145: learning rate 0.0005
[2019-03-23 10:14:21,727] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.2328580e-25 1.0000000e+00 0.0000000e+00 3.6302032e-28 2.0290213e-38], sum to 1.0000
[2019-03-23 10:14:21,732] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2224
[2019-03-23 10:14:21,736] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 100.0, 1.0, 2.0, 0.3047530313542987, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 330918.5320789242, 330918.5320789239, 111512.6064783656], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4064400.0000, 
sim time next is 4065000.0000, 
raw observation next is [16.0, 100.0, 1.0, 2.0, 0.304583825721208, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 330734.7363008813, 330734.7363008813, 111501.1913396614], 
processed observation next is [1.0, 0.043478260869565216, 0.36363636363636365, 1.0, 1.0, 1.0, 0.13072978215151, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1224943467781042, 0.1224943467781042, 0.27195412521868634], 
reward next is 0.7280, 
noisyNet noise sample is [array([-1.3362048], dtype=float32), -0.7378275]. 
=============================================
[2019-03-23 10:14:21,750] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[74.07901]
 [74.0177 ]
 [73.95517]
 [73.87903]
 [73.86296]], R is [[74.03256989]
 [74.02026367]
 [74.00806427]
 [73.99593353]
 [73.98383331]].
[2019-03-23 10:14:22,145] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0731987e-24 1.0000000e+00 3.1385364e-38 4.3926565e-16 1.3332312e-37], sum to 1.0000
[2019-03-23 10:14:22,158] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0642
[2019-03-23 10:14:22,167] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 77.0, 1.0, 2.0, 0.2786365934781147, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 302550.9663039118, 302550.9663039121, 101343.2007627213], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3888000.0000, 
sim time next is 3888600.0000, 
raw observation next is [18.0, 77.0, 1.0, 2.0, 0.2795576581333694, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 303551.3947370687, 303551.3947370687, 101443.4320590335], 
processed observation next is [0.0, 0.0, 0.45454545454545453, 0.77, 1.0, 1.0, 0.09944707266671175, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11242644249521062, 0.11242644249521062, 0.24742300502203293], 
reward next is 0.7526, 
noisyNet noise sample is [array([-0.05233803], dtype=float32), 0.08126897]. 
=============================================
[2019-03-23 10:14:23,204] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.5825205e-24 1.0000000e+00 7.4447064e-38 2.6017860e-18 4.4956623e-37], sum to 1.0000
[2019-03-23 10:14:23,212] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3060
[2019-03-23 10:14:23,215] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 77.0, 1.0, 2.0, 0.2806530956723104, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 304741.2236185433, 304741.2236185436, 101582.148930865], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3891000.0000, 
sim time next is 3891600.0000, 
raw observation next is [18.0, 77.0, 1.0, 2.0, 0.2809326349239201, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 305044.8505931056, 305044.8505931059, 101612.8383162166], 
processed observation next is [0.0, 0.043478260869565216, 0.45454545454545453, 0.77, 1.0, 1.0, 0.10116579365490014, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11297957429374282, 0.11297957429374292, 0.24783619101516244], 
reward next is 0.7522, 
noisyNet noise sample is [array([1.103263], dtype=float32), -0.22681734]. 
=============================================
[2019-03-23 10:14:25,964] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.3463469e-26 1.0000000e+00 1.1966467e-38 2.8480807e-24 4.9627635e-38], sum to 1.0000
[2019-03-23 10:14:25,972] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8445
[2019-03-23 10:14:25,978] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.3768039860320676, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 423008.5943892029, 423008.5943892029, 121972.9079534209], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4144800.0000, 
sim time next is 4145400.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.3764359247952421, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 422595.8794768703, 422595.8794768703, 121941.6820442742], 
processed observation next is [1.0, 1.0, 0.45454545454545453, 1.0, 1.0, 1.0, 0.22054490599405263, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15651699239884084, 0.15651699239884084, 0.2974187366933517], 
reward next is 0.7026, 
noisyNet noise sample is [array([-0.06432842], dtype=float32), -1.5281098]. 
=============================================
[2019-03-23 10:14:28,523] A3C_AGENT_WORKER-Thread-13 INFO:Local step 73000, global step 1166786: loss 0.0117
[2019-03-23 10:14:28,527] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 73000, global step 1166786: learning rate 0.0005
[2019-03-23 10:14:30,838] A3C_AGENT_WORKER-Thread-21 INFO:Local step 73000, global step 1167981: loss 0.0098
[2019-03-23 10:14:30,844] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 73000, global step 1167982: learning rate 0.0005
[2019-03-23 10:14:30,878] A3C_AGENT_WORKER-Thread-16 INFO:Local step 73000, global step 1168000: loss 0.0018
[2019-03-23 10:14:30,882] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 73000, global step 1168000: learning rate 0.0005
[2019-03-23 10:14:30,927] A3C_AGENT_WORKER-Thread-2 INFO:Local step 73000, global step 1168024: loss 0.0034
[2019-03-23 10:14:30,933] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 73000, global step 1168026: learning rate 0.0005
[2019-03-23 10:14:31,306] A3C_AGENT_WORKER-Thread-17 INFO:Local step 73000, global step 1168226: loss 0.0120
[2019-03-23 10:14:31,308] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 73000, global step 1168226: learning rate 0.0005
[2019-03-23 10:14:31,571] A3C_AGENT_WORKER-Thread-3 INFO:Local step 73000, global step 1168369: loss 0.0036
[2019-03-23 10:14:31,574] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 73000, global step 1168370: learning rate 0.0005
[2019-03-23 10:14:31,591] A3C_AGENT_WORKER-Thread-14 INFO:Local step 73000, global step 1168381: loss 0.0000
[2019-03-23 10:14:31,593] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 73000, global step 1168382: learning rate 0.0005
[2019-03-23 10:14:31,637] A3C_AGENT_WORKER-Thread-12 INFO:Local step 73000, global step 1168405: loss 0.0026
[2019-03-23 10:14:31,638] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 73000, global step 1168405: learning rate 0.0005
[2019-03-23 10:14:31,649] A3C_AGENT_WORKER-Thread-15 INFO:Local step 73000, global step 1168410: loss 0.0009
[2019-03-23 10:14:31,651] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 73000, global step 1168411: learning rate 0.0005
[2019-03-23 10:14:31,734] A3C_AGENT_WORKER-Thread-10 INFO:Local step 73000, global step 1168455: loss 0.0002
[2019-03-23 10:14:31,735] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 73000, global step 1168455: learning rate 0.0005
[2019-03-23 10:14:31,755] A3C_AGENT_WORKER-Thread-22 INFO:Local step 73000, global step 1168468: loss 0.0001
[2019-03-23 10:14:31,759] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 73000, global step 1168468: learning rate 0.0005
[2019-03-23 10:14:31,819] A3C_AGENT_WORKER-Thread-20 INFO:Local step 73000, global step 1168502: loss 0.0002
[2019-03-23 10:14:31,820] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 73000, global step 1168502: learning rate 0.0005
[2019-03-23 10:14:31,962] A3C_AGENT_WORKER-Thread-11 INFO:Local step 73000, global step 1168576: loss 0.0001
[2019-03-23 10:14:31,965] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 73000, global step 1168577: learning rate 0.0005
[2019-03-23 10:14:32,625] A3C_AGENT_WORKER-Thread-19 INFO:Local step 73000, global step 1168934: loss 0.0040
[2019-03-23 10:14:32,629] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 73000, global step 1168935: learning rate 0.0005
[2019-03-23 10:14:32,997] A3C_AGENT_WORKER-Thread-18 INFO:Local step 73000, global step 1169130: loss 0.0001
[2019-03-23 10:14:33,000] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 73000, global step 1169130: learning rate 0.0005
[2019-03-23 10:14:33,493] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.3158683e-24 1.0000000e+00 7.8521807e-37 1.6095603e-20 3.6219736e-35], sum to 1.0000
[2019-03-23 10:14:33,500] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8698
[2019-03-23 10:14:33,503] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.66666666666667, 94.0, 1.0, 2.0, 0.6124445450257107, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 688321.1705152004, 688321.1705152004, 146050.8789988397], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4092000.0000, 
sim time next is 4092600.0000, 
raw observation next is [18.83333333333333, 94.0, 1.0, 2.0, 0.6255533494615872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 704390.4895225094, 704390.4895225092, 148228.1736634996], 
processed observation next is [1.0, 0.34782608695652173, 0.4924242424242422, 0.94, 1.0, 1.0, 0.5319416868269841, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2608853664898183, 0.2608853664898182, 0.36153213088658437], 
reward next is 0.6385, 
noisyNet noise sample is [array([0.2901323], dtype=float32), -0.8823719]. 
=============================================
[2019-03-23 10:14:36,864] A3C_AGENT_WORKER-Thread-9 INFO:Local step 73500, global step 1171190: loss -36.7058
[2019-03-23 10:14:36,868] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 73500, global step 1171192: learning rate 0.0005
[2019-03-23 10:14:40,884] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.0516138e-25 1.0000000e+00 5.8280564e-38 8.3399937e-24 4.0701783e-37], sum to 1.0000
[2019-03-23 10:14:40,888] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8163
[2019-03-23 10:14:40,894] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 94.0, 1.0, 2.0, 0.3212686901283826, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 351489.674886905, 351489.6748869053, 113561.2077113066], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4240200.0000, 
sim time next is 4240800.0000, 
raw observation next is [17.0, 94.0, 1.0, 2.0, 0.3210770328264259, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 351278.6003962822, 351278.6003962822, 113547.1055279832], 
processed observation next is [1.0, 0.08695652173913043, 0.4090909090909091, 0.94, 1.0, 1.0, 0.15134629103303238, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1301031853319564, 0.1301031853319564, 0.2769441598243493], 
reward next is 0.7231, 
noisyNet noise sample is [array([-0.33810636], dtype=float32), 0.7676893]. 
=============================================
[2019-03-23 10:14:43,354] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.4119920e-22 1.0000000e+00 1.4488959e-34 1.3374038e-21 4.7014925e-34], sum to 1.0000
[2019-03-23 10:14:43,367] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1622
[2019-03-23 10:14:43,371] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 88.0, 1.0, 2.0, 0.4722301306617966, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 538796.140750724, 538796.1407507238, 137307.2571176199], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4482000.0000, 
sim time next is 4482600.0000, 
raw observation next is [21.83333333333334, 89.00000000000001, 1.0, 2.0, 0.472680630644752, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 539302.812001997, 539302.8120019973, 137323.995405899], 
processed observation next is [0.0, 0.9130434782608695, 0.628787878787879, 0.8900000000000001, 1.0, 1.0, 0.34085078830594, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19974178222296185, 0.19974178222296193, 0.3349365741607293], 
reward next is 0.6651, 
noisyNet noise sample is [array([0.24035683], dtype=float32), 1.7957343]. 
=============================================
[2019-03-23 10:14:43,594] A3C_AGENT_WORKER-Thread-13 INFO:Local step 73500, global step 1174769: loss -40.8480
[2019-03-23 10:14:43,600] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 73500, global step 1174769: learning rate 0.0005
[2019-03-23 10:14:44,041] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-23 10:14:44,044] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 10:14:44,045] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:14:44,045] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 10:14:44,047] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 10:14:44,048] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:14:44,049] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 10:14:44,046] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 10:14:44,049] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:14:44,051] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:14:44,053] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:14:44,073] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run48
[2019-03-23 10:14:44,098] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run48
[2019-03-23 10:14:44,124] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run48
[2019-03-23 10:14:44,124] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run48
[2019-03-23 10:14:44,173] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run48
[2019-03-23 10:14:54,697] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.04680858], dtype=float32), -1.1755629]
[2019-03-23 10:14:54,698] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [17.56246344666667, 97.45147242, 1.0, 2.0, 0.3794594074632544, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 422827.3170016162, 422827.3170016162, 125092.9316923514]
[2019-03-23 10:14:54,699] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 10:14:54,702] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.0661471e-25 1.0000000e+00 1.5906907e-38 2.5168323e-21 4.2655892e-38], sampled 0.5117987470153785
[2019-03-23 10:15:05,195] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.04680858], dtype=float32), -1.1755629]
[2019-03-23 10:15:05,197] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [10.0, 100.0, 1.0, 2.0, 0.338289171681933, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 367347.7746239086, 367347.7746239089, 81370.44007016865]
[2019-03-23 10:15:05,198] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:15:05,201] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0661471e-25 1.0000000e+00 1.5906907e-38 2.5168323e-21 4.2655892e-38], sampled 0.1516759288965256
[2019-03-23 10:15:12,224] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.04680858], dtype=float32), -1.1755629]
[2019-03-23 10:15:12,225] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [28.2, 49.0, 1.0, 2.0, 0.5498879672703679, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 627145.4663309857, 627145.4663309857, 149931.6009346533]
[2019-03-23 10:15:12,226] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 10:15:12,229] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.0661471e-25 1.0000000e+00 1.5906907e-38 2.5168323e-21 4.2655892e-38], sampled 0.6548799454236653
[2019-03-23 10:15:16,978] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.04680858], dtype=float32), -1.1755629]
[2019-03-23 10:15:16,979] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [26.49231502333333, 78.65460267, 1.0, 2.0, 0.5609332967586308, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9116622986949396, 7.014867682768953, 6.9112, 95.55299415497042, 1178579.691908102, 1136975.510468241, 271534.7398905868]
[2019-03-23 10:15:16,980] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 10:15:16,981] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.4003452e-24 1.0000000e+00 7.9230698e-37 2.1160177e-20 2.0316103e-36], sampled 0.39678795489139396
[2019-03-23 10:15:16,982] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1178579.691908102 W.
[2019-03-23 10:15:21,424] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.04680858], dtype=float32), -1.1755629]
[2019-03-23 10:15:21,426] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.85, 74.0, 1.0, 2.0, 0.389251215189668, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 439468.583863466, 439468.5838634657, 128676.812057326]
[2019-03-23 10:15:21,426] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 10:15:21,432] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.0661471e-25 1.0000000e+00 1.5906907e-38 2.5168323e-21 4.2655892e-38], sampled 0.5216499144988658
[2019-03-23 10:15:21,524] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.04680858], dtype=float32), -1.1755629]
[2019-03-23 10:15:21,526] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.381124135, 80.54750267833333, 1.0, 2.0, 0.260073918947356, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 282373.6378552089, 282373.6378552085, 91047.13372374966]
[2019-03-23 10:15:21,528] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 10:15:21,530] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0661471e-25 1.0000000e+00 1.5906907e-38 2.5168323e-21 4.2655892e-38], sampled 0.7854870236311943
[2019-03-23 10:15:25,323] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.04680858], dtype=float32), -1.1755629]
[2019-03-23 10:15:25,325] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.0, 89.0, 1.0, 2.0, 0.5194324076624407, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 591762.0347431514, 591762.0347431514, 145134.9000248478]
[2019-03-23 10:15:25,327] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:15:25,330] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0661471e-25 1.0000000e+00 1.5906907e-38 2.5168323e-21 4.2655892e-38], sampled 0.8424254412925638
[2019-03-23 10:15:41,992] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.04680858], dtype=float32), -1.1755629]
[2019-03-23 10:15:41,993] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.92997082, 91.49748369666666, 1.0, 2.0, 0.4588758087807762, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 522678.3184057404, 522678.3184057401, 138642.0404965899]
[2019-03-23 10:15:41,995] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 10:15:42,000] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.0661471e-25 1.0000000e+00 1.5906907e-38 2.5168323e-21 4.2655892e-38], sampled 0.9621732759026611
[2019-03-23 10:15:50,203] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.04680858], dtype=float32), -1.1755629]
[2019-03-23 10:15:50,204] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.32194663166667, 96.75594358500001, 1.0, 2.0, 0.4338912622212973, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 494066.625695304, 494066.6256953035, 135890.3193514458]
[2019-03-23 10:15:50,206] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 10:15:50,209] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0661471e-25 1.0000000e+00 1.5906907e-38 2.5168323e-21 4.2655892e-38], sampled 0.962734279992593
[2019-03-23 10:16:01,014] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.04680858], dtype=float32), -1.1755629]
[2019-03-23 10:16:01,014] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.03333333333333, 88.66666666666666, 1.0, 2.0, 0.370246857253312, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 414424.6529647425, 414424.6529647425, 125156.1990752192]
[2019-03-23 10:16:01,015] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 10:16:01,021] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.0661471e-25 1.0000000e+00 1.5906907e-38 2.5168323e-21 4.2655892e-38], sampled 0.503773403213838
[2019-03-23 10:16:14,290] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.04680858], dtype=float32), -1.1755629]
[2019-03-23 10:16:14,291] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.13333333333333, 79.66666666666667, 1.0, 2.0, 0.3358737781788588, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 370555.7008811749, 370555.7008811746, 120065.172266043]
[2019-03-23 10:16:14,292] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 10:16:14,295] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.0661471e-25 1.0000000e+00 1.5906907e-38 2.5168323e-21 4.2655892e-38], sampled 0.7618272192261253
[2019-03-23 10:16:22,404] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.04680858], dtype=float32), -1.1755629]
[2019-03-23 10:16:22,405] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.7, 69.5, 1.0, 2.0, 0.3536583160159538, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 384285.6364486001, 384285.6364485997, 119344.8502314125]
[2019-03-23 10:16:22,406] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 10:16:22,409] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.0661471e-25 1.0000000e+00 1.5906907e-38 2.5168323e-21 4.2655892e-38], sampled 0.9237355093628739
[2019-03-23 10:16:23,901] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 10:16:23,973] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 10:16:24,051] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 10:16:24,078] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 10:16:24,119] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 10:16:25,136] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 1175000, evaluation results [1175000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 10:16:25,142] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.3726001e-24 1.0000000e+00 4.7185520e-38 1.1221261e-18 1.2846976e-36], sum to 1.0000
[2019-03-23 10:16:25,145] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5883
[2019-03-23 10:16:25,151] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.5, 54.0, 1.0, 2.0, 0.3979046241676468, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 450511.6468039312, 450511.6468039314, 125896.8715102034], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4300200.0000, 
sim time next is 4300800.0000, 
raw observation next is [25.33333333333333, 55.0, 1.0, 2.0, 0.3981541202314092, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 450879.9019192003, 450879.9019192003, 125975.4284536729], 
processed observation next is [1.0, 0.782608695652174, 0.7878787878787876, 0.55, 1.0, 1.0, 0.24769265028926152, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1669925562663705, 0.1669925562663705, 0.3072571425699339], 
reward next is 0.6927, 
noisyNet noise sample is [array([0.9916036], dtype=float32), 0.56563073]. 
=============================================
[2019-03-23 10:16:25,355] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.28689175e-26 1.00000000e+00 0.00000000e+00 4.45083338e-23
 0.00000000e+00], sum to 1.0000
[2019-03-23 10:16:25,363] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5733
[2019-03-23 10:16:25,367] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 46.0, 1.0, 2.0, 0.8308776648142282, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 941355.6993216401, 941355.6993216401, 178690.8179187132], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4281600.0000, 
sim time next is 4282200.0000, 
raw observation next is [27.0, 46.5, 1.0, 2.0, 0.9002185109828953, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1020968.717310012, 1020968.717310012, 190156.1250798004], 
processed observation next is [1.0, 0.5652173913043478, 0.8636363636363636, 0.465, 1.0, 1.0, 0.8752731387286191, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3781365619666711, 0.3781365619666711, 0.4637954270239034], 
reward next is 0.5362, 
noisyNet noise sample is [array([1.9213996], dtype=float32), -0.16744941]. 
=============================================
[2019-03-23 10:16:27,038] A3C_AGENT_WORKER-Thread-16 INFO:Local step 73500, global step 1175953: loss -60.7525
[2019-03-23 10:16:27,039] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 73500, global step 1175953: learning rate 0.0005
[2019-03-23 10:16:27,141] A3C_AGENT_WORKER-Thread-21 INFO:Local step 73500, global step 1175999: loss -60.5176
[2019-03-23 10:16:27,145] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 73500, global step 1175999: learning rate 0.0005
[2019-03-23 10:16:27,336] A3C_AGENT_WORKER-Thread-17 INFO:Local step 73500, global step 1176101: loss -65.9113
[2019-03-23 10:16:27,338] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 73500, global step 1176101: learning rate 0.0005
[2019-03-23 10:16:27,429] A3C_AGENT_WORKER-Thread-2 INFO:Local step 73500, global step 1176142: loss -65.0868
[2019-03-23 10:16:27,433] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 73500, global step 1176143: learning rate 0.0005
[2019-03-23 10:16:27,704] A3C_AGENT_WORKER-Thread-12 INFO:Local step 73500, global step 1176282: loss -56.9401
[2019-03-23 10:16:27,706] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 73500, global step 1176282: learning rate 0.0005
[2019-03-23 10:16:27,737] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.2869466e-14 1.0000000e+00 1.7781902e-22 3.3308122e-12 2.9803402e-22], sum to 1.0000
[2019-03-23 10:16:27,747] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8247
[2019-03-23 10:16:27,755] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666667, 78.83333333333333, 1.0, 2.0, 0.8368682169015174, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 954467.804609175, 954467.804609175, 185263.0550741871], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4351800.0000, 
sim time next is 4352400.0000, 
raw observation next is [23.0, 78.0, 1.0, 2.0, 0.9206544400591571, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1050645.301946659, 1050645.301946659, 200215.3250018284], 
processed observation next is [1.0, 0.391304347826087, 0.6818181818181818, 0.78, 1.0, 1.0, 0.9008180500739462, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.38912788960987377, 0.38912788960987377, 0.48833006098006926], 
reward next is 0.5117, 
noisyNet noise sample is [array([-0.8930348], dtype=float32), 1.1360888]. 
=============================================
[2019-03-23 10:16:27,913] A3C_AGENT_WORKER-Thread-10 INFO:Local step 73500, global step 1176378: loss -2.8874
[2019-03-23 10:16:27,915] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 73500, global step 1176379: learning rate 0.0005
[2019-03-23 10:16:27,957] A3C_AGENT_WORKER-Thread-14 INFO:Local step 73500, global step 1176402: loss -1.5989
[2019-03-23 10:16:27,959] A3C_AGENT_WORKER-Thread-15 INFO:Local step 73500, global step 1176403: loss 0.5465
[2019-03-23 10:16:27,960] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 73500, global step 1176403: learning rate 0.0005
[2019-03-23 10:16:27,965] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 73500, global step 1176404: learning rate 0.0005
[2019-03-23 10:16:28,011] A3C_AGENT_WORKER-Thread-3 INFO:Local step 73500, global step 1176432: loss -8.0133
[2019-03-23 10:16:28,013] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 73500, global step 1176432: learning rate 0.0005
[2019-03-23 10:16:28,060] A3C_AGENT_WORKER-Thread-22 INFO:Local step 73500, global step 1176452: loss 0.3167
[2019-03-23 10:16:28,065] A3C_AGENT_WORKER-Thread-11 INFO:Local step 73500, global step 1176452: loss 0.2213
[2019-03-23 10:16:28,066] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 73500, global step 1176452: learning rate 0.0005
[2019-03-23 10:16:28,069] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 73500, global step 1176453: learning rate 0.0005
[2019-03-23 10:16:28,218] A3C_AGENT_WORKER-Thread-20 INFO:Local step 73500, global step 1176526: loss -17.6791
[2019-03-23 10:16:28,219] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 73500, global step 1176526: learning rate 0.0005
[2019-03-23 10:16:29,081] A3C_AGENT_WORKER-Thread-19 INFO:Local step 73500, global step 1176955: loss -8.3550
[2019-03-23 10:16:29,083] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 73500, global step 1176956: learning rate 0.0005
[2019-03-23 10:16:29,239] A3C_AGENT_WORKER-Thread-18 INFO:Local step 73500, global step 1177037: loss -52.5423
[2019-03-23 10:16:29,241] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 73500, global step 1177037: learning rate 0.0005
[2019-03-23 10:16:29,744] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.6557176e-09 9.9899405e-01 4.0790553e-15 1.0059227e-03 3.3257641e-14], sum to 1.0000
[2019-03-23 10:16:29,753] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3431
[2019-03-23 10:16:29,760] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.33333333333334, 55.66666666666667, 1.0, 2.0, 0.4564027443671764, 1.0, 2.0, 0.4564027443671764, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1039198.043155118, 1039198.043155118, 220279.0584341832], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4364400.0000, 
sim time next is 4365000.0000, 
raw observation next is [27.5, 54.5, 1.0, 2.0, 0.7993443519767712, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 912354.9403625177, 912354.9403625177, 182774.7313639816], 
processed observation next is [1.0, 0.5217391304347826, 0.8863636363636364, 0.545, 1.0, 1.0, 0.749180439970964, 0.0, 0.5, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.33790923717130283, 0.33790923717130283, 0.4457920277170283], 
reward next is 0.5542, 
noisyNet noise sample is [array([0.1284149], dtype=float32), 1.3105513]. 
=============================================
[2019-03-23 10:16:29,780] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[27.044003]
 [26.17146 ]
 [26.235954]
 [26.286938]
 [26.418755]], R is [[30.44628906]
 [30.60456085]
 [30.68934441]
 [30.76121712]
 [30.81834793]].
[2019-03-23 10:16:31,221] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0994843e-22 1.0000000e+00 2.1856205e-35 1.4726576e-17 7.8801548e-35], sum to 1.0000
[2019-03-23 10:16:31,228] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3607
[2019-03-23 10:16:31,231] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 65.0, 1.0, 2.0, 0.48799212993413, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 556751.18094839, 556751.18094839, 140184.0664129876], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4392000.0000, 
sim time next is 4392600.0000, 
raw observation next is [25.71666666666667, 66.16666666666667, 1.0, 2.0, 0.4887500771652356, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 557643.9623406285, 557643.9623406285, 140176.1758741798], 
processed observation next is [1.0, 0.8695652173913043, 0.8053030303030304, 0.6616666666666667, 1.0, 1.0, 0.3609375964565445, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20653480086689943, 0.20653480086689943, 0.34189311188824345], 
reward next is 0.6581, 
noisyNet noise sample is [array([-0.875526], dtype=float32), -0.48590517]. 
=============================================
[2019-03-23 10:16:32,589] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.2141514e-27 1.0000000e+00 2.1950002e-38 1.8402232e-21 4.1542706e-38], sum to 1.0000
[2019-03-23 10:16:32,596] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7800
[2019-03-23 10:16:32,602] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333334, 76.66666666666667, 1.0, 2.0, 0.4551952032457304, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 519183.3614703926, 519183.3614703923, 134958.5873680001], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4440000.0000, 
sim time next is 4440600.0000, 
raw observation next is [23.5, 76.0, 1.0, 2.0, 0.4575455761834382, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 521923.8685967285, 521923.8685967283, 135351.0051755031], 
processed observation next is [0.0, 0.391304347826087, 0.7045454545454546, 0.76, 1.0, 1.0, 0.32193197022929776, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19330513651730685, 0.19330513651730677, 0.3301244028670807], 
reward next is 0.6699, 
noisyNet noise sample is [array([0.27443677], dtype=float32), -0.8318586]. 
=============================================
[2019-03-23 10:16:33,373] A3C_AGENT_WORKER-Thread-9 INFO:Local step 74000, global step 1179126: loss 0.2448
[2019-03-23 10:16:33,377] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 74000, global step 1179127: learning rate 0.0005
[2019-03-23 10:16:35,956] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.7885934e-28 1.0000000e+00 0.0000000e+00 2.5852929e-26 0.0000000e+00], sum to 1.0000
[2019-03-23 10:16:35,962] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5783
[2019-03-23 10:16:35,966] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 83.0, 1.0, 2.0, 0.4664878202288025, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 532132.0540916529, 532132.0540916529, 136320.9984997625], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4480200.0000, 
sim time next is 4480800.0000, 
raw observation next is [22.33333333333334, 84.66666666666667, 1.0, 2.0, 0.4677267504842296, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 533591.2726643878, 533591.2726643878, 136582.997544167], 
processed observation next is [0.0, 0.8695652173913043, 0.6515151515151518, 0.8466666666666667, 1.0, 1.0, 0.334658438105287, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1976263972831066, 0.1976263972831066, 0.33312926230284634], 
reward next is 0.6669, 
noisyNet noise sample is [array([-0.06941905], dtype=float32), 1.9958675]. 
=============================================
[2019-03-23 10:16:37,487] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.25393236e-29 1.00000000e+00 0.00000000e+00 1.68771918e-27
 0.00000000e+00], sum to 1.0000
[2019-03-23 10:16:37,496] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6883
[2019-03-23 10:16:37,502] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666667, 69.66666666666666, 1.0, 2.0, 0.3878812418472717, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 438551.6346627735, 438551.6346627735, 124597.6792095668], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4546200.0000, 
sim time next is 4546800.0000, 
raw observation next is [23.0, 69.0, 1.0, 2.0, 0.3961901221241494, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 448737.5953562265, 448737.5953562265, 125848.7315700547], 
processed observation next is [0.0, 0.6521739130434783, 0.6818181818181818, 0.69, 1.0, 1.0, 0.2452376526551867, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.166199109391195, 0.166199109391195, 0.30694812578062125], 
reward next is 0.6931, 
noisyNet noise sample is [array([0.05911709], dtype=float32), 1.0681616]. 
=============================================
[2019-03-23 10:16:40,704] A3C_AGENT_WORKER-Thread-13 INFO:Local step 74000, global step 1182850: loss 0.0008
[2019-03-23 10:16:40,705] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 74000, global step 1182850: learning rate 0.0005
[2019-03-23 10:16:40,769] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.7305694e-26 1.0000000e+00 5.8732992e-37 1.7634869e-19 3.0232593e-36], sum to 1.0000
[2019-03-23 10:16:40,777] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4143
[2019-03-23 10:16:40,790] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1098794.840906345 W.
[2019-03-23 10:16:40,796] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.0, 95.0, 1.0, 2.0, 0.9624835210121118, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1098794.840906345, 1098794.840906345, 208815.1713416808], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4795800.0000, 
sim time next is 4796400.0000, 
raw observation next is [21.0, 96.0, 1.0, 2.0, 0.3826237927028314, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7720711387617928, 6.911200000000001, 6.9112, 77.32846344354104, 873490.0768588518, 873490.0768588516, 215617.2830048983], 
processed observation next is [1.0, 0.5217391304347826, 0.5909090909090909, 0.96, 1.0, 1.0, 0.22827974087853925, 0.0, 1.0, -0.25, 1.0, 0.5, 0.6743873410882755, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.32351484328105623, 0.3235148432810561, 0.525895812207069], 
reward next is 0.4741, 
noisyNet noise sample is [array([0.9350847], dtype=float32), 1.0398238]. 
=============================================
[2019-03-23 10:16:42,909] A3C_AGENT_WORKER-Thread-16 INFO:Local step 74000, global step 1183961: loss 0.0042
[2019-03-23 10:16:42,911] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 74000, global step 1183961: learning rate 0.0005
[2019-03-23 10:16:42,993] A3C_AGENT_WORKER-Thread-21 INFO:Local step 74000, global step 1184003: loss 0.0026
[2019-03-23 10:16:42,995] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 74000, global step 1184003: learning rate 0.0005
[2019-03-23 10:16:43,153] A3C_AGENT_WORKER-Thread-2 INFO:Local step 74000, global step 1184078: loss 0.0002
[2019-03-23 10:16:43,156] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 74000, global step 1184078: learning rate 0.0005
[2019-03-23 10:16:43,306] A3C_AGENT_WORKER-Thread-17 INFO:Local step 74000, global step 1184158: loss 0.0091
[2019-03-23 10:16:43,308] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 74000, global step 1184158: learning rate 0.0005
[2019-03-23 10:16:43,588] A3C_AGENT_WORKER-Thread-12 INFO:Local step 74000, global step 1184284: loss 0.0001
[2019-03-23 10:16:43,590] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 74000, global step 1184285: learning rate 0.0005
[2019-03-23 10:16:43,764] A3C_AGENT_WORKER-Thread-10 INFO:Local step 74000, global step 1184373: loss 0.0021
[2019-03-23 10:16:43,769] A3C_AGENT_WORKER-Thread-14 INFO:Local step 74000, global step 1184374: loss 0.0023
[2019-03-23 10:16:43,770] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 74000, global step 1184374: learning rate 0.0005
[2019-03-23 10:16:43,771] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 74000, global step 1184374: learning rate 0.0005
[2019-03-23 10:16:43,887] A3C_AGENT_WORKER-Thread-3 INFO:Local step 74000, global step 1184433: loss 0.0000
[2019-03-23 10:16:43,890] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 74000, global step 1184434: learning rate 0.0005
[2019-03-23 10:16:43,905] A3C_AGENT_WORKER-Thread-11 INFO:Local step 74000, global step 1184440: loss 0.0000
[2019-03-23 10:16:43,907] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 74000, global step 1184440: learning rate 0.0005
[2019-03-23 10:16:43,957] A3C_AGENT_WORKER-Thread-22 INFO:Local step 74000, global step 1184465: loss 0.0028
[2019-03-23 10:16:43,958] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 74000, global step 1184466: learning rate 0.0005
[2019-03-23 10:16:43,994] A3C_AGENT_WORKER-Thread-20 INFO:Local step 74000, global step 1184479: loss 0.0079
[2019-03-23 10:16:43,997] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 74000, global step 1184481: learning rate 0.0005
[2019-03-23 10:16:44,127] A3C_AGENT_WORKER-Thread-15 INFO:Local step 74000, global step 1184551: loss 0.0026
[2019-03-23 10:16:44,129] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 74000, global step 1184551: learning rate 0.0005
[2019-03-23 10:16:45,127] A3C_AGENT_WORKER-Thread-19 INFO:Local step 74000, global step 1185054: loss 0.0000
[2019-03-23 10:16:45,130] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 74000, global step 1185054: learning rate 0.0005
[2019-03-23 10:16:45,280] A3C_AGENT_WORKER-Thread-18 INFO:Local step 74000, global step 1185131: loss 0.0206
[2019-03-23 10:16:45,282] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 74000, global step 1185131: learning rate 0.0005
[2019-03-23 10:16:46,888] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.2478798e-28 1.0000000e+00 0.0000000e+00 5.5428449e-25 0.0000000e+00], sum to 1.0000
[2019-03-23 10:16:46,894] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7764
[2019-03-23 10:16:46,898] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.380623006816237, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 427324.1392549683, 427324.139254968, 122314.0905538214], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4770000.0000, 
sim time next is 4770600.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.3739746812178723, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 419842.3906121263, 419842.390612126, 121736.4368353642], 
processed observation next is [1.0, 0.21739130434782608, 0.45454545454545453, 1.0, 1.0, 1.0, 0.21746835152234037, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15549718170819493, 0.15549718170819482, 0.2969181386228395], 
reward next is 0.7031, 
noisyNet noise sample is [array([0.3107064], dtype=float32), 1.738624]. 
=============================================
[2019-03-23 10:16:49,324] A3C_AGENT_WORKER-Thread-9 INFO:Local step 74500, global step 1187166: loss 1.9482
[2019-03-23 10:16:49,330] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 74500, global step 1187168: learning rate 0.0005
[2019-03-23 10:16:52,814] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.1948458e-30 1.0000000e+00 0.0000000e+00 1.0130328e-27 0.0000000e+00], sum to 1.0000
[2019-03-23 10:16:52,822] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0380
[2019-03-23 10:16:52,827] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 100.0, 1.0, 2.0, 0.2394541498462081, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 259994.2629017013, 259994.262901701, 82213.55689583447], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5023200.0000, 
sim time next is 5023800.0000, 
raw observation next is [14.0, 100.0, 1.0, 2.0, 0.2396032199161574, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 260156.1633263934, 260156.1633263934, 82221.0953935364], 
processed observation next is [0.0, 0.13043478260869565, 0.2727272727272727, 1.0, 1.0, 1.0, 0.049504024895196744, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09635413456533089, 0.09635413456533089, 0.20053925705740583], 
reward next is 0.7995, 
noisyNet noise sample is [array([-0.11277636], dtype=float32), 1.6078624]. 
=============================================
[2019-03-23 10:16:56,395] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.5719603e-23 1.0000000e+00 4.6911688e-36 7.1478825e-22 5.2850800e-35], sum to 1.0000
[2019-03-23 10:16:56,401] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6114
[2019-03-23 10:16:56,406] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 94.0, 1.0, 2.0, 0.3479112022600844, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 380854.8171019695, 380854.8171019692, 115569.7851346001], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4952400.0000, 
sim time next is 4953000.0000, 
raw observation next is [17.0, 94.0, 1.0, 2.0, 0.3272307530019253, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 358105.303235538, 358105.3032355377, 114019.6617950543], 
processed observation next is [1.0, 0.30434782608695654, 0.4090909090909091, 0.94, 1.0, 1.0, 0.15903844125240657, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13263159379094, 0.1326315937909399, 0.2780967360854983], 
reward next is 0.7219, 
noisyNet noise sample is [array([-0.06716838], dtype=float32), -0.90512764]. 
=============================================
[2019-03-23 10:16:56,421] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[65.405624]
 [65.281525]
 [65.45206 ]
 [65.629745]
 [65.70227 ]], R is [[65.65859222]
 [65.72013092]
 [65.77471161]
 [65.83231354]
 [65.89453888]].
[2019-03-23 10:16:56,584] A3C_AGENT_WORKER-Thread-13 INFO:Local step 74500, global step 1190809: loss 0.9852
[2019-03-23 10:16:56,587] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 74500, global step 1190810: learning rate 0.0005
[2019-03-23 10:16:57,623] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [8.3925847e-25 1.0000000e+00 0.0000000e+00 3.0592450e-22 1.3839211e-37], sum to 1.0000
[2019-03-23 10:16:57,629] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2624
[2019-03-23 10:16:57,635] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.83333333333333, 88.00000000000001, 1.0, 2.0, 0.4279761139650838, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 486594.7272225847, 486594.7272225849, 130213.9539441875], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4914600.0000, 
sim time next is 4915200.0000, 
raw observation next is [20.66666666666667, 88.0, 1.0, 2.0, 0.4233411535842916, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 480886.4386862759, 480886.4386862762, 129391.5625358769], 
processed observation next is [1.0, 0.9130434782608695, 0.575757575757576, 0.88, 1.0, 1.0, 0.27917644198036445, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17810608840232442, 0.17810608840232453, 0.3155891769167729], 
reward next is 0.6844, 
noisyNet noise sample is [array([-0.45809728], dtype=float32), 1.1174891]. 
=============================================
[2019-03-23 10:16:58,927] A3C_AGENT_WORKER-Thread-16 INFO:Local step 74500, global step 1191932: loss 0.1435
[2019-03-23 10:16:58,935] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 74500, global step 1191934: learning rate 0.0005
[2019-03-23 10:16:58,977] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.4375121e-27 1.0000000e+00 0.0000000e+00 7.9728836e-22 3.5807561e-37], sum to 1.0000
[2019-03-23 10:16:58,983] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6588
[2019-03-23 10:16:58,993] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.33333333333334, 98.0, 1.0, 2.0, 0.311023979006378, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 338519.8533323131, 338519.8533323128, 112211.5530482481], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4947600.0000, 
sim time next is 4948200.0000, 
raw observation next is [16.5, 97.0, 1.0, 2.0, 0.3110726353921776, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 338986.244332385, 338986.2443323847, 112360.0572080208], 
processed observation next is [1.0, 0.2608695652173913, 0.38636363636363635, 0.97, 1.0, 1.0, 0.138840794240222, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1255504608638463, 0.1255504608638462, 0.27404892001956294], 
reward next is 0.7260, 
noisyNet noise sample is [array([-0.89679116], dtype=float32), 0.04449458]. 
=============================================
[2019-03-23 10:16:59,109] A3C_AGENT_WORKER-Thread-21 INFO:Local step 74500, global step 1192017: loss 0.0053
[2019-03-23 10:16:59,111] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 74500, global step 1192017: learning rate 0.0005
[2019-03-23 10:16:59,281] A3C_AGENT_WORKER-Thread-2 INFO:Local step 74500, global step 1192108: loss 0.1942
[2019-03-23 10:16:59,284] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 74500, global step 1192109: learning rate 0.0005
[2019-03-23 10:16:59,376] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.2220886e-23 1.0000000e+00 3.4774561e-35 1.0043590e-21 1.7966494e-35], sum to 1.0000
[2019-03-23 10:16:59,378] A3C_AGENT_WORKER-Thread-17 INFO:Local step 74500, global step 1192159: loss 0.2360
[2019-03-23 10:16:59,379] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 74500, global step 1192159: learning rate 0.0005
[2019-03-23 10:16:59,385] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9380
[2019-03-23 10:16:59,390] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.5, 68.0, 1.0, 2.0, 0.5672158981719984, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 641281.836714176, 641281.836714176, 153475.5388635244], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5146200.0000, 
sim time next is 5146800.0000, 
raw observation next is [27.66666666666666, 67.33333333333334, 1.0, 2.0, 0.5678783334034964, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 641775.3716497252, 641775.3716497252, 153637.9433136864], 
processed observation next is [0.0, 0.5652173913043478, 0.8939393939393937, 0.6733333333333335, 1.0, 1.0, 0.4598479167543704, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23769458209249084, 0.23769458209249084, 0.37472669100899125], 
reward next is 0.6253, 
noisyNet noise sample is [array([2.330283], dtype=float32), -0.72419035]. 
=============================================
[2019-03-23 10:16:59,586] A3C_AGENT_WORKER-Thread-12 INFO:Local step 74500, global step 1192267: loss 0.1642
[2019-03-23 10:16:59,586] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 74500, global step 1192267: learning rate 0.0005
[2019-03-23 10:16:59,709] A3C_AGENT_WORKER-Thread-3 INFO:Local step 74500, global step 1192328: loss 0.4971
[2019-03-23 10:16:59,713] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 74500, global step 1192329: learning rate 0.0005
[2019-03-23 10:16:59,825] A3C_AGENT_WORKER-Thread-11 INFO:Local step 74500, global step 1192394: loss 0.9483
[2019-03-23 10:16:59,827] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 74500, global step 1192395: learning rate 0.0005
[2019-03-23 10:16:59,887] A3C_AGENT_WORKER-Thread-10 INFO:Local step 74500, global step 1192423: loss 1.0484
[2019-03-23 10:16:59,890] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 74500, global step 1192424: learning rate 0.0005
[2019-03-23 10:16:59,909] A3C_AGENT_WORKER-Thread-22 INFO:Local step 74500, global step 1192436: loss 1.0904
[2019-03-23 10:16:59,911] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 74500, global step 1192436: learning rate 0.0005
[2019-03-23 10:16:59,960] A3C_AGENT_WORKER-Thread-14 INFO:Local step 74500, global step 1192465: loss 1.0435
[2019-03-23 10:16:59,961] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 74500, global step 1192466: learning rate 0.0005
[2019-03-23 10:17:00,084] A3C_AGENT_WORKER-Thread-20 INFO:Local step 74500, global step 1192529: loss 0.8891
[2019-03-23 10:17:00,086] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 74500, global step 1192529: learning rate 0.0005
[2019-03-23 10:17:00,257] A3C_AGENT_WORKER-Thread-15 INFO:Local step 74500, global step 1192622: loss 0.9297
[2019-03-23 10:17:00,259] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 74500, global step 1192622: learning rate 0.0005
[2019-03-23 10:17:01,153] A3C_AGENT_WORKER-Thread-19 INFO:Local step 74500, global step 1193103: loss 0.4212
[2019-03-23 10:17:01,153] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 74500, global step 1193103: learning rate 0.0005
[2019-03-23 10:17:01,192] A3C_AGENT_WORKER-Thread-18 INFO:Local step 74500, global step 1193127: loss 0.4078
[2019-03-23 10:17:01,195] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 74500, global step 1193127: learning rate 0.0005
[2019-03-23 10:17:04,896] A3C_AGENT_WORKER-Thread-9 INFO:Local step 75000, global step 1195094: loss 0.0785
[2019-03-23 10:17:04,898] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 75000, global step 1195094: learning rate 0.0005
[2019-03-23 10:17:08,586] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0459653e-24 1.0000000e+00 4.8403409e-36 2.1090334e-25 2.7729020e-36], sum to 1.0000
[2019-03-23 10:17:08,597] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7182
[2019-03-23 10:17:08,606] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 83.0, 1.0, 2.0, 0.3991831469852676, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 452355.8931000904, 452355.8931000904, 126276.5005001043], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5119200.0000, 
sim time next is 5119800.0000, 
raw observation next is [21.16666666666667, 83.0, 1.0, 2.0, 0.4015564066534231, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 455439.5695801688, 455439.5695801688, 126771.0639023163], 
processed observation next is [0.0, 0.2608695652173913, 0.5984848484848487, 0.83, 1.0, 1.0, 0.25194550831677887, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1686813220667292, 0.1686813220667292, 0.3091977168349178], 
reward next is 0.6908, 
noisyNet noise sample is [array([0.27953205], dtype=float32), -0.78157985]. 
=============================================
[2019-03-23 10:17:10,382] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.6392904e-27 1.0000000e+00 1.5377209e-38 8.7680937e-23 6.8487117e-38], sum to 1.0000
[2019-03-23 10:17:10,388] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1947
[2019-03-23 10:17:10,396] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.93333333333333, 79.66666666666667, 1.0, 2.0, 0.4624986099105453, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 527594.4086957108, 527594.4086957106, 135930.1338090384], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5361600.0000, 
sim time next is 5362200.0000, 
raw observation next is [22.75, 80.0, 1.0, 2.0, 0.4584245981881368, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 522824.5514198895, 522824.5514198895, 135207.3185086852], 
processed observation next is [1.0, 0.043478260869565216, 0.6704545454545454, 0.8, 1.0, 1.0, 0.323030747735171, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19363872274810723, 0.19363872274810723, 0.329773947582159], 
reward next is 0.6702, 
noisyNet noise sample is [array([0.27811074], dtype=float32), 1.2067065]. 
=============================================
[2019-03-23 10:17:10,621] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.937938e-28 1.000000e+00 0.000000e+00 3.850887e-25 0.000000e+00], sum to 1.0000
[2019-03-23 10:17:10,634] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2839
[2019-03-23 10:17:10,637] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 81.33333333333333, 1.0, 2.0, 0.4662716072978075, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 532027.1963674589, 532027.1963674589, 136833.6169174108], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5172000.0000, 
sim time next is 5172600.0000, 
raw observation next is [23.0, 82.16666666666667, 1.0, 2.0, 0.4705118056752835, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 536889.3191656884, 536889.3191656884, 137538.9808057231], 
processed observation next is [0.0, 0.8695652173913043, 0.6818181818181818, 0.8216666666666668, 1.0, 1.0, 0.3381397570941043, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.198847895987292, 0.198847895987292, 0.3354609287944466], 
reward next is 0.6645, 
noisyNet noise sample is [array([-1.8247011], dtype=float32), -0.9482296]. 
=============================================
[2019-03-23 10:17:11,857] A3C_AGENT_WORKER-Thread-13 INFO:Local step 75000, global step 1198801: loss 0.0005
[2019-03-23 10:17:11,862] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 75000, global step 1198801: learning rate 0.0005
[2019-03-23 10:17:13,211] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.3634465e-23 1.0000000e+00 5.5570256e-34 2.5648992e-19 3.3120185e-33], sum to 1.0000
[2019-03-23 10:17:13,217] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3753
[2019-03-23 10:17:13,221] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.00000000000001, 1.0, 2.0, 0.8545503378277118, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 974716.1770468085, 974716.1770468088, 193331.2109259053], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5231400.0000, 
sim time next is 5232000.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.8461526386069667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 965115.2398041103, 965115.2398041103, 191922.6191381111], 
processed observation next is [1.0, 0.5652173913043478, 0.6363636363636364, 0.94, 1.0, 1.0, 0.8076907982587084, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3574500888163371, 0.3574500888163371, 0.46810394911734415], 
reward next is 0.5319, 
noisyNet noise sample is [array([0.3839796], dtype=float32), 0.3529345]. 
=============================================
[2019-03-23 10:17:13,236] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[59.97547 ]
 [60.41365 ]
 [60.745735]
 [60.87137 ]
 [60.778473]], R is [[59.8180275 ]
 [59.74831009]
 [59.69854736]
 [59.68001938]
 [59.67546082]].
[2019-03-23 10:17:13,877] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.2101131e-25 1.0000000e+00 1.1391607e-36 9.1990547e-23 6.0879386e-36], sum to 1.0000
[2019-03-23 10:17:13,886] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0995
[2019-03-23 10:17:13,894] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 87.0, 1.0, 2.0, 0.3653427537620773, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 409682.1742347017, 409682.1742347014, 120777.8684153927], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5295000.0000, 
sim time next is 5295600.0000, 
raw observation next is [19.4, 87.0, 1.0, 2.0, 0.3708489315898937, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 415867.6929327928, 415867.6929327928, 121245.4338863126], 
processed observation next is [1.0, 0.30434782608695654, 0.5181818181818181, 0.87, 1.0, 1.0, 0.2135611644873671, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15402507145658995, 0.15402507145658995, 0.29572057045442096], 
reward next is 0.7043, 
noisyNet noise sample is [array([-1.5217143], dtype=float32), -1.8415289]. 
=============================================
[2019-03-23 10:17:14,025] A3C_AGENT_WORKER-Thread-16 INFO:Local step 75000, global step 1199945: loss 0.0807
[2019-03-23 10:17:14,027] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 75000, global step 1199945: learning rate 0.0005
[2019-03-23 10:17:14,028] A3C_AGENT_WORKER-Thread-21 INFO:Local step 75000, global step 1199946: loss 0.0947
[2019-03-23 10:17:14,034] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 75000, global step 1199947: learning rate 0.0005
[2019-03-23 10:17:14,135] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-23 10:17:14,141] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 10:17:14,142] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 10:17:14,143] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:17:14,144] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:17:14,144] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 10:17:14,145] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 10:17:14,146] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 10:17:14,146] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:17:14,147] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:17:14,147] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:17:14,163] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run49
[2019-03-23 10:17:14,185] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run49
[2019-03-23 10:17:14,211] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run49
[2019-03-23 10:17:14,212] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run49
[2019-03-23 10:17:14,266] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run49
[2019-03-23 10:17:18,348] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.03883795], dtype=float32), -1.171504]
[2019-03-23 10:17:18,349] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [14.758650365, 100.0, 1.0, 2.0, 0.240800053596342, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 261442.6072742396, 261442.6072742399, 92756.11316649665]
[2019-03-23 10:17:18,349] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 10:17:18,351] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [8.7649035e-26 1.0000000e+00 7.5650017e-38 3.6809992e-23 2.5846374e-37], sampled 0.8050136755844859
[2019-03-23 10:17:18,699] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.03883795], dtype=float32), -1.171504]
[2019-03-23 10:17:18,700] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.0262666, 45.71681236000001, 1.0, 2.0, 0.2497327469581947, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 271143.2421902279, 271143.2421902279, 83835.80344570724]
[2019-03-23 10:17:18,701] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 10:17:18,704] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [9.0198418e-26 1.0000000e+00 7.8935311e-38 3.7770130e-23 2.6953185e-37], sampled 0.37020814991124096
[2019-03-23 10:17:28,213] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.03883795], dtype=float32), -1.171504]
[2019-03-23 10:17:28,213] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.05, 85.5, 1.0, 2.0, 0.4583368944203815, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 520620.3972013193, 520620.397201319, 137218.2242085449]
[2019-03-23 10:17:28,215] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 10:17:28,217] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [9.0674495e-26 1.0000000e+00 7.9556837e-38 3.7948343e-23 2.7162095e-37], sampled 0.492247588838882
[2019-03-23 10:17:37,413] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.03883795], dtype=float32), -1.171504]
[2019-03-23 10:17:37,413] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [25.85, 46.0, 1.0, 2.0, 0.3701040816679368, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 414445.8411297915, 414445.8411297915, 125228.0118710579]
[2019-03-23 10:17:37,415] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 10:17:37,418] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [9.0699406e-26 1.0000000e+00 7.9587195e-38 3.7958478e-23 2.7172457e-37], sampled 0.37480104470896203
[2019-03-23 10:17:53,102] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.03883795], dtype=float32), -1.171504]
[2019-03-23 10:17:53,103] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.5, 53.0, 1.0, 2.0, 0.2851168178852538, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 309570.8119156136, 309570.8119156136, 105470.034728642]
[2019-03-23 10:17:53,104] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 10:17:53,107] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [9.0699406e-26 1.0000000e+00 7.9587195e-38 3.7958478e-23 2.7172457e-37], sampled 0.6916854374371003
[2019-03-23 10:18:02,272] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.03883795], dtype=float32), -1.171504]
[2019-03-23 10:18:02,274] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.25186283666667, 100.0, 1.0, 2.0, 0.3008705958215758, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 327623.6354711759, 327623.6354711755, 115890.6331414709]
[2019-03-23 10:18:02,275] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 10:18:02,277] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.1988797e-25 1.0000000e+00 1.2040974e-37 4.8761225e-23 4.0871684e-37], sampled 0.9502595460744515
[2019-03-23 10:18:19,154] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.03883795], dtype=float32), -1.171504]
[2019-03-23 10:18:19,155] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [25.69169883, 65.76145342666666, 1.0, 2.0, 0.4747720120850267, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 541691.268430092, 541691.268430092, 142532.2032236649]
[2019-03-23 10:18:19,156] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 10:18:19,159] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [8.8100571e-26 1.0000000e+00 7.6229392e-38 3.6980291e-23 2.6041538e-37], sampled 0.3410885282910978
[2019-03-23 10:18:29,179] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.03883795], dtype=float32), -1.171504]
[2019-03-23 10:18:29,180] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.2, 85.66666666666667, 1.0, 2.0, 0.3734614671521333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 416958.8043161416, 416958.8043161416, 124948.300142135]
[2019-03-23 10:18:29,182] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 10:18:29,184] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [8.6045607e-26 1.0000000e+00 7.3606117e-38 3.6204901e-23 2.5157655e-37], sampled 0.3002122488984177
[2019-03-23 10:18:41,228] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.03883795], dtype=float32), -1.171504]
[2019-03-23 10:18:41,230] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.95, 81.0, 1.0, 2.0, 0.4754227475735319, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 542371.0079068289, 542371.0079068289, 141915.0931055981]
[2019-03-23 10:18:41,231] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 10:18:41,234] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.5623639e-25 1.0000000e+00 1.7813608e-37 6.1865400e-23 6.0158384e-37], sampled 0.36988938641179714
[2019-03-23 10:18:41,963] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.03883795], dtype=float32), -1.171504]
[2019-03-23 10:18:41,965] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.96666666666667, 77.66666666666667, 1.0, 2.0, 0.3653534139559729, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 406625.2212809577, 406625.2212809574, 123727.2836147006]
[2019-03-23 10:18:41,966] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 10:18:41,969] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [9.1583891e-26 1.0000000e+00 8.0745581e-38 3.8289772e-23 2.7561644e-37], sampled 0.4764795228751174
[2019-03-23 10:18:53,426] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 10:18:53,472] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 10:18:53,528] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 10:18:53,539] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 10:18:53,817] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 10:18:54,832] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 1200000, evaluation results [1200000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 10:18:54,931] A3C_AGENT_WORKER-Thread-2 INFO:Local step 75000, global step 1200052: loss 0.0248
[2019-03-23 10:18:54,935] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 75000, global step 1200053: learning rate 0.0005
[2019-03-23 10:18:55,200] A3C_AGENT_WORKER-Thread-17 INFO:Local step 75000, global step 1200182: loss 0.0098
[2019-03-23 10:18:55,202] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 75000, global step 1200182: learning rate 0.0005
[2019-03-23 10:18:55,540] A3C_AGENT_WORKER-Thread-11 INFO:Local step 75000, global step 1200359: loss 0.0066
[2019-03-23 10:18:55,542] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 75000, global step 1200359: learning rate 0.0005
[2019-03-23 10:18:55,570] A3C_AGENT_WORKER-Thread-10 INFO:Local step 75000, global step 1200373: loss 0.0183
[2019-03-23 10:18:55,571] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 75000, global step 1200374: learning rate 0.0005
[2019-03-23 10:18:55,583] A3C_AGENT_WORKER-Thread-12 INFO:Local step 75000, global step 1200382: loss 0.0205
[2019-03-23 10:18:55,585] A3C_AGENT_WORKER-Thread-3 INFO:Local step 75000, global step 1200382: loss 0.0222
[2019-03-23 10:18:55,587] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 75000, global step 1200382: learning rate 0.0005
[2019-03-23 10:18:55,588] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 75000, global step 1200382: learning rate 0.0005
[2019-03-23 10:18:55,621] A3C_AGENT_WORKER-Thread-22 INFO:Local step 75000, global step 1200397: loss 0.0137
[2019-03-23 10:18:55,622] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 75000, global step 1200397: learning rate 0.0005
[2019-03-23 10:18:55,648] A3C_AGENT_WORKER-Thread-20 INFO:Local step 75000, global step 1200410: loss 0.0093
[2019-03-23 10:18:55,650] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 75000, global step 1200410: learning rate 0.0005
[2019-03-23 10:18:55,866] A3C_AGENT_WORKER-Thread-14 INFO:Local step 75000, global step 1200522: loss 0.0006
[2019-03-23 10:18:55,868] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 75000, global step 1200523: learning rate 0.0005
[2019-03-23 10:18:56,267] A3C_AGENT_WORKER-Thread-15 INFO:Local step 75000, global step 1200724: loss 0.0057
[2019-03-23 10:18:56,268] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 75000, global step 1200724: learning rate 0.0005
[2019-03-23 10:18:56,706] A3C_AGENT_WORKER-Thread-19 INFO:Local step 75000, global step 1200945: loss 0.0094
[2019-03-23 10:18:56,711] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 75000, global step 1200948: learning rate 0.0005
[2019-03-23 10:18:57,049] A3C_AGENT_WORKER-Thread-18 INFO:Local step 75000, global step 1201124: loss 0.0633
[2019-03-23 10:18:57,051] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 75000, global step 1201124: learning rate 0.0005
[2019-03-23 10:18:57,131] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.1389378e-26 1.0000000e+00 1.3528371e-38 2.0749426e-25 0.0000000e+00], sum to 1.0000
[2019-03-23 10:18:57,140] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2088
[2019-03-23 10:18:57,144] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.00000000000001, 1.0, 2.0, 0.502438074223152, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 572998.042733782, 572998.042733782, 142376.7688173873], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5256600.0000, 
sim time next is 5257200.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.5004321766112255, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 570709.9738494479, 570709.9738494479, 142140.2296532245], 
processed observation next is [1.0, 0.8695652173913043, 0.6363636363636364, 0.94, 1.0, 1.0, 0.3755402207640319, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21137406438868442, 0.21137406438868442, 0.34668348695908413], 
reward next is 0.6533, 
noisyNet noise sample is [array([-0.37636432], dtype=float32), -1.1971037]. 
=============================================
[2019-03-23 10:19:00,302] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.1522464e-19 1.0000000e+00 1.5338503e-28 6.0854867e-18 3.0925350e-28], sum to 1.0000
[2019-03-23 10:19:00,309] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7997
[2019-03-23 10:19:00,312] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.61666666666667, 63.0, 1.0, 2.0, 0.8914770536246878, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1006222.683447001, 1006222.683447001, 205215.1196095294], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5403000.0000, 
sim time next is 5403600.0000, 
raw observation next is [28.8, 63.0, 1.0, 2.0, 1.008237282440648, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.08778400258549, 6.9112, 77.32811306622192, 1193555.631773042, 1136205.019359051, 228267.5714056086], 
processed observation next is [1.0, 0.5652173913043478, 0.9454545454545454, 0.63, 1.0, 1.0, 1.01029660305081, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.017658400258549013, 0.0, 0.5084265092162159, 0.442057641397423, 0.4208166738366856, 0.556750174160021], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6604289], dtype=float32), -0.7896438]. 
=============================================
[2019-03-23 10:19:01,216] A3C_AGENT_WORKER-Thread-9 INFO:Local step 75500, global step 1203236: loss 0.0605
[2019-03-23 10:19:01,218] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 75500, global step 1203236: learning rate 0.0005
[2019-03-23 10:19:03,954] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.1021126e-24 1.0000000e+00 2.7385304e-34 1.3829100e-19 7.3539228e-33], sum to 1.0000
[2019-03-23 10:19:03,961] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3485
[2019-03-23 10:19:03,967] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.2, 80.5, 1.0, 2.0, 0.4695301264214009, 1.0, 2.0, 0.4695301264214009, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1071899.718277025, 1071899.718277025, 219965.2539641677], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5412600.0000, 
sim time next is 5413200.0000, 
raw observation next is [21.46666666666667, 83.66666666666667, 1.0, 2.0, 0.9098723794172741, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1037436.087210591, 1037436.087210591, 196769.6115764361], 
processed observation next is [1.0, 0.6521739130434783, 0.6121212121212122, 0.8366666666666667, 1.0, 1.0, 0.8873404742715926, 0.0, 0.5, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.38423558785577444, 0.38423558785577444, 0.4799258818937466], 
reward next is 0.5201, 
noisyNet noise sample is [array([-1.0821306], dtype=float32), 0.9711613]. 
=============================================
[2019-03-23 10:19:06,963] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.2171039e-26 1.0000000e+00 2.9965952e-38 2.4021897e-23 1.2268869e-36], sum to 1.0000
[2019-03-23 10:19:06,972] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1973
[2019-03-23 10:19:06,980] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 96.33333333333334, 1.0, 2.0, 0.3911685220501076, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 441137.0658699575, 441137.0658699572, 124242.1042926112], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5440200.0000, 
sim time next is 5440800.0000, 
raw observation next is [18.8, 95.66666666666667, 1.0, 2.0, 0.3897283972857394, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 439197.6405743325, 439197.6405743325, 123942.422193243], 
processed observation next is [1.0, 1.0, 0.49090909090909096, 0.9566666666666667, 1.0, 1.0, 0.2371604966071742, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16266579280530832, 0.16266579280530832, 0.3022985907152268], 
reward next is 0.6977, 
noisyNet noise sample is [array([-1.0715057], dtype=float32), 1.0820712]. 
=============================================
[2019-03-23 10:19:07,756] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.3990516e-09 9.9987209e-01 2.4406939e-15 1.2785752e-04 4.4366031e-15], sum to 1.0000
[2019-03-23 10:19:07,762] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6027
[2019-03-23 10:19:07,767] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1284229.616035425 W.
[2019-03-23 10:19:07,771] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.91666666666667, 69.83333333333333, 1.0, 2.0, 0.5678966297603475, 1.0, 2.0, 0.5678966297603475, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1284229.616035425, 1284229.616035425, 251382.4789783313], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5485800.0000, 
sim time next is 5486400.0000, 
raw observation next is [26.1, 69.0, 1.0, 2.0, 0.5287509421473479, 1.0, 2.0, 0.5287509421473479, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1195654.421044352, 1195654.421044352, 241128.3392906356], 
processed observation next is [1.0, 0.5217391304347826, 0.8227272727272728, 0.69, 1.0, 1.0, 0.4109386776841848, 1.0, 1.0, 0.4109386776841848, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.44283497075716743, 0.44283497075716743, 0.5881179007088673], 
reward next is 0.4119, 
noisyNet noise sample is [array([-2.6970904], dtype=float32), -1.2251945]. 
=============================================
[2019-03-23 10:19:08,370] A3C_AGENT_WORKER-Thread-13 INFO:Local step 75500, global step 1206802: loss 0.3187
[2019-03-23 10:19:08,372] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 75500, global step 1206802: learning rate 0.0005
[2019-03-23 10:19:09,548] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.5930944e-11 1.3135180e-03 7.9845701e-18 9.9868649e-01 4.3833048e-17], sum to 1.0000
[2019-03-23 10:19:09,558] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7676
[2019-03-23 10:19:09,565] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.9, 71.5, 1.0, 2.0, 0.8609124236493001, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9839054348276769, 6.911199999999999, 6.9112, 77.32846344354104, 1517908.827681769, 1517908.827681769, 324981.729954189], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5499000.0000, 
sim time next is 5499600.0000, 
raw observation next is [26.8, 72.33333333333333, 1.0, 2.0, 0.6243021016552935, 1.0, 1.0, 0.6243021016552935, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1404063.258307534, 1404063.258307534, 268923.4278345856], 
processed observation next is [1.0, 0.6521739130434783, 0.8545454545454546, 0.7233333333333333, 1.0, 1.0, 0.5303776270691168, 1.0, 0.5, 0.5303776270691168, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.5200234290027904, 0.5200234290027904, 0.6559107995965503], 
reward next is 0.3441, 
noisyNet noise sample is [array([-1.0204327], dtype=float32), -1.3129234]. 
=============================================
[2019-03-23 10:19:10,628] A3C_AGENT_WORKER-Thread-2 INFO:Local step 75500, global step 1207947: loss 0.1148
[2019-03-23 10:19:10,630] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 75500, global step 1207949: learning rate 0.0005
[2019-03-23 10:19:10,659] A3C_AGENT_WORKER-Thread-21 INFO:Local step 75500, global step 1207962: loss 0.1135
[2019-03-23 10:19:10,663] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 75500, global step 1207962: learning rate 0.0005
[2019-03-23 10:19:10,786] A3C_AGENT_WORKER-Thread-16 INFO:Local step 75500, global step 1208028: loss 0.0751
[2019-03-23 10:19:10,789] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 75500, global step 1208029: learning rate 0.0005
[2019-03-23 10:19:10,971] A3C_AGENT_WORKER-Thread-17 INFO:Local step 75500, global step 1208126: loss 0.0793
[2019-03-23 10:19:10,973] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 75500, global step 1208126: learning rate 0.0005
[2019-03-23 10:19:11,391] A3C_AGENT_WORKER-Thread-3 INFO:Local step 75500, global step 1208331: loss 0.0314
[2019-03-23 10:19:11,392] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 75500, global step 1208332: learning rate 0.0005
[2019-03-23 10:19:11,492] A3C_AGENT_WORKER-Thread-11 INFO:Local step 75500, global step 1208387: loss 0.0286
[2019-03-23 10:19:11,493] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 75500, global step 1208387: learning rate 0.0005
[2019-03-23 10:19:11,498] A3C_AGENT_WORKER-Thread-12 INFO:Local step 75500, global step 1208388: loss 0.0383
[2019-03-23 10:19:11,502] A3C_AGENT_WORKER-Thread-22 INFO:Local step 75500, global step 1208389: loss 0.0363
[2019-03-23 10:19:11,503] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 75500, global step 1208389: learning rate 0.0005
[2019-03-23 10:19:11,505] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 75500, global step 1208389: learning rate 0.0005
[2019-03-23 10:19:11,519] A3C_AGENT_WORKER-Thread-10 INFO:Local step 75500, global step 1208395: loss 0.0365
[2019-03-23 10:19:11,521] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 75500, global step 1208396: learning rate 0.0005
[2019-03-23 10:19:11,537] A3C_AGENT_WORKER-Thread-20 INFO:Local step 75500, global step 1208402: loss 0.0226
[2019-03-23 10:19:11,541] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 75500, global step 1208403: learning rate 0.0005
[2019-03-23 10:19:11,710] A3C_AGENT_WORKER-Thread-14 INFO:Local step 75500, global step 1208485: loss 0.1172
[2019-03-23 10:19:11,713] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 75500, global step 1208486: learning rate 0.0005
[2019-03-23 10:19:12,059] A3C_AGENT_WORKER-Thread-15 INFO:Local step 75500, global step 1208662: loss 0.1765
[2019-03-23 10:19:12,063] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 75500, global step 1208665: learning rate 0.0005
[2019-03-23 10:19:12,561] A3C_AGENT_WORKER-Thread-19 INFO:Local step 75500, global step 1208911: loss 0.2068
[2019-03-23 10:19:12,562] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 75500, global step 1208911: learning rate 0.0005
[2019-03-23 10:19:13,032] A3C_AGENT_WORKER-Thread-18 INFO:Local step 75500, global step 1209151: loss 0.3892
[2019-03-23 10:19:13,037] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 75500, global step 1209151: learning rate 0.0005
[2019-03-23 10:19:16,786] A3C_AGENT_WORKER-Thread-9 INFO:Local step 76000, global step 1211041: loss 0.0161
[2019-03-23 10:19:16,789] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 76000, global step 1211041: learning rate 0.0005
[2019-03-23 10:19:21,506] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.1687690e-20 1.0000000e+00 1.4703753e-29 1.0088922e-17 5.6824849e-30], sum to 1.0000
[2019-03-23 10:19:21,515] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3392
[2019-03-23 10:19:21,520] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.5, 62.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 212319.0148919458, 212319.0148919461, 69250.25654579702], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5734800.0000, 
sim time next is 5735400.0000, 
raw observation next is [15.78333333333333, 61.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 215113.5776730384, 215113.5776730381, 69970.268520895], 
processed observation next is [0.0, 0.391304347826087, 0.3537878787878786, 0.61, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07967169543445866, 0.07967169543445855, 0.17065919151437806], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.4486064], dtype=float32), -1.3783646]. 
=============================================
[2019-03-23 10:19:22,121] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.3652297e-20 1.0000000e+00 1.5818194e-31 4.4403120e-11 4.1902391e-31], sum to 1.0000
[2019-03-23 10:19:22,128] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1911
[2019-03-23 10:19:22,132] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.6, 44.0, 1.0, 2.0, 0.2637696549332583, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 286403.298783711, 286403.298783711, 85351.95854995919], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5754600.0000, 
sim time next is 5755200.0000, 
raw observation next is [21.6, 43.33333333333334, 1.0, 2.0, 0.2642285455751492, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 286901.7130519135, 286901.7130519138, 84779.33348799782], 
processed observation next is [0.0, 0.6086956521739131, 0.6181818181818183, 0.4333333333333334, 1.0, 1.0, 0.08028568196893647, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10625989372293092, 0.10625989372293103, 0.20677886216584834], 
reward next is 0.7932, 
noisyNet noise sample is [array([-1.8242841], dtype=float32), 0.39363107]. 
=============================================
[2019-03-23 10:19:23,117] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.2059526e-25 1.0000000e+00 2.0876170e-37 1.3734605e-22 1.9649837e-37], sum to 1.0000
[2019-03-23 10:19:23,122] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0676
[2019-03-23 10:19:23,127] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.66666666666667, 52.5, 1.0, 2.0, 0.2534744484480352, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 275221.5144522157, 275221.5144522155, 82446.5283090443], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5771400.0000, 
sim time next is 5772000.0000, 
raw observation next is [18.83333333333334, 56.0, 1.0, 2.0, 0.2450528602968915, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 266074.8873714529, 266074.8873714526, 80480.8286805382], 
processed observation next is [0.0, 0.8260869565217391, 0.4924242424242427, 0.56, 1.0, 1.0, 0.056316075371114355, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09854625458201959, 0.09854625458201947, 0.19629470409887365], 
reward next is 0.8037, 
noisyNet noise sample is [array([-0.29600424], dtype=float32), 1.648204]. 
=============================================
[2019-03-23 10:19:23,151] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[72.22977]
 [72.22977]
 [72.22977]
 [72.22977]
 [72.22977]], R is [[72.31117249]
 [72.38697052]
 [72.45796204]
 [72.5273819 ]
 [72.59522247]].
[2019-03-23 10:19:23,644] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.5780743e-26 1.0000000e+00 0.0000000e+00 3.6612032e-20 0.0000000e+00], sum to 1.0000
[2019-03-23 10:19:23,650] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3022
[2019-03-23 10:19:23,653] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.51666666666667, 62.33333333333334, 1.0, 2.0, 0.2099642904384584, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 227967.2921083194, 227967.2921083191, 72880.91350508589], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5782200.0000, 
sim time next is 5782800.0000, 
raw observation next is [16.43333333333334, 62.66666666666667, 1.0, 2.0, 0.2086893870927846, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 226582.7521120116, 226582.7521120113, 72674.34410681538], 
processed observation next is [0.0, 0.9565217391304348, 0.3833333333333337, 0.6266666666666667, 1.0, 1.0, 0.010861733865980723, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08391953781926356, 0.08391953781926345, 0.1772544978215009], 
reward next is 0.8227, 
noisyNet noise sample is [array([-2.9552586], dtype=float32), 2.721026]. 
=============================================
[2019-03-23 10:19:24,144] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.3702098e-27 1.0000000e+00 0.0000000e+00 4.1483797e-23 0.0000000e+00], sum to 1.0000
[2019-03-23 10:19:24,151] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7676
[2019-03-23 10:19:24,157] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 40.33333333333334, 1.0, 2.0, 0.4405308018469349, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 487683.035880072, 487683.0358800723, 124846.641053865], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5850600.0000, 
sim time next is 5851200.0000, 
raw observation next is [25.9, 40.66666666666667, 1.0, 2.0, 0.3432932622945538, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 379379.0878351167, 379379.0878351167, 116552.9933833359], 
processed observation next is [1.0, 0.7391304347826086, 0.8136363636363636, 0.40666666666666673, 1.0, 1.0, 0.17911657786819224, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14051077327226544, 0.14051077327226544, 0.28427559361789245], 
reward next is 0.7157, 
noisyNet noise sample is [array([0.33700863], dtype=float32), -0.07969039]. 
=============================================
[2019-03-23 10:19:24,405] A3C_AGENT_WORKER-Thread-13 INFO:Local step 76000, global step 1214816: loss 0.0539
[2019-03-23 10:19:24,408] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 76000, global step 1214817: learning rate 0.0005
[2019-03-23 10:19:25,957] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.2512463e-25 1.0000000e+00 1.0503296e-35 6.9367379e-24 2.2560050e-36], sum to 1.0000
[2019-03-23 10:19:25,967] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6788
[2019-03-23 10:19:25,973] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1182823.493693224 W.
[2019-03-23 10:19:25,978] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.16666666666667, 77.83333333333334, 1.0, 2.0, 0.5189521354174927, 1.0, 2.0, 0.5189521354174927, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1182823.493693224, 1182823.493693224, 234232.3704686107], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6022200.0000, 
sim time next is 6022800.0000, 
raw observation next is [22.7, 79.0, 1.0, 2.0, 0.5253323112225164, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9550376118539299, 6.934230331566791, 6.9112, 77.32840694646997, 1147968.133272074, 1140488.358095736, 256813.4963985372], 
processed observation next is [1.0, 0.7391304347826086, 0.6681818181818181, 0.79, 1.0, 1.0, 0.40666538902814553, 0.0, 0.5, -0.25, 1.0, 0.5, 0.9357680169341855, 0.002303033156679124, 0.0, 0.5084284414566743, 0.4251733826933607, 0.42240309559101336, 0.6263743814598468], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.14402999], dtype=float32), 0.090447396]. 
=============================================
[2019-03-23 10:19:26,702] A3C_AGENT_WORKER-Thread-2 INFO:Local step 76000, global step 1215978: loss 0.1107
[2019-03-23 10:19:26,706] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 76000, global step 1215979: learning rate 0.0005
[2019-03-23 10:19:26,772] A3C_AGENT_WORKER-Thread-16 INFO:Local step 76000, global step 1216011: loss 0.1149
[2019-03-23 10:19:26,775] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 76000, global step 1216011: learning rate 0.0005
[2019-03-23 10:19:26,934] A3C_AGENT_WORKER-Thread-21 INFO:Local step 76000, global step 1216094: loss 0.0677
[2019-03-23 10:19:26,935] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 76000, global step 1216094: learning rate 0.0005
[2019-03-23 10:19:26,962] A3C_AGENT_WORKER-Thread-17 INFO:Local step 76000, global step 1216113: loss 0.1075
[2019-03-23 10:19:26,964] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 76000, global step 1216113: learning rate 0.0005
[2019-03-23 10:19:27,361] A3C_AGENT_WORKER-Thread-3 INFO:Local step 76000, global step 1216318: loss 0.1763
[2019-03-23 10:19:27,364] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 76000, global step 1216319: learning rate 0.0005
[2019-03-23 10:19:27,406] A3C_AGENT_WORKER-Thread-10 INFO:Local step 76000, global step 1216337: loss 0.1413
[2019-03-23 10:19:27,411] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 76000, global step 1216340: learning rate 0.0005
[2019-03-23 10:19:27,574] A3C_AGENT_WORKER-Thread-12 INFO:Local step 76000, global step 1216423: loss 0.0636
[2019-03-23 10:19:27,576] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 76000, global step 1216424: learning rate 0.0005
[2019-03-23 10:19:27,619] A3C_AGENT_WORKER-Thread-22 INFO:Local step 76000, global step 1216448: loss 0.0235
[2019-03-23 10:19:27,622] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 76000, global step 1216448: learning rate 0.0005
[2019-03-23 10:19:27,657] A3C_AGENT_WORKER-Thread-11 INFO:Local step 76000, global step 1216463: loss 0.0190
[2019-03-23 10:19:27,660] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 76000, global step 1216463: learning rate 0.0005
[2019-03-23 10:19:27,688] A3C_AGENT_WORKER-Thread-20 INFO:Local step 76000, global step 1216483: loss 0.0061
[2019-03-23 10:19:27,690] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 76000, global step 1216483: learning rate 0.0005
[2019-03-23 10:19:27,761] A3C_AGENT_WORKER-Thread-14 INFO:Local step 76000, global step 1216517: loss 0.0002
[2019-03-23 10:19:27,764] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 76000, global step 1216517: learning rate 0.0005
[2019-03-23 10:19:27,970] A3C_AGENT_WORKER-Thread-15 INFO:Local step 76000, global step 1216623: loss 0.0004
[2019-03-23 10:19:27,971] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 76000, global step 1216624: learning rate 0.0005
[2019-03-23 10:19:28,694] A3C_AGENT_WORKER-Thread-19 INFO:Local step 76000, global step 1216965: loss 0.0043
[2019-03-23 10:19:28,699] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 76000, global step 1216966: learning rate 0.0005
[2019-03-23 10:19:28,965] A3C_AGENT_WORKER-Thread-18 INFO:Local step 76000, global step 1217077: loss 0.0225
[2019-03-23 10:19:28,968] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 76000, global step 1217078: learning rate 0.0005
[2019-03-23 10:19:32,110] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.3364954e-22 1.0000000e+00 1.8409685e-35 6.6559724e-13 3.4251254e-34], sum to 1.0000
[2019-03-23 10:19:32,117] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0033
[2019-03-23 10:19:32,120] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.8, 68.0, 1.0, 2.0, 0.3657885819922166, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 409400.9380111362, 409400.9380111362, 120447.4855827354], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5960400.0000, 
sim time next is 5961000.0000, 
raw observation next is [21.7, 68.0, 1.0, 2.0, 0.3630921442773042, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 405901.3181371827, 405901.3181371827, 120004.0945841558], 
processed observation next is [1.0, 1.0, 0.6227272727272727, 0.68, 1.0, 1.0, 0.2038651803466302, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15033382153228989, 0.15033382153228989, 0.2926929136198922], 
reward next is 0.7073, 
noisyNet noise sample is [array([1.4579461], dtype=float32), -2.0297127]. 
=============================================
[2019-03-23 10:19:32,139] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[64.89188]
 [64.87793]
 [64.86053]
 [64.85139]
 [64.86023]], R is [[64.9671402 ]
 [65.02368927]
 [65.07862091]
 [65.13181305]
 [65.18320465]].
[2019-03-23 10:19:32,874] A3C_AGENT_WORKER-Thread-9 INFO:Local step 76500, global step 1219141: loss 0.0918
[2019-03-23 10:19:32,877] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 76500, global step 1219141: learning rate 0.0005
[2019-03-23 10:19:33,372] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.1035033e-25 1.0000000e+00 7.5508744e-38 1.8664826e-19 5.5015229e-37], sum to 1.0000
[2019-03-23 10:19:33,380] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8584
[2019-03-23 10:19:33,384] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 90.0, 1.0, 2.0, 0.3257820596597852, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 358289.3720165641, 358289.3720165644, 114565.8925849105], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5979600.0000, 
sim time next is 5980200.0000, 
raw observation next is [17.61666666666667, 90.5, 1.0, 2.0, 0.3452423516646236, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 379431.2372801439, 379431.2372801442, 115910.0557623321], 
processed observation next is [1.0, 0.21739130434782608, 0.4371212121212123, 0.905, 1.0, 1.0, 0.18155293958077945, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1405300878815348, 0.14053008788153487, 0.28270745307885875], 
reward next is 0.7173, 
noisyNet noise sample is [array([-1.4987335], dtype=float32), -0.39255646]. 
=============================================
[2019-03-23 10:19:40,089] A3C_AGENT_WORKER-Thread-13 INFO:Local step 76500, global step 1222925: loss 0.0407
[2019-03-23 10:19:40,093] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 76500, global step 1222925: learning rate 0.0005
[2019-03-23 10:19:41,883] A3C_AGENT_WORKER-Thread-2 INFO:Local step 76500, global step 1223884: loss 0.1288
[2019-03-23 10:19:41,885] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 76500, global step 1223886: learning rate 0.0005
[2019-03-23 10:19:42,066] A3C_AGENT_WORKER-Thread-16 INFO:Local step 76500, global step 1223979: loss 0.0350
[2019-03-23 10:19:42,068] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 76500, global step 1223979: learning rate 0.0005
[2019-03-23 10:19:42,227] A3C_AGENT_WORKER-Thread-17 INFO:Local step 76500, global step 1224065: loss 0.0114
[2019-03-23 10:19:42,230] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 76500, global step 1224065: learning rate 0.0005
[2019-03-23 10:19:42,361] A3C_AGENT_WORKER-Thread-21 INFO:Local step 76500, global step 1224139: loss 0.0045
[2019-03-23 10:19:42,363] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 76500, global step 1224139: learning rate 0.0005
[2019-03-23 10:19:42,582] A3C_AGENT_WORKER-Thread-10 INFO:Local step 76500, global step 1224249: loss 0.0354
[2019-03-23 10:19:42,586] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 76500, global step 1224249: learning rate 0.0005
[2019-03-23 10:19:42,695] A3C_AGENT_WORKER-Thread-12 INFO:Local step 76500, global step 1224311: loss 0.0332
[2019-03-23 10:19:42,700] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 76500, global step 1224313: learning rate 0.0005
[2019-03-23 10:19:42,873] A3C_AGENT_WORKER-Thread-3 INFO:Local step 76500, global step 1224403: loss 0.0283
[2019-03-23 10:19:42,877] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 76500, global step 1224403: learning rate 0.0005
[2019-03-23 10:19:42,879] A3C_AGENT_WORKER-Thread-11 INFO:Local step 76500, global step 1224404: loss 0.0322
[2019-03-23 10:19:42,882] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 76500, global step 1224404: learning rate 0.0005
[2019-03-23 10:19:42,993] A3C_AGENT_WORKER-Thread-20 INFO:Local step 76500, global step 1224467: loss 0.0335
[2019-03-23 10:19:42,997] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 76500, global step 1224467: learning rate 0.0005
[2019-03-23 10:19:43,030] A3C_AGENT_WORKER-Thread-22 INFO:Local step 76500, global step 1224487: loss 0.0295
[2019-03-23 10:19:43,032] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 76500, global step 1224487: learning rate 0.0005
[2019-03-23 10:19:43,063] A3C_AGENT_WORKER-Thread-14 INFO:Local step 76500, global step 1224497: loss 0.0290
[2019-03-23 10:19:43,067] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 76500, global step 1224497: learning rate 0.0005
[2019-03-23 10:19:43,331] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.4939199e-24 1.0000000e+00 4.9712902e-38 3.7933602e-22 5.5097796e-36], sum to 1.0000
[2019-03-23 10:19:43,338] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0954
[2019-03-23 10:19:43,341] A3C_AGENT_WORKER-Thread-15 INFO:Local step 76500, global step 1224644: loss 0.0728
[2019-03-23 10:19:43,345] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 76500, global step 1224646: learning rate 0.0005
[2019-03-23 10:19:43,347] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.75, 79.5, 1.0, 2.0, 0.2902555918266045, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 315171.2694666111, 315171.2694666109, 103718.8272610365], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6139800.0000, 
sim time next is 6140400.0000, 
raw observation next is [17.56666666666667, 81.0, 1.0, 2.0, 0.2904928006472718, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 315428.9239370821, 315428.9239370821, 103759.0098350056], 
processed observation next is [1.0, 0.043478260869565216, 0.434848484848485, 0.81, 1.0, 1.0, 0.11311600080908972, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11682552738410448, 0.11682552738410448, 0.25307075569513565], 
reward next is 0.7469, 
noisyNet noise sample is [array([0.37833428], dtype=float32), -0.839658]. 
=============================================
[2019-03-23 10:19:44,016] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-23 10:19:44,018] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 10:19:44,020] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:19:44,020] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 10:19:44,021] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:19:44,022] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 10:19:44,023] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 10:19:44,023] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 10:19:44,025] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:19:44,025] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:19:44,026] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:19:44,042] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run50
[2019-03-23 10:19:44,067] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run50
[2019-03-23 10:19:44,090] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run50
[2019-03-23 10:19:44,115] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run50
[2019-03-23 10:19:44,149] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run50
[2019-03-23 10:20:36,410] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05994921], dtype=float32), -1.1942782]
[2019-03-23 10:20:36,411] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [26.16666666666667, 63.83333333333334, 1.0, 2.0, 0.484481802243208, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 552766.5741884566, 552766.5741884566, 139707.5509211409]
[2019-03-23 10:20:36,412] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:20:36,418] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.5407911e-24 1.0000000e+00 6.7115623e-37 5.2070538e-20 2.7827355e-36], sampled 0.6657336806638375
[2019-03-23 10:20:41,629] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05994921], dtype=float32), -1.1942782]
[2019-03-23 10:20:41,631] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [25.1, 50.0, 1.0, 2.0, 0.4538025430303227, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 509167.4125816574, 509167.4125816574, 133136.7652611728]
[2019-03-23 10:20:41,632] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 10:20:41,635] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.2057645e-24 1.0000000e+00 2.0528627e-36 9.4269225e-20 8.3457035e-36], sampled 0.007145647517933673
[2019-03-23 10:20:42,888] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05994921], dtype=float32), -1.1942782]
[2019-03-23 10:20:42,889] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [27.1, 54.0, 1.0, 2.0, 0.9655053574348196, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 1101786.300162427, 1101786.300162427, 212797.6319936953]
[2019-03-23 10:20:42,890] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 10:20:42,892] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [8.3979096e-23 1.0000000e+00 2.9768678e-34 1.3391620e-18 1.1110304e-33], sampled 0.5060224344368789
[2019-03-23 10:20:42,894] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1101786.300162427 W.
[2019-03-23 10:20:55,649] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05994921], dtype=float32), -1.1942782]
[2019-03-23 10:20:55,649] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [12.92294226, 89.81777053166667, 1.0, 2.0, 0.4934750056983341, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 535900.4138925996, 535900.4138925996, 105647.3547511882]
[2019-03-23 10:20:55,652] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 10:20:55,656] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [7.4618755e-24 1.0000000e+00 7.4526701e-36 1.8718518e-19 2.9614738e-35], sampled 0.2175086866910355
[2019-03-23 10:21:12,554] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05994921], dtype=float32), -1.1942782]
[2019-03-23 10:21:12,555] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [15.35378647, 87.58727624, 1.0, 2.0, 0.2589116860089595, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 281111.4555799442, 281111.4555799442, 89513.80462580163]
[2019-03-23 10:21:12,557] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 10:21:12,559] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.6378377e-24 1.0000000e+00 7.3678915e-37 5.4701176e-20 3.0496222e-36], sampled 0.6773463233292011
[2019-03-23 10:21:23,375] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 10:21:23,498] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 10:21:23,705] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 10:21:23,718] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 10:21:23,755] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 10:21:24,770] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 1225000, evaluation results [1225000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 10:21:24,905] A3C_AGENT_WORKER-Thread-19 INFO:Local step 76500, global step 1225071: loss 0.3006
[2019-03-23 10:21:24,907] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 76500, global step 1225072: learning rate 0.0005
[2019-03-23 10:21:24,908] A3C_AGENT_WORKER-Thread-18 INFO:Local step 76500, global step 1225072: loss 0.2218
[2019-03-23 10:21:24,913] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 76500, global step 1225072: learning rate 0.0005
[2019-03-23 10:21:29,033] A3C_AGENT_WORKER-Thread-9 INFO:Local step 77000, global step 1227148: loss 5.6134
[2019-03-23 10:21:29,037] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 77000, global step 1227149: learning rate 0.0005
[2019-03-23 10:21:35,263] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.2706459e-23 1.0000000e+00 2.4820801e-35 2.0197519e-18 7.1556652e-35], sum to 1.0000
[2019-03-23 10:21:35,271] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1264
[2019-03-23 10:21:35,276] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.8, 77.0, 1.0, 2.0, 0.5198469455353076, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 591997.7931739304, 591997.7931739307, 145388.3628325429], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6391200.0000, 
sim time next is 6391800.0000, 
raw observation next is [24.7, 77.5, 1.0, 2.0, 0.5190427038168598, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 591136.1160428739, 591136.1160428742, 145245.8011007828], 
processed observation next is [0.0, 1.0, 0.759090909090909, 0.775, 1.0, 1.0, 0.3988033797710747, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21893930223810146, 0.21893930223810154, 0.35425805146532385], 
reward next is 0.6457, 
noisyNet noise sample is [array([0.24631529], dtype=float32), -0.18783249]. 
=============================================
[2019-03-23 10:21:36,599] A3C_AGENT_WORKER-Thread-13 INFO:Local step 77000, global step 1230935: loss 0.1117
[2019-03-23 10:21:36,601] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 77000, global step 1230935: learning rate 0.0005
[2019-03-23 10:21:38,315] A3C_AGENT_WORKER-Thread-2 INFO:Local step 77000, global step 1231805: loss 0.8804
[2019-03-23 10:21:38,318] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 77000, global step 1231805: learning rate 0.0005
[2019-03-23 10:21:38,724] A3C_AGENT_WORKER-Thread-16 INFO:Local step 77000, global step 1232009: loss 0.7381
[2019-03-23 10:21:38,726] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 77000, global step 1232011: learning rate 0.0005
[2019-03-23 10:21:38,832] A3C_AGENT_WORKER-Thread-17 INFO:Local step 77000, global step 1232067: loss 0.8380
[2019-03-23 10:21:38,834] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 77000, global step 1232068: learning rate 0.0005
[2019-03-23 10:21:38,858] A3C_AGENT_WORKER-Thread-21 INFO:Local step 77000, global step 1232080: loss 0.8900
[2019-03-23 10:21:38,862] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 77000, global step 1232080: learning rate 0.0005
[2019-03-23 10:21:39,320] A3C_AGENT_WORKER-Thread-10 INFO:Local step 77000, global step 1232313: loss 0.7614
[2019-03-23 10:21:39,324] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 77000, global step 1232313: learning rate 0.0005
[2019-03-23 10:21:39,402] A3C_AGENT_WORKER-Thread-12 INFO:Local step 77000, global step 1232354: loss 0.9954
[2019-03-23 10:21:39,404] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 77000, global step 1232355: learning rate 0.0005
[2019-03-23 10:21:39,420] A3C_AGENT_WORKER-Thread-11 INFO:Local step 77000, global step 1232366: loss 0.9660
[2019-03-23 10:21:39,420] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 77000, global step 1232366: learning rate 0.0005
[2019-03-23 10:21:39,574] A3C_AGENT_WORKER-Thread-20 INFO:Local step 77000, global step 1232441: loss 0.8514
[2019-03-23 10:21:39,579] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 77000, global step 1232442: learning rate 0.0005
[2019-03-23 10:21:39,597] A3C_AGENT_WORKER-Thread-3 INFO:Local step 77000, global step 1232452: loss 0.6863
[2019-03-23 10:21:39,599] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 77000, global step 1232453: learning rate 0.0005
[2019-03-23 10:21:39,813] A3C_AGENT_WORKER-Thread-14 INFO:Local step 77000, global step 1232559: loss 2.7902
[2019-03-23 10:21:39,815] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 77000, global step 1232560: learning rate 0.0005
[2019-03-23 10:21:39,824] A3C_AGENT_WORKER-Thread-22 INFO:Local step 77000, global step 1232562: loss 2.3810
[2019-03-23 10:21:39,826] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 77000, global step 1232562: learning rate 0.0005
[2019-03-23 10:21:40,083] A3C_AGENT_WORKER-Thread-15 INFO:Local step 77000, global step 1232691: loss 12.3040
[2019-03-23 10:21:40,085] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 77000, global step 1232692: learning rate 0.0005
[2019-03-23 10:21:40,663] A3C_AGENT_WORKER-Thread-19 INFO:Local step 77000, global step 1232986: loss 2.1328
[2019-03-23 10:21:40,665] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 77000, global step 1232987: learning rate 0.0005
[2019-03-23 10:21:40,855] A3C_AGENT_WORKER-Thread-18 INFO:Local step 77000, global step 1233081: loss 2.1808
[2019-03-23 10:21:40,858] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 77000, global step 1233081: learning rate 0.0005
[2019-03-23 10:21:41,471] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.0320724e-26 1.0000000e+00 1.0427434e-37 2.5668491e-25 2.5983105e-36], sum to 1.0000
[2019-03-23 10:21:41,481] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2751
[2019-03-23 10:21:41,484] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.63333333333333, 89.0, 1.0, 2.0, 0.5509824446660636, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 614740.6387721668, 614740.6387721668, 137190.922257089], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6690000.0000, 
sim time next is 6690600.0000, 
raw observation next is [18.55, 90.0, 1.0, 2.0, 0.5428086919597414, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 605815.7290868693, 605815.7290868693, 136414.6589517729], 
processed observation next is [1.0, 0.43478260869565216, 0.47954545454545455, 0.9, 1.0, 1.0, 0.42851086494967666, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22437619595809974, 0.22437619595809974, 0.3327186803701778], 
reward next is 0.6673, 
noisyNet noise sample is [array([0.77579975], dtype=float32), -0.057438087]. 
=============================================
[2019-03-23 10:21:43,460] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.6406286e-25 1.0000000e+00 2.5028621e-37 5.9382230e-23 3.5018399e-37], sum to 1.0000
[2019-03-23 10:21:43,467] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1405
[2019-03-23 10:21:43,470] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.76666666666667, 81.66666666666667, 1.0, 2.0, 0.205872673398362, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 223523.8261408841, 223523.8261408838, 73948.551335839], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6507600.0000, 
sim time next is 6508200.0000, 
raw observation next is [15.13333333333333, 79.83333333333333, 1.0, 2.0, 0.2076873132702278, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 225494.5066661107, 225494.506666111, 74606.02837380042], 
processed observation next is [1.0, 0.30434782608695654, 0.32424242424242405, 0.7983333333333333, 1.0, 1.0, 0.009609141587784732, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08351648395041138, 0.08351648395041149, 0.18196592286292787], 
reward next is 0.8180, 
noisyNet noise sample is [array([-1.744293], dtype=float32), 1.1290303]. 
=============================================
[2019-03-23 10:21:44,660] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.8407794e-27 1.0000000e+00 0.0000000e+00 5.9029195e-24 0.0000000e+00], sum to 1.0000
[2019-03-23 10:21:44,669] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9949
[2019-03-23 10:21:44,672] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.11666666666667, 93.83333333333334, 1.0, 2.0, 0.3491459318812746, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 382772.6933400017, 382772.693340002, 115861.856209597], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6750600.0000, 
sim time next is 6751200.0000, 
raw observation next is [17.13333333333333, 93.66666666666667, 1.0, 2.0, 0.3319539384557129, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 363916.1932793955, 363916.1932793955, 114590.6468484353], 
processed observation next is [1.0, 0.13043478260869565, 0.415151515151515, 0.9366666666666668, 1.0, 1.0, 0.16494242306964113, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.134783775288665, 0.134783775288665, 0.27948938255715927], 
reward next is 0.7205, 
noisyNet noise sample is [array([-0.54281586], dtype=float32), 0.8820862]. 
=============================================
[2019-03-23 10:21:44,911] A3C_AGENT_WORKER-Thread-9 INFO:Local step 77500, global step 1235123: loss 0.0024
[2019-03-23 10:21:44,915] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 77500, global step 1235124: learning rate 0.0005
[2019-03-23 10:21:50,086] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.9303760e-26 1.0000000e+00 0.0000000e+00 1.3096256e-22 2.3928884e-38], sum to 1.0000
[2019-03-23 10:21:50,093] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9677
[2019-03-23 10:21:50,102] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.9, 68.5, 1.0, 2.0, 0.3672095462834377, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 411677.7833312263, 411677.7833312263, 120887.420879184], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6629400.0000, 
sim time next is 6630000.0000, 
raw observation next is [21.8, 69.33333333333333, 1.0, 2.0, 0.3680831262001744, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 412745.5320198758, 412745.5320198761, 121002.8972587783], 
processed observation next is [1.0, 0.7391304347826086, 0.6272727272727273, 0.6933333333333332, 1.0, 1.0, 0.210103907750218, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15286871556291698, 0.1528687155629171, 0.29512901770433736], 
reward next is 0.7049, 
noisyNet noise sample is [array([1.3665377], dtype=float32), 0.08283954]. 
=============================================
[2019-03-23 10:21:50,131] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[67.78164]
 [67.49989]
 [67.11551]
 [67.03194]
 [67.02477]], R is [[67.84778595]
 [67.87446594]
 [67.89888763]
 [67.89723206]
 [67.81608582]].
[2019-03-23 10:21:52,551] A3C_AGENT_WORKER-Thread-13 INFO:Local step 77500, global step 1238989: loss 0.0409
[2019-03-23 10:21:52,555] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 77500, global step 1238989: learning rate 0.0005
[2019-03-23 10:21:54,210] A3C_AGENT_WORKER-Thread-2 INFO:Local step 77500, global step 1239821: loss 0.0226
[2019-03-23 10:21:54,213] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 77500, global step 1239822: learning rate 0.0005
[2019-03-23 10:21:54,488] A3C_AGENT_WORKER-Thread-16 INFO:Local step 77500, global step 1239962: loss 0.0110
[2019-03-23 10:21:54,490] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 77500, global step 1239963: learning rate 0.0005
[2019-03-23 10:21:54,627] A3C_AGENT_WORKER-Thread-17 INFO:Local step 77500, global step 1240035: loss 0.0219
[2019-03-23 10:21:54,631] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 77500, global step 1240035: learning rate 0.0005
[2019-03-23 10:21:54,817] A3C_AGENT_WORKER-Thread-21 INFO:Local step 77500, global step 1240129: loss 0.0184
[2019-03-23 10:21:54,820] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 77500, global step 1240129: learning rate 0.0005
[2019-03-23 10:21:55,105] A3C_AGENT_WORKER-Thread-12 INFO:Local step 77500, global step 1240274: loss 0.0039
[2019-03-23 10:21:55,109] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 77500, global step 1240276: learning rate 0.0005
[2019-03-23 10:21:55,152] A3C_AGENT_WORKER-Thread-10 INFO:Local step 77500, global step 1240296: loss 0.0029
[2019-03-23 10:21:55,155] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 77500, global step 1240297: learning rate 0.0005
[2019-03-23 10:21:55,322] A3C_AGENT_WORKER-Thread-11 INFO:Local step 77500, global step 1240382: loss 0.0056
[2019-03-23 10:21:55,323] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 77500, global step 1240382: learning rate 0.0005
[2019-03-23 10:21:55,496] A3C_AGENT_WORKER-Thread-20 INFO:Local step 77500, global step 1240467: loss 0.0080
[2019-03-23 10:21:55,500] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 77500, global step 1240469: learning rate 0.0005
[2019-03-23 10:21:55,529] A3C_AGENT_WORKER-Thread-22 INFO:Local step 77500, global step 1240483: loss 0.0034
[2019-03-23 10:21:55,531] A3C_AGENT_WORKER-Thread-3 INFO:Local step 77500, global step 1240483: loss 0.0081
[2019-03-23 10:21:55,532] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 77500, global step 1240483: learning rate 0.0005
[2019-03-23 10:21:55,538] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 77500, global step 1240483: learning rate 0.0005
[2019-03-23 10:21:55,733] A3C_AGENT_WORKER-Thread-14 INFO:Local step 77500, global step 1240590: loss 0.0029
[2019-03-23 10:21:55,735] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 77500, global step 1240591: learning rate 0.0005
[2019-03-23 10:21:55,981] A3C_AGENT_WORKER-Thread-15 INFO:Local step 77500, global step 1240711: loss 0.0022
[2019-03-23 10:21:55,983] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 77500, global step 1240713: learning rate 0.0005
[2019-03-23 10:21:56,384] A3C_AGENT_WORKER-Thread-19 INFO:Local step 77500, global step 1240916: loss 0.0116
[2019-03-23 10:21:56,391] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 77500, global step 1240916: learning rate 0.0005
[2019-03-23 10:21:56,798] A3C_AGENT_WORKER-Thread-18 INFO:Local step 77500, global step 1241128: loss 0.0930
[2019-03-23 10:21:56,800] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 77500, global step 1241128: learning rate 0.0005
[2019-03-23 10:22:00,671] A3C_AGENT_WORKER-Thread-9 INFO:Local step 78000, global step 1243047: loss -47.4187
[2019-03-23 10:22:00,672] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 78000, global step 1243047: learning rate 0.0005
[2019-03-23 10:22:07,631] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.8136226e-21 1.0000000e+00 5.2247703e-32 6.7085299e-18 1.2771849e-32], sum to 1.0000
[2019-03-23 10:22:07,639] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0672
[2019-03-23 10:22:07,647] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.7, 95.66666666666666, 1.0, 2.0, 0.5016549546020546, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 572115.7167576231, 572115.7167576231, 139881.1911801145], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7008000.0000, 
sim time next is 7008600.0000, 
raw observation next is [20.6, 96.33333333333334, 1.0, 2.0, 0.4899129509191272, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 558681.3514920181, 558681.3514920181, 138497.7009713734], 
processed observation next is [1.0, 0.08695652173913043, 0.5727272727272728, 0.9633333333333334, 1.0, 1.0, 0.36239118864890896, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20691901907111782, 0.20691901907111782, 0.3377992706618863], 
reward next is 0.6622, 
noisyNet noise sample is [array([-0.6257409], dtype=float32), -0.5482873]. 
=============================================
[2019-03-23 10:22:08,214] A3C_AGENT_WORKER-Thread-13 INFO:Local step 78000, global step 1247071: loss -29.8398
[2019-03-23 10:22:08,216] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 78000, global step 1247071: learning rate 0.0005
[2019-03-23 10:22:09,389] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.5763458e-21 1.0000000e+00 5.6289250e-34 2.7308355e-16 1.0168942e-32], sum to 1.0000
[2019-03-23 10:22:09,395] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7709
[2019-03-23 10:22:09,406] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 97.0, 1.0, 2.0, 0.6284125887892822, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 710160.8230077735, 710160.8230077735, 149899.4873665045], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7032000.0000, 
sim time next is 7032600.0000, 
raw observation next is [18.8, 97.0, 1.0, 2.0, 0.6220963543247509, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 702916.8408460031, 702916.8408460031, 149074.8719921183], 
processed observation next is [1.0, 0.391304347826087, 0.49090909090909096, 0.97, 1.0, 1.0, 0.5276204429059386, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2603395706837049, 0.2603395706837049, 0.36359724876126415], 
reward next is 0.6364, 
noisyNet noise sample is [array([-1.220482], dtype=float32), 1.581912]. 
=============================================
[2019-03-23 10:22:09,634] A3C_AGENT_WORKER-Thread-2 INFO:Local step 78000, global step 1247818: loss -51.4236
[2019-03-23 10:22:09,635] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 78000, global step 1247819: learning rate 0.0005
[2019-03-23 10:22:09,998] A3C_AGENT_WORKER-Thread-21 INFO:Local step 78000, global step 1248014: loss -19.4683
[2019-03-23 10:22:10,003] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 78000, global step 1248014: learning rate 0.0005
[2019-03-23 10:22:10,114] A3C_AGENT_WORKER-Thread-17 INFO:Local step 78000, global step 1248076: loss -7.8054
[2019-03-23 10:22:10,115] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 78000, global step 1248077: learning rate 0.0005
[2019-03-23 10:22:10,162] A3C_AGENT_WORKER-Thread-16 INFO:Local step 78000, global step 1248101: loss -47.7123
[2019-03-23 10:22:10,165] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 78000, global step 1248102: learning rate 0.0005
[2019-03-23 10:22:10,333] A3C_AGENT_WORKER-Thread-10 INFO:Local step 78000, global step 1248188: loss -36.3652
[2019-03-23 10:22:10,335] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 78000, global step 1248188: learning rate 0.0005
[2019-03-23 10:22:10,477] A3C_AGENT_WORKER-Thread-12 INFO:Local step 78000, global step 1248265: loss -47.1457
[2019-03-23 10:22:10,478] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 78000, global step 1248266: learning rate 0.0005
[2019-03-23 10:22:10,519] A3C_AGENT_WORKER-Thread-11 INFO:Local step 78000, global step 1248279: loss -35.0303
[2019-03-23 10:22:10,524] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 78000, global step 1248279: learning rate 0.0005
[2019-03-23 10:22:10,838] A3C_AGENT_WORKER-Thread-20 INFO:Local step 78000, global step 1248446: loss -56.3910
[2019-03-23 10:22:10,839] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 78000, global step 1248446: learning rate 0.0005
[2019-03-23 10:22:10,901] A3C_AGENT_WORKER-Thread-14 INFO:Local step 78000, global step 1248484: loss -50.8083
[2019-03-23 10:22:10,907] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 78000, global step 1248488: learning rate 0.0005
[2019-03-23 10:22:10,962] A3C_AGENT_WORKER-Thread-22 INFO:Local step 78000, global step 1248515: loss -11.0281
[2019-03-23 10:22:10,968] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 78000, global step 1248515: learning rate 0.0005
[2019-03-23 10:22:11,005] A3C_AGENT_WORKER-Thread-3 INFO:Local step 78000, global step 1248535: loss -25.2459
[2019-03-23 10:22:11,009] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 78000, global step 1248535: learning rate 0.0005
[2019-03-23 10:22:11,431] A3C_AGENT_WORKER-Thread-15 INFO:Local step 78000, global step 1248762: loss -58.7019
[2019-03-23 10:22:11,433] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 78000, global step 1248763: learning rate 0.0005
[2019-03-23 10:22:11,849] A3C_AGENT_WORKER-Thread-19 INFO:Local step 78000, global step 1248946: loss -61.3453
[2019-03-23 10:22:11,855] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 78000, global step 1248948: learning rate 0.0005
[2019-03-23 10:22:12,635] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.9047561e-24 1.0000000e+00 1.3740947e-37 2.1782832e-24 7.5571567e-38], sum to 1.0000
[2019-03-23 10:22:12,642] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9197
[2019-03-23 10:22:12,646] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 97.0, 1.0, 2.0, 0.3477382456156053, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 387122.7304422396, 387122.7304422396, 118043.0962696008], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7097400.0000, 
sim time next is 7098000.0000, 
raw observation next is [17.7, 97.0, 1.0, 2.0, 0.3469567019862725, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 386248.8182662246, 386248.8182662249, 117979.8047401419], 
processed observation next is [1.0, 0.13043478260869565, 0.44090909090909086, 0.97, 1.0, 1.0, 0.18369587748284058, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14305511787637948, 0.1430551178763796, 0.2877556213174193], 
reward next is 0.7122, 
noisyNet noise sample is [array([-0.51740646], dtype=float32), 0.5703558]. 
=============================================
[2019-03-23 10:22:12,662] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[69.235504]
 [69.22612 ]
 [69.281075]
 [69.293915]
 [69.31557 ]], R is [[69.26487732]
 [69.28431702]
 [69.30331421]
 [69.32151794]
 [69.34020233]].
[2019-03-23 10:22:12,672] A3C_AGENT_WORKER-Thread-18 INFO:Local step 78000, global step 1249383: loss -4.5504
[2019-03-23 10:22:12,677] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 78000, global step 1249385: learning rate 0.0005
[2019-03-23 10:22:13,828] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 10:22:13,830] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 10:22:13,831] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:22:13,831] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 10:22:13,832] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:22:13,832] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 10:22:13,835] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 10:22:13,836] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 10:22:13,836] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:22:13,837] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:22:13,843] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:22:13,859] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run51
[2019-03-23 10:22:13,884] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run51
[2019-03-23 10:22:13,885] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run51
[2019-03-23 10:22:13,909] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run51
[2019-03-23 10:22:13,933] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run51
[2019-03-23 10:22:25,898] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05994921], dtype=float32), -1.2103927]
[2019-03-23 10:22:25,900] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.0, 94.0, 1.0, 2.0, 0.3740906619797216, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 421508.6794463283, 421508.6794463283, 122535.0989653488]
[2019-03-23 10:22:25,900] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:22:25,902] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.7836564e-25 1.0000000e+00 3.1894697e-38 4.6441268e-21 1.4296828e-37], sampled 0.2551542255239799
[2019-03-23 10:22:39,909] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05994921], dtype=float32), -1.2103927]
[2019-03-23 10:22:39,910] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [17.75, 47.5, 1.0, 2.0, 0.2830989747919518, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 95.55338769695034, 307379.3415255347, 307379.3415255341, 82816.08392428418]
[2019-03-23 10:22:39,911] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 10:22:39,913] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.5709061e-25 1.0000000e+00 5.5448596e-38 6.2820050e-21 2.4641905e-37], sampled 0.5033631253653714
[2019-03-23 10:23:01,166] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05994921], dtype=float32), -1.2103927]
[2019-03-23 10:23:01,167] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.16666666666667, 87.16666666666667, 1.0, 2.0, 0.2977459100433126, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 323307.2637393609, 323307.2637393612, 111040.3613325608]
[2019-03-23 10:23:01,169] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:23:01,172] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.8101491e-25 1.0000000e+00 3.2614459e-38 4.7005197e-21 1.4614333e-37], sampled 0.8628034352138833
[2019-03-23 10:23:01,427] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05994921], dtype=float32), -1.2103927]
[2019-03-23 10:23:01,430] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [15.98001336, 86.82334584, 1.0, 2.0, 0.2777520762240229, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 301572.4024433343, 301572.402443334, 95506.1068478707]
[2019-03-23 10:23:01,432] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 10:23:01,434] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.3650351e-25 1.0000000e+00 4.8869415e-38 5.8624233e-21 2.1761176e-37], sampled 0.8746654169619167
[2019-03-23 10:23:07,165] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05994921], dtype=float32), -1.2103927]
[2019-03-23 10:23:07,168] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.83067621833333, 69.23316934166667, 1.0, 2.0, 0.4337473950685642, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 491683.3086479582, 491683.3086479579, 134004.0257658047]
[2019-03-23 10:23:07,169] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 10:23:07,172] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.9936103e-25 1.0000000e+00 2.0054218e-37 1.2607875e-20 8.7148119e-37], sampled 0.139693850434786
[2019-03-23 10:23:34,961] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05994921], dtype=float32), -1.2103927]
[2019-03-23 10:23:34,962] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [12.26252812, 99.15071741, 1.0, 2.0, 0.222506711336966, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 241577.0792707612, 241577.0792707609, 78553.3741161494]
[2019-03-23 10:23:34,964] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 10:23:34,967] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.7442999e-25 1.0000000e+00 3.0835433e-38 4.5600900e-21 1.3829607e-37], sampled 0.7773177007433847
[2019-03-23 10:23:50,422] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05994921], dtype=float32), -1.2103927]
[2019-03-23 10:23:50,424] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [16.03333333333333, 69.66666666666667, 1.0, 2.0, 0.2279347919752702, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 247471.5972436646, 247471.5972436643, 80355.33974387115]
[2019-03-23 10:23:50,425] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 10:23:50,430] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.1280250e-25 1.0000000e+00 4.1651879e-38 5.3714597e-21 1.8593592e-37], sampled 0.839474494110965
[2019-03-23 10:23:52,800] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 10:23:53,033] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 10:23:53,264] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 10:23:53,306] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 10:23:53,315] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 10:23:54,333] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 1250000, evaluation results [1250000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 10:23:56,375] A3C_AGENT_WORKER-Thread-9 INFO:Local step 78500, global step 1251024: loss 0.0073
[2019-03-23 10:23:56,377] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 78500, global step 1251024: learning rate 0.0005
[2019-03-23 10:24:04,634] A3C_AGENT_WORKER-Thread-13 INFO:Local step 78500, global step 1255100: loss 0.0016
[2019-03-23 10:24:04,636] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 78500, global step 1255100: learning rate 0.0005
[2019-03-23 10:24:05,923] A3C_AGENT_WORKER-Thread-2 INFO:Local step 78500, global step 1255748: loss 0.0160
[2019-03-23 10:24:05,924] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 78500, global step 1255748: learning rate 0.0005
[2019-03-23 10:24:06,250] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0521433e-18 1.0000000e+00 1.5979832e-30 1.4389135e-14 4.0444670e-31], sum to 1.0000
[2019-03-23 10:24:06,256] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7324
[2019-03-23 10:24:06,263] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1130048.54028973 W.
[2019-03-23 10:24:06,268] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.1, 42.0, 1.0, 2.0, 0.3321796398893052, 1.0, 2.0, 0.3321796398893052, 1.0, 2.0, 0.6583786895650976, 6.9112, 6.9112, 77.3421103, 1130048.54028973, 1130048.54028973, 253411.6000057651], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7315200.0000, 
sim time next is 7315800.0000, 
raw observation next is [26.0, 42.83333333333334, 1.0, 2.0, 0.2850500172520108, 1.0, 2.0, 0.2850500172520108, 1.0, 2.0, 0.5645716440543028, 6.911199999999999, 6.9112, 77.3421103, 969182.0667754561, 969182.0667754563, 237910.8519040692], 
processed observation next is [1.0, 0.6956521739130435, 0.8181818181818182, 0.42833333333333345, 1.0, 1.0, 0.10631252156501347, 1.0, 1.0, 0.10631252156501347, 1.0, 1.0, 0.37795949150614694, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.35895632102794667, 0.3589563210279468, 0.5802703704977298], 
reward next is 0.4197, 
noisyNet noise sample is [array([0.35998157], dtype=float32), -0.16858858]. 
=============================================
[2019-03-23 10:24:06,363] A3C_AGENT_WORKER-Thread-21 INFO:Local step 78500, global step 1255971: loss 0.0044
[2019-03-23 10:24:06,367] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 78500, global step 1255971: learning rate 0.0005
[2019-03-23 10:24:06,547] A3C_AGENT_WORKER-Thread-17 INFO:Local step 78500, global step 1256061: loss 0.0027
[2019-03-23 10:24:06,548] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 78500, global step 1256061: learning rate 0.0005
[2019-03-23 10:24:06,772] A3C_AGENT_WORKER-Thread-11 INFO:Local step 78500, global step 1256179: loss 0.0010
[2019-03-23 10:24:06,774] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 78500, global step 1256179: learning rate 0.0005
[2019-03-23 10:24:06,775] A3C_AGENT_WORKER-Thread-16 INFO:Local step 78500, global step 1256180: loss 0.0089
[2019-03-23 10:24:06,783] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 78500, global step 1256181: learning rate 0.0005
[2019-03-23 10:24:06,826] A3C_AGENT_WORKER-Thread-12 INFO:Local step 78500, global step 1256200: loss 0.0041
[2019-03-23 10:24:06,828] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 78500, global step 1256201: learning rate 0.0005
[2019-03-23 10:24:06,948] A3C_AGENT_WORKER-Thread-10 INFO:Local step 78500, global step 1256266: loss 0.0028
[2019-03-23 10:24:06,950] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 78500, global step 1256266: learning rate 0.0005
[2019-03-23 10:24:07,318] A3C_AGENT_WORKER-Thread-14 INFO:Local step 78500, global step 1256448: loss 0.0082
[2019-03-23 10:24:07,321] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 78500, global step 1256450: learning rate 0.0005
[2019-03-23 10:24:07,331] A3C_AGENT_WORKER-Thread-20 INFO:Local step 78500, global step 1256454: loss 0.0025
[2019-03-23 10:24:07,332] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 78500, global step 1256454: learning rate 0.0005
[2019-03-23 10:24:07,452] A3C_AGENT_WORKER-Thread-22 INFO:Local step 78500, global step 1256521: loss 0.0013
[2019-03-23 10:24:07,453] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 78500, global step 1256521: learning rate 0.0005
[2019-03-23 10:24:07,454] A3C_AGENT_WORKER-Thread-3 INFO:Local step 78500, global step 1256521: loss 0.0009
[2019-03-23 10:24:07,455] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 78500, global step 1256521: learning rate 0.0005
[2019-03-23 10:24:07,899] A3C_AGENT_WORKER-Thread-15 INFO:Local step 78500, global step 1256738: loss 0.0017
[2019-03-23 10:24:07,901] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 78500, global step 1256738: learning rate 0.0005
[2019-03-23 10:24:08,406] A3C_AGENT_WORKER-Thread-19 INFO:Local step 78500, global step 1256992: loss 0.0259
[2019-03-23 10:24:08,410] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 78500, global step 1256993: learning rate 0.0005
[2019-03-23 10:24:08,986] A3C_AGENT_WORKER-Thread-18 INFO:Local step 78500, global step 1257279: loss 0.0915
[2019-03-23 10:24:08,991] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 78500, global step 1257279: learning rate 0.0005
[2019-03-23 10:24:11,293] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.7240851e-22 1.0000000e+00 5.2576571e-33 6.9109577e-17 5.0167002e-33], sum to 1.0000
[2019-03-23 10:24:11,303] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8191
[2019-03-23 10:24:11,309] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.93333333333333, 83.83333333333334, 1.0, 2.0, 0.8079926957404957, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 922250.2736525857, 922250.2736525853, 184109.0277798601], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7635000.0000, 
sim time next is 7635600.0000, 
raw observation next is [23.3, 82.0, 1.0, 2.0, 0.8237619252601417, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 940137.6226850963, 940137.6226850963, 187097.6129869782], 
processed observation next is [1.0, 0.391304347826087, 0.6954545454545454, 0.82, 1.0, 1.0, 0.779702406575177, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.34819911951299864, 0.34819911951299864, 0.45633564143165417], 
reward next is 0.5437, 
noisyNet noise sample is [array([0.4202277], dtype=float32), -1.0689987]. 
=============================================
[2019-03-23 10:24:12,492] A3C_AGENT_WORKER-Thread-9 INFO:Local step 79000, global step 1259043: loss -105.3360
[2019-03-23 10:24:12,493] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 79000, global step 1259043: learning rate 0.0005
[2019-03-23 10:24:13,738] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.6841090e-22 1.0000000e+00 9.4180085e-35 5.1170785e-15 7.1291583e-34], sum to 1.0000
[2019-03-23 10:24:13,746] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9651
[2019-03-23 10:24:13,752] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.96666666666667, 90.33333333333334, 1.0, 2.0, 0.4809068781401407, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 548755.6161930435, 548755.6161930435, 138872.669483014], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7677600.0000, 
sim time next is 7678200.0000, 
raw observation next is [21.78333333333333, 91.66666666666666, 1.0, 2.0, 0.4818567458174514, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 549841.5006062903, 549841.5006062903, 138949.8266070506], 
processed observation next is [1.0, 0.8695652173913043, 0.6265151515151515, 0.9166666666666665, 1.0, 1.0, 0.3523209322718142, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20364500022455195, 0.20364500022455195, 0.33890201611475756], 
reward next is 0.6611, 
noisyNet noise sample is [array([-1.2507335], dtype=float32), -0.66249335]. 
=============================================
[2019-03-23 10:24:14,660] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.6828791e-22 1.0000000e+00 1.3149610e-31 2.6109927e-18 1.9787013e-32], sum to 1.0000
[2019-03-23 10:24:14,674] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8400
[2019-03-23 10:24:14,678] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.88333333333333, 56.33333333333333, 1.0, 2.0, 0.4970872446501798, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 566909.1331328792, 566909.1331328788, 141722.8642860603], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7491000.0000, 
sim time next is 7491600.0000, 
raw observation next is [27.7, 57.0, 1.0, 2.0, 0.4973346876506098, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 567240.5696829824, 567240.5696829824, 141665.96632678], 
processed observation next is [0.0, 0.7391304347826086, 0.8954545454545454, 0.57, 1.0, 1.0, 0.3716683595632622, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21008909988258606, 0.21008909988258606, 0.3455267471384878], 
reward next is 0.6545, 
noisyNet noise sample is [array([0.6825712], dtype=float32), 0.19274408]. 
=============================================
[2019-03-23 10:24:16,788] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.1135256e-25 1.0000000e+00 2.7630582e-38 2.0143100e-20 9.0374594e-37], sum to 1.0000
[2019-03-23 10:24:16,798] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6711
[2019-03-23 10:24:16,805] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.08333333333334, 98.83333333333334, 1.0, 2.0, 0.4462264113189364, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 508499.0959486359, 508499.0959486359, 133249.7864113991], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7535400.0000, 
sim time next is 7536000.0000, 
raw observation next is [20.16666666666667, 97.66666666666667, 1.0, 2.0, 0.4443566506186492, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 506280.4649664879, 506280.4649664879, 132941.4676837768], 
processed observation next is [0.0, 0.21739130434782608, 0.5530303030303032, 0.9766666666666667, 1.0, 1.0, 0.3054458132733115, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18751128332092146, 0.18751128332092146, 0.32424748215555316], 
reward next is 0.6758, 
noisyNet noise sample is [array([-0.7069372], dtype=float32), 0.39252767]. 
=============================================
[2019-03-23 10:24:16,816] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[64.78025]
 [64.77754]
 [64.80147]
 [64.80702]
 [64.81403]], R is [[64.81571198]
 [64.84255981]
 [64.8684082 ]
 [64.89326477]
 [64.91714478]].
[2019-03-23 10:24:18,211] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.4077499e-20 1.0000000e+00 1.4033663e-32 3.5706459e-16 2.0404063e-32], sum to 1.0000
[2019-03-23 10:24:18,218] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3679
[2019-03-23 10:24:18,223] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.1, 56.33333333333334, 1.0, 2.0, 0.504418069118668, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 574992.9498880189, 574992.9498880189, 142972.8136656805], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7568400.0000, 
sim time next is 7569000.0000, 
raw observation next is [28.0, 56.5, 1.0, 2.0, 0.5029007369544327, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 573354.6100980745, 573354.6100980745, 142678.8502199287], 
processed observation next is [0.0, 0.6086956521739131, 0.9090909090909091, 0.565, 1.0, 1.0, 0.37862592119304084, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21235355929558317, 0.21235355929558317, 0.3479971956583627], 
reward next is 0.6520, 
noisyNet noise sample is [array([1.4750026], dtype=float32), -0.7281104]. 
=============================================
[2019-03-23 10:24:18,254] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[68.10629]
 [68.10629]
 [68.10629]
 [68.10629]
 [68.10629]], R is [[68.07723999]
 [68.04775238]
 [68.01778412]
 [67.98765564]
 [67.95828247]].
[2019-03-23 10:24:20,764] A3C_AGENT_WORKER-Thread-13 INFO:Local step 79000, global step 1263204: loss -113.2757
[2019-03-23 10:24:20,766] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 79000, global step 1263205: learning rate 0.0005
[2019-03-23 10:24:22,026] A3C_AGENT_WORKER-Thread-2 INFO:Local step 79000, global step 1263838: loss 38.9470
[2019-03-23 10:24:22,028] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 79000, global step 1263838: learning rate 0.0005
[2019-03-23 10:24:22,306] A3C_AGENT_WORKER-Thread-21 INFO:Local step 79000, global step 1263977: loss -27.4930
[2019-03-23 10:24:22,310] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 79000, global step 1263977: learning rate 0.0005
[2019-03-23 10:24:22,343] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.1708389e-11 9.9995673e-01 2.0031219e-18 4.3299424e-05 2.3774145e-18], sum to 1.0000
[2019-03-23 10:24:22,353] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1368
[2019-03-23 10:24:22,358] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1195957.285637034 W.
[2019-03-23 10:24:22,366] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.25, 73.0, 1.0, 2.0, 0.5275987416087473, 1.0, 1.0, 0.5275987416087473, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344353833, 1195957.285637034, 1195957.285637034, 239883.1745272099], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7641000.0000, 
sim time next is 7641600.0000, 
raw observation next is [25.33333333333334, 72.66666666666667, 1.0, 2.0, 0.5532683543958459, 0.0, 1.0, 0.0, 1.0, 1.0, 0.972430559467564, 6.918375249893167, 6.9112, 77.32844584152018, 1177266.65336482, 1174936.279489215, 269730.5496224632], 
processed observation next is [1.0, 0.43478260869565216, 0.7878787878787882, 0.7266666666666667, 1.0, 1.0, 0.4415854429948073, 0.0, 0.5, -0.25, 1.0, 0.5, 0.9606150849536628, 0.0007175249893166758, 0.0, 0.508428697188695, 0.4360246864314148, 0.43516158499600555, 0.6578793893230809], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2501892], dtype=float32), 0.48888385]. 
=============================================
[2019-03-23 10:24:22,569] A3C_AGENT_WORKER-Thread-17 INFO:Local step 79000, global step 1264103: loss -20.6164
[2019-03-23 10:24:22,575] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 79000, global step 1264105: learning rate 0.0005
[2019-03-23 10:24:22,684] A3C_AGENT_WORKER-Thread-16 INFO:Local step 79000, global step 1264158: loss -4.8371
[2019-03-23 10:24:22,685] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 79000, global step 1264158: learning rate 0.0005
[2019-03-23 10:24:22,734] A3C_AGENT_WORKER-Thread-11 INFO:Local step 79000, global step 1264189: loss 61.0811
[2019-03-23 10:24:22,735] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 79000, global step 1264189: learning rate 0.0005
[2019-03-23 10:24:22,744] A3C_AGENT_WORKER-Thread-12 INFO:Local step 79000, global step 1264192: loss -16.5034
[2019-03-23 10:24:22,745] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 79000, global step 1264192: learning rate 0.0005
[2019-03-23 10:24:22,953] A3C_AGENT_WORKER-Thread-10 INFO:Local step 79000, global step 1264292: loss 81.1949
[2019-03-23 10:24:22,955] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 79000, global step 1264292: learning rate 0.0005
[2019-03-23 10:24:23,128] A3C_AGENT_WORKER-Thread-14 INFO:Local step 79000, global step 1264379: loss 206.8517
[2019-03-23 10:24:23,129] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 79000, global step 1264379: learning rate 0.0005
[2019-03-23 10:24:23,259] A3C_AGENT_WORKER-Thread-20 INFO:Local step 79000, global step 1264449: loss 103.5240
[2019-03-23 10:24:23,260] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 79000, global step 1264449: learning rate 0.0005
[2019-03-23 10:24:23,472] A3C_AGENT_WORKER-Thread-3 INFO:Local step 79000, global step 1264555: loss 98.8968
[2019-03-23 10:24:23,473] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 79000, global step 1264555: learning rate 0.0005
[2019-03-23 10:24:23,510] A3C_AGENT_WORKER-Thread-22 INFO:Local step 79000, global step 1264572: loss 83.7771
[2019-03-23 10:24:23,513] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 79000, global step 1264573: learning rate 0.0005
[2019-03-23 10:24:23,892] A3C_AGENT_WORKER-Thread-15 INFO:Local step 79000, global step 1264762: loss 99.8776
[2019-03-23 10:24:23,894] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 79000, global step 1264763: learning rate 0.0005
[2019-03-23 10:24:24,466] A3C_AGENT_WORKER-Thread-19 INFO:Local step 79000, global step 1265058: loss 50.3321
[2019-03-23 10:24:24,468] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 79000, global step 1265060: learning rate 0.0005
[2019-03-23 10:24:24,871] A3C_AGENT_WORKER-Thread-18 INFO:Local step 79000, global step 1265258: loss -60.1692
[2019-03-23 10:24:24,873] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 79000, global step 1265259: learning rate 0.0005
[2019-03-23 10:24:26,076] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.7142111e-25 1.0000000e+00 2.6041823e-38 3.7074458e-18 1.4020884e-38], sum to 1.0000
[2019-03-23 10:24:26,082] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7696
[2019-03-23 10:24:26,097] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.76666666666667, 54.83333333333334, 1.0, 2.0, 0.2777851406319331, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 301626.1496302073, 301626.149630207, 87510.81694567544], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7757400.0000, 
sim time next is 7758000.0000, 
raw observation next is [19.4, 56.0, 1.0, 2.0, 0.2737748127055502, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 297270.3030153894, 297270.3030153894, 86098.81835641342], 
processed observation next is [1.0, 0.8260869565217391, 0.5181818181818181, 0.56, 1.0, 1.0, 0.09221851588193775, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11010011222792201, 0.11010011222792201, 0.20999711794247175], 
reward next is 0.7900, 
noisyNet noise sample is [array([-0.77388555], dtype=float32), -1.5719087]. 
=============================================
[2019-03-23 10:24:26,118] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[73.20887 ]
 [73.20702 ]
 [73.202   ]
 [73.198715]
 [73.20368 ]], R is [[73.26824951]
 [73.3221283 ]
 [73.37150574]
 [73.41590881]
 [73.4553833 ]].
[2019-03-23 10:24:28,868] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:24:28,869] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:24:28,966] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run7
[2019-03-23 10:24:29,595] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0154698e-28 1.0000000e+00 0.0000000e+00 8.4147584e-20 0.0000000e+00], sum to 1.0000
[2019-03-23 10:24:29,601] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5329
[2019-03-23 10:24:29,606] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.3, 95.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 215513.4275395103, 215513.4275395103, 72818.55191323622], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7796400.0000, 
sim time next is 7797000.0000, 
raw observation next is [13.3, 95.5, 1.0, 2.0, 0.2004016930155302, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 217582.4451687236, 217582.4451687236, 73279.31107844827], 
processed observation next is [1.0, 0.21739130434782608, 0.24090909090909093, 0.955, 1.0, 1.0, 0.000502116269412746, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08058609080323097, 0.08058609080323097, 0.17873002702060553], 
reward next is 0.8213, 
noisyNet noise sample is [array([-0.742366], dtype=float32), -0.28519598]. 
=============================================
[2019-03-23 10:24:29,620] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[77.35215 ]
 [77.373116]
 [77.38488 ]
 [77.38944 ]
 [77.4368  ]], R is [[77.37612915]
 [76.60237122]
 [75.83634949]
 [75.07798767]
 [75.14758301]].
[2019-03-23 10:24:35,565] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.8096469e-23 1.0000000e+00 2.3366238e-34 1.5719229e-14 4.5458699e-34], sum to 1.0000
[2019-03-23 10:24:35,574] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8535
[2019-03-23 10:24:35,580] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.31666666666667, 80.5, 1.0, 2.0, 0.3993059899883393, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 448076.2500747524, 448076.2500747521, 123837.2153176789], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7891800.0000, 
sim time next is 7892400.0000, 
raw observation next is [20.13333333333333, 83.0, 1.0, 2.0, 0.5497561305635711, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 618344.628416449, 618344.6284164487, 139234.1641121624], 
processed observation next is [1.0, 0.34782608695652173, 0.5515151515151513, 0.83, 1.0, 1.0, 0.43719516320446383, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22901652904312925, 0.22901652904312916, 0.33959552222478634], 
reward next is 0.6604, 
noisyNet noise sample is [array([-0.6898612], dtype=float32), 2.120295]. 
=============================================
[2019-03-23 10:24:36,779] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:24:36,780] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:24:36,816] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run7
[2019-03-23 10:24:38,001] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:24:38,001] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:24:38,008] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run7
[2019-03-23 10:24:38,049] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:24:38,049] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:24:38,060] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run7
[2019-03-23 10:24:38,251] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:24:38,251] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:24:38,258] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run7
[2019-03-23 10:24:38,305] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:24:38,305] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:24:38,312] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run7
[2019-03-23 10:24:38,340] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:24:38,341] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:24:38,351] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run7
[2019-03-23 10:24:38,429] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:24:38,429] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:24:38,435] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run7
[2019-03-23 10:24:38,538] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:24:38,539] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:24:38,542] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run7
[2019-03-23 10:24:38,729] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:24:38,730] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:24:38,733] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run7
[2019-03-23 10:24:38,764] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:24:38,764] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:24:38,778] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run7
[2019-03-23 10:24:38,809] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:24:38,809] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:24:38,812] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:24:38,812] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:24:38,824] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run7
[2019-03-23 10:24:38,855] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run7
[2019-03-23 10:24:38,896] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:24:38,896] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:24:38,900] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run7
[2019-03-23 10:24:38,953] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:24:38,953] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:24:39,001] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run7
[2019-03-23 10:24:39,198] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:24:39,198] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:24:39,210] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run7
[2019-03-23 10:24:42,664] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.5056311e-17 1.0000000e+00 2.9819589e-27 1.2854081e-14 1.0371477e-26], sum to 1.0000
[2019-03-23 10:24:42,671] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0933
[2019-03-23 10:24:42,675] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 83.0, 1.0, 2.0, 0.9155167106769074, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1039766.641749998, 1039766.641749998, 193689.0010265915], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 61200.0000, 
sim time next is 61800.0000, 
raw observation next is [21.16666666666667, 81.33333333333334, 1.0, 2.0, 0.5729734616306866, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 649949.2921895557, 649949.2921895559, 144846.6925817331], 
processed observation next is [1.0, 0.7391304347826086, 0.5984848484848487, 0.8133333333333335, 1.0, 1.0, 0.46621682703835826, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.24072196007020583, 0.2407219600702059, 0.3532846160530076], 
reward next is 0.6467, 
noisyNet noise sample is [array([-0.8119017], dtype=float32), -2.4647279]. 
=============================================
[2019-03-23 10:24:43,035] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.6940408e-22 1.0000000e+00 7.5215990e-33 5.0488306e-21 6.7206744e-32], sum to 1.0000
[2019-03-23 10:24:43,041] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5420
[2019-03-23 10:24:43,044] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 73.0, 1.0, 2.0, 0.4024858488302865, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 453586.6679300893, 453586.6679300893, 125091.4358171675], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 66000.0000, 
sim time next is 66600.0000, 
raw observation next is [21.5, 73.0, 1.0, 2.0, 0.3968863823053803, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 446550.1020606793, 446550.1020606793, 124208.3989912054], 
processed observation next is [1.0, 0.782608695652174, 0.6136363636363636, 0.73, 1.0, 1.0, 0.24610797788172536, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1653889266891405, 0.1653889266891405, 0.3029473146126961], 
reward next is 0.6971, 
noisyNet noise sample is [array([0.9330924], dtype=float32), -0.3252078]. 
=============================================
[2019-03-23 10:24:43,181] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.4706547e-22 1.0000000e+00 4.3145955e-34 1.3604708e-15 3.7729614e-33], sum to 1.0000
[2019-03-23 10:24:43,190] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3904
[2019-03-23 10:24:43,194] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.16666666666667, 45.66666666666667, 1.0, 2.0, 0.4809142627568607, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 522307.3689799053, 522307.3689799053, 114180.949965955], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 133800.0000, 
sim time next is 134400.0000, 
raw observation next is [22.33333333333334, 45.33333333333334, 1.0, 2.0, 0.5034682804334641, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 546816.4268587272, 546816.4268587272, 117563.5642722662], 
processed observation next is [1.0, 0.5652173913043478, 0.6515151515151518, 0.4533333333333334, 1.0, 1.0, 0.37933535054183015, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20252460254026936, 0.20252460254026936, 0.2867404006640639], 
reward next is 0.7133, 
noisyNet noise sample is [array([-2.559666], dtype=float32), -0.24682026]. 
=============================================
[2019-03-23 10:24:44,981] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-23 10:24:44,983] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 10:24:44,984] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:24:44,985] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 10:24:44,986] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:24:44,987] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 10:24:44,989] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 10:24:44,990] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 10:24:44,993] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:24:44,990] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:24:44,994] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:24:45,013] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run52
[2019-03-23 10:24:45,036] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run52
[2019-03-23 10:24:45,037] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run52
[2019-03-23 10:24:45,093] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run52
[2019-03-23 10:24:45,117] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run52
[2019-03-23 10:24:56,848] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05209292], dtype=float32), -1.2291102]
[2019-03-23 10:24:56,849] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.36666666666667, 62.66666666666667, 1.0, 2.0, 0.3803347501150406, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 428454.4200978216, 428454.4200978212, 127356.452785343]
[2019-03-23 10:24:56,850] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 10:24:56,853] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [6.2724106e-26 1.0000000e+00 0.0000000e+00 1.5039769e-20 1.3256792e-38], sampled 0.06028239341261876
[2019-03-23 10:25:14,664] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05209292], dtype=float32), -1.2291102]
[2019-03-23 10:25:14,665] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.71666666666667, 76.33333333333334, 1.0, 2.0, 0.4778715500947727, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 545221.605625738, 545221.6056257377, 142492.8464128487]
[2019-03-23 10:25:14,668] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 10:25:14,671] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.923102e-26 1.000000e+00 0.000000e+00 8.240201e-21 0.000000e+00], sampled 0.08125087704953537
[2019-03-23 10:25:28,017] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05209292], dtype=float32), -1.2291102]
[2019-03-23 10:25:28,018] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.33333333333334, 73.33333333333333, 1.0, 2.0, 0.4737538148450907, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 540533.6874418845, 540533.6874418845, 142325.926303087]
[2019-03-23 10:25:28,018] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 10:25:28,021] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.674093e-26 1.000000e+00 0.000000e+00 7.681679e-21 0.000000e+00], sampled 0.6016509462120103
[2019-03-23 10:25:50,483] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05209292], dtype=float32), -1.2291102]
[2019-03-23 10:25:50,485] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.96666666666667, 85.66666666666667, 1.0, 2.0, 0.4941986645573368, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 563541.470032144, 563541.470032144, 138921.8780160647]
[2019-03-23 10:25:50,487] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:25:50,489] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.1157665e-25 1.0000000e+00 0.0000000e+00 2.3687881e-20 3.1523593e-38], sampled 0.19393634921947833
[2019-03-23 10:26:12,169] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05209292], dtype=float32), -1.2291102]
[2019-03-23 10:26:12,171] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.8, 97.0, 1.0, 2.0, 0.4406045168993365, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 497264.66568565, 497264.66568565, 129018.0362238066]
[2019-03-23 10:26:12,172] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:26:12,175] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.00228636e-25 1.00000000e+00 0.00000000e+00 2.17667602e-20
 2.68338595e-38], sampled 0.6339161441694822
[2019-03-23 10:26:24,484] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 10:26:24,534] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 10:26:24,601] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 10:26:24,733] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 10:26:24,822] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 10:26:25,839] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 1275000, evaluation results [1275000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 10:26:27,460] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.3261959e-24 1.0000000e+00 2.3509446e-36 1.1284669e-17 2.4376011e-37], sum to 1.0000
[2019-03-23 10:26:27,465] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8336
[2019-03-23 10:26:27,471] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.33333333333334, 74.83333333333334, 1.0, 2.0, 0.2562709801893092, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 278258.845760281, 278258.8457602813, 81811.19727544353], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 115800.0000, 
sim time next is 116400.0000, 
raw observation next is [16.66666666666667, 72.66666666666667, 1.0, 2.0, 0.3452893481345998, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 374952.1879471433, 374952.1879471436, 91139.18800610153], 
processed observation next is [1.0, 0.34782608695652173, 0.39393939393939414, 0.7266666666666667, 1.0, 1.0, 0.18161168516824977, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13887118072116417, 0.1388711807211643, 0.22229070245390617], 
reward next is 0.7777, 
noisyNet noise sample is [array([-1.3636061], dtype=float32), -0.5585334]. 
=============================================
[2019-03-23 10:26:30,953] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.295134e-23 1.000000e+00 8.016804e-36 9.631890e-15 4.497142e-35], sum to 1.0000
[2019-03-23 10:26:30,963] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6360
[2019-03-23 10:26:30,969] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 77.0, 1.0, 2.0, 0.2507475857509964, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 272259.8694115796, 272259.8694115799, 86883.63084058253], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 204600.0000, 
sim time next is 205200.0000, 
raw observation next is [17.0, 77.0, 1.0, 2.0, 0.248913427558852, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 270267.8007037209, 270267.8007037212, 86688.65967884506], 
processed observation next is [0.0, 0.391304347826087, 0.4090909090909091, 0.77, 1.0, 1.0, 0.061141784448565, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10009918544582255, 0.10009918544582266, 0.21143575531425624], 
reward next is 0.7886, 
noisyNet noise sample is [array([-0.6366001], dtype=float32), 2.8421626]. 
=============================================
[2019-03-23 10:26:32,400] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.1012238e-30 1.0000000e+00 0.0000000e+00 3.1480836e-29 0.0000000e+00], sum to 1.0000
[2019-03-23 10:26:32,406] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0518
[2019-03-23 10:26:32,413] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 55.33333333333334, 1.0, 2.0, 0.2744387963179728, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 297991.4909122052, 297991.4909122052, 98688.31999837127], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 220200.0000, 
sim time next is 220800.0000, 
raw observation next is [20.0, 60.66666666666667, 1.0, 2.0, 0.2657118581522279, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 288512.7848160527, 288512.7848160524, 95996.81132590733], 
processed observation next is [0.0, 0.5652173913043478, 0.5454545454545454, 0.6066666666666667, 1.0, 1.0, 0.08213982269028489, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10685658696890842, 0.1068565869689083, 0.23413856420953008], 
reward next is 0.7659, 
noisyNet noise sample is [array([-0.36871898], dtype=float32), 2.2249188]. 
=============================================
[2019-03-23 10:26:36,603] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.2023737e-26 1.0000000e+00 1.5525151e-38 4.0685742e-17 0.0000000e+00], sum to 1.0000
[2019-03-23 10:26:36,610] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0410
[2019-03-23 10:26:36,614] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 64.0, 1.0, 2.0, 0.600504341781836, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 661314.3703234686, 661314.3703234689, 139359.4035555972], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 568800.0000, 
sim time next is 569400.0000, 
raw observation next is [21.0, 64.0, 1.0, 2.0, 0.5532645010506518, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 608689.7955799588, 608689.7955799588, 134282.6770415136], 
processed observation next is [1.0, 0.6086956521739131, 0.5909090909090909, 0.64, 1.0, 1.0, 0.44158062631331474, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22544066502961438, 0.22544066502961438, 0.3275187244914966], 
reward next is 0.6725, 
noisyNet noise sample is [array([-0.36856586], dtype=float32), -0.97289616]. 
=============================================
[2019-03-23 10:26:47,841] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.1965291e-23 1.0000000e+00 2.7199511e-38 1.3019907e-20 2.2948485e-35], sum to 1.0000
[2019-03-23 10:26:47,847] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3884
[2019-03-23 10:26:47,850] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 94.0, 1.0, 2.0, 0.2117971504057525, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 229957.7776970225, 229957.7776970222, 76366.8694500232], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 522000.0000, 
sim time next is 522600.0000, 
raw observation next is [14.0, 94.00000000000001, 1.0, 2.0, 0.2118212866604729, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 229983.9897195668, 229983.9897195671, 76369.7969033627], 
processed observation next is [1.0, 0.043478260869565216, 0.2727272727272727, 0.9400000000000002, 1.0, 1.0, 0.014776608325591106, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0851792554516914, 0.08517925545169151, 0.18626779732527488], 
reward next is 0.8137, 
noisyNet noise sample is [array([-0.6063277], dtype=float32), 0.58242774]. 
=============================================
[2019-03-23 10:26:48,927] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.4311513e-28 1.0000000e+00 0.0000000e+00 4.3851516e-18 0.0000000e+00], sum to 1.0000
[2019-03-23 10:26:48,935] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7378
[2019-03-23 10:26:48,942] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 88.0, 1.0, 2.0, 0.4281079137198302, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 464928.463002962, 464928.463002962, 108372.1915465904], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 550800.0000, 
sim time next is 551400.0000, 
raw observation next is [16.16666666666667, 88.00000000000001, 1.0, 2.0, 0.4293404939727976, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 466267.6964769795, 466267.6964769792, 110163.1784747039], 
processed observation next is [1.0, 0.391304347826087, 0.37121212121212144, 0.8800000000000001, 1.0, 1.0, 0.28667561746599696, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1726917394359183, 0.17269173943591823, 0.2686906792065949], 
reward next is 0.7313, 
noisyNet noise sample is [array([0.788308], dtype=float32), 0.28696442]. 
=============================================
[2019-03-23 10:26:53,902] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.6650512e-25 1.0000000e+00 0.0000000e+00 1.1803555e-18 0.0000000e+00], sum to 1.0000
[2019-03-23 10:26:53,914] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3864
[2019-03-23 10:26:53,923] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.33333333333334, 94.0, 1.0, 2.0, 0.2748678132924536, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 298457.4696221801, 298457.4696221801, 91960.73983058777], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 627600.0000, 
sim time next is 628200.0000, 
raw observation next is [15.5, 94.0, 1.0, 2.0, 0.2708770643544401, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 294122.9170138562, 294122.9170138559, 93136.68457836729], 
processed observation next is [1.0, 0.2608695652173913, 0.3409090909090909, 0.94, 1.0, 1.0, 0.0885963304430501, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10893441370883562, 0.10893441370883551, 0.22716264531309097], 
reward next is 0.7728, 
noisyNet noise sample is [array([-0.70071244], dtype=float32), -2.6043715]. 
=============================================
[2019-03-23 10:27:00,502] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.2775770e-21 1.0000000e+00 3.6636694e-31 2.0477329e-20 1.6712824e-31], sum to 1.0000
[2019-03-23 10:27:00,514] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4135
[2019-03-23 10:27:00,516] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.16666666666667, 99.0, 1.0, 2.0, 0.2241506345691974, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 243373.8717116997, 243373.8717116994, 76404.22669257729], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1021800.0000, 
sim time next is 1022400.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.2231484158507183, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 242285.4313358047, 242285.431335805, 76053.02536197123], 
processed observation next is [1.0, 0.8695652173913043, 0.22727272727272727, 1.0, 1.0, 1.0, 0.02893551981339785, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08973534493918692, 0.08973534493918704, 0.18549518380968594], 
reward next is 0.8145, 
noisyNet noise sample is [array([1.5251677], dtype=float32), -0.057442293]. 
=============================================
[2019-03-23 10:27:06,378] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.2194903e-24 1.0000000e+00 9.3803822e-38 4.9969221e-22 1.7269435e-36], sum to 1.0000
[2019-03-23 10:27:06,389] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3487
[2019-03-23 10:27:06,396] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.33333333333334, 98.00000000000001, 1.0, 2.0, 0.4114055570769625, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 466641.036838246, 466641.0368382463, 127720.1852079667], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 886200.0000, 
sim time next is 886800.0000, 
raw observation next is [19.66666666666667, 96.0, 1.0, 2.0, 0.4148527639173315, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 470899.1921344704, 470899.1921344704, 128302.5241183567], 
processed observation next is [0.0, 0.2608695652173913, 0.5303030303030305, 0.96, 1.0, 1.0, 0.26856595489666435, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.174407108197952, 0.174407108197952, 0.31293298565452854], 
reward next is 0.6871, 
noisyNet noise sample is [array([-0.8146121], dtype=float32), 1.0519072]. 
=============================================
[2019-03-23 10:27:07,783] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.7735195e-23 1.0000000e+00 1.1038897e-35 4.1115697e-19 3.1687627e-34], sum to 1.0000
[2019-03-23 10:27:07,789] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3816
[2019-03-23 10:27:07,796] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 78.83333333333333, 1.0, 2.0, 0.4542270752342902, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 518061.9530783548, 518061.9530783548, 134818.6013138615], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 900600.0000, 
sim time next is 901200.0000, 
raw observation next is [23.0, 79.66666666666667, 1.0, 2.0, 0.4577901788548892, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 522227.2249314512, 522227.2249314512, 135443.0537501319], 
processed observation next is [0.0, 0.43478260869565216, 0.6818181818181818, 0.7966666666666667, 1.0, 1.0, 0.32223772356861147, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1934174907153523, 0.1934174907153523, 0.3303489115856875], 
reward next is 0.6697, 
noisyNet noise sample is [array([0.64033496], dtype=float32), 1.6286378]. 
=============================================
[2019-03-23 10:27:14,500] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-23 10:27:14,503] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 10:27:14,505] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:27:14,505] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 10:27:14,506] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:27:14,507] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 10:27:14,508] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:27:14,509] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 10:27:14,509] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:27:14,510] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 10:27:14,511] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:27:14,529] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run53
[2019-03-23 10:27:14,556] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run53
[2019-03-23 10:27:14,556] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run53
[2019-03-23 10:27:14,607] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run53
[2019-03-23 10:27:14,608] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run53
[2019-03-23 10:27:30,577] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.06448276], dtype=float32), -1.2319382]
[2019-03-23 10:27:30,578] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [26.8, 64.0, 1.0, 2.0, 0.7277136011766534, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 95.55338755757306, 828861.4909473077, 828861.4909473077, 178180.6310867065]
[2019-03-23 10:27:30,579] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 10:27:30,583] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.2704734e-26 1.0000000e+00 0.0000000e+00 1.1111898e-21 1.2351881e-38], sampled 0.3948652364863461
[2019-03-23 10:28:02,645] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.06448276], dtype=float32), -1.2319382]
[2019-03-23 10:28:02,646] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.58506558, 91.36806056666666, 1.0, 2.0, 0.3562353772525502, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 393943.5938577063, 393943.593857706, 121966.5993556833]
[2019-03-23 10:28:02,647] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 10:28:02,651] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.2704734e-26 1.0000000e+00 0.0000000e+00 1.1111898e-21 1.2351881e-38], sampled 0.0720476989299027
[2019-03-23 10:28:28,916] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.06448276], dtype=float32), -1.2319382]
[2019-03-23 10:28:28,919] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.31666666666667, 36.0, 1.0, 2.0, 0.3334695080009459, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 362086.4470198497, 362086.4470198497, 103793.0736970041]
[2019-03-23 10:28:28,920] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 10:28:28,924] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.2704734e-26 1.0000000e+00 0.0000000e+00 1.1111898e-21 1.2351881e-38], sampled 0.1009061000970275
[2019-03-23 10:28:36,440] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.06448276], dtype=float32), -1.2319382]
[2019-03-23 10:28:36,441] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.6, 74.5, 1.0, 2.0, 0.4243441744937487, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 482150.9294015606, 482150.9294015603, 133934.4251000828]
[2019-03-23 10:28:36,444] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 10:28:36,446] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.2704734e-26 1.0000000e+00 0.0000000e+00 1.1111898e-21 1.2351881e-38], sampled 0.33084917132722247
[2019-03-23 10:28:54,028] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 10:28:54,294] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 10:28:54,325] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 10:28:54,428] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 10:28:54,494] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 10:28:55,514] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 1300000, evaluation results [1300000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 10:28:59,029] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.9166067e-27 1.0000000e+00 0.0000000e+00 5.1284084e-24 0.0000000e+00], sum to 1.0000
[2019-03-23 10:28:59,039] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2677
[2019-03-23 10:28:59,049] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 67.0, 1.0, 2.0, 0.3761505708960892, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 423464.6603338139, 423464.6603338136, 122519.1535468031], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1099800.0000, 
sim time next is 1100400.0000, 
raw observation next is [22.33333333333334, 67.66666666666667, 1.0, 2.0, 0.3755026936136174, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 422450.3885370153, 422450.3885370153, 122314.6886738986], 
processed observation next is [1.0, 0.7391304347826086, 0.6515151515151518, 0.6766666666666667, 1.0, 1.0, 0.2193783670170217, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15646310686556122, 0.15646310686556122, 0.2983285089607283], 
reward next is 0.7017, 
noisyNet noise sample is [array([0.01162572], dtype=float32), 0.5667654]. 
=============================================
[2019-03-23 10:29:01,871] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.6873449e-13 1.0000000e+00 3.4991977e-21 5.0793786e-11 6.0005770e-21], sum to 1.0000
[2019-03-23 10:29:01,887] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5745
[2019-03-23 10:29:01,892] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.16666666666667, 69.16666666666667, 1.0, 2.0, 0.9387276886477488, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1071573.318077801, 1071573.318077801, 206670.4018004249], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1167000.0000, 
sim time next is 1167600.0000, 
raw observation next is [25.33333333333334, 69.33333333333334, 1.0, 2.0, 0.7645385719302753, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 872362.2896315397, 872362.2896315397, 177920.2960924496], 
processed observation next is [1.0, 0.5217391304347826, 0.7878787878787882, 0.6933333333333335, 1.0, 1.0, 0.7056732149128442, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3230971443079777, 0.3230971443079777, 0.43395194168890144], 
reward next is 0.5660, 
noisyNet noise sample is [array([-0.8731133], dtype=float32), 1.9618489]. 
=============================================
[2019-03-23 10:29:04,692] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.8240140e-23 1.0000000e+00 4.1049894e-33 2.7850251e-24 6.4969977e-33], sum to 1.0000
[2019-03-23 10:29:04,699] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0253
[2019-03-23 10:29:04,702] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 96.0, 1.0, 2.0, 0.4507122123304471, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 509083.0455774519, 509083.0455774522, 130223.6629093913], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1218000.0000, 
sim time next is 1218600.0000, 
raw observation next is [19.0, 97.0, 1.0, 2.0, 0.4224101124904981, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 477500.7044702842, 477500.7044702842, 127730.6292367315], 
processed observation next is [1.0, 0.08695652173913043, 0.5, 0.97, 1.0, 1.0, 0.2780126406131226, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17685211276677193, 0.17685211276677193, 0.31153812008958903], 
reward next is 0.6885, 
noisyNet noise sample is [array([-0.9415503], dtype=float32), -0.51165277]. 
=============================================
[2019-03-23 10:29:11,244] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.0790842e-10 9.9999976e-01 5.1399251e-16 1.8399868e-07 1.0891603e-15], sum to 1.0000
[2019-03-23 10:29:11,250] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7625
[2019-03-23 10:29:11,256] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1252319.89511086 W.
[2019-03-23 10:29:11,261] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.0, 84.0, 1.0, 2.0, 0.3712704149975467, 1.0, 1.0, 0.3712704149975467, 1.0, 2.0, 0.7512209219932509, 6.9112, 6.9112, 77.3421103, 1252319.89511086, 1252319.89511086, 293987.3931555029], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1333800.0000, 
sim time next is 1334400.0000, 
raw observation next is [25.33333333333333, 82.33333333333334, 1.0, 2.0, 0.6761914484185552, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9852040275508032, 6.9112, 6.9112, 77.32846344354104, 1308554.55728285, 1308554.55728285, 295359.2229977931], 
processed observation next is [1.0, 0.43478260869565216, 0.7878787878787876, 0.8233333333333335, 1.0, 1.0, 0.5952393105231939, 0.0, 0.5, -0.25, 1.0, 1.0, 0.9788628965011473, 0.0, 0.0, 0.5084288129206541, 0.4846498360306852, 0.4846498360306852, 0.7203883487751052], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.4379833], dtype=float32), 1.5275798]. 
=============================================
[2019-03-23 10:29:24,221] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.60309213e-25 1.00000000e+00 4.09234800e-37 5.32864788e-19
 1.09765824e-35], sum to 1.0000
[2019-03-23 10:29:24,228] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5644
[2019-03-23 10:29:24,234] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.4333985332830342, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 491351.9649133786, 491351.9649133786, 129676.4223622292], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1572000.0000, 
sim time next is 1572600.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4371958754442346, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 495669.2455010431, 495669.2455010434, 130056.137521141], 
processed observation next is [1.0, 0.17391304347826086, 0.5, 1.0, 1.0, 1.0, 0.2964948443052932, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18358120203742337, 0.18358120203742348, 0.3172100915149781], 
reward next is 0.6828, 
noisyNet noise sample is [array([1.3870845], dtype=float32), -0.6475545]. 
=============================================
[2019-03-23 10:29:28,750] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.3182065e-22 1.0000000e+00 1.4375217e-34 9.0281949e-21 2.5662708e-33], sum to 1.0000
[2019-03-23 10:29:28,758] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6868
[2019-03-23 10:29:28,761] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.16666666666666, 93.0, 1.0, 2.0, 0.3512995376539663, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 391337.1687496797, 391337.16874968, 118431.7305430492], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1659000.0000, 
sim time next is 1659600.0000, 
raw observation next is [18.0, 94.0, 1.0, 2.0, 0.3460124353435253, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 385144.0633298625, 385144.0633298625, 117882.4048403556], 
processed observation next is [1.0, 0.21739130434782608, 0.45454545454545453, 0.94, 1.0, 1.0, 0.18251554417940663, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14264594938143055, 0.14264594938143055, 0.28751806058623314], 
reward next is 0.7125, 
noisyNet noise sample is [array([-0.1813542], dtype=float32), 0.46198457]. 
=============================================
[2019-03-23 10:29:34,665] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.6927888e-25 1.0000000e+00 0.0000000e+00 2.1316736e-17 3.0559310e-38], sum to 1.0000
[2019-03-23 10:29:34,670] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5517
[2019-03-23 10:29:34,675] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.66666666666667, 45.66666666666666, 1.0, 2.0, 0.3901453168590036, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 423682.8290772045, 423682.8290772045, 90409.16916235372], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1777200.0000, 
sim time next is 1777800.0000, 
raw observation next is [18.83333333333333, 45.83333333333334, 1.0, 2.0, 0.3844151422960067, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 417457.408161063, 417457.4081610627, 90212.16523025754], 
processed observation next is [1.0, 0.5652173913043478, 0.4924242424242422, 0.4583333333333334, 1.0, 1.0, 0.23051892787000836, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15461385487446777, 0.15461385487446766, 0.22002967129331108], 
reward next is 0.7800, 
noisyNet noise sample is [array([0.3517709], dtype=float32), -0.77896094]. 
=============================================
[2019-03-23 10:29:35,413] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.7980056e-31 1.0000000e+00 0.0000000e+00 4.2984599e-28 0.0000000e+00], sum to 1.0000
[2019-03-23 10:29:35,419] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1791
[2019-03-23 10:29:35,422] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.06666666666667, 44.66666666666666, 1.0, 2.0, 0.2659353480595206, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 288755.5245939007, 288755.5245939007, 78259.3171105027], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1791600.0000, 
sim time next is 1792200.0000, 
raw observation next is [19.03333333333333, 45.33333333333334, 1.0, 2.0, 0.2625698617242238, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 285100.1714324016, 285100.1714324013, 78088.02572435545], 
processed observation next is [1.0, 0.7391304347826086, 0.5015151515151515, 0.4533333333333334, 1.0, 1.0, 0.07821232715527975, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10559265608607465, 0.10559265608607456, 0.1904585993276962], 
reward next is 0.8095, 
noisyNet noise sample is [array([-0.7623657], dtype=float32), 0.90313643]. 
=============================================
[2019-03-23 10:29:35,807] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.9321143e-26 1.0000000e+00 0.0000000e+00 7.4162518e-22 0.0000000e+00], sum to 1.0000
[2019-03-23 10:29:35,815] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5573
[2019-03-23 10:29:35,823] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 52.0, 1.0, 2.0, 0.2301458661007415, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 249884.928550127, 249884.928550127, 73185.89516645805], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1800000.0000, 
sim time next is 1800600.0000, 
raw observation next is [17.0, 52.0, 1.0, 2.0, 0.2290423910530957, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 248686.504776765, 248686.5047767647, 73072.92126964727], 
processed observation next is [1.0, 0.8695652173913043, 0.4090909090909091, 0.52, 1.0, 1.0, 0.03630298881636962, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09210611288028334, 0.09210611288028323, 0.1782266372430421], 
reward next is 0.8218, 
noisyNet noise sample is [array([-0.9181634], dtype=float32), -1.3726766]. 
=============================================
[2019-03-23 10:29:37,557] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.5232047e-26 1.0000000e+00 0.0000000e+00 2.6031110e-22 0.0000000e+00], sum to 1.0000
[2019-03-23 10:29:37,564] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3676
[2019-03-23 10:29:37,574] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [10.83333333333333, 100.0, 1.0, 2.0, 0.2104712678972231, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 228517.8687207097, 228517.86872071, 70878.21838263322], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1835400.0000, 
sim time next is 1836000.0000, 
raw observation next is [11.0, 100.0, 1.0, 2.0, 0.3005860483793121, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 326392.2616203327, 326392.2616203327, 78631.4097779441], 
processed observation next is [1.0, 0.2608695652173913, 0.13636363636363635, 1.0, 1.0, 1.0, 0.12573256047414008, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12088602282234545, 0.12088602282234545, 0.19178392628766855], 
reward next is 0.8082, 
noisyNet noise sample is [array([0.5698947], dtype=float32), -0.2340185]. 
=============================================
[2019-03-23 10:29:37,598] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[77.199776]
 [77.19963 ]
 [77.19946 ]
 [77.19941 ]
 [77.199356]], R is [[77.23587036]
 [77.29063416]
 [77.32466888]
 [77.35089874]
 [77.37683105]].
[2019-03-23 10:29:38,908] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0906481e-24 1.0000000e+00 2.0725338e-36 9.3363746e-21 1.9014288e-36], sum to 1.0000
[2019-03-23 10:29:38,915] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5312
[2019-03-23 10:29:38,931] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 64.0, 1.0, 2.0, 0.3535546467649309, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 383931.0785844869, 383931.0785844869, 93541.57518116382], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1846800.0000, 
sim time next is 1847400.0000, 
raw observation next is [18.16666666666667, 62.0, 1.0, 2.0, 0.395563315848669, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 429569.1670900236, 429569.1670900236, 97277.38255014698], 
processed observation next is [1.0, 0.391304347826087, 0.4621212121212123, 0.62, 1.0, 1.0, 0.24445414481083622, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15909969151482356, 0.15909969151482356, 0.23726190865889507], 
reward next is 0.7627, 
noisyNet noise sample is [array([-0.5395897], dtype=float32), 1.5428971]. 
=============================================
[2019-03-23 10:29:40,629] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.2097138e-28 1.0000000e+00 0.0000000e+00 4.6071503e-25 0.0000000e+00], sum to 1.0000
[2019-03-23 10:29:40,631] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2346
[2019-03-23 10:29:40,636] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.83333333333334, 64.66666666666667, 1.0, 2.0, 0.2570849669210487, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 279142.9256065435, 279142.9256065438, 89191.36402453973], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1897800.0000, 
sim time next is 1898400.0000, 
raw observation next is [18.66666666666667, 65.33333333333334, 1.0, 2.0, 0.255130521885209, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 277020.1842901327, 277020.1842901324, 88386.36951458937], 
processed observation next is [1.0, 1.0, 0.4848484848484851, 0.6533333333333334, 1.0, 1.0, 0.06891315235651126, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1026000682556047, 0.10260006825560461, 0.2155765110111936], 
reward next is 0.7844, 
noisyNet noise sample is [array([0.03286027], dtype=float32), 0.5864274]. 
=============================================
[2019-03-23 10:29:43,740] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.4605275e-20 1.0000000e+00 3.1715158e-29 8.6241768e-19 1.5143902e-29], sum to 1.0000
[2019-03-23 10:29:43,747] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8609
[2019-03-23 10:29:43,753] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 60.0, 1.0, 2.0, 0.3369303425928318, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 371578.5029490732, 371578.5029490732, 115773.0945511861], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1976400.0000, 
sim time next is 1977000.0000, 
raw observation next is [21.83333333333334, 60.0, 1.0, 2.0, 0.3347724328347677, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 368515.3964578262, 368515.3964578265, 115351.9764395065], 
processed observation next is [1.0, 0.9130434782608695, 0.628787878787879, 0.6, 1.0, 1.0, 0.16846554104345962, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13648718387326897, 0.13648718387326908, 0.28134628399879635], 
reward next is 0.7187, 
noisyNet noise sample is [array([0.23370568], dtype=float32), 0.9542281]. 
=============================================
[2019-03-23 10:29:43,765] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[56.351818]
 [56.32932 ]
 [56.232124]
 [56.1829  ]
 [56.15285 ]], R is [[56.49238586]
 [56.6450882 ]
 [56.79607391]
 [56.94533157]
 [57.09292603]].
[2019-03-23 10:29:44,374] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 10:29:44,375] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 10:29:44,376] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 10:29:44,377] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:29:44,377] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:29:44,379] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 10:29:44,381] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:29:44,387] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 10:29:44,389] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 10:29:44,390] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:29:44,390] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:29:44,407] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run54
[2019-03-23 10:29:44,429] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run54
[2019-03-23 10:29:44,455] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run54
[2019-03-23 10:29:44,478] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run54
[2019-03-23 10:29:44,500] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run54
[2019-03-23 10:29:50,044] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02623145], dtype=float32), -1.1606618]
[2019-03-23 10:29:50,046] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.10571135833333, 45.69771209, 1.0, 2.0, 0.2461760052902583, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 267280.7095162165, 267280.7095162165, 77075.71503072661]
[2019-03-23 10:29:50,047] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 10:29:50,049] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.6879509e-26 1.0000000e+00 1.5481978e-38 1.3024812e-22 5.0549342e-38], sampled 0.6240931348798491
[2019-03-23 10:30:37,335] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02623145], dtype=float32), -1.1606618]
[2019-03-23 10:30:37,338] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.2, 83.0, 1.0, 2.0, 0.5402411085663712, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 614510.2729175857, 614510.2729175857, 152668.3219289817]
[2019-03-23 10:30:37,340] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 10:30:37,342] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [7.4170896e-25 1.0000000e+00 1.3543358e-36 1.7339539e-21 4.1614756e-36], sampled 0.2569595843363185
[2019-03-23 10:30:37,688] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02623145], dtype=float32), -1.1606618]
[2019-03-23 10:30:37,690] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.0, 94.0, 1.0, 2.0, 0.4320873064960606, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 491014.4479761011, 491014.4479761011, 130404.7890287598]
[2019-03-23 10:30:37,691] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:30:37,693] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.9559019e-25 1.0000000e+00 1.8587634e-37 5.4923803e-22 5.8680138e-37], sampled 0.9035236979009557
[2019-03-23 10:30:46,272] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02623145], dtype=float32), -1.1606618]
[2019-03-23 10:30:46,274] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [27.16666666666666, 69.33333333333334, 1.0, 2.0, 0.5597713945202133, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 633381.5715195404, 633381.5715195404, 152333.3672433452]
[2019-03-23 10:30:46,275] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:30:46,279] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.3852237e-25 1.0000000e+00 1.1117235e-37 4.0788357e-22 3.5342902e-37], sampled 0.3686086797785848
[2019-03-23 10:31:12,145] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02623145], dtype=float32), -1.1606618]
[2019-03-23 10:31:12,145] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.55, 93.0, 1.0, 2.0, 0.3726007236611405, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 417266.8685139545, 417266.8685139548, 121127.0923313897]
[2019-03-23 10:31:12,146] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:31:12,149] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.0654526e-26 1.0000000e+00 1.7898401e-38 1.4167561e-22 5.8327272e-38], sampled 0.6500730082896025
[2019-03-23 10:31:19,038] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02623145], dtype=float32), -1.1606618]
[2019-03-23 10:31:19,038] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [28.64463077666667, 53.85985007000001, 1.0, 2.0, 0.5264812165005804, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 599882.8043029206, 599882.8043029202, 150148.4942850414]
[2019-03-23 10:31:19,040] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 10:31:19,043] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.6840701e-26 1.0000000e+00 1.5457194e-38 1.3013091e-22 5.0469961e-38], sampled 0.00755996842232276
[2019-03-23 10:31:23,035] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 10:31:23,551] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 10:31:23,764] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 10:31:23,898] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 10:31:23,959] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 10:31:24,973] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 1325000, evaluation results [1325000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 10:31:27,632] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.7437308e-29 1.0000000e+00 0.0000000e+00 1.0869848e-24 0.0000000e+00], sum to 1.0000
[2019-03-23 10:31:27,641] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3251
[2019-03-23 10:31:27,649] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.5, 72.5, 1.0, 2.0, 0.2421362708272823, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 262907.240363693, 262907.2403636927, 85276.68233046256], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2100600.0000, 
sim time next is 2101200.0000, 
raw observation next is [18.0, 71.0, 1.0, 2.0, 0.2510262606431582, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 272562.5373299517, 272562.5373299519, 88689.63269968626], 
processed observation next is [0.0, 0.30434782608695654, 0.45454545454545453, 0.71, 1.0, 1.0, 0.06378282580394773, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10094908789998211, 0.10094908789998218, 0.21631617731630795], 
reward next is 0.7837, 
noisyNet noise sample is [array([0.9567504], dtype=float32), -0.022710444]. 
=============================================
[2019-03-23 10:31:27,984] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.8851911e-26 1.0000000e+00 1.0440648e-37 5.6625277e-17 1.2517903e-38], sum to 1.0000
[2019-03-23 10:31:27,995] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6623
[2019-03-23 10:31:28,003] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 47.00000000000001, 1.0, 2.0, 0.3233467762266972, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 354438.7178729446, 354438.7178729443, 113953.7686776238], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2045400.0000, 
sim time next is 2046000.0000, 
raw observation next is [24.0, 47.0, 1.0, 2.0, 0.3250133699460445, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 356271.0040993772, 356271.0040993772, 114075.4025684873], 
processed observation next is [0.0, 0.6956521739130435, 0.7272727272727273, 0.47, 1.0, 1.0, 0.15626671243255563, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13195222374051008, 0.13195222374051008, 0.27823268919143246], 
reward next is 0.7218, 
noisyNet noise sample is [array([1.4124827], dtype=float32), 1.5897431]. 
=============================================
[2019-03-23 10:31:28,017] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[72.66179]
 [72.66179]
 [72.66179]
 [72.66179]
 [72.66179]], R is [[72.65692902]
 [72.65242004]
 [72.64807892]
 [72.64364624]
 [72.6391449 ]].
[2019-03-23 10:31:28,518] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.0527595e-24 1.0000000e+00 1.8581193e-36 4.8697215e-18 1.6581212e-35], sum to 1.0000
[2019-03-23 10:31:28,525] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1973
[2019-03-23 10:31:28,532] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 47.0, 1.0, 2.0, 0.3252723278963493, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 356558.6688175596, 356558.6688175593, 114095.4093351333], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2046600.0000, 
sim time next is 2047200.0000, 
raw observation next is [24.0, 47.0, 1.0, 2.0, 0.3242633875697808, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 355450.8836410832, 355450.8836410832, 114022.2398691853], 
processed observation next is [0.0, 0.6956521739130435, 0.7272727272727273, 0.47, 1.0, 1.0, 0.15532923446222596, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1316484754226234, 0.1316484754226234, 0.27810302407118365], 
reward next is 0.7219, 
noisyNet noise sample is [array([-1.4187763], dtype=float32), -0.8419799]. 
=============================================
[2019-03-23 10:31:29,991] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.5697823e-26 1.0000000e+00 0.0000000e+00 6.5791949e-20 1.5552537e-38], sum to 1.0000
[2019-03-23 10:31:30,006] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8375
[2019-03-23 10:31:30,011] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.5, 63.66666666666666, 1.0, 2.0, 0.2583671957069453, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 280535.571502401, 280535.5715024007, 85858.93203571945], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2074200.0000, 
sim time next is 2074800.0000, 
raw observation next is [18.0, 67.33333333333334, 1.0, 2.0, 0.2533462545464436, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 275082.2826768341, 275082.2826768338, 85408.01991518385], 
processed observation next is [0.0, 0.0, 0.45454545454545453, 0.6733333333333335, 1.0, 1.0, 0.06668281818305449, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10188232691734596, 0.10188232691734585, 0.20831224369557036], 
reward next is 0.7917, 
noisyNet noise sample is [array([-0.03450173], dtype=float32), -0.7459458]. 
=============================================
[2019-03-23 10:31:30,679] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.662998e-28 1.000000e+00 0.000000e+00 5.799577e-24 0.000000e+00], sum to 1.0000
[2019-03-23 10:31:30,687] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2030
[2019-03-23 10:31:30,691] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 86.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 203194.6676941479, 203194.6676941476, 68236.20509079282], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2348400.0000, 
sim time next is 2349000.0000, 
raw observation next is [13.0, 85.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 201471.4990203494, 201471.4990203496, 67744.99004891537], 
processed observation next is [1.0, 0.17391304347826086, 0.22727272727272727, 0.85, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07461907371124052, 0.0746190737112406, 0.16523168304613503], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.5360686], dtype=float32), -1.7336935]. 
=============================================
[2019-03-23 10:31:30,703] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[74.21853 ]
 [74.32519 ]
 [74.47582 ]
 [74.57039 ]
 [74.657936]], R is [[73.3631897 ]
 [72.62955475]
 [71.90325928]
 [71.18422699]
 [70.47238159]].
[2019-03-23 10:31:33,989] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.9631097e-26 1.0000000e+00 1.7935798e-37 1.3053051e-24 1.6733314e-37], sum to 1.0000
[2019-03-23 10:31:33,999] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1159
[2019-03-23 10:31:34,006] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.83333333333333, 46.0, 1.0, 2.0, 0.3838007529955643, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 433528.267460776, 433528.267460776, 123986.1576735197], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2127000.0000, 
sim time next is 2127600.0000, 
raw observation next is [27.0, 45.0, 1.0, 2.0, 0.3824860815481905, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 431853.8193121884, 431853.8193121884, 123759.1203101365], 
processed observation next is [0.0, 0.6521739130434783, 0.8636363636363636, 0.45, 1.0, 1.0, 0.22810760193523813, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15994585900451422, 0.15994585900451422, 0.30185151295155244], 
reward next is 0.6981, 
noisyNet noise sample is [array([-0.34891954], dtype=float32), 0.9861297]. 
=============================================
[2019-03-23 10:31:34,978] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.9872621e-27 1.0000000e+00 0.0000000e+00 4.3303907e-27 0.0000000e+00], sum to 1.0000
[2019-03-23 10:31:34,987] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2411
[2019-03-23 10:31:34,990] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 69.0, 1.0, 2.0, 0.4056776423610355, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 459702.6730219625, 459702.6730219627, 126872.6312796374], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2146200.0000, 
sim time next is 2146800.0000, 
raw observation next is [23.0, 69.0, 1.0, 2.0, 0.4063576432142741, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 460477.8567301942, 460477.8567301942, 126939.3772372139], 
processed observation next is [0.0, 0.8695652173913043, 0.6818181818181818, 0.69, 1.0, 1.0, 0.25794705401784257, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17054735434451637, 0.17054735434451637, 0.3096082371639364], 
reward next is 0.6904, 
noisyNet noise sample is [array([-1.1005818], dtype=float32), 1.0217651]. 
=============================================
[2019-03-23 10:31:35,410] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.3764616e-24 1.0000000e+00 2.1929509e-37 5.0590127e-20 1.4574597e-35], sum to 1.0000
[2019-03-23 10:31:35,418] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5591
[2019-03-23 10:31:35,422] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.16666666666667, 88.0, 1.0, 2.0, 0.3125530162570411, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 339391.164032442, 339391.164032442, 112041.2472996097], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2163000.0000, 
sim time next is 2163600.0000, 
raw observation next is [17.0, 88.0, 1.0, 2.0, 0.3068153970052884, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 333158.7355356922, 333158.7355356922, 110935.7411240996], 
processed observation next is [1.0, 0.043478260869565216, 0.4090909090909091, 0.88, 1.0, 1.0, 0.13351924625661052, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12339212427247859, 0.12339212427247859, 0.27057497835146244], 
reward next is 0.7294, 
noisyNet noise sample is [array([-0.38390845], dtype=float32), -0.40619567]. 
=============================================
[2019-03-23 10:31:38,576] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.3328840e-28 1.0000000e+00 0.0000000e+00 1.7495427e-27 0.0000000e+00], sum to 1.0000
[2019-03-23 10:31:38,582] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1404
[2019-03-23 10:31:38,587] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.5, 85.5, 1.0, 2.0, 0.3769947057348682, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 422467.7362278725, 422467.7362278728, 121628.0789200234], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2233800.0000, 
sim time next is 2234400.0000, 
raw observation next is [19.33333333333334, 86.33333333333334, 1.0, 2.0, 0.3731138857119658, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 417789.6144477095, 417789.6144477095, 121146.2303001943], 
processed observation next is [1.0, 0.8695652173913043, 0.5151515151515155, 0.8633333333333334, 1.0, 1.0, 0.21639235713995722, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15473689423989243, 0.15473689423989243, 0.2954786104882788], 
reward next is 0.7045, 
noisyNet noise sample is [array([0.56198907], dtype=float32), 0.58350885]. 
=============================================
[2019-03-23 10:31:41,674] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.0478226e-24 1.0000000e+00 1.5159562e-37 4.0778555e-22 3.7652223e-35], sum to 1.0000
[2019-03-23 10:31:41,682] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5631
[2019-03-23 10:31:41,687] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.33333333333333, 50.0, 1.0, 2.0, 0.3551492842631254, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 385663.4096285639, 385663.4096285641, 90421.33521844447], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2292000.0000, 
sim time next is 2292600.0000, 
raw observation next is [19.66666666666667, 49.5, 1.0, 2.0, 0.3546837535787502, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 385157.6807249016, 385157.6807249016, 91135.4021954006], 
processed observation next is [1.0, 0.5217391304347826, 0.5303030303030305, 0.495, 1.0, 1.0, 0.19335469197343774, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14265099286107466, 0.14265099286107466, 0.22228146876926977], 
reward next is 0.7777, 
noisyNet noise sample is [array([-0.8862953], dtype=float32), -0.019940048]. 
=============================================
[2019-03-23 10:31:48,835] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.770790e-26 1.000000e+00 0.000000e+00 3.705356e-24 0.000000e+00], sum to 1.0000
[2019-03-23 10:31:48,844] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5173
[2019-03-23 10:31:48,847] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.5, 75.66666666666667, 1.0, 2.0, 0.2381321680646042, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 258558.501447915, 258558.5014479152, 81289.3398787324], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2419800.0000, 
sim time next is 2420400.0000, 
raw observation next is [16.0, 79.33333333333334, 1.0, 2.0, 0.2370027166953086, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 257331.8443758678, 257331.8443758681, 80875.99130889362], 
processed observation next is [1.0, 0.0, 0.36363636363636365, 0.7933333333333334, 1.0, 1.0, 0.046253395869135724, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09530809050958067, 0.09530809050958078, 0.1972585153875454], 
reward next is 0.8027, 
noisyNet noise sample is [array([-1.608195], dtype=float32), 0.8049924]. 
=============================================
[2019-03-23 10:31:51,115] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.6951256e-25 1.0000000e+00 1.9616668e-36 7.0559295e-16 3.2869395e-37], sum to 1.0000
[2019-03-23 10:31:51,122] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3197
[2019-03-23 10:31:51,128] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.03333333333333, 68.16666666666667, 1.0, 2.0, 0.7145441038062146, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 794566.6961173966, 794566.6961173966, 155005.1961585238], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2473800.0000, 
sim time next is 2474400.0000, 
raw observation next is [21.06666666666667, 67.33333333333334, 1.0, 2.0, 0.6815202753996776, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 756994.7024097586, 756994.7024097586, 150655.2588719962], 
processed observation next is [1.0, 0.6521739130434783, 0.5939393939393941, 0.6733333333333335, 1.0, 1.0, 0.601900344249597, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2803684082999106, 0.2803684082999106, 0.3674518509073078], 
reward next is 0.6325, 
noisyNet noise sample is [array([-1.1997], dtype=float32), -1.8549516]. 
=============================================
[2019-03-23 10:31:56,718] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.1041483e-28 1.0000000e+00 0.0000000e+00 3.1506249e-25 0.0000000e+00], sum to 1.0000
[2019-03-23 10:31:56,728] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1698
[2019-03-23 10:31:56,733] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.16666666666667, 52.5, 1.0, 2.0, 0.3032233814083451, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 329256.987072128, 329256.9870721277, 111407.8158965152], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2569800.0000, 
sim time next is 2570400.0000, 
raw observation next is [22.0, 53.0, 1.0, 2.0, 0.3004900835019469, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 326288.0229123501, 326288.0229123498, 111223.6385874089], 
processed observation next is [1.0, 0.782608695652174, 0.6363636363636364, 0.53, 1.0, 1.0, 0.1256126043774336, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.120847415893463, 0.12084741589346289, 0.2712771672863632], 
reward next is 0.7287, 
noisyNet noise sample is [array([2.0777206], dtype=float32), 1.0236104]. 
=============================================
[2019-03-23 10:32:00,482] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0254651e-23 1.0000000e+00 3.1894623e-35 1.4666750e-18 7.1442879e-36], sum to 1.0000
[2019-03-23 10:32:00,487] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2004
[2019-03-23 10:32:00,492] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 42.0, 1.0, 2.0, 0.357666462567485, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 401450.3368464043, 401450.3368464043, 120323.7101464733], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2640000.0000, 
sim time next is 2640600.0000, 
raw observation next is [27.0, 42.0, 1.0, 2.0, 0.3577811411993104, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 401579.419710302, 401579.419710302, 120333.4016267689], 
processed observation next is [0.0, 0.5652173913043478, 0.8636363636363636, 0.42, 1.0, 1.0, 0.19722642649913802, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14873311841122297, 0.14873311841122297, 0.29349610152870464], 
reward next is 0.7065, 
noisyNet noise sample is [array([-1.2910604], dtype=float32), -0.32217684]. 
=============================================
[2019-03-23 10:32:00,510] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.3061355e-26 1.0000000e+00 1.1515642e-37 6.2787821e-25 6.8136660e-37], sum to 1.0000
[2019-03-23 10:32:00,517] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6011
[2019-03-23 10:32:00,524] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 54.5, 1.0, 2.0, 0.3580651380151278, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 400235.5741982752, 400235.5741982752, 119571.8925608131], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2664600.0000, 
sim time next is 2665200.0000, 
raw observation next is [24.0, 55.00000000000001, 1.0, 2.0, 0.359790983226663, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 402556.072715061, 402556.0727150613, 119891.4635556923], 
processed observation next is [0.0, 0.8695652173913043, 0.7272727272727273, 0.55, 1.0, 1.0, 0.1997387290333287, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1490948417463189, 0.149094841746319, 0.29241820379437145], 
reward next is 0.7076, 
noisyNet noise sample is [array([0.83613575], dtype=float32), -0.22948745]. 
=============================================
[2019-03-23 10:32:02,322] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.8119938e-25 1.0000000e+00 1.0268165e-36 2.8508403e-25 2.7418007e-35], sum to 1.0000
[2019-03-23 10:32:02,330] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2472
[2019-03-23 10:32:02,336] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.3, 75.0, 1.0, 2.0, 0.3527265220585275, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 392480.0790681368, 392480.0790681368, 118355.0483894638], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2678400.0000, 
sim time next is 2679000.0000, 
raw observation next is [20.25, 75.83333333333333, 1.0, 2.0, 0.3512870550314278, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 390915.8214390898, 390915.8214390896, 118257.1609718758], 
processed observation next is [0.0, 0.0, 0.5568181818181818, 0.7583333333333333, 1.0, 1.0, 0.18910881878928476, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14478363757003326, 0.14478363757003318, 0.2884320999314044], 
reward next is 0.7116, 
noisyNet noise sample is [array([0.36592644], dtype=float32), 0.69314456]. 
=============================================
[2019-03-23 10:32:02,362] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[68.09745]
 [68.09745]
 [68.09745]
 [68.09745]
 [68.09745]], R is [[68.12804413]
 [68.15808868]
 [68.18621063]
 [68.2124176 ]
 [68.23677826]].
[2019-03-23 10:32:04,155] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.5434609e-24 1.0000000e+00 3.9416466e-35 1.4446646e-24 7.9157061e-35], sum to 1.0000
[2019-03-23 10:32:04,165] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1441
[2019-03-23 10:32:04,172] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.71666666666667, 84.66666666666667, 1.0, 2.0, 0.4374755810460882, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 498299.8390142911, 498299.8390142911, 132064.5398745193], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2711400.0000, 
sim time next is 2712000.0000, 
raw observation next is [21.93333333333334, 83.33333333333334, 1.0, 2.0, 0.4382218560379608, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 499224.3274911459, 499224.3274911459, 132230.6043330711], 
processed observation next is [0.0, 0.391304347826087, 0.6333333333333336, 0.8333333333333335, 1.0, 1.0, 0.297777320047451, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18489789907079476, 0.18489789907079476, 0.32251366910505147], 
reward next is 0.6775, 
noisyNet noise sample is [array([0.15332834], dtype=float32), -1.437182]. 
=============================================
[2019-03-23 10:32:04,186] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[69.62744]
 [69.60122]
 [69.57887]
 [69.57198]
 [69.56182]], R is [[69.65113831]
 [69.63252258]
 [69.61506653]
 [69.59980011]
 [69.58654022]].
[2019-03-23 10:32:13,815] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-23 10:32:13,816] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 10:32:13,816] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:32:13,817] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 10:32:13,819] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 10:32:13,819] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 10:32:13,820] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:32:13,822] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:32:13,817] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 10:32:13,822] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:32:13,824] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:32:13,841] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run55
[2019-03-23 10:32:13,866] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run55
[2019-03-23 10:32:13,890] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run55
[2019-03-23 10:32:13,891] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run55
[2019-03-23 10:32:13,940] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run55
[2019-03-23 10:32:23,647] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.03050408], dtype=float32), -1.1574255]
[2019-03-23 10:32:23,648] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.33333333333334, 57.33333333333334, 1.0, 2.0, 0.2628948462116909, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 285437.1693453452, 285437.1693453448, 90100.58344018708]
[2019-03-23 10:32:23,650] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 10:32:23,653] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.4768937e-23 1.0000000e+00 5.0801913e-34 3.0797391e-20 9.8173100e-34], sampled 0.021514168153343394
[2019-03-23 10:32:36,025] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.03050408], dtype=float32), -1.1574255]
[2019-03-23 10:32:36,028] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.98333333333333, 78.83333333333334, 1.0, 2.0, 0.6040745763982741, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 99.2718363498942, 686765.2442919126, 686765.2442919126, 154434.3602208156]
[2019-03-23 10:32:36,029] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 10:32:36,031] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [6.1267055e-21 1.0000000e+00 1.0804085e-30 3.1220061e-18 1.9702673e-30], sampled 0.043821714933241385
[2019-03-23 10:32:52,505] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.03050408], dtype=float32), -1.1574255]
[2019-03-23 10:32:52,506] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.03333333333333, 65.33333333333333, 1.0, 2.0, 0.3248844428418714, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 357306.7971342643, 357306.797134264, 118818.6942083968]
[2019-03-23 10:32:52,507] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 10:32:52,510] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.2297801e-22 1.0000000e+00 7.9639331e-33 1.6221356e-19 1.5069137e-32], sampled 0.5203136712360101
[2019-03-23 10:32:52,769] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.03050408], dtype=float32), -1.1574255]
[2019-03-23 10:32:52,772] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.481005325, 88.477513435, 1.0, 2.0, 0.4670127779120218, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 532836.630952014, 532836.630952014, 141639.9993338508]
[2019-03-23 10:32:52,774] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 10:32:52,777] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.6967600e-23 1.0000000e+00 5.5625821e-34 3.2545033e-20 1.0742054e-33], sampled 0.14183896438426657
[2019-03-23 10:33:04,978] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.03050408], dtype=float32), -1.1574255]
[2019-03-23 10:33:04,979] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [28.80164430333333, 44.41256357666667, 1.0, 2.0, 0.7530227557796662, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 857887.0297812708, 857887.0297812708, 175654.1392273608]
[2019-03-23 10:33:04,981] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 10:33:04,984] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.4918904e-21 1.0000000e+00 4.7037783e-31 1.8868649e-18 8.6217884e-31], sampled 0.3520571854085035
[2019-03-23 10:33:08,564] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.03050408], dtype=float32), -1.1574255]
[2019-03-23 10:33:08,567] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.0, 90.0, 1.0, 2.0, 0.4078117242811046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 461691.4690193054, 461691.4690193054, 131124.565440547]
[2019-03-23 10:33:08,568] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 10:33:08,571] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.7226084e-21 1.0000000e+00 7.3526401e-31 2.4726796e-18 1.3439029e-30], sampled 0.06461121462566288
[2019-03-23 10:33:19,232] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.03050408], dtype=float32), -1.1574255]
[2019-03-23 10:33:19,232] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.39144587, 98.55614073666666, 1.0, 2.0, 0.3529047109215062, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 391539.3987946216, 391539.3987946212, 122218.1452158847]
[2019-03-23 10:33:19,235] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 10:33:19,238] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.0821804e-23 1.0000000e+00 6.4428203e-34 3.5563112e-20 1.2427771e-33], sampled 0.40069332839874017
[2019-03-23 10:33:34,057] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.03050408], dtype=float32), -1.1574255]
[2019-03-23 10:33:34,058] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [13.86666666666667, 83.66666666666667, 1.0, 2.0, 0.2037913462035061, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 221263.5357140165, 221263.5357140162, 72135.38737912604]
[2019-03-23 10:33:34,060] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:33:34,063] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0072784e-22 1.0000000e+00 2.4536149e-33 7.9797073e-20 4.6849702e-33], sampled 0.2946624400245188
[2019-03-23 10:33:35,149] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.03050408], dtype=float32), -1.1574255]
[2019-03-23 10:33:35,150] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.88455734, 66.57336857666667, 1.0, 2.0, 0.3846585839381651, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 433736.1346968673, 433736.1346968673, 127958.8414613152]
[2019-03-23 10:33:35,152] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 10:33:35,159] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.4886648e-23 1.0000000e+00 5.1057198e-34 3.0889399e-20 9.8663419e-34], sampled 0.8648803460172273
[2019-03-23 10:33:52,842] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 10:33:52,918] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 10:33:53,214] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 10:33:53,243] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 10:33:53,250] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 10:33:54,265] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 1350000, evaluation results [1350000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 10:34:05,060] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.5795717e-20 1.0000000e+00 3.4118052e-30 1.2017288e-12 1.0115605e-29], sum to 1.0000
[2019-03-23 10:34:05,066] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4261
[2019-03-23 10:34:05,069] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 83.0, 1.0, 2.0, 0.530366192185336, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 604430.0772611053, 604430.0772611051, 142483.9509134935], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3122400.0000, 
sim time next is 3123000.0000, 
raw observation next is [22.0, 83.0, 1.0, 2.0, 0.531017499047291, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 605143.0008539871, 605143.0008539871, 142520.6537824201], 
processed observation next is [1.0, 0.13043478260869565, 0.6363636363636364, 0.83, 1.0, 1.0, 0.41377187380911373, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22412703735332853, 0.22412703735332853, 0.3476113506888295], 
reward next is 0.6524, 
noisyNet noise sample is [array([0.22819398], dtype=float32), -0.15732162]. 
=============================================
[2019-03-23 10:34:05,094] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[65.62141 ]
 [65.063835]
 [66.703804]
 [66.66007 ]
 [66.306595]], R is [[65.88582611]
 [65.87944794]
 [65.83662415]
 [65.84146881]
 [65.84777832]].
[2019-03-23 10:34:11,884] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.062053e-21 1.000000e+00 1.149307e-32 3.804986e-13 6.969516e-33], sum to 1.0000
[2019-03-23 10:34:11,886] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3911
[2019-03-23 10:34:11,896] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 59.0, 1.0, 2.0, 0.3584772274780035, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 399765.1579699132, 399765.1579699129, 119192.5506005101], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3234600.0000, 
sim time next is 3235200.0000, 
raw observation next is [23.33333333333334, 57.33333333333334, 1.0, 2.0, 0.3587791178705175, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 400314.2069495218, 400314.2069495221, 119309.6415449236], 
processed observation next is [0.0, 0.43478260869565216, 0.6969696969696972, 0.5733333333333335, 1.0, 1.0, 0.19847389733814688, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14826452109241547, 0.14826452109241559, 0.29099912571932585], 
reward next is 0.7090, 
noisyNet noise sample is [array([0.07706694], dtype=float32), -0.4153952]. 
=============================================
[2019-03-23 10:34:19,389] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.6499435e-20 1.0000000e+00 6.5496095e-31 8.4986029e-12 2.9691392e-30], sum to 1.0000
[2019-03-23 10:34:19,395] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3463
[2019-03-23 10:34:19,403] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.83333333333333, 95.0, 1.0, 2.0, 0.3436018676141079, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 381941.3996080966, 381941.3996080969, 117473.2862846886], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3394200.0000, 
sim time next is 3394800.0000, 
raw observation next is [18.0, 94.0, 1.0, 2.0, 0.3450961898347979, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 383922.187497608, 383922.1874976083, 117724.6482429373], 
processed observation next is [1.0, 0.30434782608695654, 0.45454545454545453, 0.94, 1.0, 1.0, 0.18137023729349736, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14219340277689185, 0.14219340277689196, 0.28713328839740804], 
reward next is 0.7129, 
noisyNet noise sample is [array([-1.0632714], dtype=float32), 0.022024931]. 
=============================================
[2019-03-23 10:34:20,350] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.1027705e-19 1.0000000e+00 1.3796783e-29 2.5183516e-12 2.6002250e-28], sum to 1.0000
[2019-03-23 10:34:20,356] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2657
[2019-03-23 10:34:20,366] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1116661.377607891 W.
[2019-03-23 10:34:20,379] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.5, 67.16666666666667, 1.0, 2.0, 0.9786492264676998, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1116661.377607891, 1116661.377607891, 210024.4560141954], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3408600.0000, 
sim time next is 3409200.0000, 
raw observation next is [25.0, 65.0, 1.0, 2.0, 0.3375133849310871, 1.0, 1.0, 0.3375133849310871, 1.0, 1.0, 0.6825413222491828, 6.9112, 6.9112, 77.3421103, 1155297.00965858, 1155297.00965858, 269649.2730912748], 
processed observation next is [1.0, 0.4782608695652174, 0.7727272727272727, 0.65, 1.0, 1.0, 0.1718917311638589, 1.0, 0.5, 0.1718917311638589, 1.0, 0.5, 0.5464876032131184, 0.0, 0.0, 0.5085185399722538, 0.4278877813550296, 0.4278877813550296, 0.657681153881158], 
reward next is 0.3423, 
noisyNet noise sample is [array([-0.29807276], dtype=float32), 1.0277836]. 
=============================================
[2019-03-23 10:34:22,395] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.3416808e-21 1.0000000e+00 5.3962185e-32 3.7671244e-17 2.3323795e-31], sum to 1.0000
[2019-03-23 10:34:22,403] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8772
[2019-03-23 10:34:22,410] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 89.0, 1.0, 2.0, 0.5230000472129046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 595820.8925987399, 595820.8925987399, 145575.649634238], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3447600.0000, 
sim time next is 3448200.0000, 
raw observation next is [23.0, 89.0, 1.0, 2.0, 0.5235989976299394, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 596503.3804635563, 596503.3804635563, 145648.8583592886], 
processed observation next is [1.0, 0.9130434782608695, 0.6818181818181818, 0.89, 1.0, 1.0, 0.4044987470374243, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2209271779494653, 0.2209271779494653, 0.3552411179494844], 
reward next is 0.6448, 
noisyNet noise sample is [array([0.29530525], dtype=float32), 1.5187093]. 
=============================================
[2019-03-23 10:34:43,181] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-23 10:34:43,185] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 10:34:43,186] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 10:34:43,186] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:34:43,187] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:34:43,186] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 10:34:43,188] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 10:34:43,190] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:34:43,190] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 10:34:43,193] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:34:43,196] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:34:43,209] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run56
[2019-03-23 10:34:43,234] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run56
[2019-03-23 10:34:43,257] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run56
[2019-03-23 10:34:43,282] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run56
[2019-03-23 10:34:43,283] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run56
[2019-03-23 10:35:07,589] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.04629762], dtype=float32), -1.1847998]
[2019-03-23 10:35:07,592] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [14.175992175, 81.339090355, 1.0, 2.0, 0.2138487355622345, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 232175.2394961421, 232175.2394961421, 77667.47588860283]
[2019-03-23 10:35:07,593] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 10:35:07,596] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.2736596e-24 1.0000000e+00 6.5673816e-36 9.2087937e-20 9.8281666e-36], sampled 0.006750964518008495
[2019-03-23 10:35:07,664] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.04629762], dtype=float32), -1.1847998]
[2019-03-23 10:35:07,664] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.0, 69.0, 1.0, 2.0, 0.9156636630970589, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1031972.4647145, 1031972.4647145, 188738.1033795012]
[2019-03-23 10:35:07,665] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:35:07,671] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.5595476e-23 1.0000000e+00 1.4255733e-34 5.0413494e-19 2.1080666e-34], sampled 0.8935507148802815
[2019-03-23 10:35:13,560] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.04629762], dtype=float32), -1.1847998]
[2019-03-23 10:35:13,561] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.08952787666666, 92.50793997, 1.0, 2.0, 0.4090821628211642, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 464489.948882752, 464489.9488827516, 132198.6407094011]
[2019-03-23 10:35:13,563] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 10:35:13,564] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.2736596e-24 1.0000000e+00 6.5673816e-36 9.2087937e-20 9.8281666e-36], sampled 0.7435159977584507
[2019-03-23 10:35:18,031] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.04629762], dtype=float32), -1.1847998]
[2019-03-23 10:35:18,032] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.0, 91.0, 1.0, 2.0, 0.4052872763414738, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 459310.8830946948, 459310.8830946945, 131204.5771327343]
[2019-03-23 10:35:18,032] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 10:35:18,034] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.2736596e-24 1.0000000e+00 6.5673816e-36 9.2087937e-20 9.8281666e-36], sampled 0.6851125524628608
[2019-03-23 10:35:23,198] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.04629762], dtype=float32), -1.1847998]
[2019-03-23 10:35:23,199] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.73333333333333, 89.33333333333333, 1.0, 2.0, 0.4382572595554526, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 498387.1398027299, 498387.1398027299, 135676.9455227544]
[2019-03-23 10:35:23,201] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 10:35:23,205] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.2736596e-24 1.0000000e+00 6.5673816e-36 9.2087937e-20 9.8281666e-36], sampled 0.46807577178370385
[2019-03-23 10:35:29,257] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.04629762], dtype=float32), -1.1847998]
[2019-03-23 10:35:29,259] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.23333333333333, 82.33333333333334, 1.0, 2.0, 0.5545133021356502, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 617007.1371041723, 617007.1371041723, 141237.9334375835]
[2019-03-23 10:35:29,260] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 10:35:29,263] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.2736596e-24 1.0000000e+00 6.5673816e-36 9.2087937e-20 9.8281666e-36], sampled 0.5100355249632365
[2019-03-23 10:35:36,878] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.04629762], dtype=float32), -1.1847998]
[2019-03-23 10:35:36,879] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [15.12523307, 90.11417876, 1.0, 2.0, 0.2311645834650197, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 250978.9535543226, 250978.9535543222, 86460.64271802957]
[2019-03-23 10:35:36,882] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 10:35:36,887] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.2736596e-24 1.0000000e+00 6.5673816e-36 9.2087937e-20 9.8281666e-36], sampled 0.6510160945616097
[2019-03-23 10:35:37,399] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.04629762], dtype=float32), -1.1847998]
[2019-03-23 10:35:37,401] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.0, 64.0, 1.0, 2.0, 0.2623934285852774, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 284908.542996777, 284908.5429967767, 90439.90025318418]
[2019-03-23 10:35:37,404] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:35:37,407] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.2736596e-24 1.0000000e+00 6.5673816e-36 9.2087937e-20 9.8281666e-36], sampled 0.7445629641216344
[2019-03-23 10:35:54,574] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.04629762], dtype=float32), -1.1847998]
[2019-03-23 10:35:54,575] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [27.36666666666667, 46.66666666666667, 1.0, 2.0, 0.5782534398674782, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9624569317371926, 6.911199999999999, 6.9112, 77.32846342270815, 1207053.763181893, 1207053.763181893, 259693.2630850093]
[2019-03-23 10:35:54,577] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:35:54,582] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [5.3748975e-23 1.0000000e+00 4.3204257e-34 9.3445436e-19 6.3615922e-34], sampled 0.8843898335784283
[2019-03-23 10:35:54,583] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1207053.763181893 W.
[2019-03-23 10:36:12,530] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.04629762], dtype=float32), -1.1847998]
[2019-03-23 10:36:12,531] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.23333333333333, 54.16666666666666, 1.0, 2.0, 0.2830028589481163, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 307274.9554986085, 307274.9554986085, 94609.90715509804]
[2019-03-23 10:36:12,532] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 10:36:12,536] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.2736596e-24 1.0000000e+00 6.5673816e-36 9.2087937e-20 9.8281666e-36], sampled 0.4177518884117901
[2019-03-23 10:36:14,493] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.04629762], dtype=float32), -1.1847998]
[2019-03-23 10:36:14,495] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.43333333333334, 84.0, 1.0, 2.0, 0.4361137375320211, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 495909.0396405181, 495909.0396405184, 131076.6163414654]
[2019-03-23 10:36:14,497] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:36:14,499] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.2736596e-24 1.0000000e+00 6.5673816e-36 9.2087937e-20 9.8281666e-36], sampled 0.6366922089895697
[2019-03-23 10:36:19,783] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.04629762], dtype=float32), -1.1847998]
[2019-03-23 10:36:19,785] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [14.52686904, 81.33417085333335, 1.0, 2.0, 0.2363020843174004, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 256558.0078963783, 256558.0078963779, 80864.17448003992]
[2019-03-23 10:36:19,786] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 10:36:19,788] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.2736596e-24 1.0000000e+00 6.5673816e-36 9.2087937e-20 9.8281666e-36], sampled 0.14698768009209306
[2019-03-23 10:36:21,735] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 10:36:21,755] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 10:36:21,761] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 10:36:21,828] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 10:36:21,932] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.04629762], dtype=float32), -1.1847998]
[2019-03-23 10:36:21,932] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [17.25, 66.83333333333333, 1.0, 2.0, 0.258024598738849, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 280148.0826458542, 280148.0826458539, 86334.62056612168]
[2019-03-23 10:36:21,932] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 10:36:21,933] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.2736596e-24 1.0000000e+00 6.5673816e-36 9.2087937e-20 9.8281666e-36], sampled 0.5613662583717999
[2019-03-23 10:36:21,977] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 10:36:22,992] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 1375000, evaluation results [1375000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 10:36:23,012] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.5307279e-26 1.0000000e+00 0.0000000e+00 2.2794476e-29 1.0734003e-37], sum to 1.0000
[2019-03-23 10:36:23,014] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2968
[2019-03-23 10:36:23,020] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 88.0, 1.0, 2.0, 0.2964661453860706, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 321917.1719117408, 321917.1719117411, 109586.3249033249], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3823200.0000, 
sim time next is 3823800.0000, 
raw observation next is [17.0, 88.00000000000001, 1.0, 2.0, 0.2968619346205142, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 322347.0812970271, 322347.0812970274, 109620.5228415872], 
processed observation next is [0.0, 0.2608695652173913, 0.4090909090909091, 0.8800000000000001, 1.0, 1.0, 0.12107741827564272, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11938780788778783, 0.11938780788778793, 0.26736712888192], 
reward next is 0.7326, 
noisyNet noise sample is [array([0.7843559], dtype=float32), -0.3683961]. 
=============================================
[2019-03-23 10:36:24,393] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.63884540e-22 1.00000000e+00 1.13486296e-35 1.37910257e-17
 5.49689536e-34], sum to 1.0000
[2019-03-23 10:36:24,401] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0138
[2019-03-23 10:36:24,408] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.83333333333333, 64.0, 1.0, 2.0, 0.3139866789242876, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 343459.8399460183, 343459.8399460183, 113024.2623585912], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3877800.0000, 
sim time next is 3878400.0000, 
raw observation next is [20.66666666666667, 64.0, 1.0, 2.0, 0.3098770186712216, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 337995.1174186108, 337995.1174186111, 112387.8916355331], 
processed observation next is [0.0, 0.9130434782608695, 0.575757575757576, 0.64, 1.0, 1.0, 0.13734627333902696, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1251833768217077, 0.1251833768217078, 0.2741168088671539], 
reward next is 0.7259, 
noisyNet noise sample is [array([-0.06984183], dtype=float32), -0.21015917]. 
=============================================
[2019-03-23 10:36:28,608] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.2399742e-27 1.0000000e+00 1.3901694e-38 1.6739371e-23 4.4777405e-38], sum to 1.0000
[2019-03-23 10:36:28,615] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8441
[2019-03-23 10:36:28,618] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 46.5, 1.0, 2.0, 0.3358118129650236, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 372528.6693386054, 372528.6693386054, 116555.6830710683], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3948600.0000, 
sim time next is 3949200.0000, 
raw observation next is [25.0, 47.0, 1.0, 2.0, 0.3385623067642199, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 376081.6376528487, 376081.6376528484, 116973.8807621974], 
processed observation next is [0.0, 0.7391304347826086, 0.7727272727272727, 0.47, 1.0, 1.0, 0.17320288345527485, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.139289495426981, 0.13928949542698088, 0.28530214820048144], 
reward next is 0.7147, 
noisyNet noise sample is [array([0.92877823], dtype=float32), -0.025826229]. 
=============================================
[2019-03-23 10:36:34,073] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.8805553e-26 1.0000000e+00 7.6153823e-38 1.8727232e-19 6.3230146e-38], sum to 1.0000
[2019-03-23 10:36:34,080] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2089
[2019-03-23 10:36:34,086] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.5, 97.0, 1.0, 2.0, 0.3155168295225377, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 343861.4778125387, 343861.477812539, 112678.5458660088], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4069800.0000, 
sim time next is 4070400.0000, 
raw observation next is [16.66666666666666, 96.0, 1.0, 2.0, 0.3143639930390195, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 343000.2126674645, 343000.2126674642, 112738.2098143315], 
processed observation next is [1.0, 0.08695652173913043, 0.39393939393939365, 0.96, 1.0, 1.0, 0.14295499129877437, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12703711580276464, 0.12703711580276453, 0.274971243449589], 
reward next is 0.7250, 
noisyNet noise sample is [array([-0.52330536], dtype=float32), -1.0902847]. 
=============================================
[2019-03-23 10:36:34,232] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.7344431e-23 1.0000000e+00 4.4186084e-37 6.2887824e-16 5.2725548e-35], sum to 1.0000
[2019-03-23 10:36:34,245] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8897
[2019-03-23 10:36:34,248] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 94.0, 1.0, 2.0, 0.3183658651175765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 348304.471991756, 348304.471991756, 113352.2780809082], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4056600.0000, 
sim time next is 4057200.0000, 
raw observation next is [17.0, 94.0, 1.0, 2.0, 0.3175327869473207, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 347386.1100369328, 347386.1100369328, 113290.9632149848], 
processed observation next is [1.0, 1.0, 0.4090909090909091, 0.94, 1.0, 1.0, 0.14691598368415082, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12866152223590105, 0.12866152223590105, 0.2763194224755727], 
reward next is 0.7237, 
noisyNet noise sample is [array([0.84011334], dtype=float32), 0.7492416]. 
=============================================
[2019-03-23 10:36:36,455] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.1025193e-24 1.0000000e+00 2.2802930e-35 8.4404599e-24 2.5833586e-35], sum to 1.0000
[2019-03-23 10:36:36,465] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7663
[2019-03-23 10:36:36,473] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 76.33333333333334, 1.0, 2.0, 0.7336344498022779, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 834475.8941730567, 834475.8941730567, 167089.2635124249], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4101600.0000, 
sim time next is 4102200.0000, 
raw observation next is [22.5, 75.5, 1.0, 2.0, 0.7432474510923743, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 845619.7811346705, 845619.7811346703, 168635.9210552208], 
processed observation next is [1.0, 0.4782608695652174, 0.6590909090909091, 0.755, 1.0, 1.0, 0.6790593138654679, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.31319251153135946, 0.31319251153135935, 0.4113071245249288], 
reward next is 0.5887, 
noisyNet noise sample is [array([-0.32705772], dtype=float32), -1.3603601]. 
=============================================
[2019-03-23 10:36:48,728] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.1457813e-23 1.0000000e+00 2.1893516e-34 7.0264125e-23 1.2706190e-33], sum to 1.0000
[2019-03-23 10:36:48,734] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7084
[2019-03-23 10:36:48,739] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 94.00000000000001, 1.0, 2.0, 0.3597933938136763, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 400403.4921823537, 400403.492182354, 118944.7422619444], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4338600.0000, 
sim time next is 4339200.0000, 
raw observation next is [18.0, 94.0, 1.0, 2.0, 0.3539867545189999, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 393940.0828595029, 393940.0828595029, 118479.8782156048], 
processed observation next is [1.0, 0.21739130434782608, 0.45454545454545453, 0.94, 1.0, 1.0, 0.19248344314874988, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14590373439240847, 0.14590373439240847, 0.2889753127209873], 
reward next is 0.7110, 
noisyNet noise sample is [array([0.6874304], dtype=float32), 0.2285891]. 
=============================================
[2019-03-23 10:36:52,520] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.4243728e-24 1.0000000e+00 8.5432252e-36 7.5801045e-17 4.7595006e-37], sum to 1.0000
[2019-03-23 10:36:52,529] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3275
[2019-03-23 10:36:52,536] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 83.0, 1.0, 2.0, 0.4664878202288025, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 532132.0540916529, 532132.0540916529, 136320.9984997625], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4480200.0000, 
sim time next is 4480800.0000, 
raw observation next is [22.33333333333334, 84.66666666666667, 1.0, 2.0, 0.4677267504842296, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 533591.2726643878, 533591.2726643878, 136582.997544167], 
processed observation next is [0.0, 0.8695652173913043, 0.6515151515151518, 0.8466666666666667, 1.0, 1.0, 0.334658438105287, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1976263972831066, 0.1976263972831066, 0.33312926230284634], 
reward next is 0.6669, 
noisyNet noise sample is [array([0.21354021], dtype=float32), 0.5861801]. 
=============================================
[2019-03-23 10:37:09,292] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.7854426e-22 1.0000000e+00 4.1433134e-33 9.4710676e-22 7.7299621e-32], sum to 1.0000
[2019-03-23 10:37:09,296] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7077
[2019-03-23 10:37:09,302] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 78.0, 1.0, 2.0, 0.3890477806826772, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 438424.6928726733, 438424.6928726733, 123879.0094364239], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4741800.0000, 
sim time next is 4742400.0000, 
raw observation next is [21.0, 78.0, 1.0, 2.0, 0.3869149613184792, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 435995.870744765, 435995.8707447647, 123676.6855286876], 
processed observation next is [1.0, 0.9130434782608695, 0.5909090909090909, 0.78, 1.0, 1.0, 0.23364370164809897, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16147995212769073, 0.16147995212769062, 0.30165045250899414], 
reward next is 0.6983, 
noisyNet noise sample is [array([-0.29227942], dtype=float32), -0.3696482]. 
=============================================
[2019-03-23 10:37:11,911] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.3017200e-18 1.0000000e+00 6.6082701e-28 9.4722082e-14 2.2447684e-28], sum to 1.0000
[2019-03-23 10:37:11,917] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3368
[2019-03-23 10:37:11,924] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.4954007559871142, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 561752.2466626638, 561752.2466626638, 136056.625884002], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4781400.0000, 
sim time next is 4782000.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.6563391966367967, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 744660.4840142245, 744660.4840142247, 155151.8566806336], 
processed observation next is [1.0, 0.34782608695652173, 0.5, 1.0, 1.0, 1.0, 0.5704239957959959, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2758001792645276, 0.27580017926452766, 0.3784191626356917], 
reward next is 0.6216, 
noisyNet noise sample is [array([0.35238957], dtype=float32), -0.12573916]. 
=============================================
[2019-03-23 10:37:11,933] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-23 10:37:11,935] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 10:37:11,936] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 10:37:11,936] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 10:37:11,938] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[62.121838]
 [62.431   ]
 [62.443733]
 [62.353367]
 [62.30817 ]], R is [[61.33766556]
 [61.39244461]
 [61.4618988 ]
 [61.53361511]
 [61.602005  ]].
[2019-03-23 10:37:11,940] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:37:11,941] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:37:11,938] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 10:37:11,940] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:37:11,942] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 10:37:11,949] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:37:11,949] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:37:11,968] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run57
[2019-03-23 10:37:11,992] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run57
[2019-03-23 10:37:12,020] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run57
[2019-03-23 10:37:12,043] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run57
[2019-03-23 10:37:12,043] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run57
[2019-03-23 10:37:17,022] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.03851357], dtype=float32), -1.1559774]
[2019-03-23 10:37:17,022] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [17.3, 86.0, 1.0, 2.0, 0.2949181113789229, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 320215.5810381335, 320215.5810381335, 115158.6386925397]
[2019-03-23 10:37:17,023] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 10:37:17,026] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.0604529e-25 1.0000000e+00 3.2780741e-37 2.7986387e-22 5.9768151e-37], sampled 0.17922372522379992
[2019-03-23 10:37:25,816] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.03851357], dtype=float32), -1.1559774]
[2019-03-23 10:37:25,817] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [25.73333333333333, 69.33333333333334, 1.0, 2.0, 0.8746997208364483, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 996940.1287025127, 996940.1287025124, 201805.4675067314]
[2019-03-23 10:37:25,818] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 10:37:25,820] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.5852154e-22 1.0000000e+00 5.9266515e-33 1.0943475e-19 9.9887809e-33], sampled 0.6366549319091318
[2019-03-23 10:37:32,503] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.03851357], dtype=float32), -1.1559774]
[2019-03-23 10:37:32,504] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.25, 50.5, 1.0, 2.0, 0.4291955585164806, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 477105.4795410495, 477105.4795410492, 128930.2644434727]
[2019-03-23 10:37:32,505] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 10:37:32,507] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.2790349e-25 1.0000000e+00 3.8068997e-37 3.0576582e-22 6.9323804e-37], sampled 0.2057627876894691
[2019-03-23 10:37:41,080] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.03851357], dtype=float32), -1.1559774]
[2019-03-23 10:37:41,082] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [28.0, 57.5, 1.0, 2.0, 0.74913820098257, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769687877, 853498.5140407382, 853498.5140407382, 181303.3801729981]
[2019-03-23 10:37:41,083] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 10:37:41,087] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.3603458e-23 1.0000000e+00 1.6274846e-34 1.1333920e-20 2.8088249e-34], sampled 0.40548334363374217
[2019-03-23 10:37:49,636] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.03851357], dtype=float32), -1.1559774]
[2019-03-23 10:37:49,637] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.45, 43.0, 1.0, 2.0, 0.3172025753751002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 345630.6663546888, 345630.6663546888, 117086.3281395754]
[2019-03-23 10:37:49,637] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 10:37:49,640] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.0426409e-25 1.0000000e+00 3.2361284e-37 2.7774422e-22 5.9010571e-37], sampled 0.5679818636401951
[2019-03-23 10:37:50,142] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.03851357], dtype=float32), -1.1559774]
[2019-03-23 10:37:50,144] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [16.35, 79.5, 1.0, 2.0, 0.2463508080359262, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 267470.5403549004, 267470.5403549001, 88533.81268955767]
[2019-03-23 10:37:50,145] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 10:37:50,147] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.0426409e-25 1.0000000e+00 3.2361284e-37 2.7774422e-22 5.9010571e-37], sampled 0.6009956766608483
[2019-03-23 10:38:23,465] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.03851357], dtype=float32), -1.1559774]
[2019-03-23 10:38:23,466] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.17474986333333, 80.25234339000001, 1.0, 2.0, 0.3597138543996477, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 403171.5914481459, 403171.5914481455, 124535.2129644083]
[2019-03-23 10:38:23,468] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 10:38:23,472] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.1719345e-25 1.0000000e+00 3.5445515e-37 2.9311138e-22 6.4585348e-37], sampled 0.12433765939566221
[2019-03-23 10:38:27,012] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.03851357], dtype=float32), -1.1559774]
[2019-03-23 10:38:27,013] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.16666666666667, 90.0, 1.0, 2.0, 0.3853596935129917, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 432907.5405032803, 432907.5405032803, 127177.2033871002]
[2019-03-23 10:38:27,015] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 10:38:27,019] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.1691738e-25 1.0000000e+00 9.3236992e-37 5.1989902e-22 1.6852153e-36], sampled 0.03042516451701771
[2019-03-23 10:38:28,457] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.03851357], dtype=float32), -1.1559774]
[2019-03-23 10:38:28,462] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.8, 93.0, 1.0, 2.0, 0.3757035464135646, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 421877.2097865174, 421877.2097865177, 121929.8568275402]
[2019-03-23 10:38:28,463] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:38:28,466] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.0426409e-25 1.0000000e+00 3.2361284e-37 2.7774422e-22 5.9010571e-37], sampled 0.7515838479994786
[2019-03-23 10:38:50,491] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 10:38:50,706] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.03851357], dtype=float32), -1.1559774]
[2019-03-23 10:38:50,706] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.4, 95.5, 1.0, 2.0, 0.65410713327396, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 741677.6823042256, 741677.682304226, 154563.5503097208]
[2019-03-23 10:38:50,706] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:38:50,709] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [8.5899427e-24 1.0000000e+00 8.2392000e-35 7.5473405e-21 1.4307926e-34], sampled 0.04390450414447722
[2019-03-23 10:38:50,725] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 10:38:51,055] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 10:38:51,079] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 10:38:51,165] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 10:38:52,182] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 1400000, evaluation results [1400000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 10:39:07,838] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.6467499e-28 1.0000000e+00 0.0000000e+00 6.1461017e-24 0.0000000e+00], sum to 1.0000
[2019-03-23 10:39:07,849] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8693
[2019-03-23 10:39:07,854] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333333, 71.66666666666667, 1.0, 2.0, 0.4291316628426298, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 488394.9788751634, 488394.9788751637, 130783.9494620991], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5089200.0000, 
sim time next is 5089800.0000, 
raw observation next is [23.16666666666667, 72.33333333333333, 1.0, 2.0, 0.4271253106486599, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 485974.5363510355, 485974.5363510355, 130449.1107196122], 
processed observation next is [0.0, 0.9130434782608695, 0.6893939393939396, 0.7233333333333333, 1.0, 1.0, 0.2839066383108248, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17999056901890204, 0.17999056901890204, 0.3181685627307615], 
reward next is 0.6818, 
noisyNet noise sample is [array([1.0695624], dtype=float32), -1.2805268]. 
=============================================
[2019-03-23 10:39:10,494] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.2326949e-27 1.0000000e+00 3.5341821e-37 4.1322203e-24 4.0095225e-37], sum to 1.0000
[2019-03-23 10:39:10,500] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3548
[2019-03-23 10:39:10,508] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.06666666666667, 89.0, 1.0, 2.0, 0.4533455573485173, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 516148.9238211405, 516148.9238211405, 133438.3685835928], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5384400.0000, 
sim time next is 5385000.0000, 
raw observation next is [21.33333333333334, 88.0, 1.0, 2.0, 0.4620689974252872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 526379.0418061235, 526379.0418061237, 134681.3452999256], 
processed observation next is [1.0, 0.30434782608695654, 0.6060606060606063, 0.88, 1.0, 1.0, 0.3275862467816089, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19495520066893463, 0.1949552006689347, 0.3284910860973795], 
reward next is 0.6715, 
noisyNet noise sample is [array([0.898292], dtype=float32), -0.049856707]. 
=============================================
[2019-03-23 10:39:10,529] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[64.066574]
 [64.15882 ]
 [64.21527 ]
 [64.20273 ]
 [64.28842 ]], R is [[63.99927521]
 [64.03382111]
 [64.07125854]
 [64.11022186]
 [64.1469574 ]].
[2019-03-23 10:39:11,908] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.7713823e-25 1.0000000e+00 2.4448008e-36 3.4941406e-22 3.0157030e-36], sum to 1.0000
[2019-03-23 10:39:11,917] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8301
[2019-03-23 10:39:11,922] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.66666666666667, 75.33333333333333, 1.0, 2.0, 0.4527042183877473, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 516448.8755057686, 516448.8755057689, 134977.7902678884], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5132400.0000, 
sim time next is 5133000.0000, 
raw observation next is [23.83333333333333, 74.66666666666667, 1.0, 2.0, 0.4548495096989603, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 518936.3414274746, 518936.3414274749, 135341.0234782863], 
processed observation next is [0.0, 0.391304347826087, 0.7196969696969695, 0.7466666666666667, 1.0, 1.0, 0.31856188712370037, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19219864497313874, 0.19219864497313885, 0.33010005726411296], 
reward next is 0.6699, 
noisyNet noise sample is [array([0.94575], dtype=float32), 0.710698]. 
=============================================
[2019-03-23 10:39:11,939] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[66.64489]
 [66.64493]
 [66.64496]
 [66.645  ]
 [66.64506]], R is [[66.64830017]
 [66.65260315]
 [66.65766144]
 [66.66352081]
 [66.67022705]].
[2019-03-23 10:39:13,716] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.3796981e-27 1.0000000e+00 5.1467355e-38 1.0795444e-28 1.8290308e-38], sum to 1.0000
[2019-03-23 10:39:13,724] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5901
[2019-03-23 10:39:13,730] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 83.0, 1.0, 2.0, 0.4378336890909922, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 498831.1369946161, 498831.1369946161, 132252.5528133897], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5190600.0000, 
sim time next is 5191200.0000, 
raw observation next is [22.0, 83.0, 1.0, 2.0, 0.4374253869066658, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 498365.5747741654, 498365.5747741654, 132210.5413427456], 
processed observation next is [1.0, 0.08695652173913043, 0.6363636363636364, 0.83, 1.0, 1.0, 0.29678173363333227, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18457984250895015, 0.18457984250895015, 0.3224647349823063], 
reward next is 0.6775, 
noisyNet noise sample is [array([1.1800297], dtype=float32), 1.6901916]. 
=============================================
[2019-03-23 10:39:14,278] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.2366103e-23 1.0000000e+00 3.3405538e-34 2.0028769e-21 1.1999913e-33], sum to 1.0000
[2019-03-23 10:39:14,291] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2704
[2019-03-23 10:39:14,296] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 90.33333333333334, 1.0, 2.0, 0.8169610223539685, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 932576.3018310582, 932576.3018310582, 184349.4468426277], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5215200.0000, 
sim time next is 5215800.0000, 
raw observation next is [21.33333333333333, 92.16666666666667, 1.0, 2.0, 0.8039380048509633, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 917641.7056196096, 917641.7056196098, 181899.1532051027], 
processed observation next is [1.0, 0.34782608695652173, 0.6060606060606059, 0.9216666666666667, 1.0, 1.0, 0.754922506063704, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3398672983776332, 0.33986729837763324, 0.4436564712319578], 
reward next is 0.5563, 
noisyNet noise sample is [array([-1.0524062], dtype=float32), -0.6534117]. 
=============================================
[2019-03-23 10:39:15,031] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.6095640e-23 1.0000000e+00 6.9745395e-34 2.0234417e-22 3.3161256e-34], sum to 1.0000
[2019-03-23 10:39:15,039] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1116
[2019-03-23 10:39:15,043] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 98.0, 1.0, 2.0, 0.8126797464545317, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 927692.6933182242, 927692.6933182242, 184310.1183163085], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5223000.0000, 
sim time next is 5223600.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.8308143683906011, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 948240.7515010262, 948240.7515010262, 188126.5201181379], 
processed observation next is [1.0, 0.4782608695652174, 0.5909090909090909, 1.0, 1.0, 1.0, 0.7885179604882514, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3512002783337134, 0.3512002783337134, 0.45884517101984856], 
reward next is 0.5412, 
noisyNet noise sample is [array([0.28531814], dtype=float32), 0.30875042]. 
=============================================
[2019-03-23 10:39:30,930] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.3012008e-18 1.0000000e+00 3.3960742e-26 5.9594168e-16 5.8207599e-26], sum to 1.0000
[2019-03-23 10:39:30,938] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0116
[2019-03-23 10:39:30,946] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 80.66666666666667, 1.0, 2.0, 0.4499095341999948, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 512655.922866853, 512655.9228668532, 133576.8636628251], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5527200.0000, 
sim time next is 5527800.0000, 
raw observation next is [22.15, 81.5, 1.0, 2.0, 0.4463129999856838, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 508438.2413994059, 508438.2413994059, 133053.3941472343], 
processed observation next is [1.0, 1.0, 0.6431818181818181, 0.815, 1.0, 1.0, 0.3078912499821047, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18831045977755773, 0.18831045977755773, 0.32452047352983976], 
reward next is 0.6755, 
noisyNet noise sample is [array([-0.39567235], dtype=float32), -0.6437298]. 
=============================================
[2019-03-23 10:39:33,761] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.1471499e-13 1.0000000e+00 5.1336057e-20 1.7896497e-11 1.7344520e-19], sum to 1.0000
[2019-03-23 10:39:33,770] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3098
[2019-03-23 10:39:33,770] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1325537.500000704 W.
[2019-03-23 10:39:33,778] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.06666666666667, 59.0, 1.0, 2.0, 0.5869320054009528, 1.0, 2.0, 0.5869320054009528, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1325537.500000704, 1325537.500000704, 257039.5077167787], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5577600.0000, 
sim time next is 5578200.0000, 
raw observation next is [28.25, 58.0, 1.0, 2.0, 0.6391518515840928, 1.0, 2.0, 0.6391518515840928, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1441983.970033298, 1441983.970033298, 272265.4685577612], 
processed observation next is [1.0, 0.5652173913043478, 0.9204545454545454, 0.58, 1.0, 1.0, 0.548939814480116, 1.0, 1.0, 0.548939814480116, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.5340681370493696, 0.5340681370493696, 0.664062118433564], 
reward next is 0.3359, 
noisyNet noise sample is [array([-2.1940787], dtype=float32), -0.74894303]. 
=============================================
[2019-03-23 10:39:41,261] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-23 10:39:41,264] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 10:39:41,264] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:39:41,268] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 10:39:41,269] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 10:39:41,270] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:39:41,271] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 10:39:41,272] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 10:39:41,274] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:39:41,274] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:39:41,274] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:39:41,295] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run58
[2019-03-23 10:39:41,319] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run58
[2019-03-23 10:39:41,353] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run58
[2019-03-23 10:39:41,354] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run58
[2019-03-23 10:39:41,398] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run58
[2019-03-23 10:40:18,478] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.03353507], dtype=float32), -1.0900612]
[2019-03-23 10:40:18,480] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.4600067, 80.15675255, 1.0, 2.0, 0.2633847349079754, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 285969.190839058, 285969.190839058, 91649.08336765823]
[2019-03-23 10:40:18,480] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 10:40:18,482] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [6.8677943e-20 1.0000000e+00 8.7553660e-29 5.3237129e-18 1.6591205e-28], sampled 0.5542169946164902
[2019-03-23 10:40:21,390] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.03353507], dtype=float32), -1.0900612]
[2019-03-23 10:40:21,391] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.53333333333333, 89.0, 1.0, 2.0, 0.4132550679870729, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 469181.0682651952, 469181.0682651949, 132561.491152357]
[2019-03-23 10:40:21,391] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 10:40:21,395] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [6.8677943e-20 1.0000000e+00 8.7553660e-29 5.3237129e-18 1.6591205e-28], sampled 0.5186963495226589
[2019-03-23 10:40:22,854] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.03353507], dtype=float32), -1.0900612]
[2019-03-23 10:40:22,855] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [17.9228103, 100.0, 1.0, 2.0, 0.3816785062084272, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 427820.35004638, 427820.35004638, 126399.2822998905]
[2019-03-23 10:40:22,856] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 10:40:22,859] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [6.8677943e-20 1.0000000e+00 8.7553660e-29 5.3237129e-18 1.6591205e-28], sampled 0.3026613988610768
[2019-03-23 10:40:33,489] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.03353507], dtype=float32), -1.0900612]
[2019-03-23 10:40:33,490] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.0, 83.0, 1.0, 2.0, 0.4066224760334996, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 460728.8088693629, 460728.8088693629, 126931.3438945497]
[2019-03-23 10:40:33,492] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:40:33,494] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [6.8677943e-20 1.0000000e+00 8.7553660e-29 5.3237129e-18 1.6591205e-28], sampled 0.083014053120264
[2019-03-23 10:40:36,327] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.03353507], dtype=float32), -1.0900612]
[2019-03-23 10:40:36,328] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [14.1530261, 72.80076869, 1.0, 2.0, 0.2144758871802288, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 232856.268919929, 232856.268919929, 76049.10568861487]
[2019-03-23 10:40:36,329] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 10:40:36,332] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [6.8677943e-20 1.0000000e+00 8.7553660e-29 5.3237129e-18 1.6591205e-28], sampled 0.2524442486623153
[2019-03-23 10:40:59,001] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.03353507], dtype=float32), -1.0900612]
[2019-03-23 10:40:59,002] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.98333333333333, 47.5, 1.0, 2.0, 0.3227034090463111, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 354353.5303096458, 354353.5303096455, 118451.7217798715]
[2019-03-23 10:40:59,005] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 10:40:59,009] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [6.8677943e-20 1.0000000e+00 8.7553660e-29 5.3237129e-18 1.6591205e-28], sampled 0.06198044678420933
[2019-03-23 10:41:00,406] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.03353507], dtype=float32), -1.0900612]
[2019-03-23 10:41:00,408] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.35, 62.5, 1.0, 2.0, 0.2687081839067808, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 291750.5125648807, 291750.5125648807, 96623.85938533382]
[2019-03-23 10:41:00,412] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 10:41:00,414] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [6.8677943e-20 1.0000000e+00 8.7553660e-29 5.3237129e-18 1.6591205e-28], sampled 0.9151585910930913
[2019-03-23 10:41:19,926] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 10:41:20,334] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 10:41:20,346] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 10:41:20,391] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 10:41:20,642] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 10:41:21,658] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 1425000, evaluation results [1425000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 10:41:22,168] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.2621416e-17 1.0000000e+00 2.1601589e-26 7.2847944e-17 8.4529534e-26], sum to 1.0000
[2019-03-23 10:41:22,179] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5673
[2019-03-23 10:41:22,186] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [11.1, 77.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 165897.7790384853, 165897.7790384855, 59932.16171255521], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5707200.0000, 
sim time next is 5707800.0000, 
raw observation next is [11.1, 77.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 164650.5366718468, 164650.5366718465, 59768.00572278892], 
processed observation next is [0.0, 0.043478260869565216, 0.1409090909090909, 0.77, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.06098168024883215, 0.060981680248832035, 0.1457756237141193], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5682065], dtype=float32), -1.6627115]. 
=============================================
[2019-03-23 10:41:22,618] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.3332991e-21 1.0000000e+00 2.4579854e-29 2.1782969e-19 2.5838592e-29], sum to 1.0000
[2019-03-23 10:41:22,624] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3596
[2019-03-23 10:41:22,631] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.6, 42.0, 1.0, 2.0, 0.2687339710295995, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 291795.2117940459, 291795.2117940456, 84125.8251242548], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5757000.0000, 
sim time next is 5757600.0000, 
raw observation next is [21.6, 42.0, 1.0, 2.0, 0.2705165360339607, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 293731.3310226157, 293731.331022616, 84324.61270304632], 
processed observation next is [0.0, 0.6521739130434783, 0.6181818181818183, 0.42, 1.0, 1.0, 0.08814567004245086, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10878938186022805, 0.10878938186022816, 0.2056697870806008], 
reward next is 0.7943, 
noisyNet noise sample is [array([-0.65279657], dtype=float32), 1.5199475]. 
=============================================
[2019-03-23 10:41:25,477] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.9742654e-27 1.0000000e+00 0.0000000e+00 9.6296004e-25 1.8867244e-37], sum to 1.0000
[2019-03-23 10:41:25,486] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3519
[2019-03-23 10:41:25,495] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.45, 81.5, 1.0, 2.0, 0.3833827008602873, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 416335.7435632223, 416335.7435632223, 86765.35600211655], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5801400.0000, 
sim time next is 5802000.0000, 
raw observation next is [12.36666666666667, 82.0, 1.0, 2.0, 0.3838700670894554, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 416865.227458022, 416865.227458022, 86758.90298655523], 
processed observation next is [1.0, 0.13043478260869565, 0.19848484848484868, 0.82, 1.0, 1.0, 0.22983758386181927, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1543945286881563, 0.1543945286881563, 0.21160708045501275], 
reward next is 0.7884, 
noisyNet noise sample is [array([-1.7860049], dtype=float32), -0.53150004]. 
=============================================
[2019-03-23 10:41:25,509] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[72.63032]
 [72.7613 ]
 [73.29608]
 [73.57061]
 [73.65428]], R is [[72.57135773]
 [72.63401794]
 [72.69599915]
 [72.75909424]
 [72.82590485]].
[2019-03-23 10:41:35,940] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.1042766e-25 1.0000000e+00 8.1276314e-35 2.8964445e-23 7.5585808e-35], sum to 1.0000
[2019-03-23 10:41:35,951] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2483
[2019-03-23 10:41:35,959] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.23333333333333, 62.66666666666667, 1.0, 2.0, 0.8018914808409484, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 911003.1716171622, 911003.1716171622, 176122.0959533345], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5998800.0000, 
sim time next is 5999400.0000, 
raw observation next is [24.7, 61.0, 1.0, 2.0, 0.840471720331793, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 955803.2024265308, 955803.2024265308, 182764.583365479], 
processed observation next is [1.0, 0.43478260869565216, 0.759090909090909, 0.61, 1.0, 1.0, 0.8005896504147411, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3540011860839003, 0.3540011860839003, 0.44576727650116826], 
reward next is 0.5542, 
noisyNet noise sample is [array([-0.10324468], dtype=float32), -0.2834779]. 
=============================================
[2019-03-23 10:41:39,368] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.6756067e-28 1.0000000e+00 0.0000000e+00 6.4093056e-28 0.0000000e+00], sum to 1.0000
[2019-03-23 10:41:39,375] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0473
[2019-03-23 10:41:39,379] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.9, 86.33333333333333, 1.0, 2.0, 0.2155655147028347, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 234050.2462237542, 234050.246223754, 73839.09587765177], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6063000.0000, 
sim time next is 6063600.0000, 
raw observation next is [14.0, 85.66666666666667, 1.0, 2.0, 0.2073911505214904, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 225172.8763748083, 225172.876374808, 73295.2042805776], 
processed observation next is [1.0, 0.17391304347826086, 0.2727272727272727, 0.8566666666666667, 1.0, 1.0, 0.00923893815186299, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08339736162029937, 0.08339736162029926, 0.17876879092823805], 
reward next is 0.8212, 
noisyNet noise sample is [array([1.646679], dtype=float32), 1.2505232]. 
=============================================
[2019-03-23 10:41:41,090] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.8095242e-25 1.0000000e+00 1.8801862e-37 1.4786169e-27 2.4708925e-37], sum to 1.0000
[2019-03-23 10:41:41,101] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4487
[2019-03-23 10:41:41,104] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.73333333333333, 51.33333333333333, 1.0, 2.0, 0.3095271124975563, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 337102.9659859745, 337102.9659859742, 112183.1730727302], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6111600.0000, 
sim time next is 6112200.0000, 
raw observation next is [22.46666666666667, 52.16666666666667, 1.0, 2.0, 0.3084229083791355, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 335243.8078234377, 335243.807823438, 111877.9542534649], 
processed observation next is [1.0, 0.7391304347826086, 0.6575757575757577, 0.5216666666666667, 1.0, 1.0, 0.13552863547391936, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12416437326793987, 0.12416437326794001, 0.27287305915479243], 
reward next is 0.7271, 
noisyNet noise sample is [array([-1.295509], dtype=float32), -0.9018119]. 
=============================================
[2019-03-23 10:41:44,794] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.1641074e-23 1.0000000e+00 3.6928471e-35 1.9629514e-24 1.6802870e-34], sum to 1.0000
[2019-03-23 10:41:44,802] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5516
[2019-03-23 10:41:44,809] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.1, 66.0, 1.0, 2.0, 0.587630879465166, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 650224.9175589904, 650224.9175589908, 139081.1695278409], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6170400.0000, 
sim time next is 6171000.0000, 
raw observation next is [20.91666666666667, 68.5, 1.0, 2.0, 0.6169183629623812, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 684230.9146542558, 684230.9146542562, 142826.8690935177], 
processed observation next is [1.0, 0.43478260869565216, 0.5871212121212124, 0.685, 1.0, 1.0, 0.5211479537029765, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.25341885727935404, 0.25341885727935415, 0.34835821730126265], 
reward next is 0.6516, 
noisyNet noise sample is [array([-0.0859549], dtype=float32), 1.6752907]. 
=============================================
[2019-03-23 10:41:44,827] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[64.00715 ]
 [64.03706 ]
 [63.973007]
 [63.860252]
 [63.84341 ]], R is [[63.81874847]
 [63.84133911]
 [63.86653519]
 [63.890728  ]
 [63.91067886]].
[2019-03-23 10:41:49,814] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.8109924e-25 1.0000000e+00 6.2397525e-37 7.7260252e-21 4.9043520e-36], sum to 1.0000
[2019-03-23 10:41:49,823] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9990
[2019-03-23 10:41:49,830] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 57.0, 1.0, 2.0, 0.4353145576061355, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 472758.7386672294, 472758.7386672294, 101307.8654451065], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6516000.0000, 
sim time next is 6516600.0000, 
raw observation next is [18.71666666666667, 57.5, 1.0, 2.0, 0.4510384059444616, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 489843.6985975142, 489843.6985975142, 102847.9012556882], 
processed observation next is [1.0, 0.43478260869565216, 0.48712121212121223, 0.575, 1.0, 1.0, 0.31379800743057695, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1814235920731534, 0.1814235920731534, 0.25084853964802], 
reward next is 0.7492, 
noisyNet noise sample is [array([-0.6576262], dtype=float32), -1.1386808]. 
=============================================
[2019-03-23 10:41:50,350] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.0625625e-21 1.0000000e+00 7.9373121e-31 2.4946017e-19 2.5913698e-30], sum to 1.0000
[2019-03-23 10:41:50,356] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4782
[2019-03-23 10:41:50,361] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.28333333333334, 70.33333333333334, 1.0, 2.0, 0.5312980386938576, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 603963.1632341399, 603963.1632341399, 147503.8558848934], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6347400.0000, 
sim time next is 6348000.0000, 
raw observation next is [26.46666666666667, 69.66666666666667, 1.0, 2.0, 0.5336445125899718, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 606404.1086078153, 606404.1086078157, 147918.2361886009], 
processed observation next is [0.0, 0.4782608695652174, 0.8393939393939395, 0.6966666666666668, 1.0, 1.0, 0.4170556407374647, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22459411429919088, 0.224594114299191, 0.3607761858258558], 
reward next is 0.6392, 
noisyNet noise sample is [array([0.05784985], dtype=float32), 1.0518379]. 
=============================================
[2019-03-23 10:41:50,383] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[61.72457]
 [61.72457]
 [61.72457]
 [61.72457]
 [61.72457]], R is [[61.74655151]
 [61.76932144]
 [61.79270172]
 [61.81646347]
 [61.84082413]].
[2019-03-23 10:41:56,357] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.2428931e-22 1.0000000e+00 1.6597049e-33 2.2204563e-18 1.8871951e-34], sum to 1.0000
[2019-03-23 10:41:56,366] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9353
[2019-03-23 10:41:56,371] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.08333333333334, 80.66666666666666, 1.0, 2.0, 0.5606326395388319, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 635552.8002981106, 635552.8002981103, 152030.6116685191], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6382200.0000, 
sim time next is 6382800.0000, 
raw observation next is [25.0, 81.0, 1.0, 2.0, 0.5588774989736637, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 633713.6348312807, 633713.6348312807, 151743.2883847794], 
processed observation next is [0.0, 0.9130434782608695, 0.7727272727272727, 0.81, 1.0, 1.0, 0.44859687371707957, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23470875364121507, 0.23470875364121507, 0.3701055814262912], 
reward next is 0.6299, 
noisyNet noise sample is [array([-0.31223226], dtype=float32), 0.11342946]. 
=============================================
[2019-03-23 10:42:03,100] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.4876849e-18 1.0000000e+00 1.0052452e-27 8.2062780e-13 2.7449213e-26], sum to 1.0000
[2019-03-23 10:42:03,110] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4413
[2019-03-23 10:42:03,113] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 57.0, 1.0, 2.0, 0.4353145576061355, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 472758.7386672294, 472758.7386672294, 101307.8654451065], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6516000.0000, 
sim time next is 6516600.0000, 
raw observation next is [18.71666666666667, 57.5, 1.0, 2.0, 0.4510384059444616, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 489843.6985975142, 489843.6985975142, 102847.9012556882], 
processed observation next is [1.0, 0.43478260869565216, 0.48712121212121223, 0.575, 1.0, 1.0, 0.31379800743057695, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1814235920731534, 0.1814235920731534, 0.25084853964802], 
reward next is 0.7492, 
noisyNet noise sample is [array([-0.9034515], dtype=float32), 0.16598897]. 
=============================================
[2019-03-23 10:42:10,558] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-23 10:42:10,560] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 10:42:10,562] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:42:10,562] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 10:42:10,564] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:42:10,564] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 10:42:10,565] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:42:10,567] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 10:42:10,568] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:42:10,568] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 10:42:10,570] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:42:10,588] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run59
[2019-03-23 10:42:10,612] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run59
[2019-03-23 10:42:10,647] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run59
[2019-03-23 10:42:10,648] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run59
[2019-03-23 10:42:10,698] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run59
[2019-03-23 10:42:23,747] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05247102], dtype=float32), -1.1716403]
[2019-03-23 10:42:23,750] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.35, 79.16666666666667, 1.0, 2.0, 0.5538276582984417, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 630763.4966144637, 630763.4966144637, 149132.073679412]
[2019-03-23 10:42:23,751] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 10:42:23,756] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.5224837e-27 1.0000000e+00 0.0000000e+00 1.5619953e-24 0.0000000e+00], sampled 0.19874094782443685
[2019-03-23 10:43:11,357] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05247102], dtype=float32), -1.1716403]
[2019-03-23 10:43:11,358] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.83809818333333, 90.35440058166665, 1.0, 2.0, 0.3249774702278178, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 358838.9747888031, 358838.9747888028, 119375.0076596661]
[2019-03-23 10:43:11,359] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 10:43:11,361] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.1942936e-26 1.0000000e+00 0.0000000e+00 1.3392666e-22 1.3828071e-38], sampled 0.4473531101392664
[2019-03-23 10:43:15,030] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05247102], dtype=float32), -1.1716403]
[2019-03-23 10:43:15,031] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [25.73333333333333, 59.33333333333334, 1.0, 2.0, 0.4865221984608054, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 554295.3356548403, 554295.3356548403, 141744.3117839425]
[2019-03-23 10:43:15,032] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 10:43:15,035] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.8493847e-26 1.0000000e+00 0.0000000e+00 7.2956497e-22 2.7447370e-38], sampled 0.34537500596910453
[2019-03-23 10:43:17,763] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05247102], dtype=float32), -1.1716403]
[2019-03-23 10:43:17,764] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.15, 67.5, 1.0, 2.0, 0.4283682278322168, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 485292.2131590363, 485292.2131590359, 133285.1623193611]
[2019-03-23 10:43:17,765] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 10:43:17,770] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.2602348e-27 1.0000000e+00 0.0000000e+00 1.3232029e-24 0.0000000e+00], sampled 0.8932761457932367
[2019-03-23 10:43:21,931] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05247102], dtype=float32), -1.1716403]
[2019-03-23 10:43:21,935] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [16.36666666666667, 89.5, 1.0, 2.0, 0.2733891852718496, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 296834.1753381782, 296834.1753381785, 102796.029627642]
[2019-03-23 10:43:21,937] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 10:43:21,941] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.5534452e-26 1.0000000e+00 0.0000000e+00 1.0054668e-21 3.0480142e-38], sampled 0.9511486097023091
[2019-03-23 10:43:40,621] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05247102], dtype=float32), -1.1716403]
[2019-03-23 10:43:40,621] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.65, 51.5, 1.0, 2.0, 0.4292857496411122, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 466165.5875991893, 466165.5875991893, 118384.4339705019]
[2019-03-23 10:43:40,622] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 10:43:40,627] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.0108490e-26 1.0000000e+00 0.0000000e+00 1.1217730e-22 1.2777171e-38], sampled 0.7946102311144138
[2019-03-23 10:43:49,208] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 10:43:49,295] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 10:43:49,316] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 10:43:49,431] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 10:43:49,615] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 10:43:50,633] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 1450000, evaluation results [1450000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 10:43:50,999] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.4825356e-21 1.0000000e+00 2.3111439e-36 1.6717076e-11 2.9180653e-34], sum to 1.0000
[2019-03-23 10:43:51,005] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3180
[2019-03-23 10:43:51,010] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.46666666666667, 91.0, 1.0, 2.0, 0.3621310768454801, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 403782.3674763278, 403782.367476328, 119463.624395628], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6668400.0000, 
sim time next is 6669000.0000, 
raw observation next is [18.55, 90.0, 1.0, 2.0, 0.3613476696145902, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 402721.3609399245, 402721.3609399245, 119319.2357550433], 
processed observation next is [1.0, 0.17391304347826086, 0.47954545454545455, 0.9, 1.0, 1.0, 0.20168458701823772, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14915605960737943, 0.14915605960737943, 0.2910225262318129], 
reward next is 0.7090, 
noisyNet noise sample is [array([-0.24220893], dtype=float32), -1.5922759]. 
=============================================
[2019-03-23 10:43:51,030] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[74.556946]
 [74.55882 ]
 [74.551254]
 [74.55878 ]
 [74.56725 ]], R is [[74.51898193]
 [74.48242188]
 [74.44483185]
 [74.41002655]
 [74.37496185]].
[2019-03-23 10:43:51,577] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.4943253e-23 1.0000000e+00 3.3306287e-34 7.7836856e-20 1.0239354e-33], sum to 1.0000
[2019-03-23 10:43:51,587] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0768
[2019-03-23 10:43:51,593] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.46666666666667, 89.0, 1.0, 2.0, 0.3473721649500891, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 385898.2839556297, 385898.28395563, 117670.5543679462], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6934800.0000, 
sim time next is 6935400.0000, 
raw observation next is [18.55, 88.5, 1.0, 2.0, 0.3479944860256505, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 386728.6945790682, 386728.6945790679, 117776.9977413137], 
processed observation next is [0.0, 0.2608695652173913, 0.47954545454545455, 0.885, 1.0, 1.0, 0.18499310753206308, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14323284984409934, 0.1432328498440992, 0.2872609701007651], 
reward next is 0.7127, 
noisyNet noise sample is [array([2.007784], dtype=float32), 0.4658575]. 
=============================================
[2019-03-23 10:43:56,847] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.3416874e-22 1.0000000e+00 1.3384171e-32 2.2807181e-21 1.6406334e-31], sum to 1.0000
[2019-03-23 10:43:56,853] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1595
[2019-03-23 10:43:56,861] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.46666666666667, 76.0, 1.0, 2.0, 0.7609335312766218, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 865931.7060974576, 865931.7060974579, 171351.9129044971], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6777600.0000, 
sim time next is 6778200.0000, 
raw observation next is [22.53333333333333, 76.0, 1.0, 2.0, 0.7674078480282822, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 873573.7461660457, 873573.7461660457, 172554.8781602207], 
processed observation next is [1.0, 0.43478260869565216, 0.6606060606060605, 0.76, 1.0, 1.0, 0.7092598100353528, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.32354583191335023, 0.32354583191335023, 0.4208655564883431], 
reward next is 0.5791, 
noisyNet noise sample is [array([-0.30980796], dtype=float32), -0.8911049]. 
=============================================
[2019-03-23 10:43:58,176] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.6252091e-27 1.0000000e+00 0.0000000e+00 1.7724184e-24 6.7958295e-38], sum to 1.0000
[2019-03-23 10:43:58,184] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.3763102e-27 1.0000000e+00 0.0000000e+00 1.4058720e-27 2.0814780e-37], sum to 1.0000
[2019-03-23 10:43:58,185] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0360
[2019-03-23 10:43:58,194] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7119
[2019-03-23 10:43:58,196] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1099765.295144872 W.
[2019-03-23 10:43:58,202] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.8, 60.33333333333333, 1.0, 2.0, 0.4174723468473076, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 474183.4788067805, 474183.4788067805, 128793.3224108865], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6804600.0000, 
sim time next is 6805200.0000, 
raw observation next is [24.6, 60.66666666666667, 1.0, 2.0, 0.4186372390841426, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 475151.0085157563, 475151.0085157563, 128632.5985360303], 
processed observation next is [1.0, 0.782608695652174, 0.7545454545454546, 0.6066666666666667, 1.0, 1.0, 0.2732965488551782, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17598185500583566, 0.17598185500583566, 0.31373804520983], 
reward next is 0.6863, 
noisyNet noise sample is [array([0.02435572], dtype=float32), -0.19470878]. 
=============================================
[2019-03-23 10:43:58,205] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.1, 52.0, 1.0, 2.0, 0.4845730557984729, 0.0, 2.0, 0.0, 1.0, 2.0, 0.933501440343366, 6.960315458611097, 6.9112, 77.32831156650519, 1099765.295144872, 1083813.630102787, 242740.3638175473], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6799800.0000, 
sim time next is 6800400.0000, 
raw observation next is [26.1, 52.0, 1.0, 2.0, 0.4710124335401647, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9249810633710654, 6.938319183946657, 6.9112, 77.32836665126055, 1072304.693672228, 1063496.948434286, 239953.2445044983], 
processed observation next is [1.0, 0.7391304347826086, 0.8227272727272728, 0.52, 1.0, 1.0, 0.33876554192520586, 0.0, 1.0, -0.25, 1.0, 1.0, 0.8928300905300937, 0.002711918394665691, 0.0, 0.5084281765187126, 0.3971498865452696, 0.3938877586793652, 0.5852518158646299], 
reward next is 0.2792, 
noisyNet noise sample is [array([1.0000116], dtype=float32), 0.48366117]. 
=============================================
[2019-03-23 10:43:58,494] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.2315753e-23 1.0000000e+00 1.3825838e-33 6.8608258e-21 6.7713117e-34], sum to 1.0000
[2019-03-23 10:43:58,504] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4083
[2019-03-23 10:43:58,511] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.7, 68.5, 1.0, 2.0, 0.4017955728742271, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 454082.5362992217, 454082.5362992217, 125742.2466711423], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6814200.0000, 
sim time next is 6814800.0000, 
raw observation next is [22.7, 68.0, 1.0, 2.0, 0.4018915550563645, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 453901.3000717233, 453901.3000717236, 125582.2733225805], 
processed observation next is [1.0, 0.9130434782608695, 0.6681818181818181, 0.68, 1.0, 1.0, 0.2523644438204556, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16811159261915679, 0.1681115926191569, 0.30629822761605], 
reward next is 0.6937, 
noisyNet noise sample is [array([-1.2158785], dtype=float32), 0.51367676]. 
=============================================
[2019-03-23 10:44:00,353] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.5973442e-29 1.0000000e+00 0.0000000e+00 2.1983414e-25 0.0000000e+00], sum to 1.0000
[2019-03-23 10:44:00,363] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9467
[2019-03-23 10:44:00,367] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.2, 96.0, 1.0, 2.0, 0.3317888398939267, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 365782.1789719983, 365782.178971998, 115341.263275946], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6849600.0000, 
sim time next is 6850200.0000, 
raw observation next is [17.2, 96.0, 1.0, 2.0, 0.3315767435408963, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 365547.2832640692, 365547.2832640692, 115325.1253524004], 
processed observation next is [0.0, 0.2608695652173913, 0.41818181818181815, 0.96, 1.0, 1.0, 0.16447092942612032, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.135387882690396, 0.135387882690396, 0.28128079354244], 
reward next is 0.7187, 
noisyNet noise sample is [array([0.2283589], dtype=float32), -1.6164187]. 
=============================================
[2019-03-23 10:44:01,548] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.2107762e-26 1.0000000e+00 2.0756808e-38 2.1659629e-23 3.0067533e-37], sum to 1.0000
[2019-03-23 10:44:01,555] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9401
[2019-03-23 10:44:01,563] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.88333333333333, 54.83333333333334, 1.0, 2.0, 0.4479027572047985, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 510680.1987366643, 510680.1987366643, 133831.510613099], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6873000.0000, 
sim time next is 6873600.0000, 
raw observation next is [27.16666666666667, 53.66666666666667, 1.0, 2.0, 0.4476942279116606, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 510488.5767158846, 510488.5767158848, 133891.1159965578], 
processed observation next is [0.0, 0.5652173913043478, 0.8712121212121214, 0.5366666666666667, 1.0, 1.0, 0.3096177848895757, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1890698432281054, 0.18906984322810547, 0.32656369755258], 
reward next is 0.6734, 
noisyNet noise sample is [array([1.3437941], dtype=float32), 0.007510063]. 
=============================================
[2019-03-23 10:44:07,610] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.4028398e-25 1.0000000e+00 2.3991687e-37 1.6536196e-25 6.0528790e-36], sum to 1.0000
[2019-03-23 10:44:07,617] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8179
[2019-03-23 10:44:07,620] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.36666666666667, 69.66666666666666, 1.0, 2.0, 0.4991639575958341, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 569355.1018958566, 569355.1018958566, 141828.5260983998], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6982800.0000, 
sim time next is 6983400.0000, 
raw observation next is [25.18333333333334, 70.33333333333334, 1.0, 2.0, 0.4974440215864634, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 567459.0977865437, 567459.097786544, 141488.024964141], 
processed observation next is [0.0, 0.8260869565217391, 0.7810606060606063, 0.7033333333333335, 1.0, 1.0, 0.3718050269830792, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2101700362172384, 0.2101700362172385, 0.345092743814978], 
reward next is 0.6549, 
noisyNet noise sample is [array([-0.24887413], dtype=float32), 1.6230224]. 
=============================================
[2019-03-23 10:44:08,417] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.6210838e-24 1.0000000e+00 1.6161928e-35 3.0689463e-22 2.2895420e-34], sum to 1.0000
[2019-03-23 10:44:08,425] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0244
[2019-03-23 10:44:08,429] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.2, 84.0, 1.0, 2.0, 0.4583006409946204, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 522665.713603448, 522665.7136034477, 135158.6450254579], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6998400.0000, 
sim time next is 6999000.0000, 
raw observation next is [22.2, 84.0, 1.0, 2.0, 0.4570858388304922, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 521259.9939512297, 521259.99395123, 134990.3161223205], 
processed observation next is [1.0, 0.0, 0.6454545454545454, 0.84, 1.0, 1.0, 0.32135729853811523, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19305925701897397, 0.19305925701897408, 0.32924467346907443], 
reward next is 0.6708, 
noisyNet noise sample is [array([0.6423777], dtype=float32), 0.18757801]. 
=============================================
[2019-03-23 10:44:08,440] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[64.79356]
 [64.79356]
 [64.79356]
 [64.79356]
 [64.79356]], R is [[64.82574463]
 [64.84783173]
 [64.86863708]
 [64.88814545]
 [64.90641785]].
[2019-03-23 10:44:16,316] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.38776245e-24 1.00000000e+00 4.26991005e-35 1.16854655e-17
 1.39221005e-34], sum to 1.0000
[2019-03-23 10:44:16,322] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0565
[2019-03-23 10:44:16,326] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.33333333333333, 77.66666666666667, 1.0, 2.0, 0.2174636905114673, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 236111.6907352358, 236111.6907352355, 75505.70530193837], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7172400.0000, 
sim time next is 7173000.0000, 
raw observation next is [15.25, 77.5, 1.0, 2.0, 0.2158789745421704, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 234390.6672317697, 234390.6672317697, 75037.50493982782], 
processed observation next is [1.0, 0.0, 0.32954545454545453, 0.775, 1.0, 1.0, 0.019848718177712978, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08681135823398878, 0.08681135823398878, 0.18301830473128736], 
reward next is 0.8170, 
noisyNet noise sample is [array([-2.1083171], dtype=float32), -1.636888]. 
=============================================
[2019-03-23 10:44:16,342] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[64.67074 ]
 [64.71253 ]
 [64.855804]
 [65.06716 ]
 [65.064224]], R is [[64.81971741]
 [64.98736572]
 [65.15213013]
 [65.31400299]
 [65.47358704]].
[2019-03-23 10:44:16,908] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.8115023e-25 1.0000000e+00 0.0000000e+00 3.6291637e-21 2.9614481e-37], sum to 1.0000
[2019-03-23 10:44:16,921] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1726
[2019-03-23 10:44:16,931] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.63333333333333, 63.00000000000001, 1.0, 2.0, 0.2603526497857677, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 282692.0076965895, 282692.0076965895, 86273.15350652678], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7158000.0000, 
sim time next is 7158600.0000, 
raw observation next is [18.55, 63.0, 1.0, 2.0, 0.2583185359688611, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 280482.7214349068, 280482.7214349065, 85535.68928235778], 
processed observation next is [1.0, 0.8695652173913043, 0.47954545454545455, 0.63, 1.0, 1.0, 0.07289816996107638, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10388248942033586, 0.10388248942033573, 0.20862363239599457], 
reward next is 0.7914, 
noisyNet noise sample is [array([0.31221753], dtype=float32), -1.6436474]. 
=============================================
[2019-03-23 10:44:17,753] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.2603119e-27 1.0000000e+00 0.0000000e+00 1.2731757e-26 0.0000000e+00], sum to 1.0000
[2019-03-23 10:44:17,759] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6748
[2019-03-23 10:44:17,765] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.0, 77.0, 1.0, 2.0, 0.2144517566349832, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 232840.6940181495, 232840.6940181492, 74049.81757067563], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7174800.0000, 
sim time next is 7175400.0000, 
raw observation next is [14.85, 77.83333333333334, 1.0, 2.0, 0.2130390704667121, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 231306.5072853492, 231306.5072853495, 73786.64776627309], 
processed observation next is [1.0, 0.043478260869565216, 0.31136363636363634, 0.7783333333333334, 1.0, 1.0, 0.016298838083390124, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08566907677235155, 0.08566907677235167, 0.17996743357627584], 
reward next is 0.8200, 
noisyNet noise sample is [array([-1.1898252], dtype=float32), -0.9338571]. 
=============================================
[2019-03-23 10:44:23,475] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.0038076e-29 1.0000000e+00 0.0000000e+00 2.3266459e-25 0.0000000e+00], sum to 1.0000
[2019-03-23 10:44:23,484] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5429
[2019-03-23 10:44:23,495] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.1, 79.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 216172.654316518, 216172.6543165178, 71091.63086101627], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7281000.0000, 
sim time next is 7281600.0000, 
raw observation next is [14.2, 80.0, 1.0, 2.0, 0.2000916645616575, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 217245.7623183948, 217245.7623183951, 71568.70815778337], 
processed observation next is [1.0, 0.2608695652173913, 0.2818181818181818, 0.8, 1.0, 1.0, 0.000114580702071862, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08046139345125733, 0.08046139345125744, 0.1745578247750814], 
reward next is 0.8254, 
noisyNet noise sample is [array([0.59128165], dtype=float32), -0.25726828]. 
=============================================
[2019-03-23 10:44:23,977] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.5354583e-22 1.0000000e+00 2.2209900e-33 7.7740554e-24 2.5385023e-33], sum to 1.0000
[2019-03-23 10:44:23,986] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0887
[2019-03-23 10:44:23,991] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.83333333333333, 73.83333333333333, 1.0, 2.0, 0.7638771805387008, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 863880.0733554735, 863880.0733554735, 167957.5970042088], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7375800.0000, 
sim time next is 7376400.0000, 
raw observation next is [22.2, 73.0, 1.0, 2.0, 0.8037104816267241, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 910736.7144019614, 910736.7144019612, 174755.4926414057], 
processed observation next is [1.0, 0.391304347826087, 0.6454545454545454, 0.73, 1.0, 1.0, 0.754638102033405, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.33730989422294866, 0.3373098942229486, 0.4262329088814773], 
reward next is 0.5738, 
noisyNet noise sample is [array([-0.82469136], dtype=float32), 2.2301447]. 
=============================================
[2019-03-23 10:44:26,324] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.502825e-24 1.000000e+00 6.497189e-35 2.792954e-22 4.033181e-35], sum to 1.0000
[2019-03-23 10:44:26,326] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6910
[2019-03-23 10:44:26,330] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.36666666666667, 72.66666666666667, 1.0, 2.0, 0.3481321985366734, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 385685.2244684424, 385685.2244684421, 117300.201846574], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7339200.0000, 
sim time next is 7339800.0000, 
raw observation next is [20.18333333333333, 73.83333333333333, 1.0, 2.0, 0.3473258567033705, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 384680.44884157, 384680.44884157, 117193.2917607934], 
processed observation next is [1.0, 0.9565217391304348, 0.5537878787878786, 0.7383333333333333, 1.0, 1.0, 0.18415732087921313, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1424742403116926, 0.1424742403116926, 0.2858372969775449], 
reward next is 0.7142, 
noisyNet noise sample is [array([0.17935236], dtype=float32), 0.49991232]. 
=============================================
[2019-03-23 10:44:27,339] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.6902131e-24 1.0000000e+00 6.9549019e-35 1.9000739e-20 1.6799666e-34], sum to 1.0000
[2019-03-23 10:44:27,347] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2395
[2019-03-23 10:44:27,351] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 87.0, 1.0, 2.0, 0.3547531767705037, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 387599.1478664508, 387599.1478664511, 115822.271239689], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7355400.0000, 
sim time next is 7356000.0000, 
raw observation next is [17.7, 87.0, 1.0, 2.0, 0.3474410204705829, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 379624.4318080782, 379624.4318080782, 115285.1861668952], 
processed observation next is [1.0, 0.13043478260869565, 0.44090909090909086, 0.87, 1.0, 1.0, 0.1843012755882286, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14060164141039933, 0.14060164141039933, 0.28118338089486633], 
reward next is 0.7188, 
noisyNet noise sample is [array([0.46053287], dtype=float32), 1.4118669]. 
=============================================
[2019-03-23 10:44:27,368] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[65.04677 ]
 [65.12755 ]
 [65.15452 ]
 [65.209435]
 [65.271866]], R is [[65.03166199]
 [65.09885406]
 [65.16924286]
 [65.23801422]
 [65.30498505]].
[2019-03-23 10:44:30,038] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.1512018e-13 1.0000000e+00 7.3662165e-19 1.0417905e-12 7.5174360e-19], sum to 1.0000
[2019-03-23 10:44:30,046] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1769
[2019-03-23 10:44:30,053] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1608349.5609333 W.
[2019-03-23 10:44:30,056] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.2, 60.0, 1.0, 2.0, 0.7109260197682244, 1.0, 2.0, 0.7109260197682244, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1608349.5609333, 1608349.5609333, 293030.2466069184], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7405200.0000, 
sim time next is 7405800.0000, 
raw observation next is [26.18333333333333, 64.0, 1.0, 2.0, 0.3834709871800792, 0.0, 1.0, 0.0, 1.0, 1.0, 0.7763801752864884, 6.911199999999999, 6.9112, 77.32846344354104, 873696.7168165414, 873696.7168165416, 219308.3515020206], 
processed observation next is [1.0, 0.7391304347826086, 0.8265151515151513, 0.64, 1.0, 1.0, 0.229338733975099, 0.0, 0.5, -0.25, 1.0, 0.5, 0.6805431075521263, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.32359137659871906, 0.3235913765987191, 0.5348984182976112], 
reward next is 0.4651, 
noisyNet noise sample is [array([0.07481503], dtype=float32), -0.37095952]. 
=============================================
[2019-03-23 10:44:37,598] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.1754031e-27 1.0000000e+00 1.8445437e-38 1.6427175e-25 1.7493068e-37], sum to 1.0000
[2019-03-23 10:44:37,607] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8438
[2019-03-23 10:44:37,610] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.83333333333334, 61.33333333333334, 1.0, 2.0, 0.4914560569397285, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 560587.5949878696, 560587.5949878696, 140876.0201892967], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7562400.0000, 
sim time next is 7563000.0000, 
raw observation next is [27.01666666666667, 60.66666666666666, 1.0, 2.0, 0.4931230206426077, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 562435.2540633754, 562435.2540633758, 141175.2709286658], 
processed observation next is [0.0, 0.5217391304347826, 0.8643939393939395, 0.6066666666666666, 1.0, 1.0, 0.3664037758032596, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2083093533568057, 0.20830935335680584, 0.3443299290943068], 
reward next is 0.6557, 
noisyNet noise sample is [array([0.36011842], dtype=float32), -2.0691535]. 
=============================================
[2019-03-23 10:44:37,626] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[65.49762]
 [65.49762]
 [65.49762]
 [65.49762]
 [65.49762]], R is [[65.4983139 ]
 [65.49973297]
 [65.50184631]
 [65.50461578]
 [65.50783539]].
[2019-03-23 10:44:39,839] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-23 10:44:39,840] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 10:44:39,841] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:44:39,841] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 10:44:39,842] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 10:44:39,842] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:44:39,842] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 10:44:39,843] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 10:44:39,843] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:44:39,844] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:44:39,843] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:44:39,865] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run60
[2019-03-23 10:44:39,892] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run60
[2019-03-23 10:44:39,892] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run60
[2019-03-23 10:44:39,892] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run60
[2019-03-23 10:44:39,968] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run60
[2019-03-23 10:44:45,027] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05192005], dtype=float32), -1.1619295]
[2019-03-23 10:44:45,029] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [12.0, 76.0, 1.0, 2.0, 0.3987942380462075, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 433079.4084106712, 433079.4084106709, 86845.40633792222]
[2019-03-23 10:44:45,030] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:44:45,032] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.8763919e-26 1.0000000e+00 1.1383303e-37 1.3422105e-25 2.5230697e-37], sampled 0.0889515353007202
[2019-03-23 10:44:55,178] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05192005], dtype=float32), -1.1619295]
[2019-03-23 10:44:55,180] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.0, 94.0, 1.0, 2.0, 0.3730766893174355, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 415271.3984046483, 415271.3984046483, 120058.0559608061]
[2019-03-23 10:44:55,181] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:44:55,184] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.8763919e-26 1.0000000e+00 1.1383303e-37 1.3422105e-25 2.5230697e-37], sampled 0.09511188751633393
[2019-03-23 10:44:57,922] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05192005], dtype=float32), -1.1619295]
[2019-03-23 10:44:57,922] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.6, 82.0, 1.0, 2.0, 0.4475373803113759, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 508728.0544869833, 508728.0544869833, 136428.5170132229]
[2019-03-23 10:44:57,923] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 10:44:57,926] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.8763919e-26 1.0000000e+00 1.1383303e-37 1.3422105e-25 2.5230697e-37], sampled 0.4996785347368873
[2019-03-23 10:45:16,907] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05192005], dtype=float32), -1.1619295]
[2019-03-23 10:45:16,910] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [24.53256947333333, 41.39145323, 1.0, 2.0, 0.3348752592932956, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 363613.2957051173, 363613.295705117, 117902.8245812338]
[2019-03-23 10:45:16,910] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 10:45:16,913] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.8763919e-26 1.0000000e+00 1.1383303e-37 1.3422105e-25 2.5230697e-37], sampled 0.4832518609423305
[2019-03-23 10:45:20,509] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05192005], dtype=float32), -1.1619295]
[2019-03-23 10:45:20,511] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [25.68333333333333, 68.33333333333333, 1.0, 2.0, 0.5036993448844767, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 574351.3550767188, 574351.3550767188, 146864.9575843706]
[2019-03-23 10:45:20,511] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 10:45:20,515] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.8763919e-26 1.0000000e+00 1.1383303e-37 1.3422105e-25 2.5230697e-37], sampled 0.2772799957232861
[2019-03-23 10:45:40,937] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05192005], dtype=float32), -1.1619295]
[2019-03-23 10:45:40,941] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [26.93333333333333, 46.83333333333334, 1.0, 2.0, 0.3959559390903289, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 448322.6898656559, 448322.6898656556, 130060.4825623368]
[2019-03-23 10:45:40,942] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 10:45:40,945] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.8763919e-26 1.0000000e+00 1.1383303e-37 1.3422105e-25 2.5230697e-37], sampled 0.2187837200153797
[2019-03-23 10:45:49,190] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05192005], dtype=float32), -1.1619295]
[2019-03-23 10:45:49,191] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.6, 42.0, 1.0, 2.0, 0.2701944095708319, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 293381.4552790268, 293381.4552790271, 84307.70171048502]
[2019-03-23 10:45:49,191] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:45:49,194] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.8763919e-26 1.0000000e+00 1.1383303e-37 1.3422105e-25 2.5230697e-37], sampled 0.14554264187897115
[2019-03-23 10:46:09,960] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05192005], dtype=float32), -1.1619295]
[2019-03-23 10:46:09,961] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.76761986, 60.32030384, 1.0, 2.0, 0.2642982680682555, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 286961.2935277127, 286961.2935277123, 82704.34282906278]
[2019-03-23 10:46:09,962] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 10:46:09,965] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.8763919e-26 1.0000000e+00 1.1383303e-37 1.3422105e-25 2.5230697e-37], sampled 0.741673547121324
[2019-03-23 10:46:18,141] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 10:46:18,406] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 10:46:18,492] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 10:46:18,520] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 10:46:18,530] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 10:46:19,544] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 1475000, evaluation results [1475000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 10:46:21,007] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.5373835e-22 1.0000000e+00 7.0879172e-33 5.6489976e-18 3.2799823e-33], sum to 1.0000
[2019-03-23 10:46:21,013] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0272
[2019-03-23 10:46:21,016] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.93333333333333, 83.83333333333334, 1.0, 2.0, 0.8079926957404957, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 922250.2736525857, 922250.2736525853, 184109.0277798601], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7635000.0000, 
sim time next is 7635600.0000, 
raw observation next is [23.3, 82.0, 1.0, 2.0, 0.8237619252601417, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 940137.6226850963, 940137.6226850963, 187097.6129869782], 
processed observation next is [1.0, 0.391304347826087, 0.6954545454545454, 0.82, 1.0, 1.0, 0.779702406575177, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.34819911951299864, 0.34819911951299864, 0.45633564143165417], 
reward next is 0.5437, 
noisyNet noise sample is [array([-1.9256307], dtype=float32), -1.7131684]. 
=============================================
[2019-03-23 10:46:21,930] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.6519646e-13 7.7081033e-08 2.7668501e-19 9.9999988e-01 6.3801135e-18], sum to 1.0000
[2019-03-23 10:46:21,936] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5071
[2019-03-23 10:46:21,943] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.33333333333334, 72.66666666666667, 1.0, 2.0, 0.5191269470891167, 1.0, 2.0, 0.5191269470891167, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354103, 1175778.198643169, 1175778.198643168, 238083.3993528306], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7641600.0000, 
sim time next is 7642200.0000, 
raw observation next is [25.41666666666666, 72.33333333333333, 1.0, 2.0, 0.5170120391613966, 1.0, 2.0, 0.5170120391613966, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1170810.63369345, 1170810.63369345, 237611.3167916632], 
processed observation next is [1.0, 0.43478260869565216, 0.7916666666666664, 0.7233333333333333, 1.0, 1.0, 0.3962650489517457, 1.0, 1.0, 0.3962650489517457, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.43363356803461106, 0.43363356803461106, 0.5795397970528371], 
reward next is 0.4205, 
noisyNet noise sample is [array([0.5808707], dtype=float32), -0.27872154]. 
=============================================
[2019-03-23 10:46:25,655] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:46:25,656] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:46:25,734] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run8
[2019-03-23 10:46:26,651] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.5532710e-26 1.0000000e+00 1.3680858e-36 1.9118430e-22 1.4273723e-37], sum to 1.0000
[2019-03-23 10:46:26,659] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6857
[2019-03-23 10:46:26,662] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.7, 46.0, 1.0, 2.0, 0.7376124579519449, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 801329.8700781842, 801329.8700781844, 149229.4499231108], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7747200.0000, 
sim time next is 7747800.0000, 
raw observation next is [22.33333333333334, 47.16666666666667, 1.0, 2.0, 0.7352530450958874, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 798764.5361650856, 798764.5361650856, 147910.5076308912], 
processed observation next is [1.0, 0.6956521739130435, 0.6515151515151518, 0.47166666666666673, 1.0, 1.0, 0.6690663063698593, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2958387170981799, 0.2958387170981799, 0.3607573356851005], 
reward next is 0.6392, 
noisyNet noise sample is [array([-0.07566174], dtype=float32), 0.57582027]. 
=============================================
[2019-03-23 10:46:26,958] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.3102276e-28 1.0000000e+00 1.3215591e-38 5.2317387e-29 3.8095563e-38], sum to 1.0000
[2019-03-23 10:46:26,966] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2529
[2019-03-23 10:46:26,969] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.8, 45.0, 1.0, 2.0, 0.7149662754331695, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 779818.9437451613, 779818.9437451615, 149795.5314819246], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7824000.0000, 
sim time next is 7824600.0000, 
raw observation next is [23.8, 45.0, 1.0, 2.0, 0.7672876401815661, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 837773.1594749712, 837773.1594749712, 156291.7006435563], 
processed observation next is [1.0, 0.5652173913043478, 0.7181818181818183, 0.45, 1.0, 1.0, 0.7091095502269575, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.31028635536110044, 0.31028635536110044, 0.38119926986233243], 
reward next is 0.6188, 
noisyNet noise sample is [array([1.5849367], dtype=float32), -0.41870996]. 
=============================================
[2019-03-23 10:46:33,506] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.9501692e-26 1.0000000e+00 6.4839892e-36 6.9412803e-27 3.9729250e-35], sum to 1.0000
[2019-03-23 10:46:33,512] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0053
[2019-03-23 10:46:33,519] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.33333333333333, 62.66666666666667, 1.0, 2.0, 0.5199768366445071, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 564756.7704847688, 564756.7704847688, 119335.1766219692], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 125400.0000, 
sim time next is 126000.0000, 
raw observation next is [19.0, 64.0, 1.0, 2.0, 0.4863712073543966, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 528237.2222320747, 528237.222232075, 114591.623811374], 
processed observation next is [1.0, 0.4782608695652174, 0.5, 0.64, 1.0, 1.0, 0.3579640091929957, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19564341564150914, 0.19564341564150925, 0.2794917653935951], 
reward next is 0.7205, 
noisyNet noise sample is [array([0.4850154], dtype=float32), -0.37435204]. 
=============================================
[2019-03-23 10:46:33,540] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[61.74185 ]
 [61.215565]
 [60.653015]
 [60.254112]
 [59.61209 ]], R is [[62.63890076]
 [62.72145081]
 [62.79751205]
 [62.86571503]
 [62.93257904]].
[2019-03-23 10:46:34,493] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:46:34,494] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:46:34,566] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run8
[2019-03-23 10:46:37,188] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:46:37,189] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:46:37,253] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run8
[2019-03-23 10:46:37,936] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:46:37,937] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:46:37,949] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run8
[2019-03-23 10:46:37,970] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:46:37,971] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:46:37,984] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:46:37,985] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:46:37,989] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run8
[2019-03-23 10:46:38,030] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run8
[2019-03-23 10:46:38,072] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:46:38,073] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:46:38,078] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run8
[2019-03-23 10:46:38,172] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:46:38,172] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:46:38,179] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run8
[2019-03-23 10:46:38,209] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:46:38,210] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:46:38,217] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run8
[2019-03-23 10:46:38,343] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:46:38,343] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:46:38,347] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run8
[2019-03-23 10:46:38,409] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:46:38,409] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:46:38,412] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:46:38,413] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:46:38,418] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run8
[2019-03-23 10:46:38,418] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run8
[2019-03-23 10:46:38,448] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:46:38,478] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:46:38,477] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:46:38,479] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:46:38,487] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run8
[2019-03-23 10:46:38,533] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run8
[2019-03-23 10:46:38,625] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:46:38,625] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:46:38,630] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run8
[2019-03-23 10:46:38,681] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:46:38,681] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:46:38,685] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run8
[2019-03-23 10:46:47,578] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.2286553e-30 1.0000000e+00 0.0000000e+00 5.7769242e-31 0.0000000e+00], sum to 1.0000
[2019-03-23 10:46:47,585] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9064
[2019-03-23 10:46:47,590] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.5, 49.0, 1.0, 2.0, 0.2749379381088899, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 298533.636048353, 298533.6360483533, 82026.69888006175], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 156600.0000, 
sim time next is 157200.0000, 
raw observation next is [19.33333333333334, 50.0, 1.0, 2.0, 0.2722234263346349, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 295585.2639794846, 295585.2639794843, 81750.37448414614], 
processed observation next is [1.0, 0.8260869565217391, 0.5151515151515155, 0.5, 1.0, 1.0, 0.09027928291829364, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10947602369610542, 0.1094760236961053, 0.19939115727840523], 
reward next is 0.8006, 
noisyNet noise sample is [array([0.98435026], dtype=float32), 1.8906562]. 
=============================================
[2019-03-23 10:46:56,379] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.8818514e-29 1.0000000e+00 0.0000000e+00 6.7335634e-30 0.0000000e+00], sum to 1.0000
[2019-03-23 10:46:56,388] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4336
[2019-03-23 10:46:56,394] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333334, 57.00000000000001, 1.0, 2.0, 0.6118054361690319, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 683669.2363886856, 683669.236388686, 144252.224128111], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 645600.0000, 
sim time next is 646200.0000, 
raw observation next is [23.5, 57.0, 1.0, 2.0, 0.5759132811528127, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 644483.5273992941, 644483.5273992941, 140647.6189799323], 
processed observation next is [1.0, 0.4782608695652174, 0.7045454545454546, 0.57, 1.0, 1.0, 0.4698916014410158, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2386976027404793, 0.2386976027404793, 0.3430429731217861], 
reward next is 0.6570, 
noisyNet noise sample is [array([1.542553], dtype=float32), 1.1990511]. 
=============================================
[2019-03-23 10:46:58,595] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.4617307e-27 1.0000000e+00 0.0000000e+00 1.4433286e-28 0.0000000e+00], sum to 1.0000
[2019-03-23 10:46:58,600] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8300
[2019-03-23 10:46:58,603] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.33333333333333, 92.0, 1.0, 2.0, 0.223684686222919, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 242867.8371630927, 242867.8371630927, 78221.6641278843], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 510000.0000, 
sim time next is 510600.0000, 
raw observation next is [14.16666666666667, 93.0, 1.0, 2.0, 0.2214802994809067, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 240473.8110155591, 240473.8110155594, 77695.92208119389], 
processed observation next is [1.0, 0.9130434782608695, 0.28030303030303044, 0.93, 1.0, 1.0, 0.026850374351133355, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08906437445020707, 0.08906437445020718, 0.18950224897852166], 
reward next is 0.8105, 
noisyNet noise sample is [array([-0.4270552], dtype=float32), 0.6666737]. 
=============================================
[2019-03-23 10:46:59,314] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.222698e-32 1.000000e+00 0.000000e+00 4.613518e-32 0.000000e+00], sum to 1.0000
[2019-03-23 10:46:59,321] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4727
[2019-03-23 10:46:59,329] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 54.0, 1.0, 2.0, 0.3408618235541673, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 370142.4772362769, 370142.4772362769, 89979.6657855905], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 387000.0000, 
sim time next is 387600.0000, 
raw observation next is [19.33333333333333, 54.66666666666666, 1.0, 2.0, 0.3494853567439301, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 379510.4420214543, 379510.4420214543, 92785.35266472206], 
processed observation next is [1.0, 0.4782608695652174, 0.5151515151515149, 0.5466666666666665, 1.0, 1.0, 0.1868566959299126, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14055942297090898, 0.14055942297090898, 0.22630573820663916], 
reward next is 0.7737, 
noisyNet noise sample is [array([-0.2427478], dtype=float32), -0.22987661]. 
=============================================
[2019-03-23 10:47:09,706] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-23 10:47:09,707] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 10:47:09,708] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:47:09,709] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 10:47:09,710] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 10:47:09,710] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:47:09,711] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:47:09,711] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 10:47:09,713] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 10:47:09,716] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:47:09,717] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:47:09,736] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run61
[2019-03-23 10:47:09,758] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run61
[2019-03-23 10:47:09,760] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run61
[2019-03-23 10:47:09,761] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run61
[2019-03-23 10:47:09,836] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run61
[2019-03-23 10:47:31,702] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.04267592], dtype=float32), -1.16348]
[2019-03-23 10:47:31,702] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.61666666666667, 71.16666666666667, 1.0, 2.0, 0.3879163560620076, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 435634.3088966224, 435634.3088966228, 127328.4477447261]
[2019-03-23 10:47:31,703] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 10:47:31,707] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.9953084e-27 1.0000000e+00 2.1439895e-38 2.3760933e-26 5.1365755e-38], sampled 0.4722758763155429
[2019-03-23 10:47:44,743] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.04267592], dtype=float32), -1.16348]
[2019-03-23 10:47:44,744] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [25.36191414166667, 70.42810234333332, 1.0, 2.0, 0.490766152666431, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 559715.4892156986, 559715.4892156986, 145150.6855442552]
[2019-03-23 10:47:44,745] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 10:47:44,748] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.4323766e-27 1.0000000e+00 2.4137913e-38 2.5849377e-26 5.7774986e-38], sampled 0.5613554187819818
[2019-03-23 10:47:49,442] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.04267592], dtype=float32), -1.16348]
[2019-03-23 10:47:49,444] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.0, 100.0, 1.0, 2.0, 0.5681953912271305, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 648328.727673503, 648328.727673503, 149786.8412627921]
[2019-03-23 10:47:49,444] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:47:49,448] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [7.1567865e-27 1.0000000e+00 3.5614782e-38 3.4159403e-26 8.4999817e-38], sampled 0.6453343033801039
[2019-03-23 10:47:57,856] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.04267592], dtype=float32), -1.16348]
[2019-03-23 10:47:57,857] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.55, 69.0, 1.0, 2.0, 0.4309421105706809, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 489986.7017423939, 489986.7017423935, 134872.6802650155]
[2019-03-23 10:47:57,859] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 10:47:57,863] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.0226897e-27 1.0000000e+00 2.1606072e-38 2.3891632e-26 5.1760725e-38], sampled 0.40754968709615547
[2019-03-23 10:48:06,614] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.04267592], dtype=float32), -1.16348]
[2019-03-23 10:48:06,616] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.0, 100.0, 1.0, 2.0, 0.3953641430104596, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 443939.5993233135, 443939.5993233137, 123627.7004669477]
[2019-03-23 10:48:06,617] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:48:06,619] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [6.2961165e-27 1.0000000e+00 2.9727311e-38 3.0001135e-26 7.1041141e-38], sampled 0.4485059295986621
[2019-03-23 10:48:44,369] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.04267592], dtype=float32), -1.16348]
[2019-03-23 10:48:44,370] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [16.53333333333333, 68.66666666666666, 1.0, 2.0, 0.2288191228480021, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 248431.9245296127, 248431.9245296123, 81550.68610954628]
[2019-03-23 10:48:44,371] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 10:48:44,374] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.9953084e-27 1.0000000e+00 2.1439895e-38 2.3760933e-26 5.1365755e-38], sampled 0.43969144351404443
[2019-03-23 10:48:49,272] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 10:48:49,286] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 10:48:49,578] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 10:48:49,632] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 10:48:49,650] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 10:48:50,666] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1500000, evaluation results [1500000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 10:48:53,852] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.5054999e-22 1.0000000e+00 8.6286237e-33 7.5325236e-22 6.4081681e-32], sum to 1.0000
[2019-03-23 10:48:53,860] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2446
[2019-03-23 10:48:53,864] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333334, 72.0, 1.0, 2.0, 0.543780329211016, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 610141.3501846641, 610141.3501846641, 137899.1877324431], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 639600.0000, 
sim time next is 640200.0000, 
raw observation next is [21.66666666666667, 70.5, 1.0, 2.0, 0.5060985262923111, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 568342.1732875314, 568342.1732875316, 134188.5511681977], 
processed observation next is [1.0, 0.391304347826087, 0.6212121212121214, 0.705, 1.0, 1.0, 0.38262315786538886, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2104971012176042, 0.2104971012176043, 0.3272891491907261], 
reward next is 0.6727, 
noisyNet noise sample is [array([0.26466763], dtype=float32), 1.6448013]. 
=============================================
[2019-03-23 10:49:07,108] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.0749839e-24 1.0000000e+00 1.0677249e-35 1.1612331e-23 2.0585334e-35], sum to 1.0000
[2019-03-23 10:49:07,111] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5763
[2019-03-23 10:49:07,124] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 81.33333333333333, 1.0, 2.0, 0.4649890654104986, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 530564.7398986603, 530564.7398986603, 136705.7478255277], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 902400.0000, 
sim time next is 903000.0000, 
raw observation next is [23.0, 82.16666666666667, 1.0, 2.0, 0.4690106335009486, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 535175.7489576885, 535175.7489576885, 137384.4563203999], 
processed observation next is [0.0, 0.43478260869565216, 0.6818181818181818, 0.8216666666666668, 1.0, 1.0, 0.33626329187618575, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19821324035469942, 0.19821324035469942, 0.33508403980585344], 
reward next is 0.6649, 
noisyNet noise sample is [array([-1.3008693], dtype=float32), -1.4417088]. 
=============================================
[2019-03-23 10:49:07,151] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[68.63226]
 [68.63226]
 [68.63226]
 [68.63226]
 [68.63226]], R is [[68.6108551 ]
 [68.59131622]
 [68.57352448]
 [68.55744171]
 [68.54303741]].
[2019-03-23 10:49:08,858] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.8688664e-30 1.0000000e+00 0.0000000e+00 3.9086069e-32 0.0000000e+00], sum to 1.0000
[2019-03-23 10:49:08,868] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4588
[2019-03-23 10:49:08,873] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 78.0, 1.0, 2.0, 0.4216811435640896, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 478910.887309756, 478910.8873097557, 129159.2943992917], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 921600.0000, 
sim time next is 922200.0000, 
raw observation next is [22.0, 78.0, 1.0, 2.0, 0.4211183903164195, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 478270.6259077512, 478270.6259077512, 129103.8065250056], 
processed observation next is [0.0, 0.6956521739130435, 0.6363636363636364, 0.78, 1.0, 1.0, 0.27639798789552433, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17713726885472267, 0.17713726885472267, 0.3148873329878185], 
reward next is 0.6851, 
noisyNet noise sample is [array([0.30939063], dtype=float32), 1.2755231]. 
=============================================
[2019-03-23 10:49:08,899] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0876343e-27 1.0000000e+00 0.0000000e+00 2.4700418e-24 0.0000000e+00], sum to 1.0000
[2019-03-23 10:49:08,905] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3891
[2019-03-23 10:49:08,912] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 78.0, 1.0, 2.0, 0.4199785227572451, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 476973.6836307785, 476973.6836307785, 128991.4830613066], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 924600.0000, 
sim time next is 925200.0000, 
raw observation next is [22.0, 78.0, 1.0, 2.0, 0.4195176613758836, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 476449.4664091091, 476449.4664091094, 128946.237728223], 
processed observation next is [0.0, 0.7391304347826086, 0.6363636363636364, 0.78, 1.0, 1.0, 0.27439707671985447, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17646276533670707, 0.17646276533670718, 0.3145030188493244], 
reward next is 0.6855, 
noisyNet noise sample is [array([0.56825155], dtype=float32), -0.16047277]. 
=============================================
[2019-03-23 10:49:10,441] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.3602894e-29 1.0000000e+00 0.0000000e+00 1.6431850e-28 0.0000000e+00], sum to 1.0000
[2019-03-23 10:49:10,451] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8168
[2019-03-23 10:49:10,462] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.83333333333333, 63.33333333333334, 1.0, 2.0, 0.50325013834785, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 573568.7992261868, 573568.7992261866, 142940.0374761898], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1275000.0000, 
sim time next is 1275600.0000, 
raw observation next is [26.66666666666667, 64.66666666666667, 1.0, 2.0, 0.5092806193370608, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 580316.7849342152, 580316.7849342152, 143791.0672805243], 
processed observation next is [1.0, 0.782608695652174, 0.8484848484848487, 0.6466666666666667, 1.0, 1.0, 0.386600774171326, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21493214256822787, 0.21493214256822787, 0.35070992019640074], 
reward next is 0.6493, 
noisyNet noise sample is [array([-1.0181919], dtype=float32), 1.1070642]. 
=============================================
[2019-03-23 10:49:17,119] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.3491165e-26 1.0000000e+00 8.9140227e-38 3.3319969e-29 1.3897996e-36], sum to 1.0000
[2019-03-23 10:49:17,126] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3018
[2019-03-23 10:49:17,131] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 69.0, 1.0, 2.0, 0.6181619108058379, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 695674.1287346568, 695674.1287346572, 147158.8059119387], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1089000.0000, 
sim time next is 1089600.0000, 
raw observation next is [22.0, 69.0, 1.0, 2.0, 0.6460721984653301, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 727128.3220301018, 727128.3220301018, 150520.3196978889], 
processed observation next is [1.0, 0.6086956521739131, 0.6363636363636364, 0.69, 1.0, 1.0, 0.5575902480816627, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.26930678593707474, 0.26930678593707474, 0.3671227309704607], 
reward next is 0.6329, 
noisyNet noise sample is [array([-1.1255437], dtype=float32), 1.0404761]. 
=============================================
[2019-03-23 10:49:22,078] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.6176861e-19 1.0000000e+00 1.3803910e-26 6.6621746e-23 1.4049238e-26], sum to 1.0000
[2019-03-23 10:49:22,084] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6601
[2019-03-23 10:49:22,091] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1396651.961630429 W.
[2019-03-23 10:49:22,095] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.0, 65.33333333333333, 1.0, 2.0, 0.6190444636194278, 1.0, 1.0, 0.6190444636194278, 0.0, 1.0, 0.0, 6.911200000000002, 6.9112, 77.32846344354104, 1396651.961630429, 1396651.961630429, 266422.4842427973], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1174200.0000, 
sim time next is 1174800.0000, 
raw observation next is [27.0, 64.66666666666667, 1.0, 2.0, 0.7378715283081307, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9789564273653737, 6.911199999999999, 6.9112, 77.32846344354104, 1385244.736713717, 1385244.736713717, 299551.5801587368], 
processed observation next is [1.0, 0.6086956521739131, 0.8636363636363636, 0.6466666666666667, 1.0, 1.0, 0.6723394103851634, 0.0, 0.5, -0.25, 1.0, 0.5, 0.9699377533791053, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.5130536061902655, 0.5130536061902655, 0.7306136101432604], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.4948275], dtype=float32), -0.07915384]. 
=============================================
[2019-03-23 10:49:27,718] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.5517192e-23 1.0000000e+00 4.6069055e-32 7.7778087e-20 1.7151503e-31], sum to 1.0000
[2019-03-23 10:49:27,727] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5608
[2019-03-23 10:49:27,732] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.33333333333334, 100.0, 1.0, 2.0, 0.3890538276816274, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 432748.5192705041, 432748.5192705044, 121259.2544780878], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1304400.0000, 
sim time next is 1305000.0000, 
raw observation next is [17.5, 100.0, 1.0, 2.0, 0.3743346130256268, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 417309.5399422572, 417309.5399422575, 120430.5047031719], 
processed observation next is [1.0, 0.08695652173913043, 0.4318181818181818, 1.0, 1.0, 1.0, 0.2179182662820335, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15455908886750266, 0.15455908886750278, 0.29373293830041924], 
reward next is 0.7063, 
noisyNet noise sample is [array([-0.90318316], dtype=float32), 0.25563595]. 
=============================================
[2019-03-23 10:49:27,754] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[48.5787  ]
 [48.316223]
 [48.649994]
 [48.410637]
 [48.318844]], R is [[48.57238388]
 [48.79090881]
 [49.0015831 ]
 [49.22563553]
 [49.44684601]].
[2019-03-23 10:49:30,385] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.8045807e-26 1.0000000e+00 1.0039349e-34 1.2014057e-27 1.6199033e-34], sum to 1.0000
[2019-03-23 10:49:30,392] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2946
[2019-03-23 10:49:30,394] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 91.0, 1.0, 2.0, 0.3445507262609159, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 381313.802067222, 381313.802067222, 116863.0281022471], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1650600.0000, 
sim time next is 1651200.0000, 
raw observation next is [18.0, 92.0, 1.0, 2.0, 0.3436711812197031, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 380977.3221764624, 380977.3221764621, 117050.2469174409], 
processed observation next is [1.0, 0.08695652173913043, 0.45454545454545453, 0.92, 1.0, 1.0, 0.17958897652462882, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1411027119172083, 0.1411027119172082, 0.28548840711570955], 
reward next is 0.7145, 
noisyNet noise sample is [array([1.1371143], dtype=float32), -0.3710184]. 
=============================================
[2019-03-23 10:49:32,152] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.9138540e-18 1.0000000e+00 2.1071909e-26 9.9049725e-16 4.3715570e-25], sum to 1.0000
[2019-03-23 10:49:32,158] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6065
[2019-03-23 10:49:32,161] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666666, 83.33333333333334, 1.0, 2.0, 0.4656392867926649, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 531312.4470719644, 531312.4470719642, 136817.5738349087], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1359600.0000, 
sim time next is 1360200.0000, 
raw observation next is [22.83333333333334, 80.66666666666666, 1.0, 2.0, 0.4688868435068663, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 534931.8252699351, 534931.8252699351, 136760.4310587307], 
processed observation next is [1.0, 0.7391304347826086, 0.6742424242424245, 0.8066666666666665, 1.0, 1.0, 0.3361085543835829, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1981228982481241, 0.1981228982481241, 0.3335620269725139], 
reward next is 0.6664, 
noisyNet noise sample is [array([-0.00708958], dtype=float32), 0.5761207]. 
=============================================
[2019-03-23 10:49:38,622] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0563854e-27 1.0000000e+00 0.0000000e+00 4.0323094e-25 0.0000000e+00], sum to 1.0000
[2019-03-23 10:49:38,631] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6413
[2019-03-23 10:49:38,639] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4765180593572917, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 543676.6504687758, 543676.6504687758, 138802.2671335917], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1493400.0000, 
sim time next is 1494000.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.4764297685549384, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 543575.8489886728, 543575.8489886728, 138792.3797822597], 
processed observation next is [0.0, 0.30434782608695654, 0.5909090909090909, 1.0, 1.0, 1.0, 0.345537210693673, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20132438851432327, 0.20132438851432327, 0.3385179994689261], 
reward next is 0.6615, 
noisyNet noise sample is [array([-0.72643274], dtype=float32), -0.11178164]. 
=============================================
[2019-03-23 10:49:38,665] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[67.586525]
 [67.586525]
 [67.586525]
 [67.586525]
 [67.586525]], R is [[67.57215881]
 [67.55789948]
 [67.54376221]
 [67.5298233 ]
 [67.51628876]].
[2019-03-23 10:49:39,993] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-23 10:49:39,995] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 10:49:39,995] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 10:49:39,995] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:49:39,996] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:49:39,997] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 10:49:39,998] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 10:49:39,996] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 10:49:40,000] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:49:40,001] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:49:40,001] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:49:40,020] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run62
[2019-03-23 10:49:40,046] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run62
[2019-03-23 10:49:40,071] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run62
[2019-03-23 10:49:40,071] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run62
[2019-03-23 10:49:40,117] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run62
[2019-03-23 10:50:07,042] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.06108168], dtype=float32), -1.149785]
[2019-03-23 10:50:07,043] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [11.18333333333333, 79.16666666666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 190658.9885873078, 190658.9885873078, 67934.43005014917]
[2019-03-23 10:50:07,043] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 10:50:07,048] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [6.4241489e-25 1.0000000e+00 1.1840478e-35 3.4401625e-24 1.9612946e-34], sampled 0.8719686140925937
[2019-03-23 10:50:15,177] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.06108168], dtype=float32), -1.149785]
[2019-03-23 10:50:15,178] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.08333333333333, 77.33333333333334, 1.0, 2.0, 0.6585794876206156, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 744325.8591542621, 744325.8591542618, 158037.1665019291]
[2019-03-23 10:50:15,181] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 10:50:15,184] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [6.4241489e-25 1.0000000e+00 1.1840478e-35 3.4401625e-24 1.9612946e-34], sampled 0.3113931217895801
[2019-03-23 10:50:15,490] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.06108168], dtype=float32), -1.149785]
[2019-03-23 10:50:15,491] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.95, 88.5, 1.0, 2.0, 0.4524508022206746, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 511441.1546731864, 511441.1546731861, 134954.6608248361]
[2019-03-23 10:50:15,492] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 10:50:15,495] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [6.4241489e-25 1.0000000e+00 1.1840478e-35 3.4401625e-24 1.9612946e-34], sampled 0.9929587186557846
[2019-03-23 10:50:48,973] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.06108168], dtype=float32), -1.149785]
[2019-03-23 10:50:48,974] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [13.45628800333333, 68.72519629, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 209321.7199303575, 209321.7199303572, 71873.33115223487]
[2019-03-23 10:50:48,976] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 10:50:48,978] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [6.4241489e-25 1.0000000e+00 1.1840478e-35 3.4401625e-24 1.9612946e-34], sampled 0.11051940925487447
[2019-03-23 10:51:18,266] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 10:51:18,696] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 10:51:18,933] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 10:51:18,937] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 10:51:19,018] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 10:51:20,036] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 1525000, evaluation results [1525000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 10:51:20,485] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.8684345e-26 1.0000000e+00 3.4232000e-37 4.1611679e-24 6.2607338e-37], sum to 1.0000
[2019-03-23 10:51:20,492] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1724
[2019-03-23 10:51:20,497] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 70.0, 1.0, 2.0, 0.6055597217993292, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 680489.1863176546, 680489.1863176546, 159671.5880935337], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1512000.0000, 
sim time next is 1512600.0000, 
raw observation next is [28.16666666666667, 69.33333333333334, 1.0, 2.0, 0.6041925368511031, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 678951.758262261, 678951.7582622608, 159480.725719851], 
processed observation next is [0.0, 0.5217391304347826, 0.9166666666666669, 0.6933333333333335, 1.0, 1.0, 0.5052406710638788, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.25146361417120777, 0.2514636141712077, 0.38897737980451463], 
reward next is 0.6110, 
noisyNet noise sample is [array([0.28660294], dtype=float32), 1.247761]. 
=============================================
[2019-03-23 10:51:32,839] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.3886528e-24 1.0000000e+00 4.2462231e-37 8.0972419e-20 8.6225890e-36], sum to 1.0000
[2019-03-23 10:51:32,850] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6362
[2019-03-23 10:51:32,854] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.5, 71.0, 1.0, 2.0, 0.2480047927097266, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 269280.9406202978, 269280.9406202978, 84764.96806948456], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2075400.0000, 
sim time next is 2076000.0000, 
raw observation next is [17.0, 74.66666666666667, 1.0, 2.0, 0.2424932347551682, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 263294.9303345646, 263294.9303345646, 83964.44476636783], 
processed observation next is [0.0, 0.0, 0.4090909090909091, 0.7466666666666667, 1.0, 1.0, 0.053116543443960246, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09751664086465354, 0.09751664086465354, 0.20479132869845812], 
reward next is 0.7952, 
noisyNet noise sample is [array([-1.3546473], dtype=float32), 1.0055629]. 
=============================================
[2019-03-23 10:51:32,871] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[81.00491]
 [81.00491]
 [81.00491]
 [81.00491]
 [81.00491]], R is [[80.99006653]
 [80.97342682]
 [80.9553833 ]
 [80.93641663]
 [80.91730499]].
[2019-03-23 10:51:36,812] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.9921268e-28 1.0000000e+00 0.0000000e+00 1.6420103e-24 6.8492863e-38], sum to 1.0000
[2019-03-23 10:51:36,819] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2449
[2019-03-23 10:51:36,823] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [10.0, 100.0, 1.0, 2.0, 0.3432851857544906, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 372775.0193771083, 372775.0193771083, 81647.37773329108], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1832400.0000, 
sim time next is 1833000.0000, 
raw observation next is [10.16666666666667, 100.0, 1.0, 2.0, 0.3499604760790149, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 380026.5815595462, 380026.5815595462, 82564.1849590038], 
processed observation next is [1.0, 0.21739130434782608, 0.09848484848484862, 1.0, 1.0, 1.0, 0.18745059509876863, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14075058576279487, 0.14075058576279487, 0.20137606087561905], 
reward next is 0.7986, 
noisyNet noise sample is [array([0.05906074], dtype=float32), 1.9336509]. 
=============================================
[2019-03-23 10:51:36,851] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[70.261505]
 [70.35058 ]
 [70.37637 ]
 [70.40253 ]
 [70.40703 ]], R is [[70.28167725]
 [70.37971497]
 [70.47991943]
 [70.57849121]
 [70.67508698]].
[2019-03-23 10:51:37,306] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.8338067e-26 1.0000000e+00 0.0000000e+00 8.5859739e-25 3.1961228e-36], sum to 1.0000
[2019-03-23 10:51:37,312] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0253
[2019-03-23 10:51:37,315] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.0, 94.0, 1.0, 2.0, 0.4415996020932154, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 479587.7666672141, 479587.7666672141, 94227.09719353884], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1837200.0000, 
sim time next is 1837800.0000, 
raw observation next is [12.5, 91.0, 1.0, 2.0, 0.4384379172198824, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 476152.4194818587, 476152.4194818587, 94518.8340625178], 
processed observation next is [1.0, 0.2608695652173913, 0.20454545454545456, 0.91, 1.0, 1.0, 0.29804739652485296, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17635274795624398, 0.17635274795624398, 0.23053374161589707], 
reward next is 0.7695, 
noisyNet noise sample is [array([-0.61023414], dtype=float32), -1.0987412]. 
=============================================
[2019-03-23 10:51:38,788] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.0016001e-27 1.0000000e+00 6.2183869e-38 1.9231329e-26 2.7893552e-37], sum to 1.0000
[2019-03-23 10:51:38,799] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6696
[2019-03-23 10:51:38,804] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.66666666666667, 43.0, 1.0, 2.0, 0.7236128479094266, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 786108.6227470953, 786108.6227470953, 149824.9706229898], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1870800.0000, 
sim time next is 1871400.0000, 
raw observation next is [23.83333333333333, 43.5, 1.0, 2.0, 0.7402955455695817, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 804247.1443812657, 804247.1443812657, 151769.5708563262], 
processed observation next is [1.0, 0.6521739130434783, 0.7196969696969695, 0.435, 1.0, 1.0, 0.6753694319619771, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2978693127338021, 0.2978693127338021, 0.37016968501542974], 
reward next is 0.6298, 
noisyNet noise sample is [array([-0.2141778], dtype=float32), 1.322931]. 
=============================================
[2019-03-23 10:51:40,342] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.971495e-27 1.000000e+00 0.000000e+00 4.332855e-26 2.266813e-37], sum to 1.0000
[2019-03-23 10:51:40,349] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0870
[2019-03-23 10:51:40,354] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.3592023996607954, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 403051.4319507862, 403051.4319507864, 120391.1450816176], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1915200.0000, 
sim time next is 1915800.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.4158905945458277, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 466944.0533472759, 466944.0533472757, 125439.7126391795], 
processed observation next is [1.0, 0.17391304347826086, 0.45454545454545453, 1.0, 1.0, 1.0, 0.2698632431822846, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17294224198047256, 0.17294224198047248, 0.3059505186321451], 
reward next is 0.6940, 
noisyNet noise sample is [array([-2.6741724], dtype=float32), -0.23916441]. 
=============================================
[2019-03-23 10:51:44,277] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.7394827e-32 1.0000000e+00 0.0000000e+00 7.2382226e-34 0.0000000e+00], sum to 1.0000
[2019-03-23 10:51:44,282] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7170
[2019-03-23 10:51:44,287] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333334, 60.0, 1.0, 2.0, 0.3235392025787905, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 353270.011074937, 353270.0110749367, 113471.6830907771], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1978800.0000, 
sim time next is 1979400.0000, 
raw observation next is [21.16666666666666, 60.0, 1.0, 2.0, 0.3191907882138674, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 347496.240232227, 347496.2402322273, 112805.3030419371], 
processed observation next is [1.0, 0.9130434782608695, 0.5984848484848482, 0.6, 1.0, 1.0, 0.14898848526733427, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1287023111971211, 0.12870231119712122, 0.2751348854681393], 
reward next is 0.7249, 
noisyNet noise sample is [array([-1.5077202], dtype=float32), 0.223281]. 
=============================================
[2019-03-23 10:51:49,507] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.4317564e-30 1.0000000e+00 0.0000000e+00 7.1630158e-34 0.0000000e+00], sum to 1.0000
[2019-03-23 10:51:49,513] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2634
[2019-03-23 10:51:49,518] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.5, 71.0, 1.0, 2.0, 0.2480047927097266, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 269280.9406202978, 269280.9406202978, 84764.96806948456], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2075400.0000, 
sim time next is 2076000.0000, 
raw observation next is [17.0, 74.66666666666667, 1.0, 2.0, 0.2424932347551682, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 263294.9303345646, 263294.9303345646, 83964.44476636783], 
processed observation next is [0.0, 0.0, 0.4090909090909091, 0.7466666666666667, 1.0, 1.0, 0.053116543443960246, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09751664086465354, 0.09751664086465354, 0.20479132869845812], 
reward next is 0.7952, 
noisyNet noise sample is [array([0.5710247], dtype=float32), 1.5340244]. 
=============================================
[2019-03-23 10:51:49,534] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[77.05061]
 [77.05061]
 [77.05061]
 [77.05061]
 [77.05061]], R is [[77.07530975]
 [77.09781647]
 [77.11852264]
 [77.13792419]
 [77.15679932]].
[2019-03-23 10:51:50,838] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.3226269e-25 1.0000000e+00 2.7118494e-38 8.5708755e-28 6.1256509e-37], sum to 1.0000
[2019-03-23 10:51:50,844] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9461
[2019-03-23 10:51:50,849] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 89.00000000000001, 1.0, 2.0, 0.2022767638880465, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 219618.7284129391, 219618.7284129391, 73616.69893307492], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2092200.0000, 
sim time next is 2092800.0000, 
raw observation next is [14.0, 90.0, 1.0, 2.0, 0.2043563863869114, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 221877.1599239327, 221877.1599239324, 74146.01881921983], 
processed observation next is [0.0, 0.21739130434782608, 0.2727272727272727, 0.9, 1.0, 1.0, 0.005445482983639227, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08217672589775285, 0.08217672589775274, 0.18084394833956055], 
reward next is 0.8192, 
noisyNet noise sample is [array([-0.34271923], dtype=float32), 0.7956282]. 
=============================================
[2019-03-23 10:51:53,778] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.3798561e-23 1.0000000e+00 2.2241151e-36 1.7357881e-20 4.3745709e-35], sum to 1.0000
[2019-03-23 10:51:53,787] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7054
[2019-03-23 10:51:53,792] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 70.5, 1.0, 2.0, 0.3118846206712691, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 341343.4787616638, 341343.4787616635, 112944.7074465485], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2158200.0000, 
sim time next is 2158800.0000, 
raw observation next is [19.33333333333334, 76.33333333333333, 1.0, 2.0, 0.3165190654116865, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 347341.5382224728, 347341.5382224731, 113610.7446882643], 
processed observation next is [0.0, 1.0, 0.5151515151515155, 0.7633333333333333, 1.0, 1.0, 0.1456488317646081, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12864501415647142, 0.12864501415647153, 0.2770993772884495], 
reward next is 0.7229, 
noisyNet noise sample is [array([-0.74172956], dtype=float32), 0.47602838]. 
=============================================
[2019-03-23 10:52:00,200] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.3032255e-32 1.0000000e+00 0.0000000e+00 9.4217140e-34 0.0000000e+00], sum to 1.0000
[2019-03-23 10:52:00,207] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8174
[2019-03-23 10:52:00,211] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.33333333333333, 78.66666666666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 206301.6512992327, 206301.651299233, 68081.35380338714], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2266800.0000, 
sim time next is 2267400.0000, 
raw observation next is [13.16666666666667, 77.83333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 204563.6170404383, 204563.6170404383, 67461.03502369658], 
processed observation next is [1.0, 0.21739130434782608, 0.23484848484848497, 0.7783333333333334, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.07576430260756974, 0.07576430260756974, 0.16453910981389408], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.06242724], dtype=float32), 0.8168036]. 
=============================================
[2019-03-23 10:52:03,986] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.8138568e-22 1.0000000e+00 1.9971569e-34 3.9889291e-21 8.5731095e-33], sum to 1.0000
[2019-03-23 10:52:03,999] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6751
[2019-03-23 10:52:04,003] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 49.0, 1.0, 2.0, 0.4570293561638016, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 496353.4045015313, 496353.4045015316, 103112.0627637181], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2371800.0000, 
sim time next is 2372400.0000, 
raw observation next is [20.0, 49.0, 1.0, 2.0, 0.4667003388226684, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 506861.9803661583, 506861.9803661583, 104115.627542079], 
processed observation next is [1.0, 0.4782608695652174, 0.5454545454545454, 0.49, 1.0, 1.0, 0.3333754235283355, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18772665939487346, 0.18772665939487346, 0.2539405549806805], 
reward next is 0.7461, 
noisyNet noise sample is [array([1.4017898], dtype=float32), -0.13954583]. 
=============================================
[2019-03-23 10:52:09,359] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-23 10:52:09,360] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 10:52:09,360] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:52:09,361] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 10:52:09,362] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 10:52:09,363] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:52:09,363] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 10:52:09,365] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 10:52:09,365] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:52:09,372] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:52:09,372] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:52:09,389] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run63
[2019-03-23 10:52:09,416] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run63
[2019-03-23 10:52:09,441] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run63
[2019-03-23 10:52:09,442] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run63
[2019-03-23 10:52:09,488] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run63
[2019-03-23 10:52:37,643] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.07839761], dtype=float32), -1.192048]
[2019-03-23 10:52:37,647] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.46666666666667, 50.33333333333334, 1.0, 2.0, 0.4548142099468201, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 518120.6109540489, 518120.6109540489, 138301.3065676424]
[2019-03-23 10:52:37,648] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 10:52:37,653] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [8.3699591e-30 1.0000000e+00 0.0000000e+00 6.5854135e-30 0.0000000e+00], sampled 0.8487325360609395
[2019-03-23 10:53:19,681] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.07839761], dtype=float32), -1.192048]
[2019-03-23 10:53:19,684] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [13.0, 80.5, 1.0, 2.0, 0.4000624296489521, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 434457.2444191743, 434457.2444191743, 89243.10624725709]
[2019-03-23 10:53:19,688] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:53:19,691] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [8.8290482e-30 1.0000000e+00 0.0000000e+00 6.9782265e-30 0.0000000e+00], sampled 0.7650462501725149
[2019-03-23 10:53:34,541] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.07839761], dtype=float32), -1.192048]
[2019-03-23 10:53:34,541] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.4, 90.0, 1.0, 2.0, 0.3840960920165604, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 432432.6611060797, 432432.6611060797, 123223.1025522424]
[2019-03-23 10:53:34,543] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:53:34,546] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [8.3699591e-30 1.0000000e+00 0.0000000e+00 6.5854135e-30 0.0000000e+00], sampled 0.040684750832281846
[2019-03-23 10:53:47,779] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 10:53:47,842] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 10:53:47,867] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 10:53:47,968] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 10:53:47,994] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 10:53:49,010] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 1550000, evaluation results [1550000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 10:53:54,162] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.4422298e-27 1.0000000e+00 2.3947328e-38 8.5577416e-28 4.2867159e-37], sum to 1.0000
[2019-03-23 10:53:54,169] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4509
[2019-03-23 10:53:54,172] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 60.0, 1.0, 2.0, 0.4411395788840875, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 479180.5530418289, 479180.5530418291, 121808.9940024942], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2552400.0000, 
sim time next is 2553000.0000, 
raw observation next is [21.0, 59.33333333333333, 1.0, 2.0, 0.473383951078237, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 514124.5857006753, 514124.5857006753, 124518.7498854993], 
processed observation next is [1.0, 0.5652173913043478, 0.5909090909090909, 0.5933333333333333, 1.0, 1.0, 0.34172993884779623, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19041651322247233, 0.19041651322247233, 0.30370426801341294], 
reward next is 0.6963, 
noisyNet noise sample is [array([-2.1267226], dtype=float32), 2.7466044]. 
=============================================
[2019-03-23 10:53:54,188] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[70.92017 ]
 [70.6304  ]
 [70.56042 ]
 [70.43497 ]
 [70.177216]], R is [[70.86229706]
 [70.85657501]
 [70.84393311]
 [70.83206177]
 [70.82007599]].
[2019-03-23 10:53:59,935] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.4936333e-16 1.0000000e+00 3.4245566e-23 5.9122764e-15 1.0518843e-22], sum to 1.0000
[2019-03-23 10:53:59,944] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7286
[2019-03-23 10:53:59,952] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1330781.280251164 W.
[2019-03-23 10:53:59,959] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.83333333333333, 63.33333333333334, 1.0, 2.0, 0.6884504759374759, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9770626770929663, 6.9112, 6.9112, 77.32846344354104, 1330781.280251164, 1330781.280251164, 290160.9136699347], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2976600.0000, 
sim time next is 2977200.0000, 
raw observation next is [27.0, 62.0, 1.0, 2.0, 0.7164890311781499, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9755433765810385, 6.9112, 6.9112, 77.32846344354104, 1363854.030584186, 1363854.030584186, 292908.5520461523], 
processed observation next is [1.0, 0.4782608695652174, 0.8636363636363636, 0.62, 1.0, 1.0, 0.6456112889726873, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9650619665443408, 0.0, 0.0, 0.5084288129206541, 0.5051311224385875, 0.5051311224385875, 0.714411102551591], 
reward next is 0.2856, 
noisyNet noise sample is [array([0.960672], dtype=float32), -1.5211995]. 
=============================================
[2019-03-23 10:53:59,967] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.3493712e-30 1.0000000e+00 0.0000000e+00 2.4333051e-25 1.3160252e-38], sum to 1.0000
[2019-03-23 10:53:59,972] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7949
[2019-03-23 10:53:59,975] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 45.0, 1.0, 2.0, 0.3838084380709237, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 433356.2781687085, 433356.2781687085, 123881.9701217966], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2655000.0000, 
sim time next is 2655600.0000, 
raw observation next is [27.0, 45.0, 1.0, 2.0, 0.3838779900669521, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 433435.0368165645, 433435.0368165645, 123888.278423883], 
processed observation next is [0.0, 0.7391304347826086, 0.8636363636363636, 0.45, 1.0, 1.0, 0.2298474875836901, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16053149511724613, 0.16053149511724613, 0.30216653274117805], 
reward next is 0.6978, 
noisyNet noise sample is [array([1.1966983], dtype=float32), -0.77632594]. 
=============================================
[2019-03-23 10:54:16,370] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.1329035e-20 1.0000000e+00 1.2200538e-29 1.9308195e-21 8.8041980e-29], sum to 1.0000
[2019-03-23 10:54:16,376] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0716
[2019-03-23 10:54:16,380] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 86.0, 1.0, 2.0, 0.696267823034629, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 792957.0610489188, 792957.0610489188, 169290.2718821724], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2964600.0000, 
sim time next is 2965200.0000, 
raw observation next is [23.66666666666667, 85.0, 1.0, 2.0, 0.6772291068679657, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 771163.4835082027, 771163.4835082025, 166562.6766363011], 
processed observation next is [1.0, 0.30434782608695654, 0.7121212121212124, 0.85, 1.0, 1.0, 0.5965363835849571, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.285616105003038, 0.28561610500303797, 0.4062504308202466], 
reward next is 0.5937, 
noisyNet noise sample is [array([-0.30046648], dtype=float32), 1.8882701]. 
=============================================
[2019-03-23 10:54:18,952] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.8351841e-26 1.0000000e+00 1.5044458e-37 4.4367329e-29 3.1688181e-37], sum to 1.0000
[2019-03-23 10:54:18,961] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9424
[2019-03-23 10:54:18,965] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 88.0, 1.0, 2.0, 0.3498075616041232, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 385426.3384592746, 385426.3384592746, 116614.0113400956], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3027600.0000, 
sim time next is 3028200.0000, 
raw observation next is [18.0, 88.00000000000001, 1.0, 2.0, 0.3459725761133343, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 380894.02257896, 380894.0225789603, 116208.4217168494], 
processed observation next is [1.0, 0.043478260869565216, 0.45454545454545453, 0.8800000000000001, 1.0, 1.0, 0.18246572014166787, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14107186021442963, 0.14107186021442975, 0.2834351749191449], 
reward next is 0.7166, 
noisyNet noise sample is [array([-0.72678995], dtype=float32), 0.19730686]. 
=============================================
[2019-03-23 10:54:22,586] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.4051870e-15 1.0000000e+00 1.1475917e-21 4.9963417e-14 4.3831020e-22], sum to 1.0000
[2019-03-23 10:54:22,592] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4094
[2019-03-23 10:54:22,596] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.8, 70.5, 1.0, 2.0, 0.5415002461349344, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 613432.4225742883, 613432.4225742883, 149716.3904319377], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3087000.0000, 
sim time next is 3087600.0000, 
raw observation next is [26.86666666666667, 70.33333333333333, 1.0, 2.0, 0.5476831981918103, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 620294.0104436654, 620294.0104436654, 150561.2681589469], 
processed observation next is [1.0, 0.7391304347826086, 0.8575757575757578, 0.7033333333333333, 1.0, 1.0, 0.4346039977397629, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22973852238654274, 0.22973852238654274, 0.3672226052657242], 
reward next is 0.6328, 
noisyNet noise sample is [array([-0.7461064], dtype=float32), -0.57838124]. 
=============================================
[2019-03-23 10:54:26,770] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.8039112e-19 1.0000000e+00 4.3013305e-28 4.2225720e-16 2.3364450e-27], sum to 1.0000
[2019-03-23 10:54:26,778] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5435
[2019-03-23 10:54:26,781] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 88.0, 1.0, 2.0, 0.4372813004168821, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 497497.1288354026, 497497.1288354026, 131431.6525404064], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3192000.0000, 
sim time next is 3192600.0000, 
raw observation next is [21.0, 88.0, 1.0, 2.0, 0.4365584487149941, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 496673.1691394537, 496673.1691394537, 131357.5874344461], 
processed observation next is [1.0, 0.9565217391304348, 0.5909090909090909, 0.88, 1.0, 1.0, 0.2956980608937426, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18395302560720506, 0.18395302560720506, 0.32038435959621], 
reward next is 0.6796, 
noisyNet noise sample is [array([-1.1567539], dtype=float32), -0.8701652]. 
=============================================
[2019-03-23 10:54:29,944] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.7983861e-25 1.0000000e+00 1.4406494e-36 2.6792086e-26 5.1582024e-35], sum to 1.0000
[2019-03-23 10:54:29,954] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9370
[2019-03-23 10:54:29,959] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.5, 85.5, 1.0, 2.0, 0.3347106426395264, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 369515.2290233215, 369515.2290233218, 115755.7572529381], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3220200.0000, 
sim time next is 3220800.0000, 
raw observation next is [18.66666666666667, 84.66666666666666, 1.0, 2.0, 0.3361326417527807, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 371483.8775799058, 371483.8775799061, 116017.8437109445], 
processed observation next is [0.0, 0.2608695652173913, 0.4848484848484851, 0.8466666666666666, 1.0, 1.0, 0.17016580219097582, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13758662132589103, 0.13758662132589114, 0.28297035051449876], 
reward next is 0.7170, 
noisyNet noise sample is [array([1.5897652], dtype=float32), 0.24203297]. 
=============================================
[2019-03-23 10:54:36,949] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.3334490e-20 1.0000000e+00 1.0356359e-29 1.7923609e-16 3.6713557e-28], sum to 1.0000
[2019-03-23 10:54:36,957] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1880
[2019-03-23 10:54:36,961] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 88.0, 1.0, 2.0, 0.372689104250342, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 410498.9397689569, 410498.9397689572, 118337.9652848144], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3378000.0000, 
sim time next is 3378600.0000, 
raw observation next is [18.0, 88.0, 1.0, 2.0, 0.3375142224829999, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 371598.6419391138, 371598.6419391138, 115580.3588649808], 
processed observation next is [1.0, 0.08695652173913043, 0.45454545454545453, 0.88, 1.0, 1.0, 0.17189277810374984, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13762912664411622, 0.13762912664411622, 0.2819033143048312], 
reward next is 0.7181, 
noisyNet noise sample is [array([2.2942574], dtype=float32), 0.3453416]. 
=============================================
[2019-03-23 10:54:37,279] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.1243517e-19 1.0000000e+00 2.9627158e-28 5.5257963e-14 1.0316663e-27], sum to 1.0000
[2019-03-23 10:54:37,289] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8693
[2019-03-23 10:54:37,294] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.33333333333333, 92.0, 1.0, 2.0, 0.3342906359246721, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 366703.3510259035, 366703.3510259035, 114842.5441735299], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3382800.0000, 
sim time next is 3383400.0000, 
raw observation next is [17.16666666666667, 93.0, 1.0, 2.0, 0.3313184833963069, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 363058.3698466326, 363058.3698466326, 114486.002612819], 
processed observation next is [1.0, 0.13043478260869565, 0.4166666666666669, 0.93, 1.0, 1.0, 0.16414810424538356, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13446606290616023, 0.13446606290616023, 0.27923415271419266], 
reward next is 0.7208, 
noisyNet noise sample is [array([0.16082269], dtype=float32), 0.30671906]. 
=============================================
[2019-03-23 10:54:38,083] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-23 10:54:38,085] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 10:54:38,085] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:54:38,086] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 10:54:38,087] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:54:38,087] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 10:54:38,088] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 10:54:38,089] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:54:38,091] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:54:38,091] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 10:54:38,093] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:54:38,114] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run64
[2019-03-23 10:54:38,139] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run64
[2019-03-23 10:54:38,176] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run64
[2019-03-23 10:54:38,176] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run64
[2019-03-23 10:54:38,210] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run64
[2019-03-23 10:54:43,173] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08450887], dtype=float32), -1.1679127]
[2019-03-23 10:54:43,174] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.0, 52.5, 1.0, 2.0, 0.2882519833820639, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 312994.970206355, 312994.9702063553, 88179.47234188291]
[2019-03-23 10:54:43,175] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:54:43,177] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.6801092e-26 1.0000000e+00 3.8620440e-37 4.2319217e-25 3.1780323e-36], sampled 0.9118245577542878
[2019-03-23 10:55:12,289] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08450887], dtype=float32), -1.1679127]
[2019-03-23 10:55:12,290] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [28.33670359833333, 62.89843843, 1.0, 2.0, 0.5850058881821133, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 662038.2546690375, 662038.2546690372, 159942.2337937519]
[2019-03-23 10:55:12,292] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 10:55:12,295] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.4538414e-24 1.0000000e+00 1.0981070e-34 4.0615368e-23 8.6331951e-34], sampled 0.256771003751299
[2019-03-23 10:55:28,535] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08450887], dtype=float32), -1.1679127]
[2019-03-23 10:55:28,537] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.0, 82.16666666666667, 1.0, 2.0, 0.4849744892950893, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 553401.877793387, 553401.877793387, 139279.7304383723]
[2019-03-23 10:55:28,539] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:55:28,543] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [7.7240021e-26 1.0000000e+00 1.0146835e-36 9.7401011e-25 8.3193209e-36], sampled 0.7365247180816218
[2019-03-23 10:56:00,358] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08450887], dtype=float32), -1.1679127]
[2019-03-23 10:56:00,360] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.830843, 74.07300438000001, 1.0, 2.0, 0.33790579486957, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 370455.887465143, 370455.8874651426, 119349.2499363619]
[2019-03-23 10:56:00,361] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 10:56:00,364] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.4226951e-25 1.0000000e+00 2.2672206e-36 1.9216389e-24 1.8560587e-35], sampled 0.5116029403023918
[2019-03-23 10:56:14,679] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 10:56:14,887] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 10:56:14,911] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 10:56:15,122] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 10:56:15,255] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 10:56:16,272] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 1575000, evaluation results [1575000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 10:56:16,294] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.8926757e-22 1.0000000e+00 1.6450758e-32 2.1101677e-18 3.3189780e-31], sum to 1.0000
[2019-03-23 10:56:16,297] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4807
[2019-03-23 10:56:16,304] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.5, 86.0, 1.0, 2.0, 0.372153784934132, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 416998.2639167141, 416998.2639167138, 121198.417147961], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3396600.0000, 
sim time next is 3397200.0000, 
raw observation next is [20.0, 83.33333333333334, 1.0, 2.0, 0.3788246869586175, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 425325.5592705904, 425325.5592705904, 122169.9728503436], 
processed observation next is [1.0, 0.30434782608695654, 0.5454545454545454, 0.8333333333333335, 1.0, 1.0, 0.22353085869827183, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1575279849150335, 0.1575279849150335, 0.29797554353742345], 
reward next is 0.7020, 
noisyNet noise sample is [array([-0.33817947], dtype=float32), 0.7444251]. 
=============================================
[2019-03-23 10:56:19,862] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.6527206e-23 1.0000000e+00 9.5403415e-34 1.7678807e-24 3.4592279e-33], sum to 1.0000
[2019-03-23 10:56:19,872] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0181
[2019-03-23 10:56:19,875] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 89.0, 1.0, 2.0, 0.5200246696497826, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 592430.0349842858, 592430.0349842862, 145213.240420755], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3450000.0000, 
sim time next is 3450600.0000, 
raw observation next is [23.0, 89.0, 1.0, 2.0, 0.5180790456492395, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 590213.3560913217, 590213.3560913217, 144976.4171016198], 
processed observation next is [1.0, 0.9565217391304348, 0.6818181818181818, 0.89, 1.0, 1.0, 0.39759880706154926, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2185975392930821, 0.2185975392930821, 0.3536010173210239], 
reward next is 0.6464, 
noisyNet noise sample is [array([0.79259676], dtype=float32), -1.3784016]. 
=============================================
[2019-03-23 10:56:20,977] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.2945037e-23 1.0000000e+00 1.8387244e-33 1.2524316e-21 5.0091112e-32], sum to 1.0000
[2019-03-23 10:56:20,984] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1574
[2019-03-23 10:56:20,989] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.5508573670176358, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 628531.9048225618, 628531.904822562, 147625.385817601], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3474600.0000, 
sim time next is 3475200.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.4951277621590892, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 564913.2709088718, 564913.2709088718, 140949.5510984264], 
processed observation next is [1.0, 0.21739130434782608, 0.5909090909090909, 1.0, 1.0, 1.0, 0.3689097026988615, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20922713737365622, 0.20922713737365622, 0.3437793929229912], 
reward next is 0.6562, 
noisyNet noise sample is [array([-0.11565037], dtype=float32), -0.6168666]. 
=============================================
[2019-03-23 10:56:32,885] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.4151428e-25 1.0000000e+00 1.5095523e-35 9.2453722e-26 1.7949446e-34], sum to 1.0000
[2019-03-23 10:56:32,893] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7068
[2019-03-23 10:56:32,898] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 83.0, 1.0, 2.0, 0.5310957330748173, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 604634.8147807398, 604634.8147807402, 146906.175489544], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3711000.0000, 
sim time next is 3711600.0000, 
raw observation next is [24.0, 83.0, 1.0, 2.0, 0.5309262534271311, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 604442.5532923451, 604442.5532923451, 146884.6358287195], 
processed observation next is [1.0, 1.0, 0.7272727272727273, 0.83, 1.0, 1.0, 0.4136578167839138, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2238676123304982, 0.2238676123304982, 0.35825520933834026], 
reward next is 0.6417, 
noisyNet noise sample is [array([-0.39359978], dtype=float32), 0.6710508]. 
=============================================
[2019-03-23 10:56:33,315] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.5778131e-22 1.0000000e+00 3.0931188e-32 1.0052876e-19 1.4129507e-30], sum to 1.0000
[2019-03-23 10:56:33,321] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9977
[2019-03-23 10:56:33,327] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.5089935710144614, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 580482.6410448605, 580482.6410448605, 143142.8333144495], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3722400.0000, 
sim time next is 3723000.0000, 
raw observation next is [22.0, 94.00000000000001, 1.0, 2.0, 0.8863941770010234, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 85.22654624974355, 1011078.557698673, 1011078.557698673, 201220.1634675362], 
processed observation next is [1.0, 0.08695652173913043, 0.6363636363636364, 0.9400000000000002, 1.0, 1.0, 0.8579927212512791, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5603581114827346, 0.3744735398883974, 0.3744735398883974, 0.49078088650618584], 
reward next is 0.5092, 
noisyNet noise sample is [array([0.74721587], dtype=float32), -0.0016582756]. 
=============================================
[2019-03-23 10:56:33,350] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[59.54274 ]
 [59.442158]
 [59.479088]
 [59.447918]
 [59.404728]], R is [[54.71440506]
 [54.81813431]
 [54.92046738]
 [55.02178955]
 [55.12252808]].
[2019-03-23 10:56:42,618] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.0388940e-27 1.0000000e+00 0.0000000e+00 1.0169416e-23 1.4206629e-38], sum to 1.0000
[2019-03-23 10:56:42,625] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5779
[2019-03-23 10:56:42,630] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 77.0, 1.0, 2.0, 0.2801251828941745, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 304167.8214426277, 304167.8214426274, 101509.4334845828], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3897000.0000, 
sim time next is 3897600.0000, 
raw observation next is [18.0, 77.0, 1.0, 2.0, 0.2807665859427075, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 304864.4932518947, 304864.4932518947, 101571.9620143177], 
processed observation next is [0.0, 0.08695652173913043, 0.45454545454545453, 0.77, 1.0, 1.0, 0.10095823242838434, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11291277527847952, 0.11291277527847952, 0.24773649271784806], 
reward next is 0.7523, 
noisyNet noise sample is [array([1.1943686], dtype=float32), 0.22192937]. 
=============================================
[2019-03-23 10:56:49,262] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.0764668e-25 1.0000000e+00 8.6723337e-36 1.9091767e-21 9.8999712e-34], sum to 1.0000
[2019-03-23 10:56:49,269] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5924
[2019-03-23 10:56:49,273] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.5, 100.0, 1.0, 2.0, 0.587945768639286, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 656516.2869126415, 656516.2869126415, 141379.5127365409], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4023000.0000, 
sim time next is 4023600.0000, 
raw observation next is [17.66666666666667, 100.0, 1.0, 2.0, 0.605994461976183, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 678307.7557213188, 678307.7557213188, 144070.6317549664], 
processed observation next is [1.0, 0.5652173913043478, 0.4393939393939396, 1.0, 1.0, 1.0, 0.5074930774702288, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.25122509471159954, 0.25122509471159954, 0.3513917847682107], 
reward next is 0.6486, 
noisyNet noise sample is [array([-0.8030831], dtype=float32), -2.4032543]. 
=============================================
[2019-03-23 10:56:49,854] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.4253817e-25 1.0000000e+00 1.6495358e-34 1.9971347e-26 1.2795146e-34], sum to 1.0000
[2019-03-23 10:56:49,865] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7849
[2019-03-23 10:56:49,871] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.6022284867443664, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 677176.4869474433, 677176.4869474433, 145026.4931625944], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4026000.0000, 
sim time next is 4026600.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.6223902689845979, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 699899.3297363847, 699899.3297363847, 147402.8899060074], 
processed observation next is [1.0, 0.6086956521739131, 0.45454545454545453, 1.0, 1.0, 1.0, 0.5279878362307474, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.25922197397643876, 0.25922197397643876, 0.35951924367318877], 
reward next is 0.6405, 
noisyNet noise sample is [array([1.3412247], dtype=float32), -1.7395701]. 
=============================================
[2019-03-23 10:56:51,042] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.8605230e-26 1.0000000e+00 7.2024566e-38 8.8503391e-27 2.2677298e-37], sum to 1.0000
[2019-03-23 10:56:51,051] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4596
[2019-03-23 10:56:51,057] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 100.0, 1.0, 2.0, 0.3041365905473509, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 330248.9375797978, 330248.9375797978, 111471.034827792], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4066200.0000, 
sim time next is 4066800.0000, 
raw observation next is [16.0, 100.0, 1.0, 2.0, 0.3042378045027081, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 330358.87882311, 330358.87882311, 111477.8571030486], 
processed observation next is [1.0, 0.043478260869565216, 0.36363636363636365, 1.0, 1.0, 1.0, 0.1302972556283851, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12235514030485556, 0.12235514030485556, 0.27189721244646003], 
reward next is 0.7281, 
noisyNet noise sample is [array([0.2729749], dtype=float32), 1.4346356]. 
=============================================
[2019-03-23 10:56:54,320] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.7500325e-24 1.0000000e+00 2.0283290e-34 6.1357536e-22 7.3352633e-33], sum to 1.0000
[2019-03-23 10:56:54,330] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3985
[2019-03-23 10:56:54,337] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.08333333333334, 93.16666666666666, 1.0, 2.0, 0.3902104644810888, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 439638.2109324537, 439638.2109324534, 123930.4698498018], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4128600.0000, 
sim time next is 4129200.0000, 
raw observation next is [19.1, 93.0, 1.0, 2.0, 0.3897738605885093, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 439131.7304985977, 439131.7304985974, 123883.9969806892], 
processed observation next is [1.0, 0.8260869565217391, 0.5045454545454546, 0.93, 1.0, 1.0, 0.23721732573563664, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1626413816661473, 0.16264138166614717, 0.30215609019680295], 
reward next is 0.6978, 
noisyNet noise sample is [array([-0.60158235], dtype=float32), 0.606578]. 
=============================================
[2019-03-23 10:56:58,606] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.6858476e-25 1.0000000e+00 2.2455302e-36 1.1942018e-24 2.1223486e-34], sum to 1.0000
[2019-03-23 10:56:58,624] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6589
[2019-03-23 10:56:58,626] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 88.0, 1.0, 2.0, 0.5951691012917197, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 666374.0683478488, 666374.0683478492, 142927.2246491715], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4181400.0000, 
sim time next is 4182000.0000, 
raw observation next is [19.0, 88.0, 1.0, 2.0, 0.5974141346617368, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 668910.0743967537, 668910.0743967533, 143189.2197222469], 
processed observation next is [1.0, 0.391304347826087, 0.5, 0.88, 1.0, 1.0, 0.4967676683271709, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.24774447199879765, 0.24774447199879754, 0.3492419993225534], 
reward next is 0.6508, 
noisyNet noise sample is [array([-2.3597667], dtype=float32), 1.2985675]. 
=============================================
[2019-03-23 10:56:58,640] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[67.942604]
 [67.93769 ]
 [67.837746]
 [67.67059 ]
 [67.50938 ]], R is [[67.91275787]
 [67.88502502]
 [67.86040497]
 [67.83397675]
 [67.79990387]].
[2019-03-23 10:57:05,549] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 10:57:05,551] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 10:57:05,551] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 10:57:05,552] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 10:57:05,552] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:57:05,553] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 10:57:05,553] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:57:05,554] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 10:57:05,554] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:57:05,556] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:57:05,554] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:57:05,575] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run65
[2019-03-23 10:57:05,599] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run65
[2019-03-23 10:57:05,623] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run65
[2019-03-23 10:57:05,624] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run65
[2019-03-23 10:57:05,647] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run65
[2019-03-23 10:57:17,005] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.07806982], dtype=float32), -1.1591263]
[2019-03-23 10:57:17,007] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [15.65104187, 87.87066387, 1.0, 2.0, 0.2609336989247528, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 283307.3586220696, 283307.3586220693, 91839.7100963357]
[2019-03-23 10:57:17,008] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 10:57:17,010] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.5115422e-25 1.0000000e+00 4.2434887e-36 6.3820632e-25 3.5060405e-35], sampled 0.6557857673420352
[2019-03-23 10:57:25,606] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.07806982], dtype=float32), -1.1591263]
[2019-03-23 10:57:25,607] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [15.22398739666667, 46.32144204666667, 1.0, 2.0, 0.2336996262432552, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 253731.8695295836, 253731.8695295833, 75346.91847906573]
[2019-03-23 10:57:25,609] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 10:57:25,614] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.5115422e-25 1.0000000e+00 4.2434887e-36 6.3820632e-25 3.5060405e-35], sampled 0.3151716254257271
[2019-03-23 10:57:26,720] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.07806982], dtype=float32), -1.1591263]
[2019-03-23 10:57:26,721] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [17.76552329, 62.61893808, 1.0, 2.0, 0.2394848063665762, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 260014.3017716125, 260014.3017716122, 84090.48323102482]
[2019-03-23 10:57:26,722] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 10:57:26,724] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.5115422e-25 1.0000000e+00 4.2434887e-36 6.3820632e-25 3.5060405e-35], sampled 0.5337749803972909
[2019-03-23 10:57:46,036] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.07806982], dtype=float32), -1.1591263]
[2019-03-23 10:57:46,038] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [26.33333333333334, 71.33333333333333, 1.0, 2.0, 0.546750254850459, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 620733.1625800604, 620733.1625800604, 149849.1179356952]
[2019-03-23 10:57:46,040] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:57:46,043] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.5046501e-25 1.0000000e+00 4.2159301e-36 6.3535942e-25 3.4838826e-35], sampled 0.8423446392035315
[2019-03-23 10:58:09,952] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.07806982], dtype=float32), -1.1591263]
[2019-03-23 10:58:09,953] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [26.1, 54.0, 1.0, 2.0, 0.4248942851650592, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 482805.9944416936, 482805.9944416936, 129669.0671666594]
[2019-03-23 10:58:09,955] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:58:09,957] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.5115422e-25 1.0000000e+00 4.2434887e-36 6.3820632e-25 3.5060405e-35], sampled 0.22374535384960936
[2019-03-23 10:58:13,254] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.07806982], dtype=float32), -1.1591263]
[2019-03-23 10:58:13,256] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.4, 61.0, 1.0, 2.0, 0.2972417592152737, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 322739.2240386494, 322739.2240386494, 110288.5914820866]
[2019-03-23 10:58:13,257] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 10:58:13,258] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.5115422e-25 1.0000000e+00 4.2434887e-36 6.3820632e-25 3.5060405e-35], sampled 0.1386527580259208
[2019-03-23 10:58:43,617] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 10:58:43,723] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 10:58:43,734] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 10:58:43,960] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 10:58:44,134] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 10:58:45,151] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 1600000, evaluation results [1600000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 10:58:50,873] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.2289328e-26 1.0000000e+00 1.1443649e-37 4.3497657e-25 4.1940143e-38], sum to 1.0000
[2019-03-23 10:58:50,881] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6020
[2019-03-23 10:58:50,884] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.16666666666667, 73.33333333333334, 1.0, 2.0, 0.5158830380192964, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 587876.4390476248, 587876.439047625, 144550.7951666983], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4456200.0000, 
sim time next is 4456800.0000, 
raw observation next is [25.0, 74.0, 1.0, 2.0, 0.5131656526916156, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 584887.0182421989, 584887.0182421989, 144108.7675804619], 
processed observation next is [0.0, 0.6086956521739131, 0.7727272727272727, 0.74, 1.0, 1.0, 0.3914570658645195, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21662482157118476, 0.21662482157118476, 0.35148479897673635], 
reward next is 0.6485, 
noisyNet noise sample is [array([0.55873007], dtype=float32), -0.85599065]. 
=============================================
[2019-03-23 10:58:54,636] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.1703893e-24 1.0000000e+00 2.0810901e-36 5.6796415e-24 7.4110521e-36], sum to 1.0000
[2019-03-23 10:58:54,645] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2262
[2019-03-23 10:58:54,650] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 99.00000000000001, 1.0, 2.0, 0.4889971306153135, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 557963.3424190213, 557963.342419021, 140036.9147782669], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4828200.0000, 
sim time next is 4828800.0000, 
raw observation next is [21.0, 98.0, 1.0, 2.0, 0.4842551527551972, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 552578.4160205754, 552578.4160205754, 139249.9826603861], 
processed observation next is [1.0, 0.9130434782608695, 0.5909090909090909, 0.98, 1.0, 1.0, 0.35531894094399646, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20465867260021312, 0.20465867260021312, 0.3396341040497222], 
reward next is 0.6604, 
noisyNet noise sample is [array([1.70537], dtype=float32), -0.4424526]. 
=============================================
[2019-03-23 10:58:56,801] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.4717509e-28 1.0000000e+00 0.0000000e+00 7.7221891e-30 0.0000000e+00], sum to 1.0000
[2019-03-23 10:58:56,814] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4215
[2019-03-23 10:58:56,822] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333333, 62.0, 1.0, 2.0, 0.385802221056345, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 434612.0813089209, 434612.0813089206, 123508.5103774434], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4558800.0000, 
sim time next is 4559400.0000, 
raw observation next is [23.0, 62.5, 1.0, 2.0, 0.3784073204891241, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 425262.2748797135, 425262.2748797138, 122333.7147159495], 
processed observation next is [0.0, 0.782608695652174, 0.6818181818181818, 0.625, 1.0, 1.0, 0.22300915061140514, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15750454625174573, 0.15750454625174584, 0.29837491394134025], 
reward next is 0.7016, 
noisyNet noise sample is [array([-0.11153769], dtype=float32), 0.06919754]. 
=============================================
[2019-03-23 10:58:57,408] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.4789772e-28 1.0000000e+00 0.0000000e+00 1.7575639e-26 0.0000000e+00], sum to 1.0000
[2019-03-23 10:58:57,416] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6590
[2019-03-23 10:58:57,422] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 71.0, 1.0, 2.0, 0.3752348331263226, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 422499.8238812301, 422499.8238812301, 122475.5238697041], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4545000.0000, 
sim time next is 4545600.0000, 
raw observation next is [22.33333333333333, 70.33333333333334, 1.0, 2.0, 0.3806277383491374, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 429504.1920744546, 429504.1920744549, 123451.6922389061], 
processed observation next is [0.0, 0.6086956521739131, 0.6515151515151513, 0.7033333333333335, 1.0, 1.0, 0.2257846729364217, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15907562669424244, 0.15907562669424255, 0.30110168838757584], 
reward next is 0.6989, 
noisyNet noise sample is [array([-0.18370779], dtype=float32), 0.014343071]. 
=============================================
[2019-03-23 10:59:04,026] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.9127283e-30 1.0000000e+00 0.0000000e+00 2.4637362e-32 0.0000000e+00], sum to 1.0000
[2019-03-23 10:59:04,033] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3729
[2019-03-23 10:59:04,038] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 82.0, 1.0, 2.0, 0.2431446729198389, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 264002.4425163615, 264002.4425163612, 83321.43355007574], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4672200.0000, 
sim time next is 4672800.0000, 
raw observation next is [16.0, 82.0, 1.0, 2.0, 0.2424278788349148, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 263223.9488120923, 263223.9488120926, 83240.54836591713], 
processed observation next is [1.0, 0.08695652173913043, 0.36363636363636365, 0.82, 1.0, 1.0, 0.05303484854364347, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09749035141188604, 0.09749035141188615, 0.2030257277217491], 
reward next is 0.7970, 
noisyNet noise sample is [array([1.0940176], dtype=float32), 0.5226067]. 
=============================================
[2019-03-23 10:59:10,373] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.1846600e-18 1.0000000e+00 5.6177503e-26 2.8422706e-19 1.1420692e-25], sum to 1.0000
[2019-03-23 10:59:10,379] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8012
[2019-03-23 10:59:10,382] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 96.0, 1.0, 2.0, 0.9456155496261079, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1077906.874363229, 1077906.874363229, 210406.8555732812], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4807200.0000, 
sim time next is 4807800.0000, 
raw observation next is [22.0, 97.0, 1.0, 2.0, 0.9971694341816058, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.096505890804076, 6.9112, 77.32806427565201, 1196391.113380386, 1136207.860874417, 220716.5688476951], 
processed observation next is [1.0, 0.6521739130434783, 0.6363636363636364, 0.97, 1.0, 1.0, 0.9964617927270072, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.018530589080407632, 0.0, 0.5084261884218999, 0.44310781977051333, 0.4208177262497841, 0.5383330947504759], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.32593492], dtype=float32), -0.44071558]. 
=============================================
[2019-03-23 10:59:10,993] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.4290637e-26 1.0000000e+00 1.4173777e-37 3.6564446e-27 6.5456431e-37], sum to 1.0000
[2019-03-23 10:59:11,001] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9341
[2019-03-23 10:59:11,006] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.05, 99.5, 1.0, 2.0, 0.5001978120177298, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 570710.0683374276, 570710.0683374276, 141504.7373858851], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4818600.0000, 
sim time next is 4819200.0000, 
raw observation next is [21.06666666666667, 99.33333333333334, 1.0, 2.0, 0.4986461910258889, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 568940.6071348606, 568940.6071348602, 141317.9172488555], 
processed observation next is [1.0, 0.782608695652174, 0.5939393939393941, 0.9933333333333334, 1.0, 1.0, 0.3733077387823611, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2107187433832817, 0.21071874338328156, 0.344677846948428], 
reward next is 0.6553, 
noisyNet noise sample is [array([-1.1730392], dtype=float32), -0.87985337]. 
=============================================
[2019-03-23 10:59:11,265] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.08442478e-22 1.00000000e+00 1.18325167e-30 1.15118965e-24
 9.42884296e-32], sum to 1.0000
[2019-03-23 10:59:11,268] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2140
[2019-03-23 10:59:11,271] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1126820.78363766 W.
[2019-03-23 10:59:11,277] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.4962874035651426, 1.0, 2.0, 0.4962874035651426, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1126820.78363766, 1126820.78363766, 231341.9753821977], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4803600.0000, 
sim time next is 4804200.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.497517026278002, 1.0, 2.0, 0.497517026278002, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1129730.668247305, 1129730.668247306, 231588.6501547038], 
processed observation next is [1.0, 0.6086956521739131, 0.6363636363636364, 0.94, 1.0, 1.0, 0.3718962828475024, 1.0, 1.0, 0.3718962828475024, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.4184187660175204, 0.41841876601752076, 0.5648503662309848], 
reward next is 0.4351, 
noisyNet noise sample is [array([1.097922], dtype=float32), 0.4561567]. 
=============================================
[2019-03-23 10:59:16,754] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.0539248e-24 1.0000000e+00 5.2052639e-36 3.9761251e-27 1.0362571e-35], sum to 1.0000
[2019-03-23 10:59:16,760] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5912
[2019-03-23 10:59:16,766] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 84.66666666666667, 1.0, 2.0, 0.4141207810991879, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 469909.2743149849, 469909.2743149849, 128114.3472692745], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4911600.0000, 
sim time next is 4912200.0000, 
raw observation next is [21.0, 85.5, 1.0, 2.0, 0.4172123549245484, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 473741.8688691885, 473741.8688691888, 128654.0691621063], 
processed observation next is [1.0, 0.8695652173913043, 0.5909090909090909, 0.855, 1.0, 1.0, 0.2715154436556855, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17545995143303278, 0.1754599514330329, 0.31379041259050316], 
reward next is 0.6862, 
noisyNet noise sample is [array([0.8909816], dtype=float32), 0.877972]. 
=============================================
[2019-03-23 10:59:19,320] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.4946391e-25 1.0000000e+00 7.3730408e-36 4.2871484e-26 1.4068212e-35], sum to 1.0000
[2019-03-23 10:59:19,327] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2774
[2019-03-23 10:59:19,332] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 94.0, 1.0, 2.0, 0.5188150923229332, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 569011.1481951758, 569011.1481951762, 130316.4644521534], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4956600.0000, 
sim time next is 4957200.0000, 
raw observation next is [17.0, 94.0, 1.0, 2.0, 0.5136556265279839, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 563418.3496465817, 563418.3496465817, 129850.1772988182], 
processed observation next is [1.0, 0.391304347826087, 0.4090909090909091, 0.94, 1.0, 1.0, 0.39206953315997983, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20867346283206728, 0.20867346283206728, 0.3167077495093127], 
reward next is 0.6833, 
noisyNet noise sample is [array([1.0488551], dtype=float32), -0.111283354]. 
=============================================
[2019-03-23 10:59:26,739] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.8683391e-22 1.0000000e+00 2.9694957e-34 1.0640081e-21 4.8072763e-35], sum to 1.0000
[2019-03-23 10:59:26,749] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0626
[2019-03-23 10:59:26,759] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 83.0, 1.0, 2.0, 0.4343683393135458, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 494853.9342894226, 494853.9342894226, 131864.178794653], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5094000.0000, 
sim time next is 5094600.0000, 
raw observation next is [22.0, 82.16666666666667, 1.0, 2.0, 0.433716950666614, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 493991.2807430426, 493991.2807430424, 131651.2873749594], 
processed observation next is [0.0, 1.0, 0.6363636363636364, 0.8216666666666668, 1.0, 1.0, 0.29214618833326744, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1829597336085343, 0.18295973360853424, 0.3211007009145351], 
reward next is 0.6789, 
noisyNet noise sample is [array([-0.11138896], dtype=float32), 1.7557155]. 
=============================================
[2019-03-23 10:59:29,575] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.8058355e-28 1.0000000e+00 2.1645010e-38 1.1515756e-25 0.0000000e+00], sum to 1.0000
[2019-03-23 10:59:29,582] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3658
[2019-03-23 10:59:29,588] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 83.0, 1.0, 2.0, 0.4743951721500702, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 541316.8193459377, 541316.8193459377, 138205.8681469843], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5173200.0000, 
sim time next is 5173800.0000, 
raw observation next is [23.0, 83.0, 1.0, 2.0, 0.4760753960244742, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 543229.2470699222, 543229.2470699224, 138452.1334101614], 
processed observation next is [0.0, 0.9130434782608695, 0.6818181818181818, 0.83, 1.0, 1.0, 0.3450942450305927, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2011960174333045, 0.2011960174333046, 0.3376881302686863], 
reward next is 0.6623, 
noisyNet noise sample is [array([0.19095638], dtype=float32), -0.5471243]. 
=============================================
[2019-03-23 10:59:30,673] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.2097086e-25 1.0000000e+00 2.3790664e-35 1.2197465e-22 9.5847301e-35], sum to 1.0000
[2019-03-23 10:59:30,680] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2414
[2019-03-23 10:59:30,684] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333334, 86.33333333333334, 1.0, 2.0, 0.4320411805894002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 491844.110288247, 491844.1102882473, 131216.5677402594], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5193600.0000, 
sim time next is 5194200.0000, 
raw observation next is [21.16666666666666, 87.16666666666667, 1.0, 2.0, 0.4239796737432574, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 482522.8208262391, 482522.8208262391, 130263.849798952], 
processed observation next is [1.0, 0.08695652173913043, 0.5984848484848482, 0.8716666666666667, 1.0, 1.0, 0.2799745921790717, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17871215586157005, 0.17871215586157005, 0.3177167068267122], 
reward next is 0.6823, 
noisyNet noise sample is [array([0.7722804], dtype=float32), 1.201179]. 
=============================================
[2019-03-23 10:59:34,180] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.5821745e-32 1.0000000e+00 0.0000000e+00 7.6592895e-30 0.0000000e+00], sum to 1.0000
[2019-03-23 10:59:34,190] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2490
[2019-03-23 10:59:34,198] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.7, 73.0, 1.0, 2.0, 0.3215035109733858, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 352720.414511594, 352720.414511594, 113932.7928182613], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5277600.0000, 
sim time next is 5278200.0000, 
raw observation next is [19.63333333333333, 73.83333333333334, 1.0, 2.0, 0.3988471332096779, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 437909.4764870738, 437909.4764870735, 119947.011794926], 
processed observation next is [1.0, 0.08695652173913043, 0.5287878787878786, 0.7383333333333334, 1.0, 1.0, 0.24855891651209736, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16218869499521252, 0.1621886949952124, 0.29255368730469755], 
reward next is 0.7074, 
noisyNet noise sample is [array([-0.5379458], dtype=float32), -0.17688066]. 
=============================================
[2019-03-23 10:59:34,253] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.3459671e-24 1.0000000e+00 1.8193896e-34 8.6601791e-26 1.3626554e-33], sum to 1.0000
[2019-03-23 10:59:34,262] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9273
[2019-03-23 10:59:34,270] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1273874.343407129 W.
[2019-03-23 10:59:34,273] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.28333333333334, 66.16666666666667, 1.0, 2.0, 0.562148432654303, 1.0, 2.0, 0.562148432654303, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1273874.343407129, 1273874.343407129, 248999.6625851212], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5569800.0000, 
sim time next is 5570400.0000, 
raw observation next is [26.46666666666667, 65.33333333333334, 1.0, 2.0, 0.3795473721946461, 1.0, 2.0, 0.3795473721946461, 1.0, 1.0, 0.7681557655777232, 6.911199999999999, 6.9112, 77.3421103, 1287538.593053133, 1287538.593053133, 294887.1634910118], 
processed observation next is [1.0, 0.4782608695652174, 0.8393939393939395, 0.6533333333333334, 1.0, 1.0, 0.22443421524330764, 1.0, 1.0, 0.22443421524330764, 1.0, 0.5, 0.668793950825319, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.47686614557523443, 0.47686614557523443, 0.7192369841244189], 
reward next is 0.2808, 
noisyNet noise sample is [array([-0.36980957], dtype=float32), -0.83950645]. 
=============================================
[2019-03-23 10:59:34,524] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-23 10:59:34,525] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 10:59:34,525] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:59:34,532] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 10:59:34,534] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:59:34,535] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 10:59:34,536] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 10:59:34,537] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:59:34,537] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 10:59:34,537] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:59:34,538] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:59:34,558] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run66
[2019-03-23 10:59:34,585] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run66
[2019-03-23 10:59:34,586] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run66
[2019-03-23 10:59:34,609] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run66
[2019-03-23 10:59:34,664] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run66
[2019-03-23 10:59:46,438] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.07251097], dtype=float32), -1.1369636]
[2019-03-23 10:59:46,439] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [28.2, 48.0, 1.0, 2.0, 0.8698541882023013, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 992270.6457546564, 992270.645754656, 195541.8828863453]
[2019-03-23 10:59:46,439] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 10:59:46,442] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.7500252e-27 1.0000000e+00 3.9383491e-38 4.9412186e-27 8.8268564e-38], sampled 0.0943544484029274
[2019-03-23 10:59:59,457] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.07251097], dtype=float32), -1.1369636]
[2019-03-23 10:59:59,460] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [15.45, 86.0, 1.0, 2.0, 0.2374285114575234, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 257794.2846014241, 257794.2846014239, 82064.99681648886]
[2019-03-23 10:59:59,461] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:59:59,464] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [5.5472603e-27 1.0000000e+00 3.8113003e-38 4.6752011e-27 8.4957671e-38], sampled 0.48056967960388286
[2019-03-23 11:00:57,347] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.07251097], dtype=float32), -1.1369636]
[2019-03-23 11:00:57,348] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.97919555, 61.71648701333334, 1.0, 2.0, 0.3461496782451199, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 382770.2097447076, 382770.2097447072, 121180.7939070899]
[2019-03-23 11:00:57,350] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 11:00:57,353] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [5.5472603e-27 1.0000000e+00 3.8113003e-38 4.6752011e-27 8.4957671e-38], sampled 0.17546667141284322
[2019-03-23 11:01:03,749] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.07251097], dtype=float32), -1.1369636]
[2019-03-23 11:01:03,752] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [24.26049227, 42.88339266333334, 1.0, 2.0, 0.3285862777916608, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 356782.5847421989, 356782.5847421989, 117459.262702426]
[2019-03-23 11:01:03,753] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 11:01:03,755] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [5.5472603e-27 1.0000000e+00 3.8113003e-38 4.6752011e-27 8.4957671e-38], sampled 0.8644726289353255
[2019-03-23 11:01:12,132] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 11:01:12,374] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 11:01:12,579] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 11:01:12,636] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 11:01:12,867] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 11:01:13,887] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 1625000, evaluation results [1625000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 11:01:15,418] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.9399319e-28 1.0000000e+00 0.0000000e+00 1.3237212e-34 0.0000000e+00], sum to 1.0000
[2019-03-23 11:01:15,425] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1573
[2019-03-23 11:01:15,436] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.1, 87.0, 1.0, 2.0, 0.3471507389384652, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 387649.6530961351, 387649.6530961351, 118514.4367430459], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5290200.0000, 
sim time next is 5290800.0000, 
raw observation next is [19.2, 87.0, 1.0, 2.0, 0.3494575209111725, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 390729.6396339812, 390729.6396339812, 118927.6540808951], 
processed observation next is [1.0, 0.21739130434782608, 0.509090909090909, 0.87, 1.0, 1.0, 0.1868219011389656, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14471468134591897, 0.14471468134591897, 0.2900674489777929], 
reward next is 0.7099, 
noisyNet noise sample is [array([-1.1231518], dtype=float32), 0.14866397]. 
=============================================
[2019-03-23 11:01:24,063] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.2842300e-29 1.0000000e+00 0.0000000e+00 1.2837873e-27 0.0000000e+00], sum to 1.0000
[2019-03-23 11:01:24,072] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5817
[2019-03-23 11:01:24,087] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.38333333333333, 95.0, 1.0, 2.0, 0.3324295737164704, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 366804.1771581601, 366804.1771581604, 115510.4856929733], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5469000.0000, 
sim time next is 5469600.0000, 
raw observation next is [17.56666666666667, 94.0, 1.0, 2.0, 0.3408441789054418, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 376582.669593591, 376582.669593591, 116332.0987962633], 
processed observation next is [1.0, 0.30434782608695654, 0.434848484848485, 0.94, 1.0, 1.0, 0.1760552236318022, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13947506281244113, 0.13947506281244113, 0.2837368263323495], 
reward next is 0.7163, 
noisyNet noise sample is [array([1.7418015], dtype=float32), 0.7448172]. 
=============================================
[2019-03-23 11:01:24,998] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.6669203e-25 1.0000000e+00 4.8277068e-37 8.5433187e-22 5.5248493e-36], sum to 1.0000
[2019-03-23 11:01:25,010] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2352
[2019-03-23 11:01:25,016] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.1, 64.0, 1.0, 2.0, 0.2041146971698404, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 221614.6893727048, 221614.6893727045, 71920.76489005936], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5785200.0000, 
sim time next is 5785800.0000, 
raw observation next is [15.85, 63.5, 1.0, 2.0, 0.2019996743228592, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 219317.8150695971, 219317.8150695968, 71160.8036285584], 
processed observation next is [0.0, 1.0, 0.3568181818181818, 0.635, 1.0, 1.0, 0.0024995929035739883, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08122882039614707, 0.08122882039614697, 0.17356293567941072], 
reward next is 0.8264, 
noisyNet noise sample is [array([0.91105515], dtype=float32), -1.8528548]. 
=============================================
[2019-03-23 11:01:33,424] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.7297998e-27 1.0000000e+00 0.0000000e+00 1.8621350e-29 2.6083579e-38], sum to 1.0000
[2019-03-23 11:01:33,429] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7148
[2019-03-23 11:01:33,434] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.61666666666667, 97.5, 1.0, 2.0, 0.3552354329223684, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 395406.4689061129, 395406.4689061129, 118611.7071059617], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5638200.0000, 
sim time next is 5638800.0000, 
raw observation next is [17.53333333333333, 98.0, 1.0, 2.0, 0.3536283835388647, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 393421.1389755509, 393421.1389755509, 118400.6471934941], 
processed observation next is [0.0, 0.2608695652173913, 0.43333333333333324, 0.98, 1.0, 1.0, 0.19203547942358087, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14571153295390774, 0.14571153295390774, 0.28878206632559533], 
reward next is 0.7112, 
noisyNet noise sample is [array([-1.7590157], dtype=float32), 0.043779813]. 
=============================================
[2019-03-23 11:01:37,899] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.2712684e-24 1.0000000e+00 4.1157910e-34 5.6914806e-25 2.4414294e-34], sum to 1.0000
[2019-03-23 11:01:37,905] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7743
[2019-03-23 11:01:37,911] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [11.46666666666667, 84.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 154874.2432830594, 154874.2432830592, 58486.96171161805], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5728200.0000, 
sim time next is 5728800.0000, 
raw observation next is [11.83333333333333, 82.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 159234.0501139188, 159234.050113919, 59058.72735495125], 
processed observation next is [0.0, 0.30434782608695654, 0.17424242424242412, 0.82, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.05897557411626623, 0.05897557411626629, 0.14404567647549085], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.38001797], dtype=float32), 0.24326064]. 
=============================================
[2019-03-23 11:01:44,180] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0784083e-28 1.0000000e+00 0.0000000e+00 3.2938313e-29 0.0000000e+00], sum to 1.0000
[2019-03-23 11:01:44,191] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1297
[2019-03-23 11:01:44,200] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 40.33333333333334, 1.0, 2.0, 0.4405308018469349, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 487683.035880072, 487683.0358800723, 124846.641053865], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5850600.0000, 
sim time next is 5851200.0000, 
raw observation next is [25.9, 40.66666666666667, 1.0, 2.0, 0.3432932622945538, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 379379.0878351167, 379379.0878351167, 116552.9933833359], 
processed observation next is [1.0, 0.7391304347826086, 0.8136363636363636, 0.40666666666666673, 1.0, 1.0, 0.17911657786819224, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14051077327226544, 0.14051077327226544, 0.28427559361789245], 
reward next is 0.7157, 
noisyNet noise sample is [array([0.2664144], dtype=float32), 0.39721066]. 
=============================================
[2019-03-23 11:01:45,926] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.6453066e-28 1.0000000e+00 0.0000000e+00 8.3578164e-27 5.3608713e-38], sum to 1.0000
[2019-03-23 11:01:45,938] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7185
[2019-03-23 11:01:45,941] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.76666666666667, 80.66666666666667, 1.0, 2.0, 0.3196732728965788, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 351044.4880297043, 351044.4880297046, 113925.3933724854], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5876400.0000, 
sim time next is 5877000.0000, 
raw observation next is [18.65, 81.5, 1.0, 2.0, 0.3190425106833292, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 350277.7482548487, 350277.748254849, 113852.5229712901], 
processed observation next is [1.0, 0.0, 0.484090909090909, 0.815, 1.0, 1.0, 0.14880313835416145, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12973249935364767, 0.12973249935364778, 0.27768908041778073], 
reward next is 0.7223, 
noisyNet noise sample is [array([-1.9760491], dtype=float32), 1.9808255]. 
=============================================
[2019-03-23 11:01:45,956] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[68.98963 ]
 [69.00688 ]
 [69.31674 ]
 [69.706505]
 [69.709465]], R is [[69.02628326]
 [69.05815125]
 [69.08951569]
 [69.12030792]
 [69.1503067 ]].
[2019-03-23 11:01:57,901] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.7312521e-27 1.0000000e+00 1.5104313e-38 3.8608350e-30 5.2578243e-38], sum to 1.0000
[2019-03-23 11:01:57,906] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2716
[2019-03-23 11:01:57,916] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 68.0, 1.0, 2.0, 0.55978151374649, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 638803.5119719822, 638803.5119719822, 147773.3408642894], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6408600.0000, 
sim time next is 6409200.0000, 
raw observation next is [25.0, 68.0, 1.0, 2.0, 0.5473493366510973, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 624607.1111179701, 624607.1111179701, 146252.0354197455], 
processed observation next is [1.0, 0.17391304347826086, 0.7727272727272727, 0.68, 1.0, 1.0, 0.4341866708138716, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23133596708072965, 0.23133596708072965, 0.35671228151157436], 
reward next is 0.6433, 
noisyNet noise sample is [array([-0.37856615], dtype=float32), -0.5409594]. 
=============================================
[2019-03-23 11:01:58,407] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.8197194e-28 1.0000000e+00 0.0000000e+00 4.6460768e-28 0.0000000e+00], sum to 1.0000
[2019-03-23 11:01:58,414] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0210
[2019-03-23 11:01:58,421] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.8, 53.0, 1.0, 2.0, 0.2974457237442274, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 322981.1983372034, 322981.1983372031, 106915.6111463076], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6115200.0000, 
sim time next is 6115800.0000, 
raw observation next is [21.7, 53.0, 1.0, 2.0, 0.295298957558185, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 320649.3655085969, 320649.3655085969, 104978.7847091586], 
processed observation next is [1.0, 0.782608695652174, 0.6227272727272727, 0.53, 1.0, 1.0, 0.11912369694773127, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1187590242624433, 0.1187590242624433, 0.25604581636380147], 
reward next is 0.7440, 
noisyNet noise sample is [array([0.5474818], dtype=float32), 1.756446]. 
=============================================
[2019-03-23 11:02:03,209] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-23 11:02:03,210] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 11:02:03,211] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 11:02:03,212] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:02:03,214] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 11:02:03,215] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 11:02:03,218] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:02:03,213] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:02:03,216] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 11:02:03,223] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:02:03,224] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:02:03,244] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run67
[2019-03-23 11:02:03,269] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run67
[2019-03-23 11:02:03,296] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run67
[2019-03-23 11:02:03,320] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run67
[2019-03-23 11:02:03,321] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run67
[2019-03-23 11:02:13,962] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.09898321], dtype=float32), -1.1358505]
[2019-03-23 11:02:13,962] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.36842729, 83.49719384, 1.0, 2.0, 0.4742343794202935, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 540936.1808588455, 540936.1808588455, 141525.1474066142]
[2019-03-23 11:02:13,963] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 11:02:13,967] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.9504706e-26 1.0000000e+00 1.8083367e-37 8.7811975e-27 2.0177697e-36], sampled 0.08947574966135197
[2019-03-23 11:02:26,213] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.09898321], dtype=float32), -1.1358505]
[2019-03-23 11:02:26,217] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.98333333333333, 89.5, 1.0, 2.0, 0.3675141177452613, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 95.55338769695034, 411552.1057390423, 411552.1057390416, 125014.6333470125]
[2019-03-23 11:02:26,217] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 11:02:26,222] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.8872947e-26 1.0000000e+00 1.1459287e-37 6.3913148e-27 1.2985328e-36], sampled 0.27313326968279994
[2019-03-23 11:02:40,957] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.09898321], dtype=float32), -1.1358505]
[2019-03-23 11:02:40,959] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [15.34987937333334, 79.82012122666667, 1.0, 2.0, 0.233186980257483, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 253175.163380753, 253175.1633807526, 82675.63750699599]
[2019-03-23 11:02:40,960] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 11:02:40,962] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.9504706e-26 1.0000000e+00 1.8083367e-37 8.7811975e-27 2.0177697e-36], sampled 0.8550834413610758
[2019-03-23 11:02:48,057] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.09898321], dtype=float32), -1.1358505]
[2019-03-23 11:02:48,059] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.1, 78.0, 1.0, 2.0, 0.3612232460247226, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 402837.7892748063, 402837.789274806, 123739.4060459128]
[2019-03-23 11:02:48,059] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 11:02:48,064] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.9504706e-26 1.0000000e+00 1.8083367e-37 8.7811975e-27 2.0177697e-36], sampled 0.02872002396421003
[2019-03-23 11:03:24,557] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.09898321], dtype=float32), -1.1358505]
[2019-03-23 11:03:24,558] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [29.91666666666666, 53.33333333333334, 1.0, 2.0, 0.8024963948205116, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695018, 909883.9261472767, 909883.926147277, 192394.7179560561]
[2019-03-23 11:03:24,560] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 11:03:24,563] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.7386549e-27 1.0000000e+00 0.0000000e+00 5.9781877e-28 4.7435298e-38], sampled 0.9112709574720596
[2019-03-23 11:03:34,757] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.09898321], dtype=float32), -1.1358505]
[2019-03-23 11:03:34,758] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.50402144833333, 91.88655815666667, 1.0, 2.0, 0.3895263389289044, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 436221.6440279537, 436221.6440279533, 126890.040200808]
[2019-03-23 11:03:34,759] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 11:03:34,761] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.4839117e-26 1.0000000e+00 1.5060651e-37 7.7314270e-27 1.6909334e-36], sampled 0.742688022717638
[2019-03-23 11:03:35,014] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.09898321], dtype=float32), -1.1358505]
[2019-03-23 11:03:35,015] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.95, 53.0, 1.0, 2.0, 0.2709240139397034, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 294156.943728456, 294156.943728456, 97754.72674546493]
[2019-03-23 11:03:35,016] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 11:03:35,017] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.9504706e-26 1.0000000e+00 1.8083367e-37 8.7811975e-27 2.0177697e-36], sampled 0.39077030678778046
[2019-03-23 11:03:40,837] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 11:03:41,252] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 11:03:41,495] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 11:03:41,530] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 11:03:41,628] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 11:03:42,647] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 1650000, evaluation results [1650000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 11:03:48,055] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.9440394e-26 1.0000000e+00 2.7001963e-37 3.1021662e-27 1.7166449e-36], sum to 1.0000
[2019-03-23 11:03:48,064] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6996
[2019-03-23 11:03:48,071] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.88333333333333, 94.16666666666666, 1.0, 2.0, 0.6660942098992656, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 743296.7745103615, 743296.7745103615, 150171.0434792291], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6443400.0000, 
sim time next is 6444000.0000, 
raw observation next is [17.7, 93.0, 1.0, 2.0, 0.6495083322504661, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 721513.1577291093, 721513.1577291093, 146925.5657910567], 
processed observation next is [1.0, 0.6086956521739131, 0.44090909090909086, 0.93, 1.0, 1.0, 0.5618854153130826, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.26722709545522566, 0.26722709545522566, 0.3583550385147724], 
reward next is 0.6416, 
noisyNet noise sample is [array([-0.4764104], dtype=float32), 0.3078679]. 
=============================================
[2019-03-23 11:03:48,096] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[65.419304]
 [65.35986 ]
 [65.37195 ]
 [65.50231 ]
 [65.62434 ]], R is [[65.4830246 ]
 [65.46192169]
 [65.43273926]
 [65.40013885]
 [65.37744904]].
[2019-03-23 11:03:50,699] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.3027350e-25 1.0000000e+00 9.6346484e-37 4.6787989e-22 4.5016047e-35], sum to 1.0000
[2019-03-23 11:03:50,711] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0068
[2019-03-23 11:03:50,714] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.7, 77.5, 1.0, 2.0, 0.5169199730029613, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 588747.3557711897, 588747.3557711897, 144963.2123147655], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6341400.0000, 
sim time next is 6342000.0000, 
raw observation next is [24.8, 77.0, 1.0, 2.0, 0.5167837339060418, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 588537.579543433, 588537.579543433, 144992.0176610946], 
processed observation next is [0.0, 0.391304347826087, 0.7636363636363637, 0.77, 1.0, 1.0, 0.39597966738255225, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2179768813123826, 0.2179768813123826, 0.3536390674660844], 
reward next is 0.6464, 
noisyNet noise sample is [array([1.154555], dtype=float32), -1.2917589]. 
=============================================
[2019-03-23 11:03:50,736] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[65.56675]
 [65.56675]
 [65.56675]
 [65.56675]
 [65.56675]], R is [[65.55744171]
 [65.5483017 ]
 [65.53991699]
 [65.53292084]
 [65.52713776]].
[2019-03-23 11:03:50,811] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.7394656e-29 1.0000000e+00 0.0000000e+00 6.4979740e-30 0.0000000e+00], sum to 1.0000
[2019-03-23 11:03:50,818] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6246
[2019-03-23 11:03:50,823] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.35, 74.0, 1.0, 2.0, 0.569171076500586, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 644146.1763249307, 644146.176324931, 153532.962682373], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6377400.0000, 
sim time next is 6378000.0000, 
raw observation next is [26.06666666666667, 75.66666666666667, 1.0, 2.0, 0.5697039184289737, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 644822.4344496748, 644822.4344496748, 153579.9039856922], 
processed observation next is [0.0, 0.8260869565217391, 0.8212121212121214, 0.7566666666666667, 1.0, 1.0, 0.4621298980362171, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23882312387024993, 0.23882312387024993, 0.37458513167241997], 
reward next is 0.6254, 
noisyNet noise sample is [array([0.23610924], dtype=float32), 0.48842353]. 
=============================================
[2019-03-23 11:03:50,836] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[65.983185]
 [65.983185]
 [65.983185]
 [65.983185]
 [65.983185]], R is [[65.94876862]
 [65.91481018]
 [65.88130188]
 [65.84825134]
 [65.81594086]].
[2019-03-23 11:03:51,838] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.6553340e-22 1.0000000e+00 3.4255175e-34 3.0209634e-22 7.9234748e-34], sum to 1.0000
[2019-03-23 11:03:51,847] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5031
[2019-03-23 11:03:51,853] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.7, 65.0, 1.0, 2.0, 0.556558022395505, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 630813.1571080239, 630813.1571080239, 151544.7132050181], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6372000.0000, 
sim time next is 6372600.0000, 
raw observation next is [27.61666666666667, 65.66666666666667, 1.0, 2.0, 0.5581300983310046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 632447.2977915723, 632447.2977915725, 151804.1144464445], 
processed observation next is [0.0, 0.782608695652174, 0.8916666666666668, 0.6566666666666667, 1.0, 1.0, 0.4476626229137557, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.23423973992280456, 0.23423973992280464, 0.37025393767425485], 
reward next is 0.6297, 
noisyNet noise sample is [array([0.8328329], dtype=float32), 0.04597391]. 
=============================================
[2019-03-23 11:03:52,183] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.2394535e-25 1.0000000e+00 7.1424044e-37 1.1694025e-25 5.0592054e-35], sum to 1.0000
[2019-03-23 11:03:52,192] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8954
[2019-03-23 11:03:52,196] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 95.0, 1.0, 2.0, 0.6741585503308106, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 753550.7672892975, 753550.7672892975, 151656.6475689324], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6694200.0000, 
sim time next is 6694800.0000, 
raw observation next is [17.9, 95.66666666666666, 1.0, 2.0, 0.6780129081224632, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 757637.1788000731, 757637.1788000731, 152033.282560957], 
processed observation next is [1.0, 0.4782608695652174, 0.44999999999999996, 0.9566666666666666, 1.0, 1.0, 0.5975161351530789, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2806063625185456, 0.2806063625185456, 0.37081288429501713], 
reward next is 0.6292, 
noisyNet noise sample is [array([1.303274], dtype=float32), -0.09249659]. 
=============================================
[2019-03-23 11:03:53,139] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0907577e-29 1.0000000e+00 0.0000000e+00 1.0843154e-28 0.0000000e+00], sum to 1.0000
[2019-03-23 11:03:53,145] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1521
[2019-03-23 11:03:53,151] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 68.0, 1.0, 2.0, 0.55978151374649, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 638803.5119719822, 638803.5119719822, 147773.3408642894], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6408600.0000, 
sim time next is 6409200.0000, 
raw observation next is [25.0, 68.0, 1.0, 2.0, 0.5473493366510973, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 624607.1111179701, 624607.1111179701, 146252.0354197455], 
processed observation next is [1.0, 0.17391304347826086, 0.7727272727272727, 0.68, 1.0, 1.0, 0.4341866708138716, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23133596708072965, 0.23133596708072965, 0.35671228151157436], 
reward next is 0.6433, 
noisyNet noise sample is [array([0.4031631], dtype=float32), -0.12366161]. 
=============================================
[2019-03-23 11:03:53,277] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.68241082e-25 1.00000000e+00 4.84015610e-36 1.51557377e-23
 1.14291765e-35], sum to 1.0000
[2019-03-23 11:03:53,288] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6550
[2019-03-23 11:03:53,292] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.7, 77.5, 1.0, 2.0, 0.5190427038168598, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 591136.1160428739, 591136.1160428742, 145245.8011007828], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6391800.0000, 
sim time next is 6392400.0000, 
raw observation next is [24.6, 78.0, 1.0, 2.0, 0.5183544952987135, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 590406.449016102, 590406.449016102, 145116.330434038], 
processed observation next is [0.0, 1.0, 0.7545454545454546, 0.78, 1.0, 1.0, 0.3979431191233918, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2186690551911489, 0.2186690551911489, 0.35394226935131223], 
reward next is 0.6461, 
noisyNet noise sample is [array([1.9426609], dtype=float32), -0.3126712]. 
=============================================
[2019-03-23 11:03:56,976] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.6825132e-32 1.0000000e+00 0.0000000e+00 5.2310605e-29 0.0000000e+00], sum to 1.0000
[2019-03-23 11:03:56,985] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4524
[2019-03-23 11:03:56,995] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.0, 77.0, 1.0, 2.0, 0.2077073911741807, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 225516.3111111478, 225516.3111111478, 73371.7353245908], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6486000.0000, 
sim time next is 6486600.0000, 
raw observation next is [15.0, 77.0, 1.0, 2.0, 0.2073433035692576, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 225120.9150010696, 225120.9150010696, 73333.51115481365], 
processed observation next is [1.0, 0.043478260869565216, 0.3181818181818182, 0.77, 1.0, 1.0, 0.009179129461571976, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08337811666706281, 0.08337811666706281, 0.17886222232881377], 
reward next is 0.8211, 
noisyNet noise sample is [array([0.30748314], dtype=float32), -0.52993894]. 
=============================================
[2019-03-23 11:04:01,884] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.0908761e-30 1.0000000e+00 0.0000000e+00 6.8869073e-31 0.0000000e+00], sum to 1.0000
[2019-03-23 11:04:01,891] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9171
[2019-03-23 11:04:01,897] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.4, 81.33333333333333, 1.0, 2.0, 0.2026210099192241, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 219992.5725017779, 219992.5725017776, 72588.2713775575], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6573000.0000, 
sim time next is 6573600.0000, 
raw observation next is [14.4, 81.0, 1.0, 2.0, 0.2021994443566857, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 219534.7610363242, 219534.7610363245, 72461.16439123054], 
processed observation next is [1.0, 0.08695652173913043, 0.29090909090909095, 0.81, 1.0, 1.0, 0.002749305445857095, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08130917075419415, 0.08130917075419425, 0.17673454729568425], 
reward next is 0.8233, 
noisyNet noise sample is [array([1.2292422], dtype=float32), -0.50264007]. 
=============================================
[2019-03-23 11:04:05,520] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.4433132e-24 1.0000000e+00 2.0249562e-36 9.4745634e-24 4.7942689e-37], sum to 1.0000
[2019-03-23 11:04:05,531] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3844
[2019-03-23 11:04:05,535] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.3, 82.0, 1.0, 2.0, 0.3510860570259114, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 389933.466036078, 389933.4660360777, 117924.5876472589], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6642600.0000, 
sim time next is 6643200.0000, 
raw observation next is [19.2, 83.0, 1.0, 2.0, 0.3531966222341438, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 392416.0215396415, 392416.0215396415, 118147.8121224592], 
processed observation next is [1.0, 0.9130434782608695, 0.509090909090909, 0.83, 1.0, 1.0, 0.1914957777926797, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14533926723690424, 0.14533926723690424, 0.2881653954206322], 
reward next is 0.7118, 
noisyNet noise sample is [array([-1.3178136], dtype=float32), 0.6064867]. 
=============================================
[2019-03-23 11:04:15,787] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.4496971e-30 1.0000000e+00 0.0000000e+00 1.2133175e-32 0.0000000e+00], sum to 1.0000
[2019-03-23 11:04:15,798] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1350
[2019-03-23 11:04:15,803] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.61666666666667, 93.5, 1.0, 2.0, 0.3384696564883997, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 374119.9514625591, 374119.9514625593, 116214.9355501881], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6844200.0000, 
sim time next is 6844800.0000, 
raw observation next is [17.53333333333333, 94.0, 1.0, 2.0, 0.337807660703731, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 373212.6608539017, 373212.6608539017, 116096.1875670421], 
processed observation next is [0.0, 0.21739130434782608, 0.43333333333333324, 0.94, 1.0, 1.0, 0.17225957587966376, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.138226911427371, 0.138226911427371, 0.2831614330903466], 
reward next is 0.7168, 
noisyNet noise sample is [array([-0.47822464], dtype=float32), 0.5685549]. 
=============================================
[2019-03-23 11:04:16,803] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.4562501e-25 1.0000000e+00 3.0681021e-38 8.5120867e-30 1.4536873e-38], sum to 1.0000
[2019-03-23 11:04:16,813] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0238
[2019-03-23 11:04:16,819] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.46666666666667, 63.0, 1.0, 2.0, 0.2569896857635383, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 279039.4396215774, 279039.4396215771, 84900.86334952968], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7159200.0000, 
sim time next is 7159800.0000, 
raw observation next is [18.38333333333333, 63.0, 1.0, 2.0, 0.2558842947702094, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 277838.8630821632, 277838.8630821629, 84318.55438317468], 
processed observation next is [1.0, 0.8695652173913043, 0.47196969696969676, 0.63, 1.0, 1.0, 0.06985536846276175, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10290328262302341, 0.1029032826230233, 0.20565501069066994], 
reward next is 0.7943, 
noisyNet noise sample is [array([-0.9105998], dtype=float32), -0.14461654]. 
=============================================
[2019-03-23 11:04:20,833] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.3048048e-27 1.0000000e+00 0.0000000e+00 7.2595058e-29 1.7996991e-38], sum to 1.0000
[2019-03-23 11:04:20,842] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2919
[2019-03-23 11:04:20,847] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.38333333333333, 46.0, 1.0, 2.0, 0.3236758041212436, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 351473.4027506759, 351473.4027506756, 112807.9031664972], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7235400.0000, 
sim time next is 7236000.0000, 
raw observation next is [23.3, 46.0, 1.0, 2.0, 0.3238283348723071, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 351639.0928795944, 351639.0928795941, 112629.0480092889], 
processed observation next is [1.0, 0.782608695652174, 0.6954545454545454, 0.46, 1.0, 1.0, 0.15478541859038386, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13023670106651644, 0.13023670106651633, 0.2747049951446071], 
reward next is 0.7253, 
noisyNet noise sample is [array([0.40090007], dtype=float32), 0.46224242]. 
=============================================
[2019-03-23 11:04:20,865] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[69.44179 ]
 [69.40776 ]
 [69.39967 ]
 [69.448425]
 [69.814255]], R is [[69.49324799]
 [69.5231781 ]
 [69.5528717 ]
 [69.5824585 ]
 [69.60913086]].
[2019-03-23 11:04:20,929] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.8846496e-30 1.0000000e+00 0.0000000e+00 2.2454515e-30 0.0000000e+00], sum to 1.0000
[2019-03-23 11:04:20,936] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3489
[2019-03-23 11:04:20,940] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.13333333333334, 78.83333333333334, 1.0, 2.0, 0.3945106984044224, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 445605.8487657108, 445605.8487657105, 124935.2723519621], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6912600.0000, 
sim time next is 6913200.0000, 
raw observation next is [20.66666666666667, 81.66666666666667, 1.0, 2.0, 0.3921169916200867, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 442577.7810373862, 442577.7810373865, 124533.3770295764], 
processed observation next is [0.0, 0.0, 0.575757575757576, 0.8166666666666668, 1.0, 1.0, 0.24014623952510833, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16391769668051343, 0.1639176966805135, 0.3037399439745766], 
reward next is 0.6963, 
noisyNet noise sample is [array([-1.6872847], dtype=float32), 0.16941471]. 
=============================================
[2019-03-23 11:04:22,620] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.5336179e-26 1.0000000e+00 4.3627488e-38 8.0519793e-31 3.3245576e-36], sum to 1.0000
[2019-03-23 11:04:22,626] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8270
[2019-03-23 11:04:22,633] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.3, 56.0, 1.0, 2.0, 0.5080079215323373, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 578906.5867699528, 578906.5867699528, 143597.655143547], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6964200.0000, 
sim time next is 6964800.0000, 
raw observation next is [28.3, 56.0, 1.0, 2.0, 0.5081465758516105, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 579064.7920513038, 579064.792051304, 143614.0761174029], 
processed observation next is [0.0, 0.6086956521739131, 0.9227272727272727, 0.56, 1.0, 1.0, 0.3851832198145131, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2144684415004829, 0.21446844150048297, 0.35027823443269], 
reward next is 0.6497, 
noisyNet noise sample is [array([0.75821203], dtype=float32), -0.18618423]. 
=============================================
[2019-03-23 11:04:27,090] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.4463438e-27 1.0000000e+00 0.0000000e+00 2.0420126e-30 0.0000000e+00], sum to 1.0000
[2019-03-23 11:04:27,103] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1030
[2019-03-23 11:04:27,109] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.03333333333333, 85.0, 1.0, 2.0, 0.3804431734392562, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 416731.870289688, 416731.870289688, 118137.7864937686], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7352400.0000, 
sim time next is 7353000.0000, 
raw observation next is [17.95, 85.5, 1.0, 2.0, 0.3558291905014667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 389470.6843523189, 389470.6843523186, 116143.1643495326], 
processed observation next is [1.0, 0.08695652173913043, 0.4522727272727272, 0.855, 1.0, 1.0, 0.19478648812683338, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14424840161196995, 0.14424840161196983, 0.28327601060861607], 
reward next is 0.7167, 
noisyNet noise sample is [array([-0.5106001], dtype=float32), 0.9261184]. 
=============================================
[2019-03-23 11:04:27,123] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[64.18644 ]
 [64.165535]
 [64.4082  ]
 [64.46952 ]
 [64.5861  ]], R is [[64.18450165]
 [64.2545166 ]
 [64.3144989 ]
 [64.39326477]
 [64.47073364]].
[2019-03-23 11:04:28,411] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.2183941e-26 1.0000000e+00 1.2554439e-38 4.8338703e-26 5.0644743e-36], sum to 1.0000
[2019-03-23 11:04:28,420] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3085
[2019-03-23 11:04:28,430] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1136713.458346498 W.
[2019-03-23 11:04:28,437] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.2, 78.0, 1.0, 2.0, 0.5162473474099322, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9467688601210095, 6.940320879351004, 6.9112, 77.3283919174236, 1136713.458346498, 1127255.601106473, 250223.091836621], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7054800.0000, 
sim time next is 7055400.0000, 
raw observation next is [22.2, 78.5, 1.0, 2.0, 0.516971436893724, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9477516840280076, 6.939749547083034, 6.9112, 77.32837582924373, 1137768.972794557, 1128496.674346873, 251055.9512972679], 
processed observation next is [1.0, 0.6521739130434783, 0.6454545454545454, 0.785, 1.0, 1.0, 0.39621429611715503, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9253595486114394, 0.0028549547083033923, 0.0, 0.5084282368632596, 0.42139591584983593, 0.41796173123958263, 0.6123315885299216], 
reward next is 0.2449, 
noisyNet noise sample is [array([-0.47751492], dtype=float32), 0.21159104]. 
=============================================
[2019-03-23 11:04:29,247] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.447573e-28 1.000000e+00 0.000000e+00 4.058263e-26 0.000000e+00], sum to 1.0000
[2019-03-23 11:04:29,253] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6487
[2019-03-23 11:04:29,260] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 97.0, 1.0, 2.0, 0.3502792967285521, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 389835.4046399841, 389835.4046399841, 118194.8286733788], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7088400.0000, 
sim time next is 7089000.0000, 
raw observation next is [17.7, 97.0, 1.0, 2.0, 0.3520297155429749, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 391900.2718743069, 391900.2718743069, 118382.9755381599], 
processed observation next is [1.0, 0.043478260869565216, 0.44090909090909086, 0.97, 1.0, 1.0, 0.1900371444287186, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14514824884233588, 0.14514824884233588, 0.28873896472721927], 
reward next is 0.7113, 
noisyNet noise sample is [array([-0.18837184], dtype=float32), -0.30311784]. 
=============================================
[2019-03-23 11:04:29,289] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[65.833046]
 [65.86033 ]
 [65.89705 ]
 [65.93039 ]
 [65.95009 ]], R is [[65.82522583]
 [65.87870026]
 [65.93254089]
 [65.98677826]
 [66.04141998]].
[2019-03-23 11:04:31,285] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.2136215e-27 1.0000000e+00 0.0000000e+00 8.8332007e-28 0.0000000e+00], sum to 1.0000
[2019-03-23 11:04:31,293] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0649
[2019-03-23 11:04:31,299] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.4, 49.66666666666667, 1.0, 2.0, 0.7464961725562146, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 832469.6395831266, 832469.639583127, 159969.8842659044], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7139400.0000, 
sim time next is 7140000.0000, 
raw observation next is [24.4, 49.33333333333334, 1.0, 2.0, 0.7397433369555678, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 824252.429030401, 824252.429030401, 158823.0004648863], 
processed observation next is [1.0, 0.6521739130434783, 0.7454545454545454, 0.4933333333333334, 1.0, 1.0, 0.6746791711944596, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.30527867741866704, 0.30527867741866704, 0.38737317186557635], 
reward next is 0.6126, 
noisyNet noise sample is [array([-2.277602], dtype=float32), -2.5619354]. 
=============================================
[2019-03-23 11:04:31,322] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[68.64403 ]
 [68.580124]
 [68.56827 ]
 [68.55377 ]
 [68.523705]], R is [[68.60636139]
 [68.53012848]
 [68.44561005]
 [68.3655777 ]
 [68.28814697]].
[2019-03-23 11:04:31,938] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-23 11:04:31,938] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 11:04:31,941] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 11:04:31,942] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:04:31,942] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:04:31,943] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 11:04:31,945] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 11:04:31,943] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 11:04:31,946] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:04:31,946] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:04:31,945] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:04:31,969] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run68
[2019-03-23 11:04:31,992] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run68
[2019-03-23 11:04:32,021] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run68
[2019-03-23 11:04:32,043] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run68
[2019-03-23 11:04:32,046] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run68
[2019-03-23 11:04:47,874] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10393716], dtype=float32), -1.085688]
[2019-03-23 11:04:47,876] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [25.8, 68.0, 1.0, 2.0, 0.6560089241915072, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 748009.5583411899, 748009.5583411895, 166692.3885455855]
[2019-03-23 11:04:47,877] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 11:04:47,879] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.2765641e-28 1.0000000e+00 0.0000000e+00 3.3799894e-30 0.0000000e+00], sampled 0.5509041573350527
[2019-03-23 11:04:56,578] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.10393716], dtype=float32), -1.085688]
[2019-03-23 11:04:56,579] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [25.99452181, 46.25493817500001, 1.0, 2.0, 0.3609483997782135, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 404074.3369894295, 404074.3369894291, 124412.2789221052]
[2019-03-23 11:04:56,579] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 11:04:56,583] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.6572814e-28 1.0000000e+00 0.0000000e+00 7.2014974e-30 0.0000000e+00], sampled 0.788773098117668
[2019-03-23 11:04:59,011] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10393716], dtype=float32), -1.085688]
[2019-03-23 11:04:59,012] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [10.9, 85.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 31.85675028, 144528.9581336484, 144528.9581336484, 43081.52320072605]
[2019-03-23 11:04:59,012] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 11:04:59,015] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.0968367e-28 1.0000000e+00 0.0000000e+00 5.6177819e-30 0.0000000e+00], sampled 0.709453527218066
[2019-03-23 11:05:31,186] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.10393716], dtype=float32), -1.085688]
[2019-03-23 11:05:31,187] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.8, 44.0, 1.0, 2.0, 0.3116763939891317, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 338416.4777311262, 338416.4777311259, 116286.876896601]
[2019-03-23 11:05:31,187] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 11:05:31,191] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.6572814e-28 1.0000000e+00 0.0000000e+00 7.2014974e-30 0.0000000e+00], sampled 0.1322409759514196
[2019-03-23 11:05:37,314] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.10393716], dtype=float32), -1.085688]
[2019-03-23 11:05:37,315] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.20134614, 100.0, 1.0, 2.0, 0.4456582640194376, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 507949.397013734, 507949.3970137336, 137711.5486946662]
[2019-03-23 11:05:37,316] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 11:05:37,320] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.229478e-28 1.000000e+00 0.000000e+00 3.226907e-30 0.000000e+00], sampled 0.985727770832084
[2019-03-23 11:06:05,319] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.10393716], dtype=float32), -1.085688]
[2019-03-23 11:06:05,321] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [29.94312229666667, 60.45009277, 1.0, 2.0, 0.6129399372816786, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 688695.395503898, 688695.3955038977, 165017.9645727571]
[2019-03-23 11:06:05,323] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 11:06:05,327] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.1014253e-28 1.0000000e+00 0.0000000e+00 5.6306115e-30 0.0000000e+00], sampled 0.6524044728925029
[2019-03-23 11:06:09,456] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 11:06:09,658] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 11:06:10,037] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 11:06:10,162] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 11:06:10,197] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 11:06:11,213] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 1675000, evaluation results [1675000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 11:06:12,316] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.0715042e-34 1.0000000e+00 0.0000000e+00 1.0141296e-37 0.0000000e+00], sum to 1.0000
[2019-03-23 11:06:12,323] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5773
[2019-03-23 11:06:12,326] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.2, 73.0, 1.0, 2.0, 0.4632740257380979, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 528593.2618712883, 528593.2618712883, 136433.3471986708], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7467600.0000, 
sim time next is 7468200.0000, 
raw observation next is [24.4, 72.5, 1.0, 2.0, 0.4670216775391569, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 532901.3831871514, 532901.3831871514, 137086.4032814736], 
processed observation next is [0.0, 0.43478260869565216, 0.7454545454545454, 0.725, 1.0, 1.0, 0.3337770969239461, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19737088266190791, 0.19737088266190791, 0.3343570811743259], 
reward next is 0.6656, 
noisyNet noise sample is [array([-0.8252899], dtype=float32), 0.492161]. 
=============================================
[2019-03-23 11:06:12,963] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.2839158e-29 1.0000000e+00 0.0000000e+00 2.2308612e-29 1.3505270e-38], sum to 1.0000
[2019-03-23 11:06:12,969] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0208
[2019-03-23 11:06:12,976] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.9, 70.0, 1.0, 2.0, 0.2389015750137675, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 259394.1288171538, 259394.1288171535, 80000.24459176254], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7165800.0000, 
sim time next is 7166400.0000, 
raw observation next is [16.8, 70.0, 1.0, 2.0, 0.2369399373775547, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 257263.6620763142, 257263.6620763145, 79383.76766861684], 
processed observation next is [1.0, 0.9565217391304348, 0.4, 0.7, 1.0, 1.0, 0.04617492172194336, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0952828378060423, 0.09528283780604241, 0.1936189455332118], 
reward next is 0.8064, 
noisyNet noise sample is [array([-1.9369053], dtype=float32), 0.571639]. 
=============================================
[2019-03-23 11:06:16,317] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.4812877e-26 1.0000000e+00 3.7958045e-38 2.9513454e-28 1.0776145e-36], sum to 1.0000
[2019-03-23 11:06:16,323] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3964
[2019-03-23 11:06:16,326] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.6, 62.33333333333334, 1.0, 2.0, 0.2807770657241773, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 304875.8760690626, 304875.8760690623, 95769.0283645501], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7248000.0000, 
sim time next is 7248600.0000, 
raw observation next is [19.4, 63.0, 1.0, 2.0, 0.279087014144658, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 303040.1973283467, 303040.197328347, 94513.61127661566], 
processed observation next is [1.0, 0.9130434782608695, 0.5181818181818181, 0.63, 1.0, 1.0, 0.09885876768082245, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1122371101216099, 0.11223711012161, 0.23052100311369672], 
reward next is 0.7695, 
noisyNet noise sample is [array([-0.18086459], dtype=float32), 0.93470895]. 
=============================================
[2019-03-23 11:06:16,642] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.1894508e-26 1.0000000e+00 0.0000000e+00 2.6675569e-30 2.5071132e-38], sum to 1.0000
[2019-03-23 11:06:16,651] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4442
[2019-03-23 11:06:16,662] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.1, 44.0, 1.0, 2.0, 0.7996465429310358, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 874309.9470220901, 874309.9470220901, 160698.0871207648], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7227000.0000, 
sim time next is 7227600.0000, 
raw observation next is [24.2, 44.33333333333334, 1.0, 2.0, 0.7792605796257955, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 854092.1691922314, 854092.1691922317, 158823.5477456591], 
processed observation next is [1.0, 0.6521739130434783, 0.7363636363636363, 0.4433333333333334, 1.0, 1.0, 0.7240757245322443, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.31633043303415975, 0.3163304330341599, 0.3873745066967295], 
reward next is 0.6126, 
noisyNet noise sample is [array([0.156041], dtype=float32), 0.8968279]. 
=============================================
[2019-03-23 11:06:18,175] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.659713e-29 1.000000e+00 0.000000e+00 4.411456e-27 0.000000e+00], sum to 1.0000
[2019-03-23 11:06:18,185] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7188
[2019-03-23 11:06:18,192] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.8, 84.0, 1.0, 2.0, 0.2012130206503769, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 218463.5270151731, 218463.5270151733, 71769.75174645339], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7275600.0000, 
sim time next is 7276200.0000, 
raw observation next is [13.8, 83.0, 1.0, 2.0, 0.2035226322512675, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 220971.7171177323, 220971.7171177323, 71745.167878156], 
processed observation next is [1.0, 0.21739130434782608, 0.26363636363636367, 0.83, 1.0, 1.0, 0.004403290314084346, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08184137671027122, 0.08184137671027122, 0.17498821433696587], 
reward next is 0.8250, 
noisyNet noise sample is [array([-0.29259235], dtype=float32), 1.6305057]. 
=============================================
[2019-03-23 11:06:20,248] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.8347550e-25 1.0000000e+00 3.3498768e-37 1.6145212e-22 1.0684909e-35], sum to 1.0000
[2019-03-23 11:06:20,257] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9974
[2019-03-23 11:06:20,262] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.08333333333334, 46.16666666666666, 1.0, 2.0, 0.3404725264453777, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 378107.7282218347, 378107.7282218344, 117081.1192438988], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7321800.0000, 
sim time next is 7322400.0000, 
raw observation next is [25.0, 46.0, 1.0, 2.0, 0.3408225332411075, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 377939.7814750216, 377939.7814750216, 116879.374539453], 
processed observation next is [1.0, 0.782608695652174, 0.7727272727272727, 0.46, 1.0, 1.0, 0.17602816655138437, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1399776968426006, 0.1399776968426006, 0.285071645218178], 
reward next is 0.7149, 
noisyNet noise sample is [array([1.1679597], dtype=float32), -0.5862225]. 
=============================================
[2019-03-23 11:06:23,088] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.6848321e-23 1.0000000e+00 1.8132015e-35 3.4603841e-21 3.5640132e-34], sum to 1.0000
[2019-03-23 11:06:23,102] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1001
[2019-03-23 11:06:23,107] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 87.0, 1.0, 2.0, 0.3225343291772858, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 352277.3672893281, 352277.3672893284, 113437.9965026222], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7365600.0000, 
sim time next is 7366200.0000, 
raw observation next is [17.8, 86.5, 1.0, 2.0, 0.331395393904433, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 362186.8585258073, 362186.8585258073, 114150.7218365403], 
processed observation next is [1.0, 0.2608695652173913, 0.4454545454545455, 0.865, 1.0, 1.0, 0.16424424238054125, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1341432809354842, 0.1341432809354842, 0.278416394723269], 
reward next is 0.7216, 
noisyNet noise sample is [array([0.9204231], dtype=float32), -2.737591]. 
=============================================
[2019-03-23 11:06:31,210] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.0067789e-27 1.0000000e+00 0.0000000e+00 1.0246554e-31 2.2288107e-37], sum to 1.0000
[2019-03-23 11:06:31,218] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1783
[2019-03-23 11:06:31,224] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.8, 74.0, 1.0, 2.0, 0.458393345318115, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 522899.3668240312, 522899.3668240312, 135462.7861758801], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7509600.0000, 
sim time next is 7510200.0000, 
raw observation next is [23.71666666666667, 74.33333333333334, 1.0, 2.0, 0.4585322443858189, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 523044.6012892884, 523044.6012892881, 135442.6261397985], 
processed observation next is [0.0, 0.9565217391304348, 0.7143939393939395, 0.7433333333333334, 1.0, 1.0, 0.3231653054822736, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19372022269973643, 0.19372022269973632, 0.33034786863365484], 
reward next is 0.6697, 
noisyNet noise sample is [array([-0.8950051], dtype=float32), 0.4821953]. 
=============================================
[2019-03-23 11:06:33,337] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.7464149e-29 1.0000000e+00 0.0000000e+00 4.2065293e-30 2.1112654e-38], sum to 1.0000
[2019-03-23 11:06:33,348] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6632
[2019-03-23 11:06:33,356] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 56.5, 1.0, 2.0, 0.5029007369544327, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 573354.6100980745, 573354.6100980745, 142678.8502199287], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7569000.0000, 
sim time next is 7569600.0000, 
raw observation next is [27.9, 56.66666666666667, 1.0, 2.0, 0.5014816662331931, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 571820.6168178784, 571820.6168178784, 142395.7775663194], 
processed observation next is [0.0, 0.6086956521739131, 0.9045454545454544, 0.5666666666666668, 1.0, 1.0, 0.37685208279149135, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21178541363625128, 0.21178541363625128, 0.3473067745519985], 
reward next is 0.6527, 
noisyNet noise sample is [array([0.35903773], dtype=float32), 0.56065166]. 
=============================================
[2019-03-23 11:06:38,901] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:06:38,901] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:06:38,975] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run9
[2019-03-23 11:06:45,099] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.786116e-34 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 11:06:45,106] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1313
[2019-03-23 11:06:45,110] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.1, 70.5, 1.0, 2.0, 0.2257492172136047, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 245109.9867078672, 245109.9867078669, 76062.45586000226], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7777800.0000, 
sim time next is 7778400.0000, 
raw observation next is [16.1, 70.0, 1.0, 2.0, 0.2252955490659663, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 244617.2870755319, 244617.2870755316, 75836.18141473836], 
processed observation next is [1.0, 0.0, 0.3681818181818182, 0.7, 1.0, 1.0, 0.03161943633245786, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09059899521315996, 0.09059899521315985, 0.18496629613350818], 
reward next is 0.8150, 
noisyNet noise sample is [array([-0.3196477], dtype=float32), -1.8846726]. 
=============================================
[2019-03-23 11:06:47,681] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:06:47,681] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:06:47,738] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run9
[2019-03-23 11:06:48,906] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.3998469e-26 1.0000000e+00 3.9909533e-36 7.0688216e-27 1.6972612e-35], sum to 1.0000
[2019-03-23 11:06:48,912] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4565
[2019-03-23 11:06:48,917] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 69.66666666666667, 1.0, 2.0, 0.2770073657651052, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 300781.3607968719, 300781.3607968719, 98580.04765803897], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7869000.0000, 
sim time next is 7869600.0000, 
raw observation next is [18.8, 70.0, 1.0, 2.0, 0.2777516875252713, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 301589.8141356527, 301589.8141356524, 99318.4266431259], 
processed observation next is [1.0, 0.08695652173913043, 0.49090909090909096, 0.7, 1.0, 1.0, 0.0971896094065891, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11169993116135284, 0.11169993116135274, 0.24224006498323392], 
reward next is 0.7578, 
noisyNet noise sample is [array([0.13457288], dtype=float32), -1.1596396]. 
=============================================
[2019-03-23 11:06:52,697] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.5184553e-23 1.0000000e+00 1.4191986e-33 1.0805612e-22 1.0796446e-33], sum to 1.0000
[2019-03-23 11:06:52,706] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3360
[2019-03-23 11:06:52,711] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.1, 87.0, 1.0, 2.0, 0.4495112231311703, 1.0, 2.0, 0.4495112231311703, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.3284633768885, 1024556.82999874, 1024556.82999874, 217870.0286696444], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7917000.0000, 
sim time next is 7917600.0000, 
raw observation next is [22.0, 87.0, 1.0, 2.0, 0.8887300609437151, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344312846, 1014602.589769463, 1014602.589769463, 196858.1199978993], 
processed observation next is [1.0, 0.6521739130434783, 0.6363636363636364, 0.87, 1.0, 1.0, 0.8609125761796438, 0.0, 0.5, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129179414, 0.375778736951653, 0.375778736951653, 0.48014175609243737], 
reward next is 0.5199, 
noisyNet noise sample is [array([-0.74067885], dtype=float32), 0.29331473]. 
=============================================
[2019-03-23 11:06:53,275] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:06:53,276] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:06:53,310] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run9
[2019-03-23 11:06:53,699] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:06:53,699] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:06:53,705] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run9
[2019-03-23 11:06:53,747] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:06:53,747] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:06:53,756] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.4086899e-26 1.0000000e+00 2.7762225e-38 1.0178099e-25 2.4508116e-38], sum to 1.0000
[2019-03-23 11:06:53,757] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8881
[2019-03-23 11:06:53,758] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run9
[2019-03-23 11:06:53,759] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.66666666666667, 61.33333333333333, 1.0, 2.0, 0.5304534901168133, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 576142.4077882548, 576142.4077882548, 121657.2350191322], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 124800.0000, 
sim time next is 125400.0000, 
raw observation next is [19.33333333333333, 62.66666666666667, 1.0, 2.0, 0.5199768366445071, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 564756.7704847688, 564756.7704847688, 119335.1766219692], 
processed observation next is [1.0, 0.43478260869565216, 0.5151515151515149, 0.6266666666666667, 1.0, 1.0, 0.39997104580563386, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20916917425361806, 0.20916917425361806, 0.29106140639504685], 
reward next is 0.7089, 
noisyNet noise sample is [array([1.0612289], dtype=float32), -1.6011136]. 
=============================================
[2019-03-23 11:06:53,832] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:06:53,833] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:06:53,836] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run9
[2019-03-23 11:06:53,941] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:06:53,941] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:06:53,950] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run9
[2019-03-23 11:06:54,093] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:06:54,093] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:06:54,099] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run9
[2019-03-23 11:06:54,132] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:06:54,135] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:06:54,146] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run9
[2019-03-23 11:06:54,178] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:06:54,180] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:06:54,185] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run9
[2019-03-23 11:06:54,236] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:06:54,237] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:06:54,247] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run9
[2019-03-23 11:06:54,298] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:06:54,299] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:06:54,302] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run9
[2019-03-23 11:06:54,461] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:06:54,461] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:06:54,464] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run9
[2019-03-23 11:06:54,522] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:06:54,523] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:06:54,526] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run9
[2019-03-23 11:06:54,587] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:06:54,588] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:06:54,591] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:06:54,592] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:06:54,596] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run9
[2019-03-23 11:06:54,672] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run9
[2019-03-23 11:07:00,298] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.3057113e-29 1.0000000e+00 0.0000000e+00 1.2178861e-23 0.0000000e+00], sum to 1.0000
[2019-03-23 11:07:00,306] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9217
[2019-03-23 11:07:00,310] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.66666666666667, 77.83333333333334, 1.0, 2.0, 0.2259100196680026, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 245284.6239728472, 245284.6239728472, 77584.6731262327], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 90600.0000, 
sim time next is 91200.0000, 
raw observation next is [15.33333333333333, 78.66666666666667, 1.0, 2.0, 0.2221834043814661, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 241237.40147955, 241237.4014795497, 76390.95671989316], 
processed observation next is [1.0, 0.043478260869565216, 0.3333333333333332, 0.7866666666666667, 1.0, 1.0, 0.027729255476832623, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08934718573316666, 0.08934718573316655, 0.18631940663388577], 
reward next is 0.8137, 
noisyNet noise sample is [array([-0.5482252], dtype=float32), 0.62212163]. 
=============================================
[2019-03-23 11:07:01,899] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-23 11:07:01,901] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 11:07:01,902] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:07:01,903] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 11:07:01,903] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 11:07:01,905] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:07:01,905] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:07:01,904] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 11:07:01,906] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 11:07:01,908] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:07:01,913] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:07:01,936] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run69
[2019-03-23 11:07:01,959] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run69
[2019-03-23 11:07:01,959] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run69
[2019-03-23 11:07:02,018] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run69
[2019-03-23 11:07:02,042] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run69
[2019-03-23 11:08:30,436] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08563656], dtype=float32), -1.0796192]
[2019-03-23 11:08:30,438] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.98333333333333, 43.33333333333334, 1.0, 2.0, 0.3458036971338818, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 375483.287950658, 375483.2879506577, 107479.7514215813]
[2019-03-23 11:08:30,439] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 11:08:30,444] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [7.3324975e-32 1.0000000e+00 0.0000000e+00 3.2524076e-34 0.0000000e+00], sampled 0.765986241169859
[2019-03-23 11:08:30,750] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08563656], dtype=float32), -1.0796192]
[2019-03-23 11:08:30,752] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.3, 50.66666666666667, 1.0, 2.0, 0.297485372666075, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 323003.8057865604, 323003.8057865601, 99730.00652274693]
[2019-03-23 11:08:30,752] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 11:08:30,754] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [7.3324975e-32 1.0000000e+00 0.0000000e+00 3.2524076e-34 0.0000000e+00], sampled 0.359120289117577
[2019-03-23 11:08:39,974] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 11:08:40,108] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 11:08:40,163] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 11:08:40,176] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 11:08:40,236] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 11:08:41,254] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 1700000, evaluation results [1700000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 11:08:41,625] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.7292487e-31 1.0000000e+00 0.0000000e+00 2.2418594e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 11:08:41,634] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7695
[2019-03-23 11:08:41,640] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.83333333333333, 50.16666666666667, 1.0, 2.0, 0.2519662644632311, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 273583.4738930545, 273583.4738930542, 86340.60745181446], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 305400.0000, 
sim time next is 306000.0000, 
raw observation next is [21.0, 49.0, 1.0, 2.0, 0.2532586413151606, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 274987.1257103356, 274987.1257103359, 86219.96498460895], 
processed observation next is [0.0, 0.5652173913043478, 0.5909090909090909, 0.49, 1.0, 1.0, 0.06657330164395077, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1018470835964206, 0.10184708359642071, 0.21029259752343646], 
reward next is 0.7897, 
noisyNet noise sample is [array([0.15565687], dtype=float32), 0.29994717]. 
=============================================
[2019-03-23 11:08:41,656] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[78.05816 ]
 [78.05816 ]
 [78.056786]
 [78.045746]
 [78.03572 ]], R is [[78.06729889]
 [78.07604218]
 [78.0843811 ]
 [78.09243774]
 [78.10048676]].
[2019-03-23 11:08:41,750] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.8613928e-31 1.0000000e+00 0.0000000e+00 1.9038839e-34 0.0000000e+00], sum to 1.0000
[2019-03-23 11:08:41,758] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2147
[2019-03-23 11:08:41,761] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 43.0, 1.0, 2.0, 0.3005551214770076, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 326358.6682822201, 326358.6682822198, 90397.81942994034], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 151200.0000, 
sim time next is 151800.0000, 
raw observation next is [21.66666666666667, 43.5, 1.0, 2.0, 0.2990887997919872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 324765.9268788145, 324765.9268788142, 89043.69175854737], 
processed observation next is [1.0, 0.782608695652174, 0.6212121212121214, 0.435, 1.0, 1.0, 0.123860999739984, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12028367662178316, 0.12028367662178303, 0.217179735996457], 
reward next is 0.7828, 
noisyNet noise sample is [array([0.9497158], dtype=float32), 0.19623747]. 
=============================================
[2019-03-23 11:08:47,647] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.2590316e-29 1.0000000e+00 0.0000000e+00 7.5035196e-32 0.0000000e+00], sum to 1.0000
[2019-03-23 11:08:47,655] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4727
[2019-03-23 11:08:47,659] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.33333333333333, 96.0, 1.0, 2.0, 0.2620800889469381, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 284568.2171813729, 284568.2171813732, 92556.29710241083], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 247200.0000, 
sim time next is 247800.0000, 
raw observation next is [15.16666666666667, 98.0, 1.0, 2.0, 0.2630885866142901, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 285663.5719191591, 285663.5719191591, 93100.6552817059], 
processed observation next is [0.0, 0.8695652173913043, 0.3257575757575759, 0.98, 1.0, 1.0, 0.07886073326786258, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10580132293302189, 0.10580132293302189, 0.2270747689797705], 
reward next is 0.7729, 
noisyNet noise sample is [array([-0.15648505], dtype=float32), 0.18318944]. 
=============================================
[2019-03-23 11:08:50,860] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.347397e-31 1.000000e+00 0.000000e+00 3.312989e-27 0.000000e+00], sum to 1.0000
[2019-03-23 11:08:50,871] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2344
[2019-03-23 11:08:50,877] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 100.0, 1.0, 2.0, 0.4628606494283352, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 502689.7124915305, 502689.7124915305, 106394.2624405614], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 482400.0000, 
sim time next is 483000.0000, 
raw observation next is [14.0, 100.0, 1.0, 2.0, 0.4106589499108854, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 445970.0637000765, 445970.0637000765, 100991.691588858], 
processed observation next is [1.0, 0.6086956521739131, 0.2727272727272727, 1.0, 1.0, 1.0, 0.26332368738860673, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.165174097666695, 0.165174097666695, 0.24632119899721464], 
reward next is 0.7537, 
noisyNet noise sample is [array([1.9906288], dtype=float32), 0.86823577]. 
=============================================
[2019-03-23 11:08:50,896] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[79.47794 ]
 [79.42397 ]
 [79.365776]
 [79.35212 ]
 [79.4941  ]], R is [[79.73995972]
 [79.68305969]
 [79.62745667]
 [79.57208252]
 [79.51750183]].
[2019-03-23 11:08:51,870] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.1099725e-31 1.0000000e+00 0.0000000e+00 1.6584139e-33 0.0000000e+00], sum to 1.0000
[2019-03-23 11:08:51,872] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8457
[2019-03-23 11:08:51,880] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 42.0, 1.0, 2.0, 0.2709492464093201, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 294201.3172214458, 294201.3172214456, 89161.43761658442], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 315000.0000, 
sim time next is 315600.0000, 
raw observation next is [22.66666666666666, 41.66666666666667, 1.0, 2.0, 0.2730114054705615, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 296441.1271587052, 296441.1271587052, 90043.01045059663], 
processed observation next is [0.0, 0.6521739130434783, 0.6666666666666664, 0.41666666666666674, 1.0, 1.0, 0.09126425683820188, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1097930100587797, 0.1097930100587797, 0.2196170986599918], 
reward next is 0.7804, 
noisyNet noise sample is [array([-0.77096164], dtype=float32), -0.8289033]. 
=============================================
[2019-03-23 11:08:55,728] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.260423e-28 1.000000e+00 0.000000e+00 7.664258e-30 0.000000e+00], sum to 1.0000
[2019-03-23 11:08:55,737] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5424
[2019-03-23 11:08:55,747] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.66666666666667, 54.0, 1.0, 2.0, 0.3695359946919348, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 401292.6608356214, 401292.6608356217, 96224.27224611287], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 397200.0000, 
sim time next is 397800.0000, 
raw observation next is [19.5, 54.5, 1.0, 2.0, 0.3659175130040233, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 397361.6135062339, 397361.6135062339, 95298.96062061051], 
processed observation next is [1.0, 0.6086956521739131, 0.5227272727272727, 0.545, 1.0, 1.0, 0.2073968912550291, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14717096796527182, 0.14717096796527182, 0.23243648931856223], 
reward next is 0.7676, 
noisyNet noise sample is [array([-1.288642], dtype=float32), 0.18251982]. 
=============================================
[2019-03-23 11:09:00,065] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.3643805e-28 1.0000000e+00 0.0000000e+00 9.5253154e-28 0.0000000e+00], sum to 1.0000
[2019-03-23 11:09:00,072] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5260
[2019-03-23 11:09:00,078] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.33333333333334, 92.0, 1.0, 2.0, 0.4161077050417683, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 451890.0880324716, 451890.0880324719, 105177.1745047302], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 490800.0000, 
sim time next is 491400.0000, 
raw observation next is [15.5, 91.0, 1.0, 2.0, 0.4164467614944541, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 452258.4722565571, 452258.4722565574, 105601.9027467257], 
processed observation next is [1.0, 0.6956521739130435, 0.3409090909090909, 0.91, 1.0, 1.0, 0.2705584518680676, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1675031378727989, 0.16750313787279902, 0.2575656164554285], 
reward next is 0.7424, 
noisyNet noise sample is [array([-0.18309699], dtype=float32), 0.890991]. 
=============================================
[2019-03-23 11:09:03,455] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.5796742e-29 1.0000000e+00 0.0000000e+00 1.1989889e-26 0.0000000e+00], sum to 1.0000
[2019-03-23 11:09:03,465] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4316
[2019-03-23 11:09:03,467] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 67.33333333333334, 1.0, 2.0, 0.5803642748560058, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 643381.720501776, 643381.7205017763, 138745.7232545421], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 566400.0000, 
sim time next is 567000.0000, 
raw observation next is [21.0, 66.5, 1.0, 2.0, 0.6344358707832954, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 702570.519236948, 702570.519236948, 144387.55069769], 
processed observation next is [1.0, 0.5652173913043478, 0.5909090909090909, 0.665, 1.0, 1.0, 0.5430448384791192, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.26021130342109183, 0.26021130342109183, 0.3521647577992439], 
reward next is 0.6478, 
noisyNet noise sample is [array([0.3216789], dtype=float32), 0.56405073]. 
=============================================
[2019-03-23 11:09:03,486] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[71.869804]
 [72.0499  ]
 [72.18716 ]
 [72.14135 ]
 [72.1927  ]], R is [[71.68750763]
 [71.63223267]
 [71.59777069]
 [71.5811615 ]
 [71.5617218 ]].
[2019-03-23 11:09:05,452] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.2876443e-28 1.0000000e+00 0.0000000e+00 1.8876559e-34 0.0000000e+00], sum to 1.0000
[2019-03-23 11:09:05,462] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9126
[2019-03-23 11:09:05,467] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 64.0, 1.0, 2.0, 0.5364596549620316, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 589915.9088544135, 589915.9088544132, 132523.0247310922], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 571800.0000, 
sim time next is 572400.0000, 
raw observation next is [21.0, 64.0, 1.0, 2.0, 0.5416671001333963, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 595644.3817481897, 595644.3817481897, 133034.8245779047], 
processed observation next is [1.0, 0.6521739130434783, 0.5909090909090909, 0.64, 1.0, 1.0, 0.4270838751667453, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2206090302771073, 0.2206090302771073, 0.32447518189732855], 
reward next is 0.6755, 
noisyNet noise sample is [array([-0.24905793], dtype=float32), 0.6033355]. 
=============================================
[2019-03-23 11:09:08,235] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.8076570e-21 1.0000000e+00 2.8087299e-33 5.6372811e-20 8.2407526e-32], sum to 1.0000
[2019-03-23 11:09:08,243] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9253
[2019-03-23 11:09:08,249] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.33333333333333, 79.66666666666667, 1.0, 2.0, 0.5152018024396411, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 570368.7293321774, 570368.7293321774, 131807.3810147967], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 636000.0000, 
sim time next is 636600.0000, 
raw observation next is [19.66666666666667, 78.83333333333333, 1.0, 2.0, 0.5297034771307342, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 588518.8684548844, 588518.8684548846, 134012.2555080139], 
processed observation next is [1.0, 0.34782608695652173, 0.5303030303030305, 0.7883333333333333, 1.0, 1.0, 0.4121293464134177, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21796995127958682, 0.2179699512795869, 0.32685915977564367], 
reward next is 0.6731, 
noisyNet noise sample is [array([1.6406057], dtype=float32), 0.5293716]. 
=============================================
[2019-03-23 11:09:11,435] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.0385927e-32 1.0000000e+00 0.0000000e+00 5.1991847e-31 0.0000000e+00], sum to 1.0000
[2019-03-23 11:09:11,441] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5559
[2019-03-23 11:09:11,450] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.16666666666667, 98.00000000000001, 1.0, 2.0, 0.2767886090109498, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 300543.7559765634, 300543.7559765631, 94669.22054756632], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 706200.0000, 
sim time next is 706800.0000, 
raw observation next is [15.33333333333334, 96.0, 1.0, 2.0, 0.2747818989618337, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 298364.1533510988, 298364.1533510985, 94009.89745488166], 
processed observation next is [1.0, 0.17391304347826086, 0.3333333333333336, 0.96, 1.0, 1.0, 0.0934773737022921, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11050524198188845, 0.11050524198188832, 0.22929243281678455], 
reward next is 0.7707, 
noisyNet noise sample is [array([0.84706914], dtype=float32), -1.1798211]. 
=============================================
[2019-03-23 11:09:18,513] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.3253805e-23 1.0000000e+00 1.0408414e-34 6.6480242e-26 1.4869166e-32], sum to 1.0000
[2019-03-23 11:09:18,522] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3905
[2019-03-23 11:09:18,527] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 56.0, 1.0, 2.0, 0.5430466468020894, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 616969.992596114, 616969.9925961138, 149165.0873069344], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 826800.0000, 
sim time next is 827400.0000, 
raw observation next is [29.0, 55.5, 1.0, 2.0, 0.5385107742475823, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 612136.8321640952, 612136.8321640952, 148422.9067834368], 
processed observation next is [0.0, 0.5652173913043478, 0.9545454545454546, 0.555, 1.0, 1.0, 0.42313846780947784, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2267173452459612, 0.2267173452459612, 0.3620070897156995], 
reward next is 0.6380, 
noisyNet noise sample is [array([-2.5458639], dtype=float32), 0.46594775]. 
=============================================
[2019-03-23 11:09:30,542] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-23 11:09:30,546] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 11:09:30,547] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:09:30,548] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 11:09:30,548] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:09:30,547] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 11:09:30,550] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:09:30,553] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 11:09:30,554] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:09:30,557] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 11:09:30,557] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:09:30,577] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run70
[2019-03-23 11:09:30,602] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run70
[2019-03-23 11:09:30,628] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run70
[2019-03-23 11:09:30,652] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run70
[2019-03-23 11:09:30,674] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run70
[2019-03-23 11:09:41,051] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.13083965], dtype=float32), -1.0841843]
[2019-03-23 11:09:41,052] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.61131131833333, 83.36652926166667, 1.0, 2.0, 0.4890737842364279, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 557998.2183286678, 557998.2183286675, 143667.8294840475]
[2019-03-23 11:09:41,053] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 11:09:41,055] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.2686853e-29 1.0000000e+00 0.0000000e+00 1.2814558e-31 0.0000000e+00], sampled 0.3193773386027353
[2019-03-23 11:09:54,146] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.13083965], dtype=float32), -1.0841843]
[2019-03-23 11:09:54,147] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [25.3, 48.0, 1.0, 2.0, 0.3529330473465488, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 394289.3652422494, 394289.365242249, 123380.4559754017]
[2019-03-23 11:09:54,149] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 11:09:54,152] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.2686853e-29 1.0000000e+00 0.0000000e+00 1.2814558e-31 0.0000000e+00], sampled 0.812243614981941
[2019-03-23 11:10:08,326] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.13083965], dtype=float32), -1.0841843]
[2019-03-23 11:10:08,329] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.5, 41.16666666666667, 1.0, 2.0, 0.3038465002355226, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 329912.4895625839, 329912.4895625839, 103776.6084491262]
[2019-03-23 11:10:08,329] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 11:10:08,333] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.2686853e-29 1.0000000e+00 0.0000000e+00 1.2814558e-31 0.0000000e+00], sampled 0.6585001082898632
[2019-03-23 11:10:09,825] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13083965], dtype=float32), -1.0841843]
[2019-03-23 11:10:09,826] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.33333333333334, 98.0, 1.0, 2.0, 0.4936934801183694, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 563199.811803277, 563199.811803277, 141002.6319397173]
[2019-03-23 11:10:09,826] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 11:10:09,829] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [9.1476557e-29 1.0000000e+00 0.0000000e+00 2.9769291e-31 0.0000000e+00], sampled 0.7482582524057757
[2019-03-23 11:11:08,306] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 11:11:08,600] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 11:11:08,623] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 11:11:08,684] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 11:11:08,723] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 11:11:09,741] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 1725000, evaluation results [1725000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 11:11:11,211] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.62700564e-28 1.00000000e+00 1.25143702e-38 1.31860345e-30
 3.31059699e-37], sum to 1.0000
[2019-03-23 11:11:11,211] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2759
[2019-03-23 11:11:11,217] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 69.0, 1.0, 2.0, 0.6181619108058379, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 695674.1287346568, 695674.1287346572, 147158.8059119387], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1089000.0000, 
sim time next is 1089600.0000, 
raw observation next is [22.0, 69.0, 1.0, 2.0, 0.6460721984653301, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 727128.3220301018, 727128.3220301018, 150520.3196978889], 
processed observation next is [1.0, 0.6086956521739131, 0.6363636363636364, 0.69, 1.0, 1.0, 0.5575902480816627, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.26930678593707474, 0.26930678593707474, 0.3671227309704607], 
reward next is 0.6329, 
noisyNet noise sample is [array([0.00853263], dtype=float32), -1.4791974]. 
=============================================
[2019-03-23 11:11:13,446] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.1424327e-31 1.0000000e+00 0.0000000e+00 1.1679265e-33 0.0000000e+00], sum to 1.0000
[2019-03-23 11:11:13,453] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8578
[2019-03-23 11:11:13,457] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 88.0, 1.0, 2.0, 0.3318797618020586, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 365298.510581647, 365298.510581647, 115126.0498924466], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1131600.0000, 
sim time next is 1132200.0000, 
raw observation next is [18.0, 88.0, 1.0, 2.0, 0.322030116543866, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 354408.92718199, 354408.92718199, 114387.0272751574], 
processed observation next is [1.0, 0.08695652173913043, 0.45454545454545453, 0.88, 1.0, 1.0, 0.15253764567983247, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13126256562295927, 0.13126256562295927, 0.2789927494516034], 
reward next is 0.7210, 
noisyNet noise sample is [array([0.2816966], dtype=float32), -1.3405634]. 
=============================================
[2019-03-23 11:11:13,622] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.8694604e-28 1.0000000e+00 0.0000000e+00 2.0704899e-26 4.8393019e-38], sum to 1.0000
[2019-03-23 11:11:13,627] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0654
[2019-03-23 11:11:13,632] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 99.0, 1.0, 2.0, 0.3661890346864636, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 410372.3726361143, 410372.3726361143, 120725.5950456322], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1147800.0000, 
sim time next is 1148400.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.3687835925934727, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 413830.4518646052, 413830.4518646052, 121206.4192798456], 
processed observation next is [1.0, 0.30434782608695654, 0.45454545454545453, 1.0, 1.0, 1.0, 0.21097949074184086, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15327053772763155, 0.15327053772763155, 0.2956254128776722], 
reward next is 0.7044, 
noisyNet noise sample is [array([0.56079215], dtype=float32), -0.8307239]. 
=============================================
[2019-03-23 11:11:14,235] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.6177883e-28 1.0000000e+00 0.0000000e+00 1.1527153e-30 0.0000000e+00], sum to 1.0000
[2019-03-23 11:11:14,242] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1229
[2019-03-23 11:11:14,248] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 96.0, 1.0, 2.0, 0.3527698955115632, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 393637.8619383592, 393637.8619383589, 118837.7467651146], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1146000.0000, 
sim time next is 1146600.0000, 
raw observation next is [18.0, 97.0, 1.0, 2.0, 0.3559486853877217, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 397760.2995952362, 397760.2995952365, 119350.112718232], 
processed observation next is [1.0, 0.2608695652173913, 0.45454545454545453, 0.97, 1.0, 1.0, 0.19493585673465208, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1473186294797171, 0.14731862947971722, 0.2910978358981268], 
reward next is 0.7089, 
noisyNet noise sample is [array([-0.3139153], dtype=float32), 0.23543882]. 
=============================================
[2019-03-23 11:11:15,684] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.7825806e-21 1.0000000e+00 3.6337757e-29 2.8346232e-21 7.4055714e-28], sum to 1.0000
[2019-03-23 11:11:15,693] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3355
[2019-03-23 11:11:15,700] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.83333333333334, 70.66666666666667, 1.0, 2.0, 0.5185811741153856, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 590461.7210730041, 590461.7210730041, 145308.468587021], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1192200.0000, 
sim time next is 1192800.0000, 
raw observation next is [25.66666666666667, 71.33333333333334, 1.0, 2.0, 0.5170956504029753, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 588893.7440306015, 588893.7440306011, 145028.9788132753], 
processed observation next is [1.0, 0.8260869565217391, 0.8030303030303032, 0.7133333333333334, 1.0, 1.0, 0.3963695630037191, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21810879408540795, 0.21810879408540781, 0.3537292166177446], 
reward next is 0.6463, 
noisyNet noise sample is [array([-0.84458774], dtype=float32), -1.6125253]. 
=============================================
[2019-03-23 11:11:15,876] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.1054072e-20 1.0000000e+00 4.2274277e-29 1.1731434e-23 3.0495895e-27], sum to 1.0000
[2019-03-23 11:11:15,882] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9049
[2019-03-23 11:11:15,891] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 64.66666666666667, 1.0, 2.0, 0.5240871319368028, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 596125.1099324976, 596125.1099324976, 146396.5773164009], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1185600.0000, 
sim time next is 1186200.0000, 
raw observation next is [27.0, 64.0, 1.0, 2.0, 0.4999002175719807, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 569110.7516969244, 569110.7516969244, 143115.6664976383], 
processed observation next is [1.0, 0.7391304347826086, 0.8636363636363636, 0.64, 1.0, 1.0, 0.3748752719649759, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2107817598877498, 0.2107817598877498, 0.34906260121375193], 
reward next is 0.6509, 
noisyNet noise sample is [array([-1.5186918], dtype=float32), -0.32363304]. 
=============================================
[2019-03-23 11:11:23,293] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0472725e-21 1.0000000e+00 1.5338289e-33 4.5326406e-19 8.1617541e-33], sum to 1.0000
[2019-03-23 11:11:23,298] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5918
[2019-03-23 11:11:23,301] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.33333333333333, 98.0, 1.0, 2.0, 0.3511665209120908, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 389559.6737506895, 389559.6737506895, 117741.696549897], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1302000.0000, 
sim time next is 1302600.0000, 
raw observation next is [17.16666666666667, 99.0, 1.0, 2.0, 0.3497153406719635, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 387578.0292217608, 387578.0292217605, 117478.4418744882], 
processed observation next is [1.0, 0.043478260869565216, 0.4166666666666669, 0.99, 1.0, 1.0, 0.18714417583995438, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14354741823028178, 0.14354741823028166, 0.2865327850597273], 
reward next is 0.7135, 
noisyNet noise sample is [array([-0.73629564], dtype=float32), -0.32677352]. 
=============================================
[2019-03-23 11:11:27,916] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.3922937e-24 1.0000000e+00 6.5046508e-36 8.9469902e-25 5.5224052e-36], sum to 1.0000
[2019-03-23 11:11:27,922] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8587
[2019-03-23 11:11:27,929] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [8.0, 84.0, 1.0, 2.0, 0.3240475756518315, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 351877.2484505494, 351877.2484505497, 76929.96476391007], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1744200.0000, 
sim time next is 1744800.0000, 
raw observation next is [8.0, 85.0, 1.0, 2.0, 0.3223862193010212, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 350072.5630547138, 350072.5630547135, 76824.79621750838], 
processed observation next is [1.0, 0.17391304347826086, 0.0, 0.85, 1.0, 1.0, 0.15298277412627645, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1296565048350792, 0.12965650483507907, 0.18737755175002044], 
reward next is 0.8126, 
noisyNet noise sample is [array([-1.8167176], dtype=float32), 0.5476074]. 
=============================================
[2019-03-23 11:11:34,605] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.3119501e-23 1.0000000e+00 1.6011774e-34 1.7441229e-22 1.2796666e-33], sum to 1.0000
[2019-03-23 11:11:34,611] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0445
[2019-03-23 11:11:34,615] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 83.0, 1.0, 2.0, 0.4820117133927728, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 549989.8476188192, 549989.8476188192, 139235.0248617304], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1540800.0000, 
sim time next is 1541400.0000, 
raw observation next is [22.83333333333334, 83.83333333333334, 1.0, 2.0, 0.4776504385134514, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 545032.6024650712, 545032.6024650712, 138577.967945097], 
processed observation next is [0.0, 0.8695652173913043, 0.6742424242424245, 0.8383333333333334, 1.0, 1.0, 0.3470630481418142, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20186392683891527, 0.20186392683891527, 0.3379950437685293], 
reward next is 0.6620, 
noisyNet noise sample is [array([0.99639326], dtype=float32), -0.9958972]. 
=============================================
[2019-03-23 11:11:35,846] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.7823310e-24 1.0000000e+00 2.7535580e-37 7.9388216e-17 2.0031673e-36], sum to 1.0000
[2019-03-23 11:11:35,851] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1359
[2019-03-23 11:11:35,858] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.4225471590481668, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 479039.168803352, 479039.168803352, 128618.5966168546], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1571400.0000, 
sim time next is 1572000.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4333985332830342, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 491351.9649133786, 491351.9649133786, 129676.4223622292], 
processed observation next is [1.0, 0.17391304347826086, 0.5, 1.0, 1.0, 1.0, 0.2917481666037927, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18198220922717726, 0.18198220922717726, 0.31628395698104683], 
reward next is 0.6837, 
noisyNet noise sample is [array([-1.2322183], dtype=float32), -0.8690044]. 
=============================================
[2019-03-23 11:11:35,870] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[70.31335 ]
 [70.31539 ]
 [70.327965]
 [70.29435 ]
 [70.28957 ]], R is [[70.30249786]
 [70.2857666 ]
 [70.26816559]
 [70.24195099]
 [70.22750092]].
[2019-03-23 11:11:36,048] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.2182925e-28 1.0000000e+00 0.0000000e+00 3.5701866e-29 0.0000000e+00], sum to 1.0000
[2019-03-23 11:11:36,054] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4269
[2019-03-23 11:11:36,057] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 88.0, 1.0, 2.0, 0.4652214771917481, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 530811.0605885301, 530811.0605885301, 136615.6708893967], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1544400.0000, 
sim time next is 1545000.0000, 
raw observation next is [21.83333333333334, 89.00000000000001, 1.0, 2.0, 0.463069357218957, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 528334.5963797003, 528334.5963797006, 136289.0932319028], 
processed observation next is [0.0, 0.9130434782608695, 0.628787878787879, 0.8900000000000001, 1.0, 1.0, 0.3288366965236962, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19567948014062975, 0.19567948014062986, 0.3324124225168361], 
reward next is 0.6676, 
noisyNet noise sample is [array([-1.2929406], dtype=float32), -0.9339957]. 
=============================================
[2019-03-23 11:11:36,074] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[65.88032]
 [65.88032]
 [65.88032]
 [65.88032]
 [65.88032]], R is [[65.88910675]
 [65.8970108 ]
 [65.90390778]
 [65.9098053 ]
 [65.91469574]].
[2019-03-23 11:11:36,724] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.9815146e-26 1.0000000e+00 0.0000000e+00 6.5606141e-23 1.1201095e-37], sum to 1.0000
[2019-03-23 11:11:36,734] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4297
[2019-03-23 11:11:36,737] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.16666666666667, 94.00000000000001, 1.0, 2.0, 0.4128079277421273, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 469285.8974811581, 469285.8974811581, 128678.3041916452], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1577400.0000, 
sim time next is 1578000.0000, 
raw observation next is [20.33333333333334, 94.0, 1.0, 2.0, 0.4128746363218472, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 469758.9252341168, 469758.9252341168, 129049.9719225623], 
processed observation next is [1.0, 0.2608695652173913, 0.5606060606060609, 0.94, 1.0, 1.0, 0.2660932954023089, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17398478712374696, 0.17398478712374696, 0.31475602907942024], 
reward next is 0.6852, 
noisyNet noise sample is [array([0.05224834], dtype=float32), 0.34798303]. 
=============================================
[2019-03-23 11:11:36,757] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[67.79995 ]
 [67.81045 ]
 [67.814804]
 [67.826256]
 [67.83911 ]], R is [[67.8002243 ]
 [67.8083725 ]
 [67.81871033]
 [67.82978821]
 [67.841362  ]].
[2019-03-23 11:11:41,224] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.4576498e-26 1.0000000e+00 0.0000000e+00 4.4641826e-30 1.5960951e-37], sum to 1.0000
[2019-03-23 11:11:41,227] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6482
[2019-03-23 11:11:41,235] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.66666666666667, 84.83333333333334, 1.0, 2.0, 0.4001332460738994, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 448977.7616681538, 448977.7616681538, 123896.950465098], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1671000.0000, 
sim time next is 1671600.0000, 
raw observation next is [19.33333333333334, 86.66666666666667, 1.0, 2.0, 0.5099413959795429, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 571837.7592976615, 571837.7592976615, 134209.6560856178], 
processed observation next is [1.0, 0.34782608695652173, 0.5151515151515155, 0.8666666666666667, 1.0, 1.0, 0.3874267449744286, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2117917627028376, 0.2117917627028376, 0.3273406245990678], 
reward next is 0.6727, 
noisyNet noise sample is [array([0.2826595], dtype=float32), -1.0775863]. 
=============================================
[2019-03-23 11:11:44,878] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.5649880e-26 1.0000000e+00 1.5387956e-37 5.6868144e-25 8.4558412e-37], sum to 1.0000
[2019-03-23 11:11:44,887] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4590
[2019-03-23 11:11:44,896] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333333, 55.0, 1.0, 2.0, 0.2824792936134417, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 306724.78732318, 306724.7873231803, 92001.69285316135], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2061600.0000, 
sim time next is 2062200.0000, 
raw observation next is [20.16666666666667, 55.5, 1.0, 2.0, 0.2801860821778105, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 304233.968285408, 304233.9682854078, 91092.36255822657], 
processed observation next is [0.0, 0.8695652173913043, 0.5530303030303032, 0.555, 1.0, 1.0, 0.1002326027222631, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11267924751311408, 0.112679247513114, 0.22217649404445505], 
reward next is 0.7778, 
noisyNet noise sample is [array([-0.28468436], dtype=float32), 0.11395271]. 
=============================================
[2019-03-23 11:11:52,730] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.9658000e-28 1.0000000e+00 0.0000000e+00 1.1240878e-34 0.0000000e+00], sum to 1.0000
[2019-03-23 11:11:52,736] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6284
[2019-03-23 11:11:52,739] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 46.0, 1.0, 2.0, 0.3895565937872391, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 423043.2202943175, 423043.2202943175, 104050.5603163937], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1861200.0000, 
sim time next is 1861800.0000, 
raw observation next is [22.16666666666667, 46.66666666666667, 1.0, 2.0, 0.3752386594204496, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 407487.9881371672, 407487.9881371669, 105044.9123734814], 
processed observation next is [1.0, 0.5652173913043478, 0.6439393939393941, 0.46666666666666673, 1.0, 1.0, 0.21904832427556198, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1509214770878397, 0.1509214770878396, 0.25620710334995467], 
reward next is 0.7438, 
noisyNet noise sample is [array([-0.23142171], dtype=float32), 0.4424404]. 
=============================================
[2019-03-23 11:11:52,951] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.1807663e-24 1.0000000e+00 6.3235241e-37 3.5576031e-26 1.1236665e-36], sum to 1.0000
[2019-03-23 11:11:52,957] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6198
[2019-03-23 11:11:52,961] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 64.0, 1.0, 2.0, 0.2650430241552673, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 287786.3428212563, 287786.3428212566, 90675.4596076764], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1896000.0000, 
sim time next is 1896600.0000, 
raw observation next is [19.0, 64.0, 1.0, 2.0, 0.2623342978040487, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 284844.3195963923, 284844.3195963926, 90389.56568378385], 
processed observation next is [1.0, 0.9565217391304348, 0.5, 0.64, 1.0, 1.0, 0.07791787225506087, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10549789614681196, 0.10549789614681208, 0.22046235532630207], 
reward next is 0.7795, 
noisyNet noise sample is [array([-0.8954657], dtype=float32), 0.11227667]. 
=============================================
[2019-03-23 11:11:55,549] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.4160216e-29 1.0000000e+00 0.0000000e+00 6.2931390e-27 0.0000000e+00], sum to 1.0000
[2019-03-23 11:11:55,557] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0601
[2019-03-23 11:11:55,561] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.11666666666667, 56.66666666666666, 1.0, 2.0, 0.333773464072854, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 370746.0305815987, 370746.0305815987, 116599.1862178985], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2110200.0000, 
sim time next is 2110800.0000, 
raw observation next is [23.23333333333333, 56.33333333333334, 1.0, 2.0, 0.3359119902307323, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 373427.7569107942, 373427.7569107942, 116892.0331230313], 
processed observation next is [0.0, 0.43478260869565216, 0.6924242424242423, 0.5633333333333335, 1.0, 1.0, 0.16988998778841538, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13830657663362747, 0.13830657663362747, 0.28510251981227147], 
reward next is 0.7149, 
noisyNet noise sample is [array([0.6397177], dtype=float32), -0.30942452]. 
=============================================
[2019-03-23 11:11:58,970] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-23 11:11:58,972] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 11:11:58,972] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 11:11:58,973] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:11:58,973] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:11:58,974] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 11:11:58,975] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 11:11:58,976] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:11:58,977] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 11:11:58,979] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:11:58,979] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:11:59,007] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run71
[2019-03-23 11:11:59,030] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run71
[2019-03-23 11:11:59,032] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run71
[2019-03-23 11:11:59,081] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run71
[2019-03-23 11:11:59,108] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run71
[2019-03-23 11:12:10,702] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.11197029], dtype=float32), -1.0913328]
[2019-03-23 11:12:10,703] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.10853289666667, 98.09791137, 1.0, 2.0, 0.4511546920834624, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 514244.9413584807, 514244.9413584807, 138326.0807735461]
[2019-03-23 11:12:10,705] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 11:12:10,710] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.4567926e-30 1.0000000e+00 0.0000000e+00 1.9207893e-31 0.0000000e+00], sampled 0.12843719930016828
[2019-03-23 11:12:25,501] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.11197029], dtype=float32), -1.0913328]
[2019-03-23 11:12:25,502] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.754650395, 58.28511625500001, 1.0, 2.0, 0.2575244353982776, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 279604.9081045494, 279604.908104549, 81510.0996227641]
[2019-03-23 11:12:25,503] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 11:12:25,504] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.4567926e-30 1.0000000e+00 0.0000000e+00 1.9207893e-31 0.0000000e+00], sampled 0.9345627229869403
[2019-03-23 11:12:53,583] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.11197029], dtype=float32), -1.0913328]
[2019-03-23 11:12:53,586] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.33333333333334, 59.33333333333334, 1.0, 2.0, 0.4892502255503792, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 553713.4398918756, 553713.4398918753, 139071.2827455601]
[2019-03-23 11:12:53,587] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 11:12:53,590] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.4567926e-30 1.0000000e+00 0.0000000e+00 1.9207893e-31 0.0000000e+00], sampled 0.10414336002664049
[2019-03-23 11:13:12,967] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.11197029], dtype=float32), -1.0913328]
[2019-03-23 11:13:12,968] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.55, 48.0, 1.0, 2.0, 0.7279375825766157, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 798350.7010305302, 798350.7010305302, 152720.89361609]
[2019-03-23 11:13:12,968] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 11:13:12,971] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.4545374e-29 1.0000000e+00 0.0000000e+00 1.4937859e-30 0.0000000e+00], sampled 0.24071618132404515
[2019-03-23 11:13:18,515] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.11197029], dtype=float32), -1.0913328]
[2019-03-23 11:13:18,516] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [13.66666666666667, 87.16666666666667, 1.0, 2.0, 0.223853908428028, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 243051.6177355375, 243051.6177355375, 74184.69881013637]
[2019-03-23 11:13:18,517] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 11:13:18,519] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.4410668e-29 1.0000000e+00 0.0000000e+00 8.8131269e-31 0.0000000e+00], sampled 0.9861596897040966
[2019-03-23 11:13:34,128] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.11197029], dtype=float32), -1.0913328]
[2019-03-23 11:13:34,131] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [28.61666666666667, 53.83333333333334, 1.0, 2.0, 0.7005533957055796, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9753619616243862, 6.911200000000001, 6.9112, 77.3284634435408, 1345815.368121542, 1345815.368121542, 290319.164170258]
[2019-03-23 11:13:34,133] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 11:13:34,136] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.5876864e-29 1.0000000e+00 0.0000000e+00 1.5742173e-30 0.0000000e+00], sampled 0.3358165365127519
[2019-03-23 11:13:34,137] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1345815.368121542 W.
[2019-03-23 11:13:36,882] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 11:13:37,583] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 11:13:37,586] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 11:13:37,606] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 11:13:37,632] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 11:13:38,650] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 1750000, evaluation results [1750000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 11:13:43,662] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0604091e-30 1.0000000e+00 0.0000000e+00 7.1414382e-33 0.0000000e+00], sum to 1.0000
[2019-03-23 11:13:43,676] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1503
[2019-03-23 11:13:43,680] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666667, 57.5, 1.0, 2.0, 0.3249471836196448, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 359167.3560122128, 359167.3560122125, 115200.8644636252], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2109000.0000, 
sim time next is 2109600.0000, 
raw observation next is [23.0, 57.0, 1.0, 2.0, 0.3304445191273721, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 366509.7883467098, 366509.7883467101, 116121.0082909612], 
processed observation next is [0.0, 0.43478260869565216, 0.6818181818181818, 0.57, 1.0, 1.0, 0.16305564890921512, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13574436605433696, 0.13574436605433707, 0.2832219714413688], 
reward next is 0.7168, 
noisyNet noise sample is [array([-1.8557327], dtype=float32), -2.2179964]. 
=============================================
[2019-03-23 11:13:52,156] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.28373720e-32 1.00000000e+00 0.00000000e+00 1.15366354e-26
 0.00000000e+00], sum to 1.0000
[2019-03-23 11:13:52,165] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5303
[2019-03-23 11:13:52,172] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 92.00000000000001, 1.0, 2.0, 0.2184436015834239, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 237175.8907858368, 237175.8907858365, 76334.57133923317], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2257800.0000, 
sim time next is 2258400.0000, 
raw observation next is [14.0, 90.0, 1.0, 2.0, 0.2126833564493995, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 230920.2002194904, 230920.2002194907, 75083.27086580114], 
processed observation next is [1.0, 0.13043478260869565, 0.2727272727272727, 0.9, 1.0, 1.0, 0.01585419556174937, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08552600008129274, 0.08552600008129285, 0.18312992894097838], 
reward next is 0.8169, 
noisyNet noise sample is [array([-1.5064334], dtype=float32), 1.0303916]. 
=============================================
[2019-03-23 11:13:54,461] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.7542063e-28 1.0000000e+00 0.0000000e+00 3.4674558e-27 0.0000000e+00], sum to 1.0000
[2019-03-23 11:13:54,473] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1512
[2019-03-23 11:13:54,483] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 49.0, 1.0, 2.0, 0.4948099645601208, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 537407.439777597, 537407.4397775967, 107234.946901141], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2295000.0000, 
sim time next is 2295600.0000, 
raw observation next is [20.0, 49.0, 1.0, 2.0, 0.5001314945042153, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 543190.3218613229, 543190.3218613229, 107978.4670898305], 
processed observation next is [1.0, 0.5652173913043478, 0.5454545454545454, 0.49, 1.0, 1.0, 0.37516436813026915, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20118160068937885, 0.20118160068937885, 0.2633621148532451], 
reward next is 0.7366, 
noisyNet noise sample is [array([0.93736684], dtype=float32), -0.20505904]. 
=============================================
[2019-03-23 11:13:58,369] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.9554353e-29 1.0000000e+00 0.0000000e+00 7.3681709e-30 0.0000000e+00], sum to 1.0000
[2019-03-23 11:13:58,375] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3404
[2019-03-23 11:13:58,383] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333334, 48.0, 1.0, 2.0, 0.46818110559947, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 508471.0147842696, 508471.0147842696, 109756.3788550529], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2380800.0000, 
sim time next is 2381400.0000, 
raw observation next is [21.5, 47.5, 1.0, 2.0, 0.5219380038532252, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 566888.0737699055, 566888.0737699055, 116448.4491693947], 
processed observation next is [1.0, 0.5652173913043478, 0.6136363636363636, 0.475, 1.0, 1.0, 0.40242250481653147, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20995854584070572, 0.20995854584070572, 0.28402060773023097], 
reward next is 0.7160, 
noisyNet noise sample is [array([0.22084615], dtype=float32), -0.33967656]. 
=============================================
[2019-03-23 11:14:02,912] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.9496091e-30 1.0000000e+00 0.0000000e+00 6.9893461e-27 0.0000000e+00], sum to 1.0000
[2019-03-23 11:14:02,920] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1451
[2019-03-23 11:14:02,928] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.83333333333333, 77.83333333333334, 1.0, 2.0, 0.4291229649206205, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 466031.3447116601, 466031.3447116601, 115646.5139881578], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2465400.0000, 
sim time next is 2466000.0000, 
raw observation next is [18.0, 77.0, 1.0, 2.0, 0.4323379955630807, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 469524.5825370961, 469524.5825370961, 116599.652424703], 
processed observation next is [1.0, 0.5652173913043478, 0.45454545454545453, 0.77, 1.0, 1.0, 0.2904224944538509, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17389799353225782, 0.17389799353225782, 0.2843893961578122], 
reward next is 0.7156, 
noisyNet noise sample is [array([0.65878755], dtype=float32), 1.6393296]. 
=============================================
[2019-03-23 11:14:02,950] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[71.953354]
 [71.77857 ]
 [71.46727 ]
 [71.21017 ]
 [71.04746 ]], R is [[71.96100616]
 [71.9593277 ]
 [71.94823456]
 [71.91499329]
 [71.86471558]].
[2019-03-23 11:14:03,908] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.3628928e-28 1.0000000e+00 0.0000000e+00 1.1310211e-27 0.0000000e+00], sum to 1.0000
[2019-03-23 11:14:03,913] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3445
[2019-03-23 11:14:03,917] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.66666666666667, 52.0, 1.0, 2.0, 0.3660125904246471, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 410242.2539437222, 410242.2539437219, 120742.3975617383], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2662800.0000, 
sim time next is 2663400.0000, 
raw observation next is [24.33333333333333, 53.0, 1.0, 2.0, 0.3624338271438657, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 405631.4698949128, 405631.4698949128, 120162.9801691631], 
processed observation next is [0.0, 0.8260869565217391, 0.7424242424242422, 0.53, 1.0, 1.0, 0.2030422839298321, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1502338777388566, 0.1502338777388566, 0.2930804394369832], 
reward next is 0.7069, 
noisyNet noise sample is [array([1.0811888], dtype=float32), -0.050141253]. 
=============================================
[2019-03-23 11:14:06,535] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.7585279e-28 1.0000000e+00 0.0000000e+00 5.1432629e-30 0.0000000e+00], sum to 1.0000
[2019-03-23 11:14:06,544] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6297
[2019-03-23 11:14:06,548] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.15, 82.0, 1.0, 2.0, 0.4385231271284085, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 499631.5069302003, 499631.5069302003, 132341.8709351669], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2712600.0000, 
sim time next is 2713200.0000, 
raw observation next is [22.36666666666667, 80.66666666666667, 1.0, 2.0, 0.4390059632208027, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 500237.9020699745, 500237.9020699745, 132464.6016866743], 
processed observation next is [0.0, 0.391304347826087, 0.6530303030303032, 0.8066666666666668, 1.0, 1.0, 0.29875745402600334, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18527329706295353, 0.18527329706295353, 0.32308439435774217], 
reward next is 0.6769, 
noisyNet noise sample is [array([-0.54384524], dtype=float32), 0.31813708]. 
=============================================
[2019-03-23 11:14:18,382] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.1311923e-22 1.0000000e+00 5.1579715e-33 3.4861291e-20 9.4258632e-31], sum to 1.0000
[2019-03-23 11:14:18,391] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8111
[2019-03-23 11:14:18,402] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1205204.191644913 W.
[2019-03-23 11:14:18,410] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.0, 74.0, 1.0, 2.0, 0.9950858278800933, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.123614574455237, 6.9112, 77.32800512539811, 1205204.191644913, 1136216.691375741, 215766.9621596901], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3072600.0000, 
sim time next is 3073200.0000, 
raw observation next is [24.0, 74.0, 1.0, 2.0, 0.3511990741380261, 1.0, 1.0, 0.3511990741380261, 1.0, 1.0, 0.7111294871169966, 6.9112, 6.9112, 77.3421103, 1200302.266771738, 1200302.266771738, 277475.2721292178], 
processed observation next is [1.0, 0.5652173913043478, 0.7272727272727273, 0.74, 1.0, 1.0, 0.18899884267253259, 1.0, 0.5, 0.18899884267253259, 1.0, 0.5, 0.5873278387385666, 0.0, 0.0, 0.5085185399722538, 0.4445563951006437, 0.4445563951006437, 0.6767689564127264], 
reward next is 0.3232, 
noisyNet noise sample is [array([1.9288002], dtype=float32), 0.10092278]. 
=============================================
[2019-03-23 11:14:25,418] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.4773694e-14 1.0000000e+00 2.8996756e-21 7.8636628e-14 2.9827545e-20], sum to 1.0000
[2019-03-23 11:14:25,425] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7091
[2019-03-23 11:14:25,433] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1991000.238604933 W.
[2019-03-23 11:14:25,443] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.0, 66.0, 1.0, 2.0, 0.6924443435305522, 1.0, 1.0, 0.5900106087068835, 1.0, 2.0, 0.9865530188920543, 6.911199999999999, 6.9112, 88.52746835743697, 1991000.238604933, 1991000.238604933, 400527.2262805062], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2899200.0000, 
sim time next is 2899800.0000, 
raw observation next is [29.0, 66.0, 1.0, 2.0, 0.7275474639807508, 1.0, 2.0, 0.6075621689319828, 1.0, 2.0, 0.9865530188920543, 6.9112, 6.9112, 87.80123989859383, 2050348.82226756, 2050348.82226756, 408198.3054692281], 
processed observation next is [1.0, 0.5652173913043478, 0.9545454545454546, 0.66, 1.0, 1.0, 0.6594343299759383, 1.0, 1.0, 0.5094527111649785, 1.0, 1.0, 0.9807900269886491, 0.0, 0.0, 0.5772865279703461, 0.7593884526916889, 0.7593884526916889, 0.9956056230956782], 
reward next is 0.0044, 
noisyNet noise sample is [array([0.36692065], dtype=float32), -0.54281306]. 
=============================================
[2019-03-23 11:14:27,959] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-23 11:14:27,962] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 11:14:27,963] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 11:14:27,963] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:14:27,965] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 11:14:27,966] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:14:27,966] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:14:27,966] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 11:14:27,968] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:14:27,968] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 11:14:27,969] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:14:27,987] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run72
[2019-03-23 11:14:28,014] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run72
[2019-03-23 11:14:28,015] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run72
[2019-03-23 11:14:28,015] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run72
[2019-03-23 11:14:28,016] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run72
[2019-03-23 11:14:32,232] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.11138162], dtype=float32), -1.0877353]
[2019-03-23 11:14:32,234] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [13.52057657666667, 93.23006275333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 200733.7592717439, 200733.7592717439, 74880.1878662846]
[2019-03-23 11:14:32,235] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 11:14:32,240] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [8.0456702e-27 1.0000000e+00 1.1770163e-38 1.4134657e-26 8.9790026e-38], sampled 0.5029659425471947
[2019-03-23 11:15:21,235] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.11138162], dtype=float32), -1.0877353]
[2019-03-23 11:15:21,236] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [17.18333333333333, 70.16666666666667, 1.0, 2.0, 0.2473984532225746, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 268608.254658495, 268608.254658495, 86874.29416825481]
[2019-03-23 11:15:21,237] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 11:15:21,241] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [7.8137944e-27 1.0000000e+00 0.0000000e+00 1.3783862e-26 8.6011610e-38], sampled 0.23140001102078678
[2019-03-23 11:15:44,712] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.11138162], dtype=float32), -1.0877353]
[2019-03-23 11:15:44,714] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [23.965569795, 74.28660736, 1.0, 2.0, 0.481626637314698, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 549495.4708595392, 549495.4708595392, 142817.9752655882]
[2019-03-23 11:15:44,715] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 11:15:44,716] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.1970538e-27 1.0000000e+00 0.0000000e+00 9.7438065e-27 4.7148817e-38], sampled 0.6176244321395687
[2019-03-23 11:16:04,931] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 11:16:05,354] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 11:16:05,480] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 11:16:05,496] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 11:16:05,703] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 11:16:06,721] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 1775000, evaluation results [1775000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 11:16:11,246] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.0938314e-22 1.0000000e+00 1.1968318e-34 2.7250651e-20 8.6104072e-33], sum to 1.0000
[2019-03-23 11:16:11,252] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5515
[2019-03-23 11:16:11,259] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 71.0, 1.0, 2.0, 0.4438476799668197, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 505290.3965391953, 505290.3965391953, 132415.5502858368], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3011400.0000, 
sim time next is 3012000.0000, 
raw observation next is [23.33333333333333, 71.66666666666667, 1.0, 2.0, 0.4424101575369203, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 503522.3468048715, 503522.3468048715, 132133.8829251554], 
processed observation next is [1.0, 0.8695652173913043, 0.6969696969696968, 0.7166666666666667, 1.0, 1.0, 0.30301269692115035, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18648975807587834, 0.18648975807587834, 0.32227776323208635], 
reward next is 0.6777, 
noisyNet noise sample is [array([0.2626722], dtype=float32), 0.47324917]. 
=============================================
[2019-03-23 11:16:11,294] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[67.81215 ]
 [67.8286  ]
 [67.80294 ]
 [67.88173 ]
 [67.751015]], R is [[67.72163391]
 [67.72145081]
 [67.72045135]
 [67.71831512]
 [67.71432495]].
[2019-03-23 11:16:14,666] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.35027328e-20 1.00000000e+00 1.12997635e-29 1.56310123e-20
 2.16098804e-29], sum to 1.0000
[2019-03-23 11:16:14,676] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4512
[2019-03-23 11:16:14,686] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1289843.746567413 W.
[2019-03-23 11:16:14,690] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.6, 71.0, 1.0, 2.0, 0.6560796851146072, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9814680415273696, 6.911199999999999, 6.9112, 77.32846344354104, 1289843.746567413, 1289843.746567413, 289367.0631567133], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3085200.0000, 
sim time next is 3085800.0000, 
raw observation next is [26.66666666666667, 70.83333333333334, 1.0, 2.0, 0.3689486732174402, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7467866989509715, 6.9112, 6.9112, 77.32846344354104, 834347.8739776076, 834347.8739776076, 217700.6329753583], 
processed observation next is [1.0, 0.7391304347826086, 0.8484848484848487, 0.7083333333333335, 1.0, 1.0, 0.2111858415218002, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6382667127871022, 0.0, 0.0, 0.5084288129206541, 0.3090177311028176, 0.3090177311028176, 0.5309771535984349], 
reward next is 0.4690, 
noisyNet noise sample is [array([0.21792836], dtype=float32), -0.17760196]. 
=============================================
[2019-03-23 11:16:22,976] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.0601621e-25 1.0000000e+00 8.0584342e-38 1.7912273e-30 3.5935524e-36], sum to 1.0000
[2019-03-23 11:16:22,983] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5246
[2019-03-23 11:16:22,988] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.03333333333333, 49.33333333333333, 1.0, 2.0, 0.3329087961342099, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 367547.8639483955, 367547.8639483952, 115629.4475775568], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3249600.0000, 
sim time next is 3250200.0000, 
raw observation next is [24.01666666666667, 49.66666666666667, 1.0, 2.0, 0.3340997199961303, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 369119.042321479, 369119.042321479, 115818.4900504444], 
processed observation next is [0.0, 0.6086956521739131, 0.7280303030303031, 0.4966666666666667, 1.0, 1.0, 0.16762464999516286, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1367107564153626, 0.1367107564153626, 0.2824841220742546], 
reward next is 0.7175, 
noisyNet noise sample is [array([-1.1173915], dtype=float32), -1.1049286]. 
=============================================
[2019-03-23 11:16:23,105] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.8062076e-27 1.0000000e+00 0.0000000e+00 1.7932391e-28 0.0000000e+00], sum to 1.0000
[2019-03-23 11:16:23,112] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4879
[2019-03-23 11:16:23,115] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 53.0, 1.0, 2.0, 0.3306426720772407, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 363694.4494922904, 363694.4494922907, 114943.3285812773], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3240000.0000, 
sim time next is 3240600.0000, 
raw observation next is [23.16666666666667, 52.00000000000001, 1.0, 2.0, 0.327667002010027, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 360039.3474304634, 360039.3474304636, 114582.7524896862], 
processed observation next is [0.0, 0.5217391304347826, 0.6893939393939396, 0.52, 1.0, 1.0, 0.15958375251253376, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1333479064557272, 0.13334790645572725, 0.27947012802362486], 
reward next is 0.7205, 
noisyNet noise sample is [array([0.38271987], dtype=float32), 1.2273319]. 
=============================================
[2019-03-23 11:16:25,763] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.9865575e-28 1.0000000e+00 0.0000000e+00 8.1365199e-31 0.0000000e+00], sum to 1.0000
[2019-03-23 11:16:25,771] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8507
[2019-03-23 11:16:25,776] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.66666666666667, 84.0, 1.0, 2.0, 0.2365968238527174, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 256891.0193116805, 256891.0193116808, 81912.94395562419], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3304200.0000, 
sim time next is 3304800.0000, 
raw observation next is [16.0, 82.0, 1.0, 2.0, 0.2401003522416112, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 260696.0838665585, 260696.0838665582, 82909.9704529661], 
processed observation next is [0.0, 0.2608695652173913, 0.36363636363636365, 0.82, 1.0, 1.0, 0.05012544030201398, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0965541051357624, 0.0965541051357623, 0.2022194401291856], 
reward next is 0.7978, 
noisyNet noise sample is [array([0.04943357], dtype=float32), -0.258803]. 
=============================================
[2019-03-23 11:16:32,746] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.5648025e-18 1.0000000e+00 6.7533778e-28 9.3994453e-14 8.9423069e-27], sum to 1.0000
[2019-03-23 11:16:32,760] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8163
[2019-03-23 11:16:32,768] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1348403.583987439 W.
[2019-03-23 11:16:32,771] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.8, 56.0, 1.0, 2.0, 0.5936677351224661, 1.0, 1.0, 0.5936677351224661, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1348403.583987439, 1348403.583987439, 256333.4939917413], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3423600.0000, 
sim time next is 3424200.0000, 
raw observation next is [27.83333333333334, 55.83333333333334, 1.0, 2.0, 0.5710034002129326, 1.0, 2.0, 0.5710034002129326, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1296093.165232633, 1296093.165232633, 250551.3204463434], 
processed observation next is [1.0, 0.6521739130434783, 0.9015151515151518, 0.5583333333333335, 1.0, 1.0, 0.46375425026616574, 1.0, 1.0, 0.46375425026616574, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.4800345056417159, 0.4800345056417159, 0.6111007815764473], 
reward next is 0.3889, 
noisyNet noise sample is [array([0.6182392], dtype=float32), 0.96484184]. 
=============================================
[2019-03-23 11:16:34,717] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.1920552e-26 1.0000000e+00 7.2722816e-37 4.3556393e-27 2.1900939e-35], sum to 1.0000
[2019-03-23 11:16:34,724] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2581
[2019-03-23 11:16:34,727] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.5, 62.0, 1.0, 2.0, 0.3388404739988671, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 372731.1374586791, 372731.1374586794, 115556.7777200867], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3778200.0000, 
sim time next is 3778800.0000, 
raw observation next is [21.33333333333334, 62.66666666666667, 1.0, 2.0, 0.3373535401763748, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 370687.0220467824, 370687.0220467827, 115295.0456207659], 
processed observation next is [1.0, 0.7391304347826086, 0.6060606060606063, 0.6266666666666667, 1.0, 1.0, 0.1716919252204685, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13729148964695645, 0.13729148964695656, 0.28120742834333146], 
reward next is 0.7188, 
noisyNet noise sample is [array([-0.48894683], dtype=float32), -0.6690556]. 
=============================================
[2019-03-23 11:16:34,885] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.1222542e-24 1.0000000e+00 6.0434460e-35 6.5219469e-20 1.5061027e-33], sum to 1.0000
[2019-03-23 11:16:34,896] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4957
[2019-03-23 11:16:34,902] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.5459002545490951, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 622878.3251586256, 622878.3251586256, 146994.2329930154], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3647400.0000, 
sim time next is 3648000.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.5170379440569611, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 589926.2664006088, 589926.2664006086, 143511.9261757722], 
processed observation next is [1.0, 0.21739130434782608, 0.5909090909090909, 1.0, 1.0, 1.0, 0.3962974300712014, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21849120977800326, 0.21849120977800318, 0.35002908823359075], 
reward next is 0.6500, 
noisyNet noise sample is [array([0.580781], dtype=float32), -0.8714693]. 
=============================================
[2019-03-23 11:16:34,916] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[63.435604]
 [63.65283 ]
 [63.619595]
 [63.586166]
 [63.548992]], R is [[63.54095078]
 [63.54701614]
 [63.56527328]
 [63.5829277 ]
 [63.59962463]].
[2019-03-23 11:16:35,684] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.1630753e-21 1.0000000e+00 1.8591175e-30 3.5187407e-21 7.2720023e-30], sum to 1.0000
[2019-03-23 11:16:35,692] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9343
[2019-03-23 11:16:35,699] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4912063678247974, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 560441.5016405418, 560441.5016405418, 140481.5504590746], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3479400.0000, 
sim time next is 3480000.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.4953868921394505, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 565214.3218864396, 565214.3218864396, 140961.112006439], 
processed observation next is [1.0, 0.2608695652173913, 0.5909090909090909, 1.0, 1.0, 1.0, 0.3692336151743131, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20933863773571837, 0.20933863773571837, 0.34380759025960733], 
reward next is 0.6562, 
noisyNet noise sample is [array([0.746211], dtype=float32), 1.6375508]. 
=============================================
[2019-03-23 11:16:35,719] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[59.02366 ]
 [58.943848]
 [58.875195]
 [59.23569 ]
 [59.229458]], R is [[59.06851959]
 [59.1352005 ]
 [59.19906235]
 [59.25608826]
 [59.32538223]].
[2019-03-23 11:16:50,990] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.73322113e-24 1.00000000e+00 1.08436654e-33 4.10136652e-29
 1.18638714e-32], sum to 1.0000
[2019-03-23 11:16:50,997] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9291
[2019-03-23 11:16:51,000] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 60.33333333333334, 1.0, 2.0, 0.6758664404824958, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 752123.0344608933, 752123.0344608935, 150521.7859155387], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3775200.0000, 
sim time next is 3775800.0000, 
raw observation next is [22.16666666666667, 60.16666666666666, 1.0, 2.0, 0.7089388308211864, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 787275.4530758444, 787275.4530758444, 153907.6720473808], 
processed observation next is [1.0, 0.6956521739130435, 0.6439393939393941, 0.6016666666666666, 1.0, 1.0, 0.636173538526483, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2915835011392017, 0.2915835011392017, 0.37538456596922143], 
reward next is 0.6246, 
noisyNet noise sample is [array([-1.4284803], dtype=float32), 1.4238548]. 
=============================================
[2019-03-23 11:16:51,262] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0950865e-27 1.0000000e+00 0.0000000e+00 3.4279776e-25 0.0000000e+00], sum to 1.0000
[2019-03-23 11:16:51,266] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2413
[2019-03-23 11:16:51,274] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 64.83333333333334, 1.0, 2.0, 0.3361367847769357, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 369068.6863550889, 369068.6863550889, 115102.1615184796], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3780600.0000, 
sim time next is 3781200.0000, 
raw observation next is [21.0, 65.66666666666667, 1.0, 2.0, 0.3375268830561205, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 371336.5753512208, 371336.5753512208, 115478.3482342013], 
processed observation next is [1.0, 0.782608695652174, 0.5909090909090909, 0.6566666666666667, 1.0, 1.0, 0.1719086038201506, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1375320649448966, 0.1375320649448966, 0.2816545078882959], 
reward next is 0.7183, 
noisyNet noise sample is [array([1.5561413], dtype=float32), -1.5619094]. 
=============================================
[2019-03-23 11:16:54,841] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0791090e-26 1.0000000e+00 0.0000000e+00 5.4052119e-28 3.1247742e-38], sum to 1.0000
[2019-03-23 11:16:54,845] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2477
[2019-03-23 11:16:54,851] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 61.0, 1.0, 2.0, 0.3536296551998585, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 395759.8067820966, 395759.8067820966, 119433.3687764327], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3859200.0000, 
sim time next is 3859800.0000, 
raw observation next is [23.0, 60.33333333333334, 1.0, 2.0, 0.3538710925340129, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 395796.3954401092, 395796.3954401095, 119344.4742682582], 
processed observation next is [0.0, 0.6956521739130435, 0.6818181818181818, 0.6033333333333334, 1.0, 1.0, 0.1923388656675161, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1465912575704108, 0.14659125757041092, 0.29108408358111754], 
reward next is 0.7089, 
noisyNet noise sample is [array([-0.16805555], dtype=float32), -2.0220335]. 
=============================================
[2019-03-23 11:16:56,005] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-23 11:16:56,006] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 11:16:56,007] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:16:56,007] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 11:16:56,008] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 11:16:56,008] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 11:16:56,009] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:16:56,009] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 11:16:56,011] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:16:56,010] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:16:56,012] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:16:56,033] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run73
[2019-03-23 11:16:56,033] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run73
[2019-03-23 11:16:56,087] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run73
[2019-03-23 11:16:56,112] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run73
[2019-03-23 11:16:56,112] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run73
[2019-03-23 11:17:09,685] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.12640302], dtype=float32), -1.0661865]
[2019-03-23 11:17:09,687] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.66666666666667, 89.33333333333334, 1.0, 2.0, 0.4188030003994437, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 476029.1677867483, 476029.167786748, 133541.327294704]
[2019-03-23 11:17:09,687] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 11:17:09,692] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.1150032e-28 1.0000000e+00 0.0000000e+00 1.0794491e-29 0.0000000e+00], sampled 0.28259509573123065
[2019-03-23 11:17:20,007] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.12640302], dtype=float32), -1.0661865]
[2019-03-23 11:17:20,008] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [15.08333333333333, 55.16666666666667, 1.0, 2.0, 0.2114703348909016, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 229592.5204298074, 229592.5204298074, 74192.44223458643]
[2019-03-23 11:17:20,010] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 11:17:20,014] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.1157349e-28 1.0000000e+00 0.0000000e+00 1.0802071e-29 0.0000000e+00], sampled 0.8282898823393872
[2019-03-23 11:17:30,316] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.12640302], dtype=float32), -1.0661865]
[2019-03-23 11:17:30,316] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.31739907333333, 91.26655558166668, 1.0, 2.0, 0.6314928010320112, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9267757325444668, 6.984713049150666, 6.9112, 95.55311142829196, 1263689.966911473, 1234187.484488379, 279794.0171134336]
[2019-03-23 11:17:30,318] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 11:17:30,321] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [6.946654e-28 1.000000e+00 0.000000e+00 7.084850e-29 0.000000e+00], sampled 0.4321336875870374
[2019-03-23 11:17:30,323] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1263689.966911473 W.
[2019-03-23 11:17:35,919] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.12640302], dtype=float32), -1.0661865]
[2019-03-23 11:17:35,920] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [17.4236353, 100.0, 1.0, 2.0, 0.3897061532157188, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 435152.1035160929, 435152.1035160929, 126339.1024027116]
[2019-03-23 11:17:35,921] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 11:17:35,924] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.1052209e-28 1.0000000e+00 0.0000000e+00 1.0692363e-29 0.0000000e+00], sampled 0.314074775038943
[2019-03-23 11:17:49,529] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.12640302], dtype=float32), -1.0661865]
[2019-03-23 11:17:49,531] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.0, 62.33333333333333, 1.0, 2.0, 0.4955461559137601, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 542059.8080214051, 542059.8080214048, 131999.9472706646]
[2019-03-23 11:17:49,532] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 11:17:49,536] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.1157349e-28 1.0000000e+00 0.0000000e+00 1.0802071e-29 0.0000000e+00], sampled 0.8115804744771512
[2019-03-23 11:17:53,069] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.12640302], dtype=float32), -1.0661865]
[2019-03-23 11:17:53,071] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.23333333333333, 70.66666666666667, 1.0, 2.0, 0.8002005258583987, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.5533876968973, 913058.0994266114, 913058.0994266111, 185053.6836286313]
[2019-03-23 11:17:53,072] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 11:17:53,074] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [9.029984e-29 1.000000e+00 0.000000e+00 8.536800e-30 0.000000e+00], sampled 0.06145563787914632
[2019-03-23 11:17:57,394] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.12640302], dtype=float32), -1.0661865]
[2019-03-23 11:17:57,395] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.78333333333333, 73.0, 1.0, 2.0, 0.3239064307819908, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 355867.6186907627, 355867.6186907627, 114294.8668458883]
[2019-03-23 11:17:57,396] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 11:17:57,399] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.1157349e-28 1.0000000e+00 0.0000000e+00 1.0802071e-29 0.0000000e+00], sampled 0.022241405352595778
[2019-03-23 11:18:31,555] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 11:18:31,992] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 11:18:32,127] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 11:18:32,224] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 11:18:32,410] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 11:18:33,429] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 1800000, evaluation results [1800000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 11:18:36,691] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.7977559e-25 1.0000000e+00 3.0432405e-37 1.8302443e-24 1.1998802e-35], sum to 1.0000
[2019-03-23 11:18:36,697] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0277
[2019-03-23 11:18:36,703] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.66666666666667, 48.0, 1.0, 2.0, 0.3391867168940226, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 376424.1436956421, 376424.1436956421, 116876.1393398815], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3950400.0000, 
sim time next is 3951000.0000, 
raw observation next is [24.5, 48.5, 1.0, 2.0, 0.3392759141451539, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 376220.0638959208, 376220.063895921, 116758.8034752272], 
processed observation next is [0.0, 0.7391304347826086, 0.75, 0.485, 1.0, 1.0, 0.17409489268144235, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1393407644058966, 0.13934076440589666, 0.2847775694517737], 
reward next is 0.7152, 
noisyNet noise sample is [array([-0.7451489], dtype=float32), 0.73537207]. 
=============================================
[2019-03-23 11:18:36,720] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[71.706505]
 [71.706505]
 [71.706505]
 [71.706505]
 [71.706505]], R is [[71.70465851]
 [71.70254517]
 [71.70010376]
 [71.69779968]
 [71.69654083]].
[2019-03-23 11:18:40,674] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.9347248e-25 1.0000000e+00 4.4495137e-36 2.3534751e-21 1.3078447e-35], sum to 1.0000
[2019-03-23 11:18:40,683] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9519
[2019-03-23 11:18:40,686] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.5, 91.0, 1.0, 2.0, 0.476811265311344, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 524431.0357723563, 524431.0357723567, 126935.1201900491], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4008600.0000, 
sim time next is 4009200.0000, 
raw observation next is [17.33333333333333, 92.0, 1.0, 2.0, 0.495852651193795, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 544945.3850678536, 544945.385067854, 128541.2374050813], 
processed observation next is [1.0, 0.391304347826087, 0.42424242424242403, 0.92, 1.0, 1.0, 0.3698158139922437, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20183162409920505, 0.20183162409920516, 0.3135152131831251], 
reward next is 0.6865, 
noisyNet noise sample is [array([0.32103956], dtype=float32), -0.5951691]. 
=============================================
[2019-03-23 11:18:45,747] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.5165308e-27 1.0000000e+00 2.5669986e-38 7.7456140e-30 3.5358543e-37], sum to 1.0000
[2019-03-23 11:18:45,754] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8499
[2019-03-23 11:18:45,760] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 83.0, 1.0, 2.0, 0.4132752629070427, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 468444.6084590276, 468444.6084590276, 127676.4365039124], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4420800.0000, 
sim time next is 4421400.0000, 
raw observation next is [20.83333333333333, 83.83333333333334, 1.0, 2.0, 0.4100424767217192, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 464536.064994645, 464536.0649946447, 127206.9684275269], 
processed observation next is [0.0, 0.17391304347826086, 0.5833333333333331, 0.8383333333333334, 1.0, 1.0, 0.2625530959021489, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17205039444246112, 0.172050394442461, 0.31026089860372413], 
reward next is 0.6897, 
noisyNet noise sample is [array([-2.812698], dtype=float32), 1.1236563]. 
=============================================
[2019-03-23 11:18:52,911] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.602090e-28 1.000000e+00 0.000000e+00 5.573067e-29 7.055662e-38], sum to 1.0000
[2019-03-23 11:18:52,920] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0512
[2019-03-23 11:18:52,924] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 95.0, 1.0, 2.0, 0.2942196758952476, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 319477.0462490141, 319477.0462490144, 104538.7488213434], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4252200.0000, 
sim time next is 4252800.0000, 
raw observation next is [16.0, 96.0, 1.0, 2.0, 0.2889938990157966, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 313800.8303404733, 313800.8303404733, 106127.837016361], 
processed observation next is [1.0, 0.21739130434782608, 0.36363636363636365, 0.96, 1.0, 1.0, 0.11124237376974572, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11622252975573084, 0.11622252975573084, 0.2588483829667341], 
reward next is 0.7412, 
noisyNet noise sample is [array([-2.3549984], dtype=float32), 1.1289355]. 
=============================================
[2019-03-23 11:18:56,372] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.4846411e-28 1.0000000e+00 0.0000000e+00 1.9617572e-28 0.0000000e+00], sum to 1.0000
[2019-03-23 11:18:56,380] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2448
[2019-03-23 11:18:56,384] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 61.0, 1.0, 2.0, 0.399720965942477, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 451914.1289775864, 451914.1289775867, 125657.6063245637], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4308600.0000, 
sim time next is 4309200.0000, 
raw observation next is [24.0, 61.0, 1.0, 2.0, 0.4004296186537679, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 452717.5122305367, 452717.5122305367, 125723.8324646054], 
processed observation next is [1.0, 0.9130434782608695, 0.7272727272727273, 0.61, 1.0, 1.0, 0.25053702331720984, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16767315267797656, 0.16767315267797656, 0.3066434938161107], 
reward next is 0.6934, 
noisyNet noise sample is [array([-0.5871286], dtype=float32), 0.8489652]. 
=============================================
[2019-03-23 11:19:02,354] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.3918937e-29 1.0000000e+00 0.0000000e+00 5.2700891e-32 0.0000000e+00], sum to 1.0000
[2019-03-23 11:19:02,360] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2053
[2019-03-23 11:19:02,363] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333334, 86.33333333333334, 1.0, 2.0, 0.3992074533698318, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 451478.7621951228, 451478.7621951225, 125698.6766093413], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4425600.0000, 
sim time next is 4426200.0000, 
raw observation next is [20.5, 85.5, 1.0, 2.0, 0.4004095531356298, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 453065.3333789844, 453065.3333789844, 125948.9342627719], 
processed observation next is [0.0, 0.21739130434782608, 0.5681818181818182, 0.855, 1.0, 1.0, 0.25051194141953725, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16780197532554977, 0.16780197532554977, 0.3071925225921266], 
reward next is 0.6928, 
noisyNet noise sample is [array([0.19501913], dtype=float32), -0.22647315]. 
=============================================
[2019-03-23 11:19:09,385] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.2244446e-30 1.0000000e+00 0.0000000e+00 2.6821570e-31 0.0000000e+00], sum to 1.0000
[2019-03-23 11:19:09,393] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5755
[2019-03-23 11:19:09,396] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.83333333333334, 73.66666666666667, 1.0, 2.0, 0.3046025387346331, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 330755.0628835199, 330755.0628835196, 111500.3129203936], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4569000.0000, 
sim time next is 4569600.0000, 
raw observation next is [18.66666666666667, 74.33333333333334, 1.0, 2.0, 0.3036850425280916, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 329758.4546238646, 329758.4546238643, 110398.0010103505], 
processed observation next is [0.0, 0.9130434782608695, 0.4848484848484851, 0.7433333333333334, 1.0, 1.0, 0.12960630316011446, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12213276097180172, 0.1221327609718016, 0.2692634170984159], 
reward next is 0.7307, 
noisyNet noise sample is [array([-1.991714], dtype=float32), 0.52807325]. 
=============================================
[2019-03-23 11:19:12,986] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.4347007e-26 1.0000000e+00 0.0000000e+00 6.2497829e-29 0.0000000e+00], sum to 1.0000
[2019-03-23 11:19:12,996] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2586
[2019-03-23 11:19:13,000] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.16666666666667, 49.5, 1.0, 2.0, 0.5945319167907074, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 651379.8308408065, 651379.8308408065, 137617.5136349936], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4639800.0000, 
sim time next is 4640400.0000, 
raw observation next is [23.0, 50.0, 1.0, 2.0, 0.6643276404652619, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 727293.9938021059, 727293.9938021061, 144940.5289095514], 
processed observation next is [1.0, 0.7391304347826086, 0.6818181818181818, 0.5, 1.0, 1.0, 0.5804095505815774, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2693681458526318, 0.2693681458526319, 0.3535134851452473], 
reward next is 0.6465, 
noisyNet noise sample is [array([-0.4665376], dtype=float32), -0.2817972]. 
=============================================
[2019-03-23 11:19:13,124] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.7638516e-25 1.0000000e+00 3.8648439e-37 4.9157711e-31 2.4529467e-36], sum to 1.0000
[2019-03-23 11:19:13,131] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8889
[2019-03-23 11:19:13,134] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.16666666666667, 49.5, 1.0, 2.0, 0.5945319167907074, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 651379.8308408065, 651379.8308408065, 137617.5136349936], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4639800.0000, 
sim time next is 4640400.0000, 
raw observation next is [23.0, 50.0, 1.0, 2.0, 0.6643276404652619, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 727293.9938021059, 727293.9938021061, 144940.5289095514], 
processed observation next is [1.0, 0.7391304347826086, 0.6818181818181818, 0.5, 1.0, 1.0, 0.5804095505815774, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2693681458526318, 0.2693681458526319, 0.3535134851452473], 
reward next is 0.6465, 
noisyNet noise sample is [array([0.22978595], dtype=float32), -0.2487884]. 
=============================================
[2019-03-23 11:19:22,718] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 11:19:22,721] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 11:19:22,722] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 11:19:22,723] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:19:22,723] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 11:19:22,724] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 11:19:22,725] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 11:19:22,724] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:19:22,727] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:19:22,728] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:19:22,726] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:19:22,789] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run74
[2019-03-23 11:19:22,816] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run74
[2019-03-23 11:19:22,817] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run74
[2019-03-23 11:19:22,866] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run74
[2019-03-23 11:19:22,866] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run74
[2019-03-23 11:19:29,047] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13920903], dtype=float32), -1.0721745]
[2019-03-23 11:19:29,048] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [13.0, 100.0, 1.0, 2.0, 0.5451571859432048, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 592122.2873352406, 592122.2873352406, 110797.7611152322]
[2019-03-23 11:19:29,049] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 11:19:29,051] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [9.196365e-28 1.000000e+00 0.000000e+00 4.642688e-30 4.794870e-38], sampled 0.9808048518739153
[2019-03-23 11:20:08,941] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13920903], dtype=float32), -1.0721745]
[2019-03-23 11:20:08,943] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.85749606, 90.29156838333333, 1.0, 2.0, 0.3140401548223288, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 341471.4619026672, 341471.4619026668, 116616.3109924737]
[2019-03-23 11:20:08,943] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 11:20:08,946] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.1061827e-28 1.0000000e+00 0.0000000e+00 4.6880859e-31 0.0000000e+00], sampled 0.9447711722990586
[2019-03-23 11:20:12,269] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13920903], dtype=float32), -1.0721745]
[2019-03-23 11:20:12,270] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [27.08333333333334, 49.33333333333334, 1.0, 2.0, 0.6941819022354504, 0.0, 2.0, 0.0, 1.0, 2.0, 0.963899590791136, 6.9112, 6.9112, 78.26345941519878, 1340031.403817379, 1340031.403817379, 277210.1721820956]
[2019-03-23 11:20:12,270] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 11:20:12,272] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.3383401e-25 1.0000000e+00 7.4981250e-36 1.0670981e-27 4.4490237e-35], sampled 0.8714123158572145
[2019-03-23 11:20:12,273] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1340031.403817379 W.
[2019-03-23 11:20:13,997] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13920903], dtype=float32), -1.0721745]
[2019-03-23 11:20:13,999] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.0, 87.16666666666667, 1.0, 2.0, 0.4317958856564903, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 491063.2627936656, 491063.2627936656, 130703.5078307502]
[2019-03-23 11:20:13,999] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 11:20:14,001] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [9.874085e-29 1.000000e+00 0.000000e+00 4.157821e-31 0.000000e+00], sampled 0.378398411591515
[2019-03-23 11:20:41,898] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13920903], dtype=float32), -1.0721745]
[2019-03-23 11:20:41,900] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.54839570666667, 44.82903392666667, 1.0, 2.0, 0.2903983631357361, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 315306.8507603352, 315306.8507603352, 88972.00170179027]
[2019-03-23 11:20:41,900] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 11:20:41,904] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [9.6952264e-29 1.0000000e+00 0.0000000e+00 4.0909559e-31 0.0000000e+00], sampled 0.7674645472811727
[2019-03-23 11:20:51,297] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13920903], dtype=float32), -1.0721745]
[2019-03-23 11:20:51,298] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.35, 65.0, 1.0, 2.0, 0.4156810941984856, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 451426.5765175346, 451426.5765175346, 102911.3263784887]
[2019-03-23 11:20:51,299] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 11:20:51,302] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.6379781e-28 1.0000000e+00 0.0000000e+00 7.1352911e-31 0.0000000e+00], sampled 0.6023796090970248
[2019-03-23 11:20:55,368] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13920903], dtype=float32), -1.0721745]
[2019-03-23 11:20:55,369] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [24.4, 69.0, 1.0, 2.0, 0.4484560534151398, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 511369.2545364974, 511369.2545364974, 133992.3862593248]
[2019-03-23 11:20:55,370] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 11:20:55,374] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [9.6952264e-29 1.0000000e+00 0.0000000e+00 4.0909559e-31 0.0000000e+00], sampled 0.9871078311456548
[2019-03-23 11:20:59,507] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 11:20:59,656] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 11:21:00,184] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 11:21:00,362] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 11:21:00,376] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 11:21:01,393] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 1825000, evaluation results [1825000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 11:21:05,924] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.4654941e-25 1.0000000e+00 2.1057176e-36 9.7096194e-30 8.5384031e-36], sum to 1.0000
[2019-03-23 11:21:05,932] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1545
[2019-03-23 11:21:05,935] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.8283340916760805, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 940494.064395405, 940494.064395405, 179695.7120185934], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4871400.0000, 
sim time next is 4872000.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.8037509272623865, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 912664.6694679019, 912664.6694679019, 176058.476028282], 
processed observation next is [1.0, 0.391304347826087, 0.5, 1.0, 1.0, 1.0, 0.754688659077983, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3380239516547785, 0.3380239516547785, 0.4294109171421512], 
reward next is 0.5706, 
noisyNet noise sample is [array([0.02742058], dtype=float32), -0.17708541]. 
=============================================
[2019-03-23 11:21:05,952] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[66.24427 ]
 [67.415695]
 [67.43349 ]
 [67.67569 ]
 [68.24    ]], R is [[66.14628601]
 [66.04653931]
 [65.99914551]
 [65.95475006]
 [65.91816711]].
[2019-03-23 11:21:08,858] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.091886e-31 1.000000e+00 0.000000e+00 7.964757e-32 0.000000e+00], sum to 1.0000
[2019-03-23 11:21:08,860] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3923
[2019-03-23 11:21:08,863] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 73.0, 1.0, 2.0, 0.6837598007283885, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 744220.8854957323, 744220.8854957327, 145755.506575311], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4966200.0000, 
sim time next is 4966800.0000, 
raw observation next is [19.0, 73.0, 1.0, 2.0, 0.6760563055664499, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 735897.7647482587, 735897.7647482587, 144919.9026182762], 
processed observation next is [1.0, 0.4782608695652174, 0.5, 0.73, 1.0, 1.0, 0.5950703819580624, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.27255472768454025, 0.27255472768454025, 0.3534631771177468], 
reward next is 0.6465, 
noisyNet noise sample is [array([-0.30768102], dtype=float32), 1.6506596]. 
=============================================
[2019-03-23 11:21:11,606] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.1492204e-34 1.0000000e+00 0.0000000e+00 1.5169743e-37 0.0000000e+00], sum to 1.0000
[2019-03-23 11:21:11,612] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7374
[2019-03-23 11:21:11,616] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.33333333333333, 86.0, 1.0, 2.0, 0.2683528143241477, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 291381.2223789658, 291381.2223789655, 92465.4662160519], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5013600.0000, 
sim time next is 5014200.0000, 
raw observation next is [16.16666666666667, 87.0, 1.0, 2.0, 0.2672619377899217, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 290196.3800568123, 290196.3800568125, 91765.90790666071], 
processed observation next is [0.0, 0.0, 0.37121212121212144, 0.87, 1.0, 1.0, 0.0840774222374021, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10748014076178233, 0.1074801407617824, 0.22381928757722125], 
reward next is 0.7762, 
noisyNet noise sample is [array([-0.45071357], dtype=float32), -0.12493732]. 
=============================================
[2019-03-23 11:21:16,059] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.4868105e-27 1.0000000e+00 0.0000000e+00 1.3986692e-31 8.6432616e-38], sum to 1.0000
[2019-03-23 11:21:16,063] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1645
[2019-03-23 11:21:16,069] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.66666666666667, 84.66666666666666, 1.0, 2.0, 0.3962921311496422, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 448622.5135311811, 448622.5135311811, 125707.8911864934], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5107200.0000, 
sim time next is 5107800.0000, 
raw observation next is [20.83333333333333, 83.83333333333334, 1.0, 2.0, 0.3981243341745114, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 450903.7469507941, 450903.7469507944, 126010.4056214257], 
processed observation next is [0.0, 0.08695652173913043, 0.5833333333333331, 0.8383333333333334, 1.0, 1.0, 0.2476554177181392, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1670013877595534, 0.16700138775955348, 0.3073424527351846], 
reward next is 0.6927, 
noisyNet noise sample is [array([-0.86005056], dtype=float32), -1.5670786]. 
=============================================
[2019-03-23 11:21:20,891] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.1187743e-27 1.0000000e+00 0.0000000e+00 1.1204608e-28 0.0000000e+00], sum to 1.0000
[2019-03-23 11:21:20,902] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9757
[2019-03-23 11:21:20,905] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 83.0, 1.0, 2.0, 0.4760753960244742, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 543229.2470699222, 543229.2470699224, 138452.1334101614], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5173800.0000, 
sim time next is 5174400.0000, 
raw observation next is [23.0, 83.0, 1.0, 2.0, 0.4766957653223965, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 543937.0919177968, 543937.0919177965, 138525.2302732508], 
processed observation next is [0.0, 0.9130434782608695, 0.6818181818181818, 0.83, 1.0, 1.0, 0.3458697066529956, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20145818219177658, 0.2014581821917765, 0.33786641530061173], 
reward next is 0.6621, 
noisyNet noise sample is [array([0.56182253], dtype=float32), -0.5830721]. 
=============================================
[2019-03-23 11:21:28,414] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.9396071e-25 1.0000000e+00 3.8683751e-34 6.3621312e-25 1.8087958e-33], sum to 1.0000
[2019-03-23 11:21:28,420] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5624
[2019-03-23 11:21:28,423] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 97.0, 1.0, 2.0, 0.3937994763752523, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 444456.6751735881, 444456.6751735878, 124673.2117895052], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5630400.0000, 
sim time next is 5631000.0000, 
raw observation next is [18.8, 97.0, 1.0, 2.0, 0.3921399272784256, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 442490.9611027878, 442490.961102788, 124472.212070962], 
processed observation next is [0.0, 0.17391304347826086, 0.49090909090909096, 0.97, 1.0, 1.0, 0.240174909098032, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16388554114918066, 0.16388554114918075, 0.3035907611486878], 
reward next is 0.6964, 
noisyNet noise sample is [array([0.7833554], dtype=float32), 1.5608835]. 
=============================================
[2019-03-23 11:21:28,437] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[54.83722 ]
 [54.64074 ]
 [54.50915 ]
 [54.340878]
 [54.16073 ]], R is [[55.04940796]
 [55.19483185]
 [55.33798599]
 [55.47878265]
 [55.61701584]].
[2019-03-23 11:21:31,167] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.2632487e-20 1.0000000e+00 8.7686781e-27 1.7946483e-21 1.7388513e-26], sum to 1.0000
[2019-03-23 11:21:31,172] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3406
[2019-03-23 11:21:31,178] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1235860.318661396 W.
[2019-03-23 11:21:31,183] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.5, 77.0, 1.0, 2.0, 0.6080088866295287, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9810546198386493, 6.9112, 6.9112, 77.32846344353395, 1235860.318661396, 1235860.318661396, 282114.8168757754], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5392800.0000, 
sim time next is 5393400.0000, 
raw observation next is [25.86666666666667, 75.33333333333334, 1.0, 2.0, 0.4368735774763586, 1.0, 1.0, 0.4368735774763586, 1.0, 2.0, 0.8839610117290079, 6.9112, 6.9112, 77.80598830105708, 1473880.227268566, 1473880.227268566, 326054.6496361183], 
processed observation next is [1.0, 0.43478260869565216, 0.8121212121212124, 0.7533333333333334, 1.0, 1.0, 0.29609197184544817, 1.0, 0.5, 0.29609197184544817, 1.0, 1.0, 0.8342300167557257, 0.0, 0.0, 0.5115685028308804, 0.5458815656550244, 0.5458815656550244, 0.7952552430149228], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2801967], dtype=float32), 0.6527134]. 
=============================================
[2019-03-23 11:21:33,883] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.1376292e-26 1.0000000e+00 2.3429843e-37 7.8020593e-27 3.8096143e-38], sum to 1.0000
[2019-03-23 11:21:33,890] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5229
[2019-03-23 11:21:33,895] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 95.0, 1.0, 2.0, 0.3875191256664936, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 436368.2788051249, 436368.2788051246, 123566.239880875], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5441400.0000, 
sim time next is 5442000.0000, 
raw observation next is [18.8, 94.33333333333334, 1.0, 2.0, 0.3846915320118071, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 432832.0780843063, 432832.0780843063, 123134.5011362064], 
processed observation next is [1.0, 1.0, 0.49090909090909096, 0.9433333333333335, 1.0, 1.0, 0.23086441501475888, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16030817706826161, 0.16030817706826161, 0.30032805155172293], 
reward next is 0.6997, 
noisyNet noise sample is [array([-0.44992396], dtype=float32), 2.0003836]. 
=============================================
[2019-03-23 11:21:33,914] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[61.421898]
 [61.377884]
 [61.357506]
 [61.38458 ]
 [61.39795 ]], R is [[61.5594635 ]
 [61.64249039]
 [61.72376633]
 [61.80350113]
 [61.88220978]].
[2019-03-23 11:21:33,929] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.1706459e-28 1.0000000e+00 0.0000000e+00 2.7601498e-31 0.0000000e+00], sum to 1.0000
[2019-03-23 11:21:33,938] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5943
[2019-03-23 11:21:33,941] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 95.0, 1.0, 2.0, 0.3904931249202954, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 439725.2980591704, 439725.2980591704, 123833.1220220733], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5430600.0000, 
sim time next is 5431200.0000, 
raw observation next is [18.8, 94.33333333333334, 1.0, 2.0, 0.3897722243597029, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 438561.3473900532, 438561.3473900534, 123586.8021217988], 
processed observation next is [1.0, 0.8695652173913043, 0.49090909090909096, 0.9433333333333335, 1.0, 1.0, 0.23721528044962858, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16243012866298268, 0.16243012866298273, 0.30143122468731415], 
reward next is 0.6986, 
noisyNet noise sample is [array([0.48830763], dtype=float32), 0.5048564]. 
=============================================
[2019-03-23 11:21:38,490] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.2737027e-27 1.0000000e+00 1.4200838e-37 9.4465774e-35 1.1155468e-37], sum to 1.0000
[2019-03-23 11:21:38,497] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7312
[2019-03-23 11:21:38,505] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.21666666666667, 74.33333333333334, 1.0, 2.0, 0.4850607495818039, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 553490.3327124427, 553490.3327124425, 139440.2683443007], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5519400.0000, 
sim time next is 5520000.0000, 
raw observation next is [24.03333333333333, 74.66666666666667, 1.0, 2.0, 0.4801652257392838, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 547911.2132126631, 547911.2132126631, 138626.1510218677], 
processed observation next is [1.0, 0.9130434782608695, 0.7287878787878787, 0.7466666666666667, 1.0, 1.0, 0.3502065321741047, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.202930078967653, 0.202930078967653, 0.33811256346797], 
reward next is 0.6619, 
noisyNet noise sample is [array([0.13255748], dtype=float32), -1.1485901]. 
=============================================
[2019-03-23 11:21:38,526] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[60.638126]
 [60.631733]
 [60.586628]
 [60.530716]
 [60.62197 ]], R is [[60.73152542]
 [60.78411102]
 [60.83453751]
 [60.88388062]
 [60.93255234]].
[2019-03-23 11:21:38,942] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.4626674e-29 1.0000000e+00 0.0000000e+00 1.0555719e-34 0.0000000e+00], sum to 1.0000
[2019-03-23 11:21:38,961] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3881
[2019-03-23 11:21:38,966] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.55, 51.5, 1.0, 2.0, 0.5203649098200159, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 574606.5656912666, 574606.5656912666, 131785.7267437475], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5830200.0000, 
sim time next is 5830800.0000, 
raw observation next is [23.83333333333333, 51.66666666666667, 1.0, 2.0, 0.5467068271760119, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 606332.9451821918, 606332.9451821921, 135340.9749438456], 
processed observation next is [1.0, 0.4782608695652174, 0.7196969696969695, 0.5166666666666667, 1.0, 1.0, 0.4333835339700149, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22456775747488586, 0.22456775747488597, 0.3300999388874283], 
reward next is 0.6699, 
noisyNet noise sample is [array([-2.1493948], dtype=float32), 0.50193614]. 
=============================================
[2019-03-23 11:21:49,532] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.6940603e-25 1.0000000e+00 6.4149820e-35 1.7874748e-28 7.1506446e-35], sum to 1.0000
[2019-03-23 11:21:49,539] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6091
[2019-03-23 11:21:49,545] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.66666666666667, 72.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 181699.8228914462, 181699.8228914462, 63469.92223899032], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5731800.0000, 
sim time next is 5732400.0000, 
raw observation next is [14.03333333333333, 70.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 186066.3239127875, 186066.3239127878, 64338.49295077027], 
processed observation next is [0.0, 0.34782608695652173, 0.27424242424242407, 0.7, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0689134533010324, 0.06891345330103252, 0.15692315353846406], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.40679425], dtype=float32), 0.37190783]. 
=============================================
[2019-03-23 11:21:50,986] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-23 11:21:50,987] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 11:21:50,988] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:21:50,989] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 11:21:50,989] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:21:50,990] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 11:21:50,992] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 11:21:50,992] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:21:50,993] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:21:50,993] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 11:21:50,994] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:21:51,019] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run75
[2019-03-23 11:21:51,046] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run75
[2019-03-23 11:21:51,047] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run75
[2019-03-23 11:21:51,069] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run75
[2019-03-23 11:21:51,130] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run75
[2019-03-23 11:21:57,293] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.20475933], dtype=float32), -1.0934658]
[2019-03-23 11:21:57,294] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [12.734435315, 99.75601508, 1.0, 2.0, 0.208800081469291, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 226692.8899947382, 226692.8899947382, 78669.8526076217]
[2019-03-23 11:21:57,298] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 11:21:57,301] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.4289821e-26 1.0000000e+00 1.4049810e-36 1.2498445e-29 5.2261949e-36], sampled 0.11780292379496271
[2019-03-23 11:22:06,373] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.20475933], dtype=float32), -1.0934658]
[2019-03-23 11:22:06,374] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.4, 90.0, 1.0, 2.0, 0.4266372288840904, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 484478.179703599, 484478.1797035987, 133936.1134146317]
[2019-03-23 11:22:06,375] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 11:22:06,378] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.4289821e-26 1.0000000e+00 1.4049810e-36 1.2498445e-29 5.2261949e-36], sampled 0.5962026308746369
[2019-03-23 11:22:26,127] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.20475933], dtype=float32), -1.0934658]
[2019-03-23 11:22:26,127] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [26.8, 62.0, 1.0, 2.0, 0.7015351913558583, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 800021.1603236757, 800021.1603236757, 173156.7063808353]
[2019-03-23 11:22:26,128] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 11:22:26,133] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.7084954e-26 1.0000000e+00 1.6257579e-36 1.4037056e-29 6.0790270e-36], sampled 0.5356960887462876
[2019-03-23 11:22:31,980] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.20475933], dtype=float32), -1.0934658]
[2019-03-23 11:22:31,982] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [25.81666666666667, 70.83333333333334, 1.0, 2.0, 0.5791974129476692, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 659425.0846081125, 659425.0846081125, 157275.1055801469]
[2019-03-23 11:22:31,983] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 11:22:31,987] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.31367850e-26 1.00000000e+00 1.31300778e-36 1.17447865e-29
 4.91367759e-36], sampled 0.31363464169741195
[2019-03-23 11:23:06,079] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.20475933], dtype=float32), -1.0934658]
[2019-03-23 11:23:06,080] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.24548984, 94.38319024833335, 1.0, 2.0, 0.3914569405594552, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 441996.3521112862, 441996.3521112862, 128896.4225866378]
[2019-03-23 11:23:06,083] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 11:23:06,085] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.4289821e-26 1.0000000e+00 1.4049810e-36 1.2498445e-29 5.2261949e-36], sampled 0.9820320012350809
[2019-03-23 11:23:13,937] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.20475933], dtype=float32), -1.0934658]
[2019-03-23 11:23:13,939] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.58333333333334, 70.16666666666667, 1.0, 2.0, 0.419525032247734, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 477342.3427918786, 477342.3427918789, 129715.2121157925]
[2019-03-23 11:23:13,939] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 11:23:13,941] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.4289821e-26 1.0000000e+00 1.4049810e-36 1.2498445e-29 5.2261949e-36], sampled 0.6910849674944278
[2019-03-23 11:23:24,492] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.20475933], dtype=float32), -1.0934658]
[2019-03-23 11:23:24,494] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [25.29132382, 79.39593779, 1.0, 2.0, 0.650814395637385, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 737799.6744270514, 737799.6744270511, 168716.4666680297]
[2019-03-23 11:23:24,497] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 11:23:24,502] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.5490495e-26 1.0000000e+00 1.4967816e-36 1.3103255e-29 5.6001339e-36], sampled 0.267229157452344
[2019-03-23 11:23:27,688] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.20475933], dtype=float32), -1.0934658]
[2019-03-23 11:23:27,690] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.31666666666667, 80.5, 1.0, 2.0, 0.3993059899883393, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 448076.2500747524, 448076.2500747521, 123837.2153176789]
[2019-03-23 11:23:27,690] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 11:23:27,695] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.4289821e-26 1.0000000e+00 1.4049810e-36 1.2498445e-29 5.2261949e-36], sampled 0.11477715497413088
[2019-03-23 11:23:28,459] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 11:23:28,517] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 11:23:28,558] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 11:23:28,798] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 11:23:28,810] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 11:23:29,827] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 1850000, evaluation results [1850000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 11:23:35,948] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.7291575e-34 1.0000000e+00 0.0000000e+00 8.8130416e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 11:23:35,958] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9436
[2019-03-23 11:23:35,965] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.1, 40.0, 1.0, 2.0, 0.6389061119094334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 708270.3975684975, 708270.3975684978, 145164.0292695678], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5847600.0000, 
sim time next is 5848200.0000, 
raw observation next is [26.1, 40.0, 1.0, 2.0, 0.6421722901902716, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 711875.3224069499, 711875.3224069496, 145528.8164544464], 
processed observation next is [1.0, 0.6956521739130435, 0.8227272727272728, 0.4, 1.0, 1.0, 0.5527153627378394, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.26365752681738885, 0.26365752681738874, 0.35494833281572297], 
reward next is 0.6451, 
noisyNet noise sample is [array([-0.8657347], dtype=float32), 0.6548036]. 
=============================================
[2019-03-23 11:23:40,479] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.7608786e-32 1.0000000e+00 0.0000000e+00 2.3687633e-33 0.0000000e+00], sum to 1.0000
[2019-03-23 11:23:40,487] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1020
[2019-03-23 11:23:40,491] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.48333333333333, 73.83333333333333, 1.0, 2.0, 0.2879291719326125, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 312644.3365806378, 312644.3365806378, 103640.8335646151], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6137400.0000, 
sim time next is 6138000.0000, 
raw observation next is [18.3, 75.0, 1.0, 2.0, 0.2880317909917877, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 312755.8000494815, 312755.8000494815, 103120.8446124918], 
processed observation next is [1.0, 0.043478260869565216, 0.4681818181818182, 0.75, 1.0, 1.0, 0.11003973873973463, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11583548149980796, 0.11583548149980796, 0.25151425515241904], 
reward next is 0.7485, 
noisyNet noise sample is [array([1.5842209], dtype=float32), -0.31327513]. 
=============================================
[2019-03-23 11:23:40,512] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[68.74978]
 [68.69254]
 [68.62311]
 [68.51751]
 [68.40828]], R is [[68.87102509]
 [68.92952728]
 [68.9861908 ]
 [69.04103088]
 [69.09420013]].
[2019-03-23 11:23:55,112] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.3823379e-30 1.0000000e+00 0.0000000e+00 8.8465133e-37 0.0000000e+00], sum to 1.0000
[2019-03-23 11:23:55,119] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4533
[2019-03-23 11:23:55,123] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.38333333333333, 95.5, 1.0, 2.0, 0.3675638670794872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 412109.5631085448, 412109.5631085448, 120933.5215786487], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6238200.0000, 
sim time next is 6238800.0000, 
raw observation next is [18.3, 96.0, 1.0, 2.0, 0.3678409194431637, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 412283.6134708462, 412283.6134708462, 120891.7617704321], 
processed observation next is [0.0, 0.21739130434782608, 0.4681818181818182, 0.96, 1.0, 1.0, 0.20980114930395463, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15269763461883193, 0.15269763461883193, 0.29485795553763927], 
reward next is 0.7051, 
noisyNet noise sample is [array([-0.05940903], dtype=float32), -0.498492]. 
=============================================
[2019-03-23 11:23:59,206] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.8919812e-29 1.0000000e+00 0.0000000e+00 1.1505039e-33 0.0000000e+00], sum to 1.0000
[2019-03-23 11:23:59,209] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9197
[2019-03-23 11:23:59,216] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.61666666666667, 85.33333333333334, 1.0, 2.0, 0.4782021685921423, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 545667.3540578359, 545667.3540578362, 138573.4002581129], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6322200.0000, 
sim time next is 6322800.0000, 
raw observation next is [22.53333333333333, 85.66666666666667, 1.0, 2.0, 0.4776892524667284, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 545084.637868731, 545084.6378687313, 138437.7834245601], 
processed observation next is [0.0, 0.17391304347826086, 0.6606060606060605, 0.8566666666666667, 1.0, 1.0, 0.34711156558341044, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20188319921064113, 0.2018831992106412, 0.3376531303038051], 
reward next is 0.6623, 
noisyNet noise sample is [array([-1.0216992], dtype=float32), 0.17957748]. 
=============================================
[2019-03-23 11:24:11,416] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.8348666e-30 1.0000000e+00 0.0000000e+00 4.5132777e-36 0.0000000e+00], sum to 1.0000
[2019-03-23 11:24:11,424] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6264
[2019-03-23 11:24:11,431] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.5, 54.0, 1.0, 2.0, 0.2706453624479536, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 293871.2551370434, 293871.2551370431, 84651.81325093997], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6547800.0000, 
sim time next is 6548400.0000, 
raw observation next is [19.4, 54.0, 1.0, 2.0, 0.2700592511002521, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 293234.6537843908, 293234.6537843905, 84144.02590101304], 
processed observation next is [1.0, 0.8260869565217391, 0.5181818181818181, 0.54, 1.0, 1.0, 0.08757406387531509, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10860542732755214, 0.10860542732755203, 0.20522933146588546], 
reward next is 0.7948, 
noisyNet noise sample is [array([-1.1959432], dtype=float32), 0.5412729]. 
=============================================
[2019-03-23 11:24:12,355] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.6443327e-32 1.0000000e+00 0.0000000e+00 3.7897479e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 11:24:12,361] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6595
[2019-03-23 11:24:12,366] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.4, 81.66666666666667, 1.0, 2.0, 0.2029459159756951, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 220345.4140405956, 220345.4140405954, 72707.6284050955], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6572400.0000, 
sim time next is 6573000.0000, 
raw observation next is [14.4, 81.33333333333333, 1.0, 2.0, 0.2026210099192241, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 219992.5725017779, 219992.5725017776, 72588.2713775575], 
processed observation next is [1.0, 0.043478260869565216, 0.29090909090909095, 0.8133333333333332, 1.0, 1.0, 0.0032762623990301165, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08147873055621403, 0.08147873055621394, 0.17704456433550608], 
reward next is 0.8230, 
noisyNet noise sample is [array([0.2630449], dtype=float32), -1.3278507]. 
=============================================
[2019-03-23 11:24:12,386] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[79.544716]
 [79.562416]
 [79.57831 ]
 [79.59051 ]
 [79.6069  ]], R is [[79.55001068]
 [79.57717133]
 [79.60377502]
 [79.62974548]
 [79.65496826]].
[2019-03-23 11:24:12,749] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.1696974e-33 1.0000000e+00 0.0000000e+00 7.0349287e-34 0.0000000e+00], sum to 1.0000
[2019-03-23 11:24:12,759] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7649
[2019-03-23 11:24:12,765] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.1, 67.0, 1.0, 2.0, 0.2231469456511012, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 242283.8346555578, 242283.8346555578, 74625.44941716586], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6566400.0000, 
sim time next is 6567000.0000, 
raw observation next is [15.81666666666667, 69.66666666666667, 1.0, 2.0, 0.2220422816768761, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 241084.1384045786, 241084.1384045788, 74669.809151459], 
processed observation next is [1.0, 0.0, 0.35530303030303045, 0.6966666666666668, 1.0, 1.0, 0.0275528520960951, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08929042163132542, 0.08929042163132549, 0.18212148573526588], 
reward next is 0.8179, 
noisyNet noise sample is [array([-0.48203772], dtype=float32), 1.6120504]. 
=============================================
[2019-03-23 11:24:12,783] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[80.89151]
 [80.97159]
 [80.97836]
 [80.98419]
 [80.9897 ]], R is [[80.78446198]
 [80.79460144]
 [80.80448151]
 [80.81386566]
 [80.82257843]].
[2019-03-23 11:24:16,854] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.5813889e-32 1.0000000e+00 0.0000000e+00 5.5685565e-31 0.0000000e+00], sum to 1.0000
[2019-03-23 11:24:16,862] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9028
[2019-03-23 11:24:16,870] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 87.0, 1.0, 2.0, 0.3500655896860268, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 389475.6455335013, 389475.645533501, 118126.1265674346], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6651000.0000, 
sim time next is 6651600.0000, 
raw observation next is [18.8, 87.0, 1.0, 2.0, 0.3492598017498975, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 388577.2600851674, 388577.2600851677, 118061.6929368505], 
processed observation next is [1.0, 1.0, 0.49090909090909096, 0.87, 1.0, 1.0, 0.18657475218737188, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1439175037352472, 0.1439175037352473, 0.2879553486264646], 
reward next is 0.7120, 
noisyNet noise sample is [array([0.40303263], dtype=float32), -0.22386217]. 
=============================================
[2019-03-23 11:24:18,735] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.1872278e-27 1.0000000e+00 1.3457751e-38 4.7712705e-26 2.6112053e-38], sum to 1.0000
[2019-03-23 11:24:18,747] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0144
[2019-03-23 11:24:18,750] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 84.0, 1.0, 2.0, 0.4832333009910278, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 540210.0958335458, 540210.0958335458, 130795.8864295273], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6687000.0000, 
sim time next is 6687600.0000, 
raw observation next is [19.2, 85.0, 1.0, 2.0, 0.5633957309684106, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 629379.4630743278, 629379.4630743274, 138826.7500405345], 
processed observation next is [1.0, 0.391304347826087, 0.509090909090909, 0.85, 1.0, 1.0, 0.45424466371051314, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.23310350484234363, 0.2331035048423435, 0.3386018293671573], 
reward next is 0.6614, 
noisyNet noise sample is [array([-2.1165411], dtype=float32), -1.5532196]. 
=============================================
[2019-03-23 11:24:18,926] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.7192832e-28 1.0000000e+00 0.0000000e+00 6.4487216e-34 0.0000000e+00], sum to 1.0000
[2019-03-23 11:24:18,936] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2983
[2019-03-23 11:24:18,940] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.1, 94.33333333333334, 1.0, 2.0, 0.4539479206820654, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 506537.9611651892, 506537.9611651892, 127605.1784369612], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6698400.0000, 
sim time next is 6699000.0000, 
raw observation next is [18.2, 93.66666666666666, 1.0, 2.0, 0.4682143176623104, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 522681.7710331297, 522681.7710331297, 129037.5563162307], 
processed observation next is [1.0, 0.5217391304347826, 0.4636363636363636, 0.9366666666666665, 1.0, 1.0, 0.335267897077888, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19358584112338137, 0.19358584112338137, 0.3147257471127578], 
reward next is 0.6853, 
noisyNet noise sample is [array([-0.148704], dtype=float32), 0.29009145]. 
=============================================
[2019-03-23 11:24:18,960] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[66.14171 ]
 [66.191666]
 [65.94256 ]
 [65.617065]
 [65.61639 ]], R is [[66.08086395]
 [66.10882568]
 [66.14079285]
 [66.15612793]
 [66.13478088]].
[2019-03-23 11:24:19,249] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-23 11:24:19,251] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 11:24:19,251] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 11:24:19,252] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 11:24:19,253] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 11:24:19,253] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:24:19,252] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:24:19,254] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:24:19,254] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 11:24:19,254] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:24:19,259] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:24:19,282] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run76
[2019-03-23 11:24:19,308] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run76
[2019-03-23 11:24:19,332] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run76
[2019-03-23 11:24:19,356] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run76
[2019-03-23 11:24:19,356] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run76
[2019-03-23 11:24:21,724] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.0872427]
[2019-03-23 11:24:21,724] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.0, 39.5, 1.0, 2.0, 0.6923010863515708, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 752066.2527857721, 752066.2527857721, 136747.2544038418]
[2019-03-23 11:24:21,725] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 11:24:21,727] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.1954151e-29 1.0000000e+00 0.0000000e+00 7.5921676e-33 0.0000000e+00], sampled 0.26738642546434266
[2019-03-23 11:24:36,693] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.0872427]
[2019-03-23 11:24:36,694] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.23333333333333, 72.33333333333333, 1.0, 2.0, 0.4813026857996467, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 549105.2319932334, 549105.2319932331, 142667.9671546241]
[2019-03-23 11:24:36,695] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 11:24:36,698] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.9510076e-28 1.0000000e+00 0.0000000e+00 9.0712276e-32 0.0000000e+00], sampled 0.7193083230072471
[2019-03-23 11:25:08,204] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.0872427]
[2019-03-23 11:25:08,206] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.98333333333333, 81.0, 1.0, 2.0, 0.5318199376602537, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 606066.1853494289, 606066.1853494289, 150701.773891644]
[2019-03-23 11:25:08,207] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 11:25:08,212] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.9510076e-28 1.0000000e+00 0.0000000e+00 9.0712276e-32 0.0000000e+00], sampled 0.8642258157879562
[2019-03-23 11:25:15,784] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.0872427]
[2019-03-23 11:25:15,785] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.08071814666667, 100.0, 1.0, 2.0, 0.4551111599737873, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 518782.3503237281, 518782.3503237281, 138785.3577593736]
[2019-03-23 11:25:15,787] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 11:25:15,790] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [6.9523242e-29 1.0000000e+00 0.0000000e+00 1.9326877e-32 0.0000000e+00], sampled 0.3706042065971571
[2019-03-23 11:25:16,878] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.0872427]
[2019-03-23 11:25:16,880] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.03950700666667, 79.79542707666667, 1.0, 2.0, 0.3478514444241741, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 377847.4897301742, 377847.4897301739, 118877.6854211681]
[2019-03-23 11:25:16,881] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 11:25:16,883] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.7652972e-29 1.0000000e+00 0.0000000e+00 1.2489895e-32 0.0000000e+00], sampled 0.6319172034751379
[2019-03-23 11:25:24,148] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.0872427]
[2019-03-23 11:25:24,149] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [26.95, 53.0, 1.0, 2.0, 0.5345501742446194, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 609165.6310501097, 609165.6310501093, 147325.4302462136]
[2019-03-23 11:25:24,151] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 11:25:24,154] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.2162537e-29 1.0000000e+00 0.0000000e+00 7.6467531e-33 0.0000000e+00], sampled 0.24672331017684557
[2019-03-23 11:25:33,666] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.0872427]
[2019-03-23 11:25:33,669] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.73685212, 90.61412888166667, 1.0, 2.0, 0.4230843847164776, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 481256.6643405573, 481256.6643405573, 134285.3274915341]
[2019-03-23 11:25:33,672] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 11:25:33,674] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.654767e-29 1.000000e+00 0.000000e+00 1.151264e-32 0.000000e+00], sampled 0.015112401893613958
[2019-03-23 11:25:56,096] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 11:25:56,546] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 11:25:56,667] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 11:25:56,726] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 11:25:56,754] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 11:25:57,772] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 1875000, evaluation results [1875000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 11:25:58,489] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.3255610e-27 1.0000000e+00 9.2886554e-38 8.1874489e-33 7.2556796e-38], sum to 1.0000
[2019-03-23 11:25:58,499] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0353
[2019-03-23 11:25:58,504] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.3, 93.0, 1.0, 2.0, 0.6931227233337288, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 775603.7608586504, 775603.7608586507, 154344.2009026215], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6708600.0000, 
sim time next is 6709200.0000, 
raw observation next is [18.3, 93.0, 1.0, 2.0, 0.7016773920105409, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 785168.143327624, 785168.1433276242, 155409.6080366018], 
processed observation next is [1.0, 0.6521739130434783, 0.4681818181818182, 0.93, 1.0, 1.0, 0.6270967400131761, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.29080301604726816, 0.2908030160472682, 0.37904782447951657], 
reward next is 0.6210, 
noisyNet noise sample is [array([-0.22153918], dtype=float32), -0.3144759]. 
=============================================
[2019-03-23 11:26:06,884] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.6154367e-27 1.0000000e+00 1.1134552e-37 3.4780884e-30 5.6765687e-38], sum to 1.0000
[2019-03-23 11:26:06,895] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6437
[2019-03-23 11:26:06,903] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.83333333333334, 59.33333333333334, 1.0, 2.0, 0.4738451890068294, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 540688.0024880238, 540688.0024880238, 138154.8452315489], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6868200.0000, 
sim time next is 6868800.0000, 
raw observation next is [27.2, 58.0, 1.0, 2.0, 0.4755893843142612, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 542650.38715759, 542650.3871575904, 138553.1559898105], 
processed observation next is [0.0, 0.5217391304347826, 0.8727272727272727, 0.58, 1.0, 1.0, 0.34448673039282646, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2009816248731815, 0.2009816248731816, 0.3379345268044159], 
reward next is 0.6621, 
noisyNet noise sample is [array([0.76042587], dtype=float32), 0.9112688]. 
=============================================
[2019-03-23 11:26:20,201] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.8124804e-27 1.0000000e+00 8.9049143e-38 1.5151248e-28 2.6263813e-37], sum to 1.0000
[2019-03-23 11:26:20,210] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1872
[2019-03-23 11:26:20,225] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.8, 84.5, 1.0, 2.0, 0.5749988569863258, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 646120.925078307, 646120.9250783067, 141728.884187987], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7120200.0000, 
sim time next is 7120800.0000, 
raw observation next is [20.0, 84.0, 1.0, 2.0, 0.6034091341217739, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 679130.6170095204, 679130.6170095206, 145463.2075697392], 
processed observation next is [1.0, 0.43478260869565216, 0.5454545454545454, 0.84, 1.0, 1.0, 0.5042614176522173, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2515298581516742, 0.25152985815167433, 0.35478831114570536], 
reward next is 0.6452, 
noisyNet noise sample is [array([-0.33719015], dtype=float32), -0.90590155]. 
=============================================
[2019-03-23 11:26:22,493] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.8471393e-33 1.0000000e+00 0.0000000e+00 7.0278936e-36 0.0000000e+00], sum to 1.0000
[2019-03-23 11:26:22,501] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6653
[2019-03-23 11:26:22,506] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.8, 70.0, 1.0, 2.0, 0.2369399373775547, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 257263.6620763142, 257263.6620763145, 79383.76766861684], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7166400.0000, 
sim time next is 7167000.0000, 
raw observation next is [16.7, 70.0, 1.0, 2.0, 0.2351140444747502, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 255280.6313778691, 255280.6313778688, 78806.1039423071], 
processed observation next is [1.0, 0.9565217391304348, 0.39545454545454545, 0.7, 1.0, 1.0, 0.04389255559343774, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09454838199180338, 0.09454838199180325, 0.19221000961538318], 
reward next is 0.8078, 
noisyNet noise sample is [array([-0.26069784], dtype=float32), -0.8268241]. 
=============================================
[2019-03-23 11:26:22,521] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[77.58475 ]
 [77.58613 ]
 [77.586586]
 [77.58633 ]
 [77.588936]], R is [[77.61503601]
 [77.6452713 ]
 [77.67369843]
 [77.70014954]
 [77.72424316]].
[2019-03-23 11:26:27,241] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.3033281e-34 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 11:26:27,250] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0963
[2019-03-23 11:26:27,254] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.2, 44.33333333333334, 1.0, 2.0, 0.7792605796257955, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 854092.1691922314, 854092.1691922317, 158823.5477456591], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7227600.0000, 
sim time next is 7228200.0000, 
raw observation next is [24.3, 44.66666666666666, 1.0, 2.0, 0.7769412797872727, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 853558.8635240407, 853558.8635240407, 159207.7011483223], 
processed observation next is [1.0, 0.6521739130434783, 0.740909090909091, 0.44666666666666655, 1.0, 1.0, 0.7211765997340908, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.31613291241631136, 0.31613291241631136, 0.38831146621542023], 
reward next is 0.6117, 
noisyNet noise sample is [array([-0.33119333], dtype=float32), -0.6213608]. 
=============================================
[2019-03-23 11:26:29,330] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.2188033e-31 1.0000000e+00 0.0000000e+00 9.4652937e-36 0.0000000e+00], sum to 1.0000
[2019-03-23 11:26:29,333] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6015
[2019-03-23 11:26:29,336] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.1, 61.0, 1.0, 2.0, 0.5559321823547516, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 606522.7279608664, 606522.7279608664, 132899.5700824411], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7293600.0000, 
sim time next is 7294200.0000, 
raw observation next is [21.46666666666667, 60.0, 1.0, 2.0, 0.5728402742297068, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 627591.7855693705, 627591.7855693705, 135395.5875219459], 
processed observation next is [1.0, 0.43478260869565216, 0.6121212121212122, 0.6, 1.0, 1.0, 0.46605034278713353, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2324414020627298, 0.2324414020627298, 0.33023314029742906], 
reward next is 0.6698, 
noisyNet noise sample is [array([0.25891653], dtype=float32), -0.18629432]. 
=============================================
[2019-03-23 11:26:33,174] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.05440594e-32 1.00000000e+00 0.00000000e+00 8.08017411e-36
 0.00000000e+00], sum to 1.0000
[2019-03-23 11:26:33,180] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7423
[2019-03-23 11:26:33,183] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 87.0, 1.0, 2.0, 0.3225343291772858, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 352277.3672893281, 352277.3672893284, 113437.9965026222], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7365600.0000, 
sim time next is 7366200.0000, 
raw observation next is [17.8, 86.5, 1.0, 2.0, 0.331395393904433, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 362186.8585258073, 362186.8585258073, 114150.7218365403], 
processed observation next is [1.0, 0.2608695652173913, 0.4454545454545455, 0.865, 1.0, 1.0, 0.16424424238054125, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1341432809354842, 0.1341432809354842, 0.278416394723269], 
reward next is 0.7216, 
noisyNet noise sample is [array([-0.46428072], dtype=float32), 1.561803]. 
=============================================
[2019-03-23 11:26:41,966] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.9147611e-31 1.0000000e+00 0.0000000e+00 2.0764658e-37 0.0000000e+00], sum to 1.0000
[2019-03-23 11:26:41,972] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2096
[2019-03-23 11:26:41,978] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.3, 69.83333333333333, 1.0, 2.0, 0.4507461102250096, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 514033.7668665426, 514033.7668665426, 134332.3530508752], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7506600.0000, 
sim time next is 7507200.0000, 
raw observation next is [24.2, 70.66666666666667, 1.0, 2.0, 0.4525117243922129, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 516082.6810059867, 516082.6810059867, 134589.2335200417], 
processed observation next is [0.0, 0.9130434782608695, 0.7363636363636363, 0.7066666666666667, 1.0, 1.0, 0.31563965549026607, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.191141733705921, 0.191141733705921, 0.32826642321961386], 
reward next is 0.6717, 
noisyNet noise sample is [array([0.28712016], dtype=float32), -1.1124419]. 
=============================================
[2019-03-23 11:26:46,394] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.1305827e-27 1.0000000e+00 9.8536831e-38 6.7618197e-32 4.1229209e-36], sum to 1.0000
[2019-03-23 11:26:46,400] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1996
[2019-03-23 11:26:46,414] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 93.5, 1.0, 2.0, 0.4369211946231585, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 496259.2049109844, 496259.2049109844, 130685.3644722929], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7613400.0000, 
sim time next is 7614000.0000, 
raw observation next is [20.0, 93.0, 1.0, 2.0, 0.4314909224533996, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 489901.6078623427, 489901.6078623427, 130002.1359837301], 
processed observation next is [1.0, 0.13043478260869565, 0.5454545454545454, 0.93, 1.0, 1.0, 0.28936365306674944, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1814450399490158, 0.1814450399490158, 0.3170783804481222], 
reward next is 0.6829, 
noisyNet noise sample is [array([2.2357225], dtype=float32), 3.0943298]. 
=============================================
[2019-03-23 11:26:46,430] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[67.10921]
 [67.10921]
 [67.10921]
 [67.10921]
 [67.10921]], R is [[67.12104034]
 [67.13108063]
 [67.13947296]
 [67.14528656]
 [67.13739014]].
[2019-03-23 11:26:47,270] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-23 11:26:47,270] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 11:26:47,271] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:26:47,273] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 11:26:47,275] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 11:26:47,278] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 11:26:47,280] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:26:47,280] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:26:47,282] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:26:47,274] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 11:26:47,285] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:26:47,309] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run77
[2019-03-23 11:26:47,335] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run77
[2019-03-23 11:26:47,336] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run77
[2019-03-23 11:26:47,380] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run77
[2019-03-23 11:26:47,407] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run77
[2019-03-23 11:27:06,581] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.1117538]
[2019-03-23 11:27:06,582] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [16.41666666666667, 82.66666666666667, 1.0, 2.0, 0.2678762028042244, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 290846.9686513425, 290846.9686513425, 94009.99152150842]
[2019-03-23 11:27:06,583] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 11:27:06,585] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [6.7753113e-28 1.0000000e+00 0.0000000e+00 1.9949291e-31 4.1271026e-38], sampled 0.08603184888759996
[2019-03-23 11:27:06,909] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.1117538]
[2019-03-23 11:27:06,911] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.88333333333333, 56.5, 1.0, 2.0, 0.3090061017000852, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 335516.2800250753, 335516.280025075, 107376.4784113269]
[2019-03-23 11:27:06,911] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 11:27:06,915] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [6.7753113e-28 1.0000000e+00 0.0000000e+00 1.9949291e-31 4.1271026e-38], sampled 0.6557490386553966
[2019-03-23 11:28:14,499] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.1117538]
[2019-03-23 11:28:14,500] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.71666666666667, 84.5, 1.0, 2.0, 0.4024637605571983, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 445380.4533892682, 445380.4533892678, 125824.395539256]
[2019-03-23 11:28:14,501] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 11:28:14,503] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [6.7753113e-28 1.0000000e+00 0.0000000e+00 1.9949291e-31 4.1271026e-38], sampled 0.36409668089534286
[2019-03-23 11:28:22,837] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.1117538]
[2019-03-23 11:28:22,839] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.3, 68.33333333333334, 1.0, 2.0, 0.2848285456543282, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 309276.4892525106, 309276.4892525109, 104475.127315812]
[2019-03-23 11:28:22,843] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 11:28:22,846] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [6.7753113e-28 1.0000000e+00 0.0000000e+00 1.9949291e-31 4.1271026e-38], sampled 0.27215139257725973
[2019-03-23 11:28:23,881] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 11:28:24,524] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 11:28:24,547] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 11:28:24,591] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.1117538]
[2019-03-23 11:28:24,592] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.88333333333333, 62.5, 1.0, 2.0, 0.3141204736553672, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 341070.9987468644, 341070.9987468647, 107478.1501723035]
[2019-03-23 11:28:24,592] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 11:28:24,593] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [6.7753113e-28 1.0000000e+00 0.0000000e+00 1.9949291e-31 4.1271026e-38], sampled 0.6840878198761746
[2019-03-23 11:28:24,673] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 11:28:25,039] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 11:28:26,059] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 1900000, evaluation results [1900000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 11:28:27,767] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:28:27,767] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:28:27,817] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run10
[2019-03-23 11:28:27,952] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.2006792e-21 1.0000000e+00 2.9416889e-29 6.4021412e-22 5.5619810e-29], sum to 1.0000
[2019-03-23 11:28:27,962] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8643
[2019-03-23 11:28:27,968] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.15, 59.0, 1.0, 2.0, 0.4697661562554377, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 535888.1966586174, 535888.1966586174, 138284.2978023632], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7666200.0000, 
sim time next is 7666800.0000, 
raw observation next is [26.96666666666667, 59.33333333333334, 1.0, 2.0, 0.4702787721036121, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 536552.4432304543, 536552.4432304543, 138109.2341814774], 
processed observation next is [1.0, 0.7391304347826086, 0.8621212121212122, 0.5933333333333334, 1.0, 1.0, 0.33784846512951505, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19872312712239049, 0.19872312712239049, 0.33685179068653026], 
reward next is 0.6631, 
noisyNet noise sample is [array([-1.6586033], dtype=float32), -1.1621476]. 
=============================================
[2019-03-23 11:28:30,460] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.5007130e-27 1.0000000e+00 0.0000000e+00 5.7371684e-33 3.6112759e-38], sum to 1.0000
[2019-03-23 11:28:30,467] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7503
[2019-03-23 11:28:30,472] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.45, 90.0, 1.0, 2.0, 0.3346431868647288, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 366543.4347967065, 366543.4347967068, 114670.8520966414], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7716600.0000, 
sim time next is 7717200.0000, 
raw observation next is [17.53333333333333, 88.0, 1.0, 2.0, 0.3367588664696569, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 367842.942318078, 367842.9423180783, 114465.6681057331], 
processed observation next is [1.0, 0.30434782608695654, 0.43333333333333324, 0.88, 1.0, 1.0, 0.17094858308707112, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13623812678447333, 0.13623812678447345, 0.2791845563554466], 
reward next is 0.7208, 
noisyNet noise sample is [array([-1.0158763], dtype=float32), 0.71119446]. 
=============================================
[2019-03-23 11:28:33,012] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.7224960e-33 1.0000000e+00 0.0000000e+00 1.9411641e-38 0.0000000e+00], sum to 1.0000
[2019-03-23 11:28:33,019] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1278
[2019-03-23 11:28:33,024] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 63.0, 1.0, 2.0, 0.2487411268572745, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 270080.6663177864, 270080.6663177864, 80483.633033743], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7768800.0000, 
sim time next is 7769400.0000, 
raw observation next is [17.51666666666667, 64.16666666666667, 1.0, 2.0, 0.247986710201251, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 269261.3013918719, 269261.3013918716, 80312.72204348199], 
processed observation next is [1.0, 0.9565217391304348, 0.43257575757575767, 0.6416666666666667, 1.0, 1.0, 0.05998338775156372, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09972640792291551, 0.0997264079229154, 0.1958846879109317], 
reward next is 0.8041, 
noisyNet noise sample is [array([1.1630415], dtype=float32), 2.0435066]. 
=============================================
[2019-03-23 11:28:33,895] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:28:33,895] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:28:33,936] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run10
[2019-03-23 11:28:34,537] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.3301817e-32 1.0000000e+00 0.0000000e+00 3.3325605e-34 0.0000000e+00], sum to 1.0000
[2019-03-23 11:28:34,545] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7770
[2019-03-23 11:28:34,552] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.3, 96.0, 1.0, 2.0, 0.203878668695625, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 221358.3664326669, 221358.3664326672, 73764.81849193096], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7797600.0000, 
sim time next is 7798200.0000, 
raw observation next is [13.48333333333333, 95.5, 1.0, 2.0, 0.2065023265737507, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 224207.6222087217, 224207.6222087214, 74462.3542343164], 
processed observation next is [1.0, 0.2608695652173913, 0.24924242424242413, 0.955, 1.0, 1.0, 0.00812790821718836, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08303986007730434, 0.08303986007730423, 0.18161549813247901], 
reward next is 0.8184, 
noisyNet noise sample is [array([1.0926406], dtype=float32), -0.49563414]. 
=============================================
[2019-03-23 11:28:36,974] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.4667562e-29 1.0000000e+00 0.0000000e+00 2.2440127e-30 0.0000000e+00], sum to 1.0000
[2019-03-23 11:28:36,981] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0613
[2019-03-23 11:28:36,987] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 68.0, 1.0, 2.0, 0.4796747567293181, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 520960.455207288, 520960.455207288, 124139.9303663625], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7808400.0000, 
sim time next is 7809000.0000, 
raw observation next is [19.68333333333333, 69.66666666666667, 1.0, 2.0, 0.5562051984454832, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 605109.004850988, 605109.004850988, 132398.7834760721], 
processed observation next is [1.0, 0.391304347826087, 0.5310606060606059, 0.6966666666666668, 1.0, 1.0, 0.44525649805685397, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22411444624110669, 0.22411444624110669, 0.3229238621367612], 
reward next is 0.6771, 
noisyNet noise sample is [array([1.5266845], dtype=float32), 0.7353174]. 
=============================================
[2019-03-23 11:28:37,016] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[74.292496]
 [74.292496]
 [74.292496]
 [74.292496]
 [74.292496]], R is [[74.22664642]
 [74.18160248]
 [74.14273071]
 [74.11315155]
 [74.09584045]].
[2019-03-23 11:28:40,464] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.8918617e-28 1.0000000e+00 0.0000000e+00 1.6128772e-30 3.3995532e-38], sum to 1.0000
[2019-03-23 11:28:40,471] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8430
[2019-03-23 11:28:40,478] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 211433.679677329, 211433.6796773287, 69934.0541956312], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 100800.0000, 
sim time next is 101400.0000, 
raw observation next is [13.0, 87.00000000000001, 1.0, 2.0, 0.2070469349687024, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 224799.0614036791, 224799.0614036794, 71286.06792038484], 
processed observation next is [1.0, 0.17391304347826086, 0.22727272727272727, 0.8700000000000001, 1.0, 1.0, 0.008808668710878001, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08325891163099226, 0.08325891163099237, 0.17386845834240205], 
reward next is 0.8261, 
noisyNet noise sample is [array([1.1917566], dtype=float32), -1.5727122]. 
=============================================
[2019-03-23 11:28:41,286] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.3286960e-24 1.0000000e+00 2.4057514e-35 1.0875140e-27 7.4229673e-35], sum to 1.0000
[2019-03-23 11:28:41,296] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3973
[2019-03-23 11:28:41,301] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.2, 94.5, 1.0, 2.0, 0.4315654349683655, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 490998.2215414611, 490998.2215414614, 130863.5122796603], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7939800.0000, 
sim time next is 7940400.0000, 
raw observation next is [20.1, 95.0, 1.0, 2.0, 0.4300967662978467, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 489226.2570896936, 489226.2570896933, 130622.1992960551], 
processed observation next is [1.0, 0.9130434782608695, 0.55, 0.95, 1.0, 1.0, 0.28762095787230835, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18119491003321986, 0.18119491003321972, 0.3185907299903783], 
reward next is 0.6814, 
noisyNet noise sample is [array([1.0499936], dtype=float32), 1.2902023]. 
=============================================
[2019-03-23 11:28:42,768] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:28:42,768] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:28:42,778] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run10
[2019-03-23 11:28:42,802] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:28:42,803] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:28:42,809] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:28:42,809] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:28:42,822] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run10
[2019-03-23 11:28:42,854] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run10
[2019-03-23 11:28:43,059] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:28:43,059] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:28:43,062] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run10
[2019-03-23 11:28:43,104] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:28:43,105] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:28:43,112] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:28:43,113] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:28:43,116] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:28:43,116] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:28:43,121] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run10
[2019-03-23 11:28:43,155] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run10
[2019-03-23 11:28:43,188] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:28:43,189] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:28:43,190] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run10
[2019-03-23 11:28:43,224] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:28:43,225] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:28:43,229] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:28:43,229] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:28:43,238] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:28:43,238] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:28:43,240] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run10
[2019-03-23 11:28:43,274] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:28:43,275] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:28:43,281] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run10
[2019-03-23 11:28:43,320] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run10
[2019-03-23 11:28:43,364] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run10
[2019-03-23 11:28:43,434] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run10
[2019-03-23 11:28:43,561] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:28:43,561] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:28:43,564] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run10
[2019-03-23 11:28:43,690] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:28:43,690] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:28:43,694] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run10
[2019-03-23 11:28:51,315] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.6302807e-34 1.0000000e+00 0.0000000e+00 3.4181782e-36 0.0000000e+00], sum to 1.0000
[2019-03-23 11:28:51,325] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6723
[2019-03-23 11:28:51,331] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.5, 74.5, 1.0, 2.0, 0.22582559641307, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 245192.9372653615, 245192.9372653618, 74010.20968543316], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 376200.0000, 
sim time next is 376800.0000, 
raw observation next is [14.66666666666667, 75.33333333333333, 1.0, 2.0, 0.2125060812246954, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 230727.6786211746, 230727.6786211746, 72815.23500315244], 
processed observation next is [1.0, 0.34782608695652173, 0.30303030303030315, 0.7533333333333333, 1.0, 1.0, 0.01563260153086922, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08545469578562022, 0.08545469578562022, 0.17759813415403033], 
reward next is 0.8224, 
noisyNet noise sample is [array([0.17670271], dtype=float32), 0.9080021]. 
=============================================
[2019-03-23 11:29:00,295] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.0686453e-31 1.0000000e+00 0.0000000e+00 2.6874507e-32 0.0000000e+00], sum to 1.0000
[2019-03-23 11:29:00,302] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0229
[2019-03-23 11:29:00,307] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 77.0, 1.0, 2.0, 0.2325307112831407, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 252474.9882886493, 252474.9882886496, 84834.08271490256], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 295200.0000, 
sim time next is 295800.0000, 
raw observation next is [17.33333333333334, 74.83333333333334, 1.0, 2.0, 0.2331349319348622, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 253131.2039698176, 253131.2039698179, 85412.07595776016], 
processed observation next is [0.0, 0.43478260869565216, 0.42424242424242453, 0.7483333333333334, 1.0, 1.0, 0.04141866491857774, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09375229776659912, 0.09375229776659923, 0.20832213648234185], 
reward next is 0.7917, 
noisyNet noise sample is [array([1.535299], dtype=float32), 1.7702986]. 
=============================================
[2019-03-23 11:29:13,507] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.7728052e-30 1.0000000e+00 0.0000000e+00 1.4634926e-36 0.0000000e+00], sum to 1.0000
[2019-03-23 11:29:13,515] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1469
[2019-03-23 11:29:13,518] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.33333333333333, 93.00000000000001, 1.0, 2.0, 0.2394556081054064, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 259995.8466719688, 259995.8466719685, 80025.66205556986], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 544200.0000, 
sim time next is 544800.0000, 
raw observation next is [14.66666666666667, 92.0, 1.0, 2.0, 0.2345460270961787, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 254663.7316207033, 254663.7316207036, 81002.76671684775], 
processed observation next is [1.0, 0.30434782608695654, 0.30303030303030315, 0.92, 1.0, 1.0, 0.043182533870223354, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09431990060026048, 0.09431990060026059, 0.19756772369962866], 
reward next is 0.8024, 
noisyNet noise sample is [array([-1.1176517], dtype=float32), 0.8873514]. 
=============================================
[2019-03-23 11:29:16,620] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-23 11:29:16,621] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 11:29:16,622] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 11:29:16,623] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:29:16,623] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 11:29:16,623] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 11:29:16,624] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 11:29:16,626] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:29:16,623] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:29:16,627] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:29:16,626] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:29:16,650] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run78
[2019-03-23 11:29:16,676] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run78
[2019-03-23 11:29:16,701] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run78
[2019-03-23 11:29:16,734] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run78
[2019-03-23 11:29:16,736] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run78
[2019-03-23 11:29:24,135] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.1042482]
[2019-03-23 11:29:24,136] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.3204101, 70.51883224, 1.0, 2.0, 0.4256923760029991, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 470282.4990318527, 470282.4990318527, 127508.390037962]
[2019-03-23 11:29:24,137] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 11:29:24,139] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.981160e-31 1.000000e+00 0.000000e+00 5.021443e-35 0.000000e+00], sampled 0.7650937145918064
[2019-03-23 11:29:50,903] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.1042482]
[2019-03-23 11:29:50,904] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [27.3, 61.66666666666667, 1.0, 2.0, 0.5035255743522263, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695011, 573520.2832875008, 573520.2832875005, 147572.8594706398]
[2019-03-23 11:29:50,906] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 11:29:50,908] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.981160e-31 1.000000e+00 0.000000e+00 5.021443e-35 0.000000e+00], sampled 0.2727341483603617
[2019-03-23 11:30:14,535] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.1042482]
[2019-03-23 11:30:14,537] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.14102558, 90.03945254, 1.0, 2.0, 0.3692471751123668, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 417614.4706076334, 417614.4706076334, 127354.7322452361]
[2019-03-23 11:30:14,538] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 11:30:14,540] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.981160e-31 1.000000e+00 0.000000e+00 5.021443e-35 0.000000e+00], sampled 0.43733444526080023
[2019-03-23 11:30:54,476] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 11:30:54,509] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 11:30:54,510] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 11:30:54,600] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 11:30:54,631] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 11:30:55,647] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 1925000, evaluation results [1925000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 11:30:57,935] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.0664497e-28 1.0000000e+00 0.0000000e+00 1.9474681e-31 0.0000000e+00], sum to 1.0000
[2019-03-23 11:30:57,944] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0063
[2019-03-23 11:30:57,949] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.33333333333334, 50.33333333333334, 1.0, 2.0, 0.6260847628300025, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 704845.0596738323, 704845.0596738323, 148220.8071512055], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 660000.0000, 
sim time next is 660600.0000, 
raw observation next is [25.5, 50.5, 1.0, 2.0, 0.6092943210146696, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 686886.4247968072, 686886.4247968072, 146710.6883349566], 
processed observation next is [1.0, 0.6521739130434783, 0.7954545454545454, 0.505, 1.0, 1.0, 0.511617901268337, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.25440237955437306, 0.25440237955437306, 0.3578309471584307], 
reward next is 0.6422, 
noisyNet noise sample is [array([0.16021487], dtype=float32), -0.11136839]. 
=============================================
[2019-03-23 11:31:02,259] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.63782087e-27 1.00000000e+00 5.70007140e-37 2.49052910e-29
 1.18922634e-35], sum to 1.0000
[2019-03-23 11:31:02,267] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6448
[2019-03-23 11:31:02,273] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 69.0, 1.0, 2.0, 0.7493087616036567, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 852538.7797764511, 852538.7797764511, 169523.354152688], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 725400.0000, 
sim time next is 726000.0000, 
raw observation next is [23.66666666666667, 69.0, 1.0, 2.0, 0.8367092919089806, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 952833.2077909847, 952833.2077909844, 183408.7702277178], 
processed observation next is [1.0, 0.391304347826087, 0.7121212121212124, 0.69, 1.0, 1.0, 0.7958866148862256, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.35290118807073506, 0.35290118807073495, 0.4473384639700434], 
reward next is 0.5527, 
noisyNet noise sample is [array([-0.7382904], dtype=float32), -0.053267144]. 
=============================================
[2019-03-23 11:31:02,292] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[62.459515]
 [62.459515]
 [62.459515]
 [62.459515]
 [62.459515]], R is [[62.38758469]
 [62.3502388 ]
 [62.31164932]
 [62.24958801]
 [62.17961502]].
[2019-03-23 11:31:02,910] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.0182925e-24 1.0000000e+00 5.6512391e-33 1.7825372e-29 6.5413630e-33], sum to 1.0000
[2019-03-23 11:31:02,919] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2483
[2019-03-23 11:31:02,925] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 100.0, 1.0, 2.0, 0.5526871443968957, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 602276.5510630984, 602276.5510630984, 132364.0756357172], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 993000.0000, 
sim time next is 993600.0000, 
raw observation next is [16.0, 100.0, 1.0, 2.0, 0.5488476133250303, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 598111.4422055962, 598111.4422055962, 131999.3888523128], 
processed observation next is [1.0, 0.5217391304347826, 0.36363636363636365, 1.0, 1.0, 1.0, 0.43605951665628784, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22152275637244306, 0.22152275637244306, 0.32194972890808005], 
reward next is 0.6781, 
noisyNet noise sample is [array([0.54479486], dtype=float32), 0.18171363]. 
=============================================
[2019-03-23 11:31:05,442] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.8390795e-30 1.0000000e+00 0.0000000e+00 1.0322722e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 11:31:05,451] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0093
[2019-03-23 11:31:05,455] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.66666666666666, 89.0, 1.0, 2.0, 0.4161237759954886, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 472736.6435995237, 472736.6435995237, 128732.1036215485], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 802200.0000, 
sim time next is 802800.0000, 
raw observation next is [21.0, 88.0, 1.0, 2.0, 0.4232138994983671, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 481346.8756731279, 481346.8756731282, 129896.0416569622], 
processed observation next is [0.0, 0.30434782608695654, 0.5909090909090909, 0.88, 1.0, 1.0, 0.2790173743729588, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.178276620619677, 0.1782766206196771, 0.3168196137974688], 
reward next is 0.6832, 
noisyNet noise sample is [array([-0.5769328], dtype=float32), -0.6707926]. 
=============================================
[2019-03-23 11:31:12,050] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.5012037e-26 1.0000000e+00 6.0545353e-38 5.1989995e-26 2.7949458e-38], sum to 1.0000
[2019-03-23 11:31:12,058] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4269
[2019-03-23 11:31:12,063] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 78.0, 1.0, 2.0, 0.427662515954193, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 485732.4698809683, 485732.4698809683, 129764.5376269299], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 918600.0000, 
sim time next is 919200.0000, 
raw observation next is [22.0, 78.0, 1.0, 2.0, 0.4246114251770631, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 482248.1098392322, 482248.1098392325, 129451.5360757826], 
processed observation next is [0.0, 0.6521739130434783, 0.6363636363636364, 0.78, 1.0, 1.0, 0.2807642814713288, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17861041105156747, 0.1786104110515676, 0.3157354538433722], 
reward next is 0.6843, 
noisyNet noise sample is [array([0.5464018], dtype=float32), -2.2069173]. 
=============================================
[2019-03-23 11:31:12,395] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.7472202e-30 1.0000000e+00 0.0000000e+00 3.9526594e-32 0.0000000e+00], sum to 1.0000
[2019-03-23 11:31:12,401] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5153
[2019-03-23 11:31:12,405] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 97.0, 1.0, 2.0, 0.3749921202029073, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 419469.2839158336, 419469.2839158339, 121110.6124046775], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1290600.0000, 
sim time next is 1291200.0000, 
raw observation next is [18.0, 96.0, 1.0, 2.0, 0.3725725530435011, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 416158.528658566, 416158.5286585663, 120637.4910260988], 
processed observation next is [1.0, 0.9565217391304348, 0.45454545454545453, 0.96, 1.0, 1.0, 0.21571569130437637, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1541327883920615, 0.1541327883920616, 0.29423778299048486], 
reward next is 0.7058, 
noisyNet noise sample is [array([-0.55028576], dtype=float32), -0.6000592]. 
=============================================
[2019-03-23 11:31:22,970] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.6123302e-29 1.0000000e+00 0.0000000e+00 2.9874702e-34 0.0000000e+00], sum to 1.0000
[2019-03-23 11:31:22,980] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5849
[2019-03-23 11:31:22,984] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 88.0, 1.0, 2.0, 0.3205560426927667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 352763.7268760317, 352763.7268760314, 114271.4958762545], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1132800.0000, 
sim time next is 1133400.0000, 
raw observation next is [18.0, 88.0, 1.0, 2.0, 0.3207379444873605, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 352958.8204428829, 352958.8204428826, 114282.7270791837], 
processed observation next is [1.0, 0.08695652173913043, 0.45454545454545453, 0.88, 1.0, 1.0, 0.15092243060920058, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13072548905291959, 0.13072548905291947, 0.27873835872971636], 
reward next is 0.7213, 
noisyNet noise sample is [array([-1.25623], dtype=float32), 0.79410046]. 
=============================================
[2019-03-23 11:31:30,864] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.0178851e-25 1.0000000e+00 1.1021657e-33 2.8098316e-27 6.0159883e-33], sum to 1.0000
[2019-03-23 11:31:30,873] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3755
[2019-03-23 11:31:30,884] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1462701.777451565 W.
[2019-03-23 11:31:30,888] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.0, 58.0, 1.0, 2.0, 0.4333110248807789, 1.0, 2.0, 0.4333110248807789, 1.0, 2.0, 0.8753334546030836, 6.911199999999999, 6.9112, 77.3421103, 1462701.777451565, 1462701.777451565, 322894.9089213598], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1267200.0000, 
sim time next is 1267800.0000, 
raw observation next is [27.83333333333334, 58.66666666666667, 1.0, 2.0, 0.5609844625146795, 1.0, 2.0, 0.5609844625146795, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1267601.028924881, 1267601.02892488, 249814.0448560975], 
processed observation next is [1.0, 0.6956521739130435, 0.9015151515151518, 0.5866666666666667, 1.0, 1.0, 0.4512305781433493, 1.0, 1.0, 0.4512305781433493, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.46948186256477076, 0.4694818625647704, 0.609302548429506], 
reward next is 0.3907, 
noisyNet noise sample is [array([0.37473163], dtype=float32), 0.40608886]. 
=============================================
[2019-03-23 11:31:34,584] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.7618130e-26 1.0000000e+00 4.8100437e-36 2.9475005e-26 1.9689945e-33], sum to 1.0000
[2019-03-23 11:31:34,596] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1924
[2019-03-23 11:31:34,605] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1224312.373783951 W.
[2019-03-23 11:31:34,609] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.66666666666667, 89.0, 1.0, 2.0, 0.5977784479514696, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9810183093937787, 6.911199999999999, 6.9112, 77.32846341838642, 1224312.373783951, 1224312.373783951, 280564.7575243615], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1330800.0000, 
sim time next is 1331400.0000, 
raw observation next is [23.83333333333333, 89.0, 1.0, 2.0, 0.5494351519515365, 1.0, 1.0, 0.5494351519515365, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846344338533, 1235502.883699339, 1235502.883699339, 248172.072569262], 
processed observation next is [1.0, 0.391304347826087, 0.7196969696969695, 0.89, 1.0, 1.0, 0.43679393993942056, 1.0, 0.5, 0.43679393993942056, 0.0, 0.5, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129196304, 0.45759366062938484, 0.45759366062938484, 0.6052977379738098], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.36477643], dtype=float32), -1.2711139]. 
=============================================
[2019-03-23 11:31:36,701] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.6478383e-25 1.0000000e+00 4.6017673e-36 5.8832284e-31 7.5246583e-36], sum to 1.0000
[2019-03-23 11:31:36,708] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7417
[2019-03-23 11:31:36,713] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4914858717308978, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 560761.9157095308, 560761.9157095308, 140508.8365591319], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1384800.0000, 
sim time next is 1385400.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.4900630407809853, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 559137.8979041154, 559137.8979041151, 140344.7483375675], 
processed observation next is [0.0, 0.0, 0.5909090909090909, 1.0, 1.0, 1.0, 0.3625788009762316, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20708811033485755, 0.20708811033485747, 0.3423042642379695], 
reward next is 0.6577, 
noisyNet noise sample is [array([-0.86719507], dtype=float32), -1.790041]. 
=============================================
[2019-03-23 11:31:36,813] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.058929e-28 1.000000e+00 0.000000e+00 6.324605e-31 0.000000e+00], sum to 1.0000
[2019-03-23 11:31:36,815] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2495
[2019-03-23 11:31:36,819] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.490379154807042, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 559498.8892290741, 559498.8892290745, 140380.5317260057], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1389000.0000, 
sim time next is 1389600.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.4900668913768946, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 559142.439666166, 559142.439666166, 140344.6633350509], 
processed observation next is [0.0, 0.08695652173913043, 0.5909090909090909, 1.0, 1.0, 1.0, 0.3625836142211182, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20708979246895035, 0.20708979246895035, 0.3423040569147583], 
reward next is 0.6577, 
noisyNet noise sample is [array([0.96910757], dtype=float32), -0.39463696]. 
=============================================
[2019-03-23 11:31:39,858] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.9569871e-27 1.0000000e+00 1.7000773e-38 4.8426299e-29 5.6365013e-37], sum to 1.0000
[2019-03-23 11:31:39,866] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8359
[2019-03-23 11:31:39,874] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.486770813360034, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 555379.8039080298, 555379.8039080298, 139967.5530452713], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1444200.0000, 
sim time next is 1444800.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.4879790531842348, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 556758.9177535077, 556758.917753508, 140106.1409645511], 
processed observation next is [0.0, 0.7391304347826086, 0.5909090909090909, 1.0, 1.0, 1.0, 0.3599738164802935, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20620700657537325, 0.20620700657537333, 0.3417222950354905], 
reward next is 0.6583, 
noisyNet noise sample is [array([1.6386561], dtype=float32), -0.11006186]. 
=============================================
[2019-03-23 11:31:40,015] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.7296418e-31 1.0000000e+00 0.0000000e+00 1.2279317e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 11:31:40,025] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1980
[2019-03-23 11:31:40,030] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 94.0, 1.0, 2.0, 0.4626643987472182, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 527737.4690593651, 527737.4690593653, 135829.1351206088], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1450800.0000, 
sim time next is 1451400.0000, 
raw observation next is [21.0, 94.00000000000001, 1.0, 2.0, 0.4607588966697403, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 525533.8270011899, 525533.8270011899, 135556.4977247802], 
processed observation next is [0.0, 0.8260869565217391, 0.5909090909090909, 0.9400000000000002, 1.0, 1.0, 0.32594862083717535, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19464215814858887, 0.19464215814858887, 0.330625604206781], 
reward next is 0.6694, 
noisyNet noise sample is [array([0.23981735], dtype=float32), 0.14076845]. 
=============================================
[2019-03-23 11:31:45,206] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-23 11:31:45,207] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 11:31:45,208] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:31:45,209] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 11:31:45,209] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 11:31:45,210] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 11:31:45,210] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 11:31:45,211] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:31:45,212] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:31:45,212] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:31:45,216] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:31:45,235] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run79
[2019-03-23 11:31:45,260] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run79
[2019-03-23 11:31:45,287] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run79
[2019-03-23 11:31:45,309] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run79
[2019-03-23 11:31:45,311] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run79
[2019-03-23 11:32:02,423] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.0978459]
[2019-03-23 11:32:02,425] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.05640972, 100.0, 1.0, 2.0, 0.38956544656937, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 438014.7213698892, 438014.7213698892, 127734.0731470634]
[2019-03-23 11:32:02,426] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 11:32:02,429] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [7.2169837e-29 1.0000000e+00 0.0000000e+00 1.8030444e-32 0.0000000e+00], sampled 0.9029867180049957
[2019-03-23 11:32:15,718] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.0978459]
[2019-03-23 11:32:15,719] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [28.20354788, 49.99305383, 1.0, 2.0, 0.4459208536474827, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 508542.4201997574, 508542.4201997574, 138268.7851997302]
[2019-03-23 11:32:15,720] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 11:32:15,723] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [7.2169837e-29 1.0000000e+00 0.0000000e+00 1.8030444e-32 0.0000000e+00], sampled 0.9449066034062275
[2019-03-23 11:32:27,946] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.0978459]
[2019-03-23 11:32:27,947] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.27107184833333, 66.16099818500001, 1.0, 2.0, 0.4615421684391996, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 512226.3417187619, 512226.3417187615, 131538.9962344893]
[2019-03-23 11:32:27,949] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 11:32:27,951] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [7.2169837e-29 1.0000000e+00 0.0000000e+00 1.8030444e-32 0.0000000e+00], sampled 0.07548554962130816
[2019-03-23 11:32:30,869] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.0978459]
[2019-03-23 11:32:30,870] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.43333333333333, 86.66666666666667, 1.0, 2.0, 0.3674818912613186, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 412054.5635744286, 412054.5635744286, 125266.6398163695]
[2019-03-23 11:32:30,871] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 11:32:30,874] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [7.2169837e-29 1.0000000e+00 0.0000000e+00 1.8030444e-32 0.0000000e+00], sampled 0.989865112309842
[2019-03-23 11:32:53,109] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.0978459]
[2019-03-23 11:32:53,111] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [15.97109976, 75.612489, 1.0, 2.0, 0.2510296226954009, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 272551.6230458522, 272551.6230458518, 85434.74920076723]
[2019-03-23 11:32:53,114] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 11:32:53,117] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [7.2169837e-29 1.0000000e+00 0.0000000e+00 1.8030444e-32 0.0000000e+00], sampled 0.19388253991669635
[2019-03-23 11:33:19,519] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.0978459]
[2019-03-23 11:33:19,521] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [16.38333333333333, 69.5, 1.0, 2.0, 0.2192692858757233, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 238061.4879481518, 238061.4879481515, 80367.71393811479]
[2019-03-23 11:33:19,522] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 11:33:19,526] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [7.2169837e-29 1.0000000e+00 0.0000000e+00 1.8030444e-32 0.0000000e+00], sampled 0.14247346641657266
[2019-03-23 11:33:22,307] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 11:33:22,514] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 11:33:22,667] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 11:33:22,747] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 11:33:22,871] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 11:33:23,891] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 1950000, evaluation results [1950000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 11:33:26,749] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.6878201e-24 1.0000000e+00 3.5792337e-33 6.2903950e-22 2.9700425e-32], sum to 1.0000
[2019-03-23 11:33:26,757] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8960
[2019-03-23 11:33:26,762] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 74.0, 1.0, 2.0, 0.9114804700348316, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1040598.732407579, 1040598.732407579, 200822.9693270464], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1594800.0000, 
sim time next is 1595400.0000, 
raw observation next is [24.33333333333333, 72.5, 1.0, 2.0, 0.8576212164692903, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 979050.6737556269, 979050.6737556269, 191634.0648870631], 
processed observation next is [1.0, 0.4782608695652174, 0.7424242424242422, 0.725, 1.0, 1.0, 0.8220265205866129, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3626113606502322, 0.3626113606502322, 0.4674001582611295], 
reward next is 0.5326, 
noisyNet noise sample is [array([-1.6110814], dtype=float32), -0.80947256]. 
=============================================
[2019-03-23 11:33:37,300] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.1835725e-34 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 11:33:37,314] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6077
[2019-03-23 11:33:37,321] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.5, 47.5, 1.0, 2.0, 0.2518263007381976, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 273431.4593916335, 273431.4593916332, 76676.36752505889], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1794600.0000, 
sim time next is 1795200.0000, 
raw observation next is [18.33333333333334, 48.0, 1.0, 2.0, 0.2466270707702944, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 267784.6131148034, 267784.6131148034, 75996.06458628632], 
processed observation next is [1.0, 0.782608695652174, 0.46969696969696995, 0.48, 1.0, 1.0, 0.05828383846286797, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09917948633881607, 0.09917948633881607, 0.1853562550885032], 
reward next is 0.8146, 
noisyNet noise sample is [array([-0.5752434], dtype=float32), 0.6918164]. 
=============================================
[2019-03-23 11:33:38,837] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.3188955e-33 1.0000000e+00 0.0000000e+00 2.1872409e-33 0.0000000e+00], sum to 1.0000
[2019-03-23 11:33:38,845] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0470
[2019-03-23 11:33:38,852] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [10.33333333333333, 97.0, 1.0, 2.0, 0.3882536384568917, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 421627.648267974, 421627.648267974, 86219.48470332305], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1828200.0000, 
sim time next is 1828800.0000, 
raw observation next is [10.0, 100.0, 1.0, 2.0, 0.3879793923443604, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 421329.6991118498, 421329.6991118498, 86096.15754941243], 
processed observation next is [1.0, 0.17391304347826086, 0.09090909090909091, 1.0, 1.0, 1.0, 0.23497424043045048, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15604803670809253, 0.15604803670809253, 0.2099906281692986], 
reward next is 0.7900, 
noisyNet noise sample is [array([-0.4408182], dtype=float32), -1.4076312]. 
=============================================
[2019-03-23 11:33:39,241] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.610095e-31 1.000000e+00 0.000000e+00 7.821542e-36 0.000000e+00], sum to 1.0000
[2019-03-23 11:33:39,250] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2885
[2019-03-23 11:33:39,257] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.16666666666667, 62.0, 1.0, 2.0, 0.395563315848669, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 429569.1670900236, 429569.1670900236, 97277.38255014698], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1847400.0000, 
sim time next is 1848000.0000, 
raw observation next is [18.33333333333334, 60.0, 1.0, 2.0, 0.3848588570391791, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 417939.469343954, 417939.4693439543, 95898.0679730134], 
processed observation next is [1.0, 0.391304347826087, 0.46969696969696995, 0.6, 1.0, 1.0, 0.23107357129897385, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1547923960533163, 0.1547923960533164, 0.2338977267634473], 
reward next is 0.7661, 
noisyNet noise sample is [array([-0.68984723], dtype=float32), -0.8778354]. 
=============================================
[2019-03-23 11:33:39,275] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[77.67051]
 [77.67051]
 [77.67051]
 [77.67051]
 [77.67051]], R is [[77.65990448]
 [77.6460495 ]
 [77.64144135]
 [77.64321899]
 [77.64899445]].
[2019-03-23 11:33:44,201] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.2096442e-26 1.0000000e+00 4.6155659e-37 2.6313146e-30 1.2018173e-36], sum to 1.0000
[2019-03-23 11:33:44,211] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9910
[2019-03-23 11:33:44,214] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333334, 81.33333333333334, 1.0, 2.0, 0.9304901413795164, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1062092.844018305, 1062092.844018305, 205404.9542256168], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1935600.0000, 
sim time next is 1936200.0000, 
raw observation next is [23.66666666666666, 79.66666666666666, 1.0, 2.0, 0.9804126522043618, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1118944.814137797, 1118944.814137797, 215056.5622984574], 
processed observation next is [1.0, 0.391304347826087, 0.7121212121212118, 0.7966666666666665, 1.0, 1.0, 0.9755158152554522, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.41442400523622114, 0.41442400523622114, 0.5245282007279449], 
reward next is 0.4755, 
noisyNet noise sample is [array([2.0277162], dtype=float32), -1.2675214]. 
=============================================
[2019-03-23 11:33:47,638] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.468537e-32 1.000000e+00 0.000000e+00 3.179380e-35 0.000000e+00], sum to 1.0000
[2019-03-23 11:33:47,646] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8507
[2019-03-23 11:33:47,653] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.66666666666667, 73.66666666666667, 1.0, 2.0, 0.2335806288718284, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 253615.2550546222, 253615.2550546222, 80463.39699358797], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2006400.0000, 
sim time next is 2007000.0000, 
raw observation next is [16.5, 74.5, 1.0, 2.0, 0.2318049515034346, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 251686.775837353, 251686.775837353, 79979.97080414672], 
processed observation next is [0.0, 0.21739130434782608, 0.38636363636363635, 0.745, 1.0, 1.0, 0.03975618937929325, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09321732438420481, 0.09321732438420481, 0.19507309952230908], 
reward next is 0.8049, 
noisyNet noise sample is [array([-2.4311006], dtype=float32), 0.60044855]. 
=============================================
[2019-03-23 11:33:47,681] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[76.84505]
 [76.84505]
 [76.84505]
 [76.84505]
 [76.84505]], R is [[76.88152313]
 [76.91645813]
 [76.9499054 ]
 [76.98199463]
 [77.01365662]].
[2019-03-23 11:33:48,063] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.6683837e-31 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 11:33:48,071] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0362
[2019-03-23 11:33:48,075] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.5, 74.5, 1.0, 2.0, 0.2297860477742447, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 249494.149261091, 249494.1492610913, 79724.93259951092], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2010600.0000, 
sim time next is 2011200.0000, 
raw observation next is [16.66666666666666, 73.66666666666667, 1.0, 2.0, 0.2319022492918302, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 251792.4461660622, 251792.4461660625, 80246.44794003424], 
processed observation next is [0.0, 0.2608695652173913, 0.39393939393939365, 0.7366666666666667, 1.0, 1.0, 0.03987781161478774, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.093256461542986, 0.09325646154298611, 0.19572304375618108], 
reward next is 0.8043, 
noisyNet noise sample is [array([0.14995094], dtype=float32), 0.29525858]. 
=============================================
[2019-03-23 11:33:51,356] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.5586679e-30 1.0000000e+00 0.0000000e+00 3.0607966e-30 0.0000000e+00], sum to 1.0000
[2019-03-23 11:33:51,366] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2537
[2019-03-23 11:33:51,372] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.5, 71.0, 1.0, 2.0, 0.2480047927097266, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 269280.9406202978, 269280.9406202978, 84764.96806948456], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2075400.0000, 
sim time next is 2076000.0000, 
raw observation next is [17.0, 74.66666666666667, 1.0, 2.0, 0.2424932347551682, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 263294.9303345646, 263294.9303345646, 83964.44476636783], 
processed observation next is [0.0, 0.0, 0.4090909090909091, 0.7466666666666667, 1.0, 1.0, 0.053116543443960246, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09751664086465354, 0.09751664086465354, 0.20479132869845812], 
reward next is 0.7952, 
noisyNet noise sample is [array([0.783889], dtype=float32), -1.0034724]. 
=============================================
[2019-03-23 11:33:51,392] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[78.16822]
 [78.16822]
 [78.16822]
 [78.16822]
 [78.16822]], R is [[78.18174744]
 [78.19319153]
 [78.20294952]
 [78.2115097 ]
 [78.21965027]].
[2019-03-23 11:33:53,577] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.1820185e-30 1.0000000e+00 0.0000000e+00 1.4949211e-29 0.0000000e+00], sum to 1.0000
[2019-03-23 11:33:53,583] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2435
[2019-03-23 11:33:53,590] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.35, 56.0, 1.0, 2.0, 0.3380947532414459, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 376135.883429849, 376135.883429849, 117180.0699975291], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2111400.0000, 
sim time next is 2112000.0000, 
raw observation next is [23.46666666666667, 55.66666666666667, 1.0, 2.0, 0.3403671723280475, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 378938.4845897508, 378938.4845897511, 117474.1667605072], 
processed observation next is [0.0, 0.43478260869565216, 0.7030303030303031, 0.5566666666666668, 1.0, 1.0, 0.17545896541005931, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14034758688509288, 0.140347586885093, 0.28652235795245656], 
reward next is 0.7135, 
noisyNet noise sample is [array([-1.8840314], dtype=float32), 0.51437515]. 
=============================================
[2019-03-23 11:33:53,617] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[75.10999]
 [75.10999]
 [75.10999]
 [75.10999]
 [75.10999]], R is [[75.07237244]
 [75.0358429 ]
 [75.00038147]
 [74.96599579]
 [74.93312073]].
[2019-03-23 11:34:00,450] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0343488e-29 1.0000000e+00 0.0000000e+00 4.6032270e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 11:34:00,457] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5307
[2019-03-23 11:34:00,465] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 73.0, 1.0, 2.0, 0.4048566990355734, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 457572.1735903056, 457572.1735903053, 126041.103417309], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2222400.0000, 
sim time next is 2223000.0000, 
raw observation next is [22.0, 73.0, 1.0, 2.0, 0.3891277333430141, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 439636.2734513578, 439636.2734513578, 124515.3981943815], 
processed observation next is [1.0, 0.7391304347826086, 0.6363636363636364, 0.73, 1.0, 1.0, 0.2364096666787676, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16282824942642882, 0.16282824942642882, 0.30369609315702806], 
reward next is 0.6963, 
noisyNet noise sample is [array([0.6116718], dtype=float32), 1.0081798]. 
=============================================
[2019-03-23 11:34:00,484] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[69.883064]
 [69.883064]
 [69.883064]
 [69.883064]
 [69.883064]], R is [[69.88054657]
 [69.87432098]
 [69.83430481]
 [69.70081329]
 [69.57064819]].
[2019-03-23 11:34:03,844] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.51289302e-31 1.00000000e+00 0.00000000e+00 1.09568115e-32
 0.00000000e+00], sum to 1.0000
[2019-03-23 11:34:03,853] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1892
[2019-03-23 11:34:03,857] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 49.0, 1.0, 2.0, 0.5024452479352619, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 545704.6885190962, 545704.6885190962, 108260.9432683935], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2296200.0000, 
sim time next is 2296800.0000, 
raw observation next is [20.0, 49.0, 1.0, 2.0, 0.4672807354687312, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 507492.6517551589, 507492.6517551589, 104494.8315107992], 
processed observation next is [1.0, 0.6086956521739131, 0.5454545454545454, 0.49, 1.0, 1.0, 0.334100919335914, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1879602413907996, 0.1879602413907996, 0.2548654427092663], 
reward next is 0.7451, 
noisyNet noise sample is [array([0.49334332], dtype=float32), -0.908152]. 
=============================================
[2019-03-23 11:34:06,374] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.500265e-30 1.000000e+00 0.000000e+00 6.950574e-29 0.000000e+00], sum to 1.0000
[2019-03-23 11:34:06,383] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6282
[2019-03-23 11:34:06,389] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 83.00000000000001, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 204534.3136242876, 204534.3136242873, 67903.88851291197], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2351400.0000, 
sim time next is 2352000.0000, 
raw observation next is [13.0, 84.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 202557.304798537, 202557.3047985367, 67774.05594633825], 
processed observation next is [1.0, 0.21739130434782608, 0.22727272727272727, 0.84, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07502122399945814, 0.07502122399945804, 0.16530257547887378], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.40151417], dtype=float32), 0.9232676]. 
=============================================
[2019-03-23 11:34:06,408] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[72.71473]
 [72.71473]
 [72.71473]
 [72.71473]
 [72.71473]], R is [[71.98758698]
 [71.26771545]
 [70.55503845]
 [69.8494873 ]
 [69.15099335]].
[2019-03-23 11:34:06,848] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.0102183e-30 1.0000000e+00 0.0000000e+00 1.8647879e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 11:34:06,855] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8778
[2019-03-23 11:34:06,859] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.33333333333333, 90.0, 1.0, 2.0, 0.2825474857094651, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 306798.8557742065, 306798.8557742062, 99796.24747488624], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2603400.0000, 
sim time next is 2604000.0000, 
raw observation next is [16.26666666666667, 92.0, 1.0, 2.0, 0.2857372249759391, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 310263.4788022421, 310263.4788022424, 102646.2534971646], 
processed observation next is [0.0, 0.13043478260869565, 0.3757575757575759, 0.92, 1.0, 1.0, 0.10717153121992389, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11491239955638596, 0.11491239955638606, 0.2503567158467429], 
reward next is 0.7496, 
noisyNet noise sample is [array([0.4487778], dtype=float32), -0.24788792]. 
=============================================
[2019-03-23 11:34:06,883] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[71.075356]
 [71.075356]
 [71.075356]
 [71.075356]
 [71.075356]], R is [[71.11425018]
 [71.15969849]
 [71.20992279]
 [71.25093842]
 [71.28144836]].
[2019-03-23 11:34:12,200] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.6781483e-33 1.0000000e+00 0.0000000e+00 3.0368987e-36 0.0000000e+00], sum to 1.0000
[2019-03-23 11:34:12,210] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1569
[2019-03-23 11:34:12,214] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.33333333333334, 84.0, 1.0, 2.0, 0.5063763630426966, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 549976.679484333, 549976.6794843328, 115989.9841904259], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2456400.0000, 
sim time next is 2457000.0000, 
raw observation next is [16.5, 85.0, 1.0, 2.0, 0.5107542704587484, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 554734.2493160967, 554734.2493160967, 118852.9575844881], 
processed observation next is [1.0, 0.43478260869565216, 0.38636363636363635, 0.85, 1.0, 1.0, 0.3884428380734355, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2054571293763321, 0.2054571293763321, 0.2898852624011905], 
reward next is 0.7101, 
noisyNet noise sample is [array([-0.10880749], dtype=float32), -0.08849952]. 
=============================================
[2019-03-23 11:34:12,231] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[81.131035]
 [81.131035]
 [81.131035]
 [81.131035]
 [81.131035]], R is [[81.02985382]
 [80.93665314]
 [80.84577942]
 [80.77161407]
 [80.69735718]].
[2019-03-23 11:34:14,474] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 11:34:14,477] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 11:34:14,478] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 11:34:14,478] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 11:34:14,479] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:34:14,480] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 11:34:14,482] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:34:14,480] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:34:14,479] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:34:14,480] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 11:34:14,485] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:34:14,499] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run80
[2019-03-23 11:34:14,521] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run80
[2019-03-23 11:34:14,557] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run80
[2019-03-23 11:34:14,557] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run80
[2019-03-23 11:34:14,558] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run80
[2019-03-23 11:34:19,406] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.0865535]
[2019-03-23 11:34:19,408] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.13333333333333, 81.0, 1.0, 2.0, 0.3392374449459555, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 374957.6939312158, 374957.6939312158, 120586.153541849]
[2019-03-23 11:34:19,409] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 11:34:19,414] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.8088641e-29 1.0000000e+00 0.0000000e+00 6.5235705e-33 0.0000000e+00], sampled 0.019728561474413042
[2019-03-23 11:34:37,473] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.0865535]
[2019-03-23 11:34:37,476] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [16.95, 72.0, 1.0, 2.0, 0.2959078333060152, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 321290.4865226275, 321290.4865226275, 91959.67310976071]
[2019-03-23 11:34:37,478] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 11:34:37,483] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.8088641e-29 1.0000000e+00 0.0000000e+00 6.5235705e-33 0.0000000e+00], sampled 0.17716240326541055
[2019-03-23 11:34:46,538] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.0865535]
[2019-03-23 11:34:46,539] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [17.21666666666667, 67.33333333333333, 1.0, 2.0, 0.2553200844459992, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 277211.0013650384, 277211.0013650384, 86150.71348175291]
[2019-03-23 11:34:46,540] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 11:34:46,545] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.8088641e-29 1.0000000e+00 0.0000000e+00 6.5235705e-33 0.0000000e+00], sampled 0.5363506667629877
[2019-03-23 11:34:58,400] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.0865535]
[2019-03-23 11:34:58,401] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.05, 87.0, 1.0, 2.0, 0.4290461090985979, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 487873.4167491217, 487873.4167491213, 134722.9645608353]
[2019-03-23 11:34:58,401] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 11:34:58,404] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.8088641e-29 1.0000000e+00 0.0000000e+00 6.5235705e-33 0.0000000e+00], sampled 0.4021380112040951
[2019-03-23 11:35:03,847] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.0865535]
[2019-03-23 11:35:03,847] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.71666666666667, 69.0, 1.0, 2.0, 0.4421350963118433, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 503105.4392436154, 503105.439243615, 136358.2843687849]
[2019-03-23 11:35:03,848] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 11:35:03,853] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.8088641e-29 1.0000000e+00 0.0000000e+00 6.5235705e-33 0.0000000e+00], sampled 0.8974441039962044
[2019-03-23 11:35:55,785] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 11:35:56,103] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 11:35:56,139] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 11:35:56,285] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 11:35:56,328] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 11:35:57,345] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 1975000, evaluation results [1975000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 11:36:00,811] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.440305e-30 1.000000e+00 0.000000e+00 2.178374e-32 0.000000e+00], sum to 1.0000
[2019-03-23 11:36:00,818] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2917
[2019-03-23 11:36:00,821] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 62.0, 1.0, 2.0, 0.4732159646193219, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 513942.0454528916, 513942.0454528916, 124503.5112709387], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2550600.0000, 
sim time next is 2551200.0000, 
raw observation next is [20.66666666666667, 61.33333333333334, 1.0, 2.0, 0.4721085528196293, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 512738.6928882706, 512738.6928882706, 124407.9933398684], 
processed observation next is [1.0, 0.5217391304347826, 0.575757575757576, 0.6133333333333334, 1.0, 1.0, 0.3401356910245366, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18990321958824838, 0.18990321958824838, 0.30343413009723996], 
reward next is 0.6966, 
noisyNet noise sample is [array([-0.7458703], dtype=float32), -0.28100786]. 
=============================================
[2019-03-23 11:36:03,236] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.13769256e-29 1.00000000e+00 0.00000000e+00 1.36861958e-34
 0.00000000e+00], sum to 1.0000
[2019-03-23 11:36:03,242] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5625
[2019-03-23 11:36:03,248] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.56666666666667, 90.0, 1.0, 2.0, 0.2965990924816578, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 322061.5800522059, 322061.5800522059, 105361.4870474758], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2601600.0000, 
sim time next is 2602200.0000, 
raw observation next is [16.48333333333333, 89.0, 1.0, 2.0, 0.2898617739667586, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 314743.5077149647, 314743.507714965, 101222.7152429084], 
processed observation next is [0.0, 0.08695652173913043, 0.3856060606060605, 0.89, 1.0, 1.0, 0.11232721745844824, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11657166952406099, 0.1165716695240611, 0.2468846713241668], 
reward next is 0.7531, 
noisyNet noise sample is [array([-0.8928143], dtype=float32), 0.70726895]. 
=============================================
[2019-03-23 11:36:05,763] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.4433538e-30 1.0000000e+00 0.0000000e+00 1.8581981e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 11:36:05,773] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1287
[2019-03-23 11:36:05,776] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.66666666666667, 41.66666666666667, 1.0, 2.0, 0.3760054151464374, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 424126.5373593016, 424126.5373593016, 122954.2522441172], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2650800.0000, 
sim time next is 2651400.0000, 
raw observation next is [27.5, 42.5, 1.0, 2.0, 0.3778099494712608, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 426278.0555881846, 426278.0555881849, 123177.2004201563], 
processed observation next is [0.0, 0.6956521739130435, 0.8863636363636364, 0.425, 1.0, 1.0, 0.22226243683907596, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15788076132895726, 0.15788076132895737, 0.3004321961467227], 
reward next is 0.6996, 
noisyNet noise sample is [array([-0.5213114], dtype=float32), -0.8896767]. 
=============================================
[2019-03-23 11:36:22,733] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.5907975e-26 1.0000000e+00 1.0123174e-36 1.0990768e-31 1.0784251e-35], sum to 1.0000
[2019-03-23 11:36:22,742] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6878
[2019-03-23 11:36:22,748] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1228891.338313256 W.
[2019-03-23 11:36:22,754] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.0, 70.66666666666667, 1.0, 2.0, 0.6002257379801371, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9790186304773437, 6.911200000000001, 6.9112, 77.32846344354104, 1228891.338313256, 1228891.338313256, 279229.2672874352], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2973000.0000, 
sim time next is 2973600.0000, 
raw observation next is [26.0, 70.0, 1.0, 2.0, 0.5312880266010652, 1.0, 1.0, 0.5312880266010652, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1201540.80071977, 1201540.80071977, 241736.0941597833], 
processed observation next is [1.0, 0.43478260869565216, 0.8181818181818182, 0.7, 1.0, 1.0, 0.4141100332513315, 1.0, 0.5, 0.4141100332513315, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.44501511137769256, 0.44501511137769256, 0.5896002296580081], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.904496], dtype=float32), -0.81814724]. 
=============================================
[2019-03-23 11:36:27,836] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.6266082e-28 1.0000000e+00 0.0000000e+00 4.3331205e-33 1.5967093e-38], sum to 1.0000
[2019-03-23 11:36:27,847] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0308
[2019-03-23 11:36:27,854] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333333, 72.0, 1.0, 2.0, 0.9312252920376295, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1056047.139433782, 1056047.139433782, 195145.9981507398], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3062400.0000, 
sim time next is 3063000.0000, 
raw observation next is [22.66666666666667, 70.5, 1.0, 2.0, 0.9488774582275847, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1076904.792170056, 1076904.792170056, 198679.3061366573], 
processed observation next is [1.0, 0.43478260869565216, 0.6666666666666669, 0.705, 1.0, 1.0, 0.9360968227844809, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.39885362672965036, 0.39885362672965036, 0.48458367350404224], 
reward next is 0.5154, 
noisyNet noise sample is [array([0.863381], dtype=float32), 0.13085906]. 
=============================================
[2019-03-23 11:36:27,873] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[67.566284]
 [67.566284]
 [67.566284]
 [67.566284]
 [67.566284]], R is [[67.40602875]
 [67.25600433]
 [67.11965942]
 [67.00099182]
 [66.89936829]].
[2019-03-23 11:36:31,168] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.9801054e-27 1.0000000e+00 1.6292702e-38 3.4618715e-31 1.8725193e-38], sum to 1.0000
[2019-03-23 11:36:31,176] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3862
[2019-03-23 11:36:31,181] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666666, 74.66666666666667, 1.0, 2.0, 0.5043304353681127, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 573467.8227407665, 573467.8227407665, 138201.4302227301], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3138000.0000, 
sim time next is 3138600.0000, 
raw observation next is [22.83333333333334, 73.83333333333333, 1.0, 2.0, 0.4949179404190522, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 562864.3869574672, 562864.3869574672, 137265.3712495546], 
processed observation next is [1.0, 0.30434782608695654, 0.6742424242424245, 0.7383333333333333, 1.0, 1.0, 0.3686474255238152, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2084682914657286, 0.2084682914657286, 0.3347935884135478], 
reward next is 0.6652, 
noisyNet noise sample is [array([0.1118641], dtype=float32), -1.0348479]. 
=============================================
[2019-03-23 11:36:37,583] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.1720108e-30 1.0000000e+00 0.0000000e+00 5.6879010e-32 0.0000000e+00], sum to 1.0000
[2019-03-23 11:36:37,591] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6848
[2019-03-23 11:36:37,595] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.03333333333333, 49.33333333333333, 1.0, 2.0, 0.3329087961342099, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 367547.8639483955, 367547.8639483952, 115629.4475775568], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3249600.0000, 
sim time next is 3250200.0000, 
raw observation next is [24.01666666666667, 49.66666666666667, 1.0, 2.0, 0.3340997199961303, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 369119.042321479, 369119.042321479, 115818.4900504444], 
processed observation next is [0.0, 0.6086956521739131, 0.7280303030303031, 0.4966666666666667, 1.0, 1.0, 0.16762464999516286, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1367107564153626, 0.1367107564153626, 0.2824841220742546], 
reward next is 0.7175, 
noisyNet noise sample is [array([2.616284], dtype=float32), 0.21052364]. 
=============================================
[2019-03-23 11:36:44,315] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.1350926e-29 1.0000000e+00 0.0000000e+00 8.8625329e-35 1.4512937e-38], sum to 1.0000
[2019-03-23 11:36:44,320] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7889
[2019-03-23 11:36:44,325] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 88.0, 1.0, 2.0, 0.3316602223709189, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 365071.4974092382, 365071.4974092382, 115115.3706077561], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3379200.0000, 
sim time next is 3379800.0000, 
raw observation next is [18.0, 88.0, 1.0, 2.0, 0.3291400512902483, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 362270.6511354152, 362270.6511354155, 114919.793458587], 
processed observation next is [1.0, 0.08695652173913043, 0.45454545454545453, 0.88, 1.0, 1.0, 0.16142506411281038, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13417431523533896, 0.13417431523533907, 0.2802921791672853], 
reward next is 0.7197, 
noisyNet noise sample is [array([1.1421632], dtype=float32), -1.2035469]. 
=============================================
[2019-03-23 11:36:46,525] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-23 11:36:46,528] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 11:36:46,529] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 11:36:46,529] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 11:36:46,529] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:36:46,530] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 11:36:46,530] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:36:46,532] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:36:46,531] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:36:46,534] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 11:36:46,536] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:36:46,563] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run81
[2019-03-23 11:36:46,592] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run81
[2019-03-23 11:36:46,592] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run81
[2019-03-23 11:36:46,651] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run81
[2019-03-23 11:36:46,680] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run81
[2019-03-23 11:36:58,295] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -0.95077425]
[2019-03-23 11:36:58,296] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [27.0, 58.0, 1.0, 2.0, 0.6894942843083909, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9718463242148453, 6.9112, 6.9112, 77.32846344354103, 1334982.0213157, 1334982.0213157, 285101.0919140305]
[2019-03-23 11:36:58,297] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 11:36:58,302] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [7.2865473e-24 1.0000000e+00 3.3343551e-33 7.9321520e-27 1.1626772e-32], sampled 0.684400579832378
[2019-03-23 11:36:58,303] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1334982.0213157 W.
[2019-03-23 11:37:09,690] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -0.95077425]
[2019-03-23 11:37:09,692] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.0, 45.0, 1.0, 2.0, 0.3254672856580749, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 353419.4454214352, 353419.4454214349, 82328.3792094001]
[2019-03-23 11:37:09,693] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 11:37:09,695] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [7.2865473e-24 1.0000000e+00 3.3343551e-33 7.9321520e-27 1.1626772e-32], sampled 0.7923172633591701
[2019-03-23 11:37:41,530] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -0.95077425]
[2019-03-23 11:37:41,531] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.95153761, 91.13538112, 1.0, 2.0, 0.5411320899084139, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 615676.1037765606, 615676.1037765603, 152681.5913193213]
[2019-03-23 11:37:41,532] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 11:37:41,535] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [7.2865473e-24 1.0000000e+00 3.3343551e-33 7.9321520e-27 1.1626772e-32], sampled 0.8431819587135744
[2019-03-23 11:38:02,950] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -0.95077425]
[2019-03-23 11:38:02,951] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.03373149333333, 85.52852610333333, 1.0, 2.0, 0.2567605044964286, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 278775.2844403164, 278775.2844403164, 92319.14493823111]
[2019-03-23 11:38:02,952] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 11:38:02,954] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [7.2865473e-24 1.0000000e+00 3.3343551e-33 7.9321520e-27 1.1626772e-32], sampled 0.48217682331335454
[2019-03-23 11:38:12,092] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -0.95077425]
[2019-03-23 11:38:12,093] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.76666666666667, 90.0, 1.0, 2.0, 0.4707804312381532, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 537093.2923544822, 537093.2923544819, 141494.3643791261]
[2019-03-23 11:38:12,095] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 11:38:12,097] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [7.2865473e-24 1.0000000e+00 3.3343551e-33 7.9321520e-27 1.1626772e-32], sampled 0.9170768262394838
[2019-03-23 11:38:26,808] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 11:38:27,566] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 11:38:27,638] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 11:38:27,640] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 11:38:27,759] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 11:38:28,775] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 2000000, evaluation results [2000000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 11:38:31,129] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.5788876e-28 1.0000000e+00 0.0000000e+00 8.3144795e-33 1.8852630e-38], sum to 1.0000
[2019-03-23 11:38:31,135] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5898
[2019-03-23 11:38:31,138] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.5, 97.0, 1.0, 2.0, 0.5221878109062527, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 595690.5581517944, 595690.5581517946, 144433.5763131564], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3483000.0000, 
sim time next is 3483600.0000, 
raw observation next is [21.66666666666667, 96.0, 1.0, 2.0, 0.5087810278590555, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 580346.5387782705, 580346.5387782705, 142926.5848628156], 
processed observation next is [1.0, 0.30434782608695654, 0.6212121212121214, 0.96, 1.0, 1.0, 0.3859762848238194, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21494316251047055, 0.21494316251047055, 0.3486014264946722], 
reward next is 0.6514, 
noisyNet noise sample is [array([-0.65307736], dtype=float32), -0.42593244]. 
=============================================
[2019-03-23 11:38:31,281] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.9127737e-25 1.0000000e+00 1.5441952e-35 6.6913783e-26 2.6821722e-35], sum to 1.0000
[2019-03-23 11:38:31,289] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3801
[2019-03-23 11:38:31,292] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.579354652763152, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 661071.5170550976, 661071.517055098, 151199.7369843234], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3471000.0000, 
sim time next is 3471600.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.556835374992577, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 635353.892598803, 635353.892598803, 148377.6943113258], 
processed observation next is [1.0, 0.17391304347826086, 0.5909090909090909, 1.0, 1.0, 1.0, 0.44604421874072114, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2353162565180752, 0.2353162565180752, 0.3618968153934775], 
reward next is 0.6381, 
noisyNet noise sample is [array([0.40748984], dtype=float32), 1.1727399]. 
=============================================
[2019-03-23 11:38:34,995] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.8934570e-25 1.0000000e+00 1.7937048e-35 5.5920689e-27 5.7772462e-34], sum to 1.0000
[2019-03-23 11:38:35,004] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8773
[2019-03-23 11:38:35,009] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 77.0, 1.0, 2.0, 0.2813410383139067, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 305488.4461892591, 305488.4461892588, 101648.7945488037], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3893400.0000, 
sim time next is 3894000.0000, 
raw observation next is [18.0, 77.0, 1.0, 2.0, 0.2812653472231958, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 305406.2327507673, 305406.2327507673, 101637.6843283391], 
processed observation next is [0.0, 0.043478260869565216, 0.45454545454545453, 0.77, 1.0, 1.0, 0.10158168402899473, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11311341953732122, 0.11311341953732122, 0.24789679104472953], 
reward next is 0.7521, 
noisyNet noise sample is [array([-0.70288557], dtype=float32), -1.0980455]. 
=============================================
[2019-03-23 11:38:35,022] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[60.654747]
 [60.654747]
 [60.654747]
 [60.654747]
 [60.654747]], R is [[60.80030823]
 [60.94438171]
 [61.0870018 ]
 [61.22822189]
 [61.36810303]].
[2019-03-23 11:38:37,621] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.1016753e-19 1.0000000e+00 2.9147909e-29 5.9968378e-24 2.5737969e-28], sum to 1.0000
[2019-03-23 11:38:37,622] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9501
[2019-03-23 11:38:37,631] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1569621.98514625 W.
[2019-03-23 11:38:37,634] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.0, 70.0, 1.0, 2.0, 0.6978141626823224, 1.0, 2.0, 0.6978141626823224, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1569621.98514625, 1569621.985146249, 291103.4192926682], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3603000.0000, 
sim time next is 3603600.0000, 
raw observation next is [27.0, 70.0, 1.0, 2.0, 0.4445905990343157, 1.0, 2.0, 0.4445905990343157, 1.0, 1.0, 0.8995754744376745, 6.9112, 6.9112, 77.3421103, 1499961.259667001, 1499961.259667001, 329826.6066734644], 
processed observation next is [1.0, 0.7391304347826086, 0.8636363636363636, 0.7, 1.0, 1.0, 0.3057382487928946, 1.0, 1.0, 0.3057382487928946, 1.0, 0.5, 0.8565363920538207, 0.0, 0.0, 0.5085185399722538, 0.5555412072840744, 0.5555412072840744, 0.804455138227962], 
reward next is 0.1955, 
noisyNet noise sample is [array([-1.2197348], dtype=float32), -0.24810208]. 
=============================================
[2019-03-23 11:38:39,490] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.0085491e-26 1.0000000e+00 4.1106537e-37 3.3582214e-28 2.3691924e-37], sum to 1.0000
[2019-03-23 11:38:39,499] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7766
[2019-03-23 11:38:39,505] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 80.5, 1.0, 2.0, 0.4938427131009861, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 563446.780811511, 563446.780811511, 140799.6447785567], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3612600.0000, 
sim time next is 3613200.0000, 
raw observation next is [23.33333333333333, 81.33333333333333, 1.0, 2.0, 0.4908025446103719, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 560001.8598673453, 560001.8598673453, 140352.3467313586], 
processed observation next is [1.0, 0.8260869565217391, 0.6969696969696968, 0.8133333333333332, 1.0, 1.0, 0.3635031807629649, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20740809624716494, 0.20740809624716494, 0.3423227969057526], 
reward next is 0.6577, 
noisyNet noise sample is [array([2.2357073], dtype=float32), 1.3476906]. 
=============================================
[2019-03-23 11:38:39,514] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.2387816e-28 1.0000000e+00 0.0000000e+00 1.6164765e-35 1.2873258e-38], sum to 1.0000
[2019-03-23 11:38:39,525] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5755
[2019-03-23 11:38:39,529] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333334, 98.0, 1.0, 2.0, 0.50069120848285, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 571187.3649459784, 571187.3649459787, 141814.1713626884], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3624000.0000, 
sim time next is 3624600.0000, 
raw observation next is [21.16666666666666, 99.0, 1.0, 2.0, 0.4987169139545122, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 568973.5660939222, 568973.5660939222, 141479.8654653361], 
processed observation next is [1.0, 0.9565217391304348, 0.5984848484848482, 0.99, 1.0, 1.0, 0.3733961424431402, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21073095040515638, 0.21073095040515638, 0.3450728425983807], 
reward next is 0.6549, 
noisyNet noise sample is [array([1.0659122], dtype=float32), -0.83654815]. 
=============================================
[2019-03-23 11:38:40,490] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.2287834e-27 1.0000000e+00 3.2650310e-38 1.7133789e-30 1.4767823e-38], sum to 1.0000
[2019-03-23 11:38:40,497] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9714
[2019-03-23 11:38:40,501] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.5428260951739021, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 619362.5911120684, 619362.5911120684, 146637.1042765845], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3652200.0000, 
sim time next is 3652800.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.5667079793945733, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 646628.4338558252, 646628.4338558252, 149605.9302989687], 
processed observation next is [1.0, 0.2608695652173913, 0.5909090909090909, 1.0, 1.0, 1.0, 0.45838497424321656, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23949201253919453, 0.23949201253919453, 0.36489251292431396], 
reward next is 0.6351, 
noisyNet noise sample is [array([1.9376448], dtype=float32), 1.1500889]. 
=============================================
[2019-03-23 11:38:45,523] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.6555204e-29 1.0000000e+00 0.0000000e+00 1.0888692e-31 0.0000000e+00], sum to 1.0000
[2019-03-23 11:38:45,530] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6877
[2019-03-23 11:38:45,534] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 89.0, 1.0, 2.0, 0.4814774311705598, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 548233.2775421429, 548233.2775421429, 136456.6353573564], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3736200.0000, 
sim time next is 3736800.0000, 
raw observation next is [21.0, 88.0, 1.0, 2.0, 0.4781066549371454, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 544091.191234209, 544091.191234209, 135786.7000774079], 
processed observation next is [1.0, 0.2608695652173913, 0.5909090909090909, 0.88, 1.0, 1.0, 0.3476333186714317, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20151525601267, 0.20151525601267, 0.33118707335953146], 
reward next is 0.6688, 
noisyNet noise sample is [array([0.666874], dtype=float32), -2.5922356]. 
=============================================
[2019-03-23 11:38:47,459] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.7302380e-24 1.0000000e+00 1.2122482e-33 2.5729416e-29 1.4368544e-32], sum to 1.0000
[2019-03-23 11:38:47,466] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0069
[2019-03-23 11:38:47,469] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666667, 60.66666666666667, 1.0, 2.0, 0.6634727650250839, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 742180.3240539464, 742180.3240539464, 150606.4816182294], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3774000.0000, 
sim time next is 3774600.0000, 
raw observation next is [22.5, 60.5, 1.0, 2.0, 0.598658168317947, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 667690.3943907535, 667690.3943907535, 142247.205171412], 
processed observation next is [1.0, 0.6956521739130435, 0.6590909090909091, 0.605, 1.0, 1.0, 0.49832271039743375, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.24729273866324203, 0.24729273866324203, 0.34694440285710243], 
reward next is 0.6531, 
noisyNet noise sample is [array([0.2719735], dtype=float32), -0.33168045]. 
=============================================
[2019-03-23 11:38:53,689] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.239531e-31 1.000000e+00 0.000000e+00 7.274055e-30 0.000000e+00], sum to 1.0000
[2019-03-23 11:38:53,698] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8670
[2019-03-23 11:38:53,703] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.25, 81.0, 1.0, 2.0, 0.2696518106823413, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 292792.1152899305, 292792.1152899302, 96526.00521144077], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3904200.0000, 
sim time next is 3904800.0000, 
raw observation next is [17.16666666666666, 81.33333333333334, 1.0, 2.0, 0.268146327420212, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 291156.9489101655, 291156.9489101658, 95777.29397225968], 
processed observation next is [0.0, 0.17391304347826086, 0.4166666666666664, 0.8133333333333335, 1.0, 1.0, 0.08518290927526498, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10783590700376501, 0.10783590700376512, 0.23360315602990164], 
reward next is 0.7664, 
noisyNet noise sample is [array([-0.42252046], dtype=float32), -0.8170643]. 
=============================================
[2019-03-23 11:38:54,039] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.2485525e-30 1.0000000e+00 0.0000000e+00 2.9652553e-31 0.0000000e+00], sum to 1.0000
[2019-03-23 11:38:54,045] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4972
[2019-03-23 11:38:54,049] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.75, 78.5, 1.0, 2.0, 0.2764803620803185, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 300208.9507096658, 300208.9507096655, 100131.1771334588], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3900600.0000, 
sim time next is 3901200.0000, 
raw observation next is [17.66666666666667, 79.0, 1.0, 2.0, 0.2755555908170147, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 299204.5031951976, 299204.5031951976, 99696.6616676426], 
processed observation next is [0.0, 0.13043478260869565, 0.4393939393939396, 0.79, 1.0, 1.0, 0.09444448852126835, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.110816482664888, 0.110816482664888, 0.24316258943327465], 
reward next is 0.7568, 
noisyNet noise sample is [array([0.87227595], dtype=float32), 2.052747]. 
=============================================
[2019-03-23 11:38:59,517] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.1492205e-30 1.0000000e+00 0.0000000e+00 1.6402329e-31 0.0000000e+00], sum to 1.0000
[2019-03-23 11:38:59,518] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1717
[2019-03-23 11:38:59,526] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.16666666666667, 100.0, 1.0, 2.0, 0.4860156546704225, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 539603.1009148221, 539603.1009148221, 129583.7304927396], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4021800.0000, 
sim time next is 4022400.0000, 
raw observation next is [17.33333333333334, 100.0, 1.0, 2.0, 0.5459424440501992, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 607938.0345139517, 607938.0345139517, 136194.6115556168], 
processed observation next is [1.0, 0.5652173913043478, 0.42424242424242453, 1.0, 1.0, 1.0, 0.43242805506274895, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2251622350051673, 0.2251622350051673, 0.33218197940394345], 
reward next is 0.6678, 
noisyNet noise sample is [array([-0.4859053], dtype=float32), 0.50461644]. 
=============================================
[2019-03-23 11:39:03,534] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.375900e-28 1.000000e+00 0.000000e+00 8.658655e-27 0.000000e+00], sum to 1.0000
[2019-03-23 11:39:03,543] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5202
[2019-03-23 11:39:03,547] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 86.0, 1.0, 2.0, 0.6661714294997233, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 752153.2251845635, 752153.2251845635, 154216.4057201089], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4095000.0000, 
sim time next is 4095600.0000, 
raw observation next is [20.33333333333334, 83.33333333333334, 1.0, 2.0, 0.6283170086832588, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 709324.0597707562, 709324.0597707559, 149490.5556311172], 
processed observation next is [1.0, 0.391304347826087, 0.5606060606060609, 0.8333333333333335, 1.0, 1.0, 0.5353962608540734, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2627126147299097, 0.2627126147299096, 0.3646111112954078], 
reward next is 0.6354, 
noisyNet noise sample is [array([0.8657421], dtype=float32), -0.81031775]. 
=============================================
[2019-03-23 11:39:08,673] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0463463e-28 1.0000000e+00 0.0000000e+00 1.8814260e-31 0.0000000e+00], sum to 1.0000
[2019-03-23 11:39:08,677] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9026
[2019-03-23 11:39:08,683] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.83333333333334, 74.66666666666667, 1.0, 2.0, 0.4291696661091014, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 488338.6487969184, 488338.6487969184, 130688.9092735294], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4539000.0000, 
sim time next is 4539600.0000, 
raw observation next is [23.0, 73.0, 1.0, 2.0, 0.4259073460238201, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 484444.0094282533, 484444.009428253, 130191.6383685889], 
processed observation next is [0.0, 0.5652173913043478, 0.6818181818181818, 0.73, 1.0, 1.0, 0.28238418252977504, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17942370719564937, 0.17942370719564926, 0.3175405813868022], 
reward next is 0.6825, 
noisyNet noise sample is [array([0.8064431], dtype=float32), 0.7335553]. 
=============================================
[2019-03-23 11:39:15,881] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.545107e-33 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 11:39:15,889] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7764
[2019-03-23 11:39:15,895] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.33333333333334, 98.0, 1.0, 2.0, 0.3813127037887906, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 428736.819226819, 428736.8192268193, 122690.0919120392], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4326000.0000, 
sim time next is 4326600.0000, 
raw observation next is [18.16666666666666, 99.0, 1.0, 2.0, 0.380652159731448, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 427718.0197075894, 427718.0197075894, 122494.3125885995], 
processed observation next is [1.0, 0.043478260869565216, 0.4621212121212119, 0.99, 1.0, 1.0, 0.22581519966431, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15841408137318128, 0.15841408137318128, 0.29876661606975485], 
reward next is 0.7012, 
noisyNet noise sample is [array([0.00579251], dtype=float32), 0.14779934]. 
=============================================
[2019-03-23 11:39:16,099] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.6242234e-25 1.0000000e+00 6.3627233e-37 5.7265129e-28 4.2230402e-38], sum to 1.0000
[2019-03-23 11:39:16,110] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2859
[2019-03-23 11:39:16,117] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.3801155654502506, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 426827.45278115, 426827.45278115, 122306.0024549569], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4327200.0000, 
sim time next is 4327800.0000, 
raw observation next is [18.0, 99.00000000000001, 1.0, 2.0, 0.5022717021895925, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 563683.4274932903, 563683.4274932906, 133631.7807083645], 
processed observation next is [1.0, 0.08695652173913043, 0.45454545454545453, 0.9900000000000001, 1.0, 1.0, 0.3778396277369906, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20877163981232974, 0.20877163981232985, 0.3259311724594256], 
reward next is 0.6741, 
noisyNet noise sample is [array([0.17482679], dtype=float32), 0.27657217]. 
=============================================
[2019-03-23 11:39:17,433] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-23 11:39:17,434] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 11:39:17,435] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 11:39:17,435] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 11:39:17,436] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:39:17,437] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 11:39:17,439] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:39:17,435] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:39:17,440] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:39:17,440] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 11:39:17,445] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:39:17,470] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run82
[2019-03-23 11:39:17,494] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run82
[2019-03-23 11:39:17,517] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run82
[2019-03-23 11:39:17,538] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run82
[2019-03-23 11:39:17,538] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run82
[2019-03-23 11:39:24,249] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -0.9813702]
[2019-03-23 11:39:24,249] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [14.977030735, 79.37975765, 1.0, 2.0, 0.2578572914207317, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 61.63163626896797, 280002.2855354256, 280002.2855354256, 69936.90747132264]
[2019-03-23 11:39:24,249] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 11:39:24,256] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.4184822e-26 1.0000000e+00 2.0136789e-36 2.0005552e-29 7.1869849e-36], sampled 0.2945762750701454
[2019-03-23 11:39:25,410] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -0.9813702]
[2019-03-23 11:39:25,413] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.75329875666667, 90.76963713666666, 1.0, 2.0, 0.315817582328736, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 347457.4931754075, 347457.4931754075, 118210.9267281489]
[2019-03-23 11:39:25,414] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 11:39:25,417] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.4184822e-26 1.0000000e+00 2.0136789e-36 2.0005552e-29 7.1869849e-36], sampled 0.7184483270213201
[2019-03-23 11:39:28,839] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -0.9813702]
[2019-03-23 11:39:28,841] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [28.7, 40.0, 1.0, 2.0, 0.4080138029599751, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 462361.239219468, 462361.239219468, 131433.4621439404]
[2019-03-23 11:39:28,842] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 11:39:28,845] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.4184822e-26 1.0000000e+00 2.0136789e-36 2.0005552e-29 7.1869849e-36], sampled 0.11803290136231814
[2019-03-23 11:39:32,894] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -0.9813702]
[2019-03-23 11:39:32,895] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.16958118, 85.08724444333333, 1.0, 2.0, 0.5079238590503635, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 579462.376041367, 579462.3760413666, 145559.1062041219]
[2019-03-23 11:39:32,897] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 11:39:32,900] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.4184822e-26 1.0000000e+00 2.0136789e-36 2.0005552e-29 7.1869849e-36], sampled 0.4216325812380304
[2019-03-23 11:39:49,375] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -0.9813702]
[2019-03-23 11:39:49,377] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.2, 82.0, 1.0, 2.0, 0.4460487570801035, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 508121.7905240182, 508121.7905240182, 137377.3816665691]
[2019-03-23 11:39:49,378] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 11:39:49,380] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.4184822e-26 1.0000000e+00 2.0136789e-36 2.0005552e-29 7.1869849e-36], sampled 0.5628935959146593
[2019-03-23 11:39:49,950] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -0.9813702]
[2019-03-23 11:39:49,952] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.887685755, 95.31589556833333, 1.0, 2.0, 0.4597443459275063, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 524452.9316544005, 524452.9316544002, 140110.8371496399]
[2019-03-23 11:39:49,953] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 11:39:49,954] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.4184822e-26 1.0000000e+00 2.0136789e-36 2.0005552e-29 7.1869849e-36], sampled 0.05837521306235316
[2019-03-23 11:39:50,335] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -0.9813702]
[2019-03-23 11:39:50,336] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [28.0, 70.0, 1.0, 2.0, 0.8849392943510733, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9865530188920543, 6.911199999999999, 6.9112, 77.32846344354104, 1543592.985129558, 1543592.985129558, 331118.5568565386]
[2019-03-23 11:39:50,337] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 11:39:50,339] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.4184822e-26 1.0000000e+00 2.0136789e-36 2.0005552e-29 7.1869849e-36], sampled 0.9239571436477313
[2019-03-23 11:39:50,340] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1543592.985129558 W.
[2019-03-23 11:40:20,555] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -0.9813702]
[2019-03-23 11:40:20,555] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [29.46559506333333, 55.58748206333333, 1.0, 2.0, 0.7613825836500855, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 863529.8759339293, 863529.8759339293, 185508.7417081257]
[2019-03-23 11:40:20,556] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 11:40:20,559] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.4184822e-26 1.0000000e+00 2.0136789e-36 2.0005552e-29 7.1869849e-36], sampled 0.147785894260115
[2019-03-23 11:40:49,172] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -0.9813702]
[2019-03-23 11:40:49,175] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.00361879833333, 83.921873025, 1.0, 2.0, 0.3808933065628085, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 427871.3105826191, 427871.3105826191, 126781.562433891]
[2019-03-23 11:40:49,175] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 11:40:49,178] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.4184822e-26 1.0000000e+00 2.0136789e-36 2.0005552e-29 7.1869849e-36], sampled 0.9380896509077997
[2019-03-23 11:40:55,322] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 11:40:55,491] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 11:40:55,667] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 11:40:55,799] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 11:40:55,808] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 11:40:56,826] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 2025000, evaluation results [2025000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 11:41:04,422] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.1532506e-26 1.0000000e+00 1.9335309e-37 4.9327523e-31 2.3952549e-37], sum to 1.0000
[2019-03-23 11:41:04,428] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8635
[2019-03-23 11:41:04,439] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.4112873546284712, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 466233.7017680871, 466233.7017680868, 127517.631287102], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4508400.0000, 
sim time next is 4509000.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4111677065038545, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 466097.0541476743, 466097.0541476743, 127505.6298388505], 
processed observation next is [0.0, 0.17391304347826086, 0.5, 1.0, 1.0, 1.0, 0.26395963312981807, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1726285385732127, 0.1726285385732127, 0.3109893410703671], 
reward next is 0.6890, 
noisyNet noise sample is [array([-0.2861779], dtype=float32), -1.4829024]. 
=============================================
[2019-03-23 11:41:04,452] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[64.722084]
 [64.722084]
 [64.722084]
 [64.722084]
 [64.722084]], R is [[64.76387787]
 [64.80522156]
 [64.84603119]
 [64.88608551]
 [64.92490387]].
[2019-03-23 11:41:09,716] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.7370444e-30 1.0000000e+00 0.0000000e+00 1.2430373e-34 0.0000000e+00], sum to 1.0000
[2019-03-23 11:41:09,723] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2835
[2019-03-23 11:41:09,728] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.5, 77.5, 1.0, 2.0, 0.4228393426560543, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 459204.0523988286, 459204.0523988289, 110184.1792708267], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4609800.0000, 
sim time next is 4610400.0000, 
raw observation next is [17.66666666666667, 76.0, 1.0, 2.0, 0.4282396008140365, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 465071.544597264, 465071.5445972643, 110897.3757818225], 
processed observation next is [1.0, 0.34782608695652173, 0.4393939393939396, 0.76, 1.0, 1.0, 0.2852995010175456, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17224872022120888, 0.17224872022120902, 0.27048140434590856], 
reward next is 0.7295, 
noisyNet noise sample is [array([0.17375644], dtype=float32), -0.91606575]. 
=============================================
[2019-03-23 11:41:10,166] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.9377604e-31 1.0000000e+00 0.0000000e+00 3.8613575e-34 0.0000000e+00], sum to 1.0000
[2019-03-23 11:41:10,172] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6312
[2019-03-23 11:41:10,180] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.16666666666667, 87.00000000000001, 1.0, 2.0, 0.2659667779004223, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 288789.6615930272, 288789.6615930269, 91535.86452729454], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4605000.0000, 
sim time next is 4605600.0000, 
raw observation next is [16.33333333333334, 86.0, 1.0, 2.0, 0.2634207300632081, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 286024.3218314349, 286024.3218314352, 91950.67283601486], 
processed observation next is [1.0, 0.30434782608695654, 0.37878787878787906, 0.86, 1.0, 1.0, 0.07927591257901011, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10593493401164256, 0.10593493401164267, 0.2242699337463777], 
reward next is 0.7757, 
noisyNet noise sample is [array([1.4972492], dtype=float32), -0.66676724]. 
=============================================
[2019-03-23 11:41:10,809] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.687212e-28 1.000000e+00 0.000000e+00 7.439392e-32 0.000000e+00], sum to 1.0000
[2019-03-23 11:41:10,819] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9827
[2019-03-23 11:41:10,825] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.33333333333334, 70.0, 1.0, 2.0, 0.4713119807954536, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 511873.1115854304, 511873.1115854304, 114442.3390396915], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4612800.0000, 
sim time next is 4613400.0000, 
raw observation next is [18.5, 68.5, 1.0, 2.0, 0.4765028655143336, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 517513.7249754209, 517513.7249754209, 114633.3396680953], 
processed observation next is [1.0, 0.391304347826087, 0.4772727272727273, 0.685, 1.0, 1.0, 0.34562858189291695, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19167174999089664, 0.19167174999089664, 0.2795935113855983], 
reward next is 0.7204, 
noisyNet noise sample is [array([1.4205415], dtype=float32), -0.533738]. 
=============================================
[2019-03-23 11:41:12,909] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.0226618e-30 1.0000000e+00 0.0000000e+00 3.9108610e-31 0.0000000e+00], sum to 1.0000
[2019-03-23 11:41:12,917] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9636
[2019-03-23 11:41:12,922] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.83333333333333, 73.66666666666667, 1.0, 2.0, 0.2699091308117739, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 293071.6016603995, 293071.6016603992, 92803.50591762588], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4662600.0000, 
sim time next is 4663200.0000, 
raw observation next is [17.66666666666667, 74.33333333333334, 1.0, 2.0, 0.2677887603696582, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 290768.5816543337, 290768.581654334, 91763.70488888826], 
processed observation next is [1.0, 1.0, 0.4393939393939396, 0.7433333333333334, 1.0, 1.0, 0.08473595046207275, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10769206727938285, 0.10769206727938295, 0.2238139143631421], 
reward next is 0.7762, 
noisyNet noise sample is [array([0.29339552], dtype=float32), -1.6944581]. 
=============================================
[2019-03-23 11:41:13,090] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.2630011e-31 1.0000000e+00 0.0000000e+00 3.5705914e-31 0.0000000e+00], sum to 1.0000
[2019-03-23 11:41:13,095] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6020
[2019-03-23 11:41:13,103] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.83333333333334, 77.83333333333334, 1.0, 2.0, 0.2559361851779284, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 277895.221721975, 277895.221721975, 87053.60592672617], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4666200.0000, 
sim time next is 4666800.0000, 
raw observation next is [16.66666666666667, 78.66666666666667, 1.0, 2.0, 0.2536636150107132, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 275426.9688878052, 275426.9688878055, 86317.61658419481], 
processed observation next is [1.0, 0.0, 0.39393939393939414, 0.7866666666666667, 1.0, 1.0, 0.06707951876339151, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10200998847696488, 0.10200998847696499, 0.2105307721565727], 
reward next is 0.7895, 
noisyNet noise sample is [array([0.48223045], dtype=float32), -1.2310036]. 
=============================================
[2019-03-23 11:41:19,695] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.9630719e-27 1.0000000e+00 1.8079997e-36 2.6051182e-29 1.4038988e-36], sum to 1.0000
[2019-03-23 11:41:19,702] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7167
[2019-03-23 11:41:19,709] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1118454.054920339 W.
[2019-03-23 11:41:19,714] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.83333333333334, 95.0, 1.0, 2.0, 0.3285470925342682, 1.0, 2.0, 0.3285470925342682, 1.0, 1.0, 0.6654747443095239, 6.911199999999999, 6.9112, 77.3421103, 1118454.054920339, 1118454.054920339, 271475.9210282447], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4801800.0000, 
sim time next is 4802400.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.5488192073703331, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9693712343681504, 6.92058779290941, 6.9112, 77.32844000875521, 1173178.097189952, 1170129.13499055, 267321.3171615622], 
processed observation next is [1.0, 0.6086956521739131, 0.6363636363636364, 0.94, 1.0, 1.0, 0.4360240092129163, 0.0, 0.5, -0.25, 1.0, 1.0, 0.9562446205259292, 0.0009387792909410387, 0.0, 0.5084286588387054, 0.43451040636664884, 0.43338116110761116, 0.6520032125891762], 
reward next is 0.3011, 
noisyNet noise sample is [array([1.2220085], dtype=float32), -0.76449734]. 
=============================================
[2019-03-23 11:41:22,891] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0856203e-26 1.0000000e+00 7.3486678e-36 1.1719724e-29 4.3093089e-37], sum to 1.0000
[2019-03-23 11:41:22,892] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9070
[2019-03-23 11:41:22,896] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.4661425616334453, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 528543.5336695788, 528543.5336695788, 132989.8579308875], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4865400.0000, 
sim time next is 4866000.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4417414720324274, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 500846.0270205991, 500846.0270205993, 130519.1796274957], 
processed observation next is [1.0, 0.30434782608695654, 0.5, 1.0, 1.0, 1.0, 0.30217684004053424, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18549852852614782, 0.18549852852614787, 0.3183394625060871], 
reward next is 0.6817, 
noisyNet noise sample is [array([0.0814281], dtype=float32), 0.46258527]. 
=============================================
[2019-03-23 11:41:22,915] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[65.54185]
 [65.54185]
 [65.54185]
 [65.54185]
 [65.54185]], R is [[65.56809235]
 [65.58805084]
 [65.61013794]
 [65.63420105]
 [65.66239929]].
[2019-03-23 11:41:29,751] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.2738667e-27 1.0000000e+00 0.0000000e+00 7.6910094e-27 0.0000000e+00], sum to 1.0000
[2019-03-23 11:41:29,758] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4942
[2019-03-23 11:41:29,761] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 64.0, 1.0, 2.0, 0.548679057713853, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 595949.9123161994, 595949.9123161994, 131377.2258673867], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4984200.0000, 
sim time next is 4984800.0000, 
raw observation next is [20.0, 64.0, 1.0, 2.0, 0.5741915964217129, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 623678.2360646215, 623678.2360646215, 133849.1592194811], 
processed observation next is [1.0, 0.6956521739130435, 0.5454545454545454, 0.64, 1.0, 1.0, 0.4677394955271411, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23099193928319314, 0.23099193928319314, 0.3264613639499539], 
reward next is 0.6735, 
noisyNet noise sample is [array([1.0596536], dtype=float32), -1.3946534]. 
=============================================
[2019-03-23 11:41:30,750] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.8626307e-34 1.0000000e+00 0.0000000e+00 1.8167168e-37 0.0000000e+00], sum to 1.0000
[2019-03-23 11:41:30,758] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0294
[2019-03-23 11:41:30,765] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.33333333333333, 86.0, 1.0, 2.0, 0.2683528143241477, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 291381.2223789658, 291381.2223789655, 92465.4662160519], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5013600.0000, 
sim time next is 5014200.0000, 
raw observation next is [16.16666666666667, 87.0, 1.0, 2.0, 0.2672619377899217, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 290196.3800568123, 290196.3800568125, 91765.90790666071], 
processed observation next is [0.0, 0.0, 0.37121212121212144, 0.87, 1.0, 1.0, 0.0840774222374021, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10748014076178233, 0.1074801407617824, 0.22381928757722125], 
reward next is 0.7762, 
noisyNet noise sample is [array([2.4065561], dtype=float32), 0.8521174]. 
=============================================
[2019-03-23 11:41:34,277] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.6370486e-34 1.0000000e+00 0.0000000e+00 2.0412497e-37 0.0000000e+00], sum to 1.0000
[2019-03-23 11:41:34,287] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0506
[2019-03-23 11:41:34,291] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.33333333333333, 56.5, 1.0, 2.0, 0.3630738704689048, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 408580.1060388203, 408580.1060388203, 121313.295373251], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5055000.0000, 
sim time next is 5055600.0000, 
raw observation next is [24.66666666666666, 56.00000000000001, 1.0, 2.0, 0.369169287482543, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 416321.6267677371, 416321.6267677371, 122308.0835391602], 
processed observation next is [0.0, 0.5217391304347826, 0.7575757575757573, 0.56, 1.0, 1.0, 0.21146160935317876, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15419319509916188, 0.15419319509916188, 0.2983123988760005], 
reward next is 0.7017, 
noisyNet noise sample is [array([0.07994428], dtype=float32), 1.1242269]. 
=============================================
[2019-03-23 11:41:37,062] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.2625336e-29 1.0000000e+00 0.0000000e+00 1.9805242e-29 0.0000000e+00], sum to 1.0000
[2019-03-23 11:41:37,070] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6747
[2019-03-23 11:41:37,074] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333334, 86.33333333333334, 1.0, 2.0, 0.4022999060115081, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 455188.4364264177, 455188.4364264177, 126112.8960155551], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5104200.0000, 
sim time next is 5104800.0000, 
raw observation next is [20.0, 88.0, 1.0, 2.0, 0.396307542427241, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 447932.3441310672, 447932.3441310672, 125272.1571426697], 
processed observation next is [0.0, 0.08695652173913043, 0.5454545454545454, 0.88, 1.0, 1.0, 0.2453844280340512, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16590086819669156, 0.16590086819669156, 0.3055418466894383], 
reward next is 0.6945, 
noisyNet noise sample is [array([0.41025773], dtype=float32), 1.0950621]. 
=============================================
[2019-03-23 11:41:37,320] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.0123896e-28 1.0000000e+00 0.0000000e+00 8.4216515e-30 1.9013335e-37], sum to 1.0000
[2019-03-23 11:41:37,329] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2529
[2019-03-23 11:41:37,337] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 83.0, 1.0, 2.0, 0.4347426442030251, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 495308.1266007958, 495308.1266007961, 131937.0241925562], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5125800.0000, 
sim time next is 5126400.0000, 
raw observation next is [22.0, 83.0, 1.0, 2.0, 0.4359823245783909, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 496722.085913942, 496722.085913942, 132064.7324437203], 
processed observation next is [0.0, 0.34782608695652173, 0.6363636363636364, 0.83, 1.0, 1.0, 0.2949779057229886, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18397114293108963, 0.18397114293108963, 0.32210910352126904], 
reward next is 0.6779, 
noisyNet noise sample is [array([-0.9177018], dtype=float32), -0.7685444]. 
=============================================
[2019-03-23 11:41:37,996] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.9489972e-29 1.0000000e+00 0.0000000e+00 2.2727203e-35 1.6157528e-38], sum to 1.0000
[2019-03-23 11:41:38,003] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7169
[2019-03-23 11:41:38,006] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.33333333333334, 66.0, 1.0, 2.0, 0.5506329912322214, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 624615.6477994922, 624615.6477994922, 150572.9041572979], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5154000.0000, 
sim time next is 5154600.0000, 
raw observation next is [27.16666666666666, 66.0, 1.0, 2.0, 0.5438595622708962, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 617552.850102115, 617552.850102115, 149432.5233408348], 
processed observation next is [0.0, 0.6521739130434783, 0.871212121212121, 0.66, 1.0, 1.0, 0.42982445283862014, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22872327781559812, 0.22872327781559812, 0.3644695691239873], 
reward next is 0.6355, 
noisyNet noise sample is [array([0.48142502], dtype=float32), -0.12970215]. 
=============================================
[2019-03-23 11:41:43,373] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.7462030e-24 1.0000000e+00 2.1669839e-34 6.8605655e-28 1.7725388e-33], sum to 1.0000
[2019-03-23 11:41:43,381] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4182
[2019-03-23 11:41:43,386] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.58333333333334, 99.0, 1.0, 2.0, 0.5082729198349857, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 579391.3993883285, 579391.3993883285, 143428.3330669244], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5262600.0000, 
sim time next is 5263200.0000, 
raw observation next is [21.5, 100.0, 1.0, 2.0, 0.5091433106194566, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 580323.253879287, 580323.2538792868, 143602.2588631997], 
processed observation next is [1.0, 0.9565217391304348, 0.6136363636363636, 1.0, 1.0, 1.0, 0.38642913827432074, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21493453847381003, 0.21493453847380994, 0.3502494118614627], 
reward next is 0.6498, 
noisyNet noise sample is [array([-0.5034272], dtype=float32), -1.2073349]. 
=============================================
[2019-03-23 11:41:44,190] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.7782983e-31 1.0000000e+00 0.0000000e+00 4.5244869e-34 0.0000000e+00], sum to 1.0000
[2019-03-23 11:41:44,196] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9393
[2019-03-23 11:41:44,199] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.9, 87.0, 1.0, 2.0, 0.3574230102779145, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 398082.4284094052, 398082.4284094055, 118889.1704585334], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5289000.0000, 
sim time next is 5289600.0000, 
raw observation next is [19.0, 87.0, 1.0, 2.0, 0.3474498041486415, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 387482.4787783488, 387482.4787783491, 118315.6109285052], 
processed observation next is [1.0, 0.21739130434782608, 0.5, 0.87, 1.0, 1.0, 0.18431225518580188, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14351202917716624, 0.14351202917716635, 0.2885746608012322], 
reward next is 0.7114, 
noisyNet noise sample is [array([0.2466732], dtype=float32), -0.5743112]. 
=============================================
[2019-03-23 11:41:45,627] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-23 11:41:45,629] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 11:41:45,630] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:41:45,632] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 11:41:45,632] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:41:45,632] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 11:41:45,634] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 11:41:45,634] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 11:41:45,637] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:41:45,638] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:41:45,638] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:41:45,655] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run83
[2019-03-23 11:41:45,680] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run83
[2019-03-23 11:41:45,705] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run83
[2019-03-23 11:41:45,707] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run83
[2019-03-23 11:41:45,770] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run83
[2019-03-23 11:41:59,162] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -0.98586684]
[2019-03-23 11:41:59,164] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.51666666666667, 84.5, 1.0, 2.0, 0.4367391012815002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 496916.9836915644, 496916.9836915641, 135765.7798570875]
[2019-03-23 11:41:59,165] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 11:41:59,168] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.5015687e-28 1.0000000e+00 0.0000000e+00 4.2543245e-32 0.0000000e+00], sampled 0.10586530658831905
[2019-03-23 11:42:26,786] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -0.98586684]
[2019-03-23 11:42:26,787] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.71666666666667, 76.5, 1.0, 2.0, 0.4814878870486204, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 549356.0989238428, 549356.0989238424, 142965.3068271487]
[2019-03-23 11:42:26,789] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 11:42:26,792] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.5015687e-28 1.0000000e+00 0.0000000e+00 4.2543245e-32 0.0000000e+00], sampled 0.9533780321851011
[2019-03-23 11:42:34,270] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -0.98586684]
[2019-03-23 11:42:34,271] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [23.08060701, 59.19470723, 1.0, 2.0, 0.445144999021344, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 497718.5989484285, 497718.5989484285, 131542.0460276157]
[2019-03-23 11:42:34,272] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 11:42:34,275] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.5015687e-28 1.0000000e+00 0.0000000e+00 4.2543245e-32 0.0000000e+00], sampled 0.8580065537949837
[2019-03-23 11:42:44,772] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -0.98586684]
[2019-03-23 11:42:44,773] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.8, 44.0, 1.0, 2.0, 0.3173596559617428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 344589.1007885188, 344589.1007885188, 116676.7099235228]
[2019-03-23 11:42:44,773] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 11:42:44,776] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.5015687e-28 1.0000000e+00 0.0000000e+00 4.2543245e-32 0.0000000e+00], sampled 0.6492975370106114
[2019-03-23 11:43:23,059] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 11:43:23,160] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 11:43:23,544] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 11:43:23,597] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 11:43:23,643] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 11:43:24,659] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 2050000, evaluation results [2050000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 11:43:31,935] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.9594929e-26 1.0000000e+00 3.9353927e-37 9.9381753e-29 1.8802579e-37], sum to 1.0000
[2019-03-23 11:43:31,944] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7205
[2019-03-23 11:43:31,948] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 97.0, 1.0, 2.0, 0.3914521612993849, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 441579.8267552112, 441579.8267552112, 124335.5982294583], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5439600.0000, 
sim time next is 5440200.0000, 
raw observation next is [18.8, 96.33333333333334, 1.0, 2.0, 0.3911685220501076, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 441137.0658699575, 441137.0658699572, 124242.1042926112], 
processed observation next is [1.0, 1.0, 0.49090909090909096, 0.9633333333333334, 1.0, 1.0, 0.2389606525626345, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16338409847035462, 0.1633840984703545, 0.30302952266490535], 
reward next is 0.6970, 
noisyNet noise sample is [array([-1.1307036], dtype=float32), -1.2820889]. 
=============================================
[2019-03-23 11:43:32,807] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.9810621e-28 1.0000000e+00 0.0000000e+00 1.1467296e-36 0.0000000e+00], sum to 1.0000
[2019-03-23 11:43:32,815] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7217
[2019-03-23 11:43:32,821] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 97.0, 1.0, 2.0, 0.3558380742791467, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 396354.9853073673, 396354.9853073676, 118777.7552956398], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5450400.0000, 
sim time next is 5451000.0000, 
raw observation next is [17.7, 97.0, 1.0, 2.0, 0.3937383839429948, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 438475.8232771831, 438475.8232771831, 121864.4152406062], 
processed observation next is [1.0, 0.08695652173913043, 0.44090909090909086, 0.97, 1.0, 1.0, 0.2421729799287435, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16239845306562337, 0.16239845306562337, 0.29723028107464927], 
reward next is 0.7028, 
noisyNet noise sample is [array([-2.347125], dtype=float32), 0.27122486]. 
=============================================
[2019-03-23 11:43:32,837] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[69.94301]
 [69.94301]
 [69.94301]
 [69.94301]
 [69.94301]], R is [[69.94633484]
 [69.95716858]
 [69.96656036]
 [69.97451782]
 [69.98107147]].
[2019-03-23 11:43:38,887] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.4550569e-26 1.0000000e+00 1.5053938e-36 7.0670117e-28 2.3151854e-36], sum to 1.0000
[2019-03-23 11:43:38,894] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7561
[2019-03-23 11:43:38,898] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 90.0, 1.0, 2.0, 0.4282060805361732, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 486507.013255471, 486507.013255471, 129943.186070107], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5551800.0000, 
sim time next is 5552400.0000, 
raw observation next is [20.5, 90.0, 1.0, 2.0, 0.4247483549473416, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 482582.5407914596, 482582.5407914593, 129607.684722063], 
processed observation next is [1.0, 0.2608695652173913, 0.5681818181818182, 0.9, 1.0, 1.0, 0.28093544368417694, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17873427436720726, 0.17873427436720715, 0.3161163042001537], 
reward next is 0.6839, 
noisyNet noise sample is [array([0.22957219], dtype=float32), -1.0956708]. 
=============================================
[2019-03-23 11:43:40,197] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.9426752e-22 1.0000000e+00 2.5746977e-30 2.1002204e-23 7.1745705e-30], sum to 1.0000
[2019-03-23 11:43:40,209] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0665
[2019-03-23 11:43:40,220] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1441983.971635122 W.
[2019-03-23 11:43:40,224] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.25, 58.0, 1.0, 2.0, 0.6385319843370113, 1.0, 1.0, 0.6385319843370113, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1441983.971635122, 1441983.971635121, 271735.6775549465], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5578200.0000, 
sim time next is 5578800.0000, 
raw observation next is [28.43333333333333, 57.0, 1.0, 2.0, 0.6368014179849081, 1.0, 2.0, 0.6368014179849081, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1436305.826310662, 1436305.826310662, 271665.8405699634], 
processed observation next is [1.0, 0.5652173913043478, 0.9287878787878786, 0.57, 1.0, 1.0, 0.546001772481135, 1.0, 1.0, 0.546001772481135, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.5319651208558007, 0.5319651208558007, 0.6625996111462522], 
reward next is 0.3374, 
noisyNet noise sample is [array([0.7275779], dtype=float32), 0.35604525]. 
=============================================
[2019-03-23 11:43:40,620] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.4946889e-25 1.0000000e+00 1.0372627e-33 6.8656971e-28 6.1134977e-34], sum to 1.0000
[2019-03-23 11:43:40,628] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8168
[2019-03-23 11:43:40,634] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.8, 68.0, 1.0, 2.0, 0.3657885819922166, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 409400.9380111362, 409400.9380111362, 120447.4855827354], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5960400.0000, 
sim time next is 5961000.0000, 
raw observation next is [21.7, 68.0, 1.0, 2.0, 0.3630921442773042, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 405901.3181371827, 405901.3181371827, 120004.0945841558], 
processed observation next is [1.0, 1.0, 0.6227272727272727, 0.68, 1.0, 1.0, 0.2038651803466302, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15033382153228989, 0.15033382153228989, 0.2926929136198922], 
reward next is 0.7073, 
noisyNet noise sample is [array([1.259059], dtype=float32), 0.58558565]. 
=============================================
[2019-03-23 11:43:40,648] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[51.173946]
 [51.173946]
 [51.173946]
 [51.173946]
 [51.173946]], R is [[51.36951447]
 [51.56204605]
 [51.75159454]
 [51.93806076]
 [52.12138748]].
[2019-03-23 11:43:45,440] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.3823517e-33 1.0000000e+00 0.0000000e+00 2.1406525e-33 0.0000000e+00], sum to 1.0000
[2019-03-23 11:43:45,452] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8415
[2019-03-23 11:43:45,455] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.2, 69.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 214281.2746398477, 214281.2746398475, 69099.13272316182], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5690400.0000, 
sim time next is 5691000.0000, 
raw observation next is [14.0, 69.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 211070.2085857615, 211070.2085857618, 68350.01646678202], 
processed observation next is [0.0, 0.8695652173913043, 0.2727272727272727, 0.69, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07817415132805981, 0.07817415132805992, 0.1667073572360537], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.11886936], dtype=float32), -0.2919814]. 
=============================================
[2019-03-23 11:43:45,464] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[77.26522]
 [77.26522]
 [77.26522]
 [77.26522]
 [77.26522]], R is [[76.49256134]
 [75.72763824]
 [74.9703598 ]
 [74.22065735]
 [74.30654907]].
[2019-03-23 11:43:45,672] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.3029884e-29 1.0000000e+00 0.0000000e+00 6.2632786e-33 0.0000000e+00], sum to 1.0000
[2019-03-23 11:43:45,679] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6745
[2019-03-23 11:43:45,685] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1232692.434590601 W.
[2019-03-23 11:43:45,689] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.45, 46.5, 1.0, 2.0, 0.6002544570377942, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9636316121451411, 6.9112, 6.9112, 77.32846341705653, 1232692.434590601, 1232692.434590601, 263997.7129223383], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5934600.0000, 
sim time next is 5935200.0000, 
raw observation next is [27.36666666666667, 46.66666666666667, 1.0, 2.0, 0.5286529970467189, 1.0, 1.0, 0.5286529970467189, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.3284634433771, 1206982.015767909, 1206982.015767909, 230641.2862160519], 
processed observation next is [1.0, 0.6956521739130435, 0.8803030303030305, 0.46666666666666673, 1.0, 1.0, 0.4108162463083985, 1.0, 0.5, 0.4108162463083985, 0.0, 0.5, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129195762, 0.44703037621033664, 0.44703037621033664, 0.5625397224781754], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2887292], dtype=float32), 1.5979486]. 
=============================================
[2019-03-23 11:43:48,433] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.3947463e-21 1.0000000e+00 5.3221955e-31 5.1584356e-21 1.1393255e-29], sum to 1.0000
[2019-03-23 11:43:48,440] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0592
[2019-03-23 11:43:48,445] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.3, 74.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 177097.4003053373, 177097.400305337, 62566.34799893029], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5731200.0000, 
sim time next is 5731800.0000, 
raw observation next is [13.66666666666667, 72.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 181699.8228914462, 181699.8228914462, 63469.92223899032], 
processed observation next is [0.0, 0.34782608695652173, 0.25757575757575774, 0.72, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.06729623070053563, 0.06729623070053563, 0.15480468838778128], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.78150713], dtype=float32), 1.3346995]. 
=============================================
[2019-03-23 11:43:55,655] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.7851112e-31 1.0000000e+00 0.0000000e+00 1.9684518e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 11:43:55,662] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8857
[2019-03-23 11:43:55,666] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 54.0, 1.0, 2.0, 0.327586524279858, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 360808.2389943374, 360808.2389943374, 114900.092701756], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5862600.0000, 
sim time next is 5863200.0000, 
raw observation next is [22.9, 55.0, 1.0, 2.0, 0.3266574551987515, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 360215.0618025628, 360215.0618025628, 114997.1768303488], 
processed observation next is [1.0, 0.8695652173913043, 0.6772727272727272, 0.55, 1.0, 1.0, 0.15832181899843936, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13341298585280104, 0.13341298585280104, 0.2804809190984117], 
reward next is 0.7195, 
noisyNet noise sample is [array([-1.6341928], dtype=float32), -0.5336445]. 
=============================================
[2019-03-23 11:43:56,781] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.0912619e-28 1.0000000e+00 0.0000000e+00 1.2041011e-31 0.0000000e+00], sum to 1.0000
[2019-03-23 11:43:56,787] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7039
[2019-03-23 11:43:56,794] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.93333333333333, 67.16666666666666, 1.0, 2.0, 0.7384602677116892, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 835708.9482273972, 835708.9482273969, 164776.3665605325], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5910600.0000, 
sim time next is 5911200.0000, 
raw observation next is [23.3, 66.0, 1.0, 2.0, 0.7589839674208169, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 860116.8772896129, 860116.8772896127, 168354.8030187569], 
processed observation next is [1.0, 0.43478260869565216, 0.6954545454545454, 0.66, 1.0, 1.0, 0.698729959276021, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.31856180640356035, 0.31856180640356024, 0.41062147077745587], 
reward next is 0.5894, 
noisyNet noise sample is [array([0.41223052], dtype=float32), -0.57502824]. 
=============================================
[2019-03-23 11:43:59,761] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.1292388e-29 1.0000000e+00 0.0000000e+00 1.8168096e-34 0.0000000e+00], sum to 1.0000
[2019-03-23 11:43:59,766] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3560
[2019-03-23 11:43:59,774] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 85.0, 1.0, 2.0, 0.3631547130483975, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 403834.8904685691, 403834.8904685691, 119086.5820798415], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5971200.0000, 
sim time next is 5971800.0000, 
raw observation next is [18.9, 86.0, 1.0, 2.0, 0.3596648097439566, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 400047.4688087259, 400047.4688087259, 118845.3233514278], 
processed observation next is [1.0, 0.08695652173913043, 0.49545454545454537, 0.86, 1.0, 1.0, 0.19958101217994573, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.148165729188417, 0.148165729188417, 0.2898666423205556], 
reward next is 0.7101, 
noisyNet noise sample is [array([0.32304993], dtype=float32), -0.4313315]. 
=============================================
[2019-03-23 11:44:04,499] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.5342468e-30 1.0000000e+00 0.0000000e+00 5.5725882e-33 0.0000000e+00], sum to 1.0000
[2019-03-23 11:44:04,506] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1827
[2019-03-23 11:44:04,509] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.9, 79.33333333333334, 1.0, 2.0, 0.2521725103478644, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 273807.4774870933, 273807.477487093, 82267.33641407182], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6056400.0000, 
sim time next is 6057000.0000, 
raw observation next is [15.8, 79.0, 1.0, 2.0, 0.2380766579582266, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 258498.2138179602, 258498.2138179599, 80062.18840564314], 
processed observation next is [1.0, 0.08695652173913043, 0.35454545454545455, 0.79, 1.0, 1.0, 0.047595822447783244, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09574007919183711, 0.09574007919183701, 0.1952736302576662], 
reward next is 0.8047, 
noisyNet noise sample is [array([0.98605335], dtype=float32), -1.411515]. 
=============================================
[2019-03-23 11:44:04,521] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[75.61795]
 [75.61795]
 [75.61795]
 [75.61795]
 [75.61795]], R is [[75.66649628]
 [75.70918274]
 [75.74557495]
 [75.78666687]
 [75.8250885 ]].
[2019-03-23 11:44:08,596] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0395692e-31 1.0000000e+00 0.0000000e+00 3.1083001e-36 0.0000000e+00], sum to 1.0000
[2019-03-23 11:44:08,604] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8926
[2019-03-23 11:44:08,607] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.3, 75.0, 1.0, 2.0, 0.2880317909917877, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 312755.8000494815, 312755.8000494815, 103120.8446124918], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6138000.0000, 
sim time next is 6138600.0000, 
raw observation next is [18.11666666666667, 76.5, 1.0, 2.0, 0.2887854142243096, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 313574.3764493893, 313574.376449389, 103374.7318834981], 
processed observation next is [1.0, 0.043478260869565216, 0.459848484848485, 0.765, 1.0, 1.0, 0.11098176778038697, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11613865794421827, 0.11613865794421814, 0.25213349239877586], 
reward next is 0.7479, 
noisyNet noise sample is [array([0.91418636], dtype=float32), -0.6707855]. 
=============================================
[2019-03-23 11:44:10,767] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.4756523e-28 1.0000000e+00 0.0000000e+00 7.7658346e-34 0.0000000e+00], sum to 1.0000
[2019-03-23 11:44:10,774] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1646
[2019-03-23 11:44:10,778] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 76.0, 1.0, 2.0, 0.5876781916664858, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 647588.889055846, 647588.8890558457, 138146.2834196305], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6166800.0000, 
sim time next is 6167400.0000, 
raw observation next is [19.68333333333333, 74.33333333333334, 1.0, 2.0, 0.6142084594389067, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 677521.6118283011, 677521.6118283011, 141205.5910318717], 
processed observation next is [1.0, 0.391304347826087, 0.5310606060606059, 0.7433333333333334, 1.0, 1.0, 0.5177605742986333, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2509339303067782, 0.2509339303067782, 0.3444038805655407], 
reward next is 0.6556, 
noisyNet noise sample is [array([-1.2419124], dtype=float32), -0.97705656]. 
=============================================
[2019-03-23 11:44:13,659] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 11:44:13,662] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 11:44:13,663] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:44:13,666] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 11:44:13,667] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:44:13,672] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 11:44:13,672] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:44:13,675] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 11:44:13,676] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:44:13,676] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 11:44:13,677] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:44:13,687] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run84
[2019-03-23 11:44:13,712] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run84
[2019-03-23 11:44:13,713] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run84
[2019-03-23 11:44:13,766] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run84
[2019-03-23 11:44:13,797] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run84
[2019-03-23 11:44:28,633] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -0.972087]
[2019-03-23 11:44:28,634] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [26.13130557, 54.94779445, 1.0, 2.0, 0.663023355698807, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 755004.1386374091, 755004.1386374091, 162692.523112733]
[2019-03-23 11:44:28,635] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 11:44:28,636] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.7492187e-29 1.0000000e+00 0.0000000e+00 1.2016822e-32 0.0000000e+00], sampled 0.31703859288151215
[2019-03-23 11:44:35,978] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -0.972087]
[2019-03-23 11:44:35,979] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.81378737, 76.68623191166667, 1.0, 2.0, 0.4362357261522843, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 494439.3285298216, 494439.3285298212, 134204.6274788783]
[2019-03-23 11:44:35,980] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 11:44:35,983] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.7492187e-29 1.0000000e+00 0.0000000e+00 1.2016822e-32 0.0000000e+00], sampled 0.49538894617793305
[2019-03-23 11:44:39,360] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -0.972087]
[2019-03-23 11:44:39,362] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [15.18626029, 100.0, 1.0, 2.0, 0.2609931383141143, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 283371.9098325719, 283371.9098325719, 100083.8785327229]
[2019-03-23 11:44:39,362] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 11:44:39,365] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.7492187e-29 1.0000000e+00 0.0000000e+00 1.2016822e-32 0.0000000e+00], sampled 0.2589623983192868
[2019-03-23 11:44:54,712] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -0.972087]
[2019-03-23 11:44:54,712] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.55856565333334, 76.37267694500001, 1.0, 2.0, 0.7716844532799473, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769669947, 879051.4281460211, 879051.4281460211, 184991.4583011248]
[2019-03-23 11:44:54,713] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 11:44:54,716] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.7492187e-29 1.0000000e+00 0.0000000e+00 1.2016822e-32 0.0000000e+00], sampled 0.8598663054024028
[2019-03-23 11:45:30,322] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -0.972087]
[2019-03-23 11:45:30,323] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.92768928, 77.47249682, 1.0, 2.0, 0.5010459520868241, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 571580.1220456143, 571580.1220456143, 146021.2928926357]
[2019-03-23 11:45:30,324] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 11:45:30,328] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.7492187e-29 1.0000000e+00 0.0000000e+00 1.2016822e-32 0.0000000e+00], sampled 0.16587413485162017
[2019-03-23 11:45:34,986] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -0.972087]
[2019-03-23 11:45:34,987] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.8, 90.0, 1.0, 2.0, 0.3579318528611459, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 400173.5575702832, 400173.5575702835, 119600.3465657158]
[2019-03-23 11:45:34,988] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 11:45:34,991] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.7492187e-29 1.0000000e+00 0.0000000e+00 1.2016822e-32 0.0000000e+00], sampled 0.9703345603721939
[2019-03-23 11:45:46,701] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -0.972087]
[2019-03-23 11:45:46,702] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.0, 57.0, 1.0, 2.0, 0.3577370937387017, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 401831.3488833489, 401831.3488833489, 124802.3409893729]
[2019-03-23 11:45:46,702] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 11:45:46,704] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.7492187e-29 1.0000000e+00 0.0000000e+00 1.2016822e-32 0.0000000e+00], sampled 0.9688983465584479
[2019-03-23 11:45:50,162] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -0.972087]
[2019-03-23 11:45:50,164] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [13.92634319666667, 92.71259697333332, 1.0, 2.0, 0.241016734551719, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 261677.914387745, 261677.9143877446, 83221.33567422489]
[2019-03-23 11:45:50,167] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 11:45:50,171] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.7492187e-29 1.0000000e+00 0.0000000e+00 1.2016822e-32 0.0000000e+00], sampled 0.0574595546679908
[2019-03-23 11:45:51,530] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 11:45:51,637] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 11:45:51,758] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 11:45:51,814] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 11:45:51,843] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 11:45:52,862] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 2075000, evaluation results [2075000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 11:45:57,356] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.4088786e-27 1.0000000e+00 0.0000000e+00 7.1203527e-34 0.0000000e+00], sum to 1.0000
[2019-03-23 11:45:57,364] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8923
[2019-03-23 11:45:57,372] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.2, 87.0, 1.0, 2.0, 0.4669439120475695, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 532793.1986276763, 532793.1986276763, 136896.44599159], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6327600.0000, 
sim time next is 6328200.0000, 
raw observation next is [22.2, 87.0, 1.0, 2.0, 0.4673167703744261, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 533218.8839629259, 533218.8839629262, 136937.3756995071], 
processed observation next is [0.0, 0.21739130434782608, 0.6454545454545454, 0.87, 1.0, 1.0, 0.33414596296803256, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1974884755418244, 0.19748847554182453, 0.3339935992670905], 
reward next is 0.6660, 
noisyNet noise sample is [array([0.14865953], dtype=float32), -0.8638469]. 
=============================================
[2019-03-23 11:46:00,535] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.1851029e-26 1.0000000e+00 4.0391816e-37 1.9968822e-27 5.4221892e-35], sum to 1.0000
[2019-03-23 11:46:00,544] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8097
[2019-03-23 11:46:00,551] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 80.16666666666667, 1.0, 2.0, 0.5550241320382218, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 629773.0287207526, 629773.0287207528, 151067.5405226552], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6383400.0000, 
sim time next is 6384000.0000, 
raw observation next is [25.0, 79.33333333333334, 1.0, 2.0, 0.5501144938231929, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 624683.0030530975, 624683.0030530975, 150220.1466709267], 
processed observation next is [0.0, 0.9130434782608695, 0.7727272727272727, 0.7933333333333334, 1.0, 1.0, 0.4376431172789911, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23136407520485094, 0.23136407520485094, 0.36639060163640663], 
reward next is 0.6336, 
noisyNet noise sample is [array([-0.43336666], dtype=float32), -0.17466345]. 
=============================================
[2019-03-23 11:46:00,567] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[65.61266]
 [65.61266]
 [65.61266]
 [65.61266]
 [65.61266]], R is [[65.59013367]
 [65.56578064]
 [65.5400238 ]
 [65.51381683]
 [65.48724365]].
[2019-03-23 11:46:01,499] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.6332093e-28 1.0000000e+00 0.0000000e+00 1.5839569e-31 1.2762515e-37], sum to 1.0000
[2019-03-23 11:46:01,512] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5573
[2019-03-23 11:46:01,515] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.4, 74.0, 1.0, 2.0, 0.4862861872565398, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 554857.0319315863, 554857.0319315863, 139786.643496403], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6422400.0000, 
sim time next is 6423000.0000, 
raw observation next is [23.93333333333333, 76.83333333333334, 1.0, 2.0, 0.5371093847793537, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 612893.0468344424, 612893.0468344424, 145706.0724052248], 
processed observation next is [1.0, 0.34782608695652173, 0.7242424242424241, 0.7683333333333334, 1.0, 1.0, 0.42138673097419205, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22699742475349718, 0.22699742475349718, 0.3553806644029873], 
reward next is 0.6446, 
noisyNet noise sample is [array([1.11202], dtype=float32), 2.655665]. 
=============================================
[2019-03-23 11:46:01,532] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[63.13571]
 [63.13571]
 [63.13571]
 [63.13571]
 [63.13571]], R is [[63.14897156]
 [63.17654037]
 [63.2033577 ]
 [63.22402191]
 [63.23326492]].
[2019-03-23 11:46:10,314] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.2909149e-33 1.0000000e+00 0.0000000e+00 6.9732027e-36 0.0000000e+00], sum to 1.0000
[2019-03-23 11:46:10,322] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6794
[2019-03-23 11:46:10,337] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.4, 82.33333333333334, 1.0, 2.0, 0.2038059782493547, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 221279.425861868, 221279.4258618683, 72978.90723822007], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6571200.0000, 
sim time next is 6571800.0000, 
raw observation next is [14.4, 82.0, 1.0, 2.0, 0.2032305474932388, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 220654.518438568, 220654.5184385683, 72827.26019872053], 
processed observation next is [1.0, 0.043478260869565216, 0.29090909090909095, 0.82, 1.0, 1.0, 0.004038184366548479, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08172389571798815, 0.08172389571798826, 0.17762746389931836], 
reward next is 0.8224, 
noisyNet noise sample is [array([0.10564435], dtype=float32), 0.5632757]. 
=============================================
[2019-03-23 11:46:13,517] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.6862405e-25 1.0000000e+00 1.4083140e-35 3.9284748e-31 9.5235011e-35], sum to 1.0000
[2019-03-23 11:46:13,528] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6255
[2019-03-23 11:46:13,530] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.9, 68.5, 1.0, 2.0, 0.3672095462834377, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 411677.7833312263, 411677.7833312263, 120887.420879184], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6629400.0000, 
sim time next is 6630000.0000, 
raw observation next is [21.8, 69.33333333333333, 1.0, 2.0, 0.3680831262001744, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 412745.5320198758, 412745.5320198761, 121002.8972587783], 
processed observation next is [1.0, 0.7391304347826086, 0.6272727272727273, 0.6933333333333332, 1.0, 1.0, 0.210103907750218, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15286871556291698, 0.1528687155629171, 0.29512901770433736], 
reward next is 0.7049, 
noisyNet noise sample is [array([-1.2706863], dtype=float32), 0.95195997]. 
=============================================
[2019-03-23 11:46:13,543] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[62.653385]
 [62.653385]
 [62.653385]
 [62.653385]
 [62.653385]], R is [[62.7317276 ]
 [62.8095665 ]
 [62.88463593]
 [62.93312454]
 [62.90161896]].
[2019-03-23 11:46:18,579] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.8516286e-28 1.0000000e+00 0.0000000e+00 8.3310525e-33 0.0000000e+00], sum to 1.0000
[2019-03-23 11:46:18,588] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9953
[2019-03-23 11:46:18,595] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 97.0, 1.0, 2.0, 0.3569796341583877, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 397446.7611131909, 397446.7611131906, 118793.0385180784], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6726600.0000, 
sim time next is 6727200.0000, 
raw observation next is [17.7, 97.0, 1.0, 2.0, 0.3562432626319031, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 396622.4417906591, 396622.4417906591, 118732.1885728334], 
processed observation next is [1.0, 0.8695652173913043, 0.44090909090909086, 0.97, 1.0, 1.0, 0.19530407828987884, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14689720066320708, 0.14689720066320708, 0.289590703836179], 
reward next is 0.7104, 
noisyNet noise sample is [array([0.14876983], dtype=float32), 1.4124337]. 
=============================================
[2019-03-23 11:46:22,066] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.2969060e-28 1.0000000e+00 4.7299417e-38 4.9033242e-28 1.5751429e-37], sum to 1.0000
[2019-03-23 11:46:22,077] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8102
[2019-03-23 11:46:22,083] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.11666666666666, 67.66666666666666, 1.0, 2.0, 0.7524020062905419, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 857443.1355986105, 857443.1355986103, 171398.3691577474], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6785400.0000, 
sim time next is 6786000.0000, 
raw observation next is [24.4, 66.0, 1.0, 2.0, 0.6667026342530882, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 759701.7684583683, 759701.7684583685, 159321.6966319043], 
processed observation next is [1.0, 0.5652173913043478, 0.7454545454545454, 0.66, 1.0, 1.0, 0.5833782928163602, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.28137102535495123, 0.2813710253549513, 0.38858950398025444], 
reward next is 0.6114, 
noisyNet noise sample is [array([0.22046722], dtype=float32), -0.27886957]. 
=============================================
[2019-03-23 11:46:22,097] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[61.004646]
 [61.004646]
 [61.004646]
 [61.004646]
 [61.004646]], R is [[61.00600815]
 [60.97790527]
 [60.96843719]
 [60.98934174]
 [60.97014236]].
[2019-03-23 11:46:31,312] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.20683901e-25 1.00000000e+00 1.97001431e-35 2.30668899e-27
 1.07098835e-35], sum to 1.0000
[2019-03-23 11:46:31,324] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5263
[2019-03-23 11:46:31,334] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.3, 56.0, 1.0, 2.0, 0.5104344143504287, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 581672.9160126221, 581672.9160126221, 143887.8123549598], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6963000.0000, 
sim time next is 6963600.0000, 
raw observation next is [28.3, 56.0, 1.0, 2.0, 0.5083853903246626, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 579336.4532610299, 579336.4532610299, 143643.210924984], 
processed observation next is [0.0, 0.6086956521739131, 0.9227272727272727, 0.56, 1.0, 1.0, 0.3854817379058282, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21456905676334442, 0.21456905676334442, 0.3503492949389854], 
reward next is 0.6497, 
noisyNet noise sample is [array([-1.4515476], dtype=float32), 0.72240114]. 
=============================================
[2019-03-23 11:46:31,686] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.5322486e-30 1.0000000e+00 0.0000000e+00 9.7747716e-29 0.0000000e+00], sum to 1.0000
[2019-03-23 11:46:31,693] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2497
[2019-03-23 11:46:31,701] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.2, 56.33333333333334, 1.0, 2.0, 0.5060769506975179, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 576772.009624317, 576772.009624317, 143297.2550050317], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6961800.0000, 
sim time next is 6962400.0000, 
raw observation next is [28.3, 56.0, 1.0, 2.0, 0.5103524332367076, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 581593.4896801997, 581593.4896801993, 143863.6381546253], 
processed observation next is [0.0, 0.6086956521739131, 0.9227272727272727, 0.56, 1.0, 1.0, 0.38794054154588453, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21540499617785172, 0.21540499617785158, 0.3508869223283544], 
reward next is 0.6491, 
noisyNet noise sample is [array([1.3037153], dtype=float32), 0.52218497]. 
=============================================
[2019-03-23 11:46:32,687] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.2107203e-25 1.0000000e+00 2.7910490e-36 1.6505391e-31 4.7763842e-35], sum to 1.0000
[2019-03-23 11:46:32,697] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7581
[2019-03-23 11:46:32,703] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.01666666666667, 85.5, 1.0, 2.0, 0.456531008373326, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 520638.3664606047, 520638.3664606047, 134953.863750597], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7002600.0000, 
sim time next is 7003200.0000, 
raw observation next is [21.83333333333334, 87.0, 1.0, 2.0, 0.4581657369131668, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 522518.9469584154, 522518.9469584154, 135159.0428556977], 
processed observation next is [1.0, 0.043478260869565216, 0.628787878787879, 0.87, 1.0, 1.0, 0.32270717114145847, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1935255359105242, 0.1935255359105242, 0.3296562020870676], 
reward next is 0.6703, 
noisyNet noise sample is [array([-0.14523418], dtype=float32), 0.7083402]. 
=============================================
[2019-03-23 11:46:36,891] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.5285119e-29 1.0000000e+00 0.0000000e+00 5.8204197e-36 0.0000000e+00], sum to 1.0000
[2019-03-23 11:46:36,898] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5227
[2019-03-23 11:46:36,902] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.55, 93.0, 1.0, 2.0, 0.3726007236611405, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 417266.8685139545, 417266.8685139548, 121127.0923313897], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7075800.0000, 
sim time next is 7076400.0000, 
raw observation next is [18.46666666666667, 93.0, 1.0, 2.0, 0.3698816849634241, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 413782.3186862787, 413782.3186862787, 120696.8131373809], 
processed observation next is [1.0, 0.9130434782608695, 0.4757575757575758, 0.93, 1.0, 1.0, 0.2123521062042801, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15325271062454768, 0.15325271062454768, 0.29438247106678267], 
reward next is 0.7056, 
noisyNet noise sample is [array([-1.9429371], dtype=float32), 0.80651104]. 
=============================================
[2019-03-23 11:46:38,857] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.2948858e-33 1.0000000e+00 0.0000000e+00 6.5482691e-36 0.0000000e+00], sum to 1.0000
[2019-03-23 11:46:38,866] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3543
[2019-03-23 11:46:38,873] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 50.0, 1.0, 2.0, 0.7594114202364457, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 843134.3747823638, 843134.3747823638, 160180.4924306367], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7136400.0000, 
sim time next is 7137000.0000, 
raw observation next is [24.1, 50.0, 1.0, 2.0, 0.7685774944784577, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 854383.0989417875, 854383.0989417875, 161778.2038928599], 
processed observation next is [1.0, 0.6086956521739131, 0.7318181818181819, 0.5, 1.0, 1.0, 0.710721868098072, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.31643818479325464, 0.31643818479325464, 0.3945809851045363], 
reward next is 0.6054, 
noisyNet noise sample is [array([-0.4547891], dtype=float32), 1.9426978]. 
=============================================
[2019-03-23 11:46:38,887] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[72.15547]
 [72.15547]
 [72.15547]
 [72.15547]
 [72.15547]], R is [[72.03933716]
 [71.9282608 ]
 [71.81732178]
 [71.71101379]
 [71.60984802]].
[2019-03-23 11:46:39,637] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.8913990e-27 1.0000000e+00 7.1652184e-37 3.5558146e-32 7.4609687e-38], sum to 1.0000
[2019-03-23 11:46:39,649] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5933
[2019-03-23 11:46:39,656] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.23333333333333, 57.0, 1.0, 2.0, 0.3051355134415185, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 331333.9948199583, 331333.9948199581, 110276.4721573456], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7152000.0000, 
sim time next is 7152600.0000, 
raw observation next is [20.86666666666667, 58.0, 1.0, 2.0, 0.3001789049960083, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 325950.0155960025, 325950.0155960022, 105838.128251656], 
processed observation next is [1.0, 0.782608695652174, 0.5848484848484851, 0.58, 1.0, 1.0, 0.12522363124501035, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12072222799851945, 0.12072222799851934, 0.2581417762235512], 
reward next is 0.7419, 
noisyNet noise sample is [array([0.4372605], dtype=float32), -0.1849167]. 
=============================================
[2019-03-23 11:46:41,955] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-23 11:46:41,955] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 11:46:41,956] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:46:41,958] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 11:46:41,958] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:46:41,961] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 11:46:41,962] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:46:41,962] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 11:46:41,963] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 11:46:41,963] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:46:41,964] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:46:41,983] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run85
[2019-03-23 11:46:42,011] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run85
[2019-03-23 11:46:42,037] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run85
[2019-03-23 11:46:42,038] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run85
[2019-03-23 11:46:42,074] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run85
[2019-03-23 11:46:52,277] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -0.9995086]
[2019-03-23 11:46:52,277] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [28.66346200666667, 71.95548759, 1.0, 2.0, 0.6671820423603362, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 749679.5152230337, 749679.5152230334, 172925.6463324396]
[2019-03-23 11:46:52,278] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 11:46:52,280] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [6.1360735e-32 1.0000000e+00 0.0000000e+00 6.2608089e-36 0.0000000e+00], sampled 0.5285971721479203
[2019-03-23 11:47:10,687] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -0.9995086]
[2019-03-23 11:47:10,690] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [13.0, 100.0, 1.0, 2.0, 0.2106226913409049, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 228682.3144302696, 228682.3144302693, 74714.27643076492]
[2019-03-23 11:47:10,691] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 11:47:10,694] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [6.1360735e-32 1.0000000e+00 0.0000000e+00 6.2608089e-36 0.0000000e+00], sampled 0.5805267791740898
[2019-03-23 11:47:31,862] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -0.9995086]
[2019-03-23 11:47:31,864] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [28.29781836166666, 50.47490247333334, 1.0, 2.0, 0.4854838199948694, 0.0, 2.0, 0.0, 1.0, 1.0, 0.8772838135865346, 7.041973413990537, 6.9112, 95.55296723860717, 1102065.892406135, 1049583.583886717, 247122.1895753628]
[2019-03-23 11:47:31,867] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 11:47:31,869] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [6.1360735e-32 1.0000000e+00 0.0000000e+00 6.2608089e-36 0.0000000e+00], sampled 0.7402449570937565
[2019-03-23 11:47:31,870] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1102065.892406135 W.
[2019-03-23 11:47:38,896] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -0.9995086]
[2019-03-23 11:47:38,899] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.01666666666667, 81.16666666666667, 1.0, 2.0, 0.6675964261310888, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 755931.2813471627, 755931.2813471627, 160010.5506170242]
[2019-03-23 11:47:38,901] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 11:47:38,906] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [6.1360735e-32 1.0000000e+00 0.0000000e+00 6.2608089e-36 0.0000000e+00], sampled 0.8248547556038937
[2019-03-23 11:47:43,225] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -0.9995086]
[2019-03-23 11:47:43,226] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.36666666666667, 73.66666666666667, 1.0, 2.0, 0.2741886071507134, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 297702.3680712124, 297702.3680712121, 104422.0124831706]
[2019-03-23 11:47:43,230] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 11:47:43,234] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [6.1360735e-32 1.0000000e+00 0.0000000e+00 6.2608089e-36 0.0000000e+00], sampled 0.17922946948760532
[2019-03-23 11:47:59,370] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -0.9995086]
[2019-03-23 11:47:59,371] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [25.76190677666667, 65.59320796, 1.0, 2.0, 0.4788619330607378, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 546364.827107216, 546364.827107216, 142883.7601973965]
[2019-03-23 11:47:59,371] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 11:47:59,373] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [6.1360735e-32 1.0000000e+00 0.0000000e+00 6.2608089e-36 0.0000000e+00], sampled 0.9114436111146248
[2019-03-23 11:48:07,640] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -0.9995086]
[2019-03-23 11:48:07,641] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.63471537666667, 92.89524903333334, 1.0, 2.0, 0.6371113612477551, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 726966.5601163052, 726966.5601163056, 162954.0252947583]
[2019-03-23 11:48:07,642] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 11:48:07,644] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [6.1360735e-32 1.0000000e+00 0.0000000e+00 6.2608089e-36 0.0000000e+00], sampled 0.6367627135542477
[2019-03-23 11:48:14,390] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -0.9995086]
[2019-03-23 11:48:14,391] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [14.6, 83.83333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 216085.4360554462, 216085.4360554462, 77872.62827615521]
[2019-03-23 11:48:14,392] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 11:48:14,395] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [6.1360735e-32 1.0000000e+00 0.0000000e+00 6.2608089e-36 0.0000000e+00], sampled 0.5129615083373501
[2019-03-23 11:48:19,812] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 11:48:19,967] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 11:48:20,023] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 11:48:20,246] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 11:48:20,249] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 11:48:21,267] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 2100000, evaluation results [2100000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 11:48:25,519] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.2165831e-31 1.0000000e+00 0.0000000e+00 1.6281428e-34 0.0000000e+00], sum to 1.0000
[2019-03-23 11:48:25,530] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5719
[2019-03-23 11:48:25,534] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.88333333333334, 53.5, 1.0, 2.0, 0.3037000757149186, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 329774.7840462131, 329774.7840462134, 110816.393410165], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7239000.0000, 
sim time next is 7239600.0000, 
raw observation next is [21.6, 55.0, 1.0, 2.0, 0.3035034145056263, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 329561.1657807234, 329561.1657807237, 110362.9077355718], 
processed observation next is [1.0, 0.8260869565217391, 0.6181818181818183, 0.55, 1.0, 1.0, 0.12937926813203285, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12205969102989755, 0.12205969102989765, 0.2691778237452971], 
reward next is 0.7308, 
noisyNet noise sample is [array([1.3687083], dtype=float32), -0.6713596]. 
=============================================
[2019-03-23 11:48:29,277] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.2466179e-27 1.0000000e+00 0.0000000e+00 1.2149370e-27 1.4818337e-37], sum to 1.0000
[2019-03-23 11:48:29,284] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8075
[2019-03-23 11:48:29,292] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1095183.459592631 W.
[2019-03-23 11:48:29,297] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.7, 43.33333333333334, 1.0, 2.0, 0.3230118786727699, 1.0, 1.0, 0.3230118786727699, 1.0, 1.0, 0.636679126730241, 6.911199999999999, 6.9112, 77.3421103, 1095183.459592631, 1095183.459592631, 247699.954294884], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7312800.0000, 
sim time next is 7313400.0000, 
raw observation next is [25.8, 43.0, 1.0, 2.0, 0.3336254526004143, 1.0, 2.0, 0.3336254526004143, 1.0, 2.0, 0.6602804886013328, 6.911199999999999, 6.9112, 77.3421103, 1134008.720216992, 1134008.720216992, 253179.1493681567], 
processed observation next is [1.0, 0.6521739130434783, 0.8090909090909091, 0.43, 1.0, 1.0, 0.16703181575051787, 1.0, 1.0, 0.16703181575051787, 1.0, 1.0, 0.5146864122876184, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.42000322970999704, 0.42000322970999704, 0.6175101204101383], 
reward next is 0.3825, 
noisyNet noise sample is [array([0.032343], dtype=float32), -1.2376326]. 
=============================================
[2019-03-23 11:48:31,274] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.9487237e-28 1.0000000e+00 0.0000000e+00 1.4861163e-33 0.0000000e+00], sum to 1.0000
[2019-03-23 11:48:31,282] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6150
[2019-03-23 11:48:31,286] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 87.0, 1.0, 2.0, 0.3306280642990159, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 361180.0185435827, 361180.0185435827, 114036.1910799973], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7357800.0000, 
sim time next is 7358400.0000, 
raw observation next is [17.7, 87.0, 1.0, 2.0, 0.3260618253971222, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 356161.8016818317, 356161.8016818319, 113699.363154942], 
processed observation next is [1.0, 0.17391304347826086, 0.44090909090909086, 0.87, 1.0, 1.0, 0.15757728174640273, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13191177840067841, 0.13191177840067847, 0.27731551989010245], 
reward next is 0.7227, 
noisyNet noise sample is [array([-0.94268066], dtype=float32), 0.16475835]. 
=============================================
[2019-03-23 11:48:32,373] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.902742e-29 1.000000e+00 0.000000e+00 6.565319e-31 0.000000e+00], sum to 1.0000
[2019-03-23 11:48:32,380] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7100
[2019-03-23 11:48:32,386] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1081501.946549123 W.
[2019-03-23 11:48:32,391] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.73333333333333, 60.66666666666667, 1.0, 2.0, 0.4736369678883235, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9341053509383782, 6.947487546486309, 6.9112, 77.32837575069581, 1081501.946549123, 1069716.507024114, 247007.1448217493], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7382400.0000, 
sim time next is 7383000.0000, 
raw observation next is [25.91666666666667, 60.33333333333333, 1.0, 2.0, 0.4691828150906019, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9307653253519014, 6.937331148180027, 6.9112, 77.32837554087946, 1071313.473481875, 1062826.620674801, 245859.3411986729], 
processed observation next is [1.0, 0.43478260869565216, 0.8143939393939396, 0.6033333333333333, 1.0, 1.0, 0.3364785188632523, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9010933219312879, 0.002613114818002682, 0.0, 0.5084282349672863, 0.39678276795624995, 0.3936394891388152, 0.5996569297528607], 
reward next is 0.2697, 
noisyNet noise sample is [array([1.3380371], dtype=float32), -1.4285411]. 
=============================================
[2019-03-23 11:48:32,405] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[66.49865]
 [66.49865]
 [66.49865]
 [66.49865]
 [66.49865]], R is [[66.10334778]
 [65.65841675]
 [65.45026398]
 [64.79576111]
 [64.50801086]].
[2019-03-23 11:48:32,570] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.5665714e-25 1.0000000e+00 1.2069591e-35 5.9203815e-29 1.2884387e-34], sum to 1.0000
[2019-03-23 11:48:32,576] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4551
[2019-03-23 11:48:32,583] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1183514.535578934 W.
[2019-03-23 11:48:32,589] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.38333333333334, 52.66666666666667, 1.0, 2.0, 0.5201003494691664, 1.0, 1.0, 0.5201003494691664, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.328463443541, 1183514.535578934, 1183514.535578934, 235889.9653556717], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7391400.0000, 
sim time next is 7392000.0000, 
raw observation next is [28.46666666666667, 52.33333333333334, 1.0, 2.0, 0.6049938912039252, 1.0, 2.0, 0.6049938912039252, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1374617.479834315, 1374617.479834315, 259242.7625251381], 
processed observation next is [1.0, 0.5652173913043478, 0.9303030303030304, 0.5233333333333334, 1.0, 1.0, 0.5062423640049065, 1.0, 1.0, 0.5062423640049065, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.5091175851238203, 0.5091175851238203, 0.6322994207930197], 
reward next is 0.3677, 
noisyNet noise sample is [array([0.4484265], dtype=float32), 0.42949736]. 
=============================================
[2019-03-23 11:48:32,615] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[63.86201]
 [63.86201]
 [63.86201]
 [63.86201]
 [63.86201]], R is [[63.59108734]
 [63.37983704]
 [63.22241211]
 [63.10992813]
 [62.47882843]].
[2019-03-23 11:48:34,851] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.4367806e-28 1.0000000e+00 0.0000000e+00 7.8598844e-29 0.0000000e+00], sum to 1.0000
[2019-03-23 11:48:34,857] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4990
[2019-03-23 11:48:34,864] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.45, 96.5, 1.0, 2.0, 0.3541708469446268, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 392692.8397521357, 392692.8397521357, 117896.9893693396], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7435800.0000, 
sim time next is 7436400.0000, 
raw observation next is [17.36666666666667, 96.33333333333334, 1.0, 2.0, 0.351137881306613, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 388697.2965606204, 388697.2965606204, 117407.6802401292], 
processed observation next is [0.0, 0.043478260869565216, 0.42575757575757595, 0.9633333333333334, 1.0, 1.0, 0.18892235163326623, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14396196168911868, 0.14396196168911868, 0.28636019570763216], 
reward next is 0.7136, 
noisyNet noise sample is [array([-0.5215678], dtype=float32), -0.4367206]. 
=============================================
[2019-03-23 11:48:42,930] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.0151097e-27 1.0000000e+00 1.3838202e-38 1.2526743e-30 1.0005846e-36], sum to 1.0000
[2019-03-23 11:48:42,941] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2794
[2019-03-23 11:48:42,945] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.4, 76.0, 1.0, 2.0, 0.4876012719858445, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 556189.370958909, 556189.3709589088, 140430.1382982024], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7552800.0000, 
sim time next is 7553400.0000, 
raw observation next is [24.56666666666666, 75.0, 1.0, 2.0, 0.4909018683057132, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 559904.7248373723, 559904.7248373723, 140910.5050935908], 
processed observation next is [0.0, 0.43478260869565216, 0.7530303030303027, 0.75, 1.0, 1.0, 0.3636273353821415, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20737212031013788, 0.20737212031013788, 0.3436841587648556], 
reward next is 0.6563, 
noisyNet noise sample is [array([1.199051], dtype=float32), 0.3940387]. 
=============================================
[2019-03-23 11:48:44,996] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:48:44,997] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:48:45,059] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run11
[2019-03-23 11:48:45,500] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.2967419e-27 1.0000000e+00 0.0000000e+00 8.4950435e-33 1.1541237e-37], sum to 1.0000
[2019-03-23 11:48:45,507] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8805
[2019-03-23 11:48:45,511] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 96.0, 1.0, 2.0, 0.4341111433436372, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 493813.4979632529, 493813.4979632532, 131041.515874987], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7621800.0000, 
sim time next is 7622400.0000, 
raw observation next is [20.0, 96.0, 1.0, 2.0, 0.4240610457940981, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 482368.5813880055, 482368.5813880055, 130032.7063656572], 
processed observation next is [1.0, 0.21739130434782608, 0.5454545454545454, 0.96, 1.0, 1.0, 0.28007630724262256, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17865503014370576, 0.17865503014370576, 0.3171529423552615], 
reward next is 0.6828, 
noisyNet noise sample is [array([-0.00021503], dtype=float32), -0.27855617]. 
=============================================
[2019-03-23 11:48:46,749] A3C_AGENT_WORKER-Thread-9 INFO:Local step 132500, global step 2112926: loss 0.3963
[2019-03-23 11:48:46,752] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 132500, global step 2112926: learning rate 0.0005
[2019-03-23 11:48:47,458] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.6944159e-26 1.0000000e+00 2.8491609e-36 2.1783950e-28 9.2860744e-37], sum to 1.0000
[2019-03-23 11:48:47,467] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6978
[2019-03-23 11:48:47,471] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.35, 92.0, 1.0, 2.0, 0.4733233603294595, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 539971.8632725861, 539971.8632725865, 137171.4383427846], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7684200.0000, 
sim time next is 7684800.0000, 
raw observation next is [21.26666666666667, 92.33333333333334, 1.0, 2.0, 0.4694875148423834, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 535559.9652041629, 535559.9652041629, 136657.9127043033], 
processed observation next is [1.0, 0.9565217391304348, 0.6030303030303031, 0.9233333333333335, 1.0, 1.0, 0.33685939355297917, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19835554266820848, 0.19835554266820848, 0.3333119822056178], 
reward next is 0.6667, 
noisyNet noise sample is [array([0.19604659], dtype=float32), -0.7089106]. 
=============================================
[2019-03-23 11:48:47,843] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.7075858e-27 1.0000000e+00 2.4261614e-38 1.3308644e-28 2.1237647e-35], sum to 1.0000
[2019-03-23 11:48:47,849] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7283
[2019-03-23 11:48:47,853] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.2, 100.0, 1.0, 2.0, 0.3602538660322353, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 400376.7053243449, 400376.7053243449, 118757.0409159642], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7707600.0000, 
sim time next is 7708200.0000, 
raw observation next is [17.28333333333333, 99.5, 1.0, 2.0, 0.3639285996086403, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 404297.6888965535, 404297.6888965532, 118985.4447281998], 
processed observation next is [1.0, 0.21739130434782608, 0.4219696969696969, 0.995, 1.0, 1.0, 0.20491074951080038, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1497398847765013, 0.1497398847765012, 0.2902084017760971], 
reward next is 0.7098, 
noisyNet noise sample is [array([0.47940326], dtype=float32), 1.3059626]. 
=============================================
[2019-03-23 11:48:49,905] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.0528247e-30 1.0000000e+00 0.0000000e+00 3.5905451e-32 0.0000000e+00], sum to 1.0000
[2019-03-23 11:48:49,914] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2076
[2019-03-23 11:48:49,919] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.35, 57.0, 1.0, 2.0, 0.6170866881585764, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 670601.268183653, 670601.268183653, 138265.6083048681], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7731000.0000, 
sim time next is 7731600.0000, 
raw observation next is [21.26666666666667, 57.0, 1.0, 2.0, 0.5771885391951107, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 626935.5696254858, 626935.5696254858, 134145.8263412662], 
processed observation next is [1.0, 0.4782608695652174, 0.6030303030303031, 0.57, 1.0, 1.0, 0.47148567399388835, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23219835912055029, 0.23219835912055029, 0.3271849422957712], 
reward next is 0.6728, 
noisyNet noise sample is [array([1.0521989], dtype=float32), -0.4311789]. 
=============================================
[2019-03-23 11:48:50,161] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:48:50,162] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:48:50,212] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run11
[2019-03-23 11:48:51,982] A3C_AGENT_WORKER-Thread-13 INFO:Local step 132500, global step 2115621: loss 0.0314
[2019-03-23 11:48:51,985] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 132500, global step 2115622: learning rate 0.0005
[2019-03-23 11:48:53,651] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.9733428e-31 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 11:48:53,658] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2703
[2019-03-23 11:48:53,664] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 57.0, 1.0, 2.0, 0.2628704329385009, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 285426.6295037621, 285426.6295037624, 82837.57136831422], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7763400.0000, 
sim time next is 7764000.0000, 
raw observation next is [18.8, 57.0, 1.0, 2.0, 0.26138938533939, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 283818.0280059872, 283818.0280059872, 82680.44965620131], 
processed observation next is [1.0, 0.8695652173913043, 0.49090909090909096, 0.57, 1.0, 1.0, 0.07673673167423747, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10511778815036563, 0.10511778815036563, 0.20165963330780806], 
reward next is 0.7983, 
noisyNet noise sample is [array([-1.2251749], dtype=float32), 0.32010826]. 
=============================================
[2019-03-23 11:48:53,689] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[80.05873]
 [80.05873]
 [80.05873]
 [80.05873]
 [80.05873]], R is [[80.05649567]
 [80.05388641]
 [80.05110168]
 [80.04841614]
 [80.04574585]].
[2019-03-23 11:49:01,342] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:49:01,343] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:49:01,387] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run11
[2019-03-23 11:49:01,715] A3C_AGENT_WORKER-Thread-9 INFO:Local step 133000, global step 2120491: loss 0.1385
[2019-03-23 11:49:01,720] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 133000, global step 2120491: learning rate 0.0005
[2019-03-23 11:49:02,044] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:49:02,044] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:49:02,053] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run11
[2019-03-23 11:49:02,110] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:49:02,111] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:49:02,118] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run11
[2019-03-23 11:49:02,142] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:49:02,143] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:49:02,151] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run11
[2019-03-23 11:49:02,175] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:49:02,176] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:49:02,182] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:49:02,183] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:49:02,193] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run11
[2019-03-23 11:49:02,220] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run11
[2019-03-23 11:49:02,275] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:49:02,276] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:49:02,280] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run11
[2019-03-23 11:49:02,349] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:49:02,349] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:49:02,352] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run11
[2019-03-23 11:49:02,650] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:49:02,650] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:49:02,653] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run11
[2019-03-23 11:49:02,685] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:49:02,686] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:49:02,692] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run11
[2019-03-23 11:49:02,745] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:49:02,748] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:49:02,755] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run11
[2019-03-23 11:49:02,793] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:49:02,793] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:49:02,797] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run11
[2019-03-23 11:49:02,849] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:49:02,849] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:49:02,864] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run11
[2019-03-23 11:49:03,045] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:49:03,046] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:49:03,074] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run11
[2019-03-23 11:49:03,361] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.119758e-30 1.000000e+00 0.000000e+00 9.197314e-35 0.000000e+00], sum to 1.0000
[2019-03-23 11:49:03,362] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8656
[2019-03-23 11:49:03,364] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.33333333333333, 75.33333333333334, 1.0, 2.0, 0.3926940140904613, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 426451.8302029423, 426451.8302029423, 88041.52885974981], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 372000.0000, 
sim time next is 372600.0000, 
raw observation next is [13.5, 74.5, 1.0, 2.0, 0.2983832254993516, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 323999.5229753169, 323999.5229753171, 79552.29336159624], 
processed observation next is [1.0, 0.30434782608695654, 0.25, 0.745, 1.0, 1.0, 0.12297903187418947, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11999982332419144, 0.11999982332419151, 0.19402998380877132], 
reward next is 0.8060, 
noisyNet noise sample is [array([1.2673477], dtype=float32), -0.46559286]. 
=============================================
[2019-03-23 11:49:03,746] A3C_AGENT_WORKER-Thread-22 INFO:Local step 132500, global step 2120799: loss 0.0014
[2019-03-23 11:49:03,747] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 132500, global step 2120799: learning rate 0.0005
[2019-03-23 11:49:04,133] A3C_AGENT_WORKER-Thread-20 INFO:Local step 132500, global step 2120924: loss 0.0005
[2019-03-23 11:49:04,134] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 132500, global step 2120924: learning rate 0.0005
[2019-03-23 11:49:04,197] A3C_AGENT_WORKER-Thread-3 INFO:Local step 132500, global step 2120956: loss 0.0004
[2019-03-23 11:49:04,198] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 132500, global step 2120956: learning rate 0.0005
[2019-03-23 11:49:04,278] A3C_AGENT_WORKER-Thread-2 INFO:Local step 132500, global step 2120996: loss 0.0005
[2019-03-23 11:49:04,282] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 132500, global step 2120997: learning rate 0.0005
[2019-03-23 11:49:04,291] A3C_AGENT_WORKER-Thread-21 INFO:Local step 132500, global step 2121003: loss 0.0001
[2019-03-23 11:49:04,293] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 132500, global step 2121004: learning rate 0.0005
[2019-03-23 11:49:04,354] A3C_AGENT_WORKER-Thread-11 INFO:Local step 132500, global step 2121039: loss 0.0000
[2019-03-23 11:49:04,355] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 132500, global step 2121039: learning rate 0.0005
[2019-03-23 11:49:04,391] A3C_AGENT_WORKER-Thread-10 INFO:Local step 132500, global step 2121062: loss 0.0012
[2019-03-23 11:49:04,394] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 132500, global step 2121062: learning rate 0.0005
[2019-03-23 11:49:04,429] A3C_AGENT_WORKER-Thread-12 INFO:Local step 132500, global step 2121083: loss 0.0031
[2019-03-23 11:49:04,435] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 132500, global step 2121084: learning rate 0.0005
[2019-03-23 11:49:04,600] A3C_AGENT_WORKER-Thread-19 INFO:Local step 132500, global step 2121185: loss 0.0007
[2019-03-23 11:49:04,602] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 132500, global step 2121185: learning rate 0.0005
[2019-03-23 11:49:04,686] A3C_AGENT_WORKER-Thread-17 INFO:Local step 132500, global step 2121239: loss 0.0022
[2019-03-23 11:49:04,687] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 132500, global step 2121239: learning rate 0.0005
[2019-03-23 11:49:04,745] A3C_AGENT_WORKER-Thread-15 INFO:Local step 132500, global step 2121270: loss 0.0003
[2019-03-23 11:49:04,746] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 132500, global step 2121270: learning rate 0.0005
[2019-03-23 11:49:04,785] A3C_AGENT_WORKER-Thread-14 INFO:Local step 132500, global step 2121299: loss 0.0007
[2019-03-23 11:49:04,790] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 132500, global step 2121300: learning rate 0.0005
[2019-03-23 11:49:05,064] A3C_AGENT_WORKER-Thread-16 INFO:Local step 132500, global step 2121460: loss 0.0000
[2019-03-23 11:49:05,066] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 132500, global step 2121461: learning rate 0.0005
[2019-03-23 11:49:05,144] A3C_AGENT_WORKER-Thread-13 INFO:Local step 133000, global step 2121507: loss 0.0906
[2019-03-23 11:49:05,146] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 133000, global step 2121507: learning rate 0.0005
[2019-03-23 11:49:05,262] A3C_AGENT_WORKER-Thread-18 INFO:Local step 132500, global step 2121572: loss 0.0108
[2019-03-23 11:49:05,264] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 132500, global step 2121575: learning rate 0.0005
[2019-03-23 11:49:11,694] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-23 11:49:11,696] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 11:49:11,696] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 11:49:11,698] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:49:11,699] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 11:49:11,699] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 11:49:11,698] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 11:49:11,700] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:49:11,702] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:49:11,703] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:49:11,706] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:49:11,727] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run86
[2019-03-23 11:49:11,754] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run86
[2019-03-23 11:49:11,780] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run86
[2019-03-23 11:49:11,808] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run86
[2019-03-23 11:49:11,810] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run86
[2019-03-23 11:49:23,761] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.0137826]
[2019-03-23 11:49:23,763] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [29.58333333333334, 42.83333333333334, 1.0, 2.0, 0.9692878971655328, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 1106062.351376026, 1106062.351376026, 213360.5560994482]
[2019-03-23 11:49:23,764] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 11:49:23,767] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.8149208e-31 1.0000000e+00 0.0000000e+00 6.2369503e-35 0.0000000e+00], sampled 0.9049973751177308
[2019-03-23 11:49:23,767] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1106062.351376026 W.
[2019-03-23 11:49:48,867] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.0137826]
[2019-03-23 11:49:48,868] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [14.78542665333333, 69.89887000166667, 1.0, 2.0, 0.2103097902222965, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 228332.2822800761, 228332.2822800758, 76014.07985989387]
[2019-03-23 11:49:48,869] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 11:49:48,872] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.8149208e-31 1.0000000e+00 0.0000000e+00 6.2369503e-35 0.0000000e+00], sampled 0.2717486133392706
[2019-03-23 11:50:02,814] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.0137826]
[2019-03-23 11:50:02,815] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.3, 87.0, 1.0, 2.0, 0.5262892935189839, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 599406.1887519942, 599406.1887519942, 150366.3343982595]
[2019-03-23 11:50:02,816] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 11:50:02,821] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.8149208e-31 1.0000000e+00 0.0000000e+00 6.2369503e-35 0.0000000e+00], sampled 0.47061513314339143
[2019-03-23 11:50:08,225] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.0137826]
[2019-03-23 11:50:08,227] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [25.1144578, 100.0, 1.0, 2.0, 0.6983308750989712, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 784702.7869340413, 784702.7869340413, 177677.7961970045]
[2019-03-23 11:50:08,228] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 11:50:08,234] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.8149208e-31 1.0000000e+00 0.0000000e+00 6.2369503e-35 0.0000000e+00], sampled 0.24735259436525991
[2019-03-23 11:50:13,393] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.0137826]
[2019-03-23 11:50:13,394] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.01532972, 67.34306637666666, 1.0, 2.0, 0.3987714447194911, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 453216.0183272266, 453216.0183272266, 131581.7445372725]
[2019-03-23 11:50:13,396] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 11:50:13,401] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.8149208e-31 1.0000000e+00 0.0000000e+00 6.2369503e-35 0.0000000e+00], sampled 0.5716751867798608
[2019-03-23 11:50:13,556] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.0137826]
[2019-03-23 11:50:13,558] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.405047555, 95.46972671, 1.0, 2.0, 0.494732762001351, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 564481.7700076514, 564481.7700076514, 144653.6182831253]
[2019-03-23 11:50:13,558] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 11:50:13,560] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.8149208e-31 1.0000000e+00 0.0000000e+00 6.2369503e-35 0.0000000e+00], sampled 0.01356165084661709
[2019-03-23 11:50:24,038] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.0137826]
[2019-03-23 11:50:24,039] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.49334617, 72.41461747, 1.0, 2.0, 0.3411083335236882, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 378634.7150851203, 378634.7150851203, 121373.917539684]
[2019-03-23 11:50:24,040] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 11:50:24,043] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.8149208e-31 1.0000000e+00 0.0000000e+00 6.2369503e-35 0.0000000e+00], sampled 0.7913571044683345
[2019-03-23 11:50:42,657] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.0137826]
[2019-03-23 11:50:42,658] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [15.65, 78.5, 1.0, 2.0, 0.4544695187851308, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 493524.119909129, 493524.119909129, 106555.4021887245]
[2019-03-23 11:50:42,658] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 11:50:42,661] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.8149208e-31 1.0000000e+00 0.0000000e+00 6.2369503e-35 0.0000000e+00], sampled 0.5614836180998332
[2019-03-23 11:50:48,372] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.0137826]
[2019-03-23 11:50:48,373] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.8, 57.0, 1.0, 2.0, 0.2634070737977168, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 286009.4893897714, 286009.4893897717, 82896.06742586986]
[2019-03-23 11:50:48,374] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 11:50:48,375] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.8149208e-31 1.0000000e+00 0.0000000e+00 6.2369503e-35 0.0000000e+00], sampled 0.8251532043645471
[2019-03-23 11:50:49,824] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 11:50:50,014] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 11:50:50,147] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 11:50:50,333] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 11:50:50,578] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 11:50:51,596] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 2125000, evaluation results [2125000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 11:50:55,352] A3C_AGENT_WORKER-Thread-9 INFO:Local step 133500, global step 2126922: loss 0.0012
[2019-03-23 11:50:55,359] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 133500, global step 2126924: learning rate 0.0005
[2019-03-23 11:50:58,515] A3C_AGENT_WORKER-Thread-22 INFO:Local step 133000, global step 2128506: loss 0.1114
[2019-03-23 11:50:58,517] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 133000, global step 2128507: learning rate 0.0005
[2019-03-23 11:50:59,304] A3C_AGENT_WORKER-Thread-20 INFO:Local step 133000, global step 2128907: loss 0.0013
[2019-03-23 11:50:59,307] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 133000, global step 2128907: learning rate 0.0005
[2019-03-23 11:50:59,320] A3C_AGENT_WORKER-Thread-21 INFO:Local step 133000, global step 2128912: loss 0.0020
[2019-03-23 11:50:59,321] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 133000, global step 2128912: learning rate 0.0005
[2019-03-23 11:50:59,390] A3C_AGENT_WORKER-Thread-3 INFO:Local step 133000, global step 2128949: loss 0.0001
[2019-03-23 11:50:59,393] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 133000, global step 2128950: learning rate 0.0005
[2019-03-23 11:50:59,410] A3C_AGENT_WORKER-Thread-12 INFO:Local step 133000, global step 2128962: loss 0.0016
[2019-03-23 11:50:59,411] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 133000, global step 2128962: learning rate 0.0005
[2019-03-23 11:50:59,422] A3C_AGENT_WORKER-Thread-2 INFO:Local step 133000, global step 2128967: loss 0.0004
[2019-03-23 11:50:59,426] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 133000, global step 2128968: learning rate 0.0005
[2019-03-23 11:50:59,451] A3C_AGENT_WORKER-Thread-10 INFO:Local step 133000, global step 2128979: loss 0.0074
[2019-03-23 11:50:59,453] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 133000, global step 2128979: learning rate 0.0005
[2019-03-23 11:50:59,661] A3C_AGENT_WORKER-Thread-11 INFO:Local step 133000, global step 2129086: loss 0.0005
[2019-03-23 11:50:59,663] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 133000, global step 2129088: learning rate 0.0005
[2019-03-23 11:50:59,752] A3C_AGENT_WORKER-Thread-19 INFO:Local step 133000, global step 2129131: loss 0.0003
[2019-03-23 11:50:59,754] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 133000, global step 2129133: learning rate 0.0005
[2019-03-23 11:50:59,969] A3C_AGENT_WORKER-Thread-17 INFO:Local step 133000, global step 2129243: loss 0.0025
[2019-03-23 11:50:59,975] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 133000, global step 2129244: learning rate 0.0005
[2019-03-23 11:51:00,096] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.6461736e-30 1.0000000e+00 0.0000000e+00 2.5040897e-33 0.0000000e+00], sum to 1.0000
[2019-03-23 11:51:00,102] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6012
[2019-03-23 11:51:00,106] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 43.0, 1.0, 2.0, 0.2587090971613467, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 280906.9159348426, 280906.9159348423, 81664.34429595717], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 309600.0000, 
sim time next is 310200.0000, 
raw observation next is [21.16666666666667, 43.0, 1.0, 2.0, 0.259506715520476, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 281773.2226145497, 281773.2226145494, 82357.9965395855], 
processed observation next is [0.0, 0.6086956521739131, 0.5984848484848487, 0.43, 1.0, 1.0, 0.07438339440059498, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10436045282020359, 0.10436045282020348, 0.20087316229167193], 
reward next is 0.7991, 
noisyNet noise sample is [array([-1.0693623], dtype=float32), -0.6048211]. 
=============================================
[2019-03-23 11:51:00,122] A3C_AGENT_WORKER-Thread-14 INFO:Local step 133000, global step 2129322: loss 0.0054
[2019-03-23 11:51:00,124] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 133000, global step 2129322: learning rate 0.0005
[2019-03-23 11:51:00,180] A3C_AGENT_WORKER-Thread-15 INFO:Local step 133000, global step 2129350: loss 0.0017
[2019-03-23 11:51:00,184] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 133000, global step 2129351: learning rate 0.0005
[2019-03-23 11:51:00,382] A3C_AGENT_WORKER-Thread-16 INFO:Local step 133000, global step 2129455: loss 0.0049
[2019-03-23 11:51:00,389] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 133000, global step 2129456: learning rate 0.0005
[2019-03-23 11:51:00,510] A3C_AGENT_WORKER-Thread-13 INFO:Local step 133500, global step 2129521: loss 0.0150
[2019-03-23 11:51:00,512] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 133500, global step 2129521: learning rate 0.0005
[2019-03-23 11:51:00,642] A3C_AGENT_WORKER-Thread-18 INFO:Local step 133000, global step 2129587: loss 0.0004
[2019-03-23 11:51:00,648] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 133000, global step 2129588: learning rate 0.0005
[2019-03-23 11:51:04,855] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.1280103e-33 1.0000000e+00 0.0000000e+00 1.2865484e-33 0.0000000e+00], sum to 1.0000
[2019-03-23 11:51:04,865] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4993
[2019-03-23 11:51:04,871] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 99.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 210779.9438469571, 210779.9438469574, 72335.62410646304], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 434400.0000, 
sim time next is 435000.0000, 
raw observation next is [13.0, 99.16666666666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 209156.2872562572, 209156.2872562575, 72014.19564137195], 
processed observation next is [1.0, 0.0, 0.22727272727272727, 0.9916666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07746529157639155, 0.07746529157639166, 0.1756443796131023], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.3322651], dtype=float32), -0.22765681]. 
=============================================
[2019-03-23 11:51:04,890] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[78.5665]
 [78.5665]
 [78.5665]
 [78.5665]
 [78.5665]], R is [[77.78082275]
 [77.00301361]
 [76.23298645]
 [75.47065735]
 [74.71595001]].
[2019-03-23 11:51:05,587] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.9996923e-32 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 11:51:05,594] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8554
[2019-03-23 11:51:05,598] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 210508.3995519143, 210508.3995519143, 72474.9815706925], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 430800.0000, 
sim time next is 431400.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 210483.8625780522, 210483.8625780524, 72466.72237976131], 
processed observation next is [1.0, 1.0, 0.22727272727272727, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07795698614001934, 0.0779569861400194, 0.1767481033652715], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.05341801], dtype=float32), -0.23203102]. 
=============================================
[2019-03-23 11:51:05,803] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.8526068e-31 1.0000000e+00 0.0000000e+00 4.5199821e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 11:51:05,810] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7486
[2019-03-23 11:51:05,817] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 99.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 207130.9254912133, 207130.925491213, 71616.61434200588], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 435600.0000, 
sim time next is 436200.0000, 
raw observation next is [13.0, 99.16666666666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 206171.7125320782, 206171.7125320779, 71483.53521518092], 
processed observation next is [1.0, 0.043478260869565216, 0.22727272727272727, 0.9916666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07635989353039933, 0.07635989353039922, 0.17435008589068518], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.01544373], dtype=float32), 0.2732003]. 
=============================================
[2019-03-23 11:51:11,496] A3C_AGENT_WORKER-Thread-9 INFO:Local step 134000, global step 2135095: loss 0.1101
[2019-03-23 11:51:11,498] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 134000, global step 2135095: learning rate 0.0005
[2019-03-23 11:51:14,213] A3C_AGENT_WORKER-Thread-22 INFO:Local step 133500, global step 2136480: loss 0.0455
[2019-03-23 11:51:14,215] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 133500, global step 2136481: learning rate 0.0005
[2019-03-23 11:51:14,953] A3C_AGENT_WORKER-Thread-21 INFO:Local step 133500, global step 2136858: loss 0.0415
[2019-03-23 11:51:14,956] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 133500, global step 2136858: learning rate 0.0005
[2019-03-23 11:51:14,967] A3C_AGENT_WORKER-Thread-12 INFO:Local step 133500, global step 2136865: loss 0.0326
[2019-03-23 11:51:14,973] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 133500, global step 2136866: learning rate 0.0005
[2019-03-23 11:51:14,995] A3C_AGENT_WORKER-Thread-3 INFO:Local step 133500, global step 2136879: loss 0.0205
[2019-03-23 11:51:14,997] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 133500, global step 2136879: learning rate 0.0005
[2019-03-23 11:51:15,052] A3C_AGENT_WORKER-Thread-2 INFO:Local step 133500, global step 2136904: loss 0.0175
[2019-03-23 11:51:15,053] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 133500, global step 2136904: learning rate 0.0005
[2019-03-23 11:51:15,110] A3C_AGENT_WORKER-Thread-20 INFO:Local step 133500, global step 2136932: loss 0.0202
[2019-03-23 11:51:15,112] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 133500, global step 2136932: learning rate 0.0005
[2019-03-23 11:51:15,157] A3C_AGENT_WORKER-Thread-10 INFO:Local step 133500, global step 2136959: loss 0.0151
[2019-03-23 11:51:15,159] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 133500, global step 2136959: learning rate 0.0005
[2019-03-23 11:51:15,490] A3C_AGENT_WORKER-Thread-11 INFO:Local step 133500, global step 2137127: loss 0.0180
[2019-03-23 11:51:15,492] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 133500, global step 2137130: learning rate 0.0005
[2019-03-23 11:51:15,507] A3C_AGENT_WORKER-Thread-19 INFO:Local step 133500, global step 2137133: loss 0.0184
[2019-03-23 11:51:15,509] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 133500, global step 2137133: learning rate 0.0005
[2019-03-23 11:51:15,595] A3C_AGENT_WORKER-Thread-17 INFO:Local step 133500, global step 2137182: loss 0.0171
[2019-03-23 11:51:15,596] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 133500, global step 2137182: learning rate 0.0005
[2019-03-23 11:51:15,817] A3C_AGENT_WORKER-Thread-14 INFO:Local step 133500, global step 2137291: loss 0.0059
[2019-03-23 11:51:15,817] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 133500, global step 2137291: learning rate 0.0005
[2019-03-23 11:51:15,932] A3C_AGENT_WORKER-Thread-15 INFO:Local step 133500, global step 2137353: loss 0.0022
[2019-03-23 11:51:15,933] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 133500, global step 2137353: learning rate 0.0005
[2019-03-23 11:51:16,167] A3C_AGENT_WORKER-Thread-16 INFO:Local step 133500, global step 2137465: loss 0.0000
[2019-03-23 11:51:16,168] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 133500, global step 2137466: learning rate 0.0005
[2019-03-23 11:51:16,358] A3C_AGENT_WORKER-Thread-18 INFO:Local step 133500, global step 2137558: loss 0.0027
[2019-03-23 11:51:16,360] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 133500, global step 2137559: learning rate 0.0005
[2019-03-23 11:51:16,523] A3C_AGENT_WORKER-Thread-13 INFO:Local step 134000, global step 2137643: loss 0.0685
[2019-03-23 11:51:16,526] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 134000, global step 2137643: learning rate 0.0005
[2019-03-23 11:51:17,568] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.8148705e-26 1.0000000e+00 1.4643016e-37 1.8985872e-29 1.0885383e-36], sum to 1.0000
[2019-03-23 11:51:17,576] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4221
[2019-03-23 11:51:17,583] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.2183762793758613, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 237102.7776516576, 237102.7776516579, 75565.10749927536], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1026000.0000, 
sim time next is 1026600.0000, 
raw observation next is [13.0, 99.00000000000001, 1.0, 2.0, 0.2171047667991586, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 235721.8940763198, 235721.8940763195, 75130.6892695007], 
processed observation next is [1.0, 0.9130434782608695, 0.22727272727272727, 0.9900000000000001, 1.0, 1.0, 0.021380958498948242, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08730440521345177, 0.08730440521345166, 0.18324558358414805], 
reward next is 0.8168, 
noisyNet noise sample is [array([-1.5932778], dtype=float32), 0.51234215]. 
=============================================
[2019-03-23 11:51:24,946] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0891777e-29 1.0000000e+00 0.0000000e+00 3.4459667e-32 0.0000000e+00], sum to 1.0000
[2019-03-23 11:51:24,954] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3327
[2019-03-23 11:51:24,959] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 69.0, 1.0, 2.0, 0.4454684337838318, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 507457.4713057235, 507457.4713057235, 132944.0150970208], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 772200.0000, 
sim time next is 772800.0000, 
raw observation next is [24.0, 69.0, 1.0, 2.0, 0.4439931461398561, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 505774.9920237183, 505774.9920237183, 132790.3793027496], 
processed observation next is [1.0, 0.9565217391304348, 0.7272727272727273, 0.69, 1.0, 1.0, 0.30499143267482004, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18732407111989566, 0.18732407111989566, 0.3238789739091454], 
reward next is 0.6761, 
noisyNet noise sample is [array([0.4683139], dtype=float32), 1.9097307]. 
=============================================
[2019-03-23 11:51:27,361] A3C_AGENT_WORKER-Thread-9 INFO:Local step 134500, global step 2143119: loss 0.0039
[2019-03-23 11:51:27,363] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 134500, global step 2143119: learning rate 0.0005
[2019-03-23 11:51:27,598] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.6057851e-25 1.0000000e+00 1.9469229e-34 1.4091305e-28 1.3881796e-34], sum to 1.0000
[2019-03-23 11:51:27,607] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8634
[2019-03-23 11:51:27,612] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.5, 63.5, 1.0, 2.0, 0.5042916925298381, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 575113.3546649943, 575113.3546649943, 142594.156710867], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 847800.0000, 
sim time next is 848400.0000, 
raw observation next is [26.33333333333334, 64.0, 1.0, 2.0, 0.501230496356984, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 571701.5251187002, 571701.5251187006, 142092.8073124532], 
processed observation next is [0.0, 0.8260869565217391, 0.8333333333333336, 0.64, 1.0, 1.0, 0.37653812044623, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2117413055995186, 0.21174130559951873, 0.3465678227133005], 
reward next is 0.6534, 
noisyNet noise sample is [array([0.22626479], dtype=float32), -0.6029368]. 
=============================================
[2019-03-23 11:51:30,169] A3C_AGENT_WORKER-Thread-22 INFO:Local step 134000, global step 2144474: loss 0.0001
[2019-03-23 11:51:30,171] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 134000, global step 2144474: learning rate 0.0005
[2019-03-23 11:51:30,812] A3C_AGENT_WORKER-Thread-3 INFO:Local step 134000, global step 2144814: loss 0.0066
[2019-03-23 11:51:30,814] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 134000, global step 2144814: learning rate 0.0005
[2019-03-23 11:51:30,883] A3C_AGENT_WORKER-Thread-21 INFO:Local step 134000, global step 2144854: loss 0.0035
[2019-03-23 11:51:30,887] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 134000, global step 2144856: learning rate 0.0005
[2019-03-23 11:51:30,941] A3C_AGENT_WORKER-Thread-2 INFO:Local step 134000, global step 2144885: loss 0.0010
[2019-03-23 11:51:30,943] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 134000, global step 2144885: learning rate 0.0005
[2019-03-23 11:51:30,982] A3C_AGENT_WORKER-Thread-20 INFO:Local step 134000, global step 2144900: loss 0.0043
[2019-03-23 11:51:30,983] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 134000, global step 2144900: learning rate 0.0005
[2019-03-23 11:51:30,996] A3C_AGENT_WORKER-Thread-10 INFO:Local step 134000, global step 2144908: loss 0.0015
[2019-03-23 11:51:30,997] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 134000, global step 2144908: learning rate 0.0005
[2019-03-23 11:51:31,035] A3C_AGENT_WORKER-Thread-12 INFO:Local step 134000, global step 2144928: loss 0.0055
[2019-03-23 11:51:31,037] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 134000, global step 2144928: learning rate 0.0005
[2019-03-23 11:51:31,433] A3C_AGENT_WORKER-Thread-11 INFO:Local step 134000, global step 2145144: loss 0.0036
[2019-03-23 11:51:31,435] A3C_AGENT_WORKER-Thread-19 INFO:Local step 134000, global step 2145144: loss 0.0000
[2019-03-23 11:51:31,437] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 134000, global step 2145144: learning rate 0.0005
[2019-03-23 11:51:31,437] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 134000, global step 2145144: learning rate 0.0005
[2019-03-23 11:51:31,497] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.3893540e-29 1.0000000e+00 0.0000000e+00 5.5630729e-33 3.8974283e-38], sum to 1.0000
[2019-03-23 11:51:31,500] A3C_AGENT_WORKER-Thread-17 INFO:Local step 134000, global step 2145179: loss 0.0008
[2019-03-23 11:51:31,501] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 134000, global step 2145179: learning rate 0.0005
[2019-03-23 11:51:31,508] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9539
[2019-03-23 11:51:31,512] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333334, 86.33333333333334, 1.0, 2.0, 0.4336759029485815, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 493642.0973243135, 493642.0973243135, 131315.0426669879], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 894000.0000, 
sim time next is 894600.0000, 
raw observation next is [21.5, 85.5, 1.0, 2.0, 0.4363438095947318, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 496805.1317823063, 496805.1317823063, 131716.6158337921], 
processed observation next is [0.0, 0.34782608695652173, 0.6136363636363636, 0.855, 1.0, 1.0, 0.2954297619934147, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18400190066011343, 0.18400190066011343, 0.32126003861900515], 
reward next is 0.6787, 
noisyNet noise sample is [array([-0.5964555], dtype=float32), -0.032695584]. 
=============================================
[2019-03-23 11:51:31,716] A3C_AGENT_WORKER-Thread-14 INFO:Local step 134000, global step 2145290: loss 0.0154
[2019-03-23 11:51:31,720] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 134000, global step 2145293: learning rate 0.0005
[2019-03-23 11:51:31,840] A3C_AGENT_WORKER-Thread-15 INFO:Local step 134000, global step 2145359: loss 0.0002
[2019-03-23 11:51:31,841] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 134000, global step 2145359: learning rate 0.0005
[2019-03-23 11:51:32,058] A3C_AGENT_WORKER-Thread-16 INFO:Local step 134000, global step 2145474: loss 0.0000
[2019-03-23 11:51:32,061] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 134000, global step 2145474: learning rate 0.0005
[2019-03-23 11:51:32,252] A3C_AGENT_WORKER-Thread-13 INFO:Local step 134500, global step 2145576: loss 0.0463
[2019-03-23 11:51:32,255] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 134500, global step 2145577: learning rate 0.0005
[2019-03-23 11:51:32,326] A3C_AGENT_WORKER-Thread-18 INFO:Local step 134000, global step 2145619: loss 0.0119
[2019-03-23 11:51:32,329] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 134000, global step 2145619: learning rate 0.0005
[2019-03-23 11:51:36,330] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.8463535e-30 1.0000000e+00 0.0000000e+00 1.8795856e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 11:51:36,337] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9718
[2019-03-23 11:51:36,345] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 94.0, 1.0, 2.0, 0.2352096884191431, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 255384.5063155297, 255384.50631553, 78909.43176149808], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1018800.0000, 
sim time next is 1019400.0000, 
raw observation next is [13.83333333333333, 95.0, 1.0, 2.0, 0.2321986358655192, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 252114.3371457989, 252114.3371457986, 78309.15633264196], 
processed observation next is [1.0, 0.8260869565217391, 0.265151515151515, 0.95, 1.0, 1.0, 0.040248294831898984, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09337568042436996, 0.09337568042436986, 0.1909979422747365], 
reward next is 0.8090, 
noisyNet noise sample is [array([-2.0628605], dtype=float32), 0.66958123]. 
=============================================
[2019-03-23 11:51:40,586] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-23 11:51:40,590] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 11:51:40,593] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 11:51:40,595] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:51:40,597] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:51:40,598] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 11:51:40,598] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 11:51:40,599] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:51:40,595] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 11:51:40,599] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:51:40,601] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:51:40,619] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run87
[2019-03-23 11:51:40,645] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run87
[2019-03-23 11:51:40,669] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run87
[2019-03-23 11:51:40,669] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run87
[2019-03-23 11:51:40,720] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run87
[2019-03-23 11:51:42,529] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.0369471]
[2019-03-23 11:51:42,530] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [17.95, 47.5, 1.0, 2.0, 0.2587583282823257, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 280944.9096424872, 280944.9096424868, 80854.42494045291]
[2019-03-23 11:51:42,531] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 11:51:42,532] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [9.9468985e-29 1.0000000e+00 0.0000000e+00 2.5242025e-32 0.0000000e+00], sampled 0.3164659191407777
[2019-03-23 11:51:57,291] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.0369471]
[2019-03-23 11:51:57,292] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [25.3, 70.0, 1.0, 2.0, 0.4960905988516002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 565846.8723092002, 565846.8723091999, 145648.4312600683]
[2019-03-23 11:51:57,293] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 11:51:57,296] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [9.9468985e-29 1.0000000e+00 0.0000000e+00 2.5242025e-32 0.0000000e+00], sampled 0.6153258627021694
[2019-03-23 11:52:36,360] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.0369471]
[2019-03-23 11:52:36,361] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.84284710666667, 62.489243555, 1.0, 2.0, 0.3838502417213174, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 429717.0998918024, 429717.0998918019, 126337.0117958718]
[2019-03-23 11:52:36,362] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 11:52:36,364] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [9.9468985e-29 1.0000000e+00 0.0000000e+00 2.5242025e-32 0.0000000e+00], sampled 0.33340465511190176
[2019-03-23 11:53:11,525] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.0369471]
[2019-03-23 11:53:11,525] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [26.03150456, 37.356378835, 1.0, 2.0, 0.4918438705328559, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 538862.9981980016, 538862.9981980013, 131939.6776844992]
[2019-03-23 11:53:11,526] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 11:53:11,528] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [9.9468985e-29 1.0000000e+00 0.0000000e+00 2.5242025e-32 0.0000000e+00], sampled 0.4341725040763611
[2019-03-23 11:53:14,480] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.0369471]
[2019-03-23 11:53:14,482] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.94296631166667, 100.0, 1.0, 2.0, 0.4343583063937161, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 494729.7689429778, 494729.7689429775, 136090.4820948377]
[2019-03-23 11:53:14,483] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 11:53:14,484] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [9.9468985e-29 1.0000000e+00 0.0000000e+00 2.5242025e-32 0.0000000e+00], sampled 0.6197996460673257
[2019-03-23 11:53:18,881] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 11:53:19,245] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 11:53:19,258] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 11:53:19,377] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 11:53:19,462] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 11:53:20,481] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 2150000, evaluation results [2150000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 11:53:21,542] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.0632212e-28 1.0000000e+00 0.0000000e+00 3.6456532e-33 0.0000000e+00], sum to 1.0000
[2019-03-23 11:53:21,555] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2313
[2019-03-23 11:53:21,561] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.5, 85.5, 1.0, 2.0, 0.3044180448231498, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 330554.6606308982, 330554.6606308979, 111489.2322066974], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1125000.0000, 
sim time next is 1125600.0000, 
raw observation next is [17.33333333333333, 86.33333333333334, 1.0, 2.0, 0.3024503827582006, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 328417.338270238, 328417.3382702377, 111356.0801224842], 
processed observation next is [1.0, 0.0, 0.42424242424242403, 0.8633333333333334, 1.0, 1.0, 0.1280629784477507, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12163605121119926, 0.12163605121119916, 0.2716001954206932], 
reward next is 0.7284, 
noisyNet noise sample is [array([-0.4520629], dtype=float32), -0.9294022]. 
=============================================
[2019-03-23 11:53:22,891] A3C_AGENT_WORKER-Thread-9 INFO:Local step 135000, global step 2151207: loss 0.0652
[2019-03-23 11:53:22,896] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 135000, global step 2151208: learning rate 0.0005
[2019-03-23 11:53:22,995] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.0110991e-29 1.0000000e+00 0.0000000e+00 7.6453711e-36 0.0000000e+00], sum to 1.0000
[2019-03-23 11:53:23,007] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4944
[2019-03-23 11:53:23,009] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.66666666666667, 90.33333333333334, 1.0, 2.0, 0.4876187984136287, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 550733.1127340088, 550733.1127340088, 133905.0140992742], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1153200.0000, 
sim time next is 1153800.0000, 
raw observation next is [20.0, 88.5, 1.0, 2.0, 0.5720119456089479, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 646977.0163746881, 646977.0163746881, 143562.589081862], 
processed observation next is [1.0, 0.34782608695652173, 0.5454545454545454, 0.885, 1.0, 1.0, 0.46501493201118477, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23962111717581042, 0.23962111717581042, 0.3501526562972244], 
reward next is 0.6498, 
noisyNet noise sample is [array([0.76493555], dtype=float32), 1.2237942]. 
=============================================
[2019-03-23 11:53:25,590] A3C_AGENT_WORKER-Thread-22 INFO:Local step 134500, global step 2152582: loss 0.0206
[2019-03-23 11:53:25,592] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 134500, global step 2152583: learning rate 0.0005
[2019-03-23 11:53:26,017] A3C_AGENT_WORKER-Thread-21 INFO:Local step 134500, global step 2152797: loss 0.0021
[2019-03-23 11:53:26,019] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 134500, global step 2152798: learning rate 0.0005
[2019-03-23 11:53:26,083] A3C_AGENT_WORKER-Thread-2 INFO:Local step 134500, global step 2152833: loss 0.0029
[2019-03-23 11:53:26,087] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 134500, global step 2152833: learning rate 0.0005
[2019-03-23 11:53:26,111] A3C_AGENT_WORKER-Thread-10 INFO:Local step 134500, global step 2152846: loss 0.0068
[2019-03-23 11:53:26,115] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 134500, global step 2152846: learning rate 0.0005
[2019-03-23 11:53:26,137] A3C_AGENT_WORKER-Thread-20 INFO:Local step 134500, global step 2152859: loss 0.0047
[2019-03-23 11:53:26,139] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 134500, global step 2152859: learning rate 0.0005
[2019-03-23 11:53:26,169] A3C_AGENT_WORKER-Thread-3 INFO:Local step 134500, global step 2152872: loss 0.0007
[2019-03-23 11:53:26,170] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 134500, global step 2152872: learning rate 0.0005
[2019-03-23 11:53:26,328] A3C_AGENT_WORKER-Thread-12 INFO:Local step 134500, global step 2152955: loss 0.0015
[2019-03-23 11:53:26,334] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 134500, global step 2152956: learning rate 0.0005
[2019-03-23 11:53:26,537] A3C_AGENT_WORKER-Thread-19 INFO:Local step 134500, global step 2153058: loss 0.0032
[2019-03-23 11:53:26,542] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 134500, global step 2153060: learning rate 0.0005
[2019-03-23 11:53:26,625] A3C_AGENT_WORKER-Thread-17 INFO:Local step 134500, global step 2153105: loss 0.0079
[2019-03-23 11:53:26,629] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 134500, global step 2153106: learning rate 0.0005
[2019-03-23 11:53:26,761] A3C_AGENT_WORKER-Thread-11 INFO:Local step 134500, global step 2153174: loss 0.0071
[2019-03-23 11:53:26,768] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 134500, global step 2153177: learning rate 0.0005
[2019-03-23 11:53:27,040] A3C_AGENT_WORKER-Thread-15 INFO:Local step 134500, global step 2153295: loss 0.0071
[2019-03-23 11:53:27,044] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 134500, global step 2153297: learning rate 0.0005
[2019-03-23 11:53:27,148] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.3432082e-29 1.0000000e+00 0.0000000e+00 1.2797821e-28 2.1151994e-38], sum to 1.0000
[2019-03-23 11:53:27,151] A3C_AGENT_WORKER-Thread-14 INFO:Local step 134500, global step 2153354: loss 0.0112
[2019-03-23 11:53:27,155] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 134500, global step 2153355: learning rate 0.0005
[2019-03-23 11:53:27,161] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9420
[2019-03-23 11:53:27,164] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 94.0, 1.0, 2.0, 0.4199173989310857, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 476997.5498079646, 476997.5498079646, 129059.560672481], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1231200.0000, 
sim time next is 1231800.0000, 
raw observation next is [20.16666666666667, 94.00000000000001, 1.0, 2.0, 0.4421318102110763, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 502655.7091112635, 502655.7091112635, 131596.3146429537], 
processed observation next is [1.0, 0.2608695652173913, 0.5530303030303032, 0.9400000000000002, 1.0, 1.0, 0.3026647627638453, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18616878115231983, 0.18616878115231983, 0.3209666210803748], 
reward next is 0.6790, 
noisyNet noise sample is [array([0.47350416], dtype=float32), 0.377816]. 
=============================================
[2019-03-23 11:53:27,497] A3C_AGENT_WORKER-Thread-16 INFO:Local step 134500, global step 2153523: loss 0.0053
[2019-03-23 11:53:27,499] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 134500, global step 2153523: learning rate 0.0005
[2019-03-23 11:53:27,767] A3C_AGENT_WORKER-Thread-18 INFO:Local step 134500, global step 2153660: loss 0.0001
[2019-03-23 11:53:27,770] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 134500, global step 2153661: learning rate 0.0005
[2019-03-23 11:53:27,858] A3C_AGENT_WORKER-Thread-13 INFO:Local step 135000, global step 2153712: loss 0.0274
[2019-03-23 11:53:27,860] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 135000, global step 2153712: learning rate 0.0005
[2019-03-23 11:53:33,323] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.8951356e-25 1.0000000e+00 2.5379382e-35 1.1518061e-29 8.2567838e-36], sum to 1.0000
[2019-03-23 11:53:33,330] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0278
[2019-03-23 11:53:33,337] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333334, 94.0, 1.0, 2.0, 0.4680682329977731, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 534050.0855259651, 534050.0855259651, 136874.7935010906], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1323600.0000, 
sim time next is 1324200.0000, 
raw observation next is [21.66666666666667, 94.0, 1.0, 2.0, 0.4818867638886157, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 549861.515477282, 549861.515477282, 139127.0786484237], 
processed observation next is [1.0, 0.30434782608695654, 0.6212121212121214, 0.94, 1.0, 1.0, 0.35235845486076955, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20365241313973406, 0.20365241313973406, 0.3393343381668871], 
reward next is 0.6607, 
noisyNet noise sample is [array([0.33737886], dtype=float32), -0.78290015]. 
=============================================
[2019-03-23 11:53:36,406] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.7033158e-24 1.0000000e+00 4.4256114e-36 6.6782289e-31 4.9520489e-35], sum to 1.0000
[2019-03-23 11:53:36,411] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6671
[2019-03-23 11:53:36,415] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4868232496396678, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 555440.109321246, 555440.109321246, 139971.9174018308], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1403400.0000, 
sim time next is 1404000.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.488066759296128, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 556859.4975658968, 556859.4975658968, 140114.5075039051], 
processed observation next is [0.0, 0.2608695652173913, 0.5909090909090909, 1.0, 1.0, 1.0, 0.36008344912016, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20624425835773957, 0.20624425835773957, 0.3417427012290368], 
reward next is 0.6583, 
noisyNet noise sample is [array([-0.16968063], dtype=float32), 0.25472972]. 
=============================================
[2019-03-23 11:53:36,426] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[68.154945]
 [68.154945]
 [68.154945]
 [68.154945]
 [68.154945]], R is [[68.13165283]
 [68.10894775]
 [68.08661652]
 [68.06439209]
 [68.04225159]].
[2019-03-23 11:53:36,467] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.0389245e-28 1.0000000e+00 0.0000000e+00 1.5979694e-32 5.6499530e-38], sum to 1.0000
[2019-03-23 11:53:36,475] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0707
[2019-03-23 11:53:36,481] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4900237159042586, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 559093.2280906494, 559093.2280906494, 140339.440657704], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1387800.0000, 
sim time next is 1388400.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.4903943248721098, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 559516.2396494407, 559516.2396494405, 140382.1529747561], 
processed observation next is [0.0, 0.043478260869565216, 0.5909090909090909, 1.0, 1.0, 1.0, 0.36299290609013724, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20722823690720027, 0.2072282369072002, 0.34239549506038075], 
reward next is 0.6576, 
noisyNet noise sample is [array([0.3412233], dtype=float32), -0.5006961]. 
=============================================
[2019-03-23 11:53:36,861] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.5359504e-27 1.0000000e+00 5.6859311e-38 1.6168321e-30 2.9716783e-37], sum to 1.0000
[2019-03-23 11:53:36,870] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6788
[2019-03-23 11:53:36,874] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4896112216855499, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 558622.3928853853, 558622.3928853853, 140291.9840234807], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1387200.0000, 
sim time next is 1387800.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.4900237159042586, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 559093.2280906494, 559093.2280906494, 140339.440657704], 
processed observation next is [0.0, 0.043478260869565216, 0.5909090909090909, 1.0, 1.0, 1.0, 0.3625296448803232, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20707156595949977, 0.20707156595949977, 0.3422913186773268], 
reward next is 0.6577, 
noisyNet noise sample is [array([0.11253785], dtype=float32), -0.6096588]. 
=============================================
[2019-03-23 11:53:38,448] A3C_AGENT_WORKER-Thread-9 INFO:Local step 135500, global step 2159038: loss 0.3723
[2019-03-23 11:53:38,450] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 135500, global step 2159039: learning rate 0.0005
[2019-03-23 11:53:41,589] A3C_AGENT_WORKER-Thread-22 INFO:Local step 135000, global step 2160619: loss 0.0090
[2019-03-23 11:53:41,596] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 135000, global step 2160622: learning rate 0.0005
[2019-03-23 11:53:41,994] A3C_AGENT_WORKER-Thread-2 INFO:Local step 135000, global step 2160823: loss 0.0179
[2019-03-23 11:53:41,996] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 135000, global step 2160823: learning rate 0.0005
[2019-03-23 11:53:42,031] A3C_AGENT_WORKER-Thread-21 INFO:Local step 135000, global step 2160843: loss 0.0144
[2019-03-23 11:53:42,033] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 135000, global step 2160844: learning rate 0.0005
[2019-03-23 11:53:42,097] A3C_AGENT_WORKER-Thread-3 INFO:Local step 135000, global step 2160873: loss 0.0184
[2019-03-23 11:53:42,100] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 135000, global step 2160874: learning rate 0.0005
[2019-03-23 11:53:42,134] A3C_AGENT_WORKER-Thread-10 INFO:Local step 135000, global step 2160892: loss 0.0089
[2019-03-23 11:53:42,135] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 135000, global step 2160892: learning rate 0.0005
[2019-03-23 11:53:42,153] A3C_AGENT_WORKER-Thread-20 INFO:Local step 135000, global step 2160899: loss 0.0081
[2019-03-23 11:53:42,155] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 135000, global step 2160899: learning rate 0.0005
[2019-03-23 11:53:42,403] A3C_AGENT_WORKER-Thread-12 INFO:Local step 135000, global step 2161029: loss 0.0092
[2019-03-23 11:53:42,408] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 135000, global step 2161029: learning rate 0.0005
[2019-03-23 11:53:42,457] A3C_AGENT_WORKER-Thread-19 INFO:Local step 135000, global step 2161058: loss 0.0023
[2019-03-23 11:53:42,460] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 135000, global step 2161059: learning rate 0.0005
[2019-03-23 11:53:42,584] A3C_AGENT_WORKER-Thread-17 INFO:Local step 135000, global step 2161122: loss 0.0014
[2019-03-23 11:53:42,586] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 135000, global step 2161124: learning rate 0.0005
[2019-03-23 11:53:42,596] A3C_AGENT_WORKER-Thread-11 INFO:Local step 135000, global step 2161130: loss 0.0014
[2019-03-23 11:53:42,603] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 135000, global step 2161130: learning rate 0.0005
[2019-03-23 11:53:42,976] A3C_AGENT_WORKER-Thread-14 INFO:Local step 135000, global step 2161320: loss 0.0157
[2019-03-23 11:53:42,976] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 135000, global step 2161320: learning rate 0.0005
[2019-03-23 11:53:43,136] A3C_AGENT_WORKER-Thread-15 INFO:Local step 135000, global step 2161397: loss 0.0069
[2019-03-23 11:53:43,137] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 135000, global step 2161398: learning rate 0.0005
[2019-03-23 11:53:43,383] A3C_AGENT_WORKER-Thread-16 INFO:Local step 135000, global step 2161526: loss 0.0102
[2019-03-23 11:53:43,385] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 135000, global step 2161527: learning rate 0.0005
[2019-03-23 11:53:43,458] A3C_AGENT_WORKER-Thread-13 INFO:Local step 135500, global step 2161564: loss 0.5158
[2019-03-23 11:53:43,461] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 135500, global step 2161565: learning rate 0.0005
[2019-03-23 11:53:43,720] A3C_AGENT_WORKER-Thread-18 INFO:Local step 135000, global step 2161700: loss 0.0138
[2019-03-23 11:53:43,722] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 135000, global step 2161700: learning rate 0.0005
[2019-03-23 11:53:54,339] A3C_AGENT_WORKER-Thread-9 INFO:Local step 136000, global step 2167054: loss 0.0321
[2019-03-23 11:53:54,341] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 136000, global step 2167054: learning rate 0.0005
[2019-03-23 11:53:54,682] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.830714e-29 1.000000e+00 0.000000e+00 5.084401e-33 0.000000e+00], sum to 1.0000
[2019-03-23 11:53:54,687] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5881
[2019-03-23 11:53:54,691] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [8.833333333333332, 82.0, 1.0, 2.0, 0.3489662987799926, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 378946.5709675075, 378946.5709675072, 79574.25216722628], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1749000.0000, 
sim time next is 1749600.0000, 
raw observation next is [9.0, 81.0, 1.0, 2.0, 0.3408322114936645, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 370110.3092080964, 370110.3092080966, 78935.09306796425], 
processed observation next is [1.0, 0.2608695652173913, 0.045454545454545456, 0.81, 1.0, 1.0, 0.1760402643670806, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13707789229929496, 0.13707789229929504, 0.19252461723893718], 
reward next is 0.8075, 
noisyNet noise sample is [array([-1.5658171], dtype=float32), 0.43575227]. 
=============================================
[2019-03-23 11:53:55,699] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.0993426e-35 1.0000000e+00 0.0000000e+00 9.1790081e-37 0.0000000e+00], sum to 1.0000
[2019-03-23 11:53:55,708] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0622
[2019-03-23 11:53:55,712] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 47.00000000000001, 1.0, 2.0, 0.3233467762266972, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 354438.7178729446, 354438.7178729443, 113953.7686776238], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2045400.0000, 
sim time next is 2046000.0000, 
raw observation next is [24.0, 47.0, 1.0, 2.0, 0.3250133699460445, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 356271.0040993772, 356271.0040993772, 114075.4025684873], 
processed observation next is [0.0, 0.6956521739130435, 0.7272727272727273, 0.47, 1.0, 1.0, 0.15626671243255563, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13195222374051008, 0.13195222374051008, 0.27823268919143246], 
reward next is 0.7218, 
noisyNet noise sample is [array([1.0659405], dtype=float32), -1.3551772]. 
=============================================
[2019-03-23 11:53:55,728] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[81.26772]
 [81.26772]
 [81.26772]
 [81.26772]
 [81.26772]], R is [[81.17681122]
 [81.0871048 ]
 [80.99842072]
 [80.91048431]
 [80.82331085]].
[2019-03-23 11:53:56,205] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.6254529e-30 1.0000000e+00 0.0000000e+00 3.7505594e-34 0.0000000e+00], sum to 1.0000
[2019-03-23 11:53:56,213] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2357
[2019-03-23 11:53:56,222] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 63.0, 1.0, 2.0, 0.272803572384921, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 296215.3892012536, 296215.3892012536, 75390.42355554267], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1760400.0000, 
sim time next is 1761000.0000, 
raw observation next is [14.33333333333333, 61.0, 1.0, 2.0, 0.3215068812166905, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 349117.365155908, 349117.365155908, 79824.05419809087], 
processed observation next is [1.0, 0.391304347826087, 0.28787878787878773, 0.61, 1.0, 1.0, 0.15188360152086314, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12930272783552146, 0.12930272783552146, 0.1946928151172948], 
reward next is 0.8053, 
noisyNet noise sample is [array([0.44242936], dtype=float32), 0.46507165]. 
=============================================
[2019-03-23 11:53:56,250] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[79.82406]
 [79.82406]
 [79.82406]
 [79.82406]
 [79.82406]], R is [[79.83111572]
 [79.84893036]
 [79.86843872]
 [79.89009857]
 [79.91228485]].
[2019-03-23 11:53:57,310] A3C_AGENT_WORKER-Thread-22 INFO:Local step 135500, global step 2168564: loss 0.0183
[2019-03-23 11:53:57,313] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 135500, global step 2168566: learning rate 0.0005
[2019-03-23 11:53:57,859] A3C_AGENT_WORKER-Thread-2 INFO:Local step 135500, global step 2168818: loss 0.0069
[2019-03-23 11:53:57,863] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 135500, global step 2168819: learning rate 0.0005
[2019-03-23 11:53:57,878] A3C_AGENT_WORKER-Thread-20 INFO:Local step 135500, global step 2168824: loss 0.0034
[2019-03-23 11:53:57,881] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 135500, global step 2168824: learning rate 0.0005
[2019-03-23 11:53:57,940] A3C_AGENT_WORKER-Thread-21 INFO:Local step 135500, global step 2168856: loss 0.0086
[2019-03-23 11:53:57,943] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 135500, global step 2168857: learning rate 0.0005
[2019-03-23 11:53:58,011] A3C_AGENT_WORKER-Thread-3 INFO:Local step 135500, global step 2168883: loss 0.0135
[2019-03-23 11:53:58,017] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 135500, global step 2168884: learning rate 0.0005
[2019-03-23 11:53:58,142] A3C_AGENT_WORKER-Thread-12 INFO:Local step 135500, global step 2168944: loss 0.0013
[2019-03-23 11:53:58,145] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 135500, global step 2168944: learning rate 0.0005
[2019-03-23 11:53:58,161] A3C_AGENT_WORKER-Thread-10 INFO:Local step 135500, global step 2168949: loss 0.0030
[2019-03-23 11:53:58,163] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 135500, global step 2168950: learning rate 0.0005
[2019-03-23 11:53:58,519] A3C_AGENT_WORKER-Thread-11 INFO:Local step 135500, global step 2169109: loss 0.0141
[2019-03-23 11:53:58,525] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 135500, global step 2169110: learning rate 0.0005
[2019-03-23 11:53:58,618] A3C_AGENT_WORKER-Thread-19 INFO:Local step 135500, global step 2169152: loss 0.0308
[2019-03-23 11:53:58,620] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 135500, global step 2169153: learning rate 0.0005
[2019-03-23 11:53:58,625] A3C_AGENT_WORKER-Thread-17 INFO:Local step 135500, global step 2169157: loss 0.0235
[2019-03-23 11:53:58,628] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 135500, global step 2169158: learning rate 0.0005
[2019-03-23 11:53:58,787] A3C_AGENT_WORKER-Thread-14 INFO:Local step 135500, global step 2169245: loss 0.0254
[2019-03-23 11:53:58,791] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 135500, global step 2169246: learning rate 0.0005
[2019-03-23 11:53:59,074] A3C_AGENT_WORKER-Thread-15 INFO:Local step 135500, global step 2169396: loss 0.0261
[2019-03-23 11:53:59,078] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 135500, global step 2169397: learning rate 0.0005
[2019-03-23 11:53:59,324] A3C_AGENT_WORKER-Thread-13 INFO:Local step 136000, global step 2169532: loss 0.0909
[2019-03-23 11:53:59,330] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 136000, global step 2169535: learning rate 0.0005
[2019-03-23 11:53:59,428] A3C_AGENT_WORKER-Thread-16 INFO:Local step 135500, global step 2169588: loss 0.0227
[2019-03-23 11:53:59,430] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 135500, global step 2169588: learning rate 0.0005
[2019-03-23 11:53:59,711] A3C_AGENT_WORKER-Thread-18 INFO:Local step 135500, global step 2169738: loss 0.0349
[2019-03-23 11:53:59,713] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 135500, global step 2169738: learning rate 0.0005
[2019-03-23 11:54:02,985] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.6320387e-30 1.0000000e+00 0.0000000e+00 5.4988065e-33 0.0000000e+00], sum to 1.0000
[2019-03-23 11:54:02,991] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1393
[2019-03-23 11:54:02,997] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 46.33333333333333, 1.0, 2.0, 0.3033668350377132, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 329412.8098426936, 329412.8098426939, 98381.14676833307], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1881600.0000, 
sim time next is 1882200.0000, 
raw observation next is [22.16666666666667, 46.16666666666666, 1.0, 2.0, 0.2999299584803533, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 325679.6058812337, 325679.605881234, 96123.5775546394], 
processed observation next is [1.0, 0.782608695652174, 0.6439393939393941, 0.46166666666666656, 1.0, 1.0, 0.12491244810044162, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12062207625230878, 0.12062207625230889, 0.23444775013326682], 
reward next is 0.7656, 
noisyNet noise sample is [array([1.5834546], dtype=float32), 1.3348558]. 
=============================================
[2019-03-23 11:54:06,350] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.4767991e-24 1.0000000e+00 2.9404934e-33 4.7114858e-22 4.2921571e-33], sum to 1.0000
[2019-03-23 11:54:06,358] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2552
[2019-03-23 11:54:06,361] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 52.33333333333333, 1.0, 2.0, 0.376915632494908, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 424200.216904038, 424200.2169040377, 122519.2973745258], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1964400.0000, 
sim time next is 1965000.0000, 
raw observation next is [25.0, 51.16666666666667, 1.0, 2.0, 0.3736581815773233, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 419624.0062537461, 419624.0062537461, 121776.35488784], 
processed observation next is [1.0, 0.7391304347826086, 0.7727272727272727, 0.5116666666666667, 1.0, 1.0, 0.21707272697165408, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15541629861249856, 0.15541629861249856, 0.29701549972643904], 
reward next is 0.7030, 
noisyNet noise sample is [array([1.2601578], dtype=float32), -0.94286704]. 
=============================================
[2019-03-23 11:54:06,381] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[55.29525]
 [55.29525]
 [55.29525]
 [55.29525]
 [55.29525]], R is [[55.44527435]
 [55.59199524]
 [55.7357254 ]
 [55.17836761]
 [54.6265831 ]].
[2019-03-23 11:54:07,510] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.529151e-29 1.000000e+00 0.000000e+00 9.599418e-32 0.000000e+00], sum to 1.0000
[2019-03-23 11:54:07,517] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8837
[2019-03-23 11:54:07,522] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.33333333333333, 70.66666666666667, 1.0, 2.0, 0.243101222386625, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 263955.2518479449, 263955.2518479446, 82961.11540864102], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2000400.0000, 
sim time next is 2001000.0000, 
raw observation next is [17.16666666666667, 71.33333333333333, 1.0, 2.0, 0.2410366687771976, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 261712.9908606742, 261712.9908606739, 82299.51079417112], 
processed observation next is [0.0, 0.13043478260869565, 0.4166666666666669, 0.7133333333333333, 1.0, 1.0, 0.05129583597149698, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09693073735580526, 0.09693073735580514, 0.20073051413212467], 
reward next is 0.7993, 
noisyNet noise sample is [array([-1.4522567], dtype=float32), 0.8060676]. 
=============================================
[2019-03-23 11:54:07,538] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[72.74593]
 [72.74593]
 [72.74593]
 [72.74593]
 [72.74593]], R is [[72.81774902]
 [72.88722229]
 [72.95429993]
 [73.01889801]
 [73.08102417]].
[2019-03-23 11:54:07,605] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.0052064e-32 1.0000000e+00 0.0000000e+00 1.8949780e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 11:54:07,613] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4485
[2019-03-23 11:54:07,615] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.66666666666666, 59.0, 1.0, 2.0, 0.3409612171599158, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 370250.4500256453, 370250.4500256453, 85378.9733910583], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2277600.0000, 
sim time next is 2278200.0000, 
raw observation next is [16.83333333333334, 59.0, 1.0, 2.0, 0.3464108248327966, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 376170.4786248282, 376170.4786248282, 86303.48410092053], 
processed observation next is [1.0, 0.34782608695652173, 0.40151515151515177, 0.59, 1.0, 1.0, 0.18301353104099574, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13932239949067712, 0.13932239949067712, 0.21049630268517203], 
reward next is 0.7895, 
noisyNet noise sample is [array([0.33181998], dtype=float32), 0.4297364]. 
=============================================
[2019-03-23 11:54:09,379] A3C_AGENT_WORKER-Thread-9 INFO:Local step 136500, global step 2174877: loss 0.0215
[2019-03-23 11:54:09,381] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 136500, global step 2174877: learning rate 0.0005
[2019-03-23 11:54:09,607] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-23 11:54:09,608] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 11:54:09,609] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:54:09,610] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 11:54:09,610] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:54:09,611] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 11:54:09,612] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 11:54:09,612] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:54:09,613] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:54:09,614] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 11:54:09,615] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:54:09,634] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run88
[2019-03-23 11:54:09,659] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run88
[2019-03-23 11:54:09,660] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run88
[2019-03-23 11:54:09,685] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run88
[2019-03-23 11:54:09,737] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run88
[2019-03-23 11:54:42,543] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.0287715]
[2019-03-23 11:54:42,547] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [29.0, 66.0, 1.0, 2.0, 0.6705575641181399, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9865530188920543, 6.911199999999999, 6.9112, 77.32844046045325, 1302212.470153854, 1302212.470153854, 295259.8293422372]
[2019-03-23 11:54:42,547] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 11:54:42,552] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.6592714e-30 1.0000000e+00 0.0000000e+00 6.0954272e-34 0.0000000e+00], sampled 0.2377043486674124
[2019-03-23 11:54:42,552] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1302212.470153854 W.
[2019-03-23 11:55:01,261] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.0287715]
[2019-03-23 11:55:01,261] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [25.02138219666667, 70.02245577333333, 1.0, 2.0, 0.4811544874521511, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 548978.713537587, 548978.713537587, 143216.8412462811]
[2019-03-23 11:55:01,263] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 11:55:01,265] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.6592714e-30 1.0000000e+00 0.0000000e+00 6.0954272e-34 0.0000000e+00], sampled 0.2834173311843816
[2019-03-23 11:55:48,283] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 11:55:48,373] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 11:55:48,542] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 11:55:48,613] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 11:55:48,656] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 11:55:49,673] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 2175000, evaluation results [2175000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 11:55:51,099] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.0516939e-31 1.0000000e+00 0.0000000e+00 2.3904765e-33 0.0000000e+00], sum to 1.0000
[2019-03-23 11:55:51,108] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4043
[2019-03-23 11:55:51,115] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.83333333333334, 57.33333333333334, 1.0, 2.0, 0.2761282378883663, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 299826.4880298654, 299826.4880298651, 90360.40265287337], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2063400.0000, 
sim time next is 2064000.0000, 
raw observation next is [19.66666666666667, 58.66666666666667, 1.0, 2.0, 0.2743676264603362, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 297914.1894954786, 297914.1894954789, 90498.20899330558], 
processed observation next is [0.0, 0.9130434782608695, 0.5303030303030305, 0.5866666666666667, 1.0, 1.0, 0.09295953307542022, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1103385887020291, 0.11033858870202921, 0.2207273390080624], 
reward next is 0.7793, 
noisyNet noise sample is [array([0.47489062], dtype=float32), -0.31490076]. 
=============================================
[2019-03-23 11:55:51,130] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[76.23888]
 [76.23888]
 [76.23888]
 [76.23888]
 [76.23888]], R is [[76.25575256]
 [76.27280426]
 [76.2900238 ]
 [76.3049469 ]
 [76.31750488]].
[2019-03-23 11:55:52,737] A3C_AGENT_WORKER-Thread-22 INFO:Local step 136000, global step 2176538: loss 0.0210
[2019-03-23 11:55:52,739] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 136000, global step 2176539: learning rate 0.0005
[2019-03-23 11:55:53,299] A3C_AGENT_WORKER-Thread-2 INFO:Local step 136000, global step 2176833: loss 0.0209
[2019-03-23 11:55:53,302] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 136000, global step 2176833: learning rate 0.0005
[2019-03-23 11:55:53,409] A3C_AGENT_WORKER-Thread-21 INFO:Local step 136000, global step 2176881: loss 0.0227
[2019-03-23 11:55:53,412] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 136000, global step 2176883: learning rate 0.0005
[2019-03-23 11:55:53,468] A3C_AGENT_WORKER-Thread-3 INFO:Local step 136000, global step 2176912: loss 0.0160
[2019-03-23 11:55:53,474] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 136000, global step 2176913: learning rate 0.0005
[2019-03-23 11:55:53,478] A3C_AGENT_WORKER-Thread-10 INFO:Local step 136000, global step 2176915: loss 0.0145
[2019-03-23 11:55:53,481] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 136000, global step 2176917: learning rate 0.0005
[2019-03-23 11:55:53,548] A3C_AGENT_WORKER-Thread-20 INFO:Local step 136000, global step 2176949: loss 0.0162
[2019-03-23 11:55:53,550] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 136000, global step 2176949: learning rate 0.0005
[2019-03-23 11:55:53,700] A3C_AGENT_WORKER-Thread-12 INFO:Local step 136000, global step 2177025: loss 0.0117
[2019-03-23 11:55:53,704] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 136000, global step 2177025: learning rate 0.0005
[2019-03-23 11:55:53,802] A3C_AGENT_WORKER-Thread-19 INFO:Local step 136000, global step 2177075: loss 0.0099
[2019-03-23 11:55:53,803] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 136000, global step 2177075: learning rate 0.0005
[2019-03-23 11:55:53,926] A3C_AGENT_WORKER-Thread-11 INFO:Local step 136000, global step 2177140: loss 0.0031
[2019-03-23 11:55:53,928] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 136000, global step 2177140: learning rate 0.0005
[2019-03-23 11:55:53,973] A3C_AGENT_WORKER-Thread-14 INFO:Local step 136000, global step 2177161: loss 0.0017
[2019-03-23 11:55:53,977] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 136000, global step 2177163: learning rate 0.0005
[2019-03-23 11:55:53,997] A3C_AGENT_WORKER-Thread-17 INFO:Local step 136000, global step 2177174: loss 0.0001
[2019-03-23 11:55:53,999] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 136000, global step 2177176: learning rate 0.0005
[2019-03-23 11:55:54,414] A3C_AGENT_WORKER-Thread-15 INFO:Local step 136000, global step 2177384: loss 0.0016
[2019-03-23 11:55:54,417] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 136000, global step 2177385: learning rate 0.0005
[2019-03-23 11:55:54,539] A3C_AGENT_WORKER-Thread-13 INFO:Local step 136500, global step 2177445: loss 0.0476
[2019-03-23 11:55:54,543] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 136500, global step 2177445: learning rate 0.0005
[2019-03-23 11:55:55,085] A3C_AGENT_WORKER-Thread-16 INFO:Local step 136000, global step 2177723: loss 0.0005
[2019-03-23 11:55:55,086] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 136000, global step 2177723: learning rate 0.0005
[2019-03-23 11:55:55,266] A3C_AGENT_WORKER-Thread-18 INFO:Local step 136000, global step 2177814: loss 0.0024
[2019-03-23 11:55:55,268] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 136000, global step 2177815: learning rate 0.0005
[2019-03-23 11:55:57,056] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.4590675e-34 1.0000000e+00 0.0000000e+00 9.0242993e-37 0.0000000e+00], sum to 1.0000
[2019-03-23 11:55:57,063] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6810
[2019-03-23 11:55:57,068] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 56.66666666666667, 1.0, 2.0, 0.6272959525548732, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 681399.8235596066, 681399.8235596066, 138218.8031922757], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2555400.0000, 
sim time next is 2556000.0000, 
raw observation next is [21.0, 56.0, 1.0, 2.0, 0.6243328205890787, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 678178.8773952522, 678178.8773952526, 136759.653123027], 
processed observation next is [1.0, 0.6086956521739131, 0.5909090909090909, 0.56, 1.0, 1.0, 0.5304160257363483, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2511773619982416, 0.2511773619982417, 0.33356012956835857], 
reward next is 0.6664, 
noisyNet noise sample is [array([0.13549091], dtype=float32), -0.11937728]. 
=============================================
[2019-03-23 11:55:57,084] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[74.89032]
 [74.89032]
 [74.89032]
 [74.89032]
 [74.89032]], R is [[74.80786896]
 [74.72267151]
 [74.63834381]
 [74.56300354]
 [74.49848175]].
[2019-03-23 11:55:57,503] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.5796710e-33 1.0000000e+00 0.0000000e+00 4.2046552e-36 0.0000000e+00], sum to 1.0000
[2019-03-23 11:55:57,512] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3168
[2019-03-23 11:55:57,517] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 82.0, 1.0, 2.0, 0.248851462006533, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 270200.5004147225, 270200.5004147222, 83938.3458544673], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2188800.0000, 
sim time next is 2189400.0000, 
raw observation next is [16.16666666666667, 81.16666666666667, 1.0, 2.0, 0.2626268636435599, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 285162.0826557829, 285162.0826557832, 85758.52210725963], 
processed observation next is [1.0, 0.34782608695652173, 0.37121212121212144, 0.8116666666666668, 1.0, 1.0, 0.07828357955444988, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10561558616880849, 0.1056155861688086, 0.20916712709087715], 
reward next is 0.7908, 
noisyNet noise sample is [array([-0.7840172], dtype=float32), -0.4649604]. 
=============================================
[2019-03-23 11:56:02,275] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.5502767e-29 1.0000000e+00 0.0000000e+00 6.1208979e-33 0.0000000e+00], sum to 1.0000
[2019-03-23 11:56:02,280] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3795
[2019-03-23 11:56:02,285] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 45.0, 1.0, 2.0, 0.3836085071403639, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 433127.9157827144, 433127.9157827144, 123862.7096672271], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2653800.0000, 
sim time next is 2654400.0000, 
raw observation next is [27.0, 45.0, 1.0, 2.0, 0.3837187670792903, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 433254.5413412665, 433254.5413412662, 123873.7253528317], 
processed observation next is [0.0, 0.7391304347826086, 0.8636363636363636, 0.45, 1.0, 1.0, 0.22964845884911286, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1604646449412098, 0.1604646449412097, 0.30213103744593095], 
reward next is 0.6979, 
noisyNet noise sample is [array([-0.7447024], dtype=float32), -1.9008319]. 
=============================================
[2019-03-23 11:56:02,758] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.9027943e-30 1.0000000e+00 0.0000000e+00 8.4378970e-36 0.0000000e+00], sum to 1.0000
[2019-03-23 11:56:02,764] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6774
[2019-03-23 11:56:02,768] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 52.33333333333334, 1.0, 2.0, 0.5348338401675179, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 580902.8883598561, 580902.8883598561, 114400.1186812468], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2301000.0000, 
sim time next is 2301600.0000, 
raw observation next is [20.0, 51.66666666666667, 1.0, 2.0, 0.5086547818659425, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 552452.682329391, 552452.682329391, 111165.9043593869], 
processed observation next is [1.0, 0.6521739130434783, 0.5454545454545454, 0.5166666666666667, 1.0, 1.0, 0.3858184773324281, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2046121045664411, 0.2046121045664411, 0.2711363520960656], 
reward next is 0.7289, 
noisyNet noise sample is [array([0.16758549], dtype=float32), -0.602034]. 
=============================================
[2019-03-23 11:56:02,802] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.077439e-31 1.000000e+00 0.000000e+00 6.187544e-34 0.000000e+00], sum to 1.0000
[2019-03-23 11:56:02,811] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6607
[2019-03-23 11:56:02,818] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 59.0, 1.0, 2.0, 0.3542915745754088, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 384731.6377721534, 384731.6377721537, 87495.91989985197], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2278800.0000, 
sim time next is 2279400.0000, 
raw observation next is [17.16666666666667, 58.5, 1.0, 2.0, 0.3480051444737796, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 377902.4367220635, 377902.4367220638, 87187.44837253205], 
processed observation next is [1.0, 0.391304347826087, 0.4166666666666669, 0.585, 1.0, 1.0, 0.1850064305922245, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1399638654526161, 0.13996386545261622, 0.2126523131037367], 
reward next is 0.7873, 
noisyNet noise sample is [array([1.0425106], dtype=float32), 0.4336829]. 
=============================================
[2019-03-23 11:56:05,286] A3C_AGENT_WORKER-Thread-9 INFO:Local step 137000, global step 2182843: loss 0.1998
[2019-03-23 11:56:05,289] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 137000, global step 2182844: learning rate 0.0005
[2019-03-23 11:56:08,681] A3C_AGENT_WORKER-Thread-22 INFO:Local step 136500, global step 2184557: loss 0.1009
[2019-03-23 11:56:08,682] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 136500, global step 2184557: learning rate 0.0005
[2019-03-23 11:56:09,165] A3C_AGENT_WORKER-Thread-2 INFO:Local step 136500, global step 2184805: loss 0.0277
[2019-03-23 11:56:09,170] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 136500, global step 2184805: learning rate 0.0005
[2019-03-23 11:56:09,325] A3C_AGENT_WORKER-Thread-3 INFO:Local step 136500, global step 2184881: loss 0.0055
[2019-03-23 11:56:09,328] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 136500, global step 2184881: learning rate 0.0005
[2019-03-23 11:56:09,401] A3C_AGENT_WORKER-Thread-21 INFO:Local step 136500, global step 2184918: loss 0.0002
[2019-03-23 11:56:09,408] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 136500, global step 2184921: learning rate 0.0005
[2019-03-23 11:56:09,531] A3C_AGENT_WORKER-Thread-20 INFO:Local step 136500, global step 2184984: loss 0.0004
[2019-03-23 11:56:09,535] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 136500, global step 2184985: learning rate 0.0005
[2019-03-23 11:56:09,560] A3C_AGENT_WORKER-Thread-12 INFO:Local step 136500, global step 2184997: loss 0.0009
[2019-03-23 11:56:09,561] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 136500, global step 2184998: learning rate 0.0005
[2019-03-23 11:56:09,565] A3C_AGENT_WORKER-Thread-10 INFO:Local step 136500, global step 2185000: loss 0.0000
[2019-03-23 11:56:09,566] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 136500, global step 2185000: learning rate 0.0005
[2019-03-23 11:56:09,753] A3C_AGENT_WORKER-Thread-11 INFO:Local step 136500, global step 2185097: loss 0.0071
[2019-03-23 11:56:09,754] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 136500, global step 2185097: learning rate 0.0005
[2019-03-23 11:56:09,800] A3C_AGENT_WORKER-Thread-19 INFO:Local step 136500, global step 2185120: loss 0.0032
[2019-03-23 11:56:09,801] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 136500, global step 2185121: learning rate 0.0005
[2019-03-23 11:56:09,884] A3C_AGENT_WORKER-Thread-14 INFO:Local step 136500, global step 2185162: loss 0.0006
[2019-03-23 11:56:09,886] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 136500, global step 2185163: learning rate 0.0005
[2019-03-23 11:56:09,973] A3C_AGENT_WORKER-Thread-17 INFO:Local step 136500, global step 2185210: loss 0.0014
[2019-03-23 11:56:09,976] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 136500, global step 2185212: learning rate 0.0005
[2019-03-23 11:56:10,239] A3C_AGENT_WORKER-Thread-15 INFO:Local step 136500, global step 2185346: loss 0.0005
[2019-03-23 11:56:10,240] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 136500, global step 2185346: learning rate 0.0005
[2019-03-23 11:56:10,312] A3C_AGENT_WORKER-Thread-13 INFO:Local step 137000, global step 2185380: loss 0.1616
[2019-03-23 11:56:10,313] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 137000, global step 2185380: learning rate 0.0005
[2019-03-23 11:56:10,959] A3C_AGENT_WORKER-Thread-16 INFO:Local step 136500, global step 2185708: loss 0.0000
[2019-03-23 11:56:10,962] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 136500, global step 2185709: learning rate 0.0005
[2019-03-23 11:56:11,325] A3C_AGENT_WORKER-Thread-18 INFO:Local step 136500, global step 2185844: loss 0.0123
[2019-03-23 11:56:11,327] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 136500, global step 2185845: learning rate 0.0005
[2019-03-23 11:56:14,067] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.0753828e-33 1.0000000e+00 0.0000000e+00 4.0350625e-33 0.0000000e+00], sum to 1.0000
[2019-03-23 11:56:14,074] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5488
[2019-03-23 11:56:14,080] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 99.00000000000001, 1.0, 2.0, 0.2226776898347961, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 241774.2092345547, 241774.2092345547, 75703.32646338739], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2495400.0000, 
sim time next is 2496000.0000, 
raw observation next is [13.0, 98.0, 1.0, 2.0, 0.2211530336842767, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 240118.3921387536, 240118.3921387533, 75264.69524092523], 
processed observation next is [1.0, 0.9130434782608695, 0.22727272727272727, 0.98, 1.0, 1.0, 0.02644129210534585, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08893273782916801, 0.08893273782916788, 0.18357242741689078], 
reward next is 0.8164, 
noisyNet noise sample is [array([-0.19246608], dtype=float32), 0.6480466]. 
=============================================
[2019-03-23 11:56:14,099] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[74.370415]
 [74.370415]
 [74.370415]
 [74.370415]
 [74.370415]], R is [[74.44314575]
 [74.51407623]
 [74.58331299]
 [74.65100098]
 [74.71704102]].
[2019-03-23 11:56:19,276] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.05777956e-29 1.00000000e+00 0.00000000e+00 1.91812008e-35
 0.00000000e+00], sum to 1.0000
[2019-03-23 11:56:19,283] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4171
[2019-03-23 11:56:19,291] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.18333333333334, 71.5, 1.0, 2.0, 0.2667925821145861, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 289686.5959685546, 289686.5959685549, 92964.9031065481], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2587800.0000, 
sim time next is 2588400.0000, 
raw observation next is [18.1, 73.0, 1.0, 2.0, 0.2701086806818737, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 293288.3413981639, 293288.3413981636, 94624.43038887338], 
processed observation next is [1.0, 1.0, 0.45909090909090916, 0.73, 1.0, 1.0, 0.08763585085234213, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10862531162894959, 0.10862531162894948, 0.2307912936313985], 
reward next is 0.7692, 
noisyNet noise sample is [array([-0.89481264], dtype=float32), 0.18500097]. 
=============================================
[2019-03-23 11:56:20,311] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.6733296e-25 1.0000000e+00 7.6143364e-38 6.9035769e-33 4.3661831e-36], sum to 1.0000
[2019-03-23 11:56:20,319] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0384
[2019-03-23 11:56:20,323] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.66666666666667, 100.0, 1.0, 2.0, 0.2891782527190499, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 314001.0733963556, 314001.0733963559, 107869.3147398646], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2612400.0000, 
sim time next is 2613000.0000, 
raw observation next is [15.83333333333333, 100.0, 1.0, 2.0, 0.2946804621724605, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 319977.553459277, 319977.553459277, 110837.0343761914], 
processed observation next is [0.0, 0.21739130434782608, 0.3560606060606059, 1.0, 1.0, 1.0, 0.11835057771557564, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11851020498491742, 0.11851020498491742, 0.2703342301858327], 
reward next is 0.7297, 
noisyNet noise sample is [array([-0.21900745], dtype=float32), -0.98705727]. 
=============================================
[2019-03-23 11:56:20,341] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[73.92519]
 [73.92519]
 [73.92519]
 [73.92519]
 [73.92519]], R is [[73.91561127]
 [73.91335297]
 [73.92121887]
 [73.93753815]
 [73.9606781 ]].
[2019-03-23 11:56:21,722] A3C_AGENT_WORKER-Thread-9 INFO:Local step 137500, global step 2191099: loss 0.0062
[2019-03-23 11:56:21,723] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 137500, global step 2191099: learning rate 0.0005
[2019-03-23 11:56:24,580] A3C_AGENT_WORKER-Thread-22 INFO:Local step 137000, global step 2192553: loss 0.0004
[2019-03-23 11:56:24,584] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 137000, global step 2192554: learning rate 0.0005
[2019-03-23 11:56:24,989] A3C_AGENT_WORKER-Thread-2 INFO:Local step 137000, global step 2192750: loss 0.0242
[2019-03-23 11:56:24,991] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 137000, global step 2192750: learning rate 0.0005
[2019-03-23 11:56:25,176] A3C_AGENT_WORKER-Thread-21 INFO:Local step 137000, global step 2192845: loss 0.0001
[2019-03-23 11:56:25,180] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 137000, global step 2192846: learning rate 0.0005
[2019-03-23 11:56:25,238] A3C_AGENT_WORKER-Thread-3 INFO:Local step 137000, global step 2192876: loss 0.0000
[2019-03-23 11:56:25,242] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 137000, global step 2192877: learning rate 0.0005
[2019-03-23 11:56:25,306] A3C_AGENT_WORKER-Thread-10 INFO:Local step 137000, global step 2192909: loss 0.0002
[2019-03-23 11:56:25,308] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 137000, global step 2192910: learning rate 0.0005
[2019-03-23 11:56:25,396] A3C_AGENT_WORKER-Thread-20 INFO:Local step 137000, global step 2192949: loss 0.0019
[2019-03-23 11:56:25,398] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 137000, global step 2192951: learning rate 0.0005
[2019-03-23 11:56:25,552] A3C_AGENT_WORKER-Thread-12 INFO:Local step 137000, global step 2193033: loss 0.0043
[2019-03-23 11:56:25,555] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 137000, global step 2193033: learning rate 0.0005
[2019-03-23 11:56:25,582] A3C_AGENT_WORKER-Thread-19 INFO:Local step 137000, global step 2193049: loss 0.0029
[2019-03-23 11:56:25,583] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 137000, global step 2193049: learning rate 0.0005
[2019-03-23 11:56:25,684] A3C_AGENT_WORKER-Thread-11 INFO:Local step 137000, global step 2193100: loss 0.0005
[2019-03-23 11:56:25,687] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 137000, global step 2193101: learning rate 0.0005
[2019-03-23 11:56:25,702] A3C_AGENT_WORKER-Thread-17 INFO:Local step 137000, global step 2193107: loss 0.0002
[2019-03-23 11:56:25,705] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 137000, global step 2193107: learning rate 0.0005
[2019-03-23 11:56:25,729] A3C_AGENT_WORKER-Thread-14 INFO:Local step 137000, global step 2193120: loss 0.0001
[2019-03-23 11:56:25,732] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 137000, global step 2193120: learning rate 0.0005
[2019-03-23 11:56:26,127] A3C_AGENT_WORKER-Thread-15 INFO:Local step 137000, global step 2193318: loss 0.0007
[2019-03-23 11:56:26,129] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 137000, global step 2193318: learning rate 0.0005
[2019-03-23 11:56:26,716] A3C_AGENT_WORKER-Thread-16 INFO:Local step 137000, global step 2193577: loss 0.0009
[2019-03-23 11:56:26,717] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 137000, global step 2193577: learning rate 0.0005
[2019-03-23 11:56:27,119] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.9867529e-28 1.0000000e+00 0.0000000e+00 5.7347179e-33 0.0000000e+00], sum to 1.0000
[2019-03-23 11:56:27,123] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8556
[2019-03-23 11:56:27,127] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 58.66666666666667, 1.0, 2.0, 0.4357441103117234, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 496587.7683274898, 496587.7683274898, 132224.0363666966], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2745600.0000, 
sim time next is 2746200.0000, 
raw observation next is [26.0, 59.83333333333334, 1.0, 2.0, 0.442119801660333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 504125.8667348261, 504125.8667348261, 133302.7418477512], 
processed observation next is [0.0, 0.782608695652174, 0.8181818181818182, 0.5983333333333334, 1.0, 1.0, 0.3026497520754162, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18671328397586154, 0.18671328397586154, 0.3251286386530517], 
reward next is 0.6749, 
noisyNet noise sample is [array([-1.1792718], dtype=float32), -0.79904634]. 
=============================================
[2019-03-23 11:56:27,145] A3C_AGENT_WORKER-Thread-18 INFO:Local step 137000, global step 2193775: loss 0.0107
[2019-03-23 11:56:27,150] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 137000, global step 2193776: learning rate 0.0005
[2019-03-23 11:56:27,197] A3C_AGENT_WORKER-Thread-13 INFO:Local step 137500, global step 2193801: loss 0.0034
[2019-03-23 11:56:27,201] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 137500, global step 2193803: learning rate 0.0005
[2019-03-23 11:56:32,084] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.4605854e-23 1.0000000e+00 3.1576508e-33 8.6186249e-25 4.6464397e-32], sum to 1.0000
[2019-03-23 11:56:32,090] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9436
[2019-03-23 11:56:32,095] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 89.0, 1.0, 2.0, 0.5246945639578317, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 597761.1588436305, 597761.1588436305, 145774.320967315], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3108000.0000, 
sim time next is 3108600.0000, 
raw observation next is [23.0, 89.0, 1.0, 2.0, 0.5251920965508002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 598327.8186483674, 598327.8186483678, 145835.5018169904], 
processed observation next is [1.0, 1.0, 0.6818181818181818, 0.89, 1.0, 1.0, 0.40649012068850027, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22160289579569165, 0.22160289579569176, 0.3556963458950986], 
reward next is 0.6443, 
noisyNet noise sample is [array([-0.32899514], dtype=float32), -1.0977873]. 
=============================================
[2019-03-23 11:56:36,039] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.1607816e-19 1.0000000e+00 8.5196968e-28 5.9759792e-27 3.0686928e-27], sum to 1.0000
[2019-03-23 11:56:36,043] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4063
[2019-03-23 11:56:36,048] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 86.0, 1.0, 2.0, 0.529828905169329, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 603374.7680944694, 603374.7680944694, 146607.9411611398], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2921400.0000, 
sim time next is 2922000.0000, 
raw observation next is [23.33333333333333, 87.0, 1.0, 2.0, 0.5265713231073212, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 599735.8448234516, 599735.8448234514, 146147.5086131939], 
processed observation next is [1.0, 0.8260869565217391, 0.6969696969696968, 0.87, 1.0, 1.0, 0.4082141538841515, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22212438697164874, 0.22212438697164866, 0.35645733808096075], 
reward next is 0.6435, 
noisyNet noise sample is [array([0.22537261], dtype=float32), -1.554724]. 
=============================================
[2019-03-23 11:56:36,068] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[48.470657]
 [48.470657]
 [48.470657]
 [48.470657]
 [48.470657]], R is [[48.62949753]
 [48.78562164]
 [48.93938446]
 [49.09136963]
 [49.24161148]].
[2019-03-23 11:56:37,127] A3C_AGENT_WORKER-Thread-9 INFO:Local step 138000, global step 2199063: loss 0.2187
[2019-03-23 11:56:37,132] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 138000, global step 2199064: learning rate 0.0005
[2019-03-23 11:56:38,893] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-23 11:56:38,895] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 11:56:38,896] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:56:38,896] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 11:56:38,897] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 11:56:38,898] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 11:56:38,899] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:56:38,900] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 11:56:38,900] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:56:38,900] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:56:38,901] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:56:38,932] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run89
[2019-03-23 11:56:38,933] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run89
[2019-03-23 11:56:38,982] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run89
[2019-03-23 11:56:39,014] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run89
[2019-03-23 11:56:39,016] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run89
[2019-03-23 11:56:59,450] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.0500716]
[2019-03-23 11:56:59,452] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.21666666666667, 46.5, 1.0, 2.0, 0.3931188239555349, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 426877.6190410114, 426877.6190410111, 122226.3575321154]
[2019-03-23 11:56:59,453] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 11:56:59,455] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.2974092e-25 1.0000000e+00 2.6510655e-35 1.6164267e-28 1.0096342e-34], sampled 0.5445315045052509
[2019-03-23 11:57:18,403] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.0500716]
[2019-03-23 11:57:18,404] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [26.0, 74.0, 1.0, 2.0, 0.5556546431919428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 630376.7551433728, 630376.7551433728, 151196.2889335268]
[2019-03-23 11:57:18,405] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 11:57:18,410] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.2974092e-25 1.0000000e+00 2.6510655e-35 1.6164267e-28 1.0096342e-34], sampled 0.8517045292091232
[2019-03-23 11:57:26,231] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.0500716]
[2019-03-23 11:57:26,232] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.31707142, 98.45789137333333, 1.0, 2.0, 0.3203233732677019, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 348494.4326278603, 348494.4326278599, 117118.582456569]
[2019-03-23 11:57:26,235] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 11:57:26,237] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.2974092e-25 1.0000000e+00 2.6510655e-35 1.6164267e-28 1.0096342e-34], sampled 0.7874125861558992
[2019-03-23 11:57:28,017] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.0500716]
[2019-03-23 11:57:28,018] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [29.9, 54.33333333333334, 1.0, 2.0, 0.7731231787712216, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 875568.1036708676, 875568.1036708676, 187897.9323807356]
[2019-03-23 11:57:28,019] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 11:57:28,021] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.2974092e-25 1.0000000e+00 2.6510655e-35 1.6164267e-28 1.0096342e-34], sampled 0.9824710264056038
[2019-03-23 11:58:18,228] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 11:58:18,476] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 11:58:18,525] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 11:58:18,594] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 11:58:18,755] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 11:58:19,771] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 2200000, evaluation results [2200000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 11:58:20,062] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.6454279e-27 1.0000000e+00 3.9691642e-37 1.1209641e-30 4.6837457e-37], sum to 1.0000
[2019-03-23 11:58:20,068] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6684
[2019-03-23 11:58:20,080] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1296907.73437151 W.
[2019-03-23 11:58:20,085] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.5, 60.0, 1.0, 2.0, 0.5723783398236602, 1.0, 1.0, 0.5723783398236602, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1296907.73437151, 1296907.73437151, 251788.0446778801], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2979000.0000, 
sim time next is 2979600.0000, 
raw observation next is [27.66666666666666, 59.33333333333333, 1.0, 2.0, 0.4254552057386262, 1.0, 2.0, 0.4254552057386262, 1.0, 1.0, 0.8606190743721277, 6.9112, 6.9112, 77.3421103, 1441142.564445543, 1441142.564445543, 317483.4913709193], 
processed observation next is [1.0, 0.4782608695652174, 0.8939393939393937, 0.5933333333333333, 1.0, 1.0, 0.28181900717328273, 1.0, 1.0, 0.28181900717328273, 1.0, 0.5, 0.8008843919601826, 0.0, 0.0, 0.5085185399722538, 0.5337565053502011, 0.5337565053502011, 0.7743499789534617], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.08504], dtype=float32), 0.5230877]. 
=============================================
[2019-03-23 11:58:20,676] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.1811597e-22 1.0000000e+00 3.5369174e-31 5.9455608e-25 5.7483276e-30], sum to 1.0000
[2019-03-23 11:58:20,683] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7956
[2019-03-23 11:58:20,689] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1522212.186227791 W.
[2019-03-23 11:58:20,696] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.0, 62.33333333333334, 1.0, 2.0, 0.4511769515167931, 1.0, 2.0, 0.4511769515167931, 1.0, 2.0, 0.9129021645928593, 6.911199999999999, 6.9112, 77.3421103, 1522212.186227791, 1522212.186227792, 333327.6374732384], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2996400.0000, 
sim time next is 2997000.0000, 
raw observation next is [28.0, 60.5, 1.0, 2.0, 0.4229019962612334, 1.0, 2.0, 0.4229019962612334, 1.0, 2.0, 0.8556912016440883, 6.911199999999999, 6.9112, 77.3421103, 1426696.002601172, 1426696.002601173, 318625.6968211737], 
processed observation next is [1.0, 0.6956521739130435, 0.9090909090909091, 0.605, 1.0, 1.0, 0.27862749532654174, 1.0, 1.0, 0.27862749532654174, 1.0, 1.0, 0.793844573777269, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.528405926889323, 0.5284059268893233, 0.7771358459053017], 
reward next is 0.2229, 
noisyNet noise sample is [array([-0.13799788], dtype=float32), 0.15628685]. 
=============================================
[2019-03-23 11:58:20,712] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[52.117336]
 [52.117336]
 [52.117336]
 [52.117336]
 [52.117336]], R is [[51.81903076]
 [51.48784637]
 [50.97296906]
 [50.46324158]
 [49.95861053]].
[2019-03-23 11:58:20,932] A3C_AGENT_WORKER-Thread-22 INFO:Local step 137500, global step 2200578: loss 0.4512
[2019-03-23 11:58:20,937] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 137500, global step 2200579: learning rate 0.0005
[2019-03-23 11:58:21,303] A3C_AGENT_WORKER-Thread-2 INFO:Local step 137500, global step 2200767: loss 0.5338
[2019-03-23 11:58:21,307] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 137500, global step 2200768: learning rate 0.0005
[2019-03-23 11:58:21,439] A3C_AGENT_WORKER-Thread-10 INFO:Local step 137500, global step 2200834: loss 0.5019
[2019-03-23 11:58:21,440] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 137500, global step 2200834: learning rate 0.0005
[2019-03-23 11:58:21,540] A3C_AGENT_WORKER-Thread-3 INFO:Local step 137500, global step 2200886: loss 0.4535
[2019-03-23 11:58:21,542] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 137500, global step 2200887: learning rate 0.0005
[2019-03-23 11:58:21,667] A3C_AGENT_WORKER-Thread-21 INFO:Local step 137500, global step 2200947: loss 0.4078
[2019-03-23 11:58:21,669] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 137500, global step 2200947: learning rate 0.0005
[2019-03-23 11:58:21,726] A3C_AGENT_WORKER-Thread-19 INFO:Local step 137500, global step 2200979: loss 0.3883
[2019-03-23 11:58:21,733] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 137500, global step 2200980: learning rate 0.0005
[2019-03-23 11:58:21,834] A3C_AGENT_WORKER-Thread-20 INFO:Local step 137500, global step 2201028: loss 0.3659
[2019-03-23 11:58:21,835] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 137500, global step 2201029: learning rate 0.0005
[2019-03-23 11:58:21,843] A3C_AGENT_WORKER-Thread-11 INFO:Local step 137500, global step 2201032: loss 0.3236
[2019-03-23 11:58:21,845] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 137500, global step 2201034: learning rate 0.0005
[2019-03-23 11:58:21,909] A3C_AGENT_WORKER-Thread-12 INFO:Local step 137500, global step 2201065: loss 0.2769
[2019-03-23 11:58:21,911] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 137500, global step 2201065: learning rate 0.0005
[2019-03-23 11:58:22,151] A3C_AGENT_WORKER-Thread-14 INFO:Local step 137500, global step 2201183: loss 0.1887
[2019-03-23 11:58:22,152] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 137500, global step 2201183: learning rate 0.0005
[2019-03-23 11:58:22,210] A3C_AGENT_WORKER-Thread-17 INFO:Local step 137500, global step 2201215: loss 0.1716
[2019-03-23 11:58:22,211] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 137500, global step 2201215: learning rate 0.0005
[2019-03-23 11:58:22,553] A3C_AGENT_WORKER-Thread-15 INFO:Local step 137500, global step 2201384: loss 0.0306
[2019-03-23 11:58:22,556] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 137500, global step 2201386: learning rate 0.0005
[2019-03-23 11:58:22,874] A3C_AGENT_WORKER-Thread-16 INFO:Local step 137500, global step 2201547: loss 0.0004
[2019-03-23 11:58:22,877] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 137500, global step 2201547: learning rate 0.0005
[2019-03-23 11:58:22,892] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.5919371e-28 1.0000000e+00 0.0000000e+00 2.1938137e-36 0.0000000e+00], sum to 1.0000
[2019-03-23 11:58:22,893] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7328
[2019-03-23 11:58:22,898] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.33333333333334, 88.0, 1.0, 2.0, 0.3580416801904152, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 396655.9646696436, 396655.9646696433, 118070.9320130994], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3026400.0000, 
sim time next is 3027000.0000, 
raw observation next is [18.16666666666666, 88.0, 1.0, 2.0, 0.3538154541998506, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 390929.9733424254, 390929.9733424254, 117331.7248713573], 
processed observation next is [1.0, 0.0, 0.4621212121212119, 0.88, 1.0, 1.0, 0.19226931774981323, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1447888790157131, 0.1447888790157131, 0.2861749387106276], 
reward next is 0.7138, 
noisyNet noise sample is [array([-0.04181193], dtype=float32), -0.4962739]. 
=============================================
[2019-03-23 11:58:22,910] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[69.396866]
 [69.396866]
 [69.396866]
 [69.396866]
 [69.396866]], R is [[69.41671753]
 [69.43457031]
 [69.45034027]
 [69.46408844]
 [69.47592163]].
[2019-03-23 11:58:23,012] A3C_AGENT_WORKER-Thread-13 INFO:Local step 138000, global step 2201617: loss 0.0491
[2019-03-23 11:58:23,014] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 138000, global step 2201617: learning rate 0.0005
[2019-03-23 11:58:23,510] A3C_AGENT_WORKER-Thread-18 INFO:Local step 137500, global step 2201870: loss 0.0111
[2019-03-23 11:58:23,513] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 137500, global step 2201870: learning rate 0.0005
[2019-03-23 11:58:27,985] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.9729148e-29 1.0000000e+00 0.0000000e+00 1.8643934e-31 0.0000000e+00], sum to 1.0000
[2019-03-23 11:58:27,993] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7455
[2019-03-23 11:58:27,997] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 78.0, 1.0, 2.0, 0.4457297248511113, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 506241.4661714248, 506241.4661714248, 131547.0300909847], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3135600.0000, 
sim time next is 3136200.0000, 
raw observation next is [22.16666666666667, 77.16666666666667, 1.0, 2.0, 0.4793486061316112, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 544582.3531333938, 544582.3531333942, 135120.9996277933], 
processed observation next is [1.0, 0.30434782608695654, 0.6439393939393941, 0.7716666666666667, 1.0, 1.0, 0.34918575766451393, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2016971678271829, 0.20169716782718303, 0.3295634137263251], 
reward next is 0.6704, 
noisyNet noise sample is [array([0.59603196], dtype=float32), 0.0081948405]. 
=============================================
[2019-03-23 11:58:28,827] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.2281372e-27 1.0000000e+00 6.6232056e-37 7.4333290e-30 4.9921070e-35], sum to 1.0000
[2019-03-23 11:58:28,834] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1740
[2019-03-23 11:58:28,841] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1390840.045187561 W.
[2019-03-23 11:58:28,845] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.16666666666667, 68.83333333333334, 1.0, 2.0, 0.6117342915312268, 1.0, 1.0, 0.6117342915312268, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1390840.045187561, 1390840.045187561, 260690.7555623706], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3150600.0000, 
sim time next is 3151200.0000, 
raw observation next is [24.33333333333334, 72.66666666666667, 1.0, 2.0, 0.3793616741673373, 1.0, 2.0, 0.3793616741673373, 1.0, 1.0, 0.7684720460811846, 6.911199999999999, 6.9112, 77.3421103, 1293243.678501022, 1293243.678501022, 291892.4750183257], 
processed observation next is [1.0, 0.4782608695652174, 0.7424242424242427, 0.7266666666666667, 1.0, 1.0, 0.2242020927091716, 1.0, 1.0, 0.2242020927091716, 1.0, 0.5, 0.669245780115978, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.4789791401855637, 0.4789791401855637, 0.7119328658983555], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.7579465], dtype=float32), -2.1754446]. 
=============================================
[2019-03-23 11:58:33,988] A3C_AGENT_WORKER-Thread-9 INFO:Local step 138500, global step 2207122: loss 0.0666
[2019-03-23 11:58:33,991] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 138500, global step 2207123: learning rate 0.0005
[2019-03-23 11:58:35,805] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.8129366e-30 1.0000000e+00 0.0000000e+00 2.0862837e-33 0.0000000e+00], sum to 1.0000
[2019-03-23 11:58:35,809] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5363
[2019-03-23 11:58:35,816] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666667, 90.66666666666667, 1.0, 2.0, 0.6790451231654135, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 773852.8805099652, 773852.8805099649, 166302.154425883], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3550800.0000, 
sim time next is 3551400.0000, 
raw observation next is [22.5, 91.5, 1.0, 2.0, 0.6276852994329998, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 715460.6308036775, 715460.6308036775, 158863.8663347276], 
processed observation next is [1.0, 0.08695652173913043, 0.6590909090909091, 0.915, 1.0, 1.0, 0.5346066242912497, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2649854188161768, 0.2649854188161768, 0.3874728447188478], 
reward next is 0.6125, 
noisyNet noise sample is [array([0.78910667], dtype=float32), -1.2255756]. 
=============================================
[2019-03-23 11:58:36,841] A3C_AGENT_WORKER-Thread-22 INFO:Local step 138000, global step 2208579: loss 0.0014
[2019-03-23 11:58:36,843] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 138000, global step 2208580: learning rate 0.0005
[2019-03-23 11:58:37,316] A3C_AGENT_WORKER-Thread-2 INFO:Local step 138000, global step 2208818: loss 0.0015
[2019-03-23 11:58:37,320] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 138000, global step 2208818: learning rate 0.0005
[2019-03-23 11:58:37,329] A3C_AGENT_WORKER-Thread-10 INFO:Local step 138000, global step 2208824: loss 0.0030
[2019-03-23 11:58:37,331] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 138000, global step 2208824: learning rate 0.0005
[2019-03-23 11:58:37,379] A3C_AGENT_WORKER-Thread-3 INFO:Local step 138000, global step 2208847: loss 0.0060
[2019-03-23 11:58:37,383] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 138000, global step 2208848: learning rate 0.0005
[2019-03-23 11:58:37,470] A3C_AGENT_WORKER-Thread-21 INFO:Local step 138000, global step 2208894: loss 0.0080
[2019-03-23 11:58:37,473] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 138000, global step 2208895: learning rate 0.0005
[2019-03-23 11:58:37,495] A3C_AGENT_WORKER-Thread-19 INFO:Local step 138000, global step 2208905: loss 0.0018
[2019-03-23 11:58:37,497] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 138000, global step 2208907: learning rate 0.0005
[2019-03-23 11:58:37,659] A3C_AGENT_WORKER-Thread-11 INFO:Local step 138000, global step 2208989: loss 0.0016
[2019-03-23 11:58:37,661] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 138000, global step 2208989: learning rate 0.0005
[2019-03-23 11:58:37,712] A3C_AGENT_WORKER-Thread-12 INFO:Local step 138000, global step 2209014: loss 0.0001
[2019-03-23 11:58:37,714] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 138000, global step 2209014: learning rate 0.0005
[2019-03-23 11:58:37,731] A3C_AGENT_WORKER-Thread-20 INFO:Local step 138000, global step 2209025: loss 0.0001
[2019-03-23 11:58:37,733] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 138000, global step 2209026: learning rate 0.0005
[2019-03-23 11:58:38,040] A3C_AGENT_WORKER-Thread-14 INFO:Local step 138000, global step 2209179: loss 0.0049
[2019-03-23 11:58:38,043] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 138000, global step 2209179: learning rate 0.0005
[2019-03-23 11:58:38,172] A3C_AGENT_WORKER-Thread-17 INFO:Local step 138000, global step 2209248: loss 0.0117
[2019-03-23 11:58:38,174] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 138000, global step 2209248: learning rate 0.0005
[2019-03-23 11:58:38,243] A3C_AGENT_WORKER-Thread-15 INFO:Local step 138000, global step 2209277: loss 0.0070
[2019-03-23 11:58:38,246] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 138000, global step 2209277: learning rate 0.0005
[2019-03-23 11:58:38,834] A3C_AGENT_WORKER-Thread-16 INFO:Local step 138000, global step 2209578: loss 0.0316
[2019-03-23 11:58:38,836] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 138000, global step 2209578: learning rate 0.0005
[2019-03-23 11:58:39,128] A3C_AGENT_WORKER-Thread-18 INFO:Local step 138000, global step 2209727: loss 0.0578
[2019-03-23 11:58:39,129] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 138000, global step 2209728: learning rate 0.0005
[2019-03-23 11:58:39,240] A3C_AGENT_WORKER-Thread-13 INFO:Local step 138500, global step 2209793: loss 0.0668
[2019-03-23 11:58:39,244] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 138500, global step 2209793: learning rate 0.0005
[2019-03-23 11:58:46,845] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.5315173e-27 1.0000000e+00 4.6677642e-37 1.7600812e-32 7.0782603e-36], sum to 1.0000
[2019-03-23 11:58:46,854] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0856
[2019-03-23 11:58:46,859] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.83333333333334, 89.83333333333333, 1.0, 2.0, 0.3158988322597855, 1.0, 2.0, 0.3158988322597855, 1.0, 1.0, 0.6395783843026245, 6.9112, 6.9112, 77.3421103, 1072891.284288673, 1072891.284288673, 267747.2475166963], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3491400.0000, 
sim time next is 3492000.0000, 
raw observation next is [23.0, 89.0, 1.0, 2.0, 0.9983373117907368, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.136733972160622, 6.9112, 77.32801593931187, 1209469.361709144, 1136220.964413954, 221947.6718447565], 
processed observation next is [1.0, 0.43478260869565216, 0.6818181818181818, 0.89, 1.0, 1.0, 0.9979216397384211, 0.0, 0.5, -0.25, 0.0, 0.5, -0.4285714285714286, 0.022553397216062178, 0.0, 0.5084258706141103, 0.4479516154478311, 0.42082257941257556, 0.5413357849872109], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.5018708], dtype=float32), -0.6578556]. 
=============================================
[2019-03-23 11:58:46,877] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[63.658756]
 [63.658756]
 [63.658756]
 [63.658756]
 [63.658756]], R is [[63.02216721]
 [62.73890305]
 [62.55410385]
 [61.92856216]
 [61.55527878]].
[2019-03-23 11:58:48,155] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.4438651e-21 1.0000000e+00 2.3518409e-29 8.8563685e-23 2.2416610e-29], sum to 1.0000
[2019-03-23 11:58:48,161] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2957
[2019-03-23 11:58:48,168] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1749715.091652488 W.
[2019-03-23 11:58:48,178] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.0, 62.0, 1.0, 2.0, 0.5494306458553151, 1.0, 2.0, 0.518503759869265, 1.0, 2.0, 0.9865530188920543, 6.911199999999999, 6.9112, 77.3421103, 1749715.091652488, 1749715.091652488, 364756.0485928841], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3513600.0000, 
sim time next is 3514200.0000, 
raw observation next is [28.93333333333333, 61.66666666666667, 1.0, 2.0, 0.7510194311106857, 1.0, 2.0, 0.7510194311106857, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1689477.383588795, 1689477.383588795, 308293.536557077], 
processed observation next is [1.0, 0.6956521739130435, 0.9515151515151513, 0.6166666666666667, 1.0, 1.0, 0.6887742888883571, 1.0, 1.0, 0.6887742888883571, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.6257323642921463, 0.6257323642921463, 0.751935455017261], 
reward next is 0.2481, 
noisyNet noise sample is [array([-2.3095686], dtype=float32), -0.23195902]. 
=============================================
[2019-03-23 11:58:49,801] A3C_AGENT_WORKER-Thread-9 INFO:Local step 139000, global step 2215103: loss 0.4397
[2019-03-23 11:58:49,804] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 139000, global step 2215103: learning rate 0.0005
[2019-03-23 11:58:50,391] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.4152674e-30 1.0000000e+00 0.0000000e+00 1.9108106e-34 0.0000000e+00], sum to 1.0000
[2019-03-23 11:58:50,399] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8252
[2019-03-23 11:58:50,406] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 91.5, 1.0, 2.0, 0.6276852994329998, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 715460.6308036775, 715460.6308036775, 158863.8663347276], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3551400.0000, 
sim time next is 3552000.0000, 
raw observation next is [22.33333333333334, 92.33333333333334, 1.0, 2.0, 0.589976978012304, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 672601.3168400595, 672601.3168400595, 153631.1418897757], 
processed observation next is [1.0, 0.08695652173913043, 0.6515151515151518, 0.9233333333333335, 1.0, 1.0, 0.48747122251537994, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.24911159882965167, 0.24911159882965167, 0.37471010217018463], 
reward next is 0.6253, 
noisyNet noise sample is [array([0.15251558], dtype=float32), 0.44823325]. 
=============================================
[2019-03-23 11:58:50,423] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[63.43349]
 [63.43349]
 [63.43349]
 [63.43349]
 [63.43349]], R is [[63.42444229]
 [63.40272522]
 [63.36308289]
 [63.27452469]
 [63.28737259]].
[2019-03-23 11:58:52,858] A3C_AGENT_WORKER-Thread-22 INFO:Local step 138500, global step 2216617: loss 0.2276
[2019-03-23 11:58:52,859] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 138500, global step 2216617: learning rate 0.0005
[2019-03-23 11:58:53,257] A3C_AGENT_WORKER-Thread-21 INFO:Local step 138500, global step 2216818: loss 0.3467
[2019-03-23 11:58:53,260] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 138500, global step 2216818: learning rate 0.0005
[2019-03-23 11:58:53,281] A3C_AGENT_WORKER-Thread-10 INFO:Local step 138500, global step 2216828: loss 0.3593
[2019-03-23 11:58:53,283] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 138500, global step 2216828: learning rate 0.0005
[2019-03-23 11:58:53,333] A3C_AGENT_WORKER-Thread-2 INFO:Local step 138500, global step 2216856: loss 0.3585
[2019-03-23 11:58:53,335] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 138500, global step 2216856: learning rate 0.0005
[2019-03-23 11:58:53,414] A3C_AGENT_WORKER-Thread-3 INFO:Local step 138500, global step 2216894: loss 0.3567
[2019-03-23 11:58:53,417] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 138500, global step 2216895: learning rate 0.0005
[2019-03-23 11:58:53,565] A3C_AGENT_WORKER-Thread-19 INFO:Local step 138500, global step 2216969: loss 0.3094
[2019-03-23 11:58:53,569] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 138500, global step 2216969: learning rate 0.0005
[2019-03-23 11:58:53,657] A3C_AGENT_WORKER-Thread-11 INFO:Local step 138500, global step 2217019: loss 0.2849
[2019-03-23 11:58:53,660] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 138500, global step 2217019: learning rate 0.0005
[2019-03-23 11:58:53,679] A3C_AGENT_WORKER-Thread-20 INFO:Local step 138500, global step 2217029: loss 0.3031
[2019-03-23 11:58:53,680] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 138500, global step 2217029: learning rate 0.0005
[2019-03-23 11:58:53,810] A3C_AGENT_WORKER-Thread-12 INFO:Local step 138500, global step 2217089: loss 0.2383
[2019-03-23 11:58:53,813] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 138500, global step 2217090: learning rate 0.0005
[2019-03-23 11:58:54,014] A3C_AGENT_WORKER-Thread-14 INFO:Local step 138500, global step 2217201: loss 0.1758
[2019-03-23 11:58:54,017] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 138500, global step 2217202: learning rate 0.0005
[2019-03-23 11:58:54,208] A3C_AGENT_WORKER-Thread-17 INFO:Local step 138500, global step 2217302: loss 0.0841
[2019-03-23 11:58:54,213] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 138500, global step 2217303: learning rate 0.0005
[2019-03-23 11:58:54,222] A3C_AGENT_WORKER-Thread-15 INFO:Local step 138500, global step 2217306: loss 0.0755
[2019-03-23 11:58:54,223] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 138500, global step 2217307: learning rate 0.0005
[2019-03-23 11:58:54,949] A3C_AGENT_WORKER-Thread-16 INFO:Local step 138500, global step 2217672: loss 0.0010
[2019-03-23 11:58:54,950] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 138500, global step 2217672: learning rate 0.0005
[2019-03-23 11:58:55,045] A3C_AGENT_WORKER-Thread-13 INFO:Local step 139000, global step 2217723: loss 0.2587
[2019-03-23 11:58:55,047] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 139000, global step 2217724: learning rate 0.0005
[2019-03-23 11:58:55,075] A3C_AGENT_WORKER-Thread-18 INFO:Local step 138500, global step 2217738: loss 0.0056
[2019-03-23 11:58:55,078] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.2817309e-29 1.0000000e+00 0.0000000e+00 1.7453262e-31 0.0000000e+00], sum to 1.0000
[2019-03-23 11:58:55,080] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 138500, global step 2217739: learning rate 0.0005
[2019-03-23 11:58:55,092] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3027
[2019-03-23 11:58:55,097] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.49334284915794, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 562882.1822016374, 562882.1822016374, 140720.8958178019], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3628200.0000, 
sim time next is 3628800.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.49293625594036, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 562418.1084748799, 562418.1084748802, 140673.8128014344], 
processed observation next is [1.0, 0.0, 0.5909090909090909, 1.0, 1.0, 1.0, 0.36617031992544996, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2083030031388444, 0.20830300313884453, 0.3431068604913034], 
reward next is 0.6569, 
noisyNet noise sample is [array([-0.9671315], dtype=float32), 1.9007893]. 
=============================================
[2019-03-23 11:58:56,234] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.57495858e-27 1.00000000e+00 8.33443225e-38 6.43470027e-31
 1.16695444e-35], sum to 1.0000
[2019-03-23 11:58:56,240] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2365
[2019-03-23 11:58:56,245] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.5, 97.0, 1.0, 2.0, 0.897032012065002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1023576.622991023, 1023576.622991024, 200132.9558701745], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3659400.0000, 
sim time next is 3660000.0000, 
raw observation next is [21.66666666666667, 96.0, 1.0, 2.0, 0.9267752744911504, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1057383.7199834, 1057383.7199834, 205721.8209717869], 
processed observation next is [1.0, 0.34782608695652173, 0.6212121212121214, 0.96, 1.0, 1.0, 0.908469093113938, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3916235999938519, 0.3916235999938519, 0.5017605389555778], 
reward next is 0.4982, 
noisyNet noise sample is [array([0.75492054], dtype=float32), -0.24608313]. 
=============================================
[2019-03-23 11:58:56,263] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[63.00053]
 [63.00053]
 [63.00053]
 [63.00053]
 [63.00053]], R is [[62.86875916]
 [62.75194168]
 [62.69631958]
 [62.71783066]
 [62.7455101 ]].
[2019-03-23 11:58:59,276] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.3446853e-28 1.0000000e+00 0.0000000e+00 3.1267187e-30 1.8511981e-38], sum to 1.0000
[2019-03-23 11:58:59,283] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9655
[2019-03-23 11:58:59,285] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.16666666666667, 93.16666666666667, 1.0, 2.0, 0.5149850124968124, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 587208.2193315495, 587208.2193315497, 144022.4688112706], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3718200.0000, 
sim time next is 3718800.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.5116165721332661, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 583452.7854301023, 583452.785430102, 143490.5112838882], 
processed observation next is [1.0, 0.043478260869565216, 0.6363636363636364, 0.94, 1.0, 1.0, 0.38952071516658254, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2160936242333712, 0.2160936242333711, 0.3499768567899712], 
reward next is 0.6500, 
noisyNet noise sample is [array([-0.84658563], dtype=float32), -1.0334169]. 
=============================================
[2019-03-23 11:59:01,945] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.3826745e-23 1.0000000e+00 5.8314100e-32 2.3212990e-26 2.7102945e-33], sum to 1.0000
[2019-03-23 11:59:01,951] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8582
[2019-03-23 11:59:01,960] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1244715.931919523 W.
[2019-03-23 11:59:01,965] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.16666666666667, 63.83333333333334, 1.0, 2.0, 0.3639692594053492, 1.0, 2.0, 0.3639692594053492, 1.0, 2.0, 0.736765153566066, 6.9112, 6.9112, 77.3421103, 1244715.931919523, 1244715.931919523, 282015.5230405245], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3755400.0000, 
sim time next is 3756000.0000, 
raw observation next is [25.33333333333334, 62.66666666666667, 1.0, 2.0, 0.6279815167746402, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9686432315820767, 6.9112, 6.9112, 77.32846344354104, 1265291.647114317, 1265291.647114317, 273126.0147847835], 
processed observation next is [1.0, 0.4782608695652174, 0.7878787878787882, 0.6266666666666667, 1.0, 1.0, 0.5349768959683002, 0.0, 0.5, -0.25, 1.0, 1.0, 0.955204616545824, 0.0, 0.0, 0.5084288129206541, 0.46862653596826553, 0.46862653596826553, 0.6661610116702036], 
reward next is 0.3338, 
noisyNet noise sample is [array([0.17608549], dtype=float32), 0.16981132]. 
=============================================
[2019-03-23 11:59:01,976] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[57.661777]
 [57.661777]
 [57.661777]
 [57.661777]
 [57.661777]], R is [[57.41900253]
 [57.15697098]
 [56.58540344]
 [56.01955032]
 [55.88561249]].
[2019-03-23 11:59:02,381] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.7035023e-26 1.0000000e+00 1.3086675e-36 4.4240910e-29 5.7292016e-35], sum to 1.0000
[2019-03-23 11:59:02,387] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3346
[2019-03-23 11:59:02,390] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 61.33333333333334, 1.0, 2.0, 0.3502664164090749, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 385923.1959674479, 385923.1959674479, 116645.7701269782], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3777600.0000, 
sim time next is 3778200.0000, 
raw observation next is [21.5, 62.0, 1.0, 2.0, 0.3388404739922836, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 372731.1374586791, 372731.1374586794, 115556.7777222846], 
processed observation next is [1.0, 0.7391304347826086, 0.6136363636363636, 0.62, 1.0, 1.0, 0.1735505924903545, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1380485694291404, 0.1380485694291405, 0.28184579932264536], 
reward next is 0.7182, 
noisyNet noise sample is [array([0.9079848], dtype=float32), -0.730133]. 
=============================================
[2019-03-23 11:59:04,868] A3C_AGENT_WORKER-Thread-9 INFO:Local step 139500, global step 2222786: loss 0.0015
[2019-03-23 11:59:04,870] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 139500, global step 2222786: learning rate 0.0005
[2019-03-23 11:59:06,552] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.2053039e-26 1.0000000e+00 4.5590091e-37 1.8407653e-27 6.6599927e-37], sum to 1.0000
[2019-03-23 11:59:06,558] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9448
[2019-03-23 11:59:06,563] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 64.0, 1.0, 2.0, 0.3177343238918643, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 348281.7203112813, 348281.720311281, 113551.450212305], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3877200.0000, 
sim time next is 3877800.0000, 
raw observation next is [20.83333333333333, 64.0, 1.0, 2.0, 0.3139866789242876, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 343459.8399460183, 343459.8399460183, 113024.2623585912], 
processed observation next is [0.0, 0.9130434782608695, 0.5833333333333331, 0.64, 1.0, 1.0, 0.1424833486553595, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12720734812815493, 0.12720734812815493, 0.27566893258192976], 
reward next is 0.7243, 
noisyNet noise sample is [array([1.6741694], dtype=float32), 0.43206093]. 
=============================================
[2019-03-23 11:59:07,077] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.9472962e-32 1.0000000e+00 0.0000000e+00 2.3748670e-36 0.0000000e+00], sum to 1.0000
[2019-03-23 11:59:07,078] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2545
[2019-03-23 11:59:07,081] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.83333333333334, 64.66666666666667, 1.0, 2.0, 0.2867870673107467, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 311403.7993256486, 311403.7993256486, 104565.5196736766], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3881400.0000, 
sim time next is 3882000.0000, 
raw observation next is [19.66666666666667, 65.33333333333334, 1.0, 2.0, 0.2840223197589025, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 308400.7842698295, 308400.7842698292, 103096.5108253885], 
processed observation next is [0.0, 0.9565217391304348, 0.5303030303030305, 0.6533333333333334, 1.0, 1.0, 0.10502789969862814, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11422251269252945, 0.11422251269252934, 0.25145490445216706], 
reward next is 0.7485, 
noisyNet noise sample is [array([0.8827979], dtype=float32), 1.0871407]. 
=============================================
[2019-03-23 11:59:07,096] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.7776295e-31 1.0000000e+00 0.0000000e+00 2.4940310e-34 0.0000000e+00], sum to 1.0000
[2019-03-23 11:59:07,100] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[73.81837]
 [73.81837]
 [73.81837]
 [73.81837]
 [73.81837]], R is [[73.82872772]
 [73.83540344]
 [73.83799744]
 [73.83042908]
 [73.82073975]].
[2019-03-23 11:59:07,109] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5026
[2019-03-23 11:59:07,114] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.16666666666666, 62.83333333333334, 1.0, 2.0, 0.3163873087828527, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 346663.923387119, 346663.9233871193, 113403.9453557174], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3873000.0000, 
sim time next is 3873600.0000, 
raw observation next is [21.0, 64.0, 1.0, 2.0, 0.3167161718566301, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 347126.3430999584, 347126.3430999581, 113464.7442119694], 
processed observation next is [0.0, 0.8695652173913043, 0.5909090909090909, 0.64, 1.0, 1.0, 0.1458952148207876, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12856531225924384, 0.12856531225924372, 0.276743278565779], 
reward next is 0.7233, 
noisyNet noise sample is [array([-1.905971], dtype=float32), 0.24779885]. 
=============================================
[2019-03-23 11:59:07,221] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.3847903e-30 1.0000000e+00 0.0000000e+00 7.8477390e-32 0.0000000e+00], sum to 1.0000
[2019-03-23 11:59:07,228] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1729
[2019-03-23 11:59:07,234] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666667, 57.00000000000001, 1.0, 2.0, 0.3348332417087067, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 370247.5744750371, 370247.5744750371, 115998.2465963177], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3864000.0000, 
sim time next is 3864600.0000, 
raw observation next is [22.5, 57.0, 1.0, 2.0, 0.3306451448063228, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 364728.5102100467, 364728.510210047, 115335.9579086701], 
processed observation next is [0.0, 0.7391304347826086, 0.6590909090909091, 0.57, 1.0, 1.0, 0.16330643100790346, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13508463341112842, 0.13508463341112853, 0.2813072144113905], 
reward next is 0.7187, 
noisyNet noise sample is [array([1.6158957], dtype=float32), -0.48524135]. 
=============================================
[2019-03-23 11:59:08,330] A3C_AGENT_WORKER-Thread-22 INFO:Local step 139000, global step 2224590: loss 0.0063
[2019-03-23 11:59:08,332] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 139000, global step 2224592: learning rate 0.0005
[2019-03-23 11:59:08,557] A3C_AGENT_WORKER-Thread-10 INFO:Local step 139000, global step 2224709: loss 0.0078
[2019-03-23 11:59:08,560] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 139000, global step 2224710: learning rate 0.0005
[2019-03-23 11:59:08,620] A3C_AGENT_WORKER-Thread-21 INFO:Local step 139000, global step 2224746: loss 0.0060
[2019-03-23 11:59:08,621] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 139000, global step 2224747: learning rate 0.0005
[2019-03-23 11:59:08,861] A3C_AGENT_WORKER-Thread-3 INFO:Local step 139000, global step 2224870: loss 0.0004
[2019-03-23 11:59:08,862] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 139000, global step 2224871: learning rate 0.0005
[2019-03-23 11:59:08,950] A3C_AGENT_WORKER-Thread-2 INFO:Local step 139000, global step 2224918: loss 0.0162
[2019-03-23 11:59:08,952] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 139000, global step 2224918: learning rate 0.0005
[2019-03-23 11:59:09,038] A3C_AGENT_WORKER-Thread-19 INFO:Local step 139000, global step 2224966: loss 0.0350
[2019-03-23 11:59:09,043] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 139000, global step 2224966: learning rate 0.0005
[2019-03-23 11:59:09,104] A3C_AGENT_WORKER-Thread-12 INFO:Local step 139000, global step 2225000: loss 0.0221
[2019-03-23 11:59:09,106] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 139000, global step 2225000: learning rate 0.0005
[2019-03-23 11:59:09,110] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-23 11:59:09,111] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 11:59:09,111] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:59:09,112] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 11:59:09,112] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 11:59:09,113] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 11:59:09,114] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 11:59:09,115] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:59:09,115] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:59:09,113] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:59:09,116] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:59:09,139] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run90
[2019-03-23 11:59:09,165] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run90
[2019-03-23 11:59:09,193] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run90
[2019-03-23 11:59:09,194] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run90
[2019-03-23 11:59:09,227] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run90
[2019-03-23 11:59:15,743] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.0807068]
[2019-03-23 11:59:15,743] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [15.51666666666667, 69.5, 1.0, 2.0, 0.2279735768499659, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 247513.7151275375, 247513.7151275371, 79062.31962789604]
[2019-03-23 11:59:15,745] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 11:59:15,749] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.8956118e-30 1.0000000e+00 0.0000000e+00 2.9477808e-34 0.0000000e+00], sampled 0.16787488708173182
[2019-03-23 11:59:24,007] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.0807068]
[2019-03-23 11:59:24,008] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [25.0, 71.5, 1.0, 2.0, 0.5022004928613993, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9512221707690696, 6.948971017383548, 6.9112, 77.32834806936305, 1120728.647175728, 1108461.411583218, 256962.9362442344]
[2019-03-23 11:59:24,008] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 11:59:24,009] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.8956118e-30 1.0000000e+00 0.0000000e+00 2.9477808e-34 0.0000000e+00], sampled 0.48471201470106606
[2019-03-23 11:59:24,010] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1120728.647175728 W.
[2019-03-23 11:59:27,621] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.0807068]
[2019-03-23 11:59:27,621] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.0, 76.66666666666667, 1.0, 2.0, 0.5234839161894407, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 589030.280962432, 589030.2809624316, 140876.2042400308]
[2019-03-23 11:59:27,622] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 11:59:27,625] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.8956118e-30 1.0000000e+00 0.0000000e+00 2.9477808e-34 0.0000000e+00], sampled 0.7333221193086221
[2019-03-23 12:00:43,981] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.0807068]
[2019-03-23 12:00:43,983] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.0, 96.0, 1.0, 2.0, 0.4198312511161901, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 477545.8031865921, 477545.8031865921, 129606.7228173712]
[2019-03-23 12:00:43,983] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 12:00:43,986] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.8956118e-30 1.0000000e+00 0.0000000e+00 2.9477808e-34 0.0000000e+00], sampled 0.7228276241480576
[2019-03-23 12:00:47,334] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 12:00:47,750] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.0807068]
[2019-03-23 12:00:47,752] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.46666666666667, 91.0, 1.0, 2.0, 0.5077435351172658, 0.0, 2.0, 0.0, 1.0, 1.0, 0.949000623841442, 6.94511023246047, 6.9112, 77.32837978447304, 1127863.252977299, 1116849.914973311, 253820.3881585383]
[2019-03-23 12:00:47,753] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 12:00:47,755] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.8956118e-30 1.0000000e+00 0.0000000e+00 2.9477808e-34 0.0000000e+00], sampled 0.7152072510075324
[2019-03-23 12:00:47,755] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1127863.252977299 W.
[2019-03-23 12:00:47,844] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 12:00:47,969] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 12:00:48,007] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 12:00:48,074] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 12:00:49,090] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 2225000, evaluation results [2225000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 12:00:49,133] A3C_AGENT_WORKER-Thread-11 INFO:Local step 139000, global step 2225029: loss 0.0205
[2019-03-23 12:00:49,136] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 139000, global step 2225029: learning rate 0.0005
[2019-03-23 12:00:49,206] A3C_AGENT_WORKER-Thread-20 INFO:Local step 139000, global step 2225065: loss 0.0126
[2019-03-23 12:00:49,215] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 139000, global step 2225067: learning rate 0.0005
[2019-03-23 12:00:49,556] A3C_AGENT_WORKER-Thread-14 INFO:Local step 139000, global step 2225236: loss 0.0269
[2019-03-23 12:00:49,558] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 139000, global step 2225237: learning rate 0.0005
[2019-03-23 12:00:49,750] A3C_AGENT_WORKER-Thread-15 INFO:Local step 139000, global step 2225334: loss 0.0357
[2019-03-23 12:00:49,753] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 139000, global step 2225335: learning rate 0.0005
[2019-03-23 12:00:50,015] A3C_AGENT_WORKER-Thread-17 INFO:Local step 139000, global step 2225472: loss 0.0272
[2019-03-23 12:00:50,020] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 139000, global step 2225472: learning rate 0.0005
[2019-03-23 12:00:50,292] A3C_AGENT_WORKER-Thread-13 INFO:Local step 139500, global step 2225610: loss 0.0082
[2019-03-23 12:00:50,293] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 139500, global step 2225612: learning rate 0.0005
[2019-03-23 12:00:50,440] A3C_AGENT_WORKER-Thread-16 INFO:Local step 139000, global step 2225683: loss 0.0663
[2019-03-23 12:00:50,444] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 139000, global step 2225685: learning rate 0.0005
[2019-03-23 12:00:50,708] A3C_AGENT_WORKER-Thread-18 INFO:Local step 139000, global step 2225819: loss 0.0130
[2019-03-23 12:00:50,714] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 139000, global step 2225821: learning rate 0.0005
[2019-03-23 12:00:51,105] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.4892278e-31 1.0000000e+00 0.0000000e+00 7.5055232e-32 0.0000000e+00], sum to 1.0000
[2019-03-23 12:00:51,112] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0760
[2019-03-23 12:00:51,121] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.33333333333334, 49.0, 1.0, 2.0, 0.3398903091271803, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 376586.4482494449, 376586.4482494446, 116678.366630983], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3951600.0000, 
sim time next is 3952200.0000, 
raw observation next is [24.16666666666666, 49.5, 1.0, 2.0, 0.3390163397341452, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 375290.150425946, 375290.1504259463, 116479.9730307644], 
processed observation next is [0.0, 0.7391304347826086, 0.7348484848484845, 0.495, 1.0, 1.0, 0.17377042466768147, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13899635200960964, 0.13899635200960975, 0.28409749519698635], 
reward next is 0.7159, 
noisyNet noise sample is [array([0.71230733], dtype=float32), -0.29054463]. 
=============================================
[2019-03-23 12:00:51,216] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.6175175e-25 1.0000000e+00 3.9723318e-36 3.2074287e-31 5.1792773e-36], sum to 1.0000
[2019-03-23 12:00:51,226] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1468
[2019-03-23 12:00:51,235] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.33333333333334, 49.0, 1.0, 2.0, 0.3398903091271803, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 376586.4482494449, 376586.4482494446, 116678.366630983], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3951600.0000, 
sim time next is 3952200.0000, 
raw observation next is [24.16666666666666, 49.5, 1.0, 2.0, 0.3390163397341452, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 375290.150425946, 375290.1504259463, 116479.9730307644], 
processed observation next is [0.0, 0.7391304347826086, 0.7348484848484845, 0.495, 1.0, 1.0, 0.17377042466768147, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13899635200960964, 0.13899635200960975, 0.28409749519698635], 
reward next is 0.7159, 
noisyNet noise sample is [array([0.00434608], dtype=float32), -0.015491267]. 
=============================================
[2019-03-23 12:00:54,462] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.6435765e-25 1.0000000e+00 2.2043765e-35 2.8481358e-31 8.4300473e-36], sum to 1.0000
[2019-03-23 12:00:54,470] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8186
[2019-03-23 12:00:54,476] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.66666666666667, 96.0, 1.0, 2.0, 0.5480557307414431, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 609773.604732649, 609773.604732649, 136212.5575316763], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4016400.0000, 
sim time next is 4017000.0000, 
raw observation next is [17.83333333333333, 95.0, 1.0, 2.0, 0.571151620649382, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 636174.4675829796, 636174.4675829796, 138912.0562819836], 
processed observation next is [1.0, 0.4782608695652174, 0.44696969696969674, 0.95, 1.0, 1.0, 0.4639395258117274, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23562017317888134, 0.23562017317888134, 0.3388098933706917], 
reward next is 0.6612, 
noisyNet noise sample is [array([-0.47987038], dtype=float32), 0.8201369]. 
=============================================
[2019-03-23 12:00:54,496] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[68.583855]
 [68.583855]
 [68.583855]
 [68.583855]
 [68.583855]], R is [[68.55921173]
 [68.54139709]
 [68.5364151 ]
 [68.5353241 ]
 [68.53566742]].
[2019-03-23 12:00:59,495] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.5599843e-25 1.0000000e+00 9.4043968e-36 5.3021393e-29 1.6279673e-36], sum to 1.0000
[2019-03-23 12:00:59,502] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7327
[2019-03-23 12:00:59,506] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333334, 83.33333333333334, 1.0, 2.0, 0.6283170086832588, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 709324.0597707562, 709324.0597707559, 149490.5556311172], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4095600.0000, 
sim time next is 4096200.0000, 
raw observation next is [20.66666666666666, 80.66666666666666, 1.0, 2.0, 0.6138051856021612, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 692782.3301771393, 692782.3301771393, 147663.7056236153], 
processed observation next is [1.0, 0.391304347826087, 0.5757575757575755, 0.8066666666666665, 1.0, 1.0, 0.5172564820027015, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2565860482137553, 0.2565860482137553, 0.36015537956979343], 
reward next is 0.6398, 
noisyNet noise sample is [array([-0.91452867], dtype=float32), -1.4510663]. 
=============================================
[2019-03-23 12:01:00,907] A3C_AGENT_WORKER-Thread-9 INFO:Local step 140000, global step 2230942: loss 0.0028
[2019-03-23 12:01:00,910] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 140000, global step 2230942: learning rate 0.0005
[2019-03-23 12:01:04,226] A3C_AGENT_WORKER-Thread-22 INFO:Local step 139500, global step 2232614: loss 0.0497
[2019-03-23 12:01:04,228] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 139500, global step 2232616: learning rate 0.0005
[2019-03-23 12:01:04,335] A3C_AGENT_WORKER-Thread-21 INFO:Local step 139500, global step 2232673: loss 0.0521
[2019-03-23 12:01:04,337] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 139500, global step 2232673: learning rate 0.0005
[2019-03-23 12:01:04,361] A3C_AGENT_WORKER-Thread-10 INFO:Local step 139500, global step 2232684: loss 0.0576
[2019-03-23 12:01:04,364] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 139500, global step 2232684: learning rate 0.0005
[2019-03-23 12:01:04,600] A3C_AGENT_WORKER-Thread-3 INFO:Local step 139500, global step 2232807: loss 0.0467
[2019-03-23 12:01:04,601] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 139500, global step 2232807: learning rate 0.0005
[2019-03-23 12:01:04,788] A3C_AGENT_WORKER-Thread-2 INFO:Local step 139500, global step 2232899: loss 0.0424
[2019-03-23 12:01:04,794] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 139500, global step 2232900: learning rate 0.0005
[2019-03-23 12:01:04,909] A3C_AGENT_WORKER-Thread-19 INFO:Local step 139500, global step 2232962: loss 0.0339
[2019-03-23 12:01:04,912] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 139500, global step 2232963: learning rate 0.0005
[2019-03-23 12:01:05,080] A3C_AGENT_WORKER-Thread-12 INFO:Local step 139500, global step 2233048: loss 0.0154
[2019-03-23 12:01:05,083] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 139500, global step 2233048: learning rate 0.0005
[2019-03-23 12:01:05,099] A3C_AGENT_WORKER-Thread-20 INFO:Local step 139500, global step 2233055: loss 0.0221
[2019-03-23 12:01:05,100] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 139500, global step 2233056: learning rate 0.0005
[2019-03-23 12:01:05,117] A3C_AGENT_WORKER-Thread-11 INFO:Local step 139500, global step 2233064: loss 0.0220
[2019-03-23 12:01:05,120] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 139500, global step 2233064: learning rate 0.0005
[2019-03-23 12:01:05,417] A3C_AGENT_WORKER-Thread-14 INFO:Local step 139500, global step 2233215: loss 0.0004
[2019-03-23 12:01:05,420] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 139500, global step 2233215: learning rate 0.0005
[2019-03-23 12:01:05,535] A3C_AGENT_WORKER-Thread-15 INFO:Local step 139500, global step 2233276: loss 0.0007
[2019-03-23 12:01:05,537] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 139500, global step 2233277: learning rate 0.0005
[2019-03-23 12:01:05,797] A3C_AGENT_WORKER-Thread-17 INFO:Local step 139500, global step 2233398: loss 0.0041
[2019-03-23 12:01:05,800] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 139500, global step 2233400: learning rate 0.0005
[2019-03-23 12:01:06,331] A3C_AGENT_WORKER-Thread-16 INFO:Local step 139500, global step 2233675: loss 0.0063
[2019-03-23 12:01:06,336] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 139500, global step 2233675: learning rate 0.0005
[2019-03-23 12:01:06,452] A3C_AGENT_WORKER-Thread-13 INFO:Local step 140000, global step 2233733: loss 0.0202
[2019-03-23 12:01:06,454] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 140000, global step 2233733: learning rate 0.0005
[2019-03-23 12:01:06,542] A3C_AGENT_WORKER-Thread-18 INFO:Local step 139500, global step 2233780: loss 0.0137
[2019-03-23 12:01:06,547] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 139500, global step 2233780: learning rate 0.0005
[2019-03-23 12:01:12,849] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.1499497e-28 1.0000000e+00 0.0000000e+00 2.0401329e-33 1.2642966e-38], sum to 1.0000
[2019-03-23 12:01:12,860] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0645
[2019-03-23 12:01:12,864] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 74.66666666666667, 1.0, 2.0, 0.4170836954112053, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 473440.8215607484, 473440.8215607487, 128522.818602985], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4738800.0000, 
sim time next is 4739400.0000, 
raw observation next is [22.0, 75.5, 1.0, 2.0, 0.4109997911643531, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 465888.201940909, 465888.201940909, 127476.618261315], 
processed observation next is [1.0, 0.8695652173913043, 0.6363636363636364, 0.755, 1.0, 1.0, 0.26374973895544135, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1725511859040404, 0.1725511859040404, 0.3109185811251585], 
reward next is 0.6891, 
noisyNet noise sample is [array([-0.292779], dtype=float32), 0.62940854]. 
=============================================
[2019-03-23 12:01:14,144] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.2537298e-27 1.0000000e+00 7.1098144e-36 4.3163163e-30 4.9067683e-35], sum to 1.0000
[2019-03-23 12:01:14,152] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3798
[2019-03-23 12:01:14,157] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.66666666666667, 92.0, 1.0, 2.0, 0.3766391310395173, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 421621.7667289701, 421621.7667289701, 121390.6721093046], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4764000.0000, 
sim time next is 4764600.0000, 
raw observation next is [18.5, 94.0, 1.0, 2.0, 0.372120939750711, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 416863.1667457073, 416863.166745707, 121149.3287977327], 
processed observation next is [1.0, 0.13043478260869565, 0.4772727272727273, 0.94, 1.0, 1.0, 0.2151511746883887, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15439376546137307, 0.15439376546137296, 0.29548616779934805], 
reward next is 0.7045, 
noisyNet noise sample is [array([-2.3248415], dtype=float32), -1.3102655]. 
=============================================
[2019-03-23 12:01:15,997] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.3604084e-28 1.0000000e+00 0.0000000e+00 2.2255624e-32 2.1218677e-37], sum to 1.0000
[2019-03-23 12:01:16,006] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5595
[2019-03-23 12:01:16,012] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 83.0, 1.0, 2.0, 0.4083378279742483, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 462733.0801397022, 462733.0801397025, 127132.6657980287], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4430400.0000, 
sim time next is 4431000.0000, 
raw observation next is [21.0, 83.0, 1.0, 2.0, 0.4087186382945818, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 463165.9880251599, 463165.9880251599, 127169.3618762332], 
processed observation next is [0.0, 0.2608695652173913, 0.5909090909090909, 0.83, 1.0, 1.0, 0.26089829786822727, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17154295852783702, 0.17154295852783702, 0.31016917530788585], 
reward next is 0.6898, 
noisyNet noise sample is [array([1.0817547], dtype=float32), 0.42518595]. 
=============================================
[2019-03-23 12:01:16,034] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[68.14762]
 [68.14762]
 [68.14762]
 [68.14762]
 [68.14762]], R is [[68.1559906 ]
 [68.16435242]
 [68.17272949]
 [68.18104553]
 [68.18929291]].
[2019-03-23 12:01:16,729] A3C_AGENT_WORKER-Thread-9 INFO:Local step 140500, global step 2238871: loss -67.0947
[2019-03-23 12:01:16,730] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 140500, global step 2238872: learning rate 0.0005
[2019-03-23 12:01:20,260] A3C_AGENT_WORKER-Thread-22 INFO:Local step 140000, global step 2240659: loss 0.0023
[2019-03-23 12:01:20,261] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 140000, global step 2240659: learning rate 0.0005
[2019-03-23 12:01:20,262] A3C_AGENT_WORKER-Thread-10 INFO:Local step 140000, global step 2240659: loss 0.0006
[2019-03-23 12:01:20,263] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 140000, global step 2240659: learning rate 0.0005
[2019-03-23 12:01:20,330] A3C_AGENT_WORKER-Thread-21 INFO:Local step 140000, global step 2240697: loss 0.0006
[2019-03-23 12:01:20,333] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 140000, global step 2240700: learning rate 0.0005
[2019-03-23 12:01:20,419] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.6267199e-29 1.0000000e+00 0.0000000e+00 6.9332708e-32 2.9962752e-38], sum to 1.0000
[2019-03-23 12:01:20,424] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8443
[2019-03-23 12:01:20,430] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.83333333333333, 78.83333333333333, 1.0, 2.0, 0.4986533458163162, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 568876.0260466185, 568876.0260466185, 141540.0152789013], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4471800.0000, 
sim time next is 4472400.0000, 
raw observation next is [23.66666666666666, 79.66666666666667, 1.0, 2.0, 0.4964667138804202, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 566412.6593348286, 566412.6593348286, 141196.7183185576], 
processed observation next is [0.0, 0.782608695652174, 0.7121212121212118, 0.7966666666666667, 1.0, 1.0, 0.3705833923505252, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2097824664203069, 0.2097824664203069, 0.34438223980136], 
reward next is 0.6556, 
noisyNet noise sample is [array([-0.99696887], dtype=float32), -0.42913494]. 
=============================================
[2019-03-23 12:01:20,511] A3C_AGENT_WORKER-Thread-3 INFO:Local step 140000, global step 2240788: loss 0.0149
[2019-03-23 12:01:20,514] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 140000, global step 2240788: learning rate 0.0005
[2019-03-23 12:01:20,723] A3C_AGENT_WORKER-Thread-2 INFO:Local step 140000, global step 2240893: loss 0.0016
[2019-03-23 12:01:20,724] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 140000, global step 2240893: learning rate 0.0005
[2019-03-23 12:01:20,839] A3C_AGENT_WORKER-Thread-19 INFO:Local step 140000, global step 2240955: loss 0.0027
[2019-03-23 12:01:20,840] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 140000, global step 2240955: learning rate 0.0005
[2019-03-23 12:01:20,926] A3C_AGENT_WORKER-Thread-20 INFO:Local step 140000, global step 2241000: loss 0.0017
[2019-03-23 12:01:20,927] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 140000, global step 2241000: learning rate 0.0005
[2019-03-23 12:01:20,990] A3C_AGENT_WORKER-Thread-11 INFO:Local step 140000, global step 2241031: loss 0.0008
[2019-03-23 12:01:20,993] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 140000, global step 2241034: learning rate 0.0005
[2019-03-23 12:01:21,024] A3C_AGENT_WORKER-Thread-12 INFO:Local step 140000, global step 2241049: loss 0.0065
[2019-03-23 12:01:21,026] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 140000, global step 2241049: learning rate 0.0005
[2019-03-23 12:01:21,434] A3C_AGENT_WORKER-Thread-15 INFO:Local step 140000, global step 2241257: loss 0.0008
[2019-03-23 12:01:21,435] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 140000, global step 2241257: learning rate 0.0005
[2019-03-23 12:01:21,482] A3C_AGENT_WORKER-Thread-14 INFO:Local step 140000, global step 2241282: loss 0.0009
[2019-03-23 12:01:21,484] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 140000, global step 2241282: learning rate 0.0005
[2019-03-23 12:01:21,778] A3C_AGENT_WORKER-Thread-17 INFO:Local step 140000, global step 2241436: loss 0.0151
[2019-03-23 12:01:21,781] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 140000, global step 2241436: learning rate 0.0005
[2019-03-23 12:01:22,291] A3C_AGENT_WORKER-Thread-13 INFO:Local step 140500, global step 2241697: loss -36.6026
[2019-03-23 12:01:22,293] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 140500, global step 2241697: learning rate 0.0005
[2019-03-23 12:01:22,356] A3C_AGENT_WORKER-Thread-16 INFO:Local step 140000, global step 2241727: loss 0.0099
[2019-03-23 12:01:22,361] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 140000, global step 2241728: learning rate 0.0005
[2019-03-23 12:01:22,485] A3C_AGENT_WORKER-Thread-18 INFO:Local step 140000, global step 2241789: loss 0.0042
[2019-03-23 12:01:22,489] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 140000, global step 2241791: learning rate 0.0005
[2019-03-23 12:01:24,060] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.4503754e-28 1.0000000e+00 0.0000000e+00 3.6668013e-31 0.0000000e+00], sum to 1.0000
[2019-03-23 12:01:24,066] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1078
[2019-03-23 12:01:24,072] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 82.0, 1.0, 2.0, 0.2743951199038175, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 297944.0516042239, 297944.0516042242, 95481.1869863673], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4579200.0000, 
sim time next is 4579800.0000, 
raw observation next is [16.83333333333334, 83.00000000000001, 1.0, 2.0, 0.2744181352719697, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 297969.0498357413, 297969.049835741, 94894.31921057339], 
processed observation next is [1.0, 0.0, 0.40151515151515177, 0.8300000000000002, 1.0, 1.0, 0.09302266908996208, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11035890734657085, 0.11035890734657074, 0.231449559050179], 
reward next is 0.7686, 
noisyNet noise sample is [array([-0.8031301], dtype=float32), -1.3320718]. 
=============================================
[2019-03-23 12:01:25,706] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.3589207e-29 1.0000000e+00 0.0000000e+00 4.2689229e-32 0.0000000e+00], sum to 1.0000
[2019-03-23 12:01:25,718] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1441
[2019-03-23 12:01:25,723] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.83333333333333, 95.0, 1.0, 2.0, 0.2497509547084188, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 271177.4331319206, 271177.4331319203, 85594.7251138538], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4590600.0000, 
sim time next is 4591200.0000, 
raw observation next is [14.66666666666667, 96.0, 1.0, 2.0, 0.2457946684061842, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 266880.5529820858, 266880.5529820861, 84719.42893956351], 
processed observation next is [1.0, 0.13043478260869565, 0.30303030303030315, 0.96, 1.0, 1.0, 0.057243335507730225, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09884464925262437, 0.09884464925262447, 0.20663275351113053], 
reward next is 0.7934, 
noisyNet noise sample is [array([-0.04830121], dtype=float32), -0.6277196]. 
=============================================
[2019-03-23 12:01:25,831] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.3628852e-29 1.0000000e+00 0.0000000e+00 2.2550610e-34 0.0000000e+00], sum to 1.0000
[2019-03-23 12:01:25,841] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1304
[2019-03-23 12:01:25,856] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.33333333333334, 86.0, 1.0, 2.0, 0.2634207300632081, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 286024.3218314349, 286024.3218314352, 91950.67283601486], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4605600.0000, 
sim time next is 4606200.0000, 
raw observation next is [16.5, 85.0, 1.0, 2.0, 0.2666122470022596, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 289490.7276559835, 289490.7276559838, 92839.97206304262], 
processed observation next is [1.0, 0.30434782608695654, 0.38636363636363635, 0.85, 1.0, 1.0, 0.0832653087528245, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10721878802073462, 0.10721878802073474, 0.22643895625132346], 
reward next is 0.7736, 
noisyNet noise sample is [array([-1.1677886], dtype=float32), -0.149989]. 
=============================================
[2019-03-23 12:01:32,558] A3C_AGENT_WORKER-Thread-9 INFO:Local step 141000, global step 2246966: loss 0.0015
[2019-03-23 12:01:32,561] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 141000, global step 2246966: learning rate 0.0005
[2019-03-23 12:01:34,131] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.6161433e-31 1.0000000e+00 0.0000000e+00 2.4451495e-33 0.0000000e+00], sum to 1.0000
[2019-03-23 12:01:34,139] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6642
[2019-03-23 12:01:34,144] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.16666666666666, 98.0, 1.0, 2.0, 0.3707550532045754, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 415890.4358423097, 415890.43584231, 121299.0799580641], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4765800.0000, 
sim time next is 4766400.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.372105236968091, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 417657.7477335338, 417657.7477335338, 121535.6141258447], 
processed observation next is [1.0, 0.17391304347826086, 0.45454545454545453, 1.0, 1.0, 1.0, 0.21513154621011374, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15468805471612362, 0.15468805471612362, 0.2964283271362066], 
reward next is 0.7036, 
noisyNet noise sample is [array([1.1245574], dtype=float32), -1.1694858]. 
=============================================
[2019-03-23 12:01:35,618] A3C_AGENT_WORKER-Thread-10 INFO:Local step 140500, global step 2248617: loss -44.9957
[2019-03-23 12:01:35,620] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 140500, global step 2248617: learning rate 0.0005
[2019-03-23 12:01:35,738] A3C_AGENT_WORKER-Thread-22 INFO:Local step 140500, global step 2248679: loss -30.3131
[2019-03-23 12:01:35,739] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 140500, global step 2248680: learning rate 0.0005
[2019-03-23 12:01:35,781] A3C_AGENT_WORKER-Thread-21 INFO:Local step 140500, global step 2248702: loss -40.9469
[2019-03-23 12:01:35,782] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 140500, global step 2248702: learning rate 0.0005
[2019-03-23 12:01:35,958] A3C_AGENT_WORKER-Thread-3 INFO:Local step 140500, global step 2248796: loss -18.6750
[2019-03-23 12:01:35,959] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 140500, global step 2248796: learning rate 0.0005
[2019-03-23 12:01:36,086] A3C_AGENT_WORKER-Thread-19 INFO:Local step 140500, global step 2248863: loss -59.7093
[2019-03-23 12:01:36,087] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 140500, global step 2248864: learning rate 0.0005
[2019-03-23 12:01:36,160] A3C_AGENT_WORKER-Thread-2 INFO:Local step 140500, global step 2248901: loss -26.0303
[2019-03-23 12:01:36,161] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 140500, global step 2248901: learning rate 0.0005
[2019-03-23 12:01:36,410] A3C_AGENT_WORKER-Thread-20 INFO:Local step 140500, global step 2249040: loss -34.8269
[2019-03-23 12:01:36,411] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 140500, global step 2249040: learning rate 0.0005
[2019-03-23 12:01:36,446] A3C_AGENT_WORKER-Thread-11 INFO:Local step 140500, global step 2249057: loss -33.7230
[2019-03-23 12:01:36,448] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 140500, global step 2249059: learning rate 0.0005
[2019-03-23 12:01:36,570] A3C_AGENT_WORKER-Thread-12 INFO:Local step 140500, global step 2249124: loss -21.8107
[2019-03-23 12:01:36,572] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 140500, global step 2249124: learning rate 0.0005
[2019-03-23 12:01:36,773] A3C_AGENT_WORKER-Thread-15 INFO:Local step 140500, global step 2249232: loss -31.8546
[2019-03-23 12:01:36,774] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 140500, global step 2249232: learning rate 0.0005
[2019-03-23 12:01:36,921] A3C_AGENT_WORKER-Thread-14 INFO:Local step 140500, global step 2249310: loss -33.1744
[2019-03-23 12:01:36,923] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 140500, global step 2249310: learning rate 0.0005
[2019-03-23 12:01:37,059] A3C_AGENT_WORKER-Thread-17 INFO:Local step 140500, global step 2249384: loss -61.3572
[2019-03-23 12:01:37,063] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 140500, global step 2249387: learning rate 0.0005
[2019-03-23 12:01:37,625] A3C_AGENT_WORKER-Thread-13 INFO:Local step 141000, global step 2249686: loss 0.0164
[2019-03-23 12:01:37,627] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 141000, global step 2249686: learning rate 0.0005
[2019-03-23 12:01:37,735] A3C_AGENT_WORKER-Thread-16 INFO:Local step 140500, global step 2249744: loss -37.2091
[2019-03-23 12:01:37,737] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 140500, global step 2249744: learning rate 0.0005
[2019-03-23 12:01:37,994] A3C_AGENT_WORKER-Thread-18 INFO:Local step 140500, global step 2249882: loss -63.4635
[2019-03-23 12:01:37,997] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 140500, global step 2249883: learning rate 0.0005
[2019-03-23 12:01:38,216] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-23 12:01:38,217] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 12:01:38,218] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 12:01:38,218] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:01:38,220] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 12:01:38,220] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 12:01:38,221] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:01:38,221] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 12:01:38,222] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:01:38,224] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:01:38,222] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:01:38,238] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run91
[2019-03-23 12:01:38,265] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run91
[2019-03-23 12:01:38,292] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run91
[2019-03-23 12:01:38,293] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run91
[2019-03-23 12:01:38,353] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run91
[2019-03-23 12:01:59,118] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.1124038]
[2019-03-23 12:01:59,119] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.61855150333334, 43.99095302000001, 1.0, 2.0, 0.3758085348606469, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 408074.4388548271, 408074.4388548267, 97686.4951681108]
[2019-03-23 12:01:59,119] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 12:01:59,122] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [8.2465203e-29 1.0000000e+00 0.0000000e+00 2.0570058e-32 0.0000000e+00], sampled 0.3282736200522661
[2019-03-23 12:02:09,447] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.1124038]
[2019-03-23 12:02:09,448] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.96730184, 78.55259746499999, 1.0, 2.0, 0.3377311887801721, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 371365.9136431533, 371365.9136431536, 119735.9821078169]
[2019-03-23 12:02:09,448] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 12:02:09,451] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [8.2465203e-29 1.0000000e+00 0.0000000e+00 2.0570058e-32 0.0000000e+00], sampled 0.642315212424057
[2019-03-23 12:02:27,231] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.1124038]
[2019-03-23 12:02:27,231] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [28.46666666666667, 54.5, 1.0, 2.0, 0.5200112813589972, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 592694.8605923855, 592694.8605923852, 149159.7252698496]
[2019-03-23 12:02:27,233] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 12:02:27,236] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [8.2465203e-29 1.0000000e+00 0.0000000e+00 2.0570058e-32 0.0000000e+00], sampled 0.18099348562413387
[2019-03-23 12:02:31,116] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.1124038]
[2019-03-23 12:02:31,119] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.81695716333333, 70.74248741166667, 1.0, 2.0, 0.4789018441319922, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 546402.7578317665, 546402.757831766, 142661.4182416528]
[2019-03-23 12:02:31,120] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 12:02:31,123] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [8.2465203e-29 1.0000000e+00 0.0000000e+00 2.0570058e-32 0.0000000e+00], sampled 0.8887567189066503
[2019-03-23 12:02:35,282] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.1124038]
[2019-03-23 12:02:35,283] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.0, 100.0, 1.0, 2.0, 0.4348517041375213, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 492995.6457677584, 492995.6457677584, 129815.7426434156]
[2019-03-23 12:02:35,284] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 12:02:35,286] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [8.2465203e-29 1.0000000e+00 0.0000000e+00 2.0570058e-32 0.0000000e+00], sampled 0.7888433116779067
[2019-03-23 12:02:46,841] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.1124038]
[2019-03-23 12:02:46,841] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.03333333333333, 58.0, 1.0, 2.0, 0.2671482993628398, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 290056.4557476285, 290056.4557476285, 96334.52153090254]
[2019-03-23 12:02:46,843] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 12:02:46,847] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [8.2465203e-29 1.0000000e+00 0.0000000e+00 2.0570058e-32 0.0000000e+00], sampled 0.839025067559252
[2019-03-23 12:02:47,754] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.1124038]
[2019-03-23 12:02:47,758] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [8.9, 89.33333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 131456.6506483555, 131456.6506483555, 55446.34579719703]
[2019-03-23 12:02:47,759] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 12:02:47,761] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [8.2465203e-29 1.0000000e+00 0.0000000e+00 2.0570058e-32 0.0000000e+00], sampled 0.36037490378991166
[2019-03-23 12:03:16,849] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 12:03:17,293] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 12:03:17,345] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 12:03:17,367] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 12:03:17,401] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 12:03:18,419] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 2250000, evaluation results [2250000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 12:03:23,648] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.1558008e-29 1.0000000e+00 0.0000000e+00 4.6769766e-38 0.0000000e+00], sum to 1.0000
[2019-03-23 12:03:23,658] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8196
[2019-03-23 12:03:23,668] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.66666666666667, 96.0, 1.0, 2.0, 0.3883494562087395, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 437259.0299480187, 437259.0299480187, 123616.1909732122], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4920000.0000, 
sim time next is 4920600.0000, 
raw observation next is [18.33333333333333, 98.0, 1.0, 2.0, 0.3846937479730377, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 432624.0662360684, 432624.0662360684, 123027.1426898832], 
processed observation next is [1.0, 0.9565217391304348, 0.4696969696969695, 0.98, 1.0, 1.0, 0.23086718496629707, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1602311356429883, 0.1602311356429883, 0.300066201682642], 
reward next is 0.6999, 
noisyNet noise sample is [array([0.595019], dtype=float32), 0.34745583]. 
=============================================
[2019-03-23 12:03:28,011] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.9170598e-29 1.0000000e+00 0.0000000e+00 2.4904266e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 12:03:28,018] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4442
[2019-03-23 12:03:28,023] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.2038986582432275, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 221380.0747388062, 221380.0747388059, 74051.74221391353], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5031600.0000, 
sim time next is 5032200.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.2033371395274445, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 220770.275404753, 220770.2754047533, 73989.70523655422], 
processed observation next is [0.0, 0.21739130434782608, 0.22727272727272727, 1.0, 1.0, 1.0, 0.004171424409305617, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08176676866842704, 0.08176676866842715, 0.18046269569891274], 
reward next is 0.8195, 
noisyNet noise sample is [array([0.2783431], dtype=float32), 0.2787445]. 
=============================================
[2019-03-23 12:03:28,672] A3C_AGENT_WORKER-Thread-9 INFO:Local step 141500, global step 2255175: loss -144.1493
[2019-03-23 12:03:28,675] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 141500, global step 2255175: learning rate 0.0005
[2019-03-23 12:03:31,445] A3C_AGENT_WORKER-Thread-10 INFO:Local step 141000, global step 2256594: loss 0.0063
[2019-03-23 12:03:31,448] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 141000, global step 2256595: learning rate 0.0005
[2019-03-23 12:03:31,502] A3C_AGENT_WORKER-Thread-22 INFO:Local step 141000, global step 2256622: loss 0.0002
[2019-03-23 12:03:31,504] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 141000, global step 2256622: learning rate 0.0005
[2019-03-23 12:03:31,590] A3C_AGENT_WORKER-Thread-21 INFO:Local step 141000, global step 2256665: loss 0.0047
[2019-03-23 12:03:31,594] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 141000, global step 2256666: learning rate 0.0005
[2019-03-23 12:03:32,005] A3C_AGENT_WORKER-Thread-3 INFO:Local step 141000, global step 2256826: loss 0.0080
[2019-03-23 12:03:32,009] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 141000, global step 2256826: learning rate 0.0005
[2019-03-23 12:03:32,048] A3C_AGENT_WORKER-Thread-19 INFO:Local step 141000, global step 2256844: loss 0.0120
[2019-03-23 12:03:32,049] A3C_AGENT_WORKER-Thread-2 INFO:Local step 141000, global step 2256844: loss 0.0113
[2019-03-23 12:03:32,050] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 141000, global step 2256844: learning rate 0.0005
[2019-03-23 12:03:32,053] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 141000, global step 2256846: learning rate 0.0005
[2019-03-23 12:03:32,281] A3C_AGENT_WORKER-Thread-20 INFO:Local step 141000, global step 2256961: loss 0.0027
[2019-03-23 12:03:32,283] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 141000, global step 2256961: learning rate 0.0005
[2019-03-23 12:03:32,505] A3C_AGENT_WORKER-Thread-12 INFO:Local step 141000, global step 2257078: loss 0.0036
[2019-03-23 12:03:32,513] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 141000, global step 2257080: learning rate 0.0005
[2019-03-23 12:03:32,541] A3C_AGENT_WORKER-Thread-11 INFO:Local step 141000, global step 2257095: loss 0.0031
[2019-03-23 12:03:32,544] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 141000, global step 2257095: learning rate 0.0005
[2019-03-23 12:03:32,750] A3C_AGENT_WORKER-Thread-15 INFO:Local step 141000, global step 2257196: loss 0.0093
[2019-03-23 12:03:32,751] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 141000, global step 2257197: learning rate 0.0005
[2019-03-23 12:03:32,877] A3C_AGENT_WORKER-Thread-14 INFO:Local step 141000, global step 2257260: loss 0.0015
[2019-03-23 12:03:32,880] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 141000, global step 2257261: learning rate 0.0005
[2019-03-23 12:03:33,168] A3C_AGENT_WORKER-Thread-17 INFO:Local step 141000, global step 2257407: loss 0.0111
[2019-03-23 12:03:33,170] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 141000, global step 2257408: learning rate 0.0005
[2019-03-23 12:03:33,709] A3C_AGENT_WORKER-Thread-16 INFO:Local step 141000, global step 2257672: loss 0.0095
[2019-03-23 12:03:33,712] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 141000, global step 2257674: learning rate 0.0005
[2019-03-23 12:03:33,966] A3C_AGENT_WORKER-Thread-18 INFO:Local step 141000, global step 2257807: loss 0.0211
[2019-03-23 12:03:33,967] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 141000, global step 2257808: learning rate 0.0005
[2019-03-23 12:03:34,022] A3C_AGENT_WORKER-Thread-13 INFO:Local step 141500, global step 2257834: loss -103.7183
[2019-03-23 12:03:34,024] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 141500, global step 2257834: learning rate 0.0005
[2019-03-23 12:03:35,403] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.3736774e-30 1.0000000e+00 0.0000000e+00 8.3130395e-36 0.0000000e+00], sum to 1.0000
[2019-03-23 12:03:35,408] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3980
[2019-03-23 12:03:35,416] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 78.0, 1.0, 2.0, 0.4588233498149162, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 523258.6840499657, 523258.6840499657, 135207.232910274], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5169600.0000, 
sim time next is 5170200.0000, 
raw observation next is [23.0, 78.83333333333333, 1.0, 2.0, 0.4572148710208191, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 521469.4887757197, 521469.4887757197, 135132.776327505], 
processed observation next is [0.0, 0.8695652173913043, 0.6818181818181818, 0.7883333333333333, 1.0, 1.0, 0.32151858877602385, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.193136847694711, 0.193136847694711, 0.32959213738415855], 
reward next is 0.6704, 
noisyNet noise sample is [array([0.8622037], dtype=float32), 0.21881305]. 
=============================================
[2019-03-23 12:03:38,235] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.3088382e-26 1.0000000e+00 7.7854295e-37 2.3252850e-28 2.2728666e-36], sum to 1.0000
[2019-03-23 12:03:38,251] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2897
[2019-03-23 12:03:38,259] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1104171.64359919 W.
[2019-03-23 12:03:38,263] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.3241988454492085, 1.0, 1.0, 0.3241988454492085, 1.0, 2.0, 0.6567008466288422, 6.911199999999999, 6.9112, 77.3421103, 1104171.64359919, 1104171.64359919, 269497.6431628442], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5236200.0000, 
sim time next is 5236800.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.4369000661806277, 0.0, 1.0, 0.0, 1.0, 2.0, 0.8847184425029978, 6.911200000000001, 6.9112, 77.32846326017426, 995128.8202274395, 995128.8202274392, 240196.4377237524], 
processed observation next is [1.0, 0.6086956521739131, 0.6363636363636364, 0.94, 1.0, 1.0, 0.2961250827257846, 0.0, 0.5, -0.25, 1.0, 1.0, 0.8353120607185684, 8.881784197001253e-17, 0.0, 0.5084288117150314, 0.3685662297138665, 0.3685662297138664, 0.5858449700579327], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.0367547], dtype=float32), -0.049175616]. 
=============================================
[2019-03-23 12:03:39,321] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.1271203e-25 1.0000000e+00 4.1171865e-35 5.5762870e-26 1.5631744e-33], sum to 1.0000
[2019-03-23 12:03:39,329] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9485
[2019-03-23 12:03:39,333] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 89.0, 1.0, 2.0, 0.6411453551456632, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 730393.6237119467, 730393.6237119467, 155731.1597524581], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5219400.0000, 
sim time next is 5220000.0000, 
raw observation next is [21.0, 88.0, 1.0, 2.0, 0.688761350092282, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 784320.7522178248, 784320.752217825, 161733.3169402636], 
processed observation next is [1.0, 0.43478260869565216, 0.5909090909090909, 0.88, 1.0, 1.0, 0.6109516876153525, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.29048916748808323, 0.29048916748808334, 0.39447150473235026], 
reward next is 0.6055, 
noisyNet noise sample is [array([0.99858665], dtype=float32), 0.49985513]. 
=============================================
[2019-03-23 12:03:39,350] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[53.872467]
 [53.872467]
 [53.872467]
 [53.872467]
 [53.872467]], R is [[53.93927383]
 [54.02005005]
 [54.09556961]
 [54.16208267]
 [54.2272377 ]].
[2019-03-23 12:03:39,535] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.3887384e-25 1.0000000e+00 6.5473979e-35 3.3523560e-30 1.1429276e-33], sum to 1.0000
[2019-03-23 12:03:39,542] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7286
[2019-03-23 12:03:39,547] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 98.0, 1.0, 2.0, 0.8126797464545317, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 927692.6933182242, 927692.6933182242, 184310.1183163085], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5223000.0000, 
sim time next is 5223600.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.8308143683906011, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 948240.7515010262, 948240.7515010262, 188126.5201181379], 
processed observation next is [1.0, 0.4782608695652174, 0.5909090909090909, 1.0, 1.0, 1.0, 0.7885179604882514, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3512002783337134, 0.3512002783337134, 0.45884517101984856], 
reward next is 0.5412, 
noisyNet noise sample is [array([0.7924887], dtype=float32), -0.3400141]. 
=============================================
[2019-03-23 12:03:44,903] A3C_AGENT_WORKER-Thread-9 INFO:Local step 142000, global step 2263312: loss 4.4549
[2019-03-23 12:03:44,906] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 142000, global step 2263313: learning rate 0.0005
[2019-03-23 12:03:47,530] A3C_AGENT_WORKER-Thread-21 INFO:Local step 141500, global step 2264640: loss -118.7455
[2019-03-23 12:03:47,532] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 141500, global step 2264641: learning rate 0.0005
[2019-03-23 12:03:47,603] A3C_AGENT_WORKER-Thread-10 INFO:Local step 141500, global step 2264680: loss -133.3930
[2019-03-23 12:03:47,604] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 141500, global step 2264680: learning rate 0.0005
[2019-03-23 12:03:47,649] A3C_AGENT_WORKER-Thread-22 INFO:Local step 141500, global step 2264700: loss -116.9051
[2019-03-23 12:03:47,651] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 141500, global step 2264700: learning rate 0.0005
[2019-03-23 12:03:48,014] A3C_AGENT_WORKER-Thread-19 INFO:Local step 141500, global step 2264883: loss -137.7771
[2019-03-23 12:03:48,016] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 141500, global step 2264883: learning rate 0.0005
[2019-03-23 12:03:48,028] A3C_AGENT_WORKER-Thread-3 INFO:Local step 141500, global step 2264892: loss -140.6721
[2019-03-23 12:03:48,030] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 141500, global step 2264892: learning rate 0.0005
[2019-03-23 12:03:48,063] A3C_AGENT_WORKER-Thread-2 INFO:Local step 141500, global step 2264908: loss -119.0656
[2019-03-23 12:03:48,066] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 141500, global step 2264908: learning rate 0.0005
[2019-03-23 12:03:48,257] A3C_AGENT_WORKER-Thread-12 INFO:Local step 141500, global step 2265000: loss -67.3347
[2019-03-23 12:03:48,259] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 141500, global step 2265000: learning rate 0.0005
[2019-03-23 12:03:48,288] A3C_AGENT_WORKER-Thread-20 INFO:Local step 141500, global step 2265014: loss -80.2191
[2019-03-23 12:03:48,291] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 141500, global step 2265015: learning rate 0.0005
[2019-03-23 12:03:48,410] A3C_AGENT_WORKER-Thread-11 INFO:Local step 141500, global step 2265075: loss -124.7767
[2019-03-23 12:03:48,411] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 141500, global step 2265075: learning rate 0.0005
[2019-03-23 12:03:48,691] A3C_AGENT_WORKER-Thread-15 INFO:Local step 141500, global step 2265220: loss -75.8331
[2019-03-23 12:03:48,695] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 141500, global step 2265221: learning rate 0.0005
[2019-03-23 12:03:48,717] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.6162132e-24 1.0000000e+00 1.6468896e-33 2.6806527e-24 3.9861667e-33], sum to 1.0000
[2019-03-23 12:03:48,724] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6583
[2019-03-23 12:03:48,729] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 93.0, 1.0, 2.0, 0.4011768618370383, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 453295.7035078321, 453295.7035078324, 125634.2256420182], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5425200.0000, 
sim time next is 5425800.0000, 
raw observation next is [19.3, 93.66666666666666, 1.0, 2.0, 0.4006218562699932, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 452601.3137815783, 452601.3137815783, 125544.1344724193], 
processed observation next is [1.0, 0.8260869565217391, 0.5136363636363637, 0.9366666666666665, 1.0, 1.0, 0.25077732033749145, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1676301162153994, 0.1676301162153994, 0.306205206030291], 
reward next is 0.6938, 
noisyNet noise sample is [array([-0.5701599], dtype=float32), 0.3826082]. 
=============================================
[2019-03-23 12:03:48,792] A3C_AGENT_WORKER-Thread-14 INFO:Local step 141500, global step 2265271: loss -92.1878
[2019-03-23 12:03:48,798] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 141500, global step 2265273: learning rate 0.0005
[2019-03-23 12:03:49,002] A3C_AGENT_WORKER-Thread-17 INFO:Local step 141500, global step 2265379: loss -130.2637
[2019-03-23 12:03:49,005] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 141500, global step 2265380: learning rate 0.0005
[2019-03-23 12:03:49,654] A3C_AGENT_WORKER-Thread-16 INFO:Local step 141500, global step 2265709: loss -77.7803
[2019-03-23 12:03:49,661] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 141500, global step 2265709: learning rate 0.0005
[2019-03-23 12:03:49,710] A3C_AGENT_WORKER-Thread-18 INFO:Local step 141500, global step 2265731: loss -118.8102
[2019-03-23 12:03:49,713] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 141500, global step 2265732: learning rate 0.0005
[2019-03-23 12:03:49,963] A3C_AGENT_WORKER-Thread-13 INFO:Local step 142000, global step 2265864: loss 6.0694
[2019-03-23 12:03:49,973] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 142000, global step 2265865: learning rate 0.0005
[2019-03-23 12:03:52,017] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.0090076e-26 1.0000000e+00 5.4410984e-38 4.5104343e-30 2.9908165e-38], sum to 1.0000
[2019-03-23 12:03:52,023] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4877
[2019-03-23 12:03:52,029] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1310754.145379662 W.
[2019-03-23 12:03:52,036] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.0, 69.5, 1.0, 2.0, 0.3866726626982229, 1.0, 1.0, 0.3866726626982229, 1.0, 2.0, 0.7823946789877688, 6.911199999999999, 6.9112, 77.3421103, 1310754.145379662, 1310754.145379663, 298480.4506226834], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5487000.0000, 
sim time next is 5487600.0000, 
raw observation next is [25.9, 70.0, 1.0, 2.0, 0.5701316442096903, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9777547606520688, 6.9112, 6.9112, 77.32846344354104, 1195676.586975961, 1195676.586975961, 273794.2013141867], 
processed observation next is [1.0, 0.5217391304347826, 0.8136363636363636, 0.7, 1.0, 1.0, 0.46266455526211286, 0.0, 0.5, -0.25, 1.0, 1.0, 0.9682210866458127, 0.0, 0.0, 0.5084288129206541, 0.442843180361467, 0.442843180361467, 0.6677907349126504], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.7356259], dtype=float32), -0.31526008]. 
=============================================
[2019-03-23 12:03:53,224] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.1962353e-24 1.0000000e+00 8.3381023e-35 2.2470142e-27 1.6919750e-33], sum to 1.0000
[2019-03-23 12:03:53,230] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3907
[2019-03-23 12:03:53,238] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1521294.377003969 W.
[2019-03-23 12:03:53,242] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.8, 69.0, 1.0, 2.0, 0.6763577626841274, 1.0, 1.0, 0.6763577626841274, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354003, 1521294.377003969, 1521294.377003969, 284437.0436624141], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5494800.0000, 
sim time next is 5495400.0000, 
raw observation next is [26.9, 69.0, 1.0, 2.0, 0.8710963164520562, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9825261931046467, 6.911200000000001, 6.9112, 77.32846344354104, 1531628.940571917, 1531628.940571917, 325520.855393633], 
processed observation next is [1.0, 0.6086956521739131, 0.859090909090909, 0.69, 1.0, 1.0, 0.8388703955650703, 0.0, 0.5, -0.25, 1.0, 0.5, 0.9750374187209239, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.5672699779895989, 0.5672699779895989, 0.7939533058381293], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.25505674], dtype=float32), -0.9892472]. 
=============================================
[2019-03-23 12:03:55,818] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.1903899e-30 1.0000000e+00 0.0000000e+00 1.0076862e-36 0.0000000e+00], sum to 1.0000
[2019-03-23 12:03:55,826] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2056
[2019-03-23 12:03:55,833] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 80.0, 1.0, 2.0, 0.6885634090063295, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 785805.5151232829, 785805.5151232831, 164429.4259385933], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5560200.0000, 
sim time next is 5560800.0000, 
raw observation next is [23.26666666666667, 78.66666666666667, 1.0, 2.0, 0.850940807477097, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 971389.2098080979, 971389.2098080983, 189773.5946625015], 
processed observation next is [1.0, 0.34782608695652173, 0.6939393939393941, 0.7866666666666667, 1.0, 1.0, 0.8136760093463713, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3597737814104066, 0.3597737814104068, 0.4628624260061012], 
reward next is 0.5371, 
noisyNet noise sample is [array([-1.1712115], dtype=float32), 0.6481168]. 
=============================================
[2019-03-23 12:03:56,329] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.3797079e-29 1.0000000e+00 0.0000000e+00 6.0382764e-30 0.0000000e+00], sum to 1.0000
[2019-03-23 12:03:56,342] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9552
[2019-03-23 12:03:56,348] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.26666666666667, 78.66666666666667, 1.0, 2.0, 0.850940807477097, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 971389.2098080979, 971389.2098080983, 189773.5946625015], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5560800.0000, 
sim time next is 5561400.0000, 
raw observation next is [23.53333333333333, 77.33333333333333, 1.0, 2.0, 0.9315337986663634, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1063517.00779025, 1063517.00779025, 204065.8748546948], 
processed observation next is [1.0, 0.34782608695652173, 0.7060606060606059, 0.7733333333333333, 1.0, 1.0, 0.9144172483329543, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.393895188070463, 0.393895188070463, 0.4977216459870605], 
reward next is 0.5023, 
noisyNet noise sample is [array([0.7650552], dtype=float32), 1.7297528]. 
=============================================
[2019-03-23 12:03:56,970] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.3497214e-26 1.0000000e+00 1.9201973e-37 6.7036215e-32 4.9706290e-37], sum to 1.0000
[2019-03-23 12:03:56,982] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6082
[2019-03-23 12:03:56,988] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1458015.591991488 W.
[2019-03-23 12:03:56,990] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.8, 55.0, 1.0, 2.0, 0.4317439994884029, 1.0, 2.0, 0.4317439994884029, 1.0, 1.0, 0.8723209158028313, 6.911199999999999, 6.9112, 77.3421103, 1458015.591991488, 1458015.591991489, 321936.3672744035], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5580000.0000, 
sim time next is 5580600.0000, 
raw observation next is [28.71666666666667, 55.0, 1.0, 2.0, 0.7144967642917763, 1.0, 2.0, 0.7144967642917763, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 81.12564115924465, 1610591.126318184, 1610591.126318184, 298159.8032664543], 
processed observation next is [1.0, 0.6086956521739131, 0.9416666666666668, 0.55, 1.0, 1.0, 0.6431209553647205, 1.0, 1.0, 0.6431209553647205, 0.0, 0.5, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5333949699147539, 0.5965152319696978, 0.5965152319696978, 0.7272190323572056], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2303919], dtype=float32), -0.27226865]. 
=============================================
[2019-03-23 12:03:57,389] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.8078191e-23 1.0000000e+00 1.0203837e-32 8.9671452e-26 1.6433518e-31], sum to 1.0000
[2019-03-23 12:03:57,395] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8158
[2019-03-23 12:03:57,400] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1513473.7446746 W.
[2019-03-23 12:03:57,404] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.01666666666667, 55.5, 1.0, 2.0, 0.6677022458325031, 1.0, 2.0, 0.6677022458325031, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1513473.7446746, 1513473.7446746, 278747.212091567], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5590200.0000, 
sim time next is 5590800.0000, 
raw observation next is [28.3, 55.0, 1.0, 2.0, 0.6929601185245612, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9759084089416823, 6.9112, 6.9112, 77.32846344354104, 1336786.42925301, 1336786.42925301, 289720.3070551199], 
processed observation next is [1.0, 0.7391304347826086, 0.9227272727272727, 0.55, 1.0, 1.0, 0.6162001481557015, 0.0, 0.5, -0.25, 1.0, 0.5, 0.9655834413452604, 0.0, 0.0, 0.5084288129206541, 0.49510608490852226, 0.49510608490852226, 0.70663489525639], 
reward next is 0.2934, 
noisyNet noise sample is [array([0.8604479], dtype=float32), 0.28087145]. 
=============================================
[2019-03-23 12:03:58,269] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.4175235e-25 1.0000000e+00 6.5837427e-34 1.0320447e-26 7.7328191e-33], sum to 1.0000
[2019-03-23 12:03:58,274] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1988
[2019-03-23 12:03:58,278] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.8, 93.0, 1.0, 2.0, 0.4172552056339279, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 473109.8003643103, 473109.8003643103, 128160.2138668923], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5602800.0000, 
sim time next is 5603400.0000, 
raw observation next is [19.7, 93.0, 1.0, 2.0, 0.4144138162320055, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 469541.2788616049, 469541.2788616049, 127654.0708251983], 
processed observation next is [1.0, 0.8695652173913043, 0.5318181818181817, 0.93, 1.0, 1.0, 0.2680172702900069, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17390417735614996, 0.17390417735614996, 0.3113513922565812], 
reward next is 0.6886, 
noisyNet noise sample is [array([-1.0385193], dtype=float32), -1.157107]. 
=============================================
[2019-03-23 12:03:59,099] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.7557197e-31 1.0000000e+00 0.0000000e+00 1.3589431e-34 0.0000000e+00], sum to 1.0000
[2019-03-23 12:03:59,104] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7693
[2019-03-23 12:03:59,110] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.2, 96.33333333333333, 1.0, 2.0, 0.4035502777978255, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 456784.9907222936, 456784.9907222939, 126342.5885597562], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5628000.0000, 
sim time next is 5628600.0000, 
raw observation next is [19.1, 96.5, 1.0, 2.0, 0.4004478761343627, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 452963.2394714696, 452963.2394714699, 125862.0675320908], 
processed observation next is [0.0, 0.13043478260869565, 0.5045454545454546, 0.965, 1.0, 1.0, 0.2505598451679534, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16776416276721096, 0.16776416276721107, 0.30698065251729467], 
reward next is 0.6930, 
noisyNet noise sample is [array([1.9709549], dtype=float32), 1.1438658]. 
=============================================
[2019-03-23 12:04:00,229] A3C_AGENT_WORKER-Thread-9 INFO:Local step 142500, global step 2271019: loss -83.0047
[2019-03-23 12:04:00,235] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 142500, global step 2271019: learning rate 0.0005
[2019-03-23 12:04:03,346] A3C_AGENT_WORKER-Thread-21 INFO:Local step 142000, global step 2272664: loss 7.6580
[2019-03-23 12:04:03,350] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 142000, global step 2272666: learning rate 0.0005
[2019-03-23 12:04:03,360] A3C_AGENT_WORKER-Thread-22 INFO:Local step 142000, global step 2272671: loss 7.6553
[2019-03-23 12:04:03,365] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 142000, global step 2272673: learning rate 0.0005
[2019-03-23 12:04:03,412] A3C_AGENT_WORKER-Thread-19 INFO:Local step 142000, global step 2272694: loss 7.7403
[2019-03-23 12:04:03,414] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 142000, global step 2272695: learning rate 0.0005
[2019-03-23 12:04:03,621] A3C_AGENT_WORKER-Thread-3 INFO:Local step 142000, global step 2272813: loss 7.1756
[2019-03-23 12:04:03,624] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 142000, global step 2272813: learning rate 0.0005
[2019-03-23 12:04:03,660] A3C_AGENT_WORKER-Thread-10 INFO:Local step 142000, global step 2272830: loss 7.0823
[2019-03-23 12:04:03,662] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 142000, global step 2272830: learning rate 0.0005
[2019-03-23 12:04:03,782] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.8927526e-28 1.0000000e+00 0.0000000e+00 2.0073021e-32 1.3024960e-37], sum to 1.0000
[2019-03-23 12:04:03,789] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0796
[2019-03-23 12:04:03,793] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [8.8, 90.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 129994.9818127729, 129994.9818127729, 55257.28753502027], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5720400.0000, 
sim time next is 5721000.0000, 
raw observation next is [8.8, 91.16666666666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 129943.0231359597, 129943.02313596, 55242.02749239385], 
processed observation next is [0.0, 0.21739130434782608, 0.0363636363636364, 0.9116666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.048127045605910995, 0.04812704560591111, 0.1347366524204728], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.12725525], dtype=float32), -0.066748634]. 
=============================================
[2019-03-23 12:04:03,805] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[70.095375]
 [70.095375]
 [70.095375]
 [70.095375]
 [70.095375]], R is [[69.39442444]
 [68.7004776 ]
 [68.01347351]
 [67.33333588]
 [66.66000366]].
[2019-03-23 12:04:03,880] A3C_AGENT_WORKER-Thread-2 INFO:Local step 142000, global step 2272943: loss 6.5289
[2019-03-23 12:04:03,882] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 142000, global step 2272943: learning rate 0.0005
[2019-03-23 12:04:03,923] A3C_AGENT_WORKER-Thread-20 INFO:Local step 142000, global step 2272966: loss 6.3760
[2019-03-23 12:04:03,926] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 142000, global step 2272966: learning rate 0.0005
[2019-03-23 12:04:04,022] A3C_AGENT_WORKER-Thread-11 INFO:Local step 142000, global step 2273018: loss 5.9561
[2019-03-23 12:04:04,024] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 142000, global step 2273018: learning rate 0.0005
[2019-03-23 12:04:04,193] A3C_AGENT_WORKER-Thread-12 INFO:Local step 142000, global step 2273108: loss 5.7426
[2019-03-23 12:04:04,195] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 142000, global step 2273109: learning rate 0.0005
[2019-03-23 12:04:04,535] A3C_AGENT_WORKER-Thread-14 INFO:Local step 142000, global step 2273288: loss 4.5181
[2019-03-23 12:04:04,537] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 142000, global step 2273289: learning rate 0.0005
[2019-03-23 12:04:04,621] A3C_AGENT_WORKER-Thread-15 INFO:Local step 142000, global step 2273336: loss 4.4174
[2019-03-23 12:04:04,624] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 142000, global step 2273336: learning rate 0.0005
[2019-03-23 12:04:04,706] A3C_AGENT_WORKER-Thread-17 INFO:Local step 142000, global step 2273375: loss 4.0501
[2019-03-23 12:04:04,707] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 142000, global step 2273375: learning rate 0.0005
[2019-03-23 12:04:05,066] A3C_AGENT_WORKER-Thread-13 INFO:Local step 142500, global step 2273574: loss -24.5942
[2019-03-23 12:04:05,068] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 142500, global step 2273574: learning rate 0.0005
[2019-03-23 12:04:05,264] A3C_AGENT_WORKER-Thread-18 INFO:Local step 142000, global step 2273675: loss 3.2591
[2019-03-23 12:04:05,266] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 142000, global step 2273676: learning rate 0.0005
[2019-03-23 12:04:05,337] A3C_AGENT_WORKER-Thread-16 INFO:Local step 142000, global step 2273711: loss 3.1647
[2019-03-23 12:04:05,339] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 142000, global step 2273711: learning rate 0.0005
[2019-03-23 12:04:07,351] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.5215186e-31 1.0000000e+00 0.0000000e+00 8.2103707e-34 0.0000000e+00], sum to 1.0000
[2019-03-23 12:04:07,359] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3563
[2019-03-23 12:04:07,363] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.3, 57.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 186574.8604285601, 186574.8604285601, 62662.63111150919], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5792400.0000, 
sim time next is 5793000.0000, 
raw observation next is [13.3, 61.33333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 185126.3252505167, 185126.3252505164, 62694.54799983211], 
processed observation next is [1.0, 0.043478260869565216, 0.24090909090909093, 0.6133333333333333, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.06856530564833951, 0.06856530564833942, 0.15291353170690758], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.24195565], dtype=float32), -0.9874471]. 
=============================================
[2019-03-23 12:04:07,384] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[80.334946]
 [80.334946]
 [80.334946]
 [80.334946]
 [80.334946]], R is [[79.53158569]
 [78.73626709]
 [77.94890594]
 [77.16941833]
 [76.39772797]].
[2019-03-23 12:04:07,839] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 12:04:07,840] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 12:04:07,841] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 12:04:07,842] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:04:07,844] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:04:07,846] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 12:04:07,848] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 12:04:07,856] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:04:07,843] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 12:04:07,856] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:04:07,858] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:04:07,882] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run92
[2019-03-23 12:04:07,907] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run92
[2019-03-23 12:04:07,908] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run92
[2019-03-23 12:04:07,944] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run92
[2019-03-23 12:04:07,997] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run92
[2019-03-23 12:04:10,263] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.1336884]
[2019-03-23 12:04:10,264] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [15.33333333333333, 78.66666666666666, 1.0, 2.0, 0.2186696685171813, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 237421.4036421941, 237421.4036421943, 75965.70555085423]
[2019-03-23 12:04:10,265] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 12:04:10,269] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.6465143e-31 1.0000000e+00 0.0000000e+00 1.8617741e-35 0.0000000e+00], sampled 0.3109409430294964
[2019-03-23 12:04:19,359] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.1336884]
[2019-03-23 12:04:19,359] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.2, 64.0, 1.0, 2.0, 0.3599099122326679, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 401619.6626042726, 401619.6626042726, 123740.672452913]
[2019-03-23 12:04:19,360] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 12:04:19,363] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.6465143e-31 1.0000000e+00 0.0000000e+00 1.8617741e-35 0.0000000e+00], sampled 0.9327977393100386
[2019-03-23 12:04:24,090] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.1336884]
[2019-03-23 12:04:24,091] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [23.0237054, 88.65858302, 1.0, 2.0, 0.7955424649259851, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 95.55333581345177, 905546.865635162, 905546.865635162, 189391.7501552862]
[2019-03-23 12:04:24,091] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 12:04:24,095] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.6465143e-31 1.0000000e+00 0.0000000e+00 1.8617741e-35 0.0000000e+00], sampled 0.6862165391310955
[2019-03-23 12:04:26,439] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.1336884]
[2019-03-23 12:04:26,439] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.5, 87.5, 1.0, 2.0, 0.4973175183384962, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 564073.6207572012, 564073.6207572009, 140709.475115308]
[2019-03-23 12:04:26,440] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 12:04:26,444] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.6465143e-31 1.0000000e+00 0.0000000e+00 1.8617741e-35 0.0000000e+00], sampled 0.05199404794114826
[2019-03-23 12:04:26,994] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.1336884]
[2019-03-23 12:04:26,995] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [25.52049984, 64.50403651, 1.0, 2.0, 0.467488503053169, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 533370.3240418578, 533370.3240418575, 141348.1067996876]
[2019-03-23 12:04:26,996] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 12:04:26,997] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.6465143e-31 1.0000000e+00 0.0000000e+00 1.8617741e-35 0.0000000e+00], sampled 0.2542197055417734
[2019-03-23 12:05:44,606] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.1336884]
[2019-03-23 12:05:44,607] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.35, 56.5, 1.0, 2.0, 0.3957593364031571, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 435256.6322823932, 435256.6322823928, 124275.0439406208]
[2019-03-23 12:05:44,610] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 12:05:44,615] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.6465143e-31 1.0000000e+00 0.0000000e+00 1.8617741e-35 0.0000000e+00], sampled 0.06181437796904554
[2019-03-23 12:05:46,089] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 12:05:46,871] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 12:05:46,892] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 12:05:46,960] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 12:05:47,004] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 12:05:48,023] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 2275000, evaluation results [2275000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 12:05:53,109] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.6502134e-29 1.0000000e+00 0.0000000e+00 2.1118567e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 12:05:53,118] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6898
[2019-03-23 12:05:53,128] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.2, 76.66666666666667, 1.0, 2.0, 0.2525177785941035, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 274182.4734577034, 274182.4734577031, 88404.079170431], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5898000.0000, 
sim time next is 5898600.0000, 
raw observation next is [17.2, 77.5, 1.0, 2.0, 0.2510245094914703, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 272560.6354090575, 272560.6354090578, 89076.4345601983], 
processed observation next is [1.0, 0.2608695652173913, 0.41818181818181815, 0.775, 1.0, 1.0, 0.06378063686433788, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1009483834848361, 0.10094838348483622, 0.21725959648828852], 
reward next is 0.7827, 
noisyNet noise sample is [array([-2.4452229], dtype=float32), -0.75478303]. 
=============================================
[2019-03-23 12:05:55,117] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.1914210e-28 1.0000000e+00 0.0000000e+00 8.1659084e-30 1.6379573e-38], sum to 1.0000
[2019-03-23 12:05:55,123] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6870
[2019-03-23 12:05:55,129] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1128699.505876086 W.
[2019-03-23 12:05:55,132] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.7, 46.0, 1.0, 2.0, 0.3295456230135158, 1.0, 1.0, 0.3295456230135158, 1.0, 2.0, 0.6638144685525751, 6.9112, 6.9112, 77.3421103, 1128699.505876086, 1128699.505876086, 262523.7849275974], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5925600.0000, 
sim time next is 5926200.0000, 
raw observation next is [27.7, 46.0, 1.0, 2.0, 0.4566291097941543, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9154046879344299, 6.9112, 6.9112, 77.3284633172004, 1041284.853589239, 1041284.853589239, 238941.6029381031], 
processed observation next is [1.0, 0.6086956521739131, 0.8954545454545454, 0.46, 1.0, 1.0, 0.3207863872426928, 0.0, 0.5, -0.25, 1.0, 1.0, 0.8791495541920428, 0.0, 0.0, 0.5084288120899739, 0.3856610568849033, 0.3856610568849033, 0.5827843974100075], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.5471084], dtype=float32), -2.9590168]. 
=============================================
[2019-03-23 12:05:56,034] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.2927870e-25 1.0000000e+00 6.6684107e-36 3.2334687e-26 3.5515389e-35], sum to 1.0000
[2019-03-23 12:05:56,042] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0572
[2019-03-23 12:05:56,046] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 65.0, 1.0, 2.0, 0.3887114833651545, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 438275.7255137858, 438275.7255137858, 123973.7198941557], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5952600.0000, 
sim time next is 5953200.0000, 
raw observation next is [22.9, 65.33333333333334, 1.0, 2.0, 0.3869448529099225, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 436099.9823482194, 436099.9823482194, 123717.1345186774], 
processed observation next is [1.0, 0.9130434782608695, 0.6772727272727272, 0.6533333333333334, 1.0, 1.0, 0.23368106613740308, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16151851198082198, 0.16151851198082198, 0.30174910858214], 
reward next is 0.6983, 
noisyNet noise sample is [array([-0.14442179], dtype=float32), 0.28136888]. 
=============================================
[2019-03-23 12:05:56,108] A3C_AGENT_WORKER-Thread-9 INFO:Local step 143000, global step 2279078: loss 0.0081
[2019-03-23 12:05:56,110] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 143000, global step 2279079: learning rate 0.0005
[2019-03-23 12:05:59,137] A3C_AGENT_WORKER-Thread-19 INFO:Local step 142500, global step 2280616: loss -52.3564
[2019-03-23 12:05:59,139] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 142500, global step 2280616: learning rate 0.0005
[2019-03-23 12:05:59,198] A3C_AGENT_WORKER-Thread-21 INFO:Local step 142500, global step 2280642: loss -51.6116
[2019-03-23 12:05:59,201] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 142500, global step 2280643: learning rate 0.0005
[2019-03-23 12:05:59,259] A3C_AGENT_WORKER-Thread-22 INFO:Local step 142500, global step 2280676: loss -90.1980
[2019-03-23 12:05:59,262] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 142500, global step 2280677: learning rate 0.0005
[2019-03-23 12:05:59,463] A3C_AGENT_WORKER-Thread-10 INFO:Local step 142500, global step 2280775: loss -74.9707
[2019-03-23 12:05:59,470] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 142500, global step 2280776: learning rate 0.0005
[2019-03-23 12:05:59,615] A3C_AGENT_WORKER-Thread-2 INFO:Local step 142500, global step 2280853: loss -71.2191
[2019-03-23 12:05:59,617] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 142500, global step 2280853: learning rate 0.0005
[2019-03-23 12:05:59,627] A3C_AGENT_WORKER-Thread-3 INFO:Local step 142500, global step 2280857: loss -77.1208
[2019-03-23 12:05:59,628] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 142500, global step 2280857: learning rate 0.0005
[2019-03-23 12:05:59,898] A3C_AGENT_WORKER-Thread-20 INFO:Local step 142500, global step 2280989: loss -78.3226
[2019-03-23 12:05:59,903] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 142500, global step 2280989: learning rate 0.0005
[2019-03-23 12:05:59,930] A3C_AGENT_WORKER-Thread-11 INFO:Local step 142500, global step 2281008: loss -80.8210
[2019-03-23 12:05:59,932] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 142500, global step 2281010: learning rate 0.0005
[2019-03-23 12:06:00,173] A3C_AGENT_WORKER-Thread-12 INFO:Local step 142500, global step 2281133: loss -98.5676
[2019-03-23 12:06:00,175] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 142500, global step 2281133: learning rate 0.0005
[2019-03-23 12:06:00,418] A3C_AGENT_WORKER-Thread-14 INFO:Local step 142500, global step 2281254: loss -67.6910
[2019-03-23 12:06:00,419] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 142500, global step 2281255: learning rate 0.0005
[2019-03-23 12:06:00,720] A3C_AGENT_WORKER-Thread-15 INFO:Local step 142500, global step 2281414: loss -52.1608
[2019-03-23 12:06:00,724] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 142500, global step 2281414: learning rate 0.0005
[2019-03-23 12:06:00,766] A3C_AGENT_WORKER-Thread-17 INFO:Local step 142500, global step 2281433: loss -46.7395
[2019-03-23 12:06:00,767] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 142500, global step 2281433: learning rate 0.0005
[2019-03-23 12:06:00,973] A3C_AGENT_WORKER-Thread-13 INFO:Local step 143000, global step 2281538: loss 0.0159
[2019-03-23 12:06:00,976] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 143000, global step 2281538: learning rate 0.0005
[2019-03-23 12:06:01,037] A3C_AGENT_WORKER-Thread-18 INFO:Local step 142500, global step 2281573: loss -80.8004
[2019-03-23 12:06:01,040] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 142500, global step 2281575: learning rate 0.0005
[2019-03-23 12:06:01,443] A3C_AGENT_WORKER-Thread-16 INFO:Local step 142500, global step 2281778: loss -48.7276
[2019-03-23 12:06:01,447] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 142500, global step 2281778: learning rate 0.0005
[2019-03-23 12:06:04,202] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.2593451e-28 1.0000000e+00 0.0000000e+00 3.5593739e-30 0.0000000e+00], sum to 1.0000
[2019-03-23 12:06:04,211] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5937
[2019-03-23 12:06:04,216] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.4, 45.0, 1.0, 2.0, 0.7221286791163993, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 795185.9228141481, 795185.9228141481, 153108.1825612406], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6107400.0000, 
sim time next is 6108000.0000, 
raw observation next is [24.2, 46.0, 1.0, 2.0, 0.7714383273038055, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 849907.3955225449, 849907.3955225449, 159339.2221084225], 
processed observation next is [1.0, 0.6956521739130435, 0.7363636363636363, 0.46, 1.0, 1.0, 0.7142979091297569, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3147805168602018, 0.3147805168602018, 0.3886322490449329], 
reward next is 0.6114, 
noisyNet noise sample is [array([-1.3045815], dtype=float32), -2.246808]. 
=============================================
[2019-03-23 12:06:04,239] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[73.43219]
 [73.43219]
 [73.43219]
 [73.43219]
 [73.43219]], R is [[73.30922699]
 [73.20269775]
 [73.10045624]
 [72.99156189]
 [72.8874588 ]].
[2019-03-23 12:06:06,484] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.1425799e-31 1.0000000e+00 0.0000000e+00 8.6298282e-36 0.0000000e+00], sum to 1.0000
[2019-03-23 12:06:06,492] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1162
[2019-03-23 12:06:06,499] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 42.0, 1.0, 2.0, 0.7255476671429281, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 798654.3920036092, 798654.3920036092, 153418.9039106448], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6105600.0000, 
sim time next is 6106200.0000, 
raw observation next is [24.8, 43.0, 1.0, 2.0, 0.7377882165793105, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 812219.7566382261, 812219.7566382261, 154936.6612159501], 
processed observation next is [1.0, 0.6956521739130435, 0.7636363636363637, 0.43, 1.0, 1.0, 0.672235270724138, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3008221320882319, 0.3008221320882319, 0.3778942956486588], 
reward next is 0.6221, 
noisyNet noise sample is [array([-1.4909676], dtype=float32), -0.003749352]. 
=============================================
[2019-03-23 12:06:11,854] A3C_AGENT_WORKER-Thread-9 INFO:Local step 143500, global step 2287034: loss 0.0031
[2019-03-23 12:06:11,860] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 143500, global step 2287035: learning rate 0.0005
[2019-03-23 12:06:15,032] A3C_AGENT_WORKER-Thread-21 INFO:Local step 143000, global step 2288648: loss 0.0020
[2019-03-23 12:06:15,035] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 143000, global step 2288648: learning rate 0.0005
[2019-03-23 12:06:15,079] A3C_AGENT_WORKER-Thread-19 INFO:Local step 143000, global step 2288668: loss 0.0037
[2019-03-23 12:06:15,083] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 143000, global step 2288671: learning rate 0.0005
[2019-03-23 12:06:15,182] A3C_AGENT_WORKER-Thread-10 INFO:Local step 143000, global step 2288723: loss 0.0075
[2019-03-23 12:06:15,183] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 143000, global step 2288723: learning rate 0.0005
[2019-03-23 12:06:15,213] A3C_AGENT_WORKER-Thread-22 INFO:Local step 143000, global step 2288737: loss 0.0068
[2019-03-23 12:06:15,216] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 143000, global step 2288739: learning rate 0.0005
[2019-03-23 12:06:15,327] A3C_AGENT_WORKER-Thread-3 INFO:Local step 143000, global step 2288797: loss 0.0005
[2019-03-23 12:06:15,332] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 143000, global step 2288797: learning rate 0.0005
[2019-03-23 12:06:15,403] A3C_AGENT_WORKER-Thread-2 INFO:Local step 143000, global step 2288834: loss 0.0018
[2019-03-23 12:06:15,405] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 143000, global step 2288835: learning rate 0.0005
[2019-03-23 12:06:15,776] A3C_AGENT_WORKER-Thread-20 INFO:Local step 143000, global step 2289017: loss 0.0134
[2019-03-23 12:06:15,778] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 143000, global step 2289017: learning rate 0.0005
[2019-03-23 12:06:15,799] A3C_AGENT_WORKER-Thread-11 INFO:Local step 143000, global step 2289028: loss 0.0080
[2019-03-23 12:06:15,800] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 143000, global step 2289029: learning rate 0.0005
[2019-03-23 12:06:16,021] A3C_AGENT_WORKER-Thread-12 INFO:Local step 143000, global step 2289142: loss 0.0124
[2019-03-23 12:06:16,022] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 143000, global step 2289142: learning rate 0.0005
[2019-03-23 12:06:16,406] A3C_AGENT_WORKER-Thread-14 INFO:Local step 143000, global step 2289338: loss 0.0047
[2019-03-23 12:06:16,410] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 143000, global step 2289340: learning rate 0.0005
[2019-03-23 12:06:16,641] A3C_AGENT_WORKER-Thread-15 INFO:Local step 143000, global step 2289454: loss 0.0135
[2019-03-23 12:06:16,643] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 143000, global step 2289454: learning rate 0.0005
[2019-03-23 12:06:16,686] A3C_AGENT_WORKER-Thread-13 INFO:Local step 143500, global step 2289476: loss 0.0161
[2019-03-23 12:06:16,689] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 143500, global step 2289477: learning rate 0.0005
[2019-03-23 12:06:16,761] A3C_AGENT_WORKER-Thread-17 INFO:Local step 143000, global step 2289514: loss 0.0057
[2019-03-23 12:06:16,764] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 143000, global step 2289514: learning rate 0.0005
[2019-03-23 12:06:16,859] A3C_AGENT_WORKER-Thread-18 INFO:Local step 143000, global step 2289566: loss 0.0000
[2019-03-23 12:06:16,862] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 143000, global step 2289566: learning rate 0.0005
[2019-03-23 12:06:17,307] A3C_AGENT_WORKER-Thread-16 INFO:Local step 143000, global step 2289788: loss 0.0060
[2019-03-23 12:06:17,309] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 143000, global step 2289788: learning rate 0.0005
[2019-03-23 12:06:20,724] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.6792109e-26 1.0000000e+00 3.0593166e-36 3.6693637e-30 3.3011532e-36], sum to 1.0000
[2019-03-23 12:06:20,731] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2364
[2019-03-23 12:06:20,736] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.7, 69.5, 1.0, 2.0, 0.4823267385159533, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 550341.9150289552, 550341.9150289549, 138518.8678782719], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6413400.0000, 
sim time next is 6414000.0000, 
raw observation next is [24.6, 70.0, 1.0, 2.0, 0.4789006623566301, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 546422.0181290058, 546422.0181290058, 138093.8233336702], 
processed observation next is [1.0, 0.21739130434782608, 0.7545454545454546, 0.7, 1.0, 1.0, 0.34862582794578756, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20237852523296512, 0.20237852523296512, 0.33681420325285416], 
reward next is 0.6632, 
noisyNet noise sample is [array([-0.9739383], dtype=float32), 0.7675668]. 
=============================================
[2019-03-23 12:06:20,759] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[62.628036]
 [62.628036]
 [62.628036]
 [62.628036]
 [62.628036]], R is [[62.66493607]
 [62.70043564]
 [62.73270416]
 [62.75785828]
 [62.78821945]].
[2019-03-23 12:06:21,310] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.5430747e-26 1.0000000e+00 3.7196371e-36 1.7512138e-25 7.7202549e-35], sum to 1.0000
[2019-03-23 12:06:21,316] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4876
[2019-03-23 12:06:21,327] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.7, 71.0, 1.0, 2.0, 0.4996071057931144, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 570109.6660890097, 570109.6660890097, 140908.6479364231], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6417000.0000, 
sim time next is 6417600.0000, 
raw observation next is [24.8, 71.0, 1.0, 2.0, 0.4880595761522142, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 556913.5545409712, 556913.5545409712, 139786.7202246134], 
processed observation next is [1.0, 0.2608695652173913, 0.7636363636363637, 0.71, 1.0, 1.0, 0.36007447019026767, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20626427945961895, 0.20626427945961895, 0.3409432200600327], 
reward next is 0.6591, 
noisyNet noise sample is [array([1.691158], dtype=float32), 0.1780042]. 
=============================================
[2019-03-23 12:06:22,218] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.5624772e-25 1.0000000e+00 3.1103402e-36 2.7929135e-28 5.4987773e-36], sum to 1.0000
[2019-03-23 12:06:22,230] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1763
[2019-03-23 12:06:22,235] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.5, 70.5, 1.0, 2.0, 0.4757123082021406, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 542773.1037110476, 542773.1037110476, 137698.5236230337], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6414600.0000, 
sim time next is 6415200.0000, 
raw observation next is [24.4, 71.0, 1.0, 2.0, 0.4696683090695508, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 535863.0885063449, 535863.0885063449, 136989.5007011991], 
processed observation next is [1.0, 0.2608695652173913, 0.7454545454545454, 0.71, 1.0, 1.0, 0.33708538633693846, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19846781055790552, 0.19846781055790552, 0.3341207334175588], 
reward next is 0.6659, 
noisyNet noise sample is [array([0.51294804], dtype=float32), 0.24372023]. 
=============================================
[2019-03-23 12:06:22,960] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.2146176e-27 1.0000000e+00 6.4126478e-38 3.4813806e-30 1.7799149e-36], sum to 1.0000
[2019-03-23 12:06:22,971] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6449
[2019-03-23 12:06:22,977] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.3, 89.5, 1.0, 2.0, 0.6769397418954228, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 753432.6652133652, 753432.6652133656, 150695.1659110348], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6448200.0000, 
sim time next is 6448800.0000, 
raw observation next is [18.3, 89.0, 1.0, 2.0, 0.646039650909571, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 718375.9740513447, 718375.9740513447, 146798.5213958317], 
processed observation next is [1.0, 0.6521739130434783, 0.4681818181818182, 0.89, 1.0, 1.0, 0.5575495636369637, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2660651755745721, 0.2660651755745721, 0.35804517413617487], 
reward next is 0.6420, 
noisyNet noise sample is [array([1.9098773], dtype=float32), 0.3007447]. 
=============================================
[2019-03-23 12:06:23,841] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.3248109e-27 1.0000000e+00 1.2389729e-38 9.0549191e-30 5.9548055e-38], sum to 1.0000
[2019-03-23 12:06:23,847] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8193
[2019-03-23 12:06:23,852] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.41666666666667, 75.83333333333333, 1.0, 2.0, 0.2179004204796491, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 236585.9866031965, 236585.9866031965, 75149.08572564187], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6477000.0000, 
sim time next is 6477600.0000, 
raw observation next is [15.33333333333333, 76.66666666666667, 1.0, 2.0, 0.2182949285429692, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 237014.4291914853, 237014.4291914853, 75229.76846226396], 
processed observation next is [1.0, 1.0, 0.3333333333333332, 0.7666666666666667, 1.0, 1.0, 0.022868660678711482, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08778312192277234, 0.08778312192277234, 0.18348724015186332], 
reward next is 0.8165, 
noisyNet noise sample is [array([1.0351883], dtype=float32), 2.1941607]. 
=============================================
[2019-03-23 12:06:23,931] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.1344435e-29 1.0000000e+00 0.0000000e+00 1.4281657e-32 0.0000000e+00], sum to 1.0000
[2019-03-23 12:06:23,940] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6289
[2019-03-23 12:06:23,945] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.5, 75.0, 1.0, 2.0, 0.2192101063668565, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 238008.3296091833, 238008.329609183, 75249.50223918281], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6473400.0000, 
sim time next is 6474000.0000, 
raw observation next is [15.5, 75.0, 1.0, 2.0, 0.2186431782385491, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 237392.6347049871, 237392.6347049874, 75188.25774682713], 
processed observation next is [1.0, 0.9565217391304348, 0.3409090909090909, 0.75, 1.0, 1.0, 0.02330397279818635, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08792319803888411, 0.08792319803888422, 0.18338599450445642], 
reward next is 0.8166, 
noisyNet noise sample is [array([-0.8487828], dtype=float32), -0.34041092]. 
=============================================
[2019-03-23 12:06:23,962] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[69.019356]
 [69.019356]
 [69.019356]
 [69.019356]
 [69.019356]], R is [[69.14577484]
 [69.27078247]
 [69.39431   ]
 [69.51597595]
 [69.63578796]].
[2019-03-23 12:06:24,901] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.7599573e-28 1.0000000e+00 0.0000000e+00 8.8205756e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 12:06:24,908] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6005
[2019-03-23 12:06:24,911] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.86666666666667, 83.66666666666667, 1.0, 2.0, 0.2037913462035061, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 221263.5357140165, 221263.5357140162, 72135.38737912604], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6489600.0000, 
sim time next is 6490200.0000, 
raw observation next is [13.58333333333333, 85.33333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 216157.9581074132, 216157.9581074132, 71347.53201714577], 
processed observation next is [1.0, 0.08695652173913043, 0.2537878787878787, 0.8533333333333333, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08005850300274563, 0.08005850300274563, 0.17401837077352628], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.8222247], dtype=float32), -1.402814]. 
=============================================
[2019-03-23 12:06:26,934] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.3868161e-31 1.0000000e+00 0.0000000e+00 1.7918191e-33 0.0000000e+00], sum to 1.0000
[2019-03-23 12:06:26,942] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0188
[2019-03-23 12:06:26,945] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.58333333333334, 51.5, 1.0, 2.0, 0.4998045797563767, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 542835.0631269406, 542835.063126941, 108025.9541482745], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6529800.0000, 
sim time next is 6530400.0000, 
raw observation next is [19.4, 52.0, 1.0, 2.0, 0.5132314261096821, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 557426.2503531997, 557426.2503531994, 109068.1462380622], 
processed observation next is [1.0, 0.6086956521739131, 0.5181818181818181, 0.52, 1.0, 1.0, 0.3915392826371026, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20645416679748135, 0.20645416679748127, 0.2660198688733224], 
reward next is 0.7340, 
noisyNet noise sample is [array([1.1296613], dtype=float32), 0.017147401]. 
=============================================
[2019-03-23 12:06:27,796] A3C_AGENT_WORKER-Thread-9 INFO:Local step 144000, global step 2295075: loss 0.0503
[2019-03-23 12:06:27,800] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 144000, global step 2295076: learning rate 0.0005
[2019-03-23 12:06:30,694] A3C_AGENT_WORKER-Thread-21 INFO:Local step 143500, global step 2296631: loss 0.0587
[2019-03-23 12:06:30,695] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 143500, global step 2296631: learning rate 0.0005
[2019-03-23 12:06:30,874] A3C_AGENT_WORKER-Thread-19 INFO:Local step 143500, global step 2296727: loss 0.0261
[2019-03-23 12:06:30,876] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 143500, global step 2296728: learning rate 0.0005
[2019-03-23 12:06:30,887] A3C_AGENT_WORKER-Thread-10 INFO:Local step 143500, global step 2296734: loss 0.0216
[2019-03-23 12:06:30,889] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 143500, global step 2296734: learning rate 0.0005
[2019-03-23 12:06:30,915] A3C_AGENT_WORKER-Thread-22 INFO:Local step 143500, global step 2296745: loss 0.0137
[2019-03-23 12:06:30,916] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 143500, global step 2296746: learning rate 0.0005
[2019-03-23 12:06:31,068] A3C_AGENT_WORKER-Thread-2 INFO:Local step 143500, global step 2296827: loss 0.0012
[2019-03-23 12:06:31,069] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 143500, global step 2296827: learning rate 0.0005
[2019-03-23 12:06:31,114] A3C_AGENT_WORKER-Thread-3 INFO:Local step 143500, global step 2296853: loss 0.0012
[2019-03-23 12:06:31,115] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 143500, global step 2296853: learning rate 0.0005
[2019-03-23 12:06:31,382] A3C_AGENT_WORKER-Thread-20 INFO:Local step 143500, global step 2296996: loss 0.0053
[2019-03-23 12:06:31,384] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 143500, global step 2296996: learning rate 0.0005
[2019-03-23 12:06:31,437] A3C_AGENT_WORKER-Thread-11 INFO:Local step 143500, global step 2297021: loss 0.0083
[2019-03-23 12:06:31,442] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 143500, global step 2297025: learning rate 0.0005
[2019-03-23 12:06:31,652] A3C_AGENT_WORKER-Thread-12 INFO:Local step 143500, global step 2297139: loss 0.0232
[2019-03-23 12:06:31,656] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 143500, global step 2297140: learning rate 0.0005
[2019-03-23 12:06:31,961] A3C_AGENT_WORKER-Thread-14 INFO:Local step 143500, global step 2297307: loss 0.0029
[2019-03-23 12:06:31,963] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 143500, global step 2297307: learning rate 0.0005
[2019-03-23 12:06:32,144] A3C_AGENT_WORKER-Thread-15 INFO:Local step 143500, global step 2297403: loss 0.0018
[2019-03-23 12:06:32,145] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 143500, global step 2297403: learning rate 0.0005
[2019-03-23 12:06:32,160] A3C_AGENT_WORKER-Thread-13 INFO:Local step 144000, global step 2297411: loss 0.0211
[2019-03-23 12:06:32,162] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 144000, global step 2297413: learning rate 0.0005
[2019-03-23 12:06:32,370] A3C_AGENT_WORKER-Thread-17 INFO:Local step 143500, global step 2297518: loss 0.0048
[2019-03-23 12:06:32,376] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 143500, global step 2297520: learning rate 0.0005
[2019-03-23 12:06:32,391] A3C_AGENT_WORKER-Thread-18 INFO:Local step 143500, global step 2297529: loss 0.0012
[2019-03-23 12:06:32,395] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 143500, global step 2297531: learning rate 0.0005
[2019-03-23 12:06:33,028] A3C_AGENT_WORKER-Thread-16 INFO:Local step 143500, global step 2297870: loss 0.0220
[2019-03-23 12:06:33,032] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 143500, global step 2297870: learning rate 0.0005
[2019-03-23 12:06:37,047] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-23 12:06:37,048] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 12:06:37,049] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:06:37,049] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 12:06:37,050] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 12:06:37,050] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:06:37,051] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:06:37,052] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 12:06:37,051] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 12:06:37,054] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:06:37,055] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:06:37,071] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run93
[2019-03-23 12:06:37,098] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run93
[2019-03-23 12:06:37,121] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run93
[2019-03-23 12:06:37,122] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run93
[2019-03-23 12:06:37,156] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run93
[2019-03-23 12:07:20,159] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.123465]
[2019-03-23 12:07:20,161] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.33333333333333, 81.33333333333334, 1.0, 2.0, 0.8876184939495539, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1008394.613921388, 1008394.613921388, 189400.3120354537]
[2019-03-23 12:07:20,161] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 12:07:20,166] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.6845282e-29 1.0000000e+00 0.0000000e+00 8.3683825e-33 0.0000000e+00], sampled 0.8931975833661637
[2019-03-23 12:07:59,711] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.123465]
[2019-03-23 12:07:59,713] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [14.85422585, 94.91937451333334, 1.0, 2.0, 0.2687950181059776, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 291844.8158814588, 291844.8158814584, 92217.53783964214]
[2019-03-23 12:07:59,714] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 12:07:59,716] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.6845282e-29 1.0000000e+00 0.0000000e+00 8.3683825e-33 0.0000000e+00], sampled 0.5681228044884561
[2019-03-23 12:08:01,750] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.123465]
[2019-03-23 12:08:01,752] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [17.46921108, 91.24962597, 1.0, 2.0, 0.3400983495242272, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 373824.1454021286, 373824.1454021286, 119858.9926495599]
[2019-03-23 12:08:01,756] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 12:08:01,759] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.6845282e-29 1.0000000e+00 0.0000000e+00 8.3683825e-33 0.0000000e+00], sampled 0.08700444140082408
[2019-03-23 12:08:08,392] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.123465]
[2019-03-23 12:08:08,394] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.0, 55.0, 1.0, 2.0, 0.3551624467613112, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 385648.5397305855, 385648.5397305851, 101778.5216370046]
[2019-03-23 12:08:08,396] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 12:08:08,399] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.6845282e-29 1.0000000e+00 0.0000000e+00 8.3683825e-33 0.0000000e+00], sampled 0.08975617538447689
[2019-03-23 12:08:13,198] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.123465]
[2019-03-23 12:08:13,199] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.13333333333334, 68.66666666666667, 1.0, 2.0, 0.3187389312336983, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 346087.149043389, 346087.1490433887, 110207.2537958885]
[2019-03-23 12:08:13,200] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 12:08:13,205] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.6845282e-29 1.0000000e+00 0.0000000e+00 8.3683825e-33 0.0000000e+00], sampled 0.6870086836678416
[2019-03-23 12:08:15,797] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 12:08:15,938] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 12:08:16,050] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 12:08:16,077] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 12:08:16,157] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 12:08:17,172] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 2300000, evaluation results [2300000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 12:08:19,335] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.7664233e-30 1.0000000e+00 0.0000000e+00 1.8607517e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 12:08:19,343] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5354
[2019-03-23 12:08:19,348] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.83333333333333, 76.16666666666667, 1.0, 2.0, 0.6922518694497877, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 784388.7322719361, 784388.7322719361, 159173.4340207471], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6774600.0000, 
sim time next is 6775200.0000, 
raw observation next is [22.2, 76.0, 1.0, 2.0, 0.7299214172460033, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 829043.1056961092, 829043.1056961092, 165595.9574734046], 
processed observation next is [1.0, 0.43478260869565216, 0.6454545454545454, 0.76, 1.0, 1.0, 0.6624017715575042, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.30705300210967007, 0.30705300210967007, 0.4038925792034258], 
reward next is 0.5961, 
noisyNet noise sample is [array([-0.98781914], dtype=float32), 0.48230484]. 
=============================================
[2019-03-23 12:08:23,139] A3C_AGENT_WORKER-Thread-9 INFO:Local step 144500, global step 2303018: loss 0.0005
[2019-03-23 12:08:23,140] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 144500, global step 2303019: learning rate 0.0005
[2019-03-23 12:08:26,234] A3C_AGENT_WORKER-Thread-21 INFO:Local step 144000, global step 2304594: loss 0.0139
[2019-03-23 12:08:26,236] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 144000, global step 2304594: learning rate 0.0005
[2019-03-23 12:08:26,357] A3C_AGENT_WORKER-Thread-22 INFO:Local step 144000, global step 2304653: loss 0.0026
[2019-03-23 12:08:26,358] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 144000, global step 2304653: learning rate 0.0005
[2019-03-23 12:08:26,451] A3C_AGENT_WORKER-Thread-10 INFO:Local step 144000, global step 2304699: loss 0.0051
[2019-03-23 12:08:26,453] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 144000, global step 2304699: learning rate 0.0005
[2019-03-23 12:08:26,604] A3C_AGENT_WORKER-Thread-19 INFO:Local step 144000, global step 2304779: loss 0.0008
[2019-03-23 12:08:26,606] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 144000, global step 2304779: learning rate 0.0005
[2019-03-23 12:08:26,851] A3C_AGENT_WORKER-Thread-3 INFO:Local step 144000, global step 2304903: loss 0.0216
[2019-03-23 12:08:26,854] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 144000, global step 2304903: learning rate 0.0005
[2019-03-23 12:08:26,857] A3C_AGENT_WORKER-Thread-2 INFO:Local step 144000, global step 2304904: loss 0.0244
[2019-03-23 12:08:26,860] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 144000, global step 2304905: learning rate 0.0005
[2019-03-23 12:08:27,103] A3C_AGENT_WORKER-Thread-20 INFO:Local step 144000, global step 2305030: loss 0.0055
[2019-03-23 12:08:27,103] A3C_AGENT_WORKER-Thread-11 INFO:Local step 144000, global step 2305031: loss 0.0053
[2019-03-23 12:08:27,106] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 144000, global step 2305031: learning rate 0.0005
[2019-03-23 12:08:27,108] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 144000, global step 2305031: learning rate 0.0005
[2019-03-23 12:08:27,439] A3C_AGENT_WORKER-Thread-12 INFO:Local step 144000, global step 2305196: loss 0.0076
[2019-03-23 12:08:27,442] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 144000, global step 2305196: learning rate 0.0005
[2019-03-23 12:08:27,548] A3C_AGENT_WORKER-Thread-14 INFO:Local step 144000, global step 2305249: loss 0.0009
[2019-03-23 12:08:27,553] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 144000, global step 2305250: learning rate 0.0005
[2019-03-23 12:08:27,835] A3C_AGENT_WORKER-Thread-15 INFO:Local step 144000, global step 2305395: loss 0.0003
[2019-03-23 12:08:27,842] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 144000, global step 2305399: learning rate 0.0005
[2019-03-23 12:08:27,925] A3C_AGENT_WORKER-Thread-13 INFO:Local step 144500, global step 2305444: loss 0.0005
[2019-03-23 12:08:27,928] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 144500, global step 2305445: learning rate 0.0005
[2019-03-23 12:08:28,113] A3C_AGENT_WORKER-Thread-18 INFO:Local step 144000, global step 2305537: loss 0.0017
[2019-03-23 12:08:28,115] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 144000, global step 2305538: learning rate 0.0005
[2019-03-23 12:08:28,160] A3C_AGENT_WORKER-Thread-17 INFO:Local step 144000, global step 2305560: loss 0.0005
[2019-03-23 12:08:28,163] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 144000, global step 2305560: learning rate 0.0005
[2019-03-23 12:08:28,689] A3C_AGENT_WORKER-Thread-16 INFO:Local step 144000, global step 2305826: loss 0.0010
[2019-03-23 12:08:28,696] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 144000, global step 2305829: learning rate 0.0005
[2019-03-23 12:08:29,385] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.3459611e-28 1.0000000e+00 0.0000000e+00 1.5174054e-26 0.0000000e+00], sum to 1.0000
[2019-03-23 12:08:29,393] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6219
[2019-03-23 12:08:29,397] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.96666666666667, 67.33333333333334, 1.0, 2.0, 0.4545994760037332, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 518616.0321634157, 518616.0321634154, 135192.855055192], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6949200.0000, 
sim time next is 6949800.0000, 
raw observation next is [25.25, 66.5, 1.0, 2.0, 0.4604340425214138, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 525347.1110905183, 525347.1110905183, 136102.9736468002], 
processed observation next is [0.0, 0.43478260869565216, 0.7840909090909091, 0.665, 1.0, 1.0, 0.3255425531517672, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19457300410759937, 0.19457300410759937, 0.3319584723092688], 
reward next is 0.6680, 
noisyNet noise sample is [array([-1.6208875], dtype=float32), 0.07143239]. 
=============================================
[2019-03-23 12:08:29,962] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.2961288e-26 1.0000000e+00 1.2093596e-36 5.6652260e-33 9.9374954e-36], sum to 1.0000
[2019-03-23 12:08:29,974] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7855
[2019-03-23 12:08:29,980] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.6, 77.0, 1.0, 2.0, 0.343588916510244, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 379730.2022459774, 379730.2022459771, 116585.105448319], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7341600.0000, 
sim time next is 7342200.0000, 
raw observation next is [19.4, 78.0, 1.0, 2.0, 0.3423971061947739, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 378011.2810551472, 378011.2810551472, 116338.6554528588], 
processed observation next is [1.0, 1.0, 0.5181818181818181, 0.78, 1.0, 1.0, 0.17799638274346738, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14000417816857302, 0.14000417816857302, 0.28375281817770437], 
reward next is 0.7162, 
noisyNet noise sample is [array([-0.5293174], dtype=float32), 1.1057721]. 
=============================================
[2019-03-23 12:08:31,808] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.0421237e-28 1.0000000e+00 0.0000000e+00 4.7876783e-34 1.7543054e-37], sum to 1.0000
[2019-03-23 12:08:31,814] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3872
[2019-03-23 12:08:31,824] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.7, 58.0, 1.0, 2.0, 0.5024532338557602, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 572854.9781791783, 572854.9781791787, 142611.9779542014], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6969600.0000, 
sim time next is 6970200.0000, 
raw observation next is [27.7, 58.5, 1.0, 2.0, 0.5043145200552027, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 574886.1152643797, 574886.11526438, 142947.5468282561], 
processed observation next is [0.0, 0.6956521739130435, 0.8954545454545454, 0.585, 1.0, 1.0, 0.38039315006900337, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21292078343125173, 0.21292078343125184, 0.34865255323964905], 
reward next is 0.6513, 
noisyNet noise sample is [array([-0.15236858], dtype=float32), 1.4227499]. 
=============================================
[2019-03-23 12:08:33,319] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.8882363e-30 1.0000000e+00 0.0000000e+00 6.6328556e-32 0.0000000e+00], sum to 1.0000
[2019-03-23 12:08:33,327] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7128
[2019-03-23 12:08:33,331] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.7, 95.66666666666666, 1.0, 2.0, 0.5016549546020546, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 572115.7167576231, 572115.7167576231, 139881.1911801145], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7008000.0000, 
sim time next is 7008600.0000, 
raw observation next is [20.6, 96.33333333333334, 1.0, 2.0, 0.4899129509191272, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 558681.3514920181, 558681.3514920181, 138497.7009713734], 
processed observation next is [1.0, 0.08695652173913043, 0.5727272727272728, 0.9633333333333334, 1.0, 1.0, 0.36239118864890896, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20691901907111782, 0.20691901907111782, 0.3377992706618863], 
reward next is 0.6622, 
noisyNet noise sample is [array([-0.37791568], dtype=float32), 1.082052]. 
=============================================
[2019-03-23 12:08:39,106] A3C_AGENT_WORKER-Thread-9 INFO:Local step 145000, global step 2311087: loss 0.0009
[2019-03-23 12:08:39,110] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 145000, global step 2311087: learning rate 0.0005
[2019-03-23 12:08:42,021] A3C_AGENT_WORKER-Thread-21 INFO:Local step 144500, global step 2312565: loss 0.0158
[2019-03-23 12:08:42,023] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 144500, global step 2312565: learning rate 0.0005
[2019-03-23 12:08:42,087] A3C_AGENT_WORKER-Thread-22 INFO:Local step 144500, global step 2312601: loss 0.0058
[2019-03-23 12:08:42,093] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 144500, global step 2312601: learning rate 0.0005
[2019-03-23 12:08:42,246] A3C_AGENT_WORKER-Thread-10 INFO:Local step 144500, global step 2312681: loss 0.0065
[2019-03-23 12:08:42,253] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 144500, global step 2312683: learning rate 0.0005
[2019-03-23 12:08:42,555] A3C_AGENT_WORKER-Thread-19 INFO:Local step 144500, global step 2312838: loss 0.0004
[2019-03-23 12:08:42,557] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 144500, global step 2312839: learning rate 0.0005
[2019-03-23 12:08:42,567] A3C_AGENT_WORKER-Thread-3 INFO:Local step 144500, global step 2312845: loss 0.0007
[2019-03-23 12:08:42,572] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 144500, global step 2312846: learning rate 0.0005
[2019-03-23 12:08:42,583] A3C_AGENT_WORKER-Thread-2 INFO:Local step 144500, global step 2312850: loss 0.0003
[2019-03-23 12:08:42,586] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 144500, global step 2312852: learning rate 0.0005
[2019-03-23 12:08:42,958] A3C_AGENT_WORKER-Thread-11 INFO:Local step 144500, global step 2313039: loss 0.0001
[2019-03-23 12:08:42,959] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 144500, global step 2313040: learning rate 0.0005
[2019-03-23 12:08:43,060] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.5196579e-27 1.0000000e+00 0.0000000e+00 4.5432893e-33 0.0000000e+00], sum to 1.0000
[2019-03-23 12:08:43,065] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8932
[2019-03-23 12:08:43,070] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.2, 49.0, 1.0, 2.0, 0.5971529052385458, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 648635.1061869533, 648635.1061869536, 133081.9333102131], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7210800.0000, 
sim time next is 7211400.0000, 
raw observation next is [22.2, 48.66666666666667, 1.0, 2.0, 0.626289717393053, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 680306.0361698159, 680306.0361698163, 135815.6680246184], 
processed observation next is [1.0, 0.4782608695652174, 0.6454545454545454, 0.4866666666666667, 1.0, 1.0, 0.5328621467413162, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2519651985814133, 0.2519651985814134, 0.3312577268893132], 
reward next is 0.6687, 
noisyNet noise sample is [array([-1.2098804], dtype=float32), 0.67602533]. 
=============================================
[2019-03-23 12:08:43,111] A3C_AGENT_WORKER-Thread-20 INFO:Local step 144500, global step 2313120: loss 0.0001
[2019-03-23 12:08:43,113] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 144500, global step 2313122: learning rate 0.0005
[2019-03-23 12:08:43,143] A3C_AGENT_WORKER-Thread-12 INFO:Local step 144500, global step 2313134: loss 0.0001
[2019-03-23 12:08:43,147] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 144500, global step 2313138: learning rate 0.0005
[2019-03-23 12:08:43,325] A3C_AGENT_WORKER-Thread-14 INFO:Local step 144500, global step 2313227: loss 0.0011
[2019-03-23 12:08:43,327] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 144500, global step 2313228: learning rate 0.0005
[2019-03-23 12:08:43,715] A3C_AGENT_WORKER-Thread-18 INFO:Local step 144500, global step 2313422: loss 0.0014
[2019-03-23 12:08:43,718] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 144500, global step 2313423: learning rate 0.0005
[2019-03-23 12:08:43,760] A3C_AGENT_WORKER-Thread-15 INFO:Local step 144500, global step 2313446: loss 0.0009
[2019-03-23 12:08:43,762] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 144500, global step 2313447: learning rate 0.0005
[2019-03-23 12:08:43,882] A3C_AGENT_WORKER-Thread-13 INFO:Local step 145000, global step 2313504: loss 0.0015
[2019-03-23 12:08:43,883] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 145000, global step 2313504: learning rate 0.0005
[2019-03-23 12:08:43,957] A3C_AGENT_WORKER-Thread-17 INFO:Local step 144500, global step 2313546: loss 0.0000
[2019-03-23 12:08:43,958] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 144500, global step 2313546: learning rate 0.0005
[2019-03-23 12:08:44,613] A3C_AGENT_WORKER-Thread-16 INFO:Local step 144500, global step 2313876: loss 0.0152
[2019-03-23 12:08:44,615] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 144500, global step 2313877: learning rate 0.0005
[2019-03-23 12:08:44,622] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.3342441e-29 1.0000000e+00 0.0000000e+00 4.4258815e-36 0.0000000e+00], sum to 1.0000
[2019-03-23 12:08:44,635] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9728
[2019-03-23 12:08:44,642] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 43.0, 1.0, 2.0, 0.7652897201850404, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 833481.2581030322, 833481.2581030326, 155378.3806152623], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7224000.0000, 
sim time next is 7224600.0000, 
raw observation next is [23.9, 43.0, 1.0, 2.0, 0.7554823563212993, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 821398.3811933488, 821398.3811933491, 153761.6717799763], 
processed observation next is [1.0, 0.6086956521739131, 0.7227272727272727, 0.43, 1.0, 1.0, 0.6943529454016242, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3042216226642033, 0.3042216226642034, 0.37502846775603976], 
reward next is 0.6250, 
noisyNet noise sample is [array([-0.6073667], dtype=float32), -0.057128858]. 
=============================================
[2019-03-23 12:08:46,526] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0808221e-35 1.0000000e+00 0.0000000e+00 6.4008599e-33 0.0000000e+00], sum to 1.0000
[2019-03-23 12:08:46,535] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3853
[2019-03-23 12:08:46,538] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.45, 87.5, 1.0, 2.0, 0.2526924119798361, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 274372.142952981, 274372.142952981, 84778.48586601549], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7260600.0000, 
sim time next is 7261200.0000, 
raw observation next is [15.0, 90.0, 1.0, 2.0, 0.2474456566183178, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 268673.6689687134, 268673.6689687137, 83098.2351404905], 
processed observation next is [1.0, 0.043478260869565216, 0.3181818181818182, 0.9, 1.0, 1.0, 0.059307070772897236, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09950876628470866, 0.09950876628470878, 0.20267862229387928], 
reward next is 0.7973, 
noisyNet noise sample is [array([0.59744364], dtype=float32), -1.2993437]. 
=============================================
[2019-03-23 12:08:52,721] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.5103400e-26 1.0000000e+00 2.5978658e-35 2.0337655e-29 2.5517035e-35], sum to 1.0000
[2019-03-23 12:08:52,727] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4464
[2019-03-23 12:08:52,730] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.13333333333333, 76.0, 1.0, 2.0, 0.4407778225693592, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 502551.1086516625, 502551.1086516625, 133084.1150524518], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7407600.0000, 
sim time next is 7408200.0000, 
raw observation next is [22.11666666666667, 80.0, 1.0, 2.0, 0.4332994906675011, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 493339.2177936847, 493339.2177936847, 131409.100998184], 
processed observation next is [1.0, 0.7391304347826086, 0.6416666666666668, 0.8, 1.0, 1.0, 0.29162436333437636, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18271822881247582, 0.18271822881247582, 0.32051000243459515], 
reward next is 0.6795, 
noisyNet noise sample is [array([0.56769377], dtype=float32), 0.3436554]. 
=============================================
[2019-03-23 12:08:55,070] A3C_AGENT_WORKER-Thread-9 INFO:Local step 145500, global step 2319117: loss 0.0575
[2019-03-23 12:08:55,076] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 145500, global step 2319117: learning rate 0.0005
[2019-03-23 12:08:55,280] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.307279e-29 1.000000e+00 0.000000e+00 2.601436e-35 0.000000e+00], sum to 1.0000
[2019-03-23 12:08:55,286] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4149
[2019-03-23 12:08:55,289] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.63333333333334, 99.83333333333334, 1.0, 2.0, 0.3300317147366758, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 362843.9129182367, 362843.912918237, 114832.0500990251], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7451400.0000, 
sim time next is 7452000.0000, 
raw observation next is [16.6, 100.0, 1.0, 2.0, 0.329319345447383, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 361952.8589658532, 361952.8589658529, 114739.6747467332], 
processed observation next is [0.0, 0.2608695652173913, 0.390909090909091, 1.0, 1.0, 1.0, 0.16164918180922874, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13405661443179748, 0.13405661443179737, 0.27985286523593467], 
reward next is 0.7201, 
noisyNet noise sample is [array([-0.00185562], dtype=float32), 0.95587987]. 
=============================================
[2019-03-23 12:08:55,299] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[71.1304]
 [71.1304]
 [71.1304]
 [71.1304]
 [71.1304]], R is [[71.13924408]
 [71.14777374]
 [71.15600586]
 [71.16397095]
 [71.17166901]].
[2019-03-23 12:08:57,742] A3C_AGENT_WORKER-Thread-21 INFO:Local step 145000, global step 2320535: loss 0.0008
[2019-03-23 12:08:57,743] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 145000, global step 2320535: learning rate 0.0005
[2019-03-23 12:08:58,000] A3C_AGENT_WORKER-Thread-22 INFO:Local step 145000, global step 2320672: loss 0.0019
[2019-03-23 12:08:58,001] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 145000, global step 2320672: learning rate 0.0005
[2019-03-23 12:08:58,021] A3C_AGENT_WORKER-Thread-10 INFO:Local step 145000, global step 2320684: loss 0.0018
[2019-03-23 12:08:58,024] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 145000, global step 2320684: learning rate 0.0005
[2019-03-23 12:08:58,229] A3C_AGENT_WORKER-Thread-2 INFO:Local step 145000, global step 2320793: loss 0.0005
[2019-03-23 12:08:58,230] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 145000, global step 2320793: learning rate 0.0005
[2019-03-23 12:08:58,269] A3C_AGENT_WORKER-Thread-19 INFO:Local step 145000, global step 2320815: loss 0.0026
[2019-03-23 12:08:58,271] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 145000, global step 2320815: learning rate 0.0005
[2019-03-23 12:08:58,403] A3C_AGENT_WORKER-Thread-3 INFO:Local step 145000, global step 2320884: loss 0.0000
[2019-03-23 12:08:58,406] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 145000, global step 2320887: learning rate 0.0005
[2019-03-23 12:08:58,674] A3C_AGENT_WORKER-Thread-11 INFO:Local step 145000, global step 2321032: loss 0.0008
[2019-03-23 12:08:58,675] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 145000, global step 2321032: learning rate 0.0005
[2019-03-23 12:08:58,725] A3C_AGENT_WORKER-Thread-20 INFO:Local step 145000, global step 2321058: loss 0.0081
[2019-03-23 12:08:58,727] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 145000, global step 2321059: learning rate 0.0005
[2019-03-23 12:08:58,817] A3C_AGENT_WORKER-Thread-12 INFO:Local step 145000, global step 2321106: loss 0.0151
[2019-03-23 12:08:58,820] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 145000, global step 2321108: learning rate 0.0005
[2019-03-23 12:08:59,008] A3C_AGENT_WORKER-Thread-14 INFO:Local step 145000, global step 2321211: loss 0.0019
[2019-03-23 12:08:59,012] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 145000, global step 2321213: learning rate 0.0005
[2019-03-23 12:08:59,358] A3C_AGENT_WORKER-Thread-18 INFO:Local step 145000, global step 2321393: loss 0.0037
[2019-03-23 12:08:59,361] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 145000, global step 2321394: learning rate 0.0005
[2019-03-23 12:08:59,545] A3C_AGENT_WORKER-Thread-13 INFO:Local step 145500, global step 2321488: loss 0.0068
[2019-03-23 12:08:59,548] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 145500, global step 2321488: learning rate 0.0005
[2019-03-23 12:08:59,561] A3C_AGENT_WORKER-Thread-15 INFO:Local step 145000, global step 2321493: loss 0.0000
[2019-03-23 12:08:59,563] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 145000, global step 2321495: learning rate 0.0005
[2019-03-23 12:08:59,670] A3C_AGENT_WORKER-Thread-17 INFO:Local step 145000, global step 2321554: loss 0.0041
[2019-03-23 12:08:59,673] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 145000, global step 2321555: learning rate 0.0005
[2019-03-23 12:09:00,365] A3C_AGENT_WORKER-Thread-16 INFO:Local step 145000, global step 2321921: loss 0.0046
[2019-03-23 12:09:00,368] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 145000, global step 2321922: learning rate 0.0005
[2019-03-23 12:09:02,893] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:09:02,893] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:09:02,952] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run12
[2019-03-23 12:09:04,847] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.3479950e-26 1.0000000e+00 8.1711098e-38 2.7848040e-30 4.7618773e-38], sum to 1.0000
[2019-03-23 12:09:04,857] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8684
[2019-03-23 12:09:04,864] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1177266.654808621 W.
[2019-03-23 12:09:04,867] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.33333333333334, 72.66666666666667, 1.0, 2.0, 0.5528824655530897, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9716824886601656, 6.918375249111845, 6.9112, 77.32844584152208, 1177266.654808621, 1174936.281186773, 269015.3503596107], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7641600.0000, 
sim time next is 7642200.0000, 
raw observation next is [25.41666666666666, 72.33333333333333, 1.0, 2.0, 0.3450471554095078, 1.0, 1.0, 0.3450471554095078, 1.0, 2.0, 0.6985310320055272, 6.911199999999999, 6.9112, 77.3421103, 1171579.503961683, 1171579.503961683, 279508.332353691], 
processed observation next is [1.0, 0.43478260869565216, 0.7916666666666664, 0.7233333333333333, 1.0, 1.0, 0.18130894426188474, 1.0, 0.5, 0.18130894426188474, 1.0, 1.0, 0.5693300457221818, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.43391833480062336, 0.43391833480062336, 0.6817276398870512], 
reward next is 0.3183, 
noisyNet noise sample is [array([-1.2172363], dtype=float32), 1.7767528]. 
=============================================
[2019-03-23 12:09:05,720] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.5621571e-22 1.0000000e+00 5.4952836e-33 4.0393120e-26 1.4231948e-32], sum to 1.0000
[2019-03-23 12:09:05,730] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9300
[2019-03-23 12:09:05,737] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1198557.827288184 W.
[2019-03-23 12:09:05,744] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.16666666666667, 73.33333333333334, 1.0, 2.0, 0.5714459479609661, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9755734065054504, 6.911199999999999, 6.9112, 77.32846344354104, 1198557.827288184, 1198557.827288185, 272043.5381949759], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7640400.0000, 
sim time next is 7641000.0000, 
raw observation next is [25.25, 73.0, 1.0, 2.0, 0.352144969420401, 1.0, 1.0, 0.352144969420401, 1.0, 2.0, 0.7129455262584041, 6.9112, 6.9112, 77.3421103, 1196003.242418554, 1196003.242418554, 282347.8401317691], 
processed observation next is [1.0, 0.43478260869565216, 0.7840909090909091, 0.73, 1.0, 1.0, 0.19018121177550126, 1.0, 0.5, 0.19018121177550126, 1.0, 1.0, 0.5899221803691488, 0.0, 0.0, 0.5085185399722538, 0.44296416385872367, 0.44296416385872367, 0.688653268614071], 
reward next is 0.3113, 
noisyNet noise sample is [array([-0.5673186], dtype=float32), -1.5138398]. 
=============================================
[2019-03-23 12:09:05,762] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[59.738544]
 [59.738544]
 [59.738544]
 [59.738544]
 [59.738544]], R is [[59.45250702]
 [59.19446182]
 [58.60251617]
 [58.01649094]
 [57.76215363]].
[2019-03-23 12:09:06,136] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-23 12:09:06,138] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 12:09:06,139] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:09:06,141] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 12:09:06,143] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:09:06,143] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 12:09:06,144] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 12:09:06,144] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:09:06,145] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 12:09:06,146] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:09:06,147] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:09:06,165] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run94
[2019-03-23 12:09:06,190] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run94
[2019-03-23 12:09:06,214] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run94
[2019-03-23 12:09:06,243] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run94
[2019-03-23 12:09:06,244] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run94
[2019-03-23 12:09:25,775] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.1029115]
[2019-03-23 12:09:25,776] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.21666666666667, 49.83333333333334, 1.0, 2.0, 0.3896887082176803, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 95.55338769695034, 423151.6331209887, 423151.633120988, 117828.2892414812]
[2019-03-23 12:09:25,777] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 12:09:25,780] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.8129696e-24 1.0000000e+00 4.9614866e-34 1.6574956e-27 1.7657091e-33], sampled 0.17545781184508713
[2019-03-23 12:10:09,967] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.1029115]
[2019-03-23 12:10:09,969] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.88333333333333, 73.66666666666666, 1.0, 2.0, 0.380455187688747, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 429411.2966201972, 429411.2966201968, 127821.3699937734]
[2019-03-23 12:10:09,970] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 12:10:09,972] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.8129696e-24 1.0000000e+00 4.9614866e-34 1.6574956e-27 1.7657091e-33], sampled 0.992007871582799
[2019-03-23 12:10:19,937] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.1029115]
[2019-03-23 12:10:19,938] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.61666666666667, 65.0, 1.0, 2.0, 0.2618244775056578, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 284274.7453918883, 284274.7453918879, 92922.88094778481]
[2019-03-23 12:10:19,939] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 12:10:19,943] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.8129696e-24 1.0000000e+00 4.9614866e-34 1.6574956e-27 1.7657091e-33], sampled 0.19488891595739943
[2019-03-23 12:10:39,840] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.1029115]
[2019-03-23 12:10:39,843] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [32.33223784, 51.15591653, 1.0, 2.0, 0.6426334881626936, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 722078.9349417954, 722078.9349417954, 169287.4843145193]
[2019-03-23 12:10:39,846] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 12:10:39,850] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.8129696e-24 1.0000000e+00 4.9614866e-34 1.6574956e-27 1.7657091e-33], sampled 0.3567066824577163
[2019-03-23 12:10:45,123] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 12:10:45,154] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 12:10:45,181] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 12:10:45,187] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 12:10:45,411] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 12:10:46,429] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 2325000, evaluation results [2325000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 12:10:47,457] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:10:47,459] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:10:47,510] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run12
[2019-03-23 12:10:48,080] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.5924663e-27 1.0000000e+00 0.0000000e+00 1.8003322e-29 0.0000000e+00], sum to 1.0000
[2019-03-23 12:10:48,087] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8874
[2019-03-23 12:10:48,094] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.55, 77.0, 1.0, 2.0, 0.4807614692249967, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 522330.5743212356, 522330.5743212356, 125220.6565754012], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7720200.0000, 
sim time next is 7720800.0000, 
raw observation next is [18.83333333333333, 74.66666666666667, 1.0, 2.0, 0.540904886168033, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 587963.3069710518, 587963.3069710518, 130781.0764111765], 
processed observation next is [1.0, 0.34782608695652173, 0.4924242424242422, 0.7466666666666667, 1.0, 1.0, 0.4261311077100412, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21776418776705625, 0.21776418776705625, 0.318978235149211], 
reward next is 0.6810, 
noisyNet noise sample is [array([-1.1022567], dtype=float32), -0.0034414935]. 
=============================================
[2019-03-23 12:10:51,629] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.4204083e-29 1.0000000e+00 0.0000000e+00 4.2132517e-33 0.0000000e+00], sum to 1.0000
[2019-03-23 12:10:51,638] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8024
[2019-03-23 12:10:51,646] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.5, 72.0, 1.0, 2.0, 0.2179856979892436, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 236678.5994233573, 236678.599423357, 74197.07264871435], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7783200.0000, 
sim time next is 7783800.0000, 
raw observation next is [15.4, 72.66666666666667, 1.0, 2.0, 0.2517900547548409, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 273392.0926628388, 273392.092662839, 77335.49345909686], 
processed observation next is [1.0, 0.08695652173913043, 0.33636363636363636, 0.7266666666666667, 1.0, 1.0, 0.06473756844355111, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10125633061586622, 0.1012563306158663, 0.18862315477828503], 
reward next is 0.8114, 
noisyNet noise sample is [array([0.82280076], dtype=float32), 0.048883688]. 
=============================================
[2019-03-23 12:10:52,685] A3C_AGENT_WORKER-Thread-21 INFO:Local step 145500, global step 2328219: loss 0.3173
[2019-03-23 12:10:52,689] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 145500, global step 2328219: learning rate 0.0005
[2019-03-23 12:10:53,139] A3C_AGENT_WORKER-Thread-22 INFO:Local step 145500, global step 2328449: loss 0.3159
[2019-03-23 12:10:53,144] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 145500, global step 2328450: learning rate 0.0005
[2019-03-23 12:10:53,595] A3C_AGENT_WORKER-Thread-2 INFO:Local step 145500, global step 2328686: loss 0.1943
[2019-03-23 12:10:53,597] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 145500, global step 2328687: learning rate 0.0005
[2019-03-23 12:10:53,648] A3C_AGENT_WORKER-Thread-3 INFO:Local step 145500, global step 2328710: loss 0.2428
[2019-03-23 12:10:53,650] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 145500, global step 2328710: learning rate 0.0005
[2019-03-23 12:10:53,662] A3C_AGENT_WORKER-Thread-19 INFO:Local step 145500, global step 2328717: loss 0.2044
[2019-03-23 12:10:53,664] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 145500, global step 2328717: learning rate 0.0005
[2019-03-23 12:10:53,679] A3C_AGENT_WORKER-Thread-10 INFO:Local step 145500, global step 2328725: loss 0.2311
[2019-03-23 12:10:53,680] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 145500, global step 2328726: learning rate 0.0005
[2019-03-23 12:10:53,881] A3C_AGENT_WORKER-Thread-20 INFO:Local step 145500, global step 2328830: loss 0.1772
[2019-03-23 12:10:53,884] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 145500, global step 2328830: learning rate 0.0005
[2019-03-23 12:10:54,045] A3C_AGENT_WORKER-Thread-11 INFO:Local step 145500, global step 2328913: loss 0.1472
[2019-03-23 12:10:54,046] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 145500, global step 2328914: learning rate 0.0005
[2019-03-23 12:10:54,162] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0281074e-26 1.0000000e+00 1.1375664e-37 4.2764435e-29 5.3757616e-37], sum to 1.0000
[2019-03-23 12:10:54,169] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6058
[2019-03-23 12:10:54,173] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.75, 49.5, 1.0, 2.0, 0.3093574907835221, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 335920.0482797407, 335920.048279741, 111822.9896871576], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7839000.0000, 
sim time next is 7839600.0000, 
raw observation next is [22.56666666666667, 50.0, 1.0, 2.0, 0.3082604536332263, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 334728.4055564363, 334728.4055564366, 111747.6676903575], 
processed observation next is [1.0, 0.7391304347826086, 0.6621212121212122, 0.5, 1.0, 1.0, 0.13532556704153284, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12397348353942085, 0.12397348353942098, 0.27255528704965243], 
reward next is 0.7274, 
noisyNet noise sample is [array([-0.71440494], dtype=float32), -2.701076]. 
=============================================
[2019-03-23 12:10:54,232] A3C_AGENT_WORKER-Thread-14 INFO:Local step 145500, global step 2329000: loss 0.1035
[2019-03-23 12:10:54,234] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 145500, global step 2329000: learning rate 0.0005
[2019-03-23 12:10:54,338] A3C_AGENT_WORKER-Thread-12 INFO:Local step 145500, global step 2329063: loss 0.0814
[2019-03-23 12:10:54,339] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 145500, global step 2329063: learning rate 0.0005
[2019-03-23 12:10:54,645] A3C_AGENT_WORKER-Thread-18 INFO:Local step 145500, global step 2329214: loss 0.0244
[2019-03-23 12:10:54,647] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 145500, global step 2329215: learning rate 0.0005
[2019-03-23 12:10:54,936] A3C_AGENT_WORKER-Thread-15 INFO:Local step 145500, global step 2329362: loss 0.0208
[2019-03-23 12:10:54,941] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 145500, global step 2329367: learning rate 0.0005
[2019-03-23 12:10:55,223] A3C_AGENT_WORKER-Thread-17 INFO:Local step 145500, global step 2329506: loss 0.0133
[2019-03-23 12:10:55,224] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 145500, global step 2329507: learning rate 0.0005
[2019-03-23 12:10:55,602] A3C_AGENT_WORKER-Thread-16 INFO:Local step 145500, global step 2329703: loss 0.0666
[2019-03-23 12:10:55,603] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 145500, global step 2329703: learning rate 0.0005
[2019-03-23 12:11:00,824] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.3837585e-28 1.0000000e+00 1.2440120e-38 1.3581432e-29 3.3217402e-38], sum to 1.0000
[2019-03-23 12:11:00,825] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4729
[2019-03-23 12:11:00,829] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.1, 92.0, 1.0, 2.0, 0.4536849421008701, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 517313.2486468707, 517313.2486468707, 134504.6780021505], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7932000.0000, 
sim time next is 7932600.0000, 
raw observation next is [21.1, 91.5, 1.0, 2.0, 0.4535550865938258, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 517085.8001779769, 517085.8001779769, 134355.740931565], 
processed observation next is [1.0, 0.8260869565217391, 0.5954545454545456, 0.915, 1.0, 1.0, 0.3169438582422822, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19151325932517663, 0.19151325932517663, 0.32769692910137804], 
reward next is 0.6723, 
noisyNet noise sample is [array([-1.0372263], dtype=float32), 0.4821642]. 
=============================================
[2019-03-23 12:11:00,876] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:11:00,877] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:11:00,909] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run12
[2019-03-23 12:11:01,208] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:11:01,208] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:11:01,248] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run12
[2019-03-23 12:11:01,745] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:11:01,745] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:11:01,753] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run12
[2019-03-23 12:11:01,785] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:11:01,786] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:11:01,793] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:11:01,794] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:11:01,807] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:11:01,807] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:11:01,812] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run12
[2019-03-23 12:11:01,839] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run12
[2019-03-23 12:11:01,863] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run12
[2019-03-23 12:11:02,000] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:11:02,000] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:11:02,006] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run12
[2019-03-23 12:11:02,093] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:11:02,093] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:11:02,104] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run12
[2019-03-23 12:11:02,188] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:11:02,188] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:11:02,191] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run12
[2019-03-23 12:11:02,219] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:11:02,220] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:11:02,244] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run12
[2019-03-23 12:11:02,302] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:11:02,303] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:11:02,306] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run12
[2019-03-23 12:11:02,409] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:11:02,409] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:11:02,412] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run12
[2019-03-23 12:11:02,504] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:11:02,504] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:11:02,507] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run12
[2019-03-23 12:11:02,557] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:11:02,558] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:11:02,564] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run12
[2019-03-23 12:11:08,943] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.6085038e-32 1.0000000e+00 0.0000000e+00 1.2677928e-31 0.0000000e+00], sum to 1.0000
[2019-03-23 12:11:08,951] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7176
[2019-03-23 12:11:08,957] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.66666666666667, 80.33333333333333, 1.0, 2.0, 0.2163740384530835, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 234928.3128455211, 234928.3128455208, 74393.54969384018], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 92400.0000, 
sim time next is 93000.0000, 
raw observation next is [14.33333333333333, 81.16666666666667, 1.0, 2.0, 0.2124794135135589, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 230698.7173875274, 230698.7173875277, 73415.6620964039], 
processed observation next is [1.0, 0.043478260869565216, 0.28787878787878773, 0.8116666666666668, 1.0, 1.0, 0.015599266891948606, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08544396940278792, 0.08544396940278803, 0.17906259047903392], 
reward next is 0.8209, 
noisyNet noise sample is [array([1.7187638], dtype=float32), -1.3523245]. 
=============================================
[2019-03-23 12:11:08,975] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[77.460495]
 [77.460495]
 [77.460495]
 [77.460495]
 [77.460495]], R is [[77.50682831]
 [77.55030823]
 [77.59107208]
 [77.62884521]
 [77.66332245]].
[2019-03-23 12:11:15,975] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.1785069e-32 1.0000000e+00 0.0000000e+00 4.2702077e-33 0.0000000e+00], sum to 1.0000
[2019-03-23 12:11:15,983] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6011
[2019-03-23 12:11:15,994] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.66666666666667, 92.0, 1.0, 2.0, 0.2989998852750671, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 324669.3467164041, 324669.3467164038, 111124.7446743036], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 242400.0000, 
sim time next is 243000.0000, 
raw observation next is [16.5, 91.0, 1.0, 2.0, 0.2905167249307224, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 315454.91032479, 315454.9103247897, 105906.3010700568], 
processed observation next is [0.0, 0.8260869565217391, 0.38636363636363635, 0.91, 1.0, 1.0, 0.11314590616340298, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11683515197214445, 0.11683515197214434, 0.25830805139038243], 
reward next is 0.7417, 
noisyNet noise sample is [array([0.25574383], dtype=float32), 0.965284]. 
=============================================
[2019-03-23 12:11:16,012] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[76.42953]
 [76.42953]
 [76.42953]
 [76.42953]
 [76.42953]], R is [[76.40692139]
 [76.37181854]
 [76.33493805]
 [76.29711914]
 [76.26165009]].
[2019-03-23 12:11:25,165] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.720292e-35 1.000000e+00 0.000000e+00 7.735046e-37 0.000000e+00], sum to 1.0000
[2019-03-23 12:11:25,174] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1025
[2019-03-23 12:11:25,180] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.33333333333333, 70.66666666666667, 1.0, 2.0, 0.221455076066828, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 240446.4177449626, 240446.4177449626, 76439.789555175], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 412800.0000, 
sim time next is 413400.0000, 
raw observation next is [16.16666666666667, 71.33333333333333, 1.0, 2.0, 0.218525003962588, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 237264.2952555351, 237264.2952555351, 75874.8063919215], 
processed observation next is [1.0, 0.782608695652174, 0.37121212121212144, 0.7133333333333333, 1.0, 1.0, 0.023156254953234992, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08787566490945745, 0.08787566490945745, 0.1850605033949305], 
reward next is 0.8149, 
noisyNet noise sample is [array([-0.26338604], dtype=float32), -0.9352472]. 
=============================================
[2019-03-23 12:11:36,285] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-23 12:11:36,287] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 12:11:36,288] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 12:11:36,289] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 12:11:36,291] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:11:36,290] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:11:36,292] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:11:36,291] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 12:11:36,291] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 12:11:36,294] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:11:36,295] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:11:36,319] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run95
[2019-03-23 12:11:36,346] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run95
[2019-03-23 12:11:36,373] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run95
[2019-03-23 12:11:36,373] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run95
[2019-03-23 12:11:36,430] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run95
[2019-03-23 12:11:55,695] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.1387533]
[2019-03-23 12:11:55,696] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.47075601, 99.41738724, 1.0, 2.0, 0.519978545478548, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 592890.4330665345, 592890.4330665345, 146162.5092629806]
[2019-03-23 12:11:55,697] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 12:11:55,699] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [5.092503e-30 1.000000e+00 0.000000e+00 8.967587e-34 0.000000e+00], sampled 0.4286976932985871
[2019-03-23 12:12:16,276] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.1387533]
[2019-03-23 12:12:16,277] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [26.83333333333333, 70.66666666666667, 1.0, 2.0, 0.7011420819373301, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9825122868738321, 6.9112, 6.9112, 77.32846344354104, 1339576.929300048, 1339576.929300048, 297046.2556643212]
[2019-03-23 12:12:16,278] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 12:12:16,280] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [5.092503e-30 1.000000e+00 0.000000e+00 8.967587e-34 0.000000e+00], sampled 0.9881370651074066
[2019-03-23 12:12:16,281] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1339576.929300048 W.
[2019-03-23 12:12:17,406] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.1387533]
[2019-03-23 12:12:17,408] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.38333333333333, 80.66666666666666, 1.0, 2.0, 0.7550380053824385, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 861590.1771095198, 861590.1771095198, 180148.8999624951]
[2019-03-23 12:12:17,409] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 12:12:17,412] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.092503e-30 1.000000e+00 0.000000e+00 8.967587e-34 0.000000e+00], sampled 0.030002875211659896
[2019-03-23 12:12:27,671] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.1387533]
[2019-03-23 12:12:27,674] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.8, 87.0, 1.0, 2.0, 0.5111530046074786, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 582986.4965115038, 582986.4965115038, 147514.2181226289]
[2019-03-23 12:12:27,676] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 12:12:27,678] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.092503e-30 1.000000e+00 0.000000e+00 8.967587e-34 0.000000e+00], sampled 0.7168366346341326
[2019-03-23 12:12:28,849] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.1387533]
[2019-03-23 12:12:28,851] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.2, 91.0, 1.0, 2.0, 0.502405020164185, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 573083.9499934383, 573083.9499934383, 146308.7730423326]
[2019-03-23 12:12:28,854] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 12:12:28,857] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.092503e-30 1.000000e+00 0.000000e+00 8.967587e-34 0.000000e+00], sampled 0.5015387927971897
[2019-03-23 12:13:14,441] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 12:13:15,529] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 12:13:15,545] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 12:13:15,560] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 12:13:15,656] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 12:13:16,673] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 2350000, evaluation results [2350000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 12:13:22,584] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.2798756e-22 1.0000000e+00 4.0852792e-31 4.4724439e-25 3.1378789e-30], sum to 1.0000
[2019-03-23 12:13:22,592] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2866
[2019-03-23 12:13:22,597] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1157850.728289209 W.
[2019-03-23 12:13:22,600] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.33333333333334, 57.0, 1.0, 2.0, 0.5093199046799534, 1.0, 2.0, 0.5093199046799534, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1157850.728289209, 1157850.728289209, 233851.4686825424], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 735600.0000, 
sim time next is 736200.0000, 
raw observation next is [27.5, 56.5, 1.0, 2.0, 0.4441328469955351, 0.0, 1.0, 0.0, 1.0, 1.0, 0.898768659976927, 6.9112, 6.9112, 77.32846344354104, 1012772.035039784, 1012772.035039784, 241926.7795684996], 
processed observation next is [1.0, 0.5217391304347826, 0.8863636363636364, 0.565, 1.0, 1.0, 0.3051660587444189, 0.0, 0.5, -0.25, 1.0, 0.5, 0.8553837999670387, 0.0, 0.0, 0.5084288129206541, 0.37510075371843854, 0.37510075371843854, 0.5900653160207308], 
reward next is 0.4099, 
noisyNet noise sample is [array([0.9384232], dtype=float32), -1.0331738]. 
=============================================
[2019-03-23 12:13:25,844] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.5787366e-25 1.0000000e+00 6.3254819e-36 9.1711871e-33 1.2399251e-35], sum to 1.0000
[2019-03-23 12:13:25,853] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1238
[2019-03-23 12:13:25,858] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 94.0, 1.0, 2.0, 0.3865278008094295, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 435546.4345235295, 435546.4345235295, 123635.4395580438], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 795600.0000, 
sim time next is 796200.0000, 
raw observation next is [19.0, 94.00000000000001, 1.0, 2.0, 0.3863486345789148, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 435344.8144455772, 435344.8144455772, 123619.7698330344], 
processed observation next is [0.0, 0.21739130434782608, 0.5, 0.9400000000000002, 1.0, 1.0, 0.23293579322364344, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1612388201650286, 0.1612388201650286, 0.3015116337391083], 
reward next is 0.6985, 
noisyNet noise sample is [array([-1.6650709], dtype=float32), 0.67514986]. 
=============================================
[2019-03-23 12:13:30,428] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.3511500e-29 1.0000000e+00 0.0000000e+00 2.4791115e-33 0.0000000e+00], sum to 1.0000
[2019-03-23 12:13:30,436] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1866
[2019-03-23 12:13:30,442] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 78.0, 1.0, 2.0, 0.4515830109197326, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 514939.8020370846, 514939.8020370843, 134327.4099053543], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 900000.0000, 
sim time next is 900600.0000, 
raw observation next is [23.0, 78.83333333333333, 1.0, 2.0, 0.4542270752342902, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 518061.9530783548, 518061.9530783548, 134818.6013138615], 
processed observation next is [0.0, 0.43478260869565216, 0.6818181818181818, 0.7883333333333333, 1.0, 1.0, 0.3177838440428627, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1918747974364277, 0.1918747974364277, 0.3288258568630768], 
reward next is 0.6712, 
noisyNet noise sample is [array([0.7818226], dtype=float32), 1.3634138]. 
=============================================
[2019-03-23 12:13:32,328] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.7757350e-31 1.0000000e+00 0.0000000e+00 2.9205627e-32 0.0000000e+00], sum to 1.0000
[2019-03-23 12:13:32,337] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5893
[2019-03-23 12:13:32,342] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.16666666666666, 86.33333333333334, 1.0, 2.0, 0.4295206182517314, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 488532.4373909666, 488532.4373909666, 130529.7281489647], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 928200.0000, 
sim time next is 928800.0000, 
raw observation next is [21.0, 88.0, 1.0, 2.0, 0.4318996757832138, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 491351.3759890615, 491351.3759890615, 130871.2684083287], 
processed observation next is [0.0, 0.782608695652174, 0.5909090909090909, 0.88, 1.0, 1.0, 0.2898745947290172, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18198199110705982, 0.18198199110705982, 0.31919821563007], 
reward next is 0.6808, 
noisyNet noise sample is [array([-0.22807555], dtype=float32), 1.0656137]. 
=============================================
[2019-03-23 12:13:32,820] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.7584475e-29 1.0000000e+00 0.0000000e+00 6.2786014e-29 0.0000000e+00], sum to 1.0000
[2019-03-23 12:13:32,828] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5117
[2019-03-23 12:13:32,837] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.3991086409323223, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 452409.8494825044, 452409.8494825044, 126364.1651010073], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 960600.0000, 
sim time next is 961200.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.3984131697666638, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 451619.1309941771, 451619.1309941771, 126297.9994769896], 
processed observation next is [1.0, 0.13043478260869565, 0.5, 1.0, 1.0, 1.0, 0.24801646220832974, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16726634481265817, 0.16726634481265817, 0.30804390116338926], 
reward next is 0.6920, 
noisyNet noise sample is [array([-0.59278136], dtype=float32), -2.9968379]. 
=============================================
[2019-03-23 12:13:34,117] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.0046517e-28 1.0000000e+00 0.0000000e+00 1.6782205e-31 0.0000000e+00], sum to 1.0000
[2019-03-23 12:13:34,124] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4048
[2019-03-23 12:13:34,128] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.418998825165494, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 475011.7512734497, 475011.75127345, 128275.307096027], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 962400.0000, 
sim time next is 963000.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4113056906518553, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 466268.5387472646, 466268.5387472649, 127529.0012909917], 
processed observation next is [1.0, 0.13043478260869565, 0.5, 1.0, 1.0, 1.0, 0.26413211331481906, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17269205138787577, 0.17269205138787588, 0.3110463446121749], 
reward next is 0.6890, 
noisyNet noise sample is [array([-0.70946366], dtype=float32), 0.8904514]. 
=============================================
[2019-03-23 12:13:34,141] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[70.912964]
 [70.912964]
 [70.912964]
 [70.912964]
 [70.912964]], R is [[70.89278412]
 [70.87098694]
 [70.8438797 ]
 [70.82740021]
 [70.81092072]].
[2019-03-23 12:13:37,294] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.7622980e-33 1.0000000e+00 0.0000000e+00 5.6768645e-33 0.0000000e+00], sum to 1.0000
[2019-03-23 12:13:37,302] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4119
[2019-03-23 12:13:37,309] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.16666666666667, 99.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 189535.1636603689, 189535.1636603691, 66614.60605883678], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1039800.0000, 
sim time next is 1040400.0000, 
raw observation next is [12.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 187160.2473436404, 187160.2473436404, 66059.97599449342], 
processed observation next is [1.0, 0.043478260869565216, 0.18181818181818182, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.06931861012727422, 0.06931861012727422, 0.16112189266949614], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8508779], dtype=float32), 1.2635802]. 
=============================================
[2019-03-23 12:13:37,814] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.0611204e-32 1.0000000e+00 0.0000000e+00 2.5134718e-38 0.0000000e+00], sum to 1.0000
[2019-03-23 12:13:37,815] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6147
[2019-03-23 12:13:37,823] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4780705757969322, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 545472.2369381172, 545472.2369381172, 138883.5528813924], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1461600.0000, 
sim time next is 1462200.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.4815976148244263, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 549476.6459192825, 549476.6459192827, 139370.7110582046], 
processed observation next is [0.0, 0.9565217391304348, 0.5909090909090909, 1.0, 1.0, 1.0, 0.35199701853053283, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2035098688589935, 0.20350986885899358, 0.33992856355659656], 
reward next is 0.6601, 
noisyNet noise sample is [array([1.1835753], dtype=float32), -0.66138655]. 
=============================================
[2019-03-23 12:13:44,304] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.7072804e-27 1.0000000e+00 2.0330901e-37 4.6576953e-30 1.1546659e-36], sum to 1.0000
[2019-03-23 12:13:44,313] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1410
[2019-03-23 12:13:44,318] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.16666666666667, 82.16666666666667, 1.0, 2.0, 0.7213358074391799, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 818680.3407805809, 818680.3407805811, 163962.5713377817], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1156200.0000, 
sim time next is 1156800.0000, 
raw observation next is [21.33333333333334, 81.33333333333334, 1.0, 2.0, 0.7014712316643928, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 796461.0673564717, 796461.0673564714, 161495.6168095935], 
processed observation next is [1.0, 0.391304347826087, 0.6060606060606063, 0.8133333333333335, 1.0, 1.0, 0.6268390395804909, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2949855805023969, 0.2949855805023968, 0.39389174831608176], 
reward next is 0.6061, 
noisyNet noise sample is [array([-0.7781242], dtype=float32), -0.30411693]. 
=============================================
[2019-03-23 12:13:48,659] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0953287e-27 1.0000000e+00 2.1911853e-38 8.8428765e-28 1.4153833e-38], sum to 1.0000
[2019-03-23 12:13:48,665] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7224
[2019-03-23 12:13:48,671] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1410310.637796592 W.
[2019-03-23 12:13:48,676] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.0, 65.0, 1.0, 2.0, 0.6217231106288778, 1.0, 2.0, 0.6217231106288778, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32845516329904, 1410310.637796592, 1410310.637796592, 264895.8906844942], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1251000.0000, 
sim time next is 1251600.0000, 
raw observation next is [26.0, 65.0, 1.0, 2.0, 0.6088397702827674, 1.0, 2.0, 0.6088397702827674, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846339228564, 1382141.91735246, 1382141.91735246, 260839.5766997651], 
processed observation next is [1.0, 0.4782608695652174, 0.8181818181818182, 0.65, 1.0, 1.0, 0.5110497128534591, 1.0, 1.0, 0.5110497128534591, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288125836537, 0.5119044138342445, 0.5119044138342445, 0.6361940895116223], 
reward next is 0.3638, 
noisyNet noise sample is [array([0.2574669], dtype=float32), 0.22290987]. 
=============================================
[2019-03-23 12:13:53,114] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.2898482e-26 1.0000000e+00 1.9274857e-36 4.7801645e-32 1.3847358e-35], sum to 1.0000
[2019-03-23 12:13:53,121] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5366
[2019-03-23 12:13:53,127] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1308596.567233284 W.
[2019-03-23 12:13:53,130] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.33333333333333, 82.33333333333334, 1.0, 2.0, 0.6762287670243718, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9853575620110065, 6.911200000000001, 6.9112, 77.32846344354104, 1308596.567233284, 1308596.567233283, 295449.5596308396], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1334400.0000, 
sim time next is 1335000.0000, 
raw observation next is [25.66666666666667, 80.66666666666667, 1.0, 2.0, 0.3985726890948947, 1.0, 1.0, 0.3985726890948947, 1.0, 2.0, 0.8064637818910906, 6.911199999999999, 6.9112, 77.3421103, 1344521.583277771, 1344521.583277771, 306660.0613464959], 
processed observation next is [1.0, 0.43478260869565216, 0.8030303030303032, 0.8066666666666668, 1.0, 1.0, 0.24821586136861834, 1.0, 0.5, 0.24821586136861834, 1.0, 1.0, 0.7235196884158438, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.49797095676954484, 0.49797095676954484, 0.7479513691377948], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.37613967], dtype=float32), 0.6593743]. 
=============================================
[2019-03-23 12:13:53,150] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[68.48067]
 [68.48067]
 [68.48067]
 [68.48067]
 [68.48067]], R is [[67.79585266]
 [67.39728546]
 [67.11316681]
 [66.83744049]
 [66.443573  ]].
[2019-03-23 12:13:59,395] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.5538817e-30 1.0000000e+00 0.0000000e+00 3.8409116e-32 0.0000000e+00], sum to 1.0000
[2019-03-23 12:13:59,401] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4604
[2019-03-23 12:13:59,403] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 47.0, 1.0, 2.0, 0.309980940019968, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 336597.2634253992, 336597.2634253989, 110003.4741345148], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1879200.0000, 
sim time next is 1879800.0000, 
raw observation next is [22.83333333333334, 46.83333333333334, 1.0, 2.0, 0.3111514929586623, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 337868.7667345243, 337868.7667345246, 106673.0828546958], 
processed observation next is [1.0, 0.782608695652174, 0.6742424242424245, 0.46833333333333343, 1.0, 1.0, 0.13893936619832783, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12513658027204602, 0.12513658027204613, 0.2601782508651117], 
reward next is 0.7398, 
noisyNet noise sample is [array([0.408526], dtype=float32), 1.7294825]. 
=============================================
[2019-03-23 12:14:05,755] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-23 12:14:05,755] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 12:14:05,756] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 12:14:05,757] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 12:14:05,757] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:14:05,758] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 12:14:05,759] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:14:05,757] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 12:14:05,758] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:14:05,761] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:14:05,763] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:14:05,780] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run96
[2019-03-23 12:14:05,806] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run96
[2019-03-23 12:14:05,807] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run96
[2019-03-23 12:14:05,807] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run96
[2019-03-23 12:14:05,878] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run96
[2019-03-23 12:14:11,614] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.1280876]
[2019-03-23 12:14:11,614] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [13.0, 100.0, 1.0, 2.0, 0.4722200495574138, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 512859.8490255371, 512859.8490255371, 102644.7200247529]
[2019-03-23 12:14:11,616] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 12:14:11,618] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.2050243e-28 1.0000000e+00 0.0000000e+00 9.6012492e-32 1.2261090e-38], sampled 0.2250482952710523
[2019-03-23 12:14:16,607] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.1280876]
[2019-03-23 12:14:16,609] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [28.65, 40.0, 1.0, 2.0, 0.3980213608815903, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 450700.5646036819, 450700.5646036814, 130276.705015607]
[2019-03-23 12:14:16,611] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 12:14:16,613] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.2050243e-28 1.0000000e+00 0.0000000e+00 9.6012492e-32 1.2261090e-38], sampled 0.5996932965651743
[2019-03-23 12:14:19,951] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.1280876]
[2019-03-23 12:14:19,951] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.58333333333334, 89.66666666666666, 1.0, 2.0, 0.417607026725378, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 474558.7168172726, 474558.7168172726, 133330.4264772344]
[2019-03-23 12:14:19,954] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 12:14:19,958] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.2050243e-28 1.0000000e+00 0.0000000e+00 9.6012492e-32 1.2261090e-38], sampled 0.8653312890662436
[2019-03-23 12:14:50,302] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.1280876]
[2019-03-23 12:14:50,303] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.05, 74.5, 1.0, 2.0, 0.3883816322010852, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 435783.1644796785, 435783.1644796785, 127188.1510271414]
[2019-03-23 12:14:50,304] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 12:14:50,309] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.2050243e-28 1.0000000e+00 0.0000000e+00 9.6012492e-32 1.2261090e-38], sampled 0.9732149037633139
[2019-03-23 12:14:50,800] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.1280876]
[2019-03-23 12:14:50,801] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.33333333333333, 53.16666666666667, 1.0, 2.0, 0.3724271164578953, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 416730.4562197756, 416730.4562197756, 125277.2857812871]
[2019-03-23 12:14:50,804] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 12:14:50,808] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.2050243e-28 1.0000000e+00 0.0000000e+00 9.6012492e-32 1.2261090e-38], sampled 0.09367390345918736
[2019-03-23 12:15:01,177] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.1280876]
[2019-03-23 12:15:01,179] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.29279583, 77.46545749, 1.0, 2.0, 0.3819227017082342, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 426347.2945202485, 426347.2945202485, 125631.5120152471]
[2019-03-23 12:15:01,181] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 12:15:01,184] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.2050243e-28 1.0000000e+00 0.0000000e+00 9.6012492e-32 1.2261090e-38], sampled 0.4861397673144179
[2019-03-23 12:15:01,738] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.1280876]
[2019-03-23 12:15:01,739] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [15.62246215666667, 76.28837504, 1.0, 2.0, 0.2347607612737037, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 254884.2071123078, 254884.2071123078, 82505.56759199795]
[2019-03-23 12:15:01,741] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 12:15:01,745] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.2050243e-28 1.0000000e+00 0.0000000e+00 9.6012492e-32 1.2261090e-38], sampled 0.879893889281744
[2019-03-23 12:15:05,771] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.1280876]
[2019-03-23 12:15:05,773] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [25.26666666666667, 71.0, 1.0, 2.0, 0.5569318290448938, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 635008.5197119608, 635008.5197119605, 153447.6472940928]
[2019-03-23 12:15:05,775] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 12:15:05,779] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.2050243e-28 1.0000000e+00 0.0000000e+00 9.6012492e-32 1.2261090e-38], sampled 0.18057411414934488
[2019-03-23 12:15:13,703] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.1280876]
[2019-03-23 12:15:13,703] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.26403233333333, 98.72599241833333, 1.0, 2.0, 0.4393376518735624, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 494543.7350284749, 494543.7350284745, 132548.7740524923]
[2019-03-23 12:15:13,704] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 12:15:13,708] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.2050243e-28 1.0000000e+00 0.0000000e+00 9.6012492e-32 1.2261090e-38], sampled 0.20178507775907684
[2019-03-23 12:15:44,997] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 12:15:45,214] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 12:15:45,370] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 12:15:45,432] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 12:15:45,465] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 12:15:46,482] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 2375000, evaluation results [2375000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 12:16:02,606] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.2055322e-28 1.0000000e+00 0.0000000e+00 8.1087945e-37 0.0000000e+00], sum to 1.0000
[2019-03-23 12:16:02,614] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4416
[2019-03-23 12:16:02,619] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 64.0, 1.0, 2.0, 0.2646966779283038, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 287410.1655337132, 287410.1655337129, 90611.26177589445], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1894800.0000, 
sim time next is 1895400.0000, 
raw observation next is [19.0, 64.0, 1.0, 2.0, 0.2655136515464241, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 288297.5061692973, 288297.506169297, 90716.32014022746], 
processed observation next is [1.0, 0.9565217391304348, 0.5, 0.64, 1.0, 1.0, 0.0818920644330301, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10677685413677679, 0.10677685413677666, 0.22125931741518892], 
reward next is 0.7787, 
noisyNet noise sample is [array([-0.15434417], dtype=float32), 1.3868752]. 
=============================================
[2019-03-23 12:16:03,727] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.9774065e-35 1.0000000e+00 0.0000000e+00 9.9953924e-37 0.0000000e+00], sum to 1.0000
[2019-03-23 12:16:03,733] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1034
[2019-03-23 12:16:03,738] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 99.0, 1.0, 2.0, 0.3537632064187428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 396415.1271392336, 396415.1271392339, 119682.8134422142], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1914600.0000, 
sim time next is 1915200.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.3592023996607954, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 403051.4319507862, 403051.4319507864, 120391.1450816176], 
processed observation next is [1.0, 0.17391304347826086, 0.45454545454545453, 1.0, 1.0, 1.0, 0.19900299957599427, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14927830812992082, 0.14927830812992088, 0.29363693922345757], 
reward next is 0.7064, 
noisyNet noise sample is [array([0.9339364], dtype=float32), -1.274239]. 
=============================================
[2019-03-23 12:16:04,770] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.0678707e-27 1.0000000e+00 0.0000000e+00 2.0487268e-26 6.4562686e-37], sum to 1.0000
[2019-03-23 12:16:04,777] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3609
[2019-03-23 12:16:04,784] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 86.33333333333334, 1.0, 2.0, 0.7570184671527644, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344267261, 864103.6901828301, 864103.6901828301, 175465.6407946703], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1939800.0000, 
sim time next is 1940400.0000, 
raw observation next is [22.0, 88.0, 1.0, 2.0, 0.8496368577347198, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344353567, 969927.0499978571, 969927.0499978571, 189857.3809599094], 
processed observation next is [1.0, 0.4782608695652174, 0.6363636363636364, 0.88, 1.0, 1.0, 0.8120460721683997, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206188, 0.3592322407399471, 0.3592322407399471, 0.46306678282904734], 
reward next is 0.5369, 
noisyNet noise sample is [array([0.588315], dtype=float32), 0.6535826]. 
=============================================
[2019-03-23 12:16:09,549] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.7112397e-33 1.0000000e+00 0.0000000e+00 8.9037975e-37 0.0000000e+00], sum to 1.0000
[2019-03-23 12:16:09,557] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5875
[2019-03-23 12:16:09,564] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.0, 88.0, 1.0, 2.0, 0.2517329099393023, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 273330.027738332, 273330.027738332, 82327.78177216876], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2446200.0000, 
sim time next is 2446800.0000, 
raw observation next is [15.0, 88.0, 1.0, 2.0, 0.2497893592770945, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 271219.1441083864, 271219.1441083864, 82162.81700971616], 
processed observation next is [1.0, 0.30434782608695654, 0.3181818181818182, 0.88, 1.0, 1.0, 0.062236699096368114, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10045153485495793, 0.10045153485495793, 0.2003971146578443], 
reward next is 0.7996, 
noisyNet noise sample is [array([-0.29642564], dtype=float32), -1.0535423]. 
=============================================
[2019-03-23 12:16:12,377] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.3824211e-32 1.0000000e+00 0.0000000e+00 4.0133868e-33 0.0000000e+00], sum to 1.0000
[2019-03-23 12:16:12,387] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0925
[2019-03-23 12:16:12,394] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 78.66666666666666, 1.0, 2.0, 0.23740378308369, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 257767.4280007591, 257767.4280007594, 80591.92430553497], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2079600.0000, 
sim time next is 2080200.0000, 
raw observation next is [16.0, 77.83333333333334, 1.0, 2.0, 0.2335868736599859, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 253622.0372372143, 253622.0372372146, 79750.9187189844], 
processed observation next is [0.0, 0.043478260869565216, 0.36363636363636365, 0.7783333333333334, 1.0, 1.0, 0.04198359207498236, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09393408786563492, 0.09393408786563504, 0.19451443589996192], 
reward next is 0.8055, 
noisyNet noise sample is [array([1.1911938], dtype=float32), 0.16907772]. 
=============================================
[2019-03-23 12:16:20,794] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.4707694e-27 1.0000000e+00 0.0000000e+00 6.8440388e-30 1.2590409e-38], sum to 1.0000
[2019-03-23 12:16:20,802] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5087
[2019-03-23 12:16:20,808] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.83333333333334, 94.00000000000001, 1.0, 2.0, 0.3323015311661696, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 362832.5001064336, 362832.5001064339, 114094.4408515917], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2239800.0000, 
sim time next is 2240400.0000, 
raw observation next is [16.66666666666667, 94.0, 1.0, 2.0, 0.3272437303746799, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 356100.143404027, 356100.1434040273, 113313.3795391986], 
processed observation next is [1.0, 0.9565217391304348, 0.39393939393939414, 0.94, 1.0, 1.0, 0.15905466296834986, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13188894200149148, 0.1318889420014916, 0.2763740964370698], 
reward next is 0.7236, 
noisyNet noise sample is [array([-0.20285527], dtype=float32), -0.29462266]. 
=============================================
[2019-03-23 12:16:26,077] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.7912594e-34 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 12:16:26,085] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4047
[2019-03-23 12:16:26,095] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 55.0, 1.0, 2.0, 0.2346765229655419, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 254805.4576203535, 254805.4576203532, 74275.92582887011], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2324400.0000, 
sim time next is 2325000.0000, 
raw observation next is [17.0, 55.0, 1.0, 2.0, 0.2342898460118094, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 254385.5043881015, 254385.5043881012, 74238.98098956428], 
processed observation next is [1.0, 0.9130434782608695, 0.4090909090909091, 0.55, 1.0, 1.0, 0.04286230751476175, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09421685347707462, 0.09421685347707452, 0.1810706853404007], 
reward next is 0.8189, 
noisyNet noise sample is [array([0.59059703], dtype=float32), 0.3962075]. 
=============================================
[2019-03-23 12:16:26,110] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[80.96699]
 [80.96699]
 [80.96699]
 [80.96699]
 [80.96699]], R is [[80.97624207]
 [80.98532104]
 [80.9942627 ]
 [81.00304413]
 [81.01161194]].
[2019-03-23 12:16:35,427] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-23 12:16:35,428] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 12:16:35,428] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:16:35,429] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 12:16:35,429] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:16:35,435] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 12:16:35,436] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:16:35,437] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 12:16:35,437] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 12:16:35,440] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:16:35,441] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:16:35,458] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run97
[2019-03-23 12:16:35,459] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run97
[2019-03-23 12:16:35,511] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run97
[2019-03-23 12:16:35,511] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run97
[2019-03-23 12:16:35,559] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run97
[2019-03-23 12:16:55,515] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.1533778]
[2019-03-23 12:16:55,516] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [7.258679872666667, 66.68754291333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 140021.0061497067, 140021.0061497063, 60936.08189332834]
[2019-03-23 12:16:55,517] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 12:16:55,519] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [6.1456986e-33 1.0000000e+00 0.0000000e+00 4.5709203e-37 0.0000000e+00], sampled 0.8955889281148373
[2019-03-23 12:16:58,755] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.1533778]
[2019-03-23 12:16:58,756] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [25.1, 43.0, 1.0, 2.0, 0.3402452352327272, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 374540.3346201078, 374540.3346201075, 120076.3941073088]
[2019-03-23 12:16:58,756] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 12:16:58,758] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [6.1456986e-33 1.0000000e+00 0.0000000e+00 4.5709203e-37 0.0000000e+00], sampled 0.14812198829005396
[2019-03-23 12:17:00,345] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.1533778]
[2019-03-23 12:17:00,348] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [15.82427593, 76.37625799, 1.0, 2.0, 0.2297097400498653, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 249399.0799213389, 249399.0799213389, 82389.22419386744]
[2019-03-23 12:17:00,348] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 12:17:00,354] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [6.1456986e-33 1.0000000e+00 0.0000000e+00 4.5709203e-37 0.0000000e+00], sampled 0.48287320447940874
[2019-03-23 12:17:04,575] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.1533778]
[2019-03-23 12:17:04,576] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.28124820666667, 50.531133165, 1.0, 2.0, 0.3233099007965719, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 351051.7633842148, 351051.7633842151, 102140.6456936652]
[2019-03-23 12:17:04,576] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 12:17:04,579] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [6.1456986e-33 1.0000000e+00 0.0000000e+00 4.5709203e-37 0.0000000e+00], sampled 0.09989749227557299
[2019-03-23 12:17:08,226] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.1533778]
[2019-03-23 12:17:08,227] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.63333333333333, 74.66666666666667, 1.0, 2.0, 0.4558198638201472, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 519857.3605386144, 519857.3605386144, 139364.1128640904]
[2019-03-23 12:17:08,228] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 12:17:08,230] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [6.1456986e-33 1.0000000e+00 0.0000000e+00 4.5709203e-37 0.0000000e+00], sampled 0.5021302074264263
[2019-03-23 12:17:11,206] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.1533778]
[2019-03-23 12:17:11,206] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.19761394, 90.2877202, 1.0, 2.0, 0.4577203367355756, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 519952.1261002509, 519952.1261002506, 137178.3229428912]
[2019-03-23 12:17:11,207] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 12:17:11,210] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [6.1456986e-33 1.0000000e+00 0.0000000e+00 4.5709203e-37 0.0000000e+00], sampled 0.09921862577857676
[2019-03-23 12:17:30,409] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.1533778]
[2019-03-23 12:17:30,411] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.118977235, 91.66022520499999, 1.0, 2.0, 0.3481678815011228, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 386494.7478556917, 386494.7478556917, 121932.856426633]
[2019-03-23 12:17:30,412] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 12:17:30,415] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [6.1456986e-33 1.0000000e+00 0.0000000e+00 4.5709203e-37 0.0000000e+00], sampled 0.35387512606729554
[2019-03-23 12:18:15,292] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 12:18:15,306] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 12:18:15,380] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 12:18:15,438] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 12:18:15,447] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 12:18:16,465] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 2400000, evaluation results [2400000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 12:18:21,201] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.0018345e-31 1.0000000e+00 0.0000000e+00 2.8977182e-36 0.0000000e+00], sum to 1.0000
[2019-03-23 12:18:21,211] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6337
[2019-03-23 12:18:21,220] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.23333333333333, 89.00000000000001, 1.0, 2.0, 0.3046946669001047, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 331066.084637569, 331066.084637569, 111582.0363303281], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2596200.0000, 
sim time next is 2596800.0000, 
raw observation next is [17.16666666666667, 90.0, 1.0, 2.0, 0.3075314577131459, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 334507.9389383007, 334507.9389383004, 111898.9533027442], 
processed observation next is [0.0, 0.043478260869565216, 0.4166666666666669, 0.9, 1.0, 1.0, 0.13441432214143234, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12389182923640767, 0.12389182923640756, 0.2729242763481566], 
reward next is 0.7271, 
noisyNet noise sample is [array([1.8937624], dtype=float32), -0.68783516]. 
=============================================
[2019-03-23 12:18:23,143] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.3567600e-28 1.0000000e+00 0.0000000e+00 2.7944390e-27 1.2458124e-37], sum to 1.0000
[2019-03-23 12:18:23,156] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7519
[2019-03-23 12:18:23,164] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 61.0, 1.0, 2.0, 0.3853148165211973, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 435637.7025837762, 435637.7025837759, 124359.191404723], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2628000.0000, 
sim time next is 2628600.0000, 
raw observation next is [24.16666666666666, 58.66666666666667, 1.0, 2.0, 0.3817341741017874, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 430965.257263606, 430965.257263606, 123669.3541789237], 
processed observation next is [0.0, 0.43478260869565216, 0.7348484848484845, 0.5866666666666667, 1.0, 1.0, 0.22716771762723423, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1596167619494837, 0.1596167619494837, 0.3016325711681066], 
reward next is 0.6984, 
noisyNet noise sample is [array([-1.0440767], dtype=float32), 0.73352075]. 
=============================================
[2019-03-23 12:18:24,856] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.8520391e-30 1.0000000e+00 0.0000000e+00 6.9846433e-38 0.0000000e+00], sum to 1.0000
[2019-03-23 12:18:24,862] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5055
[2019-03-23 12:18:24,868] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.13333333333333, 86.5, 1.0, 2.0, 0.3337410210009448, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 367219.0439096661, 367219.0439096658, 115215.2644516828], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2688600.0000, 
sim time next is 2689200.0000, 
raw observation next is [18.0, 87.0, 1.0, 2.0, 0.3313946150528904, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 364161.6539481933, 364161.6539481935, 114864.6702881015], 
processed observation next is [0.0, 0.13043478260869565, 0.45454545454545453, 0.87, 1.0, 1.0, 0.164243268816113, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.134874686647479, 0.13487468664747906, 0.28015773241000363], 
reward next is 0.7198, 
noisyNet noise sample is [array([0.04257994], dtype=float32), -0.4504852]. 
=============================================
[2019-03-23 12:18:25,683] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0205082e-32 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 12:18:25,690] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7969
[2019-03-23 12:18:25,697] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.08333333333333, 93.5, 1.0, 2.0, 0.41090534374979, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 466752.4943498238, 466752.4943498241, 128185.2223373235], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2707800.0000, 
sim time next is 2708400.0000, 
raw observation next is [20.36666666666667, 92.0, 1.0, 2.0, 0.4164031128496326, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 473307.4788793892, 473307.4788793892, 128969.5577554427], 
processed observation next is [0.0, 0.34782608695652173, 0.5621212121212124, 0.92, 1.0, 1.0, 0.2705038910620407, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1752990662516256, 0.1752990662516256, 0.3145598969644944], 
reward next is 0.6854, 
noisyNet noise sample is [array([0.96020776], dtype=float32), 1.2294236]. 
=============================================
[2019-03-23 12:18:29,621] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.4532891e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 12:18:29,627] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7541
[2019-03-23 12:18:29,630] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 88.0, 1.0, 2.0, 0.3411367132002599, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 375654.7686219086, 375654.7686219083, 115876.3101548518], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2775600.0000, 
sim time next is 2776200.0000, 
raw observation next is [18.0, 88.00000000000001, 1.0, 2.0, 0.3424388086444347, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 376960.6195749479, 376960.6195749479, 115926.3604918991], 
processed observation next is [1.0, 0.13043478260869565, 0.45454545454545453, 0.8800000000000001, 1.0, 1.0, 0.17804851080554338, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13961504428701774, 0.13961504428701774, 0.282747220711949], 
reward next is 0.7173, 
noisyNet noise sample is [array([-2.398405], dtype=float32), -0.42610484]. 
=============================================
[2019-03-23 12:18:35,786] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.4216134e-28 1.0000000e+00 0.0000000e+00 2.1327739e-30 0.0000000e+00], sum to 1.0000
[2019-03-23 12:18:35,799] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3086
[2019-03-23 12:18:35,804] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 88.00000000000001, 1.0, 2.0, 0.4361145070986443, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 496166.9921515666, 496166.9921515666, 131312.0095320698], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2869800.0000, 
sim time next is 2870400.0000, 
raw observation next is [21.0, 88.0, 1.0, 2.0, 0.4264362840332547, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 485147.7040188604, 485147.7040188604, 130339.8583805397], 
processed observation next is [1.0, 0.21739130434782608, 0.5909090909090909, 0.88, 1.0, 1.0, 0.2830453550415683, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17968433482180016, 0.17968433482180016, 0.31790209361107247], 
reward next is 0.6821, 
noisyNet noise sample is [array([1.1171215], dtype=float32), 0.121395715]. 
=============================================
[2019-03-23 12:18:39,665] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.9670626e-28 1.0000000e+00 6.7876941e-38 3.4537953e-33 9.3056795e-38], sum to 1.0000
[2019-03-23 12:18:39,671] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6713
[2019-03-23 12:18:39,677] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.83333333333333, 84.0, 1.0, 2.0, 0.6677288971226779, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 760257.4359913166, 760257.4359913169, 165244.3629847116], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2965800.0000, 
sim time next is 2966400.0000, 
raw observation next is [24.0, 83.0, 1.0, 2.0, 0.6419925826211401, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 730867.841692091, 730867.8416920913, 161626.198763685], 
processed observation next is [1.0, 0.34782608695652173, 0.7272727272727273, 0.83, 1.0, 1.0, 0.5524907282764251, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.27069179321929293, 0.2706917932192931, 0.3942102408870366], 
reward next is 0.6058, 
noisyNet noise sample is [array([-0.77868783], dtype=float32), 0.19718097]. 
=============================================
[2019-03-23 12:18:40,904] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.3874884e-27 1.0000000e+00 5.7250015e-37 5.8585426e-33 2.6141779e-36], sum to 1.0000
[2019-03-23 12:18:40,911] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7389
[2019-03-23 12:18:40,917] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 57.0, 1.0, 2.0, 0.3075329166989773, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 336048.9775816051, 336048.9775816048, 112447.1318494113], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3319200.0000, 
sim time next is 3319800.0000, 
raw observation next is [22.0, 57.5, 1.0, 2.0, 0.3133745358257272, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 343109.9351921421, 343109.9351921419, 113098.499217152], 
processed observation next is [0.0, 0.43478260869565216, 0.6363636363636364, 0.575, 1.0, 1.0, 0.141718169782159, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12707775377486744, 0.12707775377486738, 0.2758499980906146], 
reward next is 0.7242, 
noisyNet noise sample is [array([-1.0834061], dtype=float32), 0.18409061]. 
=============================================
[2019-03-23 12:18:41,814] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0937121e-21 1.0000000e+00 2.2173617e-30 1.5779642e-21 1.0180330e-29], sum to 1.0000
[2019-03-23 12:18:41,825] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3098
[2019-03-23 12:18:41,831] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.66666666666666, 61.66666666666666, 1.0, 2.0, 0.4914329671750048, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 560624.7008966026, 560624.7008966026, 140729.4658734913], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3004800.0000, 
sim time next is 3005400.0000, 
raw observation next is [26.33333333333334, 63.33333333333334, 1.0, 2.0, 0.491642580228321, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 560883.1351516963, 560883.1351516963, 140704.0736336223], 
processed observation next is [1.0, 0.782608695652174, 0.8333333333333336, 0.6333333333333334, 1.0, 1.0, 0.36455322528540124, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20773449450062825, 0.20773449450062825, 0.34318066739907876], 
reward next is 0.6568, 
noisyNet noise sample is [array([0.03951601], dtype=float32), -0.1429302]. 
=============================================
[2019-03-23 12:18:42,728] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.8148018e-21 1.0000000e+00 9.5916361e-29 2.4764598e-22 8.8484396e-29], sum to 1.0000
[2019-03-23 12:18:42,735] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1628
[2019-03-23 12:18:42,743] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.33333333333334, 63.33333333333334, 1.0, 2.0, 0.49164258022911, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 560883.1351516963, 560883.1351516963, 140704.0736361161], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3005400.0000, 
sim time next is 3006000.0000, 
raw observation next is [26.0, 65.0, 1.0, 2.0, 0.491700124348527, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 560971.8633177746, 560971.8633177746, 140645.9113196254], 
processed observation next is [1.0, 0.8260869565217391, 0.8181818181818182, 0.65, 1.0, 1.0, 0.3646251554356587, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20776735678436098, 0.20776735678436098, 0.3430388080966473], 
reward next is 0.6570, 
noisyNet noise sample is [array([-1.0210636], dtype=float32), 0.11036541]. 
=============================================
[2019-03-23 12:18:42,759] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[46.759727]
 [46.759727]
 [46.759727]
 [46.759727]
 [46.759727]], R is [[46.94909286]
 [47.1364212 ]
 [47.32181549]
 [47.50536346]
 [47.68735123]].
[2019-03-23 12:18:43,714] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.1570597e-28 1.0000000e+00 0.0000000e+00 1.1187196e-33 1.2062489e-37], sum to 1.0000
[2019-03-23 12:18:43,718] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8521
[2019-03-23 12:18:43,721] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.66666666666667, 88.0, 1.0, 2.0, 0.3671620107911553, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 408785.9890284555, 408785.9890284555, 119615.8551349524], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3025200.0000, 
sim time next is 3025800.0000, 
raw observation next is [18.5, 88.0, 1.0, 2.0, 0.3627492294630079, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 402896.0491100359, 402896.0491100362, 118853.1199007454], 
processed observation next is [1.0, 0.0, 0.4772727272727273, 0.88, 1.0, 1.0, 0.20343653682875987, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14922075892964293, 0.14922075892964304, 0.28988565829450097], 
reward next is 0.7101, 
noisyNet noise sample is [array([-0.9004319], dtype=float32), 0.65930206]. 
=============================================
[2019-03-23 12:18:54,428] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.911578e-28 1.000000e+00 0.000000e+00 1.881960e-28 0.000000e+00], sum to 1.0000
[2019-03-23 12:18:54,441] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9118
[2019-03-23 12:18:54,445] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.5040677725826117, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 575123.6903119136, 575123.6903119136, 141970.7343893655], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3646800.0000, 
sim time next is 3647400.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.5459002545490951, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 622878.3251586256, 622878.3251586256, 146994.2329930154], 
processed observation next is [1.0, 0.21739130434782608, 0.5909090909090909, 1.0, 1.0, 1.0, 0.4323753181863688, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23069567598467616, 0.23069567598467616, 0.3585225194951595], 
reward next is 0.6415, 
noisyNet noise sample is [array([0.21715426], dtype=float32), 1.5574899]. 
=============================================
[2019-03-23 12:19:00,518] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.3155858e-27 1.0000000e+00 1.5501598e-38 3.1851192e-29 0.0000000e+00], sum to 1.0000
[2019-03-23 12:19:00,528] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7900
[2019-03-23 12:19:00,530] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.33333333333333, 86.33333333333334, 1.0, 2.0, 0.3434092992692609, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 379147.1357458245, 379147.1357458248, 116422.3887855161], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3369000.0000, 
sim time next is 3369600.0000, 
raw observation next is [18.0, 88.0, 1.0, 2.0, 0.3380878583267512, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 372418.467041028, 372418.4670410283, 115693.7170670328], 
processed observation next is [1.0, 0.0, 0.45454545454545453, 0.88, 1.0, 1.0, 0.172609822908439, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13793276557075113, 0.13793276557075124, 0.28217979772447027], 
reward next is 0.7178, 
noisyNet noise sample is [array([-1.1556988], dtype=float32), 1.4122324]. 
=============================================
[2019-03-23 12:19:00,641] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.6873376e-29 1.0000000e+00 0.0000000e+00 2.1950957e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 12:19:00,650] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8422
[2019-03-23 12:19:00,655] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 57.5, 1.0, 2.0, 0.50131787191308, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 571325.2736853424, 571325.2736853424, 142754.9094922339], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3693000.0000, 
sim time next is 3693600.0000, 
raw observation next is [28.0, 58.0, 1.0, 2.0, 0.5088059582960666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 579686.804494757, 579686.804494757, 143820.2656201661], 
processed observation next is [1.0, 0.782608695652174, 0.9090909090909091, 0.58, 1.0, 1.0, 0.3860074478700832, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21469881647953962, 0.21469881647953962, 0.3507811356589417], 
reward next is 0.6492, 
noisyNet noise sample is [array([0.17217487], dtype=float32), -0.49401557]. 
=============================================
[2019-03-23 12:19:02,303] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.6040888e-28 1.0000000e+00 0.0000000e+00 6.8683093e-30 3.2067933e-38], sum to 1.0000
[2019-03-23 12:19:02,315] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2434
[2019-03-23 12:19:02,322] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.00000000000001, 1.0, 2.0, 0.5800362274303857, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 661512.9430847705, 661512.9430847708, 151997.7682703103], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3726600.0000, 
sim time next is 3727200.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.5301341061760175, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 604587.7899913618, 604587.789991362, 145709.1961343667], 
processed observation next is [1.0, 0.13043478260869565, 0.6363636363636364, 0.94, 1.0, 1.0, 0.4126676327200219, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22392140370050437, 0.22392140370050445, 0.35538828325455296], 
reward next is 0.6446, 
noisyNet noise sample is [array([-0.5826206], dtype=float32), -0.93250144]. 
=============================================
[2019-03-23 12:19:02,524] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.2675066e-28 1.0000000e+00 0.0000000e+00 1.2788816e-32 0.0000000e+00], sum to 1.0000
[2019-03-23 12:19:02,534] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4026
[2019-03-23 12:19:02,537] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.5, 94.0, 1.0, 2.0, 0.4960671043883821, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 566059.2199567584, 566059.2199567584, 140668.4830938619], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3731400.0000, 
sim time next is 3732000.0000, 
raw observation next is [21.33333333333334, 94.0, 1.0, 2.0, 0.4906683607346901, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 559896.3445480973, 559896.3445480973, 139684.3847290995], 
processed observation next is [1.0, 0.17391304347826086, 0.6060606060606063, 0.94, 1.0, 1.0, 0.3633354509183626, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20736901649929532, 0.20736901649929532, 0.3406936212904866], 
reward next is 0.6593, 
noisyNet noise sample is [array([0.6297907], dtype=float32), -0.5737913]. 
=============================================
[2019-03-23 12:19:02,549] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[71.1133]
 [71.1133]
 [71.1133]
 [71.1133]
 [71.1133]], R is [[71.06147003]
 [71.00775909]
 [70.95078278]
 [70.87879181]
 [70.815979  ]].
[2019-03-23 12:19:03,775] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.3389185e-24 1.0000000e+00 1.2119523e-33 6.2602227e-25 7.8013806e-33], sum to 1.0000
[2019-03-23 12:19:03,787] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3085
[2019-03-23 12:19:03,790] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 71.5, 1.0, 2.0, 0.8764335482035671, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 998999.192415434, 998999.192415434, 190800.1032021579], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3407400.0000, 
sim time next is 3408000.0000, 
raw observation next is [24.0, 69.33333333333333, 1.0, 2.0, 0.9399427475439973, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1072037.614974204, 1072037.614974204, 202375.0153663342], 
processed observation next is [1.0, 0.43478260869565216, 0.7272727272727273, 0.6933333333333332, 1.0, 1.0, 0.9249284344299965, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.39705096850896443, 0.39705096850896443, 0.49359759845447365], 
reward next is 0.5064, 
noisyNet noise sample is [array([-0.10710245], dtype=float32), 2.024312]. 
=============================================
[2019-03-23 12:19:03,800] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[57.56536]
 [57.56536]
 [57.56536]
 [57.56536]
 [57.56536]], R is [[57.49610901]
 [57.45578384]
 [57.43836975]
 [57.4474144 ]
 [57.47966003]].
[2019-03-23 12:19:04,308] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.4299959e-24 1.0000000e+00 8.5201263e-34 7.8770877e-28 1.0021953e-31], sum to 1.0000
[2019-03-23 12:19:04,328] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4513
[2019-03-23 12:19:04,338] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1197073.686268837 W.
[2019-03-23 12:19:04,341] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.16666666666667, 60.66666666666667, 1.0, 2.0, 0.9963301262897434, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.098605381022887, 6.9112, 77.32809159745763, 1197073.686268837, 1136208.544296541, 219593.8972640391], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3417600.0000, 
sim time next is 3418200.0000, 
raw observation next is [27.25, 60.0, 1.0, 2.0, 0.5792733133454626, 1.0, 1.0, 0.5792733133454626, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32835082994941, 1315039.252121941, 1315039.252121941, 252705.6276510266], 
processed observation next is [1.0, 0.5652173913043478, 0.875, 0.6, 1.0, 1.0, 0.4740916416818282, 1.0, 0.5, 0.4740916416818282, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084280724947856, 0.48705157485997813, 0.48705157485997813, 0.6163551893927478], 
reward next is 0.3836, 
noisyNet noise sample is [array([0.619465], dtype=float32), 0.46307284]. 
=============================================
[2019-03-23 12:19:05,500] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-23 12:19:05,500] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 12:19:05,503] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:19:05,504] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 12:19:05,508] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 12:19:05,509] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:19:05,509] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 12:19:05,511] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 12:19:05,512] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:19:05,510] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:19:05,513] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:19:05,530] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run98
[2019-03-23 12:19:05,558] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run98
[2019-03-23 12:19:05,583] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run98
[2019-03-23 12:19:05,617] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run98
[2019-03-23 12:19:05,644] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run98
[2019-03-23 12:19:29,710] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.1654855]
[2019-03-23 12:19:29,712] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.2, 66.0, 1.0, 2.0, 0.252055002052693, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 273665.1666528782, 273665.1666528778, 89884.04223115151]
[2019-03-23 12:19:29,713] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 12:19:29,718] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.3687549e-27 1.0000000e+00 2.1639725e-38 5.1566784e-31 9.1823310e-38], sampled 0.43352511190441345
[2019-03-23 12:20:01,608] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.1654855]
[2019-03-23 12:20:01,609] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.0, 57.0, 1.0, 2.0, 0.6842009086534472, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 762039.3004734945, 762039.3004734945, 151773.7614009684]
[2019-03-23 12:20:01,610] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 12:20:01,613] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.3687549e-27 1.0000000e+00 2.1639725e-38 5.1566784e-31 9.1823310e-38], sampled 0.45387321074587106
[2019-03-23 12:20:26,504] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.1654855]
[2019-03-23 12:20:26,507] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.2, 58.5, 1.0, 2.0, 0.251750657391693, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 273349.3032270002, 273349.3032270005, 80242.35759293397]
[2019-03-23 12:20:26,508] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 12:20:26,511] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.3687549e-27 1.0000000e+00 2.1639725e-38 5.1566784e-31 9.1823310e-38], sampled 0.2774475635530528
[2019-03-23 12:20:43,274] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.1654855]
[2019-03-23 12:20:43,276] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [16.18333333333333, 80.83333333333333, 1.0, 2.0, 0.2464116640840944, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 267536.6283163794, 267536.628316379, 88502.90223502101]
[2019-03-23 12:20:43,277] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 12:20:43,283] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.3687549e-27 1.0000000e+00 2.1639725e-38 5.1566784e-31 9.1823310e-38], sampled 0.32918982157862653
[2019-03-23 12:20:44,554] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 12:20:44,855] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 12:20:45,023] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 12:20:45,133] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 12:20:45,145] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 12:20:46,165] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 2425000, evaluation results [2425000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 12:20:51,076] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.7925160e-26 1.0000000e+00 3.2538687e-36 2.2693290e-31 3.5398681e-34], sum to 1.0000
[2019-03-23 12:20:51,086] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6047
[2019-03-23 12:20:51,091] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.16666666666667, 88.0, 1.0, 2.0, 0.524395417825651, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 597319.8649620186, 597319.8649620182, 145826.9500212452], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3538200.0000, 
sim time next is 3538800.0000, 
raw observation next is [23.0, 89.0, 1.0, 2.0, 0.5223547271025781, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 595070.3828472575, 595070.3828472575, 145510.5035864907], 
processed observation next is [1.0, 1.0, 0.6818181818181818, 0.89, 1.0, 1.0, 0.4029434088782226, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22039643809157686, 0.22039643809157686, 0.35490366728412365], 
reward next is 0.6451, 
noisyNet noise sample is [array([-0.19875142], dtype=float32), 0.20811296]. 
=============================================
[2019-03-23 12:20:55,011] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.3260802e-21 1.0000000e+00 1.6365524e-30 7.9271768e-23 1.8547337e-29], sum to 1.0000
[2019-03-23 12:20:55,020] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3246
[2019-03-23 12:20:55,028] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4908950554917673, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 560088.3960884822, 560088.3960884825, 140437.6339953282], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3634800.0000, 
sim time next is 3635400.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.490679253970034, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 559842.0898119854, 559842.0898119856, 140412.7110575647], 
processed observation next is [1.0, 0.043478260869565216, 0.5909090909090909, 1.0, 1.0, 1.0, 0.3633490674625424, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20734892215258718, 0.20734892215258727, 0.34247002696967005], 
reward next is 0.6575, 
noisyNet noise sample is [array([0.06489642], dtype=float32), 0.17460787]. 
=============================================
[2019-03-23 12:20:56,326] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.1871320e-28 1.0000000e+00 0.0000000e+00 1.1355705e-32 4.0541997e-38], sum to 1.0000
[2019-03-23 12:20:56,336] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9895
[2019-03-23 12:20:56,342] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.5001222029649384, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 570620.1386743383, 570620.1386743383, 141509.0229889056], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3657600.0000, 
sim time next is 3658200.0000, 
raw observation next is [21.16666666666667, 99.00000000000001, 1.0, 2.0, 0.5215874337747878, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 595097.4480396548, 595097.4480396548, 144126.264629482], 
processed observation next is [1.0, 0.34782608695652173, 0.5984848484848487, 0.9900000000000001, 1.0, 1.0, 0.4019842922184847, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22040646223690916, 0.22040646223690916, 0.35152747470605367], 
reward next is 0.6485, 
noisyNet noise sample is [array([0.25739053], dtype=float32), -1.2306186]. 
=============================================
[2019-03-23 12:20:57,397] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.8962809e-29 1.0000000e+00 0.0000000e+00 2.5148797e-32 1.4938661e-37], sum to 1.0000
[2019-03-23 12:20:57,403] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6799
[2019-03-23 12:20:57,407] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.5170379440569611, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 589926.2664006088, 589926.2664006086, 143511.9261757722], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3648000.0000, 
sim time next is 3648600.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.5123787828842317, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 584609.551801616, 584609.551801616, 142952.9400470873], 
processed observation next is [1.0, 0.21739130434782608, 0.5909090909090909, 1.0, 1.0, 1.0, 0.3904734786052895, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21652205622282072, 0.21652205622282072, 0.3486657074319202], 
reward next is 0.6513, 
noisyNet noise sample is [array([-1.3111025], dtype=float32), -0.81482244]. 
=============================================
[2019-03-23 12:20:59,733] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.964454e-24 1.000000e+00 5.713730e-34 9.096543e-28 6.312980e-33], sum to 1.0000
[2019-03-23 12:20:59,739] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5660
[2019-03-23 12:20:59,742] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.66666666666667, 71.33333333333334, 1.0, 2.0, 0.5257290163227454, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 598717.7865568905, 598717.7865568905, 146092.0872793452], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3701400.0000, 
sim time next is 3702000.0000, 
raw observation next is [25.33333333333334, 72.66666666666667, 1.0, 2.0, 0.5230551280319528, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 595912.9779795525, 595912.9779795525, 145555.1053728565], 
processed observation next is [1.0, 0.8695652173913043, 0.7878787878787882, 0.7266666666666667, 1.0, 1.0, 0.4038189100399409, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2207085103627972, 0.2207085103627972, 0.35501245212891824], 
reward next is 0.6450, 
noisyNet noise sample is [array([0.89580786], dtype=float32), -0.5779867]. 
=============================================
[2019-03-23 12:20:59,779] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[58.313953]
 [58.313953]
 [58.313953]
 [58.313953]
 [58.313953]], R is [[58.37581253]
 [58.43572998]
 [58.49471283]
 [58.55448151]
 [58.61489105]].
[2019-03-23 12:21:03,999] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.2706116e-22 1.0000000e+00 1.4965499e-33 1.1800344e-28 1.9308012e-32], sum to 1.0000
[2019-03-23 12:21:04,009] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0296
[2019-03-23 12:21:04,014] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 64.83333333333334, 1.0, 2.0, 0.3361367847769481, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 369068.6863550889, 369068.6863550889, 115102.1615184756], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3780600.0000, 
sim time next is 3781200.0000, 
raw observation next is [21.0, 65.66666666666667, 1.0, 2.0, 0.3375268830561247, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 371336.5753512208, 371336.5753512208, 115478.3482341999], 
processed observation next is [1.0, 0.782608695652174, 0.5909090909090909, 0.6566666666666667, 1.0, 1.0, 0.17190860382015588, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1375320649448966, 0.1375320649448966, 0.28165450788829244], 
reward next is 0.7183, 
noisyNet noise sample is [array([-1.1659327], dtype=float32), -1.1893526]. 
=============================================
[2019-03-23 12:21:04,502] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.5944584e-29 1.0000000e+00 0.0000000e+00 3.4352978e-31 0.0000000e+00], sum to 1.0000
[2019-03-23 12:21:04,509] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4759
[2019-03-23 12:21:04,516] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 64.83333333333334, 1.0, 2.0, 0.3361367847770578, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 369068.6863550889, 369068.6863550889, 115102.1615184396], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3780600.0000, 
sim time next is 3781200.0000, 
raw observation next is [21.0, 65.66666666666667, 1.0, 2.0, 0.3375268830561626, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 371336.5753512208, 371336.5753512208, 115478.3482341872], 
processed observation next is [1.0, 0.782608695652174, 0.5909090909090909, 0.6566666666666667, 1.0, 1.0, 0.1719086038202032, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1375320649448966, 0.1375320649448966, 0.28165450788826146], 
reward next is 0.7183, 
noisyNet noise sample is [array([1.902598], dtype=float32), -0.21792533]. 
=============================================
[2019-03-23 12:21:04,619] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.4551135e-30 1.0000000e+00 0.0000000e+00 2.7061180e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 12:21:04,631] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1070
[2019-03-23 12:21:04,635] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 88.00000000000001, 1.0, 2.0, 0.3395718302808128, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 373734.3777948564, 373734.3777948564, 115685.4482557189], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3791400.0000, 
sim time next is 3792000.0000, 
raw observation next is [18.0, 88.0, 1.0, 2.0, 0.3391599595442182, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 373280.0349507944, 373280.0349507947, 115654.3235280237], 
processed observation next is [1.0, 0.9130434782608695, 0.45454545454545453, 0.88, 1.0, 1.0, 0.1739499494302727, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13825186479659052, 0.13825186479659063, 0.28208371592200904], 
reward next is 0.7179, 
noisyNet noise sample is [array([-0.75031686], dtype=float32), 0.15138163]. 
=============================================
[2019-03-23 12:21:04,651] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[74.180466]
 [74.180466]
 [74.180466]
 [74.180466]
 [74.180466]], R is [[74.15657806]
 [74.13285828]
 [74.10932922]
 [74.08592224]
 [74.06242371]].
[2019-03-23 12:21:04,874] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.9336695e-31 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 12:21:04,881] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2264
[2019-03-23 12:21:04,888] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 91.0, 1.0, 2.0, 0.315364517071785, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 342988.0075399734, 342988.0075399734, 112421.1669580742], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3814200.0000, 
sim time next is 3814800.0000, 
raw observation next is [17.0, 90.0, 1.0, 2.0, 0.311503041341496, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 338250.633865177, 338250.6338651773, 111970.0208367677], 
processed observation next is [0.0, 0.13043478260869565, 0.4090909090909091, 0.9, 1.0, 1.0, 0.13937880167686995, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12527801254265813, 0.12527801254265825, 0.2730976117969944], 
reward next is 0.7269, 
noisyNet noise sample is [array([-0.20039134], dtype=float32), 0.1271199]. 
=============================================
[2019-03-23 12:21:16,744] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.239985e-30 1.000000e+00 0.000000e+00 2.921865e-33 0.000000e+00], sum to 1.0000
[2019-03-23 12:21:16,750] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6911
[2019-03-23 12:21:16,758] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.83333333333333, 100.0, 1.0, 2.0, 0.6161839303050766, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 691207.4973044393, 691207.4973044393, 145886.0522570462], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4024200.0000, 
sim time next is 4024800.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.6365422849094531, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 715508.0359686835, 715508.0359686835, 148941.7863558311], 
processed observation next is [1.0, 0.6086956521739131, 0.45454545454545453, 1.0, 1.0, 1.0, 0.5456778561368163, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2650029762846976, 0.2650029762846976, 0.36327264964836853], 
reward next is 0.6367, 
noisyNet noise sample is [array([0.7074321], dtype=float32), 0.3382569]. 
=============================================
[2019-03-23 12:21:18,768] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.7200456e-30 1.0000000e+00 0.0000000e+00 1.2944842e-33 0.0000000e+00], sum to 1.0000
[2019-03-23 12:21:18,778] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6507
[2019-03-23 12:21:18,786] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 99.00000000000001, 1.0, 2.0, 0.3418083363438059, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 377815.785066045, 377815.785066045, 116470.2766634027], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4050600.0000, 
sim time next is 4051200.0000, 
raw observation next is [17.0, 98.0, 1.0, 2.0, 0.3392942508987573, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 374383.0668801391, 374383.0668801391, 116025.8204579618], 
processed observation next is [1.0, 0.9130434782608695, 0.4090909090909091, 0.98, 1.0, 1.0, 0.1741178136234466, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13866039514079226, 0.13866039514079226, 0.28298980599502876], 
reward next is 0.7170, 
noisyNet noise sample is [array([-0.5852812], dtype=float32), 0.45398256]. 
=============================================
[2019-03-23 12:21:23,714] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.7655013e-32 1.0000000e+00 0.0000000e+00 4.3654168e-36 0.0000000e+00], sum to 1.0000
[2019-03-23 12:21:23,718] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5748
[2019-03-23 12:21:23,722] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 94.0, 1.0, 2.0, 0.340910911120534, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 379230.6813988574, 379230.6813988572, 117382.6176120699], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4172400.0000, 
sim time next is 4173000.0000, 
raw observation next is [18.0, 94.00000000000001, 1.0, 2.0, 0.3464444955020998, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 385483.458429406, 385483.458429406, 117856.3115876496], 
processed observation next is [1.0, 0.30434782608695654, 0.45454545454545453, 0.9400000000000002, 1.0, 1.0, 0.18305561937762477, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14277165127015037, 0.14277165127015037, 0.2874544185064624], 
reward next is 0.7125, 
noisyNet noise sample is [array([-0.22350962], dtype=float32), 1.7063624]. 
=============================================
[2019-03-23 12:21:23,742] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[72.73128]
 [72.73128]
 [72.73128]
 [72.73128]
 [72.73128]], R is [[72.71650696]
 [72.70304108]
 [72.69035339]
 [72.67837524]
 [72.66703796]].
[2019-03-23 12:21:24,733] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.3764247e-27 1.0000000e+00 4.2339443e-38 2.9279475e-32 4.2368387e-37], sum to 1.0000
[2019-03-23 12:21:24,741] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7266
[2019-03-23 12:21:24,744] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.5, 59.0, 1.0, 2.0, 0.8205327032690592, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 930424.545706033, 930424.545706033, 177660.1512135432], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4199400.0000, 
sim time next is 4200000.0000, 
raw observation next is [24.66666666666666, 58.33333333333334, 1.0, 2.0, 0.873679165057013, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 991106.2640665829, 991106.2640665829, 186101.1679013683], 
processed observation next is [1.0, 0.6086956521739131, 0.7575757575757573, 0.5833333333333335, 1.0, 1.0, 0.8420989563212663, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3670763940987344, 0.3670763940987344, 0.4539052875643129], 
reward next is 0.5461, 
noisyNet noise sample is [array([1.5245333], dtype=float32), 0.16204877]. 
=============================================
[2019-03-23 12:21:24,757] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[68.74003]
 [68.74003]
 [68.74003]
 [68.74003]
 [68.74003]], R is [[68.59871674]
 [68.47940826]
 [68.35810089]
 [68.22134399]
 [68.09570312]].
[2019-03-23 12:21:26,943] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.854245e-29 1.000000e+00 0.000000e+00 4.850591e-32 0.000000e+00], sum to 1.0000
[2019-03-23 12:21:26,950] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3803
[2019-03-23 12:21:26,953] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 100.0, 1.0, 2.0, 0.3233718087013338, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 351367.8321992232, 351367.8321992229, 112864.6209123662], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4244400.0000, 
sim time next is 4245000.0000, 
raw observation next is [16.0, 100.0, 1.0, 2.0, 0.3333367412578361, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 362084.5634335249, 362084.5634335246, 113526.9457301415], 
processed observation next is [1.0, 0.13043478260869565, 0.36363636363636365, 1.0, 1.0, 1.0, 0.16667092657229507, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13410539386426848, 0.13410539386426837, 0.27689498958571096], 
reward next is 0.7231, 
noisyNet noise sample is [array([-2.8805382], dtype=float32), 0.6073112]. 
=============================================
[2019-03-23 12:21:26,973] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[72.38542]
 [72.38542]
 [72.38542]
 [72.38542]
 [72.38542]], R is [[72.3846817 ]
 [72.38555908]
 [72.3854599 ]
 [72.38407135]
 [72.38026428]].
[2019-03-23 12:21:27,331] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.3274418e-29 1.0000000e+00 0.0000000e+00 2.3821018e-33 0.0000000e+00], sum to 1.0000
[2019-03-23 12:21:27,341] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1671
[2019-03-23 12:21:27,347] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.33333333333333, 98.0, 1.0, 2.0, 0.3316846728518382, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 361406.2766921752, 361406.2766921755, 113789.3798949598], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4243200.0000, 
sim time next is 4243800.0000, 
raw observation next is [16.16666666666667, 99.0, 1.0, 2.0, 0.3266328228267243, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 355404.0476478515, 355404.0476478512, 113259.9193347355], 
processed observation next is [1.0, 0.08695652173913043, 0.37121212121212144, 0.99, 1.0, 1.0, 0.15829102853340535, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13163112875846353, 0.13163112875846342, 0.2762437056944768], 
reward next is 0.7238, 
noisyNet noise sample is [array([-0.6844482], dtype=float32), -0.55201566]. 
=============================================
[2019-03-23 12:21:34,582] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.2474448e-20 1.0000000e+00 2.2997456e-29 1.7833384e-23 9.5572305e-29], sum to 1.0000
[2019-03-23 12:21:34,587] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6751
[2019-03-23 12:21:34,593] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.16666666666666, 57.5, 1.0, 2.0, 0.4769958480661491, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 544277.285079412, 544277.2850794124, 138578.4471767173], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4387800.0000, 
sim time next is 4388400.0000, 
raw observation next is [27.0, 58.0, 1.0, 2.0, 0.4764709938433576, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 543689.9863066991, 543689.9863066991, 138394.0136000025], 
processed observation next is [1.0, 0.8260869565217391, 0.8636363636363636, 0.58, 1.0, 1.0, 0.345588742304197, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20136666159507374, 0.20136666159507374, 0.33754637463415244], 
reward next is 0.6625, 
noisyNet noise sample is [array([0.3818641], dtype=float32), -0.65696555]. 
=============================================
[2019-03-23 12:21:35,174] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-23 12:21:35,175] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 12:21:35,176] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 12:21:35,176] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:21:35,180] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:21:35,177] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 12:21:35,181] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 12:21:35,180] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 12:21:35,188] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:21:35,188] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:21:35,189] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:21:35,209] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run99
[2019-03-23 12:21:35,232] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run99
[2019-03-23 12:21:35,258] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run99
[2019-03-23 12:21:35,284] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run99
[2019-03-23 12:21:35,284] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run99
[2019-03-23 12:21:39,633] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.1294144]
[2019-03-23 12:21:39,635] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.66666666666666, 41.66666666666667, 1.0, 2.0, 0.2730114054705615, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 296441.1271587052, 296441.1271587052, 90043.01045059663]
[2019-03-23 12:21:39,635] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 12:21:39,638] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [8.1327404e-22 1.0000000e+00 2.6091449e-30 1.7064635e-24 7.9019988e-30], sampled 0.9416332662809119
[2019-03-23 12:21:48,372] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.1294144]
[2019-03-23 12:21:48,373] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.386917645, 74.63950071666667, 1.0, 2.0, 0.3912504640391651, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 435369.4329588402, 435369.4329588402, 125837.3124633072]
[2019-03-23 12:21:48,374] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 12:21:48,377] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [8.1327404e-22 1.0000000e+00 2.6091449e-30 1.7064635e-24 7.9019988e-30], sampled 0.9833097137360662
[2019-03-23 12:23:14,258] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 12:23:14,431] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 12:23:14,627] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 12:23:14,719] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 12:23:14,854] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 12:23:15,871] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 2450000, evaluation results [2450000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 12:23:17,031] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.7237780e-30 1.0000000e+00 0.0000000e+00 1.7115651e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 12:23:17,042] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4263
[2019-03-23 12:23:17,045] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.41666666666667, 81.33333333333333, 1.0, 2.0, 0.4559162884085881, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 519761.450702538, 519761.4507025382, 134576.89105694], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4407000.0000, 
sim time next is 4407600.0000, 
raw observation next is [22.33333333333334, 81.66666666666667, 1.0, 2.0, 0.4544456249962053, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 518032.8025996123, 518032.802599612, 134341.3759065451], 
processed observation next is [0.0, 0.0, 0.6515151515151518, 0.8166666666666668, 1.0, 1.0, 0.3180570312452566, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19186400096281936, 0.19186400096281925, 0.327661892454988], 
reward next is 0.6723, 
noisyNet noise sample is [array([-1.1162274], dtype=float32), 0.18834083]. 
=============================================
[2019-03-23 12:23:20,333] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.7284589e-29 1.0000000e+00 0.0000000e+00 1.1421567e-32 0.0000000e+00], sum to 1.0000
[2019-03-23 12:23:20,340] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1290
[2019-03-23 12:23:20,349] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.16666666666666, 93.0, 1.0, 2.0, 0.4704352814619768, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 536627.0455285223, 536627.0455285223, 136723.1388474938], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4485000.0000, 
sim time next is 4485600.0000, 
raw observation next is [21.0, 94.0, 1.0, 2.0, 0.4673550172585716, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 533070.0422720443, 533070.0422720443, 136287.7890894525], 
processed observation next is [0.0, 0.9565217391304348, 0.5909090909090909, 0.94, 1.0, 1.0, 0.33419377157321445, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19743334898964604, 0.19743334898964604, 0.33240924168159147], 
reward next is 0.6676, 
noisyNet noise sample is [array([-1.1293117], dtype=float32), -0.5343028]. 
=============================================
[2019-03-23 12:23:20,382] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.8476236e-28 1.0000000e+00 2.5625761e-38 6.4104872e-33 0.0000000e+00], sum to 1.0000
[2019-03-23 12:23:20,390] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2547
[2019-03-23 12:23:20,394] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.83333333333334, 89.00000000000001, 1.0, 2.0, 0.472680630644752, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 539302.812001997, 539302.8120019973, 137323.995405899], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4482600.0000, 
sim time next is 4483200.0000, 
raw observation next is [21.66666666666667, 90.0, 1.0, 2.0, 0.4715488403881134, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 537989.8148333466, 537989.8148333466, 137118.5604807483], 
processed observation next is [0.0, 0.9130434782608695, 0.6212121212121214, 0.9, 1.0, 1.0, 0.3394360504851417, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19925548697531356, 0.19925548697531356, 0.3344355133676788], 
reward next is 0.6656, 
noisyNet noise sample is [array([-1.0468038], dtype=float32), 0.031957414]. 
=============================================
[2019-03-23 12:23:23,229] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.0459954e-28 1.0000000e+00 0.0000000e+00 1.9487928e-29 0.0000000e+00], sum to 1.0000
[2019-03-23 12:23:23,235] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2589
[2019-03-23 12:23:23,238] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.411214281627138, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 466149.7439746224, 466149.7439746224, 127509.9575241226], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4509600.0000, 
sim time next is 4510200.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4113712844941463, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 466327.9541286997, 466327.9541286997, 127524.9551303941], 
processed observation next is [0.0, 0.17391304347826086, 0.5, 1.0, 1.0, 1.0, 0.2642141056176828, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1727140570847036, 0.1727140570847036, 0.3110364759277905], 
reward next is 0.6890, 
noisyNet noise sample is [array([0.8023697], dtype=float32), 0.060883224]. 
=============================================
[2019-03-23 12:23:27,739] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.4298495e-29 1.0000000e+00 0.0000000e+00 8.1853467e-28 0.0000000e+00], sum to 1.0000
[2019-03-23 12:23:27,745] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0763
[2019-03-23 12:23:27,750] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 45.0, 1.0, 2.0, 0.3828546905462714, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 415762.1038161949, 415762.1038161949, 111201.534304881], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4625400.0000, 
sim time next is 4626000.0000, 
raw observation next is [23.0, 44.0, 1.0, 2.0, 0.3654362921210751, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 396838.8269990796, 396838.8269990796, 107128.7522134045], 
processed observation next is [1.0, 0.5652173913043478, 0.6818181818181818, 0.44, 1.0, 1.0, 0.20679536515134384, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14697734333299245, 0.14697734333299245, 0.26128963954488904], 
reward next is 0.7387, 
noisyNet noise sample is [array([-1.4721076], dtype=float32), -0.07472844]. 
=============================================
[2019-03-23 12:23:27,767] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[76.75208]
 [76.75208]
 [76.75208]
 [76.75208]
 [76.75208]], R is [[76.7232666 ]
 [76.68480682]
 [76.63711548]
 [76.57646942]
 [76.50492096]].
[2019-03-23 12:23:29,917] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.5373385e-32 1.0000000e+00 0.0000000e+00 3.5907961e-37 0.0000000e+00], sum to 1.0000
[2019-03-23 12:23:29,928] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7218
[2019-03-23 12:23:29,937] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.66666666666666, 55.0, 1.0, 2.0, 0.2851531441933772, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 309629.0615509111, 309629.0615509111, 95523.75344281038], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4650000.0000, 
sim time next is 4650600.0000, 
raw observation next is [20.33333333333334, 55.5, 1.0, 2.0, 0.2814921438089044, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 305652.5725791477, 305652.5725791474, 92804.6584054801], 
processed observation next is [1.0, 0.8260869565217391, 0.5606060606060609, 0.555, 1.0, 1.0, 0.1018651797611305, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11320465651079545, 0.11320465651079534, 0.22635282537921977], 
reward next is 0.7736, 
noisyNet noise sample is [array([-0.30834365], dtype=float32), 0.30807418]. 
=============================================
[2019-03-23 12:23:30,799] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.5065257e-33 1.0000000e+00 0.0000000e+00 1.2998072e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 12:23:30,808] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3351
[2019-03-23 12:23:30,814] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.33333333333333, 86.0, 1.0, 2.0, 0.2092439617810899, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 227185.0175480972, 227185.0175480972, 74442.4012568119], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4678800.0000, 
sim time next is 4679400.0000, 
raw observation next is [14.16666666666667, 87.0, 1.0, 2.0, 0.209025117192314, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 226947.3532913747, 226947.3532913744, 74234.40818137574], 
processed observation next is [1.0, 0.13043478260869565, 0.28030303030303044, 0.87, 1.0, 1.0, 0.011281396490392497, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08405457529310174, 0.08405457529310163, 0.18105953214969692], 
reward next is 0.8189, 
noisyNet noise sample is [array([-0.07788564], dtype=float32), 0.17672984]. 
=============================================
[2019-03-23 12:23:40,502] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.6728546e-28 1.0000000e+00 0.0000000e+00 8.4128727e-33 0.0000000e+00], sum to 1.0000
[2019-03-23 12:23:40,507] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2481
[2019-03-23 12:23:40,513] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.43010038985941, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 487589.7338302037, 487589.7338302037, 129339.6793281695], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4863600.0000, 
sim time next is 4864200.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4480747105443938, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 508007.2507688553, 508007.250768855, 131134.0359658178], 
processed observation next is [1.0, 0.30434782608695654, 0.5, 1.0, 1.0, 1.0, 0.3100933881804922, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18815083361809454, 0.18815083361809443, 0.31983911211175076], 
reward next is 0.6802, 
noisyNet noise sample is [array([0.04012492], dtype=float32), -1.4858873]. 
=============================================
[2019-03-23 12:23:55,803] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.2120111e-27 1.0000000e+00 4.3676778e-38 1.4982193e-31 2.0714273e-36], sum to 1.0000
[2019-03-23 12:23:55,814] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8723
[2019-03-23 12:23:55,823] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.33333333333334, 80.0, 1.0, 2.0, 0.5064337267179388, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 576796.8077549161, 576796.8077549161, 143702.2137983282], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5139600.0000, 
sim time next is 5140200.0000, 
raw observation next is [24.16666666666666, 81.5, 1.0, 2.0, 0.5094312911593689, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 580095.8283758555, 580095.8283758555, 144156.899395676], 
processed observation next is [0.0, 0.4782608695652174, 0.7348484848484845, 0.815, 1.0, 1.0, 0.3867891139492111, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2148503068058724, 0.2148503068058724, 0.3516021936479903], 
reward next is 0.6484, 
noisyNet noise sample is [array([0.26730543], dtype=float32), 1.1449553]. 
=============================================
[2019-03-23 12:24:04,773] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-23 12:24:04,775] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 12:24:04,776] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:24:04,778] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 12:24:04,779] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 12:24:04,781] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 12:24:04,781] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:24:04,783] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:24:04,783] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:24:04,781] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 12:24:04,786] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:24:04,798] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run100
[2019-03-23 12:24:04,827] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run100
[2019-03-23 12:24:04,852] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run100
[2019-03-23 12:24:04,854] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run100
[2019-03-23 12:24:04,909] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run100
[2019-03-23 12:24:06,154] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.1157422]
[2019-03-23 12:24:06,155] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.75, 46.5, 1.0, 2.0, 0.2969048855599954, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 322373.3551857772, 322373.3551857772, 85439.01106028979]
[2019-03-23 12:24:06,156] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 12:24:06,158] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.0072107e-23 1.0000000e+00 2.5872974e-32 4.0126510e-26 8.4519601e-32], sampled 0.15545562864710438
[2019-03-23 12:24:32,735] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.1157422]
[2019-03-23 12:24:32,735] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [15.1363208, 100.0, 1.0, 2.0, 0.2839853139786424, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 308341.9456565856, 308341.9456565853, 101877.6643979713]
[2019-03-23 12:24:32,735] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 12:24:32,738] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.0072107e-23 1.0000000e+00 2.5872974e-32 4.0126510e-26 8.4519601e-32], sampled 0.07162548072156738
[2019-03-23 12:24:40,972] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.1157422]
[2019-03-23 12:24:40,973] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.31666666666666, 85.66666666666667, 1.0, 2.0, 0.4192899389604025, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 473952.2764569373, 473952.2764569369, 131755.8175371337]
[2019-03-23 12:24:40,973] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 12:24:40,976] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.0072107e-23 1.0000000e+00 2.5872974e-32 4.0126510e-26 8.4519601e-32], sampled 0.797745849383499
[2019-03-23 12:25:06,068] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.1157422]
[2019-03-23 12:25:06,071] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.9, 52.33333333333334, 1.0, 2.0, 0.2787299971760833, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 302634.4583075856, 302634.4583075853, 96877.2843984681]
[2019-03-23 12:25:06,073] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 12:25:06,075] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.0072107e-23 1.0000000e+00 2.5872974e-32 4.0126510e-26 8.4519601e-32], sampled 0.5414540444990772
[2019-03-23 12:25:44,368] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 12:25:44,565] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 12:25:44,607] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 12:25:44,719] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 12:25:44,749] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 12:25:45,764] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 2475000, evaluation results [2475000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 12:25:46,205] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.9832848e-23 1.0000000e+00 4.6852052e-32 3.0697129e-26 2.1977048e-32], sum to 1.0000
[2019-03-23 12:25:46,213] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9123
[2019-03-23 12:25:46,217] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.55, 58.0, 1.0, 2.0, 0.4266002193183771, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 485204.5014636535, 485204.5014636535, 130234.9462516586], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5347800.0000, 
sim time next is 5348400.0000, 
raw observation next is [25.36666666666667, 59.33333333333333, 1.0, 2.0, 0.4313867724052046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 490794.466430725, 490794.4664307253, 130845.4727944333], 
processed observation next is [1.0, 0.9130434782608695, 0.7893939393939395, 0.5933333333333333, 1.0, 1.0, 0.28923346550650575, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18177572830767594, 0.18177572830767605, 0.3191352994986178], 
reward next is 0.6809, 
noisyNet noise sample is [array([0.54947597], dtype=float32), -1.0380683]. 
=============================================
[2019-03-23 12:25:47,391] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.0939515e-30 1.0000000e+00 0.0000000e+00 4.3353504e-34 0.0000000e+00], sum to 1.0000
[2019-03-23 12:25:47,400] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0992
[2019-03-23 12:25:47,405] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 87.0, 1.0, 2.0, 0.4407186418726612, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 499743.4841302434, 499743.4841302431, 130456.9853546697], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5371200.0000, 
sim time next is 5371800.0000, 
raw observation next is [20.41666666666667, 87.0, 1.0, 2.0, 0.4369801375429586, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 495105.6881572517, 495105.6881572517, 129821.7018466758], 
processed observation next is [1.0, 0.17391304347826086, 0.5643939393939396, 0.87, 1.0, 1.0, 0.29622517192869824, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1833724770952784, 0.1833724770952784, 0.31663829718701414], 
reward next is 0.6834, 
noisyNet noise sample is [array([-1.2141427], dtype=float32), 1.7074517]. 
=============================================
[2019-03-23 12:25:50,123] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.1031902e-25 1.0000000e+00 3.2556211e-35 9.5739580e-26 3.5978631e-34], sum to 1.0000
[2019-03-23 12:25:50,133] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9119
[2019-03-23 12:25:50,140] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1670408.502350114 W.
[2019-03-23 12:25:50,144] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.8, 61.0, 1.0, 2.0, 0.7425552765524612, 1.0, 2.0, 0.7425552765524612, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1670408.502350114, 1670408.502350114, 305492.2106705445], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5407200.0000, 
sim time next is 5407800.0000, 
raw observation next is [28.06666666666667, 62.66666666666667, 1.0, 2.0, 0.4492556194479885, 1.0, 2.0, 0.4492556194479885, 1.0, 1.0, 0.9090145807998115, 6.9112, 6.9112, 77.3421103, 1515721.186265603, 1515721.186265603, 332301.5475735358], 
processed observation next is [1.0, 0.6086956521739131, 0.9121212121212122, 0.6266666666666667, 1.0, 1.0, 0.3115695243099856, 1.0, 1.0, 0.3115695243099856, 1.0, 0.5, 0.8700208297140165, 0.0, 0.0, 0.5085185399722538, 0.5613782171354085, 0.5613782171354085, 0.8104915794476484], 
reward next is 0.1895, 
noisyNet noise sample is [array([0.9819583], dtype=float32), -0.8331374]. 
=============================================
[2019-03-23 12:25:50,978] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.9145268e-24 1.0000000e+00 6.9096366e-33 1.6678394e-28 8.7281374e-33], sum to 1.0000
[2019-03-23 12:25:50,989] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1960
[2019-03-23 12:25:50,996] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 95.66666666666666, 1.0, 2.0, 0.3970694942735168, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 448296.2640756891, 448296.2640756891, 125052.4173724242], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5427600.0000, 
sim time next is 5428200.0000, 
raw observation next is [18.9, 96.33333333333334, 1.0, 2.0, 0.3965173815380258, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 447569.1542469403, 447569.15424694, 124943.6196498813], 
processed observation next is [1.0, 0.8260869565217391, 0.49545454545454537, 0.9633333333333334, 1.0, 1.0, 0.24564672692253223, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1657663534247927, 0.1657663534247926, 0.3047405357314178], 
reward next is 0.6953, 
noisyNet noise sample is [array([-0.48453614], dtype=float32), 0.16209559]. 
=============================================
[2019-03-23 12:25:54,007] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.8320516e-28 1.0000000e+00 0.0000000e+00 5.8832790e-29 2.0309350e-37], sum to 1.0000
[2019-03-23 12:25:54,014] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4883
[2019-03-23 12:25:54,020] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.56666666666667, 75.0, 1.0, 2.0, 0.3756207784484725, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 412354.6914645118, 412354.6914645121, 118078.4604567704], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5905200.0000, 
sim time next is 5905800.0000, 
raw observation next is [19.95, 74.5, 1.0, 2.0, 0.4646550798449726, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 513195.4978170656, 513195.4978170656, 126586.8594365316], 
processed observation next is [1.0, 0.34782608695652173, 0.5431818181818181, 0.745, 1.0, 1.0, 0.33081884980621573, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1900724065989132, 0.1900724065989132, 0.30874843765007703], 
reward next is 0.6913, 
noisyNet noise sample is [array([-0.6619855], dtype=float32), -1.2965909]. 
=============================================
[2019-03-23 12:25:59,707] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.7342908e-20 1.0000000e+00 1.0513395e-28 1.7232443e-22 6.5070841e-28], sum to 1.0000
[2019-03-23 12:25:59,718] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8349
[2019-03-23 12:25:59,722] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.7, 57.0, 1.0, 2.0, 0.4872839426409306, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 555779.8287216079, 555779.8287216079, 140486.4163103882], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5594400.0000, 
sim time next is 5595000.0000, 
raw observation next is [26.5, 62.0, 1.0, 2.0, 0.4885156539609924, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 557333.4282363129, 557333.4282363129, 140289.7550395723], 
processed observation next is [1.0, 0.782608695652174, 0.8409090909090909, 0.62, 1.0, 1.0, 0.36064456745124046, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20641978823567145, 0.20641978823567145, 0.3421701342428593], 
reward next is 0.6578, 
noisyNet noise sample is [array([0.909266], dtype=float32), -2.4048624]. 
=============================================
[2019-03-23 12:25:59,737] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[47.041676]
 [47.041676]
 [47.041676]
 [47.041676]
 [47.041676]], R is [[47.22908783]
 [47.41414642]
 [47.59970093]
 [47.78548813]
 [47.97075653]].
[2019-03-23 12:26:04,400] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.2201603e-30 1.0000000e+00 0.0000000e+00 7.4171363e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 12:26:04,410] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4560
[2019-03-23 12:26:04,413] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.6, 74.0, 1.0, 2.0, 0.2116034279376582, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 229747.3947471854, 229747.3947471857, 74391.79374336688], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5677800.0000, 
sim time next is 5678400.0000, 
raw observation next is [15.7, 73.0, 1.0, 2.0, 0.21366325472341, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 231984.3750128008, 231984.3750128005, 74537.32473470323], 
processed observation next is [0.0, 0.7391304347826086, 0.35, 0.73, 1.0, 1.0, 0.01707906840426248, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08592013889362993, 0.08592013889362982, 0.1817983530114713], 
reward next is 0.8182, 
noisyNet noise sample is [array([1.2253401], dtype=float32), 0.55958897]. 
=============================================
[2019-03-23 12:26:14,072] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.1719646e-27 1.0000000e+00 0.0000000e+00 9.9606234e-33 0.0000000e+00], sum to 1.0000
[2019-03-23 12:26:14,080] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2784
[2019-03-23 12:26:14,084] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 81.0, 1.0, 2.0, 0.2941101869265628, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 319358.1191323, 319358.1191323003, 106759.4901434247], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5882400.0000, 
sim time next is 5883000.0000, 
raw observation next is [17.61666666666667, 81.5, 1.0, 2.0, 0.3069819766176168, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 333339.6797596989, 333339.6797596986, 107357.3722261454], 
processed observation next is [1.0, 0.08695652173913043, 0.4371212121212123, 0.815, 1.0, 1.0, 0.13372747077202096, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12345914065174034, 0.12345914065174023, 0.26184724933206194], 
reward next is 0.7382, 
noisyNet noise sample is [array([0.3926881], dtype=float32), -1.6956178]. 
=============================================
[2019-03-23 12:26:14,099] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[69.02986]
 [69.02986]
 [69.02986]
 [69.02986]
 [69.02986]], R is [[69.07772064]
 [69.1265564 ]
 [69.16446686]
 [69.20095062]
 [69.23571777]].
[2019-03-23 12:26:14,736] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.254025e-29 1.000000e+00 0.000000e+00 3.886941e-33 0.000000e+00], sum to 1.0000
[2019-03-23 12:26:14,743] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5746
[2019-03-23 12:26:14,747] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.8, 68.0, 1.0, 2.0, 0.5052230432535578, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 576102.039094069, 576102.039094069, 142817.8681479], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6298200.0000, 
sim time next is 6298800.0000, 
raw observation next is [25.7, 68.33333333333334, 1.0, 2.0, 0.5014713845905128, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 571875.7857047151, 571875.7857047151, 142293.9393949432], 
processed observation next is [0.0, 0.9130434782608695, 0.8045454545454546, 0.6833333333333335, 1.0, 1.0, 0.3768392307381409, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21180584655730186, 0.21180584655730186, 0.3470583887681542], 
reward next is 0.6529, 
noisyNet noise sample is [array([0.0991921], dtype=float32), -1.5689244]. 
=============================================
[2019-03-23 12:26:22,071] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.7473491e-26 1.0000000e+00 1.6635753e-36 9.5618257e-29 8.0648390e-36], sum to 1.0000
[2019-03-23 12:26:22,080] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3211
[2019-03-23 12:26:22,080] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1280654.900131118 W.
[2019-03-23 12:26:22,086] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.5, 71.5, 1.0, 2.0, 0.5658170571094165, 1.0, 2.0, 0.5658170571094165, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1280654.900131118, 1280654.900131118, 250482.4860099093], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6018600.0000, 
sim time next is 6019200.0000, 
raw observation next is [25.5, 72.0, 1.0, 2.0, 0.3845175759679703, 1.0, 2.0, 0.3845175759679703, 1.0, 1.0, 0.7778989354465553, 6.9112, 6.9112, 77.3421103, 1302753.010168177, 1302753.010168177, 297719.3371223173], 
processed observation next is [1.0, 0.6956521739130435, 0.7954545454545454, 0.72, 1.0, 1.0, 0.23064696995996287, 1.0, 1.0, 0.23064696995996287, 1.0, 0.5, 0.6827127649236505, 0.0, 0.0, 0.5085185399722538, 0.4825011148771026, 0.4825011148771026, 0.7261447246885787], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.5069351], dtype=float32), 0.80057645]. 
=============================================
[2019-03-23 12:26:23,405] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.6870359e-28 1.0000000e+00 0.0000000e+00 6.0006639e-30 5.7933257e-37], sum to 1.0000
[2019-03-23 12:26:23,411] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5409
[2019-03-23 12:26:23,414] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.6, 78.33333333333333, 1.0, 2.0, 0.2229941375773117, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 242117.8805986359, 242117.8805986356, 77276.6732292362], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6058200.0000, 
sim time next is 6058800.0000, 
raw observation next is [15.5, 78.0, 1.0, 2.0, 0.2210385729075685, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 239994.0849210345, 239994.0849210348, 76539.08626361765], 
processed observation next is [1.0, 0.13043478260869565, 0.3409090909090909, 0.78, 1.0, 1.0, 0.026298216134460622, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08888669811890167, 0.08888669811890178, 0.18668069820394548], 
reward next is 0.8133, 
noisyNet noise sample is [array([1.1887203], dtype=float32), 1.2430413]. 
=============================================
[2019-03-23 12:26:25,741] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.3373701e-33 1.0000000e+00 0.0000000e+00 1.7152104e-37 0.0000000e+00], sum to 1.0000
[2019-03-23 12:26:25,749] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0068
[2019-03-23 12:26:25,753] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.0, 80.0, 1.0, 2.0, 0.2132111277692698, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 231493.3624207602, 231493.3624207602, 74875.42145730517], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6073200.0000, 
sim time next is 6073800.0000, 
raw observation next is [15.26666666666667, 78.66666666666667, 1.0, 2.0, 0.2219274825424147, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 240959.4634745188, 240959.4634745188, 76028.8064373111], 
processed observation next is [1.0, 0.30434782608695654, 0.33030303030303043, 0.7866666666666667, 1.0, 1.0, 0.02740935317801837, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08924424573130325, 0.08924424573130325, 0.1854361132617344], 
reward next is 0.8146, 
noisyNet noise sample is [array([0.7600771], dtype=float32), 0.3308076]. 
=============================================
[2019-03-23 12:26:27,203] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.40917e-34 1.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00], sum to 1.0000
[2019-03-23 12:26:27,210] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9947
[2019-03-23 12:26:27,215] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.5, 44.5, 1.0, 2.0, 0.7655840836858431, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 843756.9071680858, 843756.9071680856, 158704.7160967243], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6102600.0000, 
sim time next is 6103200.0000, 
raw observation next is [24.6, 44.0, 1.0, 2.0, 0.7323847390892414, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 806689.1620915818, 806689.1620915818, 154421.8460857491], 
processed observation next is [1.0, 0.6521739130434783, 0.7545454545454546, 0.44, 1.0, 1.0, 0.6654809238615517, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.29877376373762293, 0.29877376373762293, 0.37663864898963195], 
reward next is 0.6234, 
noisyNet noise sample is [array([2.0985863], dtype=float32), -0.45019406]. 
=============================================
[2019-03-23 12:26:27,498] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.6618987e-31 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 12:26:27,503] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2037
[2019-03-23 12:26:27,507] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.9, 64.66666666666667, 1.0, 2.0, 0.2673811894515012, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 290325.9036627324, 290325.9036627327, 90779.46101549163], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6126600.0000, 
sim time next is 6127200.0000, 
raw observation next is [18.8, 65.0, 1.0, 2.0, 0.2659979321420624, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 288823.4992569625, 288823.4992569622, 90186.4701479191], 
processed observation next is [1.0, 0.9565217391304348, 0.49090909090909096, 0.65, 1.0, 1.0, 0.082497415177578, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10697166639146759, 0.10697166639146749, 0.2199670003607783], 
reward next is 0.7800, 
noisyNet noise sample is [array([2.4832702], dtype=float32), -0.20395583]. 
=============================================
[2019-03-23 12:26:34,226] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.5344276e-28 1.0000000e+00 0.0000000e+00 1.6703191e-32 2.9842293e-38], sum to 1.0000
[2019-03-23 12:26:34,236] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6793
[2019-03-23 12:26:34,239] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.7, 63.0, 1.0, 2.0, 0.5308039224285933, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 602961.6500184381, 602961.6500184379, 147670.2308377319], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6265800.0000, 
sim time next is 6266400.0000, 
raw observation next is [28.06666666666667, 61.0, 1.0, 2.0, 0.5305880440934212, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 602748.7109599009, 602748.7109599009, 147627.2332406184], 
processed observation next is [0.0, 0.5217391304347826, 0.9121212121212122, 0.61, 1.0, 1.0, 0.41323505511677644, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2232402633184818, 0.2232402633184818, 0.3600664225380937], 
reward next is 0.6399, 
noisyNet noise sample is [array([0.34189257], dtype=float32), -0.8168363]. 
=============================================
[2019-03-23 12:26:34,736] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-23 12:26:34,741] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 12:26:34,743] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 12:26:34,743] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:26:34,746] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:26:34,744] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 12:26:34,747] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 12:26:34,748] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:26:34,748] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 12:26:34,749] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:26:34,750] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:26:34,766] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run101
[2019-03-23 12:26:34,793] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run101
[2019-03-23 12:26:34,817] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run101
[2019-03-23 12:26:34,843] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run101
[2019-03-23 12:26:34,869] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/38/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run101
[2019-03-23 12:26:42,404] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.1223961]
[2019-03-23 12:26:42,406] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [13.91598131666667, 97.59596159999998, 1.0, 2.0, 0.3432103464951319, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 372666.4824479729, 372666.4824479729, 95580.60869486564]
[2019-03-23 12:26:42,407] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 12:26:42,410] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.63502714e-27 1.00000000e+00 8.37573861e-38 1.56731455e-30
 3.46767650e-37], sampled 0.8547769891672509
[2019-03-23 12:26:45,383] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.1223961]
[2019-03-23 12:26:45,384] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [18.38333333333333, 60.33333333333334, 1.0, 2.0, 0.2629549190129343, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 285502.4086727286, 285502.4086727283, 87711.75076795179]
[2019-03-23 12:26:45,385] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 12:26:45,386] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.63502714e-27 1.00000000e+00 8.37573861e-38 1.56731455e-30
 3.46767650e-37], sampled 0.10258077595257653
[2019-03-23 12:26:48,287] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.1223961]
[2019-03-23 12:26:48,287] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [13.0, 98.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 212997.2234048798, 212997.2234048795, 72410.1788559896]
[2019-03-23 12:26:48,289] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 12:26:48,291] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.63502714e-27 1.00000000e+00 8.37573861e-38 1.56731455e-30
 3.46767650e-37], sampled 0.9626241026229678
[2019-03-23 12:27:02,188] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.1223961]
[2019-03-23 12:27:02,189] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [10.5, 84.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 186824.1872462464, 186824.187246246, 67159.23032323956]
[2019-03-23 12:27:02,190] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 12:27:02,193] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.63502714e-27 1.00000000e+00 8.37573861e-38 1.56731455e-30
 3.46767650e-37], sampled 0.9016101375658755
[2019-03-23 12:27:03,183] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.1223961]
[2019-03-23 12:27:03,187] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [15.6, 67.66666666666667, 1.0, 2.0, 0.2153124506384276, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 233764.7016925181, 233764.7016925177, 77496.44847212634]
[2019-03-23 12:27:03,187] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 12:27:03,189] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.63502714e-27 1.00000000e+00 8.37573861e-38 1.56731455e-30
 3.46767650e-37], sampled 0.14578740126820433
[2019-03-23 12:27:10,931] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.1223961]
[2019-03-23 12:27:10,933] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.41419221, 87.0729093, 1.0, 2.0, 0.3931759672064028, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 95.55338769695034, 436602.8586060581, 436602.8586060574, 125631.5351317725]
[2019-03-23 12:27:10,933] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 12:27:10,936] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.63502714e-27 1.00000000e+00 8.37573861e-38 1.56731455e-30
 3.46767650e-37], sampled 0.5225150012403209
[2019-03-23 12:27:16,636] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.1223961]
[2019-03-23 12:27:16,641] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [23.03562009666667, 76.65513724333334, 1.0, 2.0, 0.671220454561077, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 764870.3522627417, 764870.3522627413, 164403.1365453316]
[2019-03-23 12:27:16,642] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 12:27:16,646] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.63502714e-27 1.00000000e+00 8.37573861e-38 1.56731455e-30
 3.46767650e-37], sampled 0.19789279029739093
[2019-03-23 12:27:18,120] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.1223961]
[2019-03-23 12:27:18,121] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.9, 79.0, 1.0, 2.0, 0.7142025154079067, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 814763.9779252742, 814763.9779252737, 171821.6636171086]
[2019-03-23 12:27:18,122] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 12:27:18,124] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.63502714e-27 1.00000000e+00 8.37573861e-38 1.56731455e-30
 3.46767650e-37], sampled 0.43282046204654634
[2019-03-23 12:27:19,466] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.1223961]
[2019-03-23 12:27:19,467] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.46666666666667, 84.33333333333334, 1.0, 2.0, 0.5998855362861629, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 680355.7135458343, 680355.713545834, 161435.256660861]
[2019-03-23 12:27:19,468] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 12:27:19,471] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.63502714e-27 1.00000000e+00 8.37573861e-38 1.56731455e-30
 3.46767650e-37], sampled 0.5402900317151937
[2019-03-23 12:27:26,564] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.1223961]
[2019-03-23 12:27:26,566] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.70341390166666, 59.30325554666666, 1.0, 2.0, 0.3914417441167649, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 440366.0981564319, 440366.0981564319, 128022.1113085039]
[2019-03-23 12:27:26,566] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 12:27:26,568] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.63502714e-27 1.00000000e+00 8.37573861e-38 1.56731455e-30
 3.46767650e-37], sampled 0.08718465620503624
[2019-03-23 12:27:38,573] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.1223961]
[2019-03-23 12:27:38,574] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [28.0, 66.0, 1.0, 2.0, 0.5729050072600443, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 646893.437600073, 646893.437600073, 154464.035451266]
[2019-03-23 12:27:38,575] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 12:27:38,577] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.63502714e-27 1.00000000e+00 8.37573861e-38 1.56731455e-30
 3.46767650e-37], sampled 0.3537196353118153
[2019-03-23 12:27:46,689] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.21793473], dtype=float32), -1.1223961]
[2019-03-23 12:27:46,689] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.6, 42.0, 1.0, 2.0, 0.2676902997336957, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 290661.6398444979, 290661.6398444976, 84029.64472553415]
[2019-03-23 12:27:46,691] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 12:27:46,694] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.63502714e-27 1.00000000e+00 8.37573861e-38 1.56731455e-30
 3.46767650e-37], sampled 0.7706485381075193
[2019-03-23 12:28:15,017] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 12:28:15,049] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 12:28:15,321] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 12:28:15,355] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 12:28:15,504] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 12:28:16,521] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 2500000, evaluation results [2500000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
