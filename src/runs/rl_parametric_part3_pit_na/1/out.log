Using TensorFlow backend.
[2019-03-22 22:12:36,381] A3C_AGENT_MAIN INFO:Namespace(action_repeat_n=1, action_space='part3_v1', activation='linear', agent_num=5, check_args_only=False, clip_norm=5.0, debug_log_prob=0.0005, decay_steps=1000000, dropout_prob=0.0, end_e=0.0, env='Part3-NA-Pit-Train-v1', eval_act_func='part3_pit_det_v1', eval_env_res_max_keep=50, eval_epi_num=1, eval_freq=25000, forecast_dim=0, gamma=0.99, h_decay_bounds=[], h_regu_frac=[0.0], init_e=0.0, isNoisyNet=True, isNoisyNetEval_rmNoise=True, is_greedy_policy=False, is_learning_rate_decay_staircase=False, is_warm_start=False, job_mode='Train', learning_rate=0.001, learning_rate_decay_rate=1.0, learning_rate_decay_steps=100000, max_interactions=2500000, metric_func='part3_v1', model_dir='None', model_param=[19, 1], model_type='nn', num_threads=16, output='./Part3-NA-Pit-Train-v1-res1', p_loss_frac=1.0, raw_state_prcs_func='cslDx_1', reward_func='part3_v3', rmsprop_decay=0.99, rmsprop_epsil=1e-10, rmsprop_momet=0.0, rwd_e_para=1.0, rwd_p_para=1.0, save_freq=500000, save_max_to_keep=5, save_scope='all', sharedNet_type='Dense', state_dim=17, test_env=['Part3-NA-Pit-Test-v1', 'Part3-NA-Pit-Test-v2', 'Part3-NA-Pit-Test-v3', 'Part3-NA-Pit-Test-v4'], test_mode='Multiple', train_act_func='part3_pit_sto_v1', train_freq=5, v_loss_frac=0.5, violation_penalty_scl=50.0, weight_initer='glorot_uniform', window_len=21)
[2019-03-22 22:12:36,382] A3C_AGENT_MAIN INFO:Start compiling...
2019-03-22 22:12:36.413631: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
[2019-03-22 22:12:51,041] A3C_AGENT_MAIN INFO:Start the learning...
[2019-03-22 22:12:51,041] A3C_AGENT_MAIN INFO:Prepare the evaluation environments ['Part3-NA-Pit-Train-v1', 'Part3-NA-Pit-Test-v1', 'Part3-NA-Pit-Test-v2', 'Part3-NA-Pit-Test-v3', 'Part3-NA-Pit-Test-v4'] ...
[2019-03-22 22:12:51,051] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation worker starts!
[2019-03-22 22:12:51,053] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation worker starts!
[2019-03-22 22:12:51,055] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation worker starts!
[2019-03-22 22:12:51,060] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation worker starts!
[2019-03-22 22:12:51,063] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation worker starts!
[2019-03-22 22:12:51,064] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-22 22:12:51,064] A3C_AGENT_WORKER-Thread-2 INFO:Local worker starts!
[2019-03-22 22:12:51,118] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:12:51,119] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run1
[2019-03-22 22:12:52,065] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-22 22:12:52,067] A3C_AGENT_WORKER-Thread-3 INFO:Local worker starts!
[2019-03-22 22:12:52,130] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:12:52,130] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run1
[2019-03-22 22:12:52,265] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-22 22:12:52,266] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-22 22:12:52,267] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-22 22:12:52,267] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:12:52,267] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:12:52,268] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-22 22:12:52,268] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-22 22:12:52,268] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-22 22:12:52,269] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:12:52,269] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:12:52,269] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:12:52,273] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run1
[2019-03-22 22:12:52,274] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run1
[2019-03-22 22:12:52,274] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run1
[2019-03-22 22:12:52,297] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run1
[2019-03-22 22:12:52,305] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run1
[2019-03-22 22:12:53,068] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-22 22:12:53,069] A3C_AGENT_WORKER-Thread-9 INFO:Local worker starts!
[2019-03-22 22:12:53,126] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:12:53,127] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run1
[2019-03-22 22:12:54,070] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-22 22:12:54,070] A3C_AGENT_WORKER-Thread-10 INFO:Local worker starts!
[2019-03-22 22:12:54,127] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:12:54,128] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run1
[2019-03-22 22:12:55,071] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-22 22:12:55,073] A3C_AGENT_WORKER-Thread-11 INFO:Local worker starts!
[2019-03-22 22:12:55,153] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:12:55,154] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run1
[2019-03-22 22:12:56,073] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-22 22:12:56,074] A3C_AGENT_WORKER-Thread-12 INFO:Local worker starts!
[2019-03-22 22:12:56,147] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:12:56,147] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run1
[2019-03-22 22:12:57,075] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-22 22:12:57,076] A3C_AGENT_WORKER-Thread-13 INFO:Local worker starts!
[2019-03-22 22:12:57,147] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:12:57,148] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run1
[2019-03-22 22:12:58,077] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-22 22:12:58,078] A3C_AGENT_WORKER-Thread-14 INFO:Local worker starts!
[2019-03-22 22:12:58,166] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:12:58,167] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run1
[2019-03-22 22:12:59,079] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-22 22:12:59,080] A3C_AGENT_WORKER-Thread-15 INFO:Local worker starts!
[2019-03-22 22:12:59,157] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:12:59,157] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run1
[2019-03-22 22:13:00,081] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-22 22:13:00,086] A3C_AGENT_WORKER-Thread-16 INFO:Local worker starts!
[2019-03-22 22:13:00,180] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:13:00,181] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run1
[2019-03-22 22:13:01,086] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-22 22:13:01,091] A3C_AGENT_WORKER-Thread-17 INFO:Local worker starts!
[2019-03-22 22:13:01,189] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:13:01,191] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run1
[2019-03-22 22:13:02,092] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-22 22:13:02,093] A3C_AGENT_WORKER-Thread-18 INFO:Local worker starts!
[2019-03-22 22:13:02,179] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:13:02,180] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run1
[2019-03-22 22:13:03,094] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-22 22:13:03,095] A3C_AGENT_WORKER-Thread-19 INFO:Local worker starts!
[2019-03-22 22:13:03,183] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:13:03,184] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run1
[2019-03-22 22:13:04,096] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-22 22:13:04,097] A3C_AGENT_WORKER-Thread-20 INFO:Local worker starts!
[2019-03-22 22:13:04,172] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:13:04,173] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run1
[2019-03-22 22:13:05,098] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-22 22:13:05,099] A3C_AGENT_WORKER-Thread-21 INFO:Local worker starts!
[2019-03-22 22:13:05,185] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:13:05,185] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run1
[2019-03-22 22:13:06,100] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-22 22:13:06,101] A3C_AGENT_WORKER-Thread-22 INFO:Local worker starts!
[2019-03-22 22:13:06,189] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:13:06,190] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run1
[2019-03-22 22:13:58,520] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-22 22:13:58,522] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.02911991166667, 79.8270318, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 2.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 340463.7659236004, 340463.7659236004, 167379.5625089347]
[2019-03-22 22:13:58,522] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 22:13:58,525] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0.07845695 0.32536185 0.31742066 0.15463196 0.12412861], sampled 0.9296849235516218
[2019-03-22 22:14:35,223] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-22 22:14:35,225] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.56666666666667, 62.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 95.55338769695034, 291797.4223538049, 291797.4223538045, 126403.9423834335]
[2019-03-22 22:14:35,225] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 22:14:35,228] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0.05758787 0.0927356  0.35486338 0.23201083 0.2628024 ], sampled 0.903444376682741
[2019-03-22 22:14:45,251] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-22 22:14:45,252] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.085597655, 99.31869307333335, 1.0, 1.0, 0.4393851794474171, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 95.55311693178074, 498017.9371192227, 498017.9371192223, 134521.383459262]
[2019-03-22 22:14:45,255] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 22:14:45,258] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0.1205636  0.2387533  0.33580163 0.13021292 0.17466852], sampled 0.06873317745170993
[2019-03-22 22:14:58,354] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 2119.0504 2084795518.9465 592.0000
[2019-03-22 22:14:58,779] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 2513.6190 2139723903.6671 509.0000
[2019-03-22 22:14:58,820] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 2263.3172 2080466703.6150 567.0000
[2019-03-22 22:14:58,879] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 2217.7584 2074368810.5631 552.0000
[2019-03-22 22:14:58,955] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2089.7790 2098849400.2671 837.0000
[2019-03-22 22:14:59,971] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 0, evaluation results [0.0, 2513.6190148499754, 2139723903.6671364, 509.0, 2217.758389975883, 2074368810.5630565, 552.0, 2263.3172253546627, 2080466703.6149762, 567.0, 2089.778987363973, 2098849400.267111, 837.0, 2119.050436021084, 2084795518.9465456, 592.0]
[2019-03-22 22:15:03,503] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.1256075  0.2579346  0.5277171  0.06536281 0.02337797], sum to 1.0000
[2019-03-22 22:15:03,512] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8825
[2019-03-22 22:15:03,615] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 1.0, 0.3792573543955122, 6.9112, 6.9112, 77.32846344354104, 435669.2075647441, 435669.2075647441, 157766.9610023297], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 28200.0000, 
sim time next is 28800.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3849299230769969, 6.911200000000001, 6.9112, 77.32846344354104, 442116.8675478919, 442116.8675478916, 158565.9433133627], 
processed observation next is [1.0, 0.34782608695652173, 0.45454545454545453, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.12132846153856705, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1637469879807007, 0.16374698798070061, 0.38674620320332365], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.36335444], dtype=float32), -1.2244986]. 
=============================================
[2019-03-22 22:15:05,041] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.1671833e-04 4.5306799e-03 9.9037981e-01 4.1360557e-03 3.6768040e-05], sum to 1.0000
[2019-03-22 22:15:05,049] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0988
[2019-03-22 22:15:05,151] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.0, 78.0, 1.0, 2.0, 0.4287891149736566, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8483939699478302, 6.9112, 6.9112, 77.32846344354104, 971353.5013658251, 971353.5013658251, 221527.1265337223], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 48600.0000, 
sim time next is 49200.0000, 
raw observation next is [21.0, 78.0, 1.0, 2.0, 0.4304628399528503, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8519805084228457, 6.911200000000001, 6.9112, 77.32846344354104, 975334.7890800295, 975334.7890800291, 222268.8481765276], 
processed observation next is [1.0, 0.5652173913043478, 0.5909090909090909, 0.78, 1.0, 1.0, 0.2880785499410628, 0.0, 1.0, -0.25, 1.0, 1.0, 0.7885435834612082, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3612351070666776, 0.36123510706667744, 0.5421191418939697], 
reward next is 0.4579, 
noisyNet noise sample is [array([0.8071339], dtype=float32), -1.4261513]. 
=============================================
[2019-03-22 22:15:08,101] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.8826671e-03 9.7335362e-01 1.0534985e-02 9.1942213e-03 3.4421195e-05], sum to 1.0000
[2019-03-22 22:15:08,115] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0096
[2019-03-22 22:15:08,123] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.66666666666667, 80.33333333333333, 1.0, 2.0, 0.2163740384530835, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 234928.3128455211, 234928.3128455208, 74393.5491021593], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 92400.0000, 
sim time next is 93000.0000, 
raw observation next is [14.33333333333333, 81.16666666666667, 1.0, 2.0, 0.2124794135135589, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 230698.7173875274, 230698.7173875277, 73415.66208966363], 
processed observation next is [1.0, 0.043478260869565216, 0.28787878787878773, 0.8116666666666668, 1.0, 1.0, 0.015599266891948606, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08544396940278792, 0.08544396940278803, 0.17906259046259423], 
reward next is 0.8209, 
noisyNet noise sample is [array([0.54147124], dtype=float32), 1.2429144]. 
=============================================
[2019-03-22 22:15:08,141] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[21.255085]
 [20.87806 ]
 [21.605213]
 [22.125607]
 [22.320784]], R is [[21.84139442]
 [22.44153214]
 [23.03338432]
 [23.61674118]
 [23.38057327]].
[2019-03-22 22:15:11,902] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.6318569e-06 9.9996889e-01 6.8977970e-06 2.2560220e-05 1.3001439e-12], sum to 1.0000
[2019-03-22 22:15:11,916] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5190
[2019-03-22 22:15:12,017] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 43.0, 1.0, 2.0, 0.300684635535671, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 326499.3487163366, 326499.3487163369, 90544.81048211729], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 149400.0000, 
sim time next is 150000.0000, 
raw observation next is [22.0, 43.0, 1.0, 2.0, 0.3012090195589224, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 327068.9442233415, 327068.9442233415, 90462.14327483665], 
processed observation next is [1.0, 0.7391304347826086, 0.6363636363636364, 0.43, 1.0, 1.0, 0.12651127444865296, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12113664600864499, 0.12113664600864499, 0.220639373841065], 
reward next is 0.7794, 
noisyNet noise sample is [array([-0.6381858], dtype=float32), -0.7137796]. 
=============================================
[2019-03-22 22:15:12,033] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[85.2732  ]
 [85.278145]
 [85.34028 ]
 [85.51299 ]
 [85.45911 ]], R is [[85.11781311]
 [85.04579163]
 [84.96872711]
 [84.85980988]
 [84.67935944]].
[2019-03-22 22:15:14,494] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.9260895e-03 9.8487210e-01 4.9702646e-03 8.1361318e-03 9.5469448e-05], sum to 1.0000
[2019-03-22 22:15:14,504] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7104
[2019-03-22 22:15:14,603] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.5, 91.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 209490.0626140104, 209490.0626140106, 71258.66509146146], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 185400.0000, 
sim time next is 186000.0000, 
raw observation next is [13.66666666666667, 90.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 211020.3423804344, 211020.3423804347, 71690.96046971813], 
processed observation next is [0.0, 0.13043478260869565, 0.25757575757575774, 0.9, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07815568236312385, 0.07815568236312397, 0.174856001145654], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.76136374], dtype=float32), 1.6667136]. 
=============================================
[2019-03-22 22:15:14,621] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[18.268723]
 [18.261993]
 [18.121557]
 [18.264626]
 [18.36628 ]], R is [[18.1118679 ]
 [17.93074989]
 [17.75144196]
 [17.57392693]
 [17.39818764]].
[2019-03-22 22:15:16,126] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.4226880e-06 9.9979454e-01 1.0176888e-05 1.9191430e-04 1.5720541e-12], sum to 1.0000
[2019-03-22 22:15:16,138] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5465
[2019-03-22 22:15:16,231] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 75.0, 1.0, 2.0, 0.2647956508738085, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 287517.6630636335, 287517.6630636338, 96059.89764421132], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 207000.0000, 
sim time next is 207600.0000, 
raw observation next is [18.33333333333333, 74.33333333333333, 1.0, 2.0, 0.2716875572680008, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 295003.2308975053, 295003.2308975056, 100566.8172112323], 
processed observation next is [0.0, 0.391304347826087, 0.4696969696969695, 0.7433333333333333, 1.0, 1.0, 0.089609446585001, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10926045588796493, 0.10926045588796504, 0.24528492002739583], 
reward next is 0.7547, 
noisyNet noise sample is [array([0.2839171], dtype=float32), 1.4247464]. 
=============================================
[2019-03-22 22:15:20,528] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.7375129e-04 9.9867624e-01 4.0782001e-04 2.3032515e-04 1.1758984e-05], sum to 1.0000
[2019-03-22 22:15:20,541] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8472
[2019-03-22 22:15:20,636] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 206149.1706384155, 206149.1706384152, 71708.97026249368], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 271800.0000, 
sim time next is 272400.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 205805.1577237288, 205805.1577237285, 71644.80696632239], 
processed observation next is [0.0, 0.13043478260869565, 0.22727272727272727, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07622413249026992, 0.07622413249026982, 0.17474343162517655], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.01906308], dtype=float32), -0.44819856]. 
=============================================
[2019-03-22 22:15:22,112] A3C_AGENT_WORKER-Thread-10 INFO:Local step 500, global step 7877: loss 0.0264
[2019-03-22 22:15:22,165] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 500, global step 7877: learning rate 0.0010
[2019-03-22 22:15:22,199] A3C_AGENT_WORKER-Thread-15 INFO:Local step 500, global step 7893: loss 0.0518
[2019-03-22 22:15:22,200] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 500, global step 7893: learning rate 0.0010
[2019-03-22 22:15:22,315] A3C_AGENT_WORKER-Thread-17 INFO:Local step 500, global step 7936: loss 0.2758
[2019-03-22 22:15:22,319] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 500, global step 7936: learning rate 0.0010
[2019-03-22 22:15:22,351] A3C_AGENT_WORKER-Thread-19 INFO:Local step 500, global step 7952: loss 0.1436
[2019-03-22 22:15:22,354] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 500, global step 7953: learning rate 0.0010
[2019-03-22 22:15:22,368] A3C_AGENT_WORKER-Thread-21 INFO:Local step 500, global step 7959: loss 0.3451
[2019-03-22 22:15:22,371] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 500, global step 7960: learning rate 0.0010
[2019-03-22 22:15:22,408] A3C_AGENT_WORKER-Thread-9 INFO:Local step 500, global step 7973: loss 0.2006
[2019-03-22 22:15:22,415] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 500, global step 7973: learning rate 0.0010
[2019-03-22 22:15:22,427] A3C_AGENT_WORKER-Thread-14 INFO:Local step 500, global step 7980: loss 0.0497
[2019-03-22 22:15:22,429] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 500, global step 7980: learning rate 0.0010
[2019-03-22 22:15:22,432] A3C_AGENT_WORKER-Thread-3 INFO:Local step 500, global step 7981: loss 0.0457
[2019-03-22 22:15:22,433] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 500, global step 7981: learning rate 0.0010
[2019-03-22 22:15:22,448] A3C_AGENT_WORKER-Thread-16 INFO:Local step 500, global step 7986: loss 0.0252
[2019-03-22 22:15:22,453] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 500, global step 7988: learning rate 0.0010
[2019-03-22 22:15:22,454] A3C_AGENT_WORKER-Thread-11 INFO:Local step 500, global step 7988: loss 0.0306
[2019-03-22 22:15:22,458] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 500, global step 7989: learning rate 0.0010
[2019-03-22 22:15:22,471] A3C_AGENT_WORKER-Thread-12 INFO:Local step 500, global step 7995: loss 0.0264
[2019-03-22 22:15:22,474] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 500, global step 7995: learning rate 0.0010
[2019-03-22 22:15:22,545] A3C_AGENT_WORKER-Thread-18 INFO:Local step 500, global step 8027: loss 0.0169
[2019-03-22 22:15:22,548] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 500, global step 8027: learning rate 0.0010
[2019-03-22 22:15:22,562] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.3015760e-10 9.9999845e-01 8.2537866e-08 1.3981247e-06 8.8142274e-15], sum to 1.0000
[2019-03-22 22:15:22,563] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5200
[2019-03-22 22:15:22,568] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 70.5, 1.0, 2.0, 0.2328017302815452, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 252769.3291887488, 252769.3291887488, 86230.14968370399], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 297000.0000, 
sim time next is 297600.0000, 
raw observation next is [18.33333333333333, 68.33333333333333, 1.0, 2.0, 0.2333122390689602, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 253323.7690914676, 253323.7690914676, 86621.06360465166], 
processed observation next is [0.0, 0.43478260869565216, 0.4696969696969695, 0.6833333333333332, 1.0, 1.0, 0.04164029883620024, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09382361818202505, 0.09382361818202505, 0.2112708868406138], 
reward next is 0.7887, 
noisyNet noise sample is [array([-1.2241248], dtype=float32), 0.012021393]. 
=============================================
[2019-03-22 22:15:22,602] A3C_AGENT_WORKER-Thread-22 INFO:Local step 500, global step 8046: loss 0.0049
[2019-03-22 22:15:22,603] A3C_AGENT_WORKER-Thread-20 INFO:Local step 500, global step 8046: loss 0.0002
[2019-03-22 22:15:22,605] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 500, global step 8046: learning rate 0.0010
[2019-03-22 22:15:22,606] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 500, global step 8046: learning rate 0.0010
[2019-03-22 22:15:22,641] A3C_AGENT_WORKER-Thread-13 INFO:Local step 500, global step 8063: loss 0.0296
[2019-03-22 22:15:22,647] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 500, global step 8063: learning rate 0.0010
[2019-03-22 22:15:22,719] A3C_AGENT_WORKER-Thread-2 INFO:Local step 500, global step 8092: loss 0.1718
[2019-03-22 22:15:22,723] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 500, global step 8093: learning rate 0.0010
[2019-03-22 22:15:22,869] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.2571311e-12 1.0000000e+00 8.2762757e-09 3.0642774e-08 7.0416747e-17], sum to 1.0000
[2019-03-22 22:15:22,882] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1248
[2019-03-22 22:15:22,975] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 45.0, 1.0, 2.0, 0.2545822735931406, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 276424.7282769462, 276424.7282769459, 82668.51587932225], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 308400.0000, 
sim time next is 309000.0000, 
raw observation next is [21.0, 44.0, 1.0, 2.0, 0.2563920248457976, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 278390.3135770482, 278390.3135770485, 82105.32288452762], 
processed observation next is [0.0, 0.5652173913043478, 0.5909090909090909, 0.44, 1.0, 1.0, 0.07049003105724698, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10310752354705488, 0.10310752354705499, 0.2002568850842137], 
reward next is 0.7997, 
noisyNet noise sample is [array([-0.68392503], dtype=float32), -0.18097968]. 
=============================================
[2019-03-22 22:15:22,990] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[84.15464 ]
 [84.14442 ]
 [84.148056]
 [84.13291 ]
 [84.08931 ]], R is [[84.08609009]
 [84.04360199]
 [83.99954987]
 [83.95384216]
 [83.90637207]].
[2019-03-22 22:15:23,604] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.9672245e-10 9.9999714e-01 5.7113706e-08 2.8350530e-06 1.8323511e-14], sum to 1.0000
[2019-03-22 22:15:23,613] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6048
[2019-03-22 22:15:23,618] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.16666666666667, 42.66666666666667, 1.0, 2.0, 0.2670070200367589, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 289919.5046458542, 289919.5046458539, 87507.28186709319], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 313800.0000, 
sim time next is 314400.0000, 
raw observation next is [22.33333333333334, 42.33333333333334, 1.0, 2.0, 0.2689309280928402, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 292009.1348101647, 292009.134810165, 88314.71492694085], 
processed observation next is [0.0, 0.6521739130434783, 0.6515151515151518, 0.42333333333333345, 1.0, 1.0, 0.08616366011605023, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1081515314111721, 0.10815153141117222, 0.21540174372424598], 
reward next is 0.7846, 
noisyNet noise sample is [array([-0.10342826], dtype=float32), -0.9282544]. 
=============================================
[2019-03-22 22:15:26,917] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.6443595e-11 1.0000000e+00 2.1149329e-08 2.0783151e-08 1.0242875e-17], sum to 1.0000
[2019-03-22 22:15:26,928] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2495
[2019-03-22 22:15:26,938] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.0, 76.0, 1.0, 2.0, 0.3812699123825723, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 414040.3768443649, 414040.3768443651, 85245.9642569822], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 362400.0000, 
sim time next is 363000.0000, 
raw observation next is [12.0, 76.0, 1.0, 2.0, 0.381912716639745, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 414738.7283788644, 414738.7283788641, 85162.59497858699], 
processed observation next is [1.0, 0.17391304347826086, 0.18181818181818182, 0.76, 1.0, 1.0, 0.22739089579968125, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15360693643661644, 0.15360693643661635, 0.20771364628923655], 
reward next is 0.7923, 
noisyNet noise sample is [array([0.9203118], dtype=float32), 0.2741038]. 
=============================================
[2019-03-22 22:15:26,959] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[83.10191 ]
 [83.17113 ]
 [83.2003  ]
 [83.202576]
 [83.4583  ]], R is [[82.98149109]
 [82.94376373]
 [82.89969635]
 [82.87996674]
 [82.88928986]].
[2019-03-22 22:15:31,063] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.0527474e-10 9.9999988e-01 8.5264482e-08 3.8368064e-08 1.6857539e-15], sum to 1.0000
[2019-03-22 22:15:31,071] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3394
[2019-03-22 22:15:31,077] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.66666666666667, 96.0, 1.0, 2.0, 0.2038937499029703, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 221374.7443653102, 221374.7443653105, 75030.54034139331], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 426000.0000, 
sim time next is 426600.0000, 
raw observation next is [13.5, 97.0, 1.0, 2.0, 0.2025671736857859, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 219934.1074438305, 219934.1074438302, 74637.04924029895], 
processed observation next is [1.0, 0.9565217391304348, 0.25, 0.97, 1.0, 1.0, 0.003208967107232348, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08145707683104833, 0.08145707683104822, 0.18204158351292427], 
reward next is 0.8180, 
noisyNet noise sample is [array([-1.4342006], dtype=float32), 0.9120293]. 
=============================================
[2019-03-22 22:15:32,806] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.7283007e-07 9.9999809e-01 1.5386086e-06 4.3884012e-09 6.7556002e-15], sum to 1.0000
[2019-03-22 22:15:32,817] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3481
[2019-03-22 22:15:32,910] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.5389753544531629, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 585403.8496765246, 585403.8496765243, 110099.0083279956], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 448200.0000, 
sim time next is 448800.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.5340306161252266, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 580029.9563577559, 580029.9563577559, 109523.6740018485], 
processed observation next is [1.0, 0.17391304347826086, 0.22727272727272727, 1.0, 1.0, 1.0, 0.4175382701565332, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21482590976213184, 0.21482590976213184, 0.2671309121996305], 
reward next is 0.7329, 
noisyNet noise sample is [array([0.953737], dtype=float32), -0.72701067]. 
=============================================
[2019-03-22 22:15:33,600] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.7089316e-07 9.9999547e-01 4.0898422e-06 7.8861817e-08 5.5829025e-11], sum to 1.0000
[2019-03-22 22:15:33,612] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6807
[2019-03-22 22:15:33,620] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.2322523078341357, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 252172.6276719162, 252172.6276719159, 77146.6226580023], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 462600.0000, 
sim time next is 463200.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.2577871581723156, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 279905.5844561803, 279905.58445618, 79486.81044573913], 
processed observation next is [1.0, 0.34782608695652173, 0.22727272727272727, 1.0, 1.0, 1.0, 0.07223394771539451, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10366873498377048, 0.10366873498377037, 0.19387026937985155], 
reward next is 0.8061, 
noisyNet noise sample is [array([-1.0503826], dtype=float32), -1.278794]. 
=============================================
[2019-03-22 22:15:38,318] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.3015175e-11 1.0000000e+00 8.3983133e-11 1.2941616e-13 1.3234365e-22], sum to 1.0000
[2019-03-22 22:15:38,331] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6694
[2019-03-22 22:15:38,429] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.66666666666667, 96.0, 1.0, 2.0, 0.2124579870288766, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 230675.4481465858, 230675.4481465855, 75963.14582182984], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 534000.0000, 
sim time next is 534600.0000, 
raw observation next is [13.5, 97.0, 1.0, 2.0, 0.2093696984334703, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 227321.5670497013, 227321.5670497013, 75367.65968922015], 
processed observation next is [1.0, 0.17391304347826086, 0.25, 0.97, 1.0, 1.0, 0.011712123041837871, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08419317298137084, 0.08419317298137084, 0.18382356021761012], 
reward next is 0.8162, 
noisyNet noise sample is [array([-0.48885232], dtype=float32), -0.2999596]. 
=============================================
[2019-03-22 22:15:42,739] A3C_AGENT_WORKER-Thread-9 INFO:Local step 1000, global step 15883: loss 0.0056
[2019-03-22 22:15:42,742] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 1000, global step 15883: learning rate 0.0010
[2019-03-22 22:15:42,776] A3C_AGENT_WORKER-Thread-10 INFO:Local step 1000, global step 15894: loss 0.1064
[2019-03-22 22:15:42,777] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 1000, global step 15894: learning rate 0.0010
[2019-03-22 22:15:42,803] A3C_AGENT_WORKER-Thread-19 INFO:Local step 1000, global step 15902: loss 0.1356
[2019-03-22 22:15:42,808] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 1000, global step 15903: learning rate 0.0010
[2019-03-22 22:15:42,841] A3C_AGENT_WORKER-Thread-17 INFO:Local step 1000, global step 15918: loss 0.2257
[2019-03-22 22:15:42,843] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 1000, global step 15919: learning rate 0.0010
[2019-03-22 22:15:42,851] A3C_AGENT_WORKER-Thread-3 INFO:Local step 1000, global step 15922: loss 0.1889
[2019-03-22 22:15:42,855] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 1000, global step 15924: learning rate 0.0010
[2019-03-22 22:15:42,908] A3C_AGENT_WORKER-Thread-21 INFO:Local step 1000, global step 15947: loss 0.1908
[2019-03-22 22:15:42,913] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 1000, global step 15947: learning rate 0.0010
[2019-03-22 22:15:42,932] A3C_AGENT_WORKER-Thread-15 INFO:Local step 1000, global step 15955: loss 0.5687
[2019-03-22 22:15:42,934] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 1000, global step 15955: learning rate 0.0010
[2019-03-22 22:15:42,946] A3C_AGENT_WORKER-Thread-11 INFO:Local step 1000, global step 15961: loss 0.3723
[2019-03-22 22:15:42,949] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 1000, global step 15961: learning rate 0.0010
[2019-03-22 22:15:42,962] A3C_AGENT_WORKER-Thread-14 INFO:Local step 1000, global step 15966: loss 0.2017
[2019-03-22 22:15:42,963] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 1000, global step 15966: learning rate 0.0010
[2019-03-22 22:15:43,082] A3C_AGENT_WORKER-Thread-20 INFO:Local step 1000, global step 16014: loss 0.0651
[2019-03-22 22:15:43,085] A3C_AGENT_WORKER-Thread-16 INFO:Local step 1000, global step 16014: loss 0.0699
[2019-03-22 22:15:43,086] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 1000, global step 16014: learning rate 0.0010
[2019-03-22 22:15:43,089] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 1000, global step 16015: learning rate 0.0010
[2019-03-22 22:15:43,131] A3C_AGENT_WORKER-Thread-22 INFO:Local step 1000, global step 16032: loss 0.0608
[2019-03-22 22:15:43,133] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 1000, global step 16032: learning rate 0.0010
[2019-03-22 22:15:43,192] A3C_AGENT_WORKER-Thread-12 INFO:Local step 1000, global step 16052: loss 0.0151
[2019-03-22 22:15:43,194] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 1000, global step 16053: learning rate 0.0010
[2019-03-22 22:15:43,274] A3C_AGENT_WORKER-Thread-13 INFO:Local step 1000, global step 16083: loss 0.0135
[2019-03-22 22:15:43,279] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 1000, global step 16083: learning rate 0.0010
[2019-03-22 22:15:43,392] A3C_AGENT_WORKER-Thread-2 INFO:Local step 1000, global step 16135: loss 0.2795
[2019-03-22 22:15:43,395] A3C_AGENT_WORKER-Thread-18 INFO:Local step 1000, global step 16135: loss 0.1659
[2019-03-22 22:15:43,396] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 1000, global step 16135: learning rate 0.0010
[2019-03-22 22:15:43,401] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 1000, global step 16136: learning rate 0.0010
[2019-03-22 22:15:44,998] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.5685214e-13 1.0000000e+00 2.6175841e-11 2.5429623e-13 3.4948675e-18], sum to 1.0000
[2019-03-22 22:15:45,009] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2498
[2019-03-22 22:15:45,102] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.66666666666667, 90.33333333333334, 1.0, 2.0, 0.2846430769564107, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 309075.0370585172, 309075.0370585169, 107003.6708553076], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 631200.0000, 
sim time next is 631800.0000, 
raw observation next is [17.0, 88.5, 1.0, 2.0, 0.2888527293400111, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 313647.4933773316, 313647.4933773314, 110451.8874143725], 
processed observation next is [1.0, 0.30434782608695654, 0.4090909090909091, 0.885, 1.0, 1.0, 0.11106591167501387, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11616573828790058, 0.11616573828790053, 0.26939484735212804], 
reward next is 0.7306, 
noisyNet noise sample is [array([1.0271715], dtype=float32), 0.8640986]. 
=============================================
[2019-03-22 22:15:52,852] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.783114e-03 9.895036e-02 9.517206e-05 9.910364e-03 8.822610e-01], sum to 1.0000
[2019-03-22 22:15:52,866] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3077
[2019-03-22 22:15:52,957] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.66666666666666, 56.0, 1.0, 2.0, 0.6066453498917789, 1.0, 1.0, 0.6066453498917789, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1378834.330300053, 1378834.330300053, 259486.2054995453], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 744000.0000, 
sim time next is 744600.0000, 
raw observation next is [27.83333333333334, 55.5, 1.0, 2.0, 0.4167692768817012, 1.0, 2.0, 0.4167692768817012, 1.0, 1.0, 0.8439652507704217, 6.911199999999999, 6.9112, 77.3421103, 1417103.384465184, 1417103.384465184, 311145.3712970279], 
processed observation next is [1.0, 0.6086956521739131, 0.9015151515151518, 0.555, 1.0, 1.0, 0.27096159610212645, 1.0, 1.0, 0.27096159610212645, 1.0, 0.5, 0.7770932153863169, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.5248531053574755, 0.5248531053574755, 0.7588911495049462], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.02923929], dtype=float32), -0.13377741]. 
=============================================
[2019-03-22 22:16:00,167] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.7313057e-05 5.1267278e-08 3.7113288e-05 9.9994254e-01 2.9332427e-06], sum to 1.0000
[2019-03-22 22:16:00,178] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1037
[2019-03-22 22:16:00,184] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.5, 63.5, 1.0, 2.0, 0.2526189283730829, 1.0, 2.0, 0.2526189283730829, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 575113.3546649943, 575113.3546649939, 180566.5737038384], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 847800.0000, 
sim time next is 848400.0000, 
raw observation next is [26.33333333333334, 64.0, 1.0, 2.0, 0.2510452852780568, 1.0, 2.0, 0.2510452852780568, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 571701.5251186996, 571701.5251187, 180140.657035934], 
processed observation next is [0.0, 0.8260869565217391, 0.8333333333333336, 0.64, 1.0, 1.0, 0.063806606597571, 1.0, 1.0, 0.063806606597571, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2117413055995184, 0.2117413055995185, 0.4393674561852049], 
reward next is 0.5606, 
noisyNet noise sample is [array([-1.48942], dtype=float32), 1.2588015]. 
=============================================
[2019-03-22 22:16:01,831] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.6015176e-09 3.9407611e-02 2.6328533e-09 9.6059233e-01 2.5668816e-11], sum to 1.0000
[2019-03-22 22:16:01,839] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7119
[2019-03-22 22:16:01,845] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [19.83333333333334, 89.00000000000001, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 452862.7279485962, 452862.7279485965, 164674.3330018024], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 871800.0000, 
sim time next is 872400.0000, 
raw observation next is [19.66666666666667, 90.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 452940.8354143014, 452940.8354143014, 164580.6426086468], 
processed observation next is [0.0, 0.08695652173913043, 0.5303030303030305, 0.9, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16775586496825975, 0.16775586496825975, 0.4014162014845044], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.49836567], dtype=float32), 0.8915023]. 
=============================================
[2019-03-22 22:16:03,124] A3C_AGENT_WORKER-Thread-10 INFO:Local step 1500, global step 23826: loss 1.2941
[2019-03-22 22:16:03,128] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 1500, global step 23828: learning rate 0.0010
[2019-03-22 22:16:03,340] A3C_AGENT_WORKER-Thread-19 INFO:Local step 1500, global step 23911: loss 1.3824
[2019-03-22 22:16:03,344] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 1500, global step 23913: learning rate 0.0010
[2019-03-22 22:16:03,424] A3C_AGENT_WORKER-Thread-14 INFO:Local step 1500, global step 23944: loss 1.5350
[2019-03-22 22:16:03,428] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 1500, global step 23945: learning rate 0.0010
[2019-03-22 22:16:03,429] A3C_AGENT_WORKER-Thread-9 INFO:Local step 1500, global step 23947: loss 1.4887
[2019-03-22 22:16:03,439] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 1500, global step 23949: learning rate 0.0010
[2019-03-22 22:16:03,447] A3C_AGENT_WORKER-Thread-15 INFO:Local step 1500, global step 23950: loss 1.3030
[2019-03-22 22:16:03,451] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 1500, global step 23950: learning rate 0.0010
[2019-03-22 22:16:03,456] A3C_AGENT_WORKER-Thread-21 INFO:Local step 1500, global step 23953: loss 1.0836
[2019-03-22 22:16:03,462] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 1500, global step 23955: learning rate 0.0010
[2019-03-22 22:16:03,471] A3C_AGENT_WORKER-Thread-3 INFO:Local step 1500, global step 23959: loss 1.5270
[2019-03-22 22:16:03,473] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 1500, global step 23959: learning rate 0.0010
[2019-03-22 22:16:03,482] A3C_AGENT_WORKER-Thread-11 INFO:Local step 1500, global step 23964: loss 1.3626
[2019-03-22 22:16:03,485] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 1500, global step 23966: learning rate 0.0010
[2019-03-22 22:16:03,527] A3C_AGENT_WORKER-Thread-16 INFO:Local step 1500, global step 23981: loss 1.1096
[2019-03-22 22:16:03,533] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 1500, global step 23983: learning rate 0.0010
[2019-03-22 22:16:03,586] A3C_AGENT_WORKER-Thread-17 INFO:Local step 1500, global step 24006: loss 1.2156
[2019-03-22 22:16:03,589] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 1500, global step 24007: learning rate 0.0010
[2019-03-22 22:16:03,601] A3C_AGENT_WORKER-Thread-13 INFO:Local step 1500, global step 24012: loss 0.8495
[2019-03-22 22:16:03,604] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 1500, global step 24012: learning rate 0.0010
[2019-03-22 22:16:03,693] A3C_AGENT_WORKER-Thread-22 INFO:Local step 1500, global step 24050: loss 0.6332
[2019-03-22 22:16:03,697] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 1500, global step 24051: learning rate 0.0010
[2019-03-22 22:16:03,716] A3C_AGENT_WORKER-Thread-20 INFO:Local step 1500, global step 24059: loss 0.4557
[2019-03-22 22:16:03,720] A3C_AGENT_WORKER-Thread-2 INFO:Local step 1500, global step 24060: loss 0.7479
[2019-03-22 22:16:03,721] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 1500, global step 24060: learning rate 0.0010
[2019-03-22 22:16:03,721] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 1500, global step 24061: learning rate 0.0010
[2019-03-22 22:16:03,791] A3C_AGENT_WORKER-Thread-12 INFO:Local step 1500, global step 24085: loss 0.5756
[2019-03-22 22:16:03,795] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 1500, global step 24085: learning rate 0.0010
[2019-03-22 22:16:03,799] A3C_AGENT_WORKER-Thread-18 INFO:Local step 1500, global step 24089: loss 0.4811
[2019-03-22 22:16:03,803] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 1500, global step 24089: learning rate 0.0010
[2019-03-22 22:16:06,129] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-22 22:16:06,132] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-22 22:16:06,132] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-22 22:16:06,133] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:16:06,135] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-22 22:16:06,136] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-22 22:16:06,135] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:16:06,138] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:16:06,138] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:16:06,137] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-22 22:16:06,141] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:16:06,162] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run2
[2019-03-22 22:16:06,163] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run2
[2019-03-22 22:16:06,164] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run2
[2019-03-22 22:16:06,185] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run2
[2019-03-22 22:16:06,252] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run2
[2019-03-22 22:16:24,791] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.2775425], dtype=float32), 0.13769881]
[2019-03-22 22:16:24,794] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.21666666666667, 60.66666666666666, 1.0, 2.0, 0.5816492539874788, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 662985.4227219938, 662985.4227219938, 156885.0070976456]
[2019-03-22 22:16:24,795] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 22:16:24,798] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.3730497e-26 1.0000000e+00 2.6110221e-26 2.0091591e-14 9.8930168e-28], sampled 0.4496200886795383
[2019-03-22 22:16:53,313] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.2775425], dtype=float32), 0.13769881]
[2019-03-22 22:16:53,313] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.3, 61.66666666666667, 1.0, 2.0, 0.5311256961870804, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 604951.3865327421, 604951.3865327421, 150930.5464805978]
[2019-03-22 22:16:53,314] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 22:16:53,315] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.7158917e-27 1.0000000e+00 2.7386027e-27 3.2831559e-14 1.8479619e-28], sampled 0.5850103048319537
[2019-03-22 22:17:07,403] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.2775425], dtype=float32), 0.13769881]
[2019-03-22 22:17:07,404] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.91666666666667, 77.5, 1.0, 2.0, 0.2786368806913792, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 302551.2782646624, 302551.2782646621, 101028.7155958319]
[2019-03-22 22:17:07,405] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 22:17:07,407] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.8808331e-22 1.0000000e+00 3.6297156e-22 3.1131423e-13 8.5505478e-24], sampled 0.46546037277156493
[2019-03-22 22:17:10,001] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.2775425], dtype=float32), 0.13769881]
[2019-03-22 22:17:10,001] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.05, 69.83333333333333, 1.0, 2.0, 0.4219824704220616, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 478772.9241614001, 478772.9241613997, 133166.3055433196]
[2019-03-22 22:17:10,001] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 22:17:10,004] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [8.5483581e-25 1.0000000e+00 6.7641396e-25 1.4627814e-13 2.1040903e-26], sampled 0.7275389010316938
[2019-03-22 22:17:24,005] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.2775425], dtype=float32), 0.13769881]
[2019-03-22 22:17:24,006] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.33400928333333, 71.37294045000002, 1.0, 2.0, 0.3323895677043692, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 360913.4787095396, 360913.47870954, 105957.9963758559]
[2019-03-22 22:17:24,008] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 22:17:24,010] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.9940394e-23 1.0000000e+00 1.4845600e-23 4.9279266e-13 5.0676913e-25], sampled 0.3851712099543865
[2019-03-22 22:17:28,326] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.2775425], dtype=float32), 0.13769881]
[2019-03-22 22:17:28,329] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [27.4, 41.33333333333334, 1.0, 2.0, 0.3784012661098506, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 425757.6991161208, 425757.6991161204, 126913.5680752469]
[2019-03-22 22:17:28,330] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 22:17:28,333] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.0966552e-25 1.0000000e+00 7.4491839e-26 1.4310425e-13 6.1285803e-27], sampled 0.16168822231784863
[2019-03-22 22:17:59,744] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.2775425], dtype=float32), 0.13769881]
[2019-03-22 22:17:59,744] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [13.8, 78.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 214352.9149994753, 214352.9149994756, 69981.9586707609]
[2019-03-22 22:17:59,745] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 22:17:59,747] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.5972404e-21 1.0000000e+00 2.2295347e-21 6.8431057e-13 7.0891705e-23], sampled 0.04537322984532677
[2019-03-22 22:18:05,268] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.2775425], dtype=float32), 0.13769881]
[2019-03-22 22:18:05,268] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.15761076, 100.0, 1.0, 2.0, 0.4526289998830511, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 515973.8664228739, 515973.8664228735, 138559.6705626363]
[2019-03-22 22:18:05,268] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 22:18:05,269] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [6.3206895e-26 1.0000000e+00 8.6936096e-26 1.2149873e-13 1.5317403e-27], sampled 0.5219476736838556
[2019-03-22 22:18:09,946] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-22 22:18:09,989] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-22 22:18:10,036] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-22 22:18:10,067] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1147 1656209757.7786 80.0000
[2019-03-22 22:18:10,151] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-22 22:18:11,168] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 25000, evaluation results [25000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.114669779829, 1656209757.7786272, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-22 22:18:15,650] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.5867050e-23 1.0000000e+00 1.2690699e-24 3.0937757e-12 5.1008842e-22], sum to 1.0000
[2019-03-22 22:18:15,665] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1597
[2019-03-22 22:18:15,672] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 100.0, 1.0, 2.0, 0.4842278031282397, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 525908.0581059431, 525908.0581059431, 108840.2288272988], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1009800.0000, 
sim time next is 1010400.0000, 
raw observation next is [14.0, 100.0, 1.0, 2.0, 0.4788890421458148, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 520106.6575049819, 520106.6575049819, 108238.4175700115], 
processed observation next is [1.0, 0.6956521739130435, 0.2727272727272727, 1.0, 1.0, 1.0, 0.3486113026822685, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1926320953722155, 0.1926320953722155, 0.2639961404146622], 
reward next is 0.7360, 
noisyNet noise sample is [array([0.39977726], dtype=float32), -0.27691293]. 
=============================================
[2019-03-22 22:18:25,525] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.8300747e-33 1.0000000e+00 1.0347706e-30 6.6881258e-22 4.5345329e-31], sum to 1.0000
[2019-03-22 22:18:25,533] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3903
[2019-03-22 22:18:25,537] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 99.0, 1.0, 2.0, 0.3661890346864636, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 410372.3726361143, 410372.3726361143, 120725.5950456322], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1147800.0000, 
sim time next is 1148400.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.3687835925934727, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 413830.4518646052, 413830.4518646052, 121206.4192798456], 
processed observation next is [1.0, 0.30434782608695654, 0.45454545454545453, 1.0, 1.0, 1.0, 0.21097949074184086, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15327053772763155, 0.15327053772763155, 0.2956254128776722], 
reward next is 0.7044, 
noisyNet noise sample is [array([0.97967947], dtype=float32), -0.31854627]. 
=============================================
[2019-03-22 22:18:26,846] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.2548607e-29 1.0000000e+00 1.2235787e-27 2.4239300e-17 1.4823421e-30], sum to 1.0000
[2019-03-22 22:18:26,852] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9498
[2019-03-22 22:18:26,863] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1222159.026077215 W.
[2019-03-22 22:18:26,868] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.66666666666667, 67.33333333333334, 1.0, 2.0, 0.5944987461969665, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9792940846793796, 6.911200000000001, 6.9112, 77.32846344354104, 1222159.026077215, 1222159.026077215, 278626.1381661565], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1172400.0000, 
sim time next is 1173000.0000, 
raw observation next is [26.83333333333333, 66.66666666666666, 1.0, 2.0, 0.5752872399782356, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9784889219045906, 6.9112, 6.9112, 77.32846344354104, 1200994.354150088, 1200994.354150088, 275162.9038108183], 
processed observation next is [1.0, 0.5652173913043478, 0.8560606060606059, 0.6666666666666665, 1.0, 1.0, 0.46910904997279446, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9692698884351295, 0.0, 0.0, 0.5084288129206541, 0.4448127237592919, 0.4448127237592919, 0.6711290336849226], 
reward next is 0.3289, 
noisyNet noise sample is [array([1.3692558], dtype=float32), -1.008877]. 
=============================================
[2019-03-22 22:18:26,891] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[82.45934 ]
 [83.34707 ]
 [84.532234]
 [84.05114 ]
 [83.96507 ]], R is [[81.17436218]
 [80.36261749]
 [79.84191895]
 [79.50714111]
 [79.28795624]].
[2019-03-22 22:18:28,512] A3C_AGENT_WORKER-Thread-10 INFO:Local step 2000, global step 31817: loss 1.6236
[2019-03-22 22:18:28,514] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 2000, global step 31817: learning rate 0.0010
[2019-03-22 22:18:28,647] A3C_AGENT_WORKER-Thread-9 INFO:Local step 2000, global step 31872: loss 1.0856
[2019-03-22 22:18:28,654] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 2000, global step 31875: learning rate 0.0010
[2019-03-22 22:18:28,731] A3C_AGENT_WORKER-Thread-19 INFO:Local step 2000, global step 31903: loss 0.6204
[2019-03-22 22:18:28,733] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 2000, global step 31903: learning rate 0.0010
[2019-03-22 22:18:28,749] A3C_AGENT_WORKER-Thread-14 INFO:Local step 2000, global step 31908: loss 0.7784
[2019-03-22 22:18:28,751] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 2000, global step 31908: learning rate 0.0010
[2019-03-22 22:18:28,832] A3C_AGENT_WORKER-Thread-16 INFO:Local step 2000, global step 31942: loss 0.5206
[2019-03-22 22:18:28,834] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 2000, global step 31942: learning rate 0.0010
[2019-03-22 22:18:28,852] A3C_AGENT_WORKER-Thread-21 INFO:Local step 2000, global step 31949: loss 0.4161
[2019-03-22 22:18:28,860] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 2000, global step 31949: learning rate 0.0010
[2019-03-22 22:18:28,893] A3C_AGENT_WORKER-Thread-15 INFO:Local step 2000, global step 31965: loss 0.3892
[2019-03-22 22:18:28,896] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 2000, global step 31966: learning rate 0.0010
[2019-03-22 22:18:28,934] A3C_AGENT_WORKER-Thread-3 INFO:Local step 2000, global step 31980: loss 0.1993
[2019-03-22 22:18:28,939] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 2000, global step 31980: learning rate 0.0010
[2019-03-22 22:18:28,961] A3C_AGENT_WORKER-Thread-11 INFO:Local step 2000, global step 31988: loss 0.2418
[2019-03-22 22:18:28,963] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 2000, global step 31989: learning rate 0.0010
[2019-03-22 22:18:29,084] A3C_AGENT_WORKER-Thread-22 INFO:Local step 2000, global step 32037: loss 0.2166
[2019-03-22 22:18:29,093] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 2000, global step 32039: learning rate 0.0010
[2019-03-22 22:18:29,099] A3C_AGENT_WORKER-Thread-17 INFO:Local step 2000, global step 32044: loss 0.0754
[2019-03-22 22:18:29,100] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 2000, global step 32044: learning rate 0.0010
[2019-03-22 22:18:29,111] A3C_AGENT_WORKER-Thread-2 INFO:Local step 2000, global step 32048: loss 0.1255
[2019-03-22 22:18:29,115] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 2000, global step 32049: learning rate 0.0010
[2019-03-22 22:18:29,149] A3C_AGENT_WORKER-Thread-13 INFO:Local step 2000, global step 32062: loss 0.2013
[2019-03-22 22:18:29,155] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 2000, global step 32063: learning rate 0.0010
[2019-03-22 22:18:29,189] A3C_AGENT_WORKER-Thread-12 INFO:Local step 2000, global step 32076: loss 0.0942
[2019-03-22 22:18:29,190] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 2000, global step 32076: learning rate 0.0010
[2019-03-22 22:18:29,219] A3C_AGENT_WORKER-Thread-20 INFO:Local step 2000, global step 32085: loss 0.0616
[2019-03-22 22:18:29,221] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 2000, global step 32086: learning rate 0.0010
[2019-03-22 22:18:29,329] A3C_AGENT_WORKER-Thread-18 INFO:Local step 2000, global step 32135: loss 0.0939
[2019-03-22 22:18:29,330] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 2000, global step 32136: learning rate 0.0010
[2019-03-22 22:18:30,141] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 2.1707522e-38 1.4491991e-35 0.0000000e+00], sum to 1.0000
[2019-03-22 22:18:30,152] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7296
[2019-03-22 22:18:30,159] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.9, 83.66666666666667, 1.0, 2.0, 0.5210440839737538, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 593195.9301219936, 593195.9301219936, 145663.0709208692], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1212600.0000, 
sim time next is 1213200.0000, 
raw observation next is [24.0, 83.0, 1.0, 2.0, 0.5204269174985957, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 592477.8459733204, 592477.8459733204, 145598.9860243731], 
processed observation next is [1.0, 0.043478260869565216, 0.7272727272727273, 0.83, 1.0, 1.0, 0.4005336468732446, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21943623924937794, 0.21943623924937794, 0.3551194781082271], 
reward next is 0.6449, 
noisyNet noise sample is [array([0.07218132], dtype=float32), 1.1602049]. 
=============================================
[2019-03-22 22:18:34,536] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.2849341e-20 1.0000000e+00 2.0042710e-18 3.2496679e-11 3.2085318e-15], sum to 1.0000
[2019-03-22 22:18:34,549] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6335
[2019-03-22 22:18:34,661] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 94.0, 1.0, 2.0, 0.375395842396367, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 417883.6461790773, 417883.6461790773, 120261.4359890788], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1282800.0000, 
sim time next is 1283400.0000, 
raw observation next is [18.0, 94.0, 1.0, 2.0, 0.3730766893174353, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 415271.3984046483, 415271.3984046483, 120058.0559608062], 
processed observation next is [1.0, 0.8695652173913043, 0.45454545454545453, 0.94, 1.0, 1.0, 0.21634586164679412, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1538042216313512, 0.1538042216313512, 0.29282452673367365], 
reward next is 0.7072, 
noisyNet noise sample is [array([2.3808682], dtype=float32), -0.8209346]. 
=============================================
[2019-03-22 22:18:45,795] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.9081358e-25 1.0000000e+00 5.4607371e-27 5.9106244e-17 4.7235095e-21], sum to 1.0000
[2019-03-22 22:18:45,804] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9339
[2019-03-22 22:18:45,911] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 98.0, 1.0, 2.0, 0.4816483103512926, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 549602.0290041616, 549602.0290041614, 138957.5449397267], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1448400.0000, 
sim time next is 1449000.0000, 
raw observation next is [21.0, 97.0, 1.0, 2.0, 0.47712883238344, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 544440.3679564478, 544440.3679564478, 138197.7518135987], 
processed observation next is [0.0, 0.782608695652174, 0.5909090909090909, 0.97, 1.0, 1.0, 0.3464110404793, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20164458072461028, 0.20164458072461028, 0.33706768735024073], 
reward next is 0.6629, 
noisyNet noise sample is [array([1.0418842], dtype=float32), 0.7390502]. 
=============================================
[2019-03-22 22:18:45,943] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[67.731224]
 [67.67915 ]
 [67.61718 ]
 [67.5529  ]
 [67.5029  ]], R is [[67.75845337]
 [67.74195099]
 [67.72379303]
 [67.70441437]
 [67.68495941]].
[2019-03-22 22:18:49,165] A3C_AGENT_WORKER-Thread-10 INFO:Local step 2500, global step 39855: loss 0.0004
[2019-03-22 22:18:49,170] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 2500, global step 39856: learning rate 0.0010
[2019-03-22 22:18:49,260] A3C_AGENT_WORKER-Thread-9 INFO:Local step 2500, global step 39894: loss 0.0368
[2019-03-22 22:18:49,262] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 2500, global step 39894: learning rate 0.0010
[2019-03-22 22:18:49,274] A3C_AGENT_WORKER-Thread-19 INFO:Local step 2500, global step 39898: loss 0.0833
[2019-03-22 22:18:49,276] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 2500, global step 39899: learning rate 0.0010
[2019-03-22 22:18:49,285] A3C_AGENT_WORKER-Thread-16 INFO:Local step 2500, global step 39902: loss 0.0194
[2019-03-22 22:18:49,288] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 2500, global step 39902: learning rate 0.0010
[2019-03-22 22:18:49,341] A3C_AGENT_WORKER-Thread-3 INFO:Local step 2500, global step 39920: loss 0.0752
[2019-03-22 22:18:49,343] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 2500, global step 39920: learning rate 0.0010
[2019-03-22 22:18:49,422] A3C_AGENT_WORKER-Thread-15 INFO:Local step 2500, global step 39953: loss 0.0657
[2019-03-22 22:18:49,426] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 2500, global step 39953: learning rate 0.0010
[2019-03-22 22:18:49,431] A3C_AGENT_WORKER-Thread-21 INFO:Local step 2500, global step 39956: loss 0.0613
[2019-03-22 22:18:49,434] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 2500, global step 39956: learning rate 0.0010
[2019-03-22 22:18:49,443] A3C_AGENT_WORKER-Thread-11 INFO:Local step 2500, global step 39960: loss 0.0358
[2019-03-22 22:18:49,449] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 2500, global step 39962: learning rate 0.0010
[2019-03-22 22:18:49,485] A3C_AGENT_WORKER-Thread-14 INFO:Local step 2500, global step 39980: loss 0.0364
[2019-03-22 22:18:49,490] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 2500, global step 39981: learning rate 0.0010
[2019-03-22 22:18:49,519] A3C_AGENT_WORKER-Thread-17 INFO:Local step 2500, global step 39990: loss 0.0084
[2019-03-22 22:18:49,526] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 2500, global step 39991: learning rate 0.0010
[2019-03-22 22:18:49,601] A3C_AGENT_WORKER-Thread-22 INFO:Local step 2500, global step 40021: loss 0.0029
[2019-03-22 22:18:49,603] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 2500, global step 40023: learning rate 0.0010
[2019-03-22 22:18:49,681] A3C_AGENT_WORKER-Thread-2 INFO:Local step 2500, global step 40054: loss 0.0510
[2019-03-22 22:18:49,684] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 2500, global step 40056: learning rate 0.0010
[2019-03-22 22:18:49,715] A3C_AGENT_WORKER-Thread-12 INFO:Local step 2500, global step 40069: loss 0.0831
[2019-03-22 22:18:49,720] A3C_AGENT_WORKER-Thread-13 INFO:Local step 2500, global step 40070: loss 0.0700
[2019-03-22 22:18:49,720] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 2500, global step 40070: learning rate 0.0010
[2019-03-22 22:18:49,722] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 2500, global step 40070: learning rate 0.0010
[2019-03-22 22:18:49,879] A3C_AGENT_WORKER-Thread-20 INFO:Local step 2500, global step 40133: loss 0.0669
[2019-03-22 22:18:49,882] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 2500, global step 40133: learning rate 0.0010
[2019-03-22 22:18:49,947] A3C_AGENT_WORKER-Thread-18 INFO:Local step 2500, global step 40155: loss 0.0044
[2019-03-22 22:18:49,949] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 2500, global step 40155: learning rate 0.0010
[2019-03-22 22:19:01,420] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.5333863e-29 1.0000000e+00 4.8789776e-27 1.4917360e-15 2.8116851e-28], sum to 1.0000
[2019-03-22 22:19:01,427] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1434
[2019-03-22 22:19:01,436] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 90.0, 1.0, 2.0, 0.5569430480895754, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 617337.9318874725, 617337.9318874725, 136264.49852985], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1676400.0000, 
sim time next is 1677000.0000, 
raw observation next is [18.0, 89.0, 1.0, 2.0, 0.5398251500079626, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 597180.2348087722, 597180.2348087722, 134086.7102312262], 
processed observation next is [1.0, 0.391304347826087, 0.45454545454545453, 0.89, 1.0, 1.0, 0.42478143750995323, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2211778647439897, 0.2211778647439897, 0.3270407566615273], 
reward next is 0.6730, 
noisyNet noise sample is [array([0.24000096], dtype=float32), -1.0357827]. 
=============================================
[2019-03-22 22:19:01,459] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[72.876205]
 [72.84483 ]
 [72.80111 ]
 [72.766464]
 [72.71776 ]], R is [[72.83473206]
 [72.77403259]
 [72.70579529]
 [72.63748169]
 [72.56316376]].
[2019-03-22 22:19:02,214] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.9309161e-28 1.0000000e+00 2.3398878e-27 3.5145763e-13 2.2352227e-29], sum to 1.0000
[2019-03-22 22:19:02,223] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4524
[2019-03-22 22:19:02,322] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.25, 65.0, 1.0, 2.0, 0.4566659311500944, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 496632.5884228879, 496632.5884228876, 123292.5509885148], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1689000.0000, 
sim time next is 1689600.0000, 
raw observation next is [20.4, 64.0, 1.0, 2.0, 0.5587578680199821, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 608197.7997584784, 608197.7997584784, 132740.0796030096], 
processed observation next is [1.0, 0.5652173913043478, 0.5636363636363636, 0.64, 1.0, 1.0, 0.4484473350249775, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.225258444354992, 0.225258444354992, 0.32375629171465753], 
reward next is 0.6762, 
noisyNet noise sample is [array([0.2630732], dtype=float32), -0.94830304]. 
=============================================
[2019-03-22 22:19:03,754] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.5398390e-34 1.0000000e+00 1.5345312e-33 5.1123683e-18 8.0967206e-34], sum to 1.0000
[2019-03-22 22:19:03,764] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4801
[2019-03-22 22:19:03,772] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.5, 50.5, 1.0, 2.0, 0.2489060489384469, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 270259.7868428361, 270259.7868428361, 75466.98465493109], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1708200.0000, 
sim time next is 1708800.0000, 
raw observation next is [17.33333333333333, 51.0, 1.0, 2.0, 0.2451835334610601, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 266216.809253199, 266216.809253199, 74959.04740680095], 
processed observation next is [1.0, 0.782608695652174, 0.42424242424242403, 0.51, 1.0, 1.0, 0.056479416826325096, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09859881824192557, 0.09859881824192557, 0.18282694489463647], 
reward next is 0.8172, 
noisyNet noise sample is [array([0.91023886], dtype=float32), 0.8300815]. 
=============================================
[2019-03-22 22:19:09,552] A3C_AGENT_WORKER-Thread-10 INFO:Local step 3000, global step 47846: loss 0.0014
[2019-03-22 22:19:09,556] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 3000, global step 47847: learning rate 0.0010
[2019-03-22 22:19:09,666] A3C_AGENT_WORKER-Thread-11 INFO:Local step 3000, global step 47887: loss 0.0086
[2019-03-22 22:19:09,668] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 3000, global step 47888: learning rate 0.0010
[2019-03-22 22:19:09,739] A3C_AGENT_WORKER-Thread-16 INFO:Local step 3000, global step 47919: loss 0.0954
[2019-03-22 22:19:09,741] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 3000, global step 47919: learning rate 0.0010
[2019-03-22 22:19:09,745] A3C_AGENT_WORKER-Thread-9 INFO:Local step 3000, global step 47920: loss 0.1930
[2019-03-22 22:19:09,747] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 3000, global step 47921: learning rate 0.0010
[2019-03-22 22:19:09,783] A3C_AGENT_WORKER-Thread-21 INFO:Local step 3000, global step 47934: loss 0.3525
[2019-03-22 22:19:09,786] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 3000, global step 47934: learning rate 0.0010
[2019-03-22 22:19:09,806] A3C_AGENT_WORKER-Thread-17 INFO:Local step 3000, global step 47942: loss 0.1663
[2019-03-22 22:19:09,810] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 3000, global step 47943: learning rate 0.0010
[2019-03-22 22:19:09,816] A3C_AGENT_WORKER-Thread-19 INFO:Local step 3000, global step 47945: loss 0.0127
[2019-03-22 22:19:09,821] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 3000, global step 47945: learning rate 0.0010
[2019-03-22 22:19:09,839] A3C_AGENT_WORKER-Thread-3 INFO:Local step 3000, global step 47953: loss 0.0527
[2019-03-22 22:19:09,841] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 3000, global step 47953: learning rate 0.0010
[2019-03-22 22:19:09,869] A3C_AGENT_WORKER-Thread-14 INFO:Local step 3000, global step 47964: loss 0.1047
[2019-03-22 22:19:09,873] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 3000, global step 47964: learning rate 0.0010
[2019-03-22 22:19:09,874] A3C_AGENT_WORKER-Thread-15 INFO:Local step 3000, global step 47965: loss 0.0242
[2019-03-22 22:19:09,877] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 3000, global step 47965: learning rate 0.0010
[2019-03-22 22:19:09,911] A3C_AGENT_WORKER-Thread-22 INFO:Local step 3000, global step 47979: loss 0.0003
[2019-03-22 22:19:09,912] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 3000, global step 47979: learning rate 0.0010
[2019-03-22 22:19:10,065] A3C_AGENT_WORKER-Thread-2 INFO:Local step 3000, global step 48039: loss 0.0749
[2019-03-22 22:19:10,066] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 3000, global step 48039: learning rate 0.0010
[2019-03-22 22:19:10,183] A3C_AGENT_WORKER-Thread-20 INFO:Local step 3000, global step 48086: loss 0.1540
[2019-03-22 22:19:10,186] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 3000, global step 48086: learning rate 0.0010
[2019-03-22 22:19:10,202] A3C_AGENT_WORKER-Thread-12 INFO:Local step 3000, global step 48092: loss 0.1448
[2019-03-22 22:19:10,208] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 3000, global step 48094: learning rate 0.0010
[2019-03-22 22:19:10,229] A3C_AGENT_WORKER-Thread-13 INFO:Local step 3000, global step 48101: loss 0.0800
[2019-03-22 22:19:10,231] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 3000, global step 48103: learning rate 0.0010
[2019-03-22 22:19:10,526] A3C_AGENT_WORKER-Thread-18 INFO:Local step 3000, global step 48217: loss 0.1830
[2019-03-22 22:19:10,528] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 3000, global step 48218: learning rate 0.0010
[2019-03-22 22:19:10,707] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.781969e-32 1.000000e+00 9.752013e-37 5.505509e-23 0.000000e+00], sum to 1.0000
[2019-03-22 22:19:10,717] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4520
[2019-03-22 22:19:10,724] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.33333333333333, 61.66666666666667, 1.0, 2.0, 0.2076574415421734, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 225462.0662072988, 225462.0662072991, 70615.68025080557], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1812000.0000, 
sim time next is 1812600.0000, 
raw observation next is [15.0, 63.0, 1.0, 2.0, 0.2039200223960056, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 221403.2758436803, 221403.2758436801, 70055.96774573112], 
processed observation next is [1.0, 1.0, 0.3181818181818182, 0.63, 1.0, 1.0, 0.004900027995006981, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08200121327543715, 0.08200121327543708, 0.17086821401397834], 
reward next is 0.8291, 
noisyNet noise sample is [array([-0.26044747], dtype=float32), -0.472612]. 
=============================================
[2019-03-22 22:19:15,068] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-22 22:19:15,073] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-22 22:19:15,074] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-22 22:19:15,075] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-22 22:19:15,077] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-22 22:19:15,078] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-22 22:19:15,082] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:19:15,083] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:19:15,083] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:19:15,076] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:19:15,078] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:19:15,097] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run3
[2019-03-22 22:19:15,098] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run3
[2019-03-22 22:19:15,114] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run3
[2019-03-22 22:19:15,116] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run3
[2019-03-22 22:19:15,174] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run3
[2019-03-22 22:19:22,077] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.2510479], dtype=float32), -0.09855051]
[2019-03-22 22:19:22,079] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.8, 65.33333333333334, 1.0, 2.0, 0.4246812829604188, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 478267.972517081, 478267.972517081, 131287.5434233325]
[2019-03-22 22:19:22,079] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 22:19:22,082] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [6.6978957e-32 1.0000000e+00 2.6568589e-33 1.4764064e-21 4.4344037e-34], sampled 0.6897484664754646
[2019-03-22 22:20:01,267] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.2510479], dtype=float32), -0.09855051]
[2019-03-22 22:20:01,269] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.34412602, 85.85607527666667, 1.0, 2.0, 0.68811741917796, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 783927.2298479292, 783927.2298479292, 172073.0598270333]
[2019-03-22 22:20:01,271] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 22:20:01,274] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.0529359e-30 1.0000000e+00 2.1632458e-31 7.5847721e-14 4.0522506e-31], sampled 0.1922213055471388
[2019-03-22 22:20:28,311] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.2510479], dtype=float32), -0.09855051]
[2019-03-22 22:20:28,312] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.92959745, 77.70806336, 1.0, 2.0, 0.3292628523632448, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 360713.7869670819, 360713.7869670819, 118619.0465383593]
[2019-03-22 22:20:28,312] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 22:20:28,316] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.9422862e-31 1.0000000e+00 1.1302203e-32 5.2219876e-22 3.9387646e-33], sampled 0.951596151539936
[2019-03-22 22:20:39,701] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.2510479], dtype=float32), -0.09855051]
[2019-03-22 22:20:39,703] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [26.1, 54.0, 1.0, 2.0, 0.4188533316751809, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 475932.556197922, 475932.556197922, 129072.9868929396]
[2019-03-22 22:20:39,706] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 22:20:39,709] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.32094955e-30 1.00000000e+00 8.81281986e-32 4.35100492e-20
 3.80227959e-32], sampled 0.7652506516323707
[2019-03-22 22:20:50,914] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.2510479], dtype=float32), -0.09855051]
[2019-03-22 22:20:50,915] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.43333333333334, 71.33333333333334, 1.0, 2.0, 0.6302579647321433, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 719188.5956067394, 719188.5956067394, 161140.3164517927]
[2019-03-22 22:20:50,916] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 22:20:50,920] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [8.2976861e-33 1.0000000e+00 7.0535235e-34 3.5565672e-21 3.2396395e-35], sampled 0.6323669582205065
[2019-03-22 22:20:52,519] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.2510479], dtype=float32), -0.09855051]
[2019-03-22 22:20:52,519] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.25, 71.0, 1.0, 2.0, 0.5984029337569755, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 661115.1722356452, 661115.1722356456, 139867.8286366811]
[2019-03-22 22:20:52,520] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 22:20:52,522] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [5.9039315e-32 1.0000000e+00 2.4776366e-33 6.5163203e-22 1.4184672e-34], sampled 0.7919781742874235
[2019-03-22 22:21:16,927] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.2510479], dtype=float32), -0.09855051]
[2019-03-22 22:21:16,930] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.40871313, 54.32238126666666, 1.0, 2.0, 0.4014318384123552, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 438585.1173787077, 438585.1173787077, 123743.7627255642]
[2019-03-22 22:21:16,933] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 22:21:16,935] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.1726292e-30 1.0000000e+00 8.7288408e-32 4.5898830e-20 1.5208428e-32], sampled 0.3961645443364167
[2019-03-22 22:21:18,248] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9310 1705987275.5940 465.0000
[2019-03-22 22:21:18,322] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-22 22:21:18,618] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-22 22:21:18,893] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-22 22:21:18,932] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2492 1773187030.7201 173.0000
[2019-03-22 22:21:19,947] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 50000, evaluation results [50000.0, 8512.249193409023, 1773187030.7201214, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8596.931041181726, 1705987275.594041, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-22 22:21:27,232] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.3079363e-22 1.0000000e+00 3.9915006e-29 1.4335479e-09 3.5547458e-23], sum to 1.0000
[2019-03-22 22:21:27,244] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7012
[2019-03-22 22:21:27,251] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 66.0, 1.0, 2.0, 0.311930846753211, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 338715.3350989922, 338715.3350989919, 111998.6333007394], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1985400.0000, 
sim time next is 1986000.0000, 
raw observation next is [19.66666666666667, 66.66666666666666, 1.0, 2.0, 0.3050513298042205, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 331242.552168073, 331242.5521680727, 109356.4876598977], 
processed observation next is [1.0, 1.0, 0.5303030303030305, 0.6666666666666665, 1.0, 1.0, 0.13131416225527562, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12268242672891594, 0.12268242672891583, 0.26672314063389685], 
reward next is 0.7333, 
noisyNet noise sample is [array([-0.46195954], dtype=float32), 0.43599668]. 
=============================================
[2019-03-22 22:21:27,264] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[51.301   ]
 [51.28824 ]
 [51.27203 ]
 [51.25388 ]
 [51.231194]], R is [[51.53453064]
 [51.74601746]
 [51.95363998]
 [52.15732956]
 [52.3580513 ]].
[2019-03-22 22:21:34,858] A3C_AGENT_WORKER-Thread-10 INFO:Local step 3500, global step 55856: loss 0.0184
[2019-03-22 22:21:34,859] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 3500, global step 55856: learning rate 0.0010
[2019-03-22 22:21:34,895] A3C_AGENT_WORKER-Thread-11 INFO:Local step 3500, global step 55870: loss 0.0030
[2019-03-22 22:21:34,896] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 3500, global step 55870: learning rate 0.0010
[2019-03-22 22:21:34,910] A3C_AGENT_WORKER-Thread-16 INFO:Local step 3500, global step 55873: loss 0.0304
[2019-03-22 22:21:34,912] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 3500, global step 55874: learning rate 0.0010
[2019-03-22 22:21:34,952] A3C_AGENT_WORKER-Thread-21 INFO:Local step 3500, global step 55890: loss 0.0279
[2019-03-22 22:21:34,961] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 3500, global step 55891: learning rate 0.0010
[2019-03-22 22:21:34,976] A3C_AGENT_WORKER-Thread-19 INFO:Local step 3500, global step 55895: loss 0.0807
[2019-03-22 22:21:34,978] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 3500, global step 55895: learning rate 0.0010
[2019-03-22 22:21:35,061] A3C_AGENT_WORKER-Thread-3 INFO:Local step 3500, global step 55930: loss 0.0678
[2019-03-22 22:21:35,061] A3C_AGENT_WORKER-Thread-9 INFO:Local step 3500, global step 55930: loss 0.0897
[2019-03-22 22:21:35,066] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 3500, global step 55930: learning rate 0.0010
[2019-03-22 22:21:35,067] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 3500, global step 55930: learning rate 0.0010
[2019-03-22 22:21:35,128] A3C_AGENT_WORKER-Thread-17 INFO:Local step 3500, global step 55957: loss 0.0526
[2019-03-22 22:21:35,134] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 3500, global step 55957: learning rate 0.0010
[2019-03-22 22:21:35,139] A3C_AGENT_WORKER-Thread-14 INFO:Local step 3500, global step 55958: loss 0.0696
[2019-03-22 22:21:35,144] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 3500, global step 55960: learning rate 0.0010
[2019-03-22 22:21:35,190] A3C_AGENT_WORKER-Thread-15 INFO:Local step 3500, global step 55979: loss 0.0796
[2019-03-22 22:21:35,196] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 3500, global step 55979: learning rate 0.0010
[2019-03-22 22:21:35,317] A3C_AGENT_WORKER-Thread-22 INFO:Local step 3500, global step 56026: loss 0.0273
[2019-03-22 22:21:35,320] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 3500, global step 56026: learning rate 0.0010
[2019-03-22 22:21:35,389] A3C_AGENT_WORKER-Thread-12 INFO:Local step 3500, global step 56058: loss 0.0026
[2019-03-22 22:21:35,393] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 3500, global step 56058: learning rate 0.0010
[2019-03-22 22:21:35,427] A3C_AGENT_WORKER-Thread-2 INFO:Local step 3500, global step 56069: loss 0.0029
[2019-03-22 22:21:35,432] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 3500, global step 56070: learning rate 0.0010
[2019-03-22 22:21:35,588] A3C_AGENT_WORKER-Thread-13 INFO:Local step 3500, global step 56135: loss 0.0312
[2019-03-22 22:21:35,592] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 3500, global step 56135: learning rate 0.0010
[2019-03-22 22:21:35,611] A3C_AGENT_WORKER-Thread-20 INFO:Local step 3500, global step 56142: loss 0.0613
[2019-03-22 22:21:35,616] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 3500, global step 56143: learning rate 0.0010
[2019-03-22 22:21:35,861] A3C_AGENT_WORKER-Thread-18 INFO:Local step 3500, global step 56237: loss 0.1791
[2019-03-22 22:21:35,862] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 3500, global step 56237: learning rate 0.0010
[2019-03-22 22:21:55,069] A3C_AGENT_WORKER-Thread-11 INFO:Local step 4000, global step 63770: loss 0.2989
[2019-03-22 22:21:55,078] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 4000, global step 63773: learning rate 0.0010
[2019-03-22 22:21:55,187] A3C_AGENT_WORKER-Thread-10 INFO:Local step 4000, global step 63816: loss 0.2620
[2019-03-22 22:21:55,194] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 4000, global step 63817: learning rate 0.0010
[2019-03-22 22:21:55,269] A3C_AGENT_WORKER-Thread-19 INFO:Local step 4000, global step 63848: loss 0.0454
[2019-03-22 22:21:55,275] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 4000, global step 63849: learning rate 0.0010
[2019-03-22 22:21:55,311] A3C_AGENT_WORKER-Thread-21 INFO:Local step 4000, global step 63863: loss 0.1147
[2019-03-22 22:21:55,315] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 4000, global step 63864: learning rate 0.0010
[2019-03-22 22:21:55,331] A3C_AGENT_WORKER-Thread-16 INFO:Local step 4000, global step 63871: loss 0.1215
[2019-03-22 22:21:55,335] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 4000, global step 63872: learning rate 0.0010
[2019-03-22 22:21:55,445] A3C_AGENT_WORKER-Thread-3 INFO:Local step 4000, global step 63915: loss 0.0965
[2019-03-22 22:21:55,447] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 4000, global step 63915: learning rate 0.0010
[2019-03-22 22:21:55,507] A3C_AGENT_WORKER-Thread-15 INFO:Local step 4000, global step 63940: loss 0.0017
[2019-03-22 22:21:55,510] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 4000, global step 63941: learning rate 0.0010
[2019-03-22 22:21:55,567] A3C_AGENT_WORKER-Thread-14 INFO:Local step 4000, global step 63962: loss 0.0061
[2019-03-22 22:21:55,571] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 4000, global step 63962: learning rate 0.0010
[2019-03-22 22:21:55,608] A3C_AGENT_WORKER-Thread-9 INFO:Local step 4000, global step 63978: loss 0.1467
[2019-03-22 22:21:55,609] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 4000, global step 63978: learning rate 0.0010
[2019-03-22 22:21:55,629] A3C_AGENT_WORKER-Thread-17 INFO:Local step 4000, global step 63986: loss 0.0072
[2019-03-22 22:21:55,632] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 4000, global step 63987: learning rate 0.0010
[2019-03-22 22:21:55,775] A3C_AGENT_WORKER-Thread-22 INFO:Local step 4000, global step 64043: loss 0.0318
[2019-03-22 22:21:55,780] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 4000, global step 64044: learning rate 0.0010
[2019-03-22 22:21:55,818] A3C_AGENT_WORKER-Thread-2 INFO:Local step 4000, global step 64058: loss 0.0553
[2019-03-22 22:21:55,820] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 4000, global step 64058: learning rate 0.0010
[2019-03-22 22:21:55,981] A3C_AGENT_WORKER-Thread-12 INFO:Local step 4000, global step 64125: loss 0.0932
[2019-03-22 22:21:55,986] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 4000, global step 64127: learning rate 0.0010
[2019-03-22 22:21:56,076] A3C_AGENT_WORKER-Thread-13 INFO:Local step 4000, global step 64161: loss 0.3615
[2019-03-22 22:21:56,079] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 4000, global step 64162: learning rate 0.0010
[2019-03-22 22:21:56,157] A3C_AGENT_WORKER-Thread-20 INFO:Local step 4000, global step 64193: loss 0.2713
[2019-03-22 22:21:56,160] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 4000, global step 64194: learning rate 0.0010
[2019-03-22 22:21:56,327] A3C_AGENT_WORKER-Thread-18 INFO:Local step 4000, global step 64255: loss 0.0208
[2019-03-22 22:21:56,330] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 4000, global step 64256: learning rate 0.0010
[2019-03-22 22:21:59,440] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.3228200e-38 2.2332067e-33 0.0000000e+00], sum to 1.0000
[2019-03-22 22:21:59,449] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9084
[2019-03-22 22:21:59,456] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.5, 85.0, 1.0, 2.0, 0.5107542704587484, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 554734.2493160967, 554734.2493160967, 118852.9575844881], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2457000.0000, 
sim time next is 2457600.0000, 
raw observation next is [16.66666666666666, 86.0, 1.0, 2.0, 0.5086613968613858, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 552459.87099427, 552459.8709942702, 121546.0898237038], 
processed observation next is [1.0, 0.43478260869565216, 0.39393939393939365, 0.86, 1.0, 1.0, 0.3858267460767322, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2046147670349148, 0.20461476703491488, 0.2964538776187898], 
reward next is 0.7035, 
noisyNet noise sample is [array([0.47002944], dtype=float32), -0.2776333]. 
=============================================
[2019-03-22 22:22:00,125] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.288143e-36 1.000000e+00 1.560223e-36 8.091239e-23 0.000000e+00], sum to 1.0000
[2019-03-22 22:22:00,136] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0025
[2019-03-22 22:22:00,144] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.16666666666667, 81.16666666666667, 1.0, 2.0, 0.7217736557406981, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 784108.9739954432, 784108.9739954435, 145325.3740618487], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2463000.0000, 
sim time next is 2463600.0000, 
raw observation next is [17.33333333333334, 80.33333333333334, 1.0, 2.0, 0.6323432369262454, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 686886.3078188018, 686886.3078188018, 135763.7149635712], 
processed observation next is [1.0, 0.5217391304347826, 0.42424242424242453, 0.8033333333333335, 1.0, 1.0, 0.5404290461578067, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.25440233622918584, 0.25440233622918584, 0.3311310121062712], 
reward next is 0.6689, 
noisyNet noise sample is [array([0.93479174], dtype=float32), 0.5461845]. 
=============================================
[2019-03-22 22:22:01,211] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.1640299e-35 1.0000000e+00 1.0638890e-31 8.7900945e-16 8.7331241e-35], sum to 1.0000
[2019-03-22 22:22:01,225] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9688
[2019-03-22 22:22:01,233] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.1, 62.0, 1.0, 2.0, 0.7750995563830971, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 852048.0049246709, 852048.0049246709, 159149.7442285513], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2478600.0000, 
sim time next is 2479200.0000, 
raw observation next is [21.06666666666667, 61.33333333333334, 1.0, 2.0, 0.7715382515918809, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 846300.1983953983, 846300.1983953986, 158083.3251378278], 
processed observation next is [1.0, 0.6956521739130435, 0.5939393939393941, 0.6133333333333334, 1.0, 1.0, 0.7144228144898512, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3134445179242216, 0.3134445179242217, 0.38556908570201903], 
reward next is 0.6144, 
noisyNet noise sample is [array([0.72131777], dtype=float32), -2.0930774]. 
=============================================
[2019-03-22 22:22:14,956] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.1997899e-33 1.0000000e+00 4.0860718e-32 2.1354435e-23 1.4423540e-36], sum to 1.0000
[2019-03-22 22:22:14,971] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8653
[2019-03-22 22:22:14,979] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.1, 78.33333333333333, 1.0, 2.0, 0.3557309620517927, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 396828.2020843345, 396828.2020843347, 119025.9993830151], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2680800.0000, 
sim time next is 2681400.0000, 
raw observation next is [20.05, 79.16666666666667, 1.0, 2.0, 0.3575209519800368, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 399143.5646982838, 399143.5646982835, 119310.7120506737], 
processed observation next is [0.0, 0.0, 0.5477272727272727, 0.7916666666666667, 1.0, 1.0, 0.196901189975046, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14783094988825327, 0.14783094988825315, 0.29100173670896023], 
reward next is 0.7090, 
noisyNet noise sample is [array([0.02731118], dtype=float32), 1.2439414]. 
=============================================
[2019-03-22 22:22:15,632] A3C_AGENT_WORKER-Thread-11 INFO:Local step 4500, global step 71795: loss 0.0173
[2019-03-22 22:22:15,635] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 4500, global step 71795: learning rate 0.0010
[2019-03-22 22:22:15,761] A3C_AGENT_WORKER-Thread-10 INFO:Local step 4500, global step 71848: loss 0.0317
[2019-03-22 22:22:15,765] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 4500, global step 71848: learning rate 0.0010
[2019-03-22 22:22:15,792] A3C_AGENT_WORKER-Thread-21 INFO:Local step 4500, global step 71859: loss 0.0277
[2019-03-22 22:22:15,801] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 4500, global step 71860: learning rate 0.0010
[2019-03-22 22:22:15,809] A3C_AGENT_WORKER-Thread-19 INFO:Local step 4500, global step 71863: loss 0.0289
[2019-03-22 22:22:15,816] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 4500, global step 71866: learning rate 0.0010
[2019-03-22 22:22:15,826] A3C_AGENT_WORKER-Thread-16 INFO:Local step 4500, global step 71870: loss 0.0294
[2019-03-22 22:22:15,832] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 4500, global step 71870: learning rate 0.0010
[2019-03-22 22:22:15,838] A3C_AGENT_WORKER-Thread-15 INFO:Local step 4500, global step 71874: loss 0.0122
[2019-03-22 22:22:15,840] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 4500, global step 71874: learning rate 0.0010
[2019-03-22 22:22:15,895] A3C_AGENT_WORKER-Thread-3 INFO:Local step 4500, global step 71896: loss 0.0038
[2019-03-22 22:22:15,900] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 4500, global step 71896: learning rate 0.0010
[2019-03-22 22:22:15,990] A3C_AGENT_WORKER-Thread-14 INFO:Local step 4500, global step 71936: loss 0.0016
[2019-03-22 22:22:15,995] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 4500, global step 71936: learning rate 0.0010
[2019-03-22 22:22:16,183] A3C_AGENT_WORKER-Thread-9 INFO:Local step 4500, global step 72010: loss 0.0675
[2019-03-22 22:22:16,187] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 4500, global step 72011: learning rate 0.0010
[2019-03-22 22:22:16,269] A3C_AGENT_WORKER-Thread-17 INFO:Local step 4500, global step 72046: loss 0.0050
[2019-03-22 22:22:16,271] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 4500, global step 72046: learning rate 0.0010
[2019-03-22 22:22:16,278] A3C_AGENT_WORKER-Thread-2 INFO:Local step 4500, global step 72049: loss 0.0058
[2019-03-22 22:22:16,281] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 4500, global step 72049: learning rate 0.0010
[2019-03-22 22:22:16,308] A3C_AGENT_WORKER-Thread-22 INFO:Local step 4500, global step 72059: loss 0.0006
[2019-03-22 22:22:16,310] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 4500, global step 72059: learning rate 0.0010
[2019-03-22 22:22:16,334] A3C_AGENT_WORKER-Thread-12 INFO:Local step 4500, global step 72069: loss 0.0006
[2019-03-22 22:22:16,336] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 4500, global step 72069: learning rate 0.0010
[2019-03-22 22:22:16,538] A3C_AGENT_WORKER-Thread-20 INFO:Local step 4500, global step 72148: loss 0.0698
[2019-03-22 22:22:16,540] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 4500, global step 72148: learning rate 0.0010
[2019-03-22 22:22:16,571] A3C_AGENT_WORKER-Thread-13 INFO:Local step 4500, global step 72158: loss 0.0739
[2019-03-22 22:22:16,573] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 4500, global step 72158: learning rate 0.0010
[2019-03-22 22:22:16,961] A3C_AGENT_WORKER-Thread-18 INFO:Local step 4500, global step 72313: loss 0.0067
[2019-03-22 22:22:16,964] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 4500, global step 72313: learning rate 0.0010
[2019-03-22 22:22:18,234] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.7190677e-38 1.0000000e+00 1.5292252e-33 8.1020988e-26 0.0000000e+00], sum to 1.0000
[2019-03-22 22:22:18,244] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5824
[2019-03-22 22:22:18,250] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.33333333333334, 57.66666666666667, 1.0, 2.0, 0.4511995276312597, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 514515.0188324074, 514515.0188324074, 134310.0878085838], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2737200.0000, 
sim time next is 2737800.0000, 
raw observation next is [26.5, 56.0, 1.0, 2.0, 0.4470117758204592, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 509563.6637642221, 509563.6637642221, 133574.9505439058], 
processed observation next is [0.0, 0.6956521739130435, 0.8409090909090909, 0.56, 1.0, 1.0, 0.30876471977557396, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1887272828756378, 0.1887272828756378, 0.3257925623022093], 
reward next is 0.6742, 
noisyNet noise sample is [array([1.1410336], dtype=float32), -0.3409109]. 
=============================================
[2019-03-22 22:22:20,048] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.7221191e-37 1.0000000e+00 5.1368718e-37 1.2823197e-26 4.4280048e-38], sum to 1.0000
[2019-03-22 22:22:20,060] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5913
[2019-03-22 22:22:20,067] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 78.0, 1.0, 2.0, 0.4103057639828598, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 465104.7058717265, 465104.7058717265, 127413.4084215083], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2762400.0000, 
sim time next is 2763000.0000, 
raw observation next is [21.5, 78.0, 1.0, 2.0, 0.4059084020733732, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 459561.8725940645, 459561.8725940645, 126629.8482746088], 
processed observation next is [0.0, 1.0, 0.6136363636363636, 0.78, 1.0, 1.0, 0.25738550259171644, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17020810096076464, 0.17020810096076464, 0.3088532884746556], 
reward next is 0.6911, 
noisyNet noise sample is [array([1.7132021], dtype=float32), -1.9362072]. 
=============================================
[2019-03-22 22:22:20,089] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[75.57007]
 [75.61174]
 [75.64274]
 [75.65093]
 [75.65816]], R is [[75.43908691]
 [75.37393188]
 [75.30781555]
 [75.2409668 ]
 [75.17399597]].
[2019-03-22 22:22:23,836] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-22 22:22:23,839] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-22 22:22:23,840] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-22 22:22:23,841] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-22 22:22:23,842] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-22 22:22:23,843] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-22 22:22:23,841] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:22:23,844] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:22:23,845] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:22:23,844] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:22:23,843] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:22:23,864] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run4
[2019-03-22 22:22:23,885] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run4
[2019-03-22 22:22:23,886] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run4
[2019-03-22 22:22:23,886] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run4
[2019-03-22 22:22:23,926] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run4
[2019-03-22 22:22:26,518] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.3327801], dtype=float32), -0.025735231]
[2019-03-22 22:22:26,519] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [16.0, 77.0, 1.0, 2.0, 0.227373980264706, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 246874.5408641394, 246874.5408641394, 78567.62690610436]
[2019-03-22 22:22:26,520] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 22:22:26,526] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.2731294e-30 1.0000000e+00 5.7803248e-29 1.2775618e-22 5.0698635e-30], sampled 0.4409333580539263
[2019-03-22 22:22:29,477] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.3327801], dtype=float32), -0.025735231]
[2019-03-22 22:22:29,478] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.853610195, 57.68791866, 1.0, 2.0, 0.2388007102467615, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 259271.4022882671, 259271.4022882668, 91363.29562514194]
[2019-03-22 22:22:29,478] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 22:22:29,480] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.5429030e-31 1.0000000e+00 1.3678454e-29 9.2560433e-23 6.7094321e-31], sampled 0.7125481269963891
[2019-03-22 22:22:44,771] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.3327801], dtype=float32), -0.025735231]
[2019-03-22 22:22:44,771] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.32478819166667, 93.40629684166667, 1.0, 2.0, 0.4186682168898867, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 473688.3652673561, 473688.3652673561, 131961.0572740405]
[2019-03-22 22:22:44,771] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 22:22:44,774] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [8.4844944e-31 1.0000000e+00 6.5644305e-27 1.2386027e-18 2.3777591e-28], sampled 0.49401113460953094
[2019-03-22 22:22:54,473] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.3327801], dtype=float32), -0.025735231]
[2019-03-22 22:22:54,474] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.0, 90.0, 1.0, 2.0, 0.5969564549710767, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 676425.2205950181, 676425.2205950181, 151573.4928758502]
[2019-03-22 22:22:54,477] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 22:22:54,486] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.5440166e-30 1.0000000e+00 6.4145889e-28 4.0452809e-18 3.8406097e-29], sampled 0.6556501061392078
[2019-03-22 22:22:56,596] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.3327801], dtype=float32), -0.025735231]
[2019-03-22 22:22:56,596] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.74849833833333, 42.70757793333333, 1.0, 2.0, 0.2802599292640041, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 304296.0210588393, 304296.0210588393, 87287.34873224537]
[2019-03-22 22:22:56,597] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 22:22:56,603] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.5834711e-31 1.0000000e+00 5.4994893e-29 4.6751951e-22 2.4852984e-30], sampled 0.5554495558042917
[2019-03-22 22:22:59,081] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.3327801], dtype=float32), -0.025735231]
[2019-03-22 22:22:59,082] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.21236528666667, 71.51351547499999, 1.0, 2.0, 0.3334569335429897, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 362072.7893621293, 362072.7893621293, 117801.4087578561]
[2019-03-22 22:22:59,082] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 22:22:59,086] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [6.9916255e-31 1.0000000e+00 2.7483971e-28 4.2649756e-21 1.7483800e-29], sampled 0.08627515837436883
[2019-03-22 22:23:03,984] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.3327801], dtype=float32), -0.025735231]
[2019-03-22 22:23:03,984] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [27.8, 59.0, 1.0, 2.0, 0.524013562934252, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 596830.6969897773, 596830.6969897769, 150072.6404955131]
[2019-03-22 22:23:03,987] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 22:23:03,989] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.2552869e-32 1.0000000e+00 9.0325633e-30 2.3839291e-18 2.9829116e-29], sampled 0.044485747713009616
[2019-03-22 22:23:31,597] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.3327801], dtype=float32), -0.025735231]
[2019-03-22 22:23:31,600] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.32840312, 83.39322336166667, 1.0, 2.0, 0.397002120489316, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 447888.6088064973, 447888.608806497, 129187.5883766207]
[2019-03-22 22:23:31,602] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 22:23:31,604] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.1185772e-31 1.0000000e+00 1.7976224e-28 1.6152929e-20 8.6858681e-30], sampled 0.8584040609210655
[2019-03-22 22:23:39,125] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.3327801], dtype=float32), -0.025735231]
[2019-03-22 22:23:39,127] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.10530163833333, 98.56651956166667, 1.0, 2.0, 0.4820351425174208, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 549036.7853872775, 549036.7853872771, 141079.5767886441]
[2019-03-22 22:23:39,128] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 22:23:39,131] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.7142550e-30 1.0000000e+00 1.1282115e-27 1.3798484e-19 4.2697927e-29], sampled 0.847689748047339
[2019-03-22 22:23:48,290] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.3327801], dtype=float32), -0.025735231]
[2019-03-22 22:23:48,290] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [18.9, 90.0, 1.0, 2.0, 0.4967879897344893, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 556604.1288631391, 556604.1288631387, 136995.7856435804]
[2019-03-22 22:23:48,291] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 22:23:48,294] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.8861851e-29 1.0000000e+00 1.8981771e-26 2.0216415e-17 6.1812640e-28], sampled 0.0757274198946738
[2019-03-22 22:24:10,496] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.3327801], dtype=float32), -0.025735231]
[2019-03-22 22:24:10,497] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.09004112666667, 86.51976237333335, 1.0, 2.0, 0.2424721729341865, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 263258.4664090197, 263258.4664090193, 91950.37155299427]
[2019-03-22 22:24:10,498] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 22:24:10,503] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.6876577e-31 1.0000000e+00 1.2965329e-29 2.3280169e-22 9.8800281e-31], sampled 0.6384960596516378
[2019-03-22 22:24:27,224] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8598.8494 1705487039.1040 455.0000
[2019-03-22 22:24:27,545] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.3327801], dtype=float32), -0.025735231]
[2019-03-22 22:24:27,546] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.92129777, 53.9023053, 1.0, 2.0, 0.2469354780482419, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 268105.4758904767, 268105.4758904764, 81542.22087775126]
[2019-03-22 22:24:27,547] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 22:24:27,549] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [6.1705587e-31 1.0000000e+00 6.7566765e-28 2.5718334e-21 4.7276723e-29], sampled 0.8477172519061332
[2019-03-22 22:24:27,673] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8507.6406 1770974200.7695 169.0000
[2019-03-22 22:24:27,685] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.9940 1663737739.7118 104.0000
[2019-03-22 22:24:27,686] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1361 1656178005.9856 80.0000
[2019-03-22 22:24:27,905] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8577.8754 1682705644.1635 202.0000
[2019-03-22 22:24:28,920] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 75000, evaluation results [75000.0, 8507.640550729937, 1770974200.7694817, 169.0, 9061.136132309683, 1656178005.9856246, 80.0, 8856.994013198835, 1663737739.7117612, 104.0, 8598.849369838277, 1705487039.1039698, 455.0, 8577.875447937373, 1682705644.163458, 202.0]
[2019-03-22 22:24:36,665] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0280316e-36 1.0000000e+00 3.9492010e-28 5.0442921e-19 4.4510505e-32], sum to 1.0000
[2019-03-22 22:24:36,677] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4632
[2019-03-22 22:24:36,683] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.83333333333334, 89.83333333333334, 1.0, 2.0, 0.5231594874231991, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 596105.3683108569, 596105.3683108569, 145498.3814270614], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2923800.0000, 
sim time next is 2924400.0000, 
raw observation next is [22.66666666666667, 90.66666666666667, 1.0, 2.0, 0.5234163683763344, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 596512.5555762494, 596512.5555762494, 145414.4257577642], 
processed observation next is [1.0, 0.8695652173913043, 0.6666666666666669, 0.9066666666666667, 1.0, 1.0, 0.404270460470418, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22093057613935163, 0.22093057613935163, 0.35466933111649807], 
reward next is 0.6453, 
noisyNet noise sample is [array([-1.4438119], dtype=float32), -0.70576984]. 
=============================================
[2019-03-22 22:24:38,530] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.3532666e-36 1.0000000e+00 1.7838065e-32 4.0881331e-23 5.2425108e-35], sum to 1.0000
[2019-03-22 22:24:38,537] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8033
[2019-03-22 22:24:38,542] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 91.5, 1.0, 2.0, 0.5514712014379658, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 628659.4517007879, 628659.4517007879, 148711.536472957], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2961000.0000, 
sim time next is 2961600.0000, 
raw observation next is [22.66666666666666, 90.66666666666666, 1.0, 2.0, 0.5416122162698038, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 617304.9401360824, 617304.940136082, 147604.6980901794], 
processed observation next is [1.0, 0.2608695652173913, 0.6666666666666664, 0.9066666666666666, 1.0, 1.0, 0.4270152703372547, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22863145930966014, 0.22863145930966, 0.36001145875653506], 
reward next is 0.6400, 
noisyNet noise sample is [array([1.1291115], dtype=float32), 1.002438]. 
=============================================
[2019-03-22 22:24:41,235] A3C_AGENT_WORKER-Thread-11 INFO:Local step 5000, global step 79842: loss 24.3846
[2019-03-22 22:24:41,237] A3C_AGENT_WORKER-Thread-10 INFO:Local step 5000, global step 79843: loss 24.7656
[2019-03-22 22:24:41,238] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 5000, global step 79843: learning rate 0.0010
[2019-03-22 22:24:41,239] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 5000, global step 79843: learning rate 0.0010
[2019-03-22 22:24:41,413] A3C_AGENT_WORKER-Thread-19 INFO:Local step 5000, global step 79857: loss 110.7645
[2019-03-22 22:24:41,414] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 5000, global step 79858: learning rate 0.0010
[2019-03-22 22:24:41,512] A3C_AGENT_WORKER-Thread-21 INFO:Local step 5000, global step 79877: loss 28.8205
[2019-03-22 22:24:41,514] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 5000, global step 79877: learning rate 0.0010
[2019-03-22 22:24:41,603] A3C_AGENT_WORKER-Thread-3 INFO:Local step 5000, global step 79889: loss 6.8654
[2019-03-22 22:24:41,603] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 5000, global step 79889: learning rate 0.0010
[2019-03-22 22:24:41,723] A3C_AGENT_WORKER-Thread-15 INFO:Local step 5000, global step 79913: loss 22.2037
[2019-03-22 22:24:41,727] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 5000, global step 79913: learning rate 0.0010
[2019-03-22 22:24:41,805] A3C_AGENT_WORKER-Thread-16 INFO:Local step 5000, global step 79926: loss 69.7355
[2019-03-22 22:24:41,811] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 5000, global step 79926: learning rate 0.0010
[2019-03-22 22:24:41,943] A3C_AGENT_WORKER-Thread-14 INFO:Local step 5000, global step 79957: loss 37.8745
[2019-03-22 22:24:41,947] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 5000, global step 79957: learning rate 0.0010
[2019-03-22 22:24:42,044] A3C_AGENT_WORKER-Thread-17 INFO:Local step 5000, global step 79972: loss 13.0072
[2019-03-22 22:24:42,050] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 5000, global step 79975: learning rate 0.0010
[2019-03-22 22:24:42,206] A3C_AGENT_WORKER-Thread-9 INFO:Local step 5000, global step 80016: loss 40.3270
[2019-03-22 22:24:42,209] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 5000, global step 80017: learning rate 0.0010
[2019-03-22 22:24:42,312] A3C_AGENT_WORKER-Thread-2 INFO:Local step 5000, global step 80034: loss 11.3116
[2019-03-22 22:24:42,313] A3C_AGENT_WORKER-Thread-12 INFO:Local step 5000, global step 80034: loss 53.5167
[2019-03-22 22:24:42,315] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 5000, global step 80034: learning rate 0.0010
[2019-03-22 22:24:42,317] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 5000, global step 80034: learning rate 0.0010
[2019-03-22 22:24:42,524] A3C_AGENT_WORKER-Thread-22 INFO:Local step 5000, global step 80068: loss 93.8776
[2019-03-22 22:24:42,527] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 5000, global step 80068: learning rate 0.0010
[2019-03-22 22:24:42,773] A3C_AGENT_WORKER-Thread-13 INFO:Local step 5000, global step 80151: loss 37.3348
[2019-03-22 22:24:42,777] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 5000, global step 80152: learning rate 0.0010
[2019-03-22 22:24:42,782] A3C_AGENT_WORKER-Thread-20 INFO:Local step 5000, global step 80156: loss 184.9061
[2019-03-22 22:24:42,861] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 5000, global step 80157: learning rate 0.0010
[2019-03-22 22:24:43,211] A3C_AGENT_WORKER-Thread-18 INFO:Local step 5000, global step 80277: loss 29.5889
[2019-03-22 22:24:43,217] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 5000, global step 80278: learning rate 0.0010
[2019-03-22 22:24:48,419] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.3121577e-22 7.3188380e-03 5.7677175e-12 9.9268109e-01 2.7688552e-15], sum to 1.0000
[2019-03-22 22:24:48,432] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9389
[2019-03-22 22:24:48,438] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.0, 74.0, 1.0, 2.0, 0.5780014660084472, 1.0, 1.0, 0.5780014660084472, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1311039.087145277, 1311039.087145277, 252805.2021928974], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3076200.0000, 
sim time next is 3076800.0000, 
raw observation next is [25.33333333333333, 74.0, 1.0, 2.0, 0.5513780228078907, 1.0, 2.0, 0.5513780228078907, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1246744.059688761, 1246744.059688761, 247026.1596200923], 
processed observation next is [1.0, 0.6086956521739131, 0.7878787878787876, 0.74, 1.0, 1.0, 0.4392225285098634, 1.0, 1.0, 0.4392225285098634, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.4617570591439855, 0.4617570591439855, 0.6025028283416886], 
reward next is 0.3975, 
noisyNet noise sample is [array([0.10652895], dtype=float32), 2.0195005]. 
=============================================
[2019-03-22 22:24:49,036] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.1363522e-34 1.0000000e+00 5.2128519e-22 5.9544767e-19 1.9158775e-25], sum to 1.0000
[2019-03-22 22:24:49,046] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7653
[2019-03-22 22:24:49,051] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.16666666666667, 73.33333333333334, 1.0, 2.0, 0.5621985041663362, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 637518.8441695552, 637518.8441695552, 152161.6553943965], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3091800.0000, 
sim time next is 3092400.0000, 
raw observation next is [26.0, 74.0, 1.0, 2.0, 0.5628906973642842, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 638552.0046038725, 638552.0046038725, 152152.596992558], 
processed observation next is [1.0, 0.8260869565217391, 0.8181818181818182, 0.74, 1.0, 1.0, 0.4536133717053552, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2365007424458787, 0.2365007424458787, 0.37110389510380004], 
reward next is 0.6289, 
noisyNet noise sample is [array([0.16365048], dtype=float32), -0.90793645]. 
=============================================
[2019-03-22 22:25:02,408] A3C_AGENT_WORKER-Thread-11 INFO:Local step 5500, global step 87769: loss 0.3764
[2019-03-22 22:25:02,412] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 5500, global step 87770: learning rate 0.0010
[2019-03-22 22:25:02,594] A3C_AGENT_WORKER-Thread-10 INFO:Local step 5500, global step 87845: loss 0.1781
[2019-03-22 22:25:02,596] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 5500, global step 87845: learning rate 0.0010
[2019-03-22 22:25:02,623] A3C_AGENT_WORKER-Thread-19 INFO:Local step 5500, global step 87859: loss 0.1288
[2019-03-22 22:25:02,625] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 5500, global step 87859: learning rate 0.0010
[2019-03-22 22:25:02,649] A3C_AGENT_WORKER-Thread-15 INFO:Local step 5500, global step 87870: loss 0.1141
[2019-03-22 22:25:02,652] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 5500, global step 87871: learning rate 0.0010
[2019-03-22 22:25:02,693] A3C_AGENT_WORKER-Thread-21 INFO:Local step 5500, global step 87886: loss 0.0891
[2019-03-22 22:25:02,704] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 5500, global step 87888: learning rate 0.0010
[2019-03-22 22:25:02,714] A3C_AGENT_WORKER-Thread-16 INFO:Local step 5500, global step 87895: loss 0.0538
[2019-03-22 22:25:02,717] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 5500, global step 87896: learning rate 0.0010
[2019-03-22 22:25:02,720] A3C_AGENT_WORKER-Thread-3 INFO:Local step 5500, global step 87897: loss 0.0514
[2019-03-22 22:25:02,722] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 5500, global step 87897: learning rate 0.0010
[2019-03-22 22:25:02,860] A3C_AGENT_WORKER-Thread-14 INFO:Local step 5500, global step 87952: loss 0.0526
[2019-03-22 22:25:02,862] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 5500, global step 87952: learning rate 0.0010
[2019-03-22 22:25:02,909] A3C_AGENT_WORKER-Thread-17 INFO:Local step 5500, global step 87971: loss 0.0356
[2019-03-22 22:25:02,912] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 5500, global step 87972: learning rate 0.0010
[2019-03-22 22:25:02,925] A3C_AGENT_WORKER-Thread-9 INFO:Local step 5500, global step 87975: loss 0.0519
[2019-03-22 22:25:02,930] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 5500, global step 87975: learning rate 0.0010
[2019-03-22 22:25:03,031] A3C_AGENT_WORKER-Thread-12 INFO:Local step 5500, global step 88017: loss 0.0626
[2019-03-22 22:25:03,039] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 5500, global step 88019: learning rate 0.0010
[2019-03-22 22:25:03,058] A3C_AGENT_WORKER-Thread-2 INFO:Local step 5500, global step 88027: loss 0.0594
[2019-03-22 22:25:03,062] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 5500, global step 88027: learning rate 0.0010
[2019-03-22 22:25:03,207] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 3.695835e-35 0.000000e+00], sum to 1.0000
[2019-03-22 22:25:03,211] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1329
[2019-03-22 22:25:03,219] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 77.0, 1.0, 2.0, 0.2535364909210974, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 275288.8989798814, 275288.8989798814, 87202.81330190477], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3308400.0000, 
sim time next is 3309000.0000, 
raw observation next is [17.33333333333334, 75.5, 1.0, 2.0, 0.2564917191351824, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 278498.5925724228, 278498.5925724228, 88702.3849443147], 
processed observation next is [0.0, 0.30434782608695654, 0.42424242424242453, 0.755, 1.0, 1.0, 0.07061464891897802, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10314762687867511, 0.10314762687867511, 0.21634728035198708], 
reward next is 0.7837, 
noisyNet noise sample is [array([-0.02028264], dtype=float32), 0.13465199]. 
=============================================
[2019-03-22 22:25:03,237] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[74.70449]
 [74.71653]
 [74.75695]
 [74.79901]
 [74.84455]], R is [[74.72059631]
 [74.76069641]
 [74.80186462]
 [74.84407043]
 [74.88741302]].
[2019-03-22 22:25:03,319] A3C_AGENT_WORKER-Thread-22 INFO:Local step 5500, global step 88127: loss 0.0194
[2019-03-22 22:25:03,323] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 5500, global step 88128: learning rate 0.0010
[2019-03-22 22:25:03,388] A3C_AGENT_WORKER-Thread-13 INFO:Local step 5500, global step 88151: loss 0.0112
[2019-03-22 22:25:03,389] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 5500, global step 88151: learning rate 0.0010
[2019-03-22 22:25:03,559] A3C_AGENT_WORKER-Thread-20 INFO:Local step 5500, global step 88219: loss 0.0146
[2019-03-22 22:25:03,561] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 5500, global step 88220: learning rate 0.0010
[2019-03-22 22:25:03,802] A3C_AGENT_WORKER-Thread-18 INFO:Local step 5500, global step 88310: loss 0.1334
[2019-03-22 22:25:03,805] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 5500, global step 88311: learning rate 0.0010
[2019-03-22 22:25:09,774] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.2470305e-28 1.0000000e+00 1.7468501e-25 2.9494246e-18 5.8618437e-28], sum to 1.0000
[2019-03-22 22:25:09,788] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4152
[2019-03-22 22:25:09,799] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 78.0, 1.0, 2.0, 0.7326722754445353, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 832856.5561123712, 832856.5561123709, 166514.4028998267], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3402000.0000, 
sim time next is 3402600.0000, 
raw observation next is [22.0, 78.0, 1.0, 2.0, 0.7676562901952988, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 872918.2309250328, 872918.2309250328, 171746.4472320341], 
processed observation next is [1.0, 0.391304347826087, 0.6363636363636364, 0.78, 1.0, 1.0, 0.7095703627441236, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.32330304849075286, 0.32330304849075286, 0.41889377373666853], 
reward next is 0.5811, 
noisyNet noise sample is [array([0.4853868], dtype=float32), 1.9027423]. 
=============================================
[2019-03-22 22:25:12,790] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.2401665e-21 9.9999964e-01 5.8100639e-19 4.0286278e-07 2.4102528e-19], sum to 1.0000
[2019-03-22 22:25:12,798] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5843
[2019-03-22 22:25:12,805] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 89.0, 1.0, 2.0, 0.5238212741077436, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 596756.5050248498, 596756.5050248498, 145676.180149655], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3448800.0000, 
sim time next is 3449400.0000, 
raw observation next is [23.0, 89.0, 1.0, 2.0, 0.5223592442743391, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 595090.2240000144, 595090.2240000144, 145497.833076891], 
processed observation next is [1.0, 0.9565217391304348, 0.6818181818181818, 0.89, 1.0, 1.0, 0.40294905534292386, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22040378666667199, 0.22040378666667199, 0.3548727636021732], 
reward next is 0.6451, 
noisyNet noise sample is [array([0.44269943], dtype=float32), 0.39372757]. 
=============================================
[2019-03-22 22:25:16,526] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.3250096e-21 9.9997950e-01 6.3928156e-20 2.0518177e-05 4.7685381e-17], sum to 1.0000
[2019-03-22 22:25:16,534] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3719
[2019-03-22 22:25:16,542] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1138208.227448457 W.
[2019-03-22 22:25:16,548] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.0, 70.0, 1.0, 2.0, 0.5062110912757443, 1.0, 2.0, 0.5062110912757443, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1138208.227448457, 1138208.227448456, 237043.6282744843], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3501000.0000, 
sim time next is 3501600.0000, 
raw observation next is [27.0, 70.0, 1.0, 2.0, 0.4998380858355564, 1.0, 2.0, 0.4998380858355564, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1123864.404376839, 1123864.404376839, 235453.8775658561], 
processed observation next is [1.0, 0.5217391304347826, 0.8636363636363636, 0.7, 1.0, 1.0, 0.37479760729444545, 1.0, 1.0, 0.37479760729444545, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.41624607569512556, 0.41624607569512556, 0.5742777501606247], 
reward next is 0.4257, 
noisyNet noise sample is [array([0.23062797], dtype=float32), -2.5750172]. 
=============================================
[2019-03-22 22:25:21,207] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.1489745e-26 1.0000000e+00 3.5780708e-27 5.5255211e-22 1.8642829e-20], sum to 1.0000
[2019-03-22 22:25:21,223] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7830
[2019-03-22 22:25:21,319] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.00000000000001, 1.0, 2.0, 0.6337993601147939, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 722861.9095967278, 722861.909596728, 159170.2720467303], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3571800.0000, 
sim time next is 3572400.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.8081051394041989, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 921763.8787278692, 921763.8787278689, 185470.5326321287], 
processed observation next is [1.0, 0.34782608695652173, 0.6363636363636364, 0.94, 1.0, 1.0, 0.7601314242552487, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3413940291584701, 0.34139402915846995, 0.4523671527612895], 
reward next is 0.5476, 
noisyNet noise sample is [array([0.6747517], dtype=float32), 1.3142531]. 
=============================================
[2019-03-22 22:25:21,494] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.0676907e-15 9.9995351e-01 3.7107401e-18 4.6134635e-05 3.7977119e-07], sum to 1.0000
[2019-03-22 22:25:21,504] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8764
[2019-03-22 22:25:21,511] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1276048.223162207 W.
[2019-03-22 22:25:21,516] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.66666666666667, 89.0, 1.0, 2.0, 0.3782971461239379, 1.0, 2.0, 0.3782971461239379, 1.0, 1.0, 0.7647107816402018, 6.911199999999999, 6.9112, 77.3421103, 1276048.223162207, 1276048.223162207, 296830.1426633432], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3580800.0000, 
sim time next is 3581400.0000, 
raw observation next is [23.83333333333333, 89.0, 1.0, 2.0, 0.3685902462438742, 1.0, 2.0, 0.3685902462438742, 1.0, 2.0, 0.7457737255638386, 6.9112, 6.9112, 77.3421103, 1243269.586739317, 1243269.586739317, 292775.2262536], 
processed observation next is [1.0, 0.43478260869565216, 0.7196969696969695, 0.89, 1.0, 1.0, 0.21073780780484275, 1.0, 1.0, 0.21073780780484275, 1.0, 1.0, 0.6368196079483409, 0.0, 0.0, 0.5085185399722538, 0.4604702173108582, 0.4604702173108582, 0.7140859176917073], 
reward next is 0.2859, 
noisyNet noise sample is [array([-0.3914933], dtype=float32), -1.1558716]. 
=============================================
[2019-03-22 22:25:22,675] A3C_AGENT_WORKER-Thread-19 INFO:Local step 6000, global step 95806: loss 7.2208
[2019-03-22 22:25:22,677] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 6000, global step 95806: learning rate 0.0010
[2019-03-22 22:25:22,819] A3C_AGENT_WORKER-Thread-16 INFO:Local step 6000, global step 95864: loss -49.7379
[2019-03-22 22:25:22,821] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 6000, global step 95864: learning rate 0.0010
[2019-03-22 22:25:22,852] A3C_AGENT_WORKER-Thread-11 INFO:Local step 6000, global step 95876: loss 14.2064
[2019-03-22 22:25:22,854] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 6000, global step 95876: learning rate 0.0010
[2019-03-22 22:25:22,897] A3C_AGENT_WORKER-Thread-3 INFO:Local step 6000, global step 95891: loss -21.3244
[2019-03-22 22:25:22,899] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 6000, global step 95891: learning rate 0.0010
[2019-03-22 22:25:22,913] A3C_AGENT_WORKER-Thread-21 INFO:Local step 6000, global step 95897: loss -2.2592
[2019-03-22 22:25:22,916] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 6000, global step 95897: learning rate 0.0010
[2019-03-22 22:25:22,988] A3C_AGENT_WORKER-Thread-15 INFO:Local step 6000, global step 95927: loss -47.2819
[2019-03-22 22:25:22,992] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 6000, global step 95928: learning rate 0.0010
[2019-03-22 22:25:23,049] A3C_AGENT_WORKER-Thread-10 INFO:Local step 6000, global step 95950: loss -35.7988
[2019-03-22 22:25:23,052] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 6000, global step 95950: learning rate 0.0010
[2019-03-22 22:25:23,075] A3C_AGENT_WORKER-Thread-14 INFO:Local step 6000, global step 95957: loss -1.5166
[2019-03-22 22:25:23,078] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 6000, global step 95959: learning rate 0.0010
[2019-03-22 22:25:23,097] A3C_AGENT_WORKER-Thread-17 INFO:Local step 6000, global step 95966: loss 5.5889
[2019-03-22 22:25:23,099] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 6000, global step 95966: learning rate 0.0010
[2019-03-22 22:25:23,148] A3C_AGENT_WORKER-Thread-9 INFO:Local step 6000, global step 95987: loss 12.0707
[2019-03-22 22:25:23,155] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 6000, global step 95987: learning rate 0.0010
[2019-03-22 22:25:23,214] A3C_AGENT_WORKER-Thread-12 INFO:Local step 6000, global step 96013: loss 48.5428
[2019-03-22 22:25:23,217] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 6000, global step 96014: learning rate 0.0010
[2019-03-22 22:25:23,244] A3C_AGENT_WORKER-Thread-2 INFO:Local step 6000, global step 96023: loss 55.1293
[2019-03-22 22:25:23,245] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 6000, global step 96023: learning rate 0.0010
[2019-03-22 22:25:23,392] A3C_AGENT_WORKER-Thread-13 INFO:Local step 6000, global step 96081: loss -79.8422
[2019-03-22 22:25:23,394] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 6000, global step 96081: learning rate 0.0010
[2019-03-22 22:25:23,588] A3C_AGENT_WORKER-Thread-22 INFO:Local step 6000, global step 96158: loss -4.8957
[2019-03-22 22:25:23,593] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 6000, global step 96159: learning rate 0.0010
[2019-03-22 22:25:23,713] A3C_AGENT_WORKER-Thread-20 INFO:Local step 6000, global step 96206: loss 28.3570
[2019-03-22 22:25:23,716] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 6000, global step 96206: learning rate 0.0010
[2019-03-22 22:25:23,959] A3C_AGENT_WORKER-Thread-18 INFO:Local step 6000, global step 96297: loss -19.9325
[2019-03-22 22:25:23,965] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 6000, global step 96297: learning rate 0.0010
[2019-03-22 22:25:28,490] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.3266508e-18 9.9795973e-01 5.4579089e-15 2.0402914e-03 5.4430873e-14], sum to 1.0000
[2019-03-22 22:25:28,497] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2659
[2019-03-22 22:25:28,506] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1585319.30480568 W.
[2019-03-22 22:25:28,515] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.5, 56.5, 1.0, 2.0, 0.4698554724976782, 1.0, 2.0, 0.4698554724976782, 1.0, 1.0, 0.949052677460676, 6.9112, 6.9112, 77.3421103, 1585319.30480568, 1585319.30480568, 342626.0412614766], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3681000.0000, 
sim time next is 3681600.0000, 
raw observation next is [28.66666666666666, 56.0, 1.0, 2.0, 0.4778815555268857, 1.0, 2.0, 0.4778815555268857, 1.0, 2.0, 0.9661005757961528, 6.911199999999999, 6.9112, 77.3421103, 1612438.332815429, 1612438.332815429, 347544.2997160631], 
processed observation next is [1.0, 0.6086956521739131, 0.9393939393939391, 0.56, 1.0, 1.0, 0.3473519444086071, 1.0, 1.0, 0.3473519444086071, 1.0, 1.0, 0.9515722511373613, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.597199382524233, 0.597199382524233, 0.8476690236977148], 
reward next is 0.1523, 
noisyNet noise sample is [array([-0.63138765], dtype=float32), -0.44486904]. 
=============================================
[2019-03-22 22:25:28,602] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.6198490e-19 9.9872595e-01 2.9725578e-16 1.2739815e-03 9.6456343e-15], sum to 1.0000
[2019-03-22 22:25:28,613] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9030
[2019-03-22 22:25:28,624] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1501564.308023675 W.
[2019-03-22 22:25:28,632] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.0, 55.0, 1.0, 2.0, 0.6672814341088652, 1.0, 2.0, 0.6672814341088652, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1501564.308023675, 1501564.308023675, 281517.3349258516], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3682800.0000, 
sim time next is 3683400.0000, 
raw observation next is [29.0, 54.5, 1.0, 2.0, 0.4164741316061416, 1.0, 2.0, 0.4164741316061416, 1.0, 1.0, 0.8411389597645319, 6.911199999999999, 6.9112, 77.3421103, 1404984.153678027, 1404984.153678027, 314634.264216435], 
processed observation next is [1.0, 0.6521739130434783, 0.9545454545454546, 0.545, 1.0, 1.0, 0.270592664507677, 1.0, 1.0, 0.270592664507677, 1.0, 0.5, 0.7730556568064743, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.5203645013622322, 0.5203645013622322, 0.7674006444303293], 
reward next is 0.2326, 
noisyNet noise sample is [array([-0.63138765], dtype=float32), -0.44486904]. 
=============================================
[2019-03-22 22:25:33,214] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-22 22:25:33,214] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-22 22:25:33,215] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:25:33,216] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-22 22:25:33,217] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:25:33,218] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-22 22:25:33,221] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-22 22:25:33,221] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-22 22:25:33,225] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:25:33,226] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:25:33,228] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:25:33,245] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run5
[2019-03-22 22:25:33,246] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run5
[2019-03-22 22:25:33,264] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run5
[2019-03-22 22:25:33,283] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run5
[2019-03-22 22:25:33,284] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run5
[2019-03-22 22:26:05,084] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.28653002], dtype=float32), -0.10107639]
[2019-03-22 22:26:05,084] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [25.5, 48.0, 1.0, 2.0, 0.3644873344075987, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 408099.2056773676, 408099.2056773672, 124733.4704932334]
[2019-03-22 22:26:05,085] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 22:26:05,088] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.1775782e-37 0.0000000e+00], sampled 0.9642682144336313
[2019-03-22 22:26:49,224] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.28653002], dtype=float32), -0.10107639]
[2019-03-22 22:26:49,225] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.59673304666667, 88.69568814833333, 1.0, 2.0, 0.4138424397274514, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 465519.9861194795, 465519.9861194791, 130011.0044085281]
[2019-03-22 22:26:49,226] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 22:26:49,230] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.1062298e-38 1.0000000e+00 0.0000000e+00 3.5012674e-36 6.2112274e-38], sampled 0.8335890059995973
[2019-03-22 22:27:36,785] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1147 1656209757.7786 80.0000
[2019-03-22 22:27:37,174] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3486 1683344882.4587 214.0000
[2019-03-22 22:27:37,310] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9293 1705966326.6889 465.0000
[2019-03-22 22:27:37,444] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2492 1773187030.7201 173.0000
[2019-03-22 22:27:37,511] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5598 1663796639.0689 105.0000
[2019-03-22 22:27:38,578] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 100000, evaluation results [100000.0, 8512.249193409023, 1773187030.7201214, 173.0, 9061.114669779829, 1656209757.7786272, 80.0, 8856.559759326878, 1663796639.0688558, 105.0, 8596.929320447398, 1705966326.688919, 465.0, 8574.348638023737, 1683344882.4586744, 214.0]
[2019-03-22 22:27:40,614] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.9438466e-38], sum to 1.0000
[2019-03-22 22:27:40,624] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4625
[2019-03-22 22:27:40,631] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 88.0, 1.0, 2.0, 0.3421249238091587, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 376559.293360077, 376559.293360077, 115882.0099887087], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3789600.0000, 
sim time next is 3790200.0000, 
raw observation next is [18.0, 88.0, 1.0, 2.0, 0.3403920272148871, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 374643.6934151347, 374643.6934151347, 115749.1808570178], 
processed observation next is [1.0, 0.8695652173913043, 0.45454545454545453, 0.88, 1.0, 1.0, 0.17549003401860885, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13875692348708693, 0.13875692348708693, 0.282315075261019], 
reward next is 0.7177, 
noisyNet noise sample is [array([0.08885626], dtype=float32), 0.2469991]. 
=============================================
[2019-03-22 22:27:41,012] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 22:27:41,021] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8449
[2019-03-22 22:27:41,027] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 88.0, 1.0, 2.0, 0.3416763748208801, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 376289.4215244665, 376289.4215244662, 115931.8251060038], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3787200.0000, 
sim time next is 3787800.0000, 
raw observation next is [18.0, 88.00000000000001, 1.0, 2.0, 0.3424849355796491, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 376972.6417938228, 376972.6417938225, 115915.3641534386], 
processed observation next is [1.0, 0.8695652173913043, 0.45454545454545453, 0.8800000000000001, 1.0, 1.0, 0.17810616947456134, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1396194969606751, 0.13961949696067502, 0.28272040037424045], 
reward next is 0.7173, 
noisyNet noise sample is [array([0.44675425], dtype=float32), 2.0110424]. 
=============================================
[2019-03-22 22:27:42,519] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.2577694e-37], sum to 1.0000
[2019-03-22 22:27:42,529] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7955
[2019-03-22 22:27:42,535] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.16666666666667, 93.0, 1.0, 2.0, 0.3331910555174638, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 365070.8397355153, 365070.8397355153, 114607.8449930145], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3797400.0000, 
sim time next is 3798000.0000, 
raw observation next is [17.0, 94.0, 1.0, 2.0, 0.3329777706618763, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 364452.4026181274, 364452.4026181276, 114454.4346673623], 
processed observation next is [1.0, 1.0, 0.4090909090909091, 0.94, 1.0, 1.0, 0.16622221332734533, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1349823713400472, 0.13498237134004726, 0.2791571577252739], 
reward next is 0.7208, 
noisyNet noise sample is [array([-1.3094426], dtype=float32), 0.51860934]. 
=============================================
[2019-03-22 22:27:42,548] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[72.04179 ]
 [72.011024]
 [71.99119 ]
 [71.975464]
 [71.94117 ]], R is [[72.10276031]
 [72.10220337]
 [72.10126495]
 [72.09980011]
 [72.09771729]].
[2019-03-22 22:27:45,321] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.3482282e-35 1.1205146e-31 1.3666968e-38], sum to 1.0000
[2019-03-22 22:27:45,333] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8420
[2019-03-22 22:27:45,342] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 73.0, 1.0, 2.0, 0.2999969934747828, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 325752.4203570376, 325752.4203570373, 111191.381749966], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3841800.0000, 
sim time next is 3842400.0000, 
raw observation next is [19.0, 73.0, 1.0, 2.0, 0.2982750101389878, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 323881.9781609855, 323881.9781609857, 111076.2838134219], 
processed observation next is [0.0, 0.4782608695652174, 0.5, 0.73, 1.0, 1.0, 0.1228437626737347, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11995628820777242, 0.11995628820777247, 0.27091776539859], 
reward next is 0.7291, 
noisyNet noise sample is [array([-0.10854892], dtype=float32), -1.5568477]. 
=============================================
[2019-03-22 22:27:48,017] A3C_AGENT_WORKER-Thread-19 INFO:Local step 6500, global step 103707: loss 0.0032
[2019-03-22 22:27:48,022] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 6500, global step 103708: learning rate 0.0010
[2019-03-22 22:27:48,093] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.5930204e-38 1.0000000e+00 1.4162320e-37 5.9637954e-27 2.0100566e-36], sum to 1.0000
[2019-03-22 22:27:48,102] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6609
[2019-03-22 22:27:48,209] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 77.0, 1.0, 2.0, 0.281362457399602, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 305511.7109732488, 305511.710973249, 101643.3464513569], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3894600.0000, 
sim time next is 3895200.0000, 
raw observation next is [18.0, 77.0, 1.0, 2.0, 0.2816331722128767, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 305805.7535760876, 305805.7535760876, 101667.6814641793], 
processed observation next is [0.0, 0.08695652173913043, 0.45454545454545453, 0.77, 1.0, 1.0, 0.10204146526609587, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11326139021336577, 0.11326139021336577, 0.24796995479068124], 
reward next is 0.7520, 
noisyNet noise sample is [array([0.09545358], dtype=float32), 1.0980514]. 
=============================================
[2019-03-22 22:27:48,392] A3C_AGENT_WORKER-Thread-21 INFO:Local step 6500, global step 103819: loss 0.0487
[2019-03-22 22:27:48,393] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 6500, global step 103819: learning rate 0.0010
[2019-03-22 22:27:48,510] A3C_AGENT_WORKER-Thread-16 INFO:Local step 6500, global step 103871: loss 0.0791
[2019-03-22 22:27:48,514] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 6500, global step 103871: learning rate 0.0010
[2019-03-22 22:27:48,547] A3C_AGENT_WORKER-Thread-3 INFO:Local step 6500, global step 103884: loss 0.0670
[2019-03-22 22:27:48,552] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 6500, global step 103884: learning rate 0.0010
[2019-03-22 22:27:48,559] A3C_AGENT_WORKER-Thread-11 INFO:Local step 6500, global step 103886: loss 0.0688
[2019-03-22 22:27:48,561] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 6500, global step 103886: learning rate 0.0010
[2019-03-22 22:27:48,641] A3C_AGENT_WORKER-Thread-14 INFO:Local step 6500, global step 103917: loss 0.0418
[2019-03-22 22:27:48,645] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 6500, global step 103917: learning rate 0.0010
[2019-03-22 22:27:48,676] A3C_AGENT_WORKER-Thread-2 INFO:Local step 6500, global step 103935: loss 0.0235
[2019-03-22 22:27:48,678] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 6500, global step 103935: learning rate 0.0010
[2019-03-22 22:27:48,699] A3C_AGENT_WORKER-Thread-17 INFO:Local step 6500, global step 103943: loss 0.0597
[2019-03-22 22:27:48,704] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 6500, global step 103943: learning rate 0.0010
[2019-03-22 22:27:48,740] A3C_AGENT_WORKER-Thread-15 INFO:Local step 6500, global step 103959: loss 0.0137
[2019-03-22 22:27:48,743] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 6500, global step 103960: learning rate 0.0010
[2019-03-22 22:27:48,844] A3C_AGENT_WORKER-Thread-10 INFO:Local step 6500, global step 103995: loss 0.0195
[2019-03-22 22:27:48,847] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 6500, global step 103996: learning rate 0.0010
[2019-03-22 22:27:48,915] A3C_AGENT_WORKER-Thread-9 INFO:Local step 6500, global step 104024: loss 0.0042
[2019-03-22 22:27:48,920] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 6500, global step 104025: learning rate 0.0010
[2019-03-22 22:27:49,024] A3C_AGENT_WORKER-Thread-12 INFO:Local step 6500, global step 104062: loss 0.0087
[2019-03-22 22:27:49,027] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 6500, global step 104063: learning rate 0.0010
[2019-03-22 22:27:49,184] A3C_AGENT_WORKER-Thread-13 INFO:Local step 6500, global step 104128: loss 0.0382
[2019-03-22 22:27:49,185] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 6500, global step 104128: learning rate 0.0010
[2019-03-22 22:27:49,344] A3C_AGENT_WORKER-Thread-22 INFO:Local step 6500, global step 104191: loss 0.0622
[2019-03-22 22:27:49,347] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 6500, global step 104191: learning rate 0.0010
[2019-03-22 22:27:49,363] A3C_AGENT_WORKER-Thread-18 INFO:Local step 6500, global step 104200: loss 0.0895
[2019-03-22 22:27:49,369] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 6500, global step 104201: learning rate 0.0010
[2019-03-22 22:27:49,632] A3C_AGENT_WORKER-Thread-20 INFO:Local step 6500, global step 104302: loss 0.0556
[2019-03-22 22:27:49,634] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 6500, global step 104303: learning rate 0.0010
[2019-03-22 22:27:51,237] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.4509504e-38 2.4880797e-36 0.0000000e+00], sum to 1.0000
[2019-03-22 22:27:51,247] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2893
[2019-03-22 22:27:51,252] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 45.0, 1.0, 2.0, 0.3499843986518817, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 391461.5976313567, 391461.597631357, 119035.6675711657], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3937800.0000, 
sim time next is 3938400.0000, 
raw observation next is [26.0, 45.0, 1.0, 2.0, 0.3494400322035693, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 390849.9105148989, 390849.9105148989, 118990.4350787147], 
processed observation next is [0.0, 0.6086956521739131, 0.8181818181818182, 0.45, 1.0, 1.0, 0.1868000402544616, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14475922611662922, 0.14475922611662922, 0.2902205733627188], 
reward next is 0.7098, 
noisyNet noise sample is [array([0.7626741], dtype=float32), 1.0322008]. 
=============================================
[2019-03-22 22:27:53,078] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.4367791e-30 5.5551490e-38], sum to 1.0000
[2019-03-22 22:27:53,090] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3894
[2019-03-22 22:27:53,097] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.83333333333334, 53.66666666666667, 1.0, 2.0, 0.3220360675148651, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 353658.7723394582, 353658.7723394582, 114102.4062646259], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3960600.0000, 
sim time next is 3961200.0000, 
raw observation next is [22.66666666666667, 54.33333333333334, 1.0, 2.0, 0.3218633527582166, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 353224.7430109989, 353224.7430109992, 113999.1920340932], 
processed observation next is [0.0, 0.8695652173913043, 0.6666666666666669, 0.5433333333333334, 1.0, 1.0, 0.15232919094777073, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13082397889296254, 0.13082397889296268, 0.2780468098392517], 
reward next is 0.7220, 
noisyNet noise sample is [array([1.5803077], dtype=float32), 1.14004]. 
=============================================
[2019-03-22 22:27:55,402] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 8.941929e-35 5.967221e-38], sum to 1.0000
[2019-03-22 22:27:55,412] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5142
[2019-03-22 22:27:55,425] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.16666666666667, 88.00000000000001, 1.0, 2.0, 0.262118877870271, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 284610.3467631422, 284610.3467631419, 92286.6061526765], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3996600.0000, 
sim time next is 3997200.0000, 
raw observation next is [16.33333333333334, 88.0, 1.0, 2.0, 0.2649510883316621, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 287686.4884677681, 287686.4884677678, 94604.47702971786], 
processed observation next is [1.0, 0.2608695652173913, 0.37878787878787906, 0.88, 1.0, 1.0, 0.0811888604145776, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10655055128435857, 0.10655055128435843, 0.23074262690175087], 
reward next is 0.7693, 
noisyNet noise sample is [array([-0.89018166], dtype=float32), 0.4070401]. 
=============================================
[2019-03-22 22:27:58,051] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.6671917e-35 1.0000000e+00 1.8405889e-28 1.2395534e-32 6.1296822e-26], sum to 1.0000
[2019-03-22 22:27:58,062] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6911
[2019-03-22 22:27:58,068] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 94.0, 1.0, 2.0, 0.3345622444334198, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 366451.8598301183, 366451.8598301183, 114663.8665722539], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4039200.0000, 
sim time next is 4039800.0000, 
raw observation next is [17.0, 95.0, 1.0, 2.0, 0.3366214463914776, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 368936.3511369004, 368936.3511369004, 114896.8123517901], 
processed observation next is [1.0, 0.782608695652174, 0.4090909090909091, 0.95, 1.0, 1.0, 0.170776807989347, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1366430930136668, 0.1366430930136668, 0.28023612768729295], 
reward next is 0.7198, 
noisyNet noise sample is [array([1.1614827], dtype=float32), -2.8808777]. 
=============================================
[2019-03-22 22:28:02,806] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.9615694e-30 1.0000000e+00 1.0526132e-25 8.9302692e-13 9.8374860e-25], sum to 1.0000
[2019-03-22 22:28:02,814] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8453
[2019-03-22 22:28:02,821] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 78.0, 1.0, 2.0, 0.6603394179265698, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 745249.7138316043, 745249.7138316047, 153313.1234306427], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4096800.0000, 
sim time next is 4097400.0000, 
raw observation next is [21.16666666666667, 78.0, 1.0, 2.0, 0.6813598708037037, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 769873.564897728, 769873.5648977278, 156459.2659965756], 
processed observation next is [1.0, 0.43478260869565216, 0.5984848484848487, 0.78, 1.0, 1.0, 0.6016998385046296, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2851383573695289, 0.2851383573695288, 0.3816079658453063], 
reward next is 0.6184, 
noisyNet noise sample is [array([1.3243229], dtype=float32), -2.0166016]. 
=============================================
[2019-03-22 22:28:08,682] A3C_AGENT_WORKER-Thread-21 INFO:Local step 7000, global step 111751: loss 0.0618
[2019-03-22 22:28:08,685] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 7000, global step 111752: learning rate 0.0010
[2019-03-22 22:28:08,710] A3C_AGENT_WORKER-Thread-19 INFO:Local step 7000, global step 111764: loss 0.1404
[2019-03-22 22:28:08,714] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 7000, global step 111765: learning rate 0.0010
[2019-03-22 22:28:08,898] A3C_AGENT_WORKER-Thread-14 INFO:Local step 7000, global step 111836: loss 0.0517
[2019-03-22 22:28:08,904] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 7000, global step 111837: learning rate 0.0010
[2019-03-22 22:28:09,028] A3C_AGENT_WORKER-Thread-11 INFO:Local step 7000, global step 111882: loss 0.0528
[2019-03-22 22:28:09,033] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 7000, global step 111882: learning rate 0.0010
[2019-03-22 22:28:09,064] A3C_AGENT_WORKER-Thread-3 INFO:Local step 7000, global step 111894: loss 0.0889
[2019-03-22 22:28:09,069] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 7000, global step 111896: learning rate 0.0010
[2019-03-22 22:28:09,190] A3C_AGENT_WORKER-Thread-16 INFO:Local step 7000, global step 111947: loss 0.0486
[2019-03-22 22:28:09,193] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 7000, global step 111947: learning rate 0.0010
[2019-03-22 22:28:09,208] A3C_AGENT_WORKER-Thread-2 INFO:Local step 7000, global step 111953: loss 0.0086
[2019-03-22 22:28:09,212] A3C_AGENT_WORKER-Thread-15 INFO:Local step 7000, global step 111954: loss 0.0161
[2019-03-22 22:28:09,215] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 7000, global step 111953: learning rate 0.0010
[2019-03-22 22:28:09,224] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 7000, global step 111956: learning rate 0.0010
[2019-03-22 22:28:09,266] A3C_AGENT_WORKER-Thread-17 INFO:Local step 7000, global step 111977: loss 0.0095
[2019-03-22 22:28:09,268] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 7000, global step 111978: learning rate 0.0010
[2019-03-22 22:28:09,341] A3C_AGENT_WORKER-Thread-9 INFO:Local step 7000, global step 112008: loss 0.0181
[2019-03-22 22:28:09,343] A3C_AGENT_WORKER-Thread-10 INFO:Local step 7000, global step 112008: loss 0.0115
[2019-03-22 22:28:09,345] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 7000, global step 112008: learning rate 0.0010
[2019-03-22 22:28:09,345] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 7000, global step 112009: learning rate 0.0010
[2019-03-22 22:28:09,380] A3C_AGENT_WORKER-Thread-12 INFO:Local step 7000, global step 112021: loss 0.0145
[2019-03-22 22:28:09,382] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 7000, global step 112022: learning rate 0.0010
[2019-03-22 22:28:09,639] A3C_AGENT_WORKER-Thread-18 INFO:Local step 7000, global step 112120: loss 0.0060
[2019-03-22 22:28:09,642] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 7000, global step 112121: learning rate 0.0010
[2019-03-22 22:28:09,650] A3C_AGENT_WORKER-Thread-13 INFO:Local step 7000, global step 112123: loss 0.0055
[2019-03-22 22:28:09,652] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 7000, global step 112124: learning rate 0.0010
[2019-03-22 22:28:09,938] A3C_AGENT_WORKER-Thread-22 INFO:Local step 7000, global step 112236: loss 0.0051
[2019-03-22 22:28:09,942] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 7000, global step 112239: learning rate 0.0010
[2019-03-22 22:28:10,191] A3C_AGENT_WORKER-Thread-20 INFO:Local step 7000, global step 112333: loss 3.0758
[2019-03-22 22:28:10,195] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 7000, global step 112334: learning rate 0.0010
[2019-03-22 22:28:11,143] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.6317757e-32 1.0000000e+00 8.0707275e-26 3.0051716e-14 3.7278115e-25], sum to 1.0000
[2019-03-22 22:28:11,151] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9998
[2019-03-22 22:28:11,158] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.66666666666667, 83.0, 1.0, 2.0, 0.3642760232305241, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 407363.2806871947, 407363.2806871947, 120164.4267844521], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4225200.0000, 
sim time next is 4225800.0000, 
raw observation next is [19.33333333333333, 85.5, 1.0, 2.0, 0.3641662861324884, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 407150.983673771, 407150.983673771, 120114.7412731171], 
processed observation next is [1.0, 0.9130434782608695, 0.5151515151515149, 0.855, 1.0, 1.0, 0.2052078576656105, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1507966606199152, 0.1507966606199152, 0.29296278359296857], 
reward next is 0.7070, 
noisyNet noise sample is [array([-0.2517746], dtype=float32), 0.0022287646]. 
=============================================
[2019-03-22 22:28:14,030] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.1230936e-34 1.0000000e+00 7.0443957e-30 6.1362859e-24 1.6692341e-27], sum to 1.0000
[2019-03-22 22:28:14,039] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8691
[2019-03-22 22:28:14,045] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.66666666666667, 90.50000000000001, 1.0, 2.0, 0.4494370092156947, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 501803.3498673955, 501803.3498673955, 127311.9840802748], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4263000.0000, 
sim time next is 4263600.0000, 
raw observation next is [19.33333333333334, 87.0, 1.0, 2.0, 0.6101100186438727, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 684015.6169695109, 684015.6169695113, 145016.9211424236], 
processed observation next is [1.0, 0.34782608695652173, 0.5151515151515155, 0.87, 1.0, 1.0, 0.5126375233048408, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.25333911739611514, 0.2533391173961153, 0.35369980766444786], 
reward next is 0.6463, 
noisyNet noise sample is [array([0.54382724], dtype=float32), 2.172623]. 
=============================================
[2019-03-22 22:28:14,487] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.4730525e-29 1.0000000e+00 1.9104298e-21 1.9097442e-14 9.5649511e-24], sum to 1.0000
[2019-03-22 22:28:14,497] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1024
[2019-03-22 22:28:14,503] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.66666666666667, 80.0, 1.0, 2.0, 0.7533149192089412, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 849656.9011904761, 849656.9011904761, 165228.8048407145], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4264800.0000, 
sim time next is 4265400.0000, 
raw observation next is [21.33333333333334, 76.5, 1.0, 2.0, 0.7852106982956313, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 887349.087522032, 887349.0875220316, 170598.5347975518], 
processed observation next is [1.0, 0.34782608695652173, 0.6060606060606063, 0.765, 1.0, 1.0, 0.7315133728695391, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.32864781019334516, 0.32864781019334505, 0.416093987311102], 
reward next is 0.5839, 
noisyNet noise sample is [array([0.00783252], dtype=float32), -0.53973067]. 
=============================================
[2019-03-22 22:28:14,619] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.6602118e-25 9.9894589e-01 1.4607258e-18 1.0541643e-03 9.0498567e-16], sum to 1.0000
[2019-03-22 22:28:14,625] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6459
[2019-03-22 22:28:14,631] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.33333333333334, 49.16666666666667, 1.0, 2.0, 0.8234639553108187, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 926099.497715344, 926099.497715344, 173781.8780813472], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4277400.0000, 
sim time next is 4278000.0000, 
raw observation next is [25.66666666666667, 48.33333333333334, 1.0, 2.0, 0.7061304469333003, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 794876.7671065208, 794876.7671065208, 158128.5319669299], 
processed observation next is [1.0, 0.5217391304347826, 0.8030303030303032, 0.48333333333333345, 1.0, 1.0, 0.6326630586666254, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.29439880263204476, 0.29439880263204476, 0.38567934626080463], 
reward next is 0.6143, 
noisyNet noise sample is [array([-1.5977517], dtype=float32), -0.18694393]. 
=============================================
[2019-03-22 22:28:14,646] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[60.12533 ]
 [60.172535]
 [60.249893]
 [59.872017]
 [59.59645 ]], R is [[60.09296799]
 [60.06818008]
 [60.04637909]
 [60.05155182]
 [60.05386353]].
[2019-03-22 22:28:17,199] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.7666862e-35 1.0000000e+00 4.1454993e-31 4.0695870e-30 3.1386178e-32], sum to 1.0000
[2019-03-22 22:28:17,211] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7928
[2019-03-22 22:28:17,216] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.33333333333333, 86.33333333333334, 1.0, 2.0, 0.373699904059857, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 418545.254292322, 418545.2542923223, 121241.4696997538], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4319400.0000, 
sim time next is 4320000.0000, 
raw observation next is [19.0, 88.0, 1.0, 2.0, 0.3694703055992113, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 413133.1807921334, 413133.1807921334, 120576.7722836099], 
processed observation next is [1.0, 0.0, 0.5, 0.88, 1.0, 1.0, 0.2118378819990141, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1530122891822716, 0.1530122891822716, 0.2940896884966095], 
reward next is 0.7059, 
noisyNet noise sample is [array([-1.0414964], dtype=float32), 2.145784]. 
=============================================
[2019-03-22 22:28:17,230] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[68.300285]
 [68.26182 ]
 [68.220825]
 [68.18797 ]
 [68.16122 ]], R is [[67.74163818]
 [67.76851654]
 [67.79362488]
 [67.81716156]
 [67.83916473]].
[2019-03-22 22:28:25,985] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 22:28:25,996] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2325
[2019-03-22 22:28:26,004] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333334, 76.66666666666667, 1.0, 2.0, 0.4551952032457304, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 519183.3614703926, 519183.3614703923, 134958.5873680001], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4440000.0000, 
sim time next is 4440600.0000, 
raw observation next is [23.5, 76.0, 1.0, 2.0, 0.4575455761834382, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 521923.8685967285, 521923.8685967283, 135351.0051755031], 
processed observation next is [0.0, 0.391304347826087, 0.7045454545454546, 0.76, 1.0, 1.0, 0.32193197022929776, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19330513651730685, 0.19330513651730677, 0.3301244028670807], 
reward next is 0.6699, 
noisyNet noise sample is [array([-0.86506015], dtype=float32), 1.1847962]. 
=============================================
[2019-03-22 22:28:27,318] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 22:28:27,331] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8664
[2019-03-22 22:28:27,335] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.33333333333334, 72.66666666666667, 1.0, 2.0, 0.5180331971621116, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 590184.9280608207, 590184.9280608207, 144948.6276026574], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4465200.0000, 
sim time next is 4465800.0000, 
raw observation next is [25.0, 74.0, 1.0, 2.0, 0.5148289267140117, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 586756.4149830873, 586756.4149830873, 144338.029359015], 
processed observation next is [0.0, 0.6956521739130435, 0.7727272727272727, 0.74, 1.0, 1.0, 0.3935361583925146, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21731719073447678, 0.21731719073447678, 0.35204397404637805], 
reward next is 0.6480, 
noisyNet noise sample is [array([0.96631324], dtype=float32), 0.399595]. 
=============================================
[2019-03-22 22:28:28,942] A3C_AGENT_WORKER-Thread-19 INFO:Local step 7500, global step 119704: loss 0.0723
[2019-03-22 22:28:28,943] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 7500, global step 119704: learning rate 0.0010
[2019-03-22 22:28:29,092] A3C_AGENT_WORKER-Thread-21 INFO:Local step 7500, global step 119766: loss 0.0170
[2019-03-22 22:28:29,093] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 7500, global step 119766: learning rate 0.0010
[2019-03-22 22:28:29,115] A3C_AGENT_WORKER-Thread-14 INFO:Local step 7500, global step 119774: loss 0.0072
[2019-03-22 22:28:29,117] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 7500, global step 119774: learning rate 0.0010
[2019-03-22 22:28:29,344] A3C_AGENT_WORKER-Thread-3 INFO:Local step 7500, global step 119862: loss 0.0932
[2019-03-22 22:28:29,347] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 7500, global step 119863: learning rate 0.0010
[2019-03-22 22:28:29,462] A3C_AGENT_WORKER-Thread-11 INFO:Local step 7500, global step 119906: loss 0.0384
[2019-03-22 22:28:29,467] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 7500, global step 119908: learning rate 0.0010
[2019-03-22 22:28:29,499] A3C_AGENT_WORKER-Thread-10 INFO:Local step 7500, global step 119924: loss 0.0283
[2019-03-22 22:28:29,504] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 7500, global step 119924: learning rate 0.0010
[2019-03-22 22:28:29,515] A3C_AGENT_WORKER-Thread-2 INFO:Local step 7500, global step 119930: loss 0.0263
[2019-03-22 22:28:29,520] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 7500, global step 119931: learning rate 0.0010
[2019-03-22 22:28:29,537] A3C_AGENT_WORKER-Thread-9 INFO:Local step 7500, global step 119939: loss 0.0090
[2019-03-22 22:28:29,540] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 7500, global step 119940: learning rate 0.0010
[2019-03-22 22:28:29,609] A3C_AGENT_WORKER-Thread-16 INFO:Local step 7500, global step 119959: loss 0.0070
[2019-03-22 22:28:29,613] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 7500, global step 119963: learning rate 0.0010
[2019-03-22 22:28:29,655] A3C_AGENT_WORKER-Thread-15 INFO:Local step 7500, global step 119979: loss 0.0006
[2019-03-22 22:28:29,658] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 7500, global step 119981: learning rate 0.0010
[2019-03-22 22:28:29,782] A3C_AGENT_WORKER-Thread-17 INFO:Local step 7500, global step 120030: loss 0.0359
[2019-03-22 22:28:29,783] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 7500, global step 120030: learning rate 0.0010
[2019-03-22 22:28:29,934] A3C_AGENT_WORKER-Thread-12 INFO:Local step 7500, global step 120091: loss 0.0243
[2019-03-22 22:28:29,936] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 7500, global step 120092: learning rate 0.0010
[2019-03-22 22:28:29,996] A3C_AGENT_WORKER-Thread-18 INFO:Local step 7500, global step 120115: loss 0.0120
[2019-03-22 22:28:30,000] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 7500, global step 120115: learning rate 0.0010
[2019-03-22 22:28:30,026] A3C_AGENT_WORKER-Thread-13 INFO:Local step 7500, global step 120125: loss 0.0124
[2019-03-22 22:28:30,031] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 7500, global step 120127: learning rate 0.0010
[2019-03-22 22:28:30,491] A3C_AGENT_WORKER-Thread-22 INFO:Local step 7500, global step 120308: loss 0.0359
[2019-03-22 22:28:30,494] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 7500, global step 120308: learning rate 0.0010
[2019-03-22 22:28:30,611] A3C_AGENT_WORKER-Thread-20 INFO:Local step 7500, global step 120354: loss 0.0087
[2019-03-22 22:28:30,614] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 7500, global step 120354: learning rate 0.0010
[2019-03-22 22:28:39,506] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 4.6305607e-35 7.6594823e-33 4.8881449e-34], sum to 1.0000
[2019-03-22 22:28:39,522] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7768
[2019-03-22 22:28:39,528] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 48.5, 1.0, 2.0, 0.6860823231109369, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 754001.5772497415, 754001.5772497418, 148339.5795933605], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4638600.0000, 
sim time next is 4639200.0000, 
raw observation next is [23.33333333333333, 49.0, 1.0, 2.0, 0.6260306497869582, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 686966.6958731554, 686966.6958731554, 141283.0994558597], 
processed observation next is [1.0, 0.6956521739130435, 0.6969696969696968, 0.49, 1.0, 1.0, 0.5325383122336977, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2544321095826501, 0.2544321095826501, 0.3445929255020968], 
reward next is 0.6554, 
noisyNet noise sample is [array([0.03127306], dtype=float32), -0.5921482]. 
=============================================
[2019-03-22 22:28:42,517] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-22 22:28:42,520] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-22 22:28:42,521] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-22 22:28:42,521] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:28:42,523] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:28:42,523] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-22 22:28:42,523] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-22 22:28:42,526] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-22 22:28:42,525] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:28:42,529] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:28:42,529] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:28:42,548] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run6
[2019-03-22 22:28:42,549] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run6
[2019-03-22 22:28:42,549] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run6
[2019-03-22 22:28:42,550] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run6
[2019-03-22 22:28:42,625] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run6
[2019-03-22 22:29:39,479] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.20903338], dtype=float32), -0.1917669]
[2019-03-22 22:29:39,479] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [25.0, 78.0, 1.0, 2.0, 0.5947771498408321, 0.0, 2.0, 0.0, 1.0, 2.0, 0.97857159789892, 6.911199999999999, 6.9112, 77.32846344354104, 1223068.825822633, 1223068.825822633, 278044.6985186926]
[2019-03-22 22:29:39,479] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 22:29:39,481] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.6866134e-33 1.0000000e+00 2.8489798e-26 2.0637311e-12 1.5654909e-24], sampled 0.269886732219886
[2019-03-22 22:29:39,483] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1223068.825822633 W.
[2019-03-22 22:29:44,392] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.20903338], dtype=float32), -0.1917669]
[2019-03-22 22:29:44,392] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.3, 77.0, 1.0, 2.0, 0.3675328094544989, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 410240.7183115649, 410240.7183115646, 124413.9921417805]
[2019-03-22 22:29:44,394] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 22:29:44,397] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 1.096753e-37 0.000000e+00], sampled 0.030779575715789598
[2019-03-22 22:29:55,340] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.20903338], dtype=float32), -0.1917669]
[2019-03-22 22:29:55,342] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [14.79567833333333, 75.93345296000001, 1.0, 2.0, 0.2180109011059182, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 236694.9858729746, 236694.9858729749, 78319.74808138605]
[2019-03-22 22:29:55,343] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 22:29:55,348] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.26431491064036383
[2019-03-22 22:30:02,340] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.20903338], dtype=float32), -0.1917669]
[2019-03-22 22:30:02,341] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.25, 57.33333333333333, 1.0, 2.0, 0.3677837463516258, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 95.55338769695034, 414158.0874868209, 414158.0874868202, 126184.5757579278]
[2019-03-22 22:30:02,343] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 22:30:02,346] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.0000e+00 1.0000e+00 0.0000e+00 8.6428e-38 0.0000e+00], sampled 0.9146165748558345
[2019-03-22 22:30:06,557] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.20903338], dtype=float32), -0.1917669]
[2019-03-22 22:30:06,557] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.2, 88.66666666666667, 1.0, 2.0, 0.3666044076262011, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 411001.6812375383, 411001.681237538, 125160.1922225473]
[2019-03-22 22:30:06,558] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 22:30:06,560] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.8646797e-38 0.0000000e+00], sampled 0.21069552878712494
[2019-03-22 22:30:08,076] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.20903338], dtype=float32), -0.1917669]
[2019-03-22 22:30:08,077] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [26.98333333333333, 51.66666666666666, 1.0, 2.0, 0.4520954682472659, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 514631.824807533, 514631.8248075327, 137571.1255062092]
[2019-03-22 22:30:08,077] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 22:30:08,080] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 1.7395571e-38 5.2966703e-33 1.0003861e-36], sampled 0.3667945341114016
[2019-03-22 22:30:08,490] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.20903338], dtype=float32), -0.1917669]
[2019-03-22 22:30:08,493] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [27.83333333333334, 49.66666666666667, 1.0, 2.0, 0.4387434562475048, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338766425707, 500125.4736766899, 500125.4736766896, 137087.1818697546]
[2019-03-22 22:30:08,495] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 22:30:08,498] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0.0000000e+00 1.0000000e+00 4.1843344e-36 1.5433535e-27 1.7787705e-33], sampled 0.3748406221186309
[2019-03-22 22:30:10,990] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.20903338], dtype=float32), -0.1917669]
[2019-03-22 22:30:10,990] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.5, 66.0, 1.0, 2.0, 0.2931058704400538, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 318247.3688167782, 318247.3688167782, 107432.6659027897]
[2019-03-22 22:30:10,992] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 22:30:10,995] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.2043586e-38 0.0000000e+00], sampled 0.4877343973449483
[2019-03-22 22:30:23,282] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.20903338], dtype=float32), -0.1917669]
[2019-03-22 22:30:23,284] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.53333333333333, 84.66666666666667, 1.0, 2.0, 0.4047590227756183, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 457751.1879324687, 457751.1879324687, 130536.9911187448]
[2019-03-22 22:30:23,285] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 22:30:23,287] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.8976077e-36 1.5251608e-38], sampled 0.781462360946322
[2019-03-22 22:30:34,851] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.20903338], dtype=float32), -0.1917669]
[2019-03-22 22:30:34,852] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.31666666666667, 40.66666666666667, 1.0, 2.0, 0.3514916404392553, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 381661.3765092632, 381661.3765092632, 105775.5333012849]
[2019-03-22 22:30:34,853] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 22:30:34,855] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.8605369e-37 0.0000000e+00], sampled 0.5012053071996374
[2019-03-22 22:30:45,818] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5598 1663796639.0689 105.0000
[2019-03-22 22:30:45,951] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2492 1773187030.7201 173.0000
[2019-03-22 22:30:46,046] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1147 1656209757.7786 80.0000
[2019-03-22 22:30:46,119] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9309 1705967916.6745 465.0000
[2019-03-22 22:30:46,138] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3486 1683344882.4587 214.0000
[2019-03-22 22:30:47,153] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 125000, evaluation results [125000.0, 8512.249193409023, 1773187030.7201214, 173.0, 9061.114669779829, 1656209757.7786272, 80.0, 8856.559759326878, 1663796639.0688558, 105.0, 8596.930884973775, 1705967916.6744611, 465.0, 8574.348638023737, 1683344882.4586744, 214.0]
[2019-03-22 22:30:50,210] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.3579098e-37 1.0000000e+00 1.4693678e-34 8.5597830e-24 4.5804219e-27], sum to 1.0000
[2019-03-22 22:30:50,219] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0688
[2019-03-22 22:30:50,225] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333333, 77.16666666666666, 1.0, 2.0, 0.3988258622279365, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 450580.7021191473, 450580.7021191471, 125384.8336583239], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4740600.0000, 
sim time next is 4741200.0000, 
raw observation next is [21.0, 78.0, 1.0, 2.0, 0.3926610253617681, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 442744.5239819146, 442744.5239819146, 124333.6988661375], 
processed observation next is [1.0, 0.9130434782608695, 0.5909090909090909, 0.78, 1.0, 1.0, 0.24082628170221013, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16397945332663505, 0.16397945332663505, 0.30325292406375004], 
reward next is 0.6967, 
noisyNet noise sample is [array([-0.56660247], dtype=float32), -0.702557]. 
=============================================
[2019-03-22 22:30:51,189] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.0139173e-36 5.4788248e-28 7.1012326e-33], sum to 1.0000
[2019-03-22 22:30:51,201] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6169
[2019-03-22 22:30:51,206] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 83.0, 1.0, 2.0, 0.3746679383776181, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 420682.4972960377, 420682.497296038, 121825.7935257942], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4749600.0000, 
sim time next is 4750200.0000, 
raw observation next is [20.0, 83.0, 1.0, 2.0, 0.3743948593897641, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 420372.9200172487, 420372.920017249, 121801.0573494533], 
processed observation next is [1.0, 1.0, 0.5454545454545454, 0.83, 1.0, 1.0, 0.21799357423720508, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1556936740804625, 0.15569367408046259, 0.2970757496328129], 
reward next is 0.7029, 
noisyNet noise sample is [array([0.38140833], dtype=float32), 1.2253518]. 
=============================================
[2019-03-22 22:30:54,012] A3C_AGENT_WORKER-Thread-19 INFO:Local step 8000, global step 127692: loss 0.2254
[2019-03-22 22:30:54,019] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 8000, global step 127695: learning rate 0.0010
[2019-03-22 22:30:54,198] A3C_AGENT_WORKER-Thread-21 INFO:Local step 8000, global step 127761: loss 0.2106
[2019-03-22 22:30:54,202] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 8000, global step 127761: learning rate 0.0010
[2019-03-22 22:30:54,248] A3C_AGENT_WORKER-Thread-14 INFO:Local step 8000, global step 127781: loss 0.2069
[2019-03-22 22:30:54,251] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 8000, global step 127782: learning rate 0.0010
[2019-03-22 22:30:54,518] A3C_AGENT_WORKER-Thread-11 INFO:Local step 8000, global step 127884: loss 0.5489
[2019-03-22 22:30:54,520] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 8000, global step 127884: learning rate 0.0010
[2019-03-22 22:30:54,539] A3C_AGENT_WORKER-Thread-3 INFO:Local step 8000, global step 127892: loss 0.4772
[2019-03-22 22:30:54,542] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 8000, global step 127893: learning rate 0.0010
[2019-03-22 22:30:54,570] A3C_AGENT_WORKER-Thread-9 INFO:Local step 8000, global step 127901: loss 0.3623
[2019-03-22 22:30:54,572] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 8000, global step 127901: learning rate 0.0010
[2019-03-22 22:30:54,595] A3C_AGENT_WORKER-Thread-10 INFO:Local step 8000, global step 127913: loss 0.6437
[2019-03-22 22:30:54,597] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 8000, global step 127914: learning rate 0.0010
[2019-03-22 22:30:54,622] A3C_AGENT_WORKER-Thread-2 INFO:Local step 8000, global step 127922: loss 0.4082
[2019-03-22 22:30:54,628] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 8000, global step 127924: learning rate 0.0010
[2019-03-22 22:30:54,734] A3C_AGENT_WORKER-Thread-16 INFO:Local step 8000, global step 127967: loss 0.6538
[2019-03-22 22:30:54,735] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 8000, global step 127967: learning rate 0.0010
[2019-03-22 22:30:54,800] A3C_AGENT_WORKER-Thread-15 INFO:Local step 8000, global step 127988: loss 0.8300
[2019-03-22 22:30:54,803] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 8000, global step 127988: learning rate 0.0010
[2019-03-22 22:30:54,896] A3C_AGENT_WORKER-Thread-17 INFO:Local step 8000, global step 128029: loss 1.3838
[2019-03-22 22:30:54,901] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 8000, global step 128030: learning rate 0.0010
[2019-03-22 22:30:54,967] A3C_AGENT_WORKER-Thread-12 INFO:Local step 8000, global step 128055: loss 1.3805
[2019-03-22 22:30:54,970] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 8000, global step 128056: learning rate 0.0010
[2019-03-22 22:30:55,011] A3C_AGENT_WORKER-Thread-13 INFO:Local step 8000, global step 128071: loss 2.2795
[2019-03-22 22:30:55,013] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 8000, global step 128071: learning rate 0.0010
[2019-03-22 22:30:55,283] A3C_AGENT_WORKER-Thread-18 INFO:Local step 8000, global step 128175: loss 0.4286
[2019-03-22 22:30:55,285] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 8000, global step 128176: learning rate 0.0010
[2019-03-22 22:30:55,546] A3C_AGENT_WORKER-Thread-22 INFO:Local step 8000, global step 128275: loss 0.3833
[2019-03-22 22:30:55,550] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 8000, global step 128276: learning rate 0.0010
[2019-03-22 22:30:55,887] A3C_AGENT_WORKER-Thread-20 INFO:Local step 8000, global step 128409: loss 0.6391
[2019-03-22 22:30:55,890] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 8000, global step 128410: learning rate 0.0010
[2019-03-22 22:31:07,760] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.2017289e-33 1.0000000e+00 1.1533150e-35 1.4300668e-19 1.0775331e-27], sum to 1.0000
[2019-03-22 22:31:07,774] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2901
[2019-03-22 22:31:07,780] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.5, 77.5, 1.0, 2.0, 0.2806725808253456, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 304762.3877889157, 304762.3877889159, 95609.21051519265], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4998600.0000, 
sim time next is 4999200.0000, 
raw observation next is [17.33333333333333, 79.0, 1.0, 2.0, 0.2814307607021613, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 305585.9000288247, 305585.9000288244, 95915.65884235923], 
processed observation next is [1.0, 0.8695652173913043, 0.42424242424242403, 0.79, 1.0, 1.0, 0.10178845087770158, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11317996297363878, 0.11317996297363866, 0.23394063132282739], 
reward next is 0.7661, 
noisyNet noise sample is [array([-0.6587267], dtype=float32), 0.78361124]. 
=============================================
[2019-03-22 22:31:08,051] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.5516066e-28 1.0000000e+00 4.9089177e-29 4.6329831e-08 9.7369999e-21], sum to 1.0000
[2019-03-22 22:31:08,059] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1222
[2019-03-22 22:31:08,064] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 61.33333333333334, 1.0, 2.0, 0.2841714861711744, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 308562.8054544231, 308562.8054544228, 99303.53796131328], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4988400.0000, 
sim time next is 4989000.0000, 
raw observation next is [20.0, 60.66666666666666, 1.0, 2.0, 0.2837466399189732, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 308101.3472024469, 308101.3472024472, 97916.76415726473], 
processed observation next is [1.0, 0.7391304347826086, 0.5454545454545454, 0.6066666666666666, 1.0, 1.0, 0.10468329989871648, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11411161007498033, 0.11411161007498044, 0.2388213759933286], 
reward next is 0.7612, 
noisyNet noise sample is [array([-0.42489797], dtype=float32), 1.0115504]. 
=============================================
[2019-03-22 22:31:08,078] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[68.47797 ]
 [68.45247 ]
 [68.28476 ]
 [67.916145]
 [67.52496 ]], R is [[68.50891876]
 [68.58162689]
 [68.64928436]
 [68.7073822 ]
 [68.73750305]].
[2019-03-22 22:31:08,110] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.4254807e-27 1.0000000e+00 2.9357950e-27 4.6200083e-13 5.3771058e-18], sum to 1.0000
[2019-03-22 22:31:08,120] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2204
[2019-03-22 22:31:08,128] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.66666666666667, 69.66666666666667, 1.0, 2.0, 0.2819896484291571, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 306192.9480063909, 306192.9480063906, 97510.21112873477], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4994400.0000, 
sim time next is 4995000.0000, 
raw observation next is [18.5, 70.5, 1.0, 2.0, 0.2800564649246914, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 304093.1822056074, 304093.1822056074, 96639.38729623515], 
processed observation next is [1.0, 0.8260869565217391, 0.4772727272727273, 0.705, 1.0, 1.0, 0.10007058115586422, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11262710452059534, 0.11262710452059534, 0.23570582267374426], 
reward next is 0.7643, 
noisyNet noise sample is [array([-0.5907402], dtype=float32), -0.59337604]. 
=============================================
[2019-03-22 22:31:08,156] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[68.88269 ]
 [68.98238 ]
 [69.093925]
 [69.19145 ]
 [69.32106 ]], R is [[68.84867096]
 [68.92235565]
 [68.99329376]
 [69.06173706]
 [69.1302948 ]].
[2019-03-22 22:31:14,579] A3C_AGENT_WORKER-Thread-19 INFO:Local step 8500, global step 135738: loss 0.2116
[2019-03-22 22:31:14,582] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 8500, global step 135738: learning rate 0.0010
[2019-03-22 22:31:14,635] A3C_AGENT_WORKER-Thread-21 INFO:Local step 8500, global step 135759: loss 0.1262
[2019-03-22 22:31:14,638] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 8500, global step 135759: learning rate 0.0010
[2019-03-22 22:31:14,648] A3C_AGENT_WORKER-Thread-14 INFO:Local step 8500, global step 135761: loss 0.1421
[2019-03-22 22:31:14,655] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 8500, global step 135762: learning rate 0.0010
[2019-03-22 22:31:14,794] A3C_AGENT_WORKER-Thread-3 INFO:Local step 8500, global step 135819: loss 0.1520
[2019-03-22 22:31:14,798] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 8500, global step 135820: learning rate 0.0010
[2019-03-22 22:31:14,941] A3C_AGENT_WORKER-Thread-10 INFO:Local step 8500, global step 135876: loss 0.1365
[2019-03-22 22:31:14,943] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 8500, global step 135876: learning rate 0.0010
[2019-03-22 22:31:14,977] A3C_AGENT_WORKER-Thread-9 INFO:Local step 8500, global step 135889: loss 0.1511
[2019-03-22 22:31:14,979] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 8500, global step 135890: learning rate 0.0010
[2019-03-22 22:31:14,999] A3C_AGENT_WORKER-Thread-11 INFO:Local step 8500, global step 135899: loss 0.2614
[2019-03-22 22:31:15,004] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 8500, global step 135900: learning rate 0.0010
[2019-03-22 22:31:15,111] A3C_AGENT_WORKER-Thread-2 INFO:Local step 8500, global step 135942: loss 0.3381
[2019-03-22 22:31:15,114] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 8500, global step 135942: learning rate 0.0010
[2019-03-22 22:31:15,125] A3C_AGENT_WORKER-Thread-16 INFO:Local step 8500, global step 135947: loss 0.4617
[2019-03-22 22:31:15,127] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 8500, global step 135947: learning rate 0.0010
[2019-03-22 22:31:15,352] A3C_AGENT_WORKER-Thread-15 INFO:Local step 8500, global step 136035: loss 0.3273
[2019-03-22 22:31:15,356] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 8500, global step 136036: learning rate 0.0010
[2019-03-22 22:31:15,357] A3C_AGENT_WORKER-Thread-17 INFO:Local step 8500, global step 136036: loss 0.2299
[2019-03-22 22:31:15,367] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 8500, global step 136036: learning rate 0.0010
[2019-03-22 22:31:15,439] A3C_AGENT_WORKER-Thread-12 INFO:Local step 8500, global step 136067: loss 0.2540
[2019-03-22 22:31:15,442] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 8500, global step 136068: learning rate 0.0010
[2019-03-22 22:31:15,652] A3C_AGENT_WORKER-Thread-13 INFO:Local step 8500, global step 136150: loss 0.1089
[2019-03-22 22:31:15,654] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 8500, global step 136150: learning rate 0.0010
[2019-03-22 22:31:15,696] A3C_AGENT_WORKER-Thread-18 INFO:Local step 8500, global step 136165: loss 0.0767
[2019-03-22 22:31:15,701] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 8500, global step 136166: learning rate 0.0010
[2019-03-22 22:31:16,045] A3C_AGENT_WORKER-Thread-22 INFO:Local step 8500, global step 136304: loss 0.2770
[2019-03-22 22:31:16,047] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 8500, global step 136305: learning rate 0.0010
[2019-03-22 22:31:16,295] A3C_AGENT_WORKER-Thread-20 INFO:Local step 8500, global step 136401: loss 0.1553
[2019-03-22 22:31:16,297] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 8500, global step 136401: learning rate 0.0010
[2019-03-22 22:31:23,388] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.1072889e-26 9.9999809e-01 9.2236125e-20 1.9421050e-06 2.0445419e-15], sum to 1.0000
[2019-03-22 22:31:23,403] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7900
[2019-03-22 22:31:23,409] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 98.0, 1.0, 2.0, 0.8126797464545317, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 927692.6933182242, 927692.6933182242, 184310.1183163085], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5223000.0000, 
sim time next is 5223600.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.8308143683906011, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 948240.7515010262, 948240.7515010262, 188126.5201181379], 
processed observation next is [1.0, 0.4782608695652174, 0.5909090909090909, 1.0, 1.0, 1.0, 0.7885179604882514, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3512002783337134, 0.3512002783337134, 0.45884517101984856], 
reward next is 0.5412, 
noisyNet noise sample is [array([0.3992383], dtype=float32), 0.6095725]. 
=============================================
[2019-03-22 22:31:35,113] A3C_AGENT_WORKER-Thread-21 INFO:Local step 9000, global step 143780: loss 57.5460
[2019-03-22 22:31:35,116] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 9000, global step 143780: learning rate 0.0010
[2019-03-22 22:31:35,171] A3C_AGENT_WORKER-Thread-19 INFO:Local step 9000, global step 143805: loss 6.2768
[2019-03-22 22:31:35,173] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 9000, global step 143805: learning rate 0.0010
[2019-03-22 22:31:35,192] A3C_AGENT_WORKER-Thread-3 INFO:Local step 9000, global step 143811: loss -65.4788
[2019-03-22 22:31:35,197] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 9000, global step 143811: learning rate 0.0010
[2019-03-22 22:31:35,237] A3C_AGENT_WORKER-Thread-14 INFO:Local step 9000, global step 143823: loss -48.7545
[2019-03-22 22:31:35,239] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 9000, global step 143823: learning rate 0.0010
[2019-03-22 22:31:35,417] A3C_AGENT_WORKER-Thread-9 INFO:Local step 9000, global step 143896: loss 74.8527
[2019-03-22 22:31:35,419] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 9000, global step 143896: learning rate 0.0010
[2019-03-22 22:31:35,464] A3C_AGENT_WORKER-Thread-10 INFO:Local step 9000, global step 143907: loss 190.2143
[2019-03-22 22:31:35,467] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 9000, global step 143908: learning rate 0.0010
[2019-03-22 22:31:35,475] A3C_AGENT_WORKER-Thread-11 INFO:Local step 9000, global step 143911: loss 1.1318
[2019-03-22 22:31:35,479] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 9000, global step 143911: learning rate 0.0010
[2019-03-22 22:31:35,539] A3C_AGENT_WORKER-Thread-2 INFO:Local step 9000, global step 143940: loss 138.0606
[2019-03-22 22:31:35,541] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 9000, global step 143940: learning rate 0.0010
[2019-03-22 22:31:35,641] A3C_AGENT_WORKER-Thread-16 INFO:Local step 9000, global step 143976: loss 39.5728
[2019-03-22 22:31:35,643] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 9000, global step 143976: learning rate 0.0010
[2019-03-22 22:31:35,787] A3C_AGENT_WORKER-Thread-17 INFO:Local step 9000, global step 144036: loss 37.3252
[2019-03-22 22:31:35,789] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 9000, global step 144037: learning rate 0.0010
[2019-03-22 22:31:35,835] A3C_AGENT_WORKER-Thread-15 INFO:Local step 9000, global step 144054: loss 77.5164
[2019-03-22 22:31:35,838] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 9000, global step 144054: learning rate 0.0010
[2019-03-22 22:31:35,876] A3C_AGENT_WORKER-Thread-13 INFO:Local step 9000, global step 144068: loss 78.0087
[2019-03-22 22:31:35,877] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 9000, global step 144068: learning rate 0.0010
[2019-03-22 22:31:35,900] A3C_AGENT_WORKER-Thread-12 INFO:Local step 9000, global step 144075: loss 120.9095
[2019-03-22 22:31:35,903] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 9000, global step 144075: learning rate 0.0010
[2019-03-22 22:31:35,992] A3C_AGENT_WORKER-Thread-18 INFO:Local step 9000, global step 144112: loss 48.8204
[2019-03-22 22:31:35,995] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 9000, global step 144113: learning rate 0.0010
[2019-03-22 22:31:36,385] A3C_AGENT_WORKER-Thread-22 INFO:Local step 9000, global step 144265: loss -4.1654
[2019-03-22 22:31:36,388] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 9000, global step 144265: learning rate 0.0010
[2019-03-22 22:31:36,557] A3C_AGENT_WORKER-Thread-20 INFO:Local step 9000, global step 144330: loss 1.8115
[2019-03-22 22:31:36,559] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 9000, global step 144330: learning rate 0.0010
[2019-03-22 22:31:42,679] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.8029881e-27 1.0000000e+00 1.8005108e-29 1.1949966e-21 2.9792180e-20], sum to 1.0000
[2019-03-22 22:31:42,686] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2666
[2019-03-22 22:31:42,691] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.33333333333334, 61.0, 1.0, 2.0, 0.5013643930264776, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 571215.1654239085, 571215.1654239087, 142923.1076176438], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5506800.0000, 
sim time next is 5507400.0000, 
raw observation next is [27.51666666666667, 59.0, 1.0, 2.0, 0.4987478849266387, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 568553.0146244733, 568553.0146244733, 142271.1017772068], 
processed observation next is [1.0, 0.7391304347826086, 0.8871212121212122, 0.59, 1.0, 1.0, 0.3734348561582983, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21057519060165678, 0.21057519060165678, 0.34700268726148], 
reward next is 0.6530, 
noisyNet noise sample is [array([1.3925614], dtype=float32), 0.21793787]. 
=============================================
[2019-03-22 22:31:43,202] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.8867038e-31 1.0000000e+00 4.9314240e-28 7.2575528e-18 1.7692926e-22], sum to 1.0000
[2019-03-22 22:31:43,212] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0088
[2019-03-22 22:31:43,219] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.51666666666667, 59.0, 1.0, 2.0, 0.4987478865765455, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 568553.0146243977, 568553.0146243977, 142271.1042527954], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5507400.0000, 
sim time next is 5508000.0000, 
raw observation next is [27.7, 57.0, 1.0, 2.0, 0.4952167910257668, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 564781.6115448138, 564781.6115448138, 141493.1302258556], 
processed observation next is [1.0, 0.782608695652174, 0.8954545454545454, 0.57, 1.0, 1.0, 0.3690209887822085, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20917837464622735, 0.20917837464622735, 0.3451051956728185], 
reward next is 0.6549, 
noisyNet noise sample is [array([0.7781016], dtype=float32), 0.5957632]. 
=============================================
[2019-03-22 22:31:43,233] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[52.290096]
 [52.586163]
 [52.383797]
 [52.137375]
 [50.899624]], R is [[52.13286209]
 [52.26453018]
 [52.39329147]
 [52.51958466]
 [52.633564  ]].
[2019-03-22 22:31:45,720] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.2616506e-32 1.0000000e+00 1.2542264e-33 1.3777674e-24 2.3562021e-24], sum to 1.0000
[2019-03-22 22:31:45,732] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2773
[2019-03-22 22:31:45,740] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333334, 91.0, 1.0, 2.0, 0.4132946168885536, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 469408.0894266563, 469408.0894266563, 128367.4871523724], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5550000.0000, 
sim time next is 5550600.0000, 
raw observation next is [20.41666666666667, 90.5, 1.0, 2.0, 0.4133341685823857, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 469515.4178417821, 469515.4178417821, 128421.0199026589], 
processed observation next is [1.0, 0.21739130434782608, 0.5643939393939396, 0.905, 1.0, 1.0, 0.26666771072798207, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17389459920066003, 0.17389459920066003, 0.3132219997625827], 
reward next is 0.6868, 
noisyNet noise sample is [array([-1.7608397], dtype=float32), 1.1558642]. 
=============================================
[2019-03-22 22:31:51,052] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-22 22:31:51,056] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-22 22:31:51,059] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-22 22:31:51,060] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:31:51,061] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:31:51,062] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-22 22:31:51,064] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-22 22:31:51,064] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-22 22:31:51,067] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:31:51,069] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:31:51,067] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:31:51,088] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run7
[2019-03-22 22:31:51,090] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run7
[2019-03-22 22:31:51,107] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run7
[2019-03-22 22:31:51,108] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run7
[2019-03-22 22:31:51,161] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run7
[2019-03-22 22:32:01,847] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.24844056], dtype=float32), -0.21414198]
[2019-03-22 22:32:01,850] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [24.33333333333333, 54.66666666666667, 1.0, 2.0, 0.8184914555975605, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 921636.0766143061, 921636.0766143061, 173628.6547596423]
[2019-03-22 22:32:01,851] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 22:32:01,853] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.7492870e-29 1.0000000e+00 9.2537958e-28 9.1331438e-23 1.9916203e-17], sampled 0.4636439814142488
[2019-03-22 22:32:32,222] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.24844056], dtype=float32), -0.21414198]
[2019-03-22 22:32:32,224] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [17.59975286, 73.24372809, 1.0, 2.0, 0.2703056190942338, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 293485.3548641718, 293485.3548641718, 94557.85658961296]
[2019-03-22 22:32:32,224] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 22:32:32,227] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.8891216e-38 1.0000000e+00 0.0000000e+00 3.4146704e-37 1.0060991e-30], sampled 0.3383213891787249
[2019-03-22 22:32:46,870] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.24844056], dtype=float32), -0.21414198]
[2019-03-22 22:32:46,871] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.08333333333334, 86.33333333333334, 1.0, 2.0, 0.4396494667081988, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 499814.1341885441, 499814.1341885438, 135678.7000928717]
[2019-03-22 22:32:46,874] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 22:32:46,879] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.4125521e-35 1.0000000e+00 1.2089641e-34 1.2348822e-30 6.1730527e-24], sampled 0.8598981101505827
[2019-03-22 22:33:04,412] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.24844056], dtype=float32), -0.21414198]
[2019-03-22 22:33:04,412] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.94363588, 40.81314385, 1.0, 2.0, 0.4132506032785764, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 448746.3633039282, 448746.3633039278, 110285.4109234841]
[2019-03-22 22:33:04,412] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 22:33:04,417] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.5386529e-34 1.0000000e+00 1.5372263e-33 3.8007753e-30 1.7682324e-23], sampled 0.3144684040577803
[2019-03-22 22:33:39,048] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.24844056], dtype=float32), -0.21414198]
[2019-03-22 22:33:39,048] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [16.78333333333333, 90.5, 1.0, 2.0, 0.3091451968281812, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 335667.3505466122, 335667.3505466118, 116114.2383243489]
[2019-03-22 22:33:39,048] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 22:33:39,049] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.7717535e-37 1.0000000e+00 4.9133941e-37 2.0644874e-34 1.3620671e-27], sampled 0.6179710560431163
[2019-03-22 22:33:54,720] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2263 1772922583.1357 173.0000
[2019-03-22 22:33:54,985] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5896 1663766061.8834 105.0000
[2019-03-22 22:33:55,009] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9309 1705967916.6745 465.0000
[2019-03-22 22:33:55,231] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.9846 1683160853.8638 213.0000
[2019-03-22 22:33:55,259] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-22 22:33:56,273] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 150000, evaluation results [150000.0, 8512.226270214534, 1772922583.1357026, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8856.58956291602, 1663766061.8834455, 105.0, 8596.930884973775, 1705967916.6744611, 465.0, 8574.984562583924, 1683160853.8637543, 213.0]
[2019-03-22 22:33:56,700] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 4.685604e-37 4.517244e-34 5.174948e-30], sum to 1.0000
[2019-03-22 22:33:56,706] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0031
[2019-03-22 22:33:56,716] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.1, 99.5, 1.0, 2.0, 0.3481332337755834, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 385871.8532915084, 385871.8532915084, 117374.2371228994], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5641800.0000, 
sim time next is 5642400.0000, 
raw observation next is [17.0, 99.0, 1.0, 2.0, 0.3444215965631068, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 380823.3200114635, 380823.3200114632, 116715.8507654641], 
processed observation next is [0.0, 0.30434782608695654, 0.4090909090909091, 0.99, 1.0, 1.0, 0.18052699570388345, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1410456740783198, 0.1410456740783197, 0.28467280674503437], 
reward next is 0.7153, 
noisyNet noise sample is [array([0.59432334], dtype=float32), -0.22449847]. 
=============================================
[2019-03-22 22:33:59,612] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.6962322e-38 1.0000000e+00 0.0000000e+00 1.7823101e-32 1.5732484e-33], sum to 1.0000
[2019-03-22 22:33:59,619] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5282
[2019-03-22 22:33:59,625] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.5, 76.5, 1.0, 2.0, 0.2128307895924549, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 231080.3132566185, 231080.3132566188, 75100.36366147973], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5675400.0000, 
sim time next is 5676000.0000, 
raw observation next is [15.5, 76.0, 1.0, 2.0, 0.2120931116649998, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 230279.1923342038, 230279.1923342041, 74852.58385029194], 
processed observation next is [0.0, 0.6956521739130435, 0.3409090909090909, 0.76, 1.0, 1.0, 0.015116389581249744, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08528858975340882, 0.08528858975340893, 0.18256727768363887], 
reward next is 0.8174, 
noisyNet noise sample is [array([-0.35416827], dtype=float32), 0.22292791]. 
=============================================
[2019-03-22 22:33:59,641] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[77.22579]
 [77.28317]
 [77.32515]
 [77.35579]
 [77.36571]], R is [[77.21867371]
 [77.26331329]
 [77.30703735]
 [77.35002899]
 [77.39226532]].
[2019-03-22 22:34:00,640] A3C_AGENT_WORKER-Thread-21 INFO:Local step 9500, global step 151707: loss 8.2759
[2019-03-22 22:34:00,650] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 9500, global step 151708: learning rate 0.0010
[2019-03-22 22:34:00,786] A3C_AGENT_WORKER-Thread-19 INFO:Local step 9500, global step 151761: loss 8.3514
[2019-03-22 22:34:00,789] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 9500, global step 151761: learning rate 0.0010
[2019-03-22 22:34:00,913] A3C_AGENT_WORKER-Thread-3 INFO:Local step 9500, global step 151813: loss 7.5103
[2019-03-22 22:34:00,914] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 9500, global step 151813: learning rate 0.0010
[2019-03-22 22:34:01,021] A3C_AGENT_WORKER-Thread-14 INFO:Local step 9500, global step 151853: loss 7.2614
[2019-03-22 22:34:01,022] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 9500, global step 151853: learning rate 0.0010
[2019-03-22 22:34:01,103] A3C_AGENT_WORKER-Thread-11 INFO:Local step 9500, global step 151883: loss 6.6786
[2019-03-22 22:34:01,106] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 9500, global step 151884: learning rate 0.0010
[2019-03-22 22:34:01,238] A3C_AGENT_WORKER-Thread-9 INFO:Local step 9500, global step 151936: loss 6.5150
[2019-03-22 22:34:01,241] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 9500, global step 151936: learning rate 0.0010
[2019-03-22 22:34:01,293] A3C_AGENT_WORKER-Thread-16 INFO:Local step 9500, global step 151956: loss 6.6200
[2019-03-22 22:34:01,296] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 9500, global step 151956: learning rate 0.0010
[2019-03-22 22:34:01,310] A3C_AGENT_WORKER-Thread-2 INFO:Local step 9500, global step 151961: loss 6.2791
[2019-03-22 22:34:01,318] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 9500, global step 151963: learning rate 0.0010
[2019-03-22 22:34:01,356] A3C_AGENT_WORKER-Thread-10 INFO:Local step 9500, global step 151976: loss 6.0690
[2019-03-22 22:34:01,360] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 9500, global step 151976: learning rate 0.0010
[2019-03-22 22:34:01,441] A3C_AGENT_WORKER-Thread-17 INFO:Local step 9500, global step 152013: loss 5.8113
[2019-03-22 22:34:01,443] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 9500, global step 152013: learning rate 0.0010
[2019-03-22 22:34:01,572] A3C_AGENT_WORKER-Thread-13 INFO:Local step 9500, global step 152063: loss 5.0605
[2019-03-22 22:34:01,574] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 9500, global step 152063: learning rate 0.0010
[2019-03-22 22:34:01,621] A3C_AGENT_WORKER-Thread-15 INFO:Local step 9500, global step 152083: loss 5.0047
[2019-03-22 22:34:01,625] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 9500, global step 152084: learning rate 0.0010
[2019-03-22 22:34:01,678] A3C_AGENT_WORKER-Thread-12 INFO:Local step 9500, global step 152109: loss 4.4060
[2019-03-22 22:34:01,682] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 9500, global step 152109: learning rate 0.0010
[2019-03-22 22:34:01,741] A3C_AGENT_WORKER-Thread-18 INFO:Local step 9500, global step 152133: loss 4.5212
[2019-03-22 22:34:01,743] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 9500, global step 152133: learning rate 0.0010
[2019-03-22 22:34:01,996] A3C_AGENT_WORKER-Thread-22 INFO:Local step 9500, global step 152234: loss 3.0207
[2019-03-22 22:34:01,999] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 9500, global step 152234: learning rate 0.0010
[2019-03-22 22:34:02,182] A3C_AGENT_WORKER-Thread-20 INFO:Local step 9500, global step 152304: loss 1.2275
[2019-03-22 22:34:02,185] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 9500, global step 152305: learning rate 0.0010
[2019-03-22 22:34:03,413] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.8180011e-20 1.0000000e+00 6.6612343e-23 3.7118816e-22 5.2628169e-17], sum to 1.0000
[2019-03-22 22:34:03,424] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2878
[2019-03-22 22:34:03,428] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [9.200000000000001, 87.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 135966.7805900251, 135966.7805900248, 56021.77953916509], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5718000.0000, 
sim time next is 5718600.0000, 
raw observation next is [9.100000000000001, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 134505.1939309605, 134505.1939309608, 55841.02184192377], 
processed observation next is [0.0, 0.17391304347826086, 0.050000000000000065, 0.88, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.049816738492948334, 0.04981673849294845, 0.13619761424859456], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.57811564], dtype=float32), -0.29920596]. 
=============================================
[2019-03-22 22:34:05,711] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.5996678e-38 1.0000000e+00 3.6542062e-31 1.2378375e-18 4.2668002e-20], sum to 1.0000
[2019-03-22 22:34:05,720] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2428
[2019-03-22 22:34:05,726] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.83333333333334, 56.0, 1.0, 2.0, 0.2450528602968915, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 266074.8873714529, 266074.8873714526, 80480.8286805382], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5772000.0000, 
sim time next is 5772600.0000, 
raw observation next is [18.0, 59.5, 1.0, 2.0, 0.2371524130926898, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 257494.4241456849, 257494.4241456849, 78563.50410578282], 
processed observation next is [0.0, 0.8260869565217391, 0.45454545454545453, 0.595, 1.0, 1.0, 0.046440516365862244, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09536830523914255, 0.09536830523914255, 0.19161830269703126], 
reward next is 0.8084, 
noisyNet noise sample is [array([-0.45038274], dtype=float32), 0.47224492]. 
=============================================
[2019-03-22 22:34:13,055] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.2622147e-38 1.0000000e+00 1.4676425e-34 2.3427596e-23 4.4444269e-20], sum to 1.0000
[2019-03-22 22:34:13,066] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8602
[2019-03-22 22:34:13,072] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.55, 69.5, 1.0, 2.0, 0.327586895629065, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 361357.4710936822, 361357.4710936819, 115110.9246722401], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5869800.0000, 
sim time next is 5870400.0000, 
raw observation next is [20.36666666666667, 70.66666666666667, 1.0, 2.0, 0.3274554047841684, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 361133.5251837183, 361133.5251837183, 115070.6619871107], 
processed observation next is [1.0, 0.9565217391304348, 0.5621212121212124, 0.7066666666666667, 1.0, 1.0, 0.1593192559802105, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13375315747545122, 0.13375315747545122, 0.28066015118807486], 
reward next is 0.7193, 
noisyNet noise sample is [array([0.5529118], dtype=float32), 2.0959098]. 
=============================================
[2019-03-22 22:34:21,122] A3C_AGENT_WORKER-Thread-21 INFO:Local step 10000, global step 159733: loss 0.5445
[2019-03-22 22:34:21,126] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 10000, global step 159733: learning rate 0.0010
[2019-03-22 22:34:21,185] A3C_AGENT_WORKER-Thread-19 INFO:Local step 10000, global step 159753: loss 0.7561
[2019-03-22 22:34:21,189] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 10000, global step 159753: learning rate 0.0010
[2019-03-22 22:34:21,322] A3C_AGENT_WORKER-Thread-3 INFO:Local step 10000, global step 159801: loss 0.6574
[2019-03-22 22:34:21,324] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 10000, global step 159802: learning rate 0.0010
[2019-03-22 22:34:21,445] A3C_AGENT_WORKER-Thread-14 INFO:Local step 10000, global step 159852: loss 0.6442
[2019-03-22 22:34:21,448] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 10000, global step 159852: learning rate 0.0010
[2019-03-22 22:34:21,594] A3C_AGENT_WORKER-Thread-11 INFO:Local step 10000, global step 159906: loss 0.6579
[2019-03-22 22:34:21,600] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 10000, global step 159907: learning rate 0.0010
[2019-03-22 22:34:21,632] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.9945988e-34 1.0000000e+00 6.5053819e-25 7.0928290e-21 2.6719415e-26], sum to 1.0000
[2019-03-22 22:34:21,640] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9102
[2019-03-22 22:34:21,648] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.6, 71.0, 1.0, 2.0, 0.7057313621439792, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 793614.7219912338, 793614.721991234, 157683.2358871978], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5994000.0000, 
sim time next is 5994600.0000, 
raw observation next is [21.88333333333334, 70.16666666666667, 1.0, 2.0, 0.8066620956301606, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 908669.5095606619, 908669.5095606619, 172111.9295485898], 
processed observation next is [1.0, 0.391304347826087, 0.6310606060606063, 0.7016666666666667, 1.0, 1.0, 0.7583276195377006, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.33654426280024513, 0.33654426280024513, 0.4197851940209507], 
reward next is 0.5802, 
noisyNet noise sample is [array([1.3379929], dtype=float32), 0.6677801]. 
=============================================
[2019-03-22 22:34:21,697] A3C_AGENT_WORKER-Thread-16 INFO:Local step 10000, global step 159946: loss 0.6656
[2019-03-22 22:34:21,700] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 10000, global step 159946: learning rate 0.0010
[2019-03-22 22:34:21,701] A3C_AGENT_WORKER-Thread-2 INFO:Local step 10000, global step 159946: loss 0.8429
[2019-03-22 22:34:21,704] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 10000, global step 159946: learning rate 0.0010
[2019-03-22 22:34:21,796] A3C_AGENT_WORKER-Thread-9 INFO:Local step 10000, global step 159979: loss 0.6710
[2019-03-22 22:34:21,799] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 10000, global step 159980: learning rate 0.0010
[2019-03-22 22:34:21,814] A3C_AGENT_WORKER-Thread-10 INFO:Local step 10000, global step 159986: loss 0.8938
[2019-03-22 22:34:21,818] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 10000, global step 159986: learning rate 0.0010
[2019-03-22 22:34:21,870] A3C_AGENT_WORKER-Thread-17 INFO:Local step 10000, global step 160015: loss 0.6997
[2019-03-22 22:34:21,871] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 10000, global step 160016: learning rate 0.0010
[2019-03-22 22:34:21,919] A3C_AGENT_WORKER-Thread-13 INFO:Local step 10000, global step 160033: loss 0.4875
[2019-03-22 22:34:21,923] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 10000, global step 160033: learning rate 0.0010
[2019-03-22 22:34:21,947] A3C_AGENT_WORKER-Thread-12 INFO:Local step 10000, global step 160040: loss 0.8698
[2019-03-22 22:34:21,948] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 10000, global step 160040: learning rate 0.0010
[2019-03-22 22:34:22,083] A3C_AGENT_WORKER-Thread-15 INFO:Local step 10000, global step 160094: loss 0.5899
[2019-03-22 22:34:22,087] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 10000, global step 160095: learning rate 0.0010
[2019-03-22 22:34:22,151] A3C_AGENT_WORKER-Thread-18 INFO:Local step 10000, global step 160118: loss 0.5468
[2019-03-22 22:34:22,154] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 10000, global step 160118: learning rate 0.0010
[2019-03-22 22:34:22,431] A3C_AGENT_WORKER-Thread-22 INFO:Local step 10000, global step 160225: loss 0.3644
[2019-03-22 22:34:22,433] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 10000, global step 160225: learning rate 0.0010
[2019-03-22 22:34:22,475] A3C_AGENT_WORKER-Thread-20 INFO:Local step 10000, global step 160241: loss 0.6428
[2019-03-22 22:34:22,477] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 10000, global step 160241: learning rate 0.0010
[2019-03-22 22:34:25,454] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 22:34:25,465] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7868
[2019-03-22 22:34:25,473] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.9, 79.33333333333334, 1.0, 2.0, 0.2521725103478644, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 273807.4774870933, 273807.477487093, 82267.33641407182], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6056400.0000, 
sim time next is 6057000.0000, 
raw observation next is [15.8, 79.0, 1.0, 2.0, 0.2380766579582266, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 258498.2138179602, 258498.2138179599, 80062.18840564314], 
processed observation next is [1.0, 0.08695652173913043, 0.35454545454545455, 0.79, 1.0, 1.0, 0.047595822447783244, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09574007919183711, 0.09574007919183701, 0.1952736302576662], 
reward next is 0.8047, 
noisyNet noise sample is [array([0.54038864], dtype=float32), 0.7813816]. 
=============================================
[2019-03-22 22:34:25,484] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[70.07789 ]
 [70.0472  ]
 [70.03078 ]
 [69.957054]
 [69.99098 ]], R is [[70.12595367]
 [70.2240448 ]
 [70.31528473]
 [70.41067505]
 [70.50285339]].
[2019-03-22 22:34:31,966] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 6.2995088e-33 9.2869955e-37], sum to 1.0000
[2019-03-22 22:34:31,977] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0439
[2019-03-22 22:34:31,985] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.45, 81.0, 1.0, 2.0, 0.3082319729020636, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 334697.4687614769, 334697.4687614772, 103574.5208049504], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6150600.0000, 
sim time next is 6151200.0000, 
raw observation next is [17.36666666666667, 82.0, 1.0, 2.0, 0.3045641112961298, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 330713.3219586681, 330713.3219586681, 103802.7962675692], 
processed observation next is [1.0, 0.17391304347826086, 0.42575757575757595, 0.82, 1.0, 1.0, 0.13070513912016224, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12248641554024746, 0.12248641554024746, 0.25317755187212], 
reward next is 0.7468, 
noisyNet noise sample is [array([-1.0843018], dtype=float32), 1.0092517]. 
=============================================
[2019-03-22 22:34:33,649] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.4604225e-38 1.0000000e+00 1.0649574e-30 7.7886850e-25 2.6167774e-32], sum to 1.0000
[2019-03-22 22:34:33,660] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8834
[2019-03-22 22:34:33,664] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.81666666666667, 67.66666666666666, 1.0, 2.0, 0.5777653734166595, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 638976.8422333816, 638976.8422333816, 137920.2704973376], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6169800.0000, 
sim time next is 6170400.0000, 
raw observation next is [21.1, 66.0, 1.0, 2.0, 0.587630879465166, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 650224.9175589904, 650224.9175589908, 139081.1695278409], 
processed observation next is [1.0, 0.43478260869565216, 0.5954545454545456, 0.66, 1.0, 1.0, 0.4845385993314575, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.24082404354036682, 0.24082404354036696, 0.33922236470205097], 
reward next is 0.6608, 
noisyNet noise sample is [array([0.50890785], dtype=float32), 0.60526925]. 
=============================================
[2019-03-22 22:34:34,039] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.4935128e-37 1.0000000e+00 1.7997692e-29 2.5914659e-17 5.6980977e-28], sum to 1.0000
[2019-03-22 22:34:34,054] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4305
[2019-03-22 22:34:34,064] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.6, 71.0, 1.0, 2.0, 0.7577996304576934, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 852520.5961333811, 852520.5961333811, 164733.8354824267], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6177600.0000, 
sim time next is 6178200.0000, 
raw observation next is [21.7, 71.0, 1.0, 2.0, 0.7053934491185083, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 794043.6641460327, 794043.6641460327, 158031.4423889381], 
processed observation next is [1.0, 0.5217391304347826, 0.6227272727272727, 0.71, 1.0, 1.0, 0.6317418113981355, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2940902459800121, 0.2940902459800121, 0.3854425424120441], 
reward next is 0.6146, 
noisyNet noise sample is [array([-1.2724566], dtype=float32), -1.9643761]. 
=============================================
[2019-03-22 22:34:41,631] A3C_AGENT_WORKER-Thread-21 INFO:Local step 10500, global step 167738: loss 0.0728
[2019-03-22 22:34:41,634] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 10500, global step 167738: learning rate 0.0010
[2019-03-22 22:34:41,796] A3C_AGENT_WORKER-Thread-19 INFO:Local step 10500, global step 167801: loss 0.0019
[2019-03-22 22:34:41,798] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 10500, global step 167801: learning rate 0.0010
[2019-03-22 22:34:41,909] A3C_AGENT_WORKER-Thread-3 INFO:Local step 10500, global step 167844: loss 0.0145
[2019-03-22 22:34:41,913] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 10500, global step 167845: learning rate 0.0010
[2019-03-22 22:34:41,959] A3C_AGENT_WORKER-Thread-14 INFO:Local step 10500, global step 167861: loss 0.0175
[2019-03-22 22:34:41,962] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 10500, global step 167861: learning rate 0.0010
[2019-03-22 22:34:42,104] A3C_AGENT_WORKER-Thread-16 INFO:Local step 10500, global step 167923: loss 0.0007
[2019-03-22 22:34:42,105] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 10500, global step 167923: learning rate 0.0010
[2019-03-22 22:34:42,138] A3C_AGENT_WORKER-Thread-11 INFO:Local step 10500, global step 167935: loss 0.0060
[2019-03-22 22:34:42,139] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 10500, global step 167935: learning rate 0.0010
[2019-03-22 22:34:42,203] A3C_AGENT_WORKER-Thread-2 INFO:Local step 10500, global step 167961: loss 0.0415
[2019-03-22 22:34:42,205] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 10500, global step 167961: learning rate 0.0010
[2019-03-22 22:34:42,209] A3C_AGENT_WORKER-Thread-10 INFO:Local step 10500, global step 167962: loss 0.0188
[2019-03-22 22:34:42,211] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 10500, global step 167962: learning rate 0.0010
[2019-03-22 22:34:42,233] A3C_AGENT_WORKER-Thread-13 INFO:Local step 10500, global step 167969: loss 0.0137
[2019-03-22 22:34:42,240] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 10500, global step 167971: learning rate 0.0010
[2019-03-22 22:34:42,267] A3C_AGENT_WORKER-Thread-9 INFO:Local step 10500, global step 167980: loss 0.0233
[2019-03-22 22:34:42,272] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 10500, global step 167980: learning rate 0.0010
[2019-03-22 22:34:42,319] A3C_AGENT_WORKER-Thread-17 INFO:Local step 10500, global step 168000: loss 0.0657
[2019-03-22 22:34:42,321] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 10500, global step 168000: learning rate 0.0010
[2019-03-22 22:34:42,518] A3C_AGENT_WORKER-Thread-12 INFO:Local step 10500, global step 168078: loss 0.0086
[2019-03-22 22:34:42,521] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 10500, global step 168079: learning rate 0.0010
[2019-03-22 22:34:42,527] A3C_AGENT_WORKER-Thread-15 INFO:Local step 10500, global step 168081: loss 0.0080
[2019-03-22 22:34:42,529] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 10500, global step 168082: learning rate 0.0010
[2019-03-22 22:34:42,604] A3C_AGENT_WORKER-Thread-18 INFO:Local step 10500, global step 168112: loss 0.0002
[2019-03-22 22:34:42,605] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 10500, global step 168112: learning rate 0.0010
[2019-03-22 22:34:42,980] A3C_AGENT_WORKER-Thread-22 INFO:Local step 10500, global step 168263: loss 0.0006
[2019-03-22 22:34:42,983] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 10500, global step 168264: learning rate 0.0010
[2019-03-22 22:34:43,086] A3C_AGENT_WORKER-Thread-20 INFO:Local step 10500, global step 168301: loss 0.0470
[2019-03-22 22:34:43,090] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 10500, global step 168302: learning rate 0.0010
[2019-03-22 22:34:47,773] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 6.008832e-33 2.424044e-37], sum to 1.0000
[2019-03-22 22:34:47,784] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9950
[2019-03-22 22:34:47,790] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.25, 80.0, 1.0, 2.0, 0.5634859468535822, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 638479.5795716877, 638479.5795716877, 152518.5975798556], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6381000.0000, 
sim time next is 6381600.0000, 
raw observation next is [25.16666666666666, 80.33333333333334, 1.0, 2.0, 0.5621777641194718, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 637151.5862435669, 637151.5862435669, 152290.2793742855], 
processed observation next is [0.0, 0.8695652173913043, 0.78030303030303, 0.8033333333333335, 1.0, 1.0, 0.45272220514933975, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23598206897909887, 0.23598206897909887, 0.37143970579094027], 
reward next is 0.6286, 
noisyNet noise sample is [array([-0.7766707], dtype=float32), -0.47110325]. 
=============================================
[2019-03-22 22:34:48,927] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 7.4696412e-34 1.9637418e-35], sum to 1.0000
[2019-03-22 22:34:48,936] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5885
[2019-03-22 22:34:48,949] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.4, 74.66666666666666, 1.0, 2.0, 0.597521024136646, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 681756.8567969718, 681756.8567969721, 153715.0301932448], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6403200.0000, 
sim time next is 6403800.0000, 
raw observation next is [24.4, 74.33333333333334, 1.0, 2.0, 0.5791555697904275, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 660835.6190273796, 660835.6190273796, 151201.9765666981], 
processed observation next is [1.0, 0.08695652173913043, 0.7454545454545454, 0.7433333333333334, 1.0, 1.0, 0.4739444622380343, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.24475393297310355, 0.24475393297310355, 0.3687853086992637], 
reward next is 0.6312, 
noisyNet noise sample is [array([0.4144044], dtype=float32), -0.26826942]. 
=============================================
[2019-03-22 22:34:49,671] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 22:34:49,685] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1965
[2019-03-22 22:34:49,694] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.8, 71.0, 1.0, 2.0, 0.4880595761522142, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 556913.5545409712, 556913.5545409712, 139786.7202246134], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6417600.0000, 
sim time next is 6418200.0000, 
raw observation next is [24.9, 71.0, 1.0, 2.0, 0.4836757180308804, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 551879.2119674638, 551879.2119674636, 139478.9205815407], 
processed observation next is [1.0, 0.2608695652173913, 0.7681818181818181, 0.71, 1.0, 1.0, 0.3545946475386004, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20439970813609773, 0.20439970813609762, 0.34019248922327], 
reward next is 0.6598, 
noisyNet noise sample is [array([0.22565846], dtype=float32), -1.038722]. 
=============================================
[2019-03-22 22:34:52,196] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 3.1954020e-37 3.3045725e-33 4.6325196e-36], sum to 1.0000
[2019-03-22 22:34:52,205] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0692
[2019-03-22 22:34:52,214] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.93333333333333, 95.33333333333334, 1.0, 2.0, 0.7560319797272058, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 860548.0195438527, 860548.0195438529, 170823.6723032492], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6438000.0000, 
sim time next is 6438600.0000, 
raw observation next is [19.65, 96.5, 1.0, 2.0, 0.6830364057432368, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 776680.5422104098, 776680.5422104095, 159923.5391370106], 
processed observation next is [1.0, 0.5217391304347826, 0.5295454545454544, 0.965, 1.0, 1.0, 0.603795507179046, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.28765946007792953, 0.2876594600779295, 0.39005741252929416], 
reward next is 0.6099, 
noisyNet noise sample is [array([1.5712769], dtype=float32), 0.7069456]. 
=============================================
[2019-03-22 22:34:54,911] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 22:34:54,922] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8897
[2019-03-22 22:34:54,927] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.0, 77.0, 1.0, 2.0, 0.2082288009244206, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 226082.5583220183, 226082.5583220181, 73422.61797076499], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6485400.0000, 
sim time next is 6486000.0000, 
raw observation next is [15.0, 77.0, 1.0, 2.0, 0.2077073911741807, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 225516.3111111478, 225516.3111111478, 73371.7353245908], 
processed observation next is [1.0, 0.043478260869565216, 0.3181818181818182, 0.77, 1.0, 1.0, 0.009634238967725847, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08352455967079549, 0.08352455967079549, 0.17895545201119709], 
reward next is 0.8210, 
noisyNet noise sample is [array([-0.8946601], dtype=float32), 0.089972734]. 
=============================================
[2019-03-22 22:34:54,949] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[70.76041 ]
 [70.88969 ]
 [71.022194]
 [71.17152 ]
 [71.23209 ]], R is [[70.7539978 ]
 [70.86737823]
 [70.97955322]
 [71.0905838 ]
 [71.20040131]].
[2019-03-22 22:34:55,036] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.5305694e-38], sum to 1.0000
[2019-03-22 22:34:55,047] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4433
[2019-03-22 22:34:55,052] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.1, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 205156.1253947009, 205156.1253947012, 69063.11974416862], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6492000.0000, 
sim time next is 6492600.0000, 
raw observation next is [13.0, 88.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 203154.3702369949, 203154.3702369946, 68615.94282274973], 
processed observation next is [1.0, 0.13043478260869565, 0.22727272727272727, 0.885, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07524235934703515, 0.07524235934703503, 0.16735595810426762], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.1368355], dtype=float32), -0.81129336]. 
=============================================
[2019-03-22 22:34:55,950] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.9456617e-38 0.0000000e+00], sum to 1.0000
[2019-03-22 22:34:55,965] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2233
[2019-03-22 22:34:55,969] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.03333333333333, 85.33333333333334, 1.0, 2.0, 0.2068306439604302, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 224564.1714756488, 224564.1714756488, 73309.17502795758], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6506400.0000, 
sim time next is 6507000.0000, 
raw observation next is [14.4, 83.5, 1.0, 2.0, 0.204454487708134, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 221983.6964005556, 221983.6964005553, 73384.22220334488], 
processed observation next is [1.0, 0.30434782608695654, 0.29090909090909095, 0.835, 1.0, 1.0, 0.005568109635167469, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08221618385205763, 0.08221618385205752, 0.17898590781303628], 
reward next is 0.8210, 
noisyNet noise sample is [array([0.2251652], dtype=float32), -1.6263978]. 
=============================================
[2019-03-22 22:34:55,981] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[58.45332 ]
 [58.442013]
 [58.494778]
 [58.47187 ]
 [58.460064]], R is [[58.69296265]
 [58.92723083]
 [59.15702057]
 [58.56545258]
 [57.97979736]].
[2019-03-22 22:34:58,234] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 22:34:58,248] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1897
[2019-03-22 22:34:58,254] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.31666666666667, 49.83333333333334, 1.0, 2.0, 0.3697447049840054, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 401519.4005609863, 401519.4005609865, 95596.18491284885], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6526200.0000, 
sim time next is 6526800.0000, 
raw observation next is [20.5, 49.0, 1.0, 2.0, 0.425047333443745, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 461603.071506443, 461603.0715064427, 101484.5352522724], 
processed observation next is [1.0, 0.5652173913043478, 0.5681818181818182, 0.49, 1.0, 1.0, 0.2813091668046812, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17096410055794187, 0.17096410055794173, 0.24752325671285952], 
reward next is 0.7525, 
noisyNet noise sample is [array([0.04794709], dtype=float32), 0.8468372]. 
=============================================
[2019-03-22 22:34:59,473] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 22:34:59,483] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6624
[2019-03-22 22:34:59,487] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.9, 73.66666666666666, 1.0, 2.0, 0.2287854754034231, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 248407.4831936879, 248407.4831936876, 77000.64661245803], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6561600.0000, 
sim time next is 6562200.0000, 
raw observation next is [15.45, 76.83333333333334, 1.0, 2.0, 0.2234690021631683, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 242633.5976736057, 242633.5976736055, 76224.10775790681], 
processed observation next is [1.0, 0.9565217391304348, 0.3386363636363636, 0.7683333333333334, 1.0, 1.0, 0.029336252703960376, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08986429543466877, 0.0898642954346687, 0.18591245794611416], 
reward next is 0.8141, 
noisyNet noise sample is [array([0.75034106], dtype=float32), -0.3999143]. 
=============================================
[2019-03-22 22:35:00,225] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-22 22:35:00,232] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-22 22:35:00,233] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-22 22:35:00,234] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:35:00,235] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:35:00,236] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-22 22:35:00,238] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-22 22:35:00,240] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-22 22:35:00,242] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:35:00,245] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:35:00,242] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:35:00,265] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run8
[2019-03-22 22:35:00,265] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run8
[2019-03-22 22:35:00,266] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run8
[2019-03-22 22:35:00,302] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run8
[2019-03-22 22:35:00,343] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run8
[2019-03-22 22:35:29,136] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.22877865], dtype=float32), -0.2613883]
[2019-03-22 22:35:29,136] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.4, 72.0, 1.0, 2.0, 0.3708270577238343, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 415732.2783361297, 415732.2783361297, 125513.3535580326]
[2019-03-22 22:35:29,138] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 22:35:29,141] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.2664667235009903
[2019-03-22 22:35:36,476] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.22877865], dtype=float32), -0.2613883]
[2019-03-22 22:35:36,476] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.25, 47.16666666666667, 1.0, 2.0, 0.3432299009305835, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 372687.7217329507, 372687.7217329511, 91662.91421125486]
[2019-03-22 22:35:36,478] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 22:35:36,480] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.3801297483311977
[2019-03-22 22:36:02,507] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.22877865], dtype=float32), -0.2613883]
[2019-03-22 22:36:02,509] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [25.10193799, 54.01201686, 1.0, 2.0, 0.3699390772475197, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 417183.9003745656, 417183.9003745659, 126696.9219324496]
[2019-03-22 22:36:02,511] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 22:36:02,513] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.6071383878763218
[2019-03-22 22:36:13,827] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.22877865], dtype=float32), -0.2613883]
[2019-03-22 22:36:13,830] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.33333333333333, 75.66666666666666, 1.0, 2.0, 0.2629561672483062, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 285519.7477671632, 285519.7477671629, 89714.63813194231]
[2019-03-22 22:36:13,831] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 22:36:13,835] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.710064305444958
[2019-03-22 22:36:20,670] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.22877865], dtype=float32), -0.2613883]
[2019-03-22 22:36:20,673] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.23867588, 100.0, 1.0, 2.0, 0.5994653568815508, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 673546.9541925214, 673546.9541925214, 163134.7098372317]
[2019-03-22 22:36:20,674] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 22:36:20,676] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.9911610152264766
[2019-03-22 22:36:28,866] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.22877865], dtype=float32), -0.2613883]
[2019-03-22 22:36:28,868] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.85859400666666, 97.53570237999999, 1.0, 2.0, 0.4120241339695251, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 468342.7204261676, 468342.7204261676, 132901.959414806]
[2019-03-22 22:36:28,870] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 22:36:28,875] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.3141876876621056
[2019-03-22 22:36:49,117] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.22877865], dtype=float32), -0.2613883]
[2019-03-22 22:36:49,118] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.95, 80.0, 1.0, 2.0, 0.3728876973759027, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 420657.0652048053, 420657.065204805, 127035.6557582129]
[2019-03-22 22:36:49,119] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 22:36:49,122] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.9456344209670589
[2019-03-22 22:37:03,310] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9309 1705967916.6745 465.0000
[2019-03-22 22:37:03,903] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-22 22:37:03,914] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1147 1656209757.7786 80.0000
[2019-03-22 22:37:04,058] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3486 1683344882.4587 214.0000
[2019-03-22 22:37:04,148] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-22 22:37:05,166] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 175000, evaluation results [175000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.114669779829, 1656209757.7786272, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8596.930884973775, 1705967916.6744611, 465.0, 8574.348638023737, 1683344882.4586744, 214.0]
[2019-03-22 22:37:06,126] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 22:37:06,138] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3007
[2019-03-22 22:37:06,146] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [11.1, 96.66666666666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 187939.2061498055, 187939.2061498057, 64439.88881794196], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6587400.0000, 
sim time next is 6588000.0000, 
raw observation next is [11.1, 96.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 186888.8648029277, 186888.864802928, 64202.10524088257], 
processed observation next is [1.0, 0.2608695652173913, 0.1409090909090909, 0.96, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.06921809807515841, 0.06921809807515852, 0.15659050058751847], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.30792996], dtype=float32), -1.6800079]. 
=============================================
[2019-03-22 22:37:06,161] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[68.27259]
 [68.31008]
 [68.34762]
 [68.37714]
 [68.40038]], R is [[67.56865692]
 [66.89296722]
 [66.22403717]
 [65.5617981 ]
 [64.90618134]].
[2019-03-22 22:37:06,953] A3C_AGENT_WORKER-Thread-21 INFO:Local step 11000, global step 175707: loss 2.6723
[2019-03-22 22:37:06,956] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 11000, global step 175707: learning rate 0.0010
[2019-03-22 22:37:07,267] A3C_AGENT_WORKER-Thread-14 INFO:Local step 11000, global step 175823: loss 4.5276
[2019-03-22 22:37:07,270] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 11000, global step 175824: learning rate 0.0010
[2019-03-22 22:37:07,353] A3C_AGENT_WORKER-Thread-3 INFO:Local step 11000, global step 175857: loss 3.9032
[2019-03-22 22:37:07,357] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 11000, global step 175858: learning rate 0.0010
[2019-03-22 22:37:07,389] A3C_AGENT_WORKER-Thread-19 INFO:Local step 11000, global step 175869: loss 4.9898
[2019-03-22 22:37:07,395] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 11000, global step 175869: learning rate 0.0010
[2019-03-22 22:37:07,487] A3C_AGENT_WORKER-Thread-16 INFO:Local step 11000, global step 175908: loss 4.5191
[2019-03-22 22:37:07,489] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 11000, global step 175908: learning rate 0.0010
[2019-03-22 22:37:07,513] A3C_AGENT_WORKER-Thread-13 INFO:Local step 11000, global step 175919: loss 3.5810
[2019-03-22 22:37:07,520] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 11000, global step 175919: learning rate 0.0010
[2019-03-22 22:37:07,533] A3C_AGENT_WORKER-Thread-2 INFO:Local step 11000, global step 175926: loss 2.7473
[2019-03-22 22:37:07,536] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 11000, global step 175927: learning rate 0.0010
[2019-03-22 22:37:07,632] A3C_AGENT_WORKER-Thread-11 INFO:Local step 11000, global step 175963: loss 3.7927
[2019-03-22 22:37:07,638] A3C_AGENT_WORKER-Thread-9 INFO:Local step 11000, global step 175963: loss 3.6114
[2019-03-22 22:37:07,639] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 11000, global step 175963: learning rate 0.0010
[2019-03-22 22:37:07,641] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 11000, global step 175963: learning rate 0.0010
[2019-03-22 22:37:07,766] A3C_AGENT_WORKER-Thread-10 INFO:Local step 11000, global step 176023: loss 3.4145
[2019-03-22 22:37:07,769] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 11000, global step 176024: learning rate 0.0010
[2019-03-22 22:37:07,832] A3C_AGENT_WORKER-Thread-17 INFO:Local step 11000, global step 176049: loss 2.4806
[2019-03-22 22:37:07,836] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 11000, global step 176051: learning rate 0.0010
[2019-03-22 22:37:07,840] A3C_AGENT_WORKER-Thread-15 INFO:Local step 11000, global step 176051: loss 3.4431
[2019-03-22 22:37:07,843] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 11000, global step 176052: learning rate 0.0010
[2019-03-22 22:37:07,880] A3C_AGENT_WORKER-Thread-12 INFO:Local step 11000, global step 176069: loss 2.4852
[2019-03-22 22:37:07,882] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 11000, global step 176069: learning rate 0.0010
[2019-03-22 22:37:08,158] A3C_AGENT_WORKER-Thread-18 INFO:Local step 11000, global step 176176: loss 1.9296
[2019-03-22 22:37:08,162] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 11000, global step 176178: learning rate 0.0010
[2019-03-22 22:37:08,354] A3C_AGENT_WORKER-Thread-20 INFO:Local step 11000, global step 176253: loss 1.7925
[2019-03-22 22:37:08,357] A3C_AGENT_WORKER-Thread-22 INFO:Local step 11000, global step 176254: loss 1.7810
[2019-03-22 22:37:08,357] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 11000, global step 176254: learning rate 0.0010
[2019-03-22 22:37:08,363] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 11000, global step 176254: learning rate 0.0010
[2019-03-22 22:37:13,076] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.7484716e-31 7.3825118e-32], sum to 1.0000
[2019-03-22 22:37:13,085] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9135
[2019-03-22 22:37:13,094] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 89.0, 1.0, 2.0, 0.3716850397377511, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 416086.551290492, 416086.551290492, 120978.6557607885], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6680400.0000, 
sim time next is 6681000.0000, 
raw observation next is [18.9, 89.5, 1.0, 2.0, 0.3704024611223494, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 414437.0121586117, 414437.012158612, 120773.1929058636], 
processed observation next is [1.0, 0.30434782608695654, 0.49545454545454537, 0.895, 1.0, 1.0, 0.21300307640293675, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1534951896883747, 0.15349518968837483, 0.29456876318503317], 
reward next is 0.7054, 
noisyNet noise sample is [array([-0.6891343], dtype=float32), 0.9963641]. 
=============================================
[2019-03-22 22:37:13,118] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[68.161255]
 [68.105545]
 [68.044106]
 [67.99207 ]
 [67.99459 ]], R is [[68.23031616]
 [68.25294495]
 [68.27472687]
 [68.29496002]
 [68.31218719]].
[2019-03-22 22:37:14,218] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.0289876e-31 1.6219949e-32], sum to 1.0000
[2019-03-22 22:37:14,231] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3740
[2019-03-22 22:37:14,238] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.2, 93.66666666666666, 1.0, 2.0, 0.6518664969328933, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 728779.9248950768, 728779.9248950768, 149041.7657164647], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6693000.0000, 
sim time next is 6693600.0000, 
raw observation next is [18.1, 94.33333333333334, 1.0, 2.0, 0.6693770697184795, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 748370.1171846767, 748370.117184677, 151145.9321541288], 
processed observation next is [1.0, 0.4782608695652174, 0.45909090909090916, 0.9433333333333335, 1.0, 1.0, 0.5867213371480994, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.27717411747580617, 0.27717411747580634, 0.36864861501007024], 
reward next is 0.6314, 
noisyNet noise sample is [array([-1.5847012], dtype=float32), -0.3466282]. 
=============================================
[2019-03-22 22:37:16,110] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 3.2021443e-33], sum to 1.0000
[2019-03-22 22:37:16,119] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9064
[2019-03-22 22:37:16,126] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 97.0, 1.0, 2.0, 0.3562432626319031, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 396622.4417906591, 396622.4417906591, 118732.1885728334], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6727200.0000, 
sim time next is 6727800.0000, 
raw observation next is [17.7, 97.0, 1.0, 2.0, 0.3562318422108859, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 396608.3024093672, 396608.3024093675, 118730.6716286765], 
processed observation next is [1.0, 0.8695652173913043, 0.44090909090909086, 0.97, 1.0, 1.0, 0.19528980276360733, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1468919638553212, 0.1468919638553213, 0.2895870039723817], 
reward next is 0.7104, 
noisyNet noise sample is [array([0.61933434], dtype=float32), -0.0035554413]. 
=============================================
[2019-03-22 22:37:18,426] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 22:37:18,433] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1190
[2019-03-22 22:37:18,443] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.2, 93.0, 1.0, 2.0, 0.3216150273591896, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 352466.5883604378, 352466.5883604381, 113802.7531004965], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6753600.0000, 
sim time next is 6754200.0000, 
raw observation next is [17.2, 92.5, 1.0, 2.0, 0.3592081464821024, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 393478.911608036, 393478.911608036, 116505.8107564511], 
processed observation next is [1.0, 0.17391304347826086, 0.41818181818181815, 0.925, 1.0, 1.0, 0.199010183102628, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14573293022519854, 0.14573293022519854, 0.28416051404012466], 
reward next is 0.7158, 
noisyNet noise sample is [array([0.08012707], dtype=float32), 0.84663117]. 
=============================================
[2019-03-22 22:37:20,397] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.9593144e-29 5.5128309e-35], sum to 1.0000
[2019-03-22 22:37:20,407] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4717
[2019-03-22 22:37:20,416] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1255098.023620622 W.
[2019-03-22 22:37:20,423] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.7, 64.0, 1.0, 2.0, 0.9964689008021744, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.277086730254196, 6.9112, 77.32768968023734, 1255098.023620622, 1136266.686372727, 211848.294339017], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6787800.0000, 
sim time next is 6788400.0000, 
raw observation next is [24.8, 63.33333333333333, 1.0, 2.0, 0.3625230339047295, 1.0, 1.0, 0.3625230339047295, 1.0, 1.0, 0.7322225620407092, 6.9112, 6.9112, 77.3421103, 1241640.68792349, 1241640.68792349, 278046.9778834818], 
processed observation next is [1.0, 0.5652173913043478, 0.7636363636363637, 0.6333333333333333, 1.0, 1.0, 0.20315379238091186, 1.0, 0.5, 0.20315379238091186, 1.0, 0.5, 0.6174608029152989, 0.0, 0.0, 0.5085185399722538, 0.45986692145314445, 0.45986692145314445, 0.6781633606914191], 
reward next is 0.3218, 
noisyNet noise sample is [array([0.2747006], dtype=float32), 0.49285865]. 
=============================================
[2019-03-22 22:37:22,697] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.9022287e-25 7.2986817e-30], sum to 1.0000
[2019-03-22 22:37:22,708] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1551
[2019-03-22 22:37:22,715] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 72.66666666666667, 1.0, 2.0, 0.4081353229611981, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 462186.9833881573, 462186.9833881573, 126904.567516271], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6819600.0000, 
sim time next is 6820200.0000, 
raw observation next is [22.15, 73.5, 1.0, 2.0, 0.4062313020654916, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 459827.3802183582, 459827.3802183582, 126596.4186782655], 
processed observation next is [1.0, 0.9565217391304348, 0.6431818181818181, 0.735, 1.0, 1.0, 0.25778912758186445, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17030643711791044, 0.17030643711791044, 0.3087717528738183], 
reward next is 0.6912, 
noisyNet noise sample is [array([-0.14398877], dtype=float32), -0.8606205]. 
=============================================
[2019-03-22 22:37:25,085] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.0087927e-35 0.0000000e+00], sum to 1.0000
[2019-03-22 22:37:25,094] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4886
[2019-03-22 22:37:25,100] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.73333333333333, 95.0, 1.0, 2.0, 0.338642414237675, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 375566.0118740706, 375566.0118740706, 116730.6358912148], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6852000.0000, 
sim time next is 6852600.0000, 
raw observation next is [18.0, 94.5, 1.0, 2.0, 0.3439997495040985, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 382732.5125120567, 382732.512512057, 117651.9416518361], 
processed observation next is [0.0, 0.30434782608695654, 0.45454545454545453, 0.945, 1.0, 1.0, 0.1799996868801231, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14175278241187284, 0.14175278241187295, 0.28695595524838075], 
reward next is 0.7130, 
noisyNet noise sample is [array([0.15408342], dtype=float32), -0.6942465]. 
=============================================
[2019-03-22 22:37:27,373] A3C_AGENT_WORKER-Thread-21 INFO:Local step 11500, global step 183690: loss 0.0019
[2019-03-22 22:37:27,376] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 11500, global step 183690: learning rate 0.0010
[2019-03-22 22:37:27,687] A3C_AGENT_WORKER-Thread-14 INFO:Local step 11500, global step 183808: loss 0.0567
[2019-03-22 22:37:27,687] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 11500, global step 183808: learning rate 0.0010
[2019-03-22 22:37:27,878] A3C_AGENT_WORKER-Thread-3 INFO:Local step 11500, global step 183889: loss 0.0006
[2019-03-22 22:37:27,882] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 11500, global step 183889: learning rate 0.0010
[2019-03-22 22:37:27,981] A3C_AGENT_WORKER-Thread-9 INFO:Local step 11500, global step 183930: loss 0.0415
[2019-03-22 22:37:27,983] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 11500, global step 183930: learning rate 0.0010
[2019-03-22 22:37:27,991] A3C_AGENT_WORKER-Thread-19 INFO:Local step 11500, global step 183933: loss 0.0198
[2019-03-22 22:37:27,995] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 11500, global step 183933: learning rate 0.0010
[2019-03-22 22:37:28,008] A3C_AGENT_WORKER-Thread-16 INFO:Local step 11500, global step 183937: loss 0.0646
[2019-03-22 22:37:28,011] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 11500, global step 183938: learning rate 0.0010
[2019-03-22 22:37:28,017] A3C_AGENT_WORKER-Thread-13 INFO:Local step 11500, global step 183941: loss 0.0492
[2019-03-22 22:37:28,019] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 11500, global step 183941: learning rate 0.0010
[2019-03-22 22:37:28,027] A3C_AGENT_WORKER-Thread-2 INFO:Local step 11500, global step 183945: loss 0.0422
[2019-03-22 22:37:28,029] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 11500, global step 183945: learning rate 0.0010
[2019-03-22 22:37:28,139] A3C_AGENT_WORKER-Thread-11 INFO:Local step 11500, global step 183989: loss 0.0060
[2019-03-22 22:37:28,144] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 11500, global step 183990: learning rate 0.0010
[2019-03-22 22:37:28,181] A3C_AGENT_WORKER-Thread-10 INFO:Local step 11500, global step 184007: loss 0.0020
[2019-03-22 22:37:28,187] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 11500, global step 184009: learning rate 0.0010
[2019-03-22 22:37:28,313] A3C_AGENT_WORKER-Thread-15 INFO:Local step 11500, global step 184055: loss 0.0204
[2019-03-22 22:37:28,317] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 11500, global step 184057: learning rate 0.0010
[2019-03-22 22:37:28,327] A3C_AGENT_WORKER-Thread-12 INFO:Local step 11500, global step 184060: loss 0.0477
[2019-03-22 22:37:28,334] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 11500, global step 184063: learning rate 0.0010
[2019-03-22 22:37:28,351] A3C_AGENT_WORKER-Thread-17 INFO:Local step 11500, global step 184069: loss 0.0540
[2019-03-22 22:37:28,355] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 11500, global step 184069: learning rate 0.0010
[2019-03-22 22:37:28,493] A3C_AGENT_WORKER-Thread-22 INFO:Local step 11500, global step 184121: loss 0.0310
[2019-03-22 22:37:28,494] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 11500, global step 184122: learning rate 0.0010
[2019-03-22 22:37:28,632] A3C_AGENT_WORKER-Thread-18 INFO:Local step 11500, global step 184176: loss 0.0005
[2019-03-22 22:37:28,634] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 11500, global step 184176: learning rate 0.0010
[2019-03-22 22:37:28,809] A3C_AGENT_WORKER-Thread-20 INFO:Local step 11500, global step 184245: loss 0.0504
[2019-03-22 22:37:28,810] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 11500, global step 184245: learning rate 0.0010
[2019-03-22 22:37:34,136] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 1.785999e-32 8.700459e-30 2.147867e-33], sum to 1.0000
[2019-03-22 22:37:34,143] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2263
[2019-03-22 22:37:34,148] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 71.0, 1.0, 2.0, 0.4951950023491119, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 564949.2558362321, 564949.2558362321, 141083.2665683016], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6984000.0000, 
sim time next is 6984600.0000, 
raw observation next is [24.9, 71.5, 1.0, 2.0, 0.4929763313925222, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 562438.7489638311, 562438.7489638311, 140762.2795781337], 
processed observation next is [0.0, 0.8695652173913043, 0.7681818181818181, 0.715, 1.0, 1.0, 0.36622041424065277, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20831064776438188, 0.20831064776438188, 0.34332263311739925], 
reward next is 0.6567, 
noisyNet noise sample is [array([0.83191097], dtype=float32), -1.0620828]. 
=============================================
[2019-03-22 22:37:37,240] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 4.1002996e-38 9.6595972e-30 4.5188490e-33], sum to 1.0000
[2019-03-22 22:37:37,249] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9710
[2019-03-22 22:37:37,256] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 97.0, 1.0, 2.0, 0.6547068116146683, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 739756.6801315775, 739756.6801315778, 153078.4970378015], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7034400.0000, 
sim time next is 7035000.0000, 
raw observation next is [18.9, 96.33333333333334, 1.0, 2.0, 0.7359390082554287, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 832019.8966910738, 832019.8966910735, 163942.1890712533], 
processed observation next is [1.0, 0.43478260869565216, 0.49545454545454537, 0.9633333333333334, 1.0, 1.0, 0.6699237603192859, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3081555172929903, 0.3081555172929902, 0.39985899773476413], 
reward next is 0.6001, 
noisyNet noise sample is [array([-0.25532636], dtype=float32), 0.81338555]. 
=============================================
[2019-03-22 22:37:37,278] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[61.67772 ]
 [61.84129 ]
 [61.810863]
 [61.745476]
 [61.703197]], R is [[61.41430283]
 [61.42679596]
 [61.4632225 ]
 [61.49422455]
 [61.51568604]].
[2019-03-22 22:37:47,727] A3C_AGENT_WORKER-Thread-21 INFO:Local step 12000, global step 191670: loss 0.6675
[2019-03-22 22:37:47,733] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 12000, global step 191670: learning rate 0.0010
[2019-03-22 22:37:48,075] A3C_AGENT_WORKER-Thread-14 INFO:Local step 12000, global step 191812: loss 1.8465
[2019-03-22 22:37:48,080] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 12000, global step 191812: learning rate 0.0010
[2019-03-22 22:37:48,249] A3C_AGENT_WORKER-Thread-3 INFO:Local step 12000, global step 191881: loss 3.1287
[2019-03-22 22:37:48,251] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 12000, global step 191881: learning rate 0.0010
[2019-03-22 22:37:48,324] A3C_AGENT_WORKER-Thread-2 INFO:Local step 12000, global step 191909: loss 3.3462
[2019-03-22 22:37:48,327] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 12000, global step 191909: learning rate 0.0010
[2019-03-22 22:37:48,339] A3C_AGENT_WORKER-Thread-19 INFO:Local step 12000, global step 191912: loss 2.9149
[2019-03-22 22:37:48,341] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 12000, global step 191913: learning rate 0.0010
[2019-03-22 22:37:48,449] A3C_AGENT_WORKER-Thread-16 INFO:Local step 12000, global step 191954: loss 4.5284
[2019-03-22 22:37:48,455] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 12000, global step 191954: learning rate 0.0010
[2019-03-22 22:37:48,473] A3C_AGENT_WORKER-Thread-10 INFO:Local step 12000, global step 191963: loss 3.9272
[2019-03-22 22:37:48,478] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 12000, global step 191963: learning rate 0.0010
[2019-03-22 22:37:48,495] A3C_AGENT_WORKER-Thread-13 INFO:Local step 12000, global step 191971: loss 3.8943
[2019-03-22 22:37:48,500] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 12000, global step 191971: learning rate 0.0010
[2019-03-22 22:37:48,552] A3C_AGENT_WORKER-Thread-9 INFO:Local step 12000, global step 191992: loss 4.2659
[2019-03-22 22:37:48,560] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 12000, global step 191996: learning rate 0.0010
[2019-03-22 22:37:48,622] A3C_AGENT_WORKER-Thread-11 INFO:Local step 12000, global step 192022: loss 5.4295
[2019-03-22 22:37:48,631] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 12000, global step 192025: learning rate 0.0010
[2019-03-22 22:37:48,698] A3C_AGENT_WORKER-Thread-22 INFO:Local step 12000, global step 192049: loss 4.8119
[2019-03-22 22:37:48,699] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 12000, global step 192049: learning rate 0.0010
[2019-03-22 22:37:48,822] A3C_AGENT_WORKER-Thread-15 INFO:Local step 12000, global step 192098: loss 3.5575
[2019-03-22 22:37:48,826] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 12000, global step 192099: learning rate 0.0010
[2019-03-22 22:37:48,853] A3C_AGENT_WORKER-Thread-17 INFO:Local step 12000, global step 192108: loss 3.7146
[2019-03-22 22:37:48,860] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 12000, global step 192109: learning rate 0.0010
[2019-03-22 22:37:48,883] A3C_AGENT_WORKER-Thread-12 INFO:Local step 12000, global step 192122: loss 3.8365
[2019-03-22 22:37:48,888] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 12000, global step 192123: learning rate 0.0010
[2019-03-22 22:37:48,988] A3C_AGENT_WORKER-Thread-18 INFO:Local step 12000, global step 192160: loss 3.9167
[2019-03-22 22:37:48,994] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 12000, global step 192160: learning rate 0.0010
[2019-03-22 22:37:49,158] A3C_AGENT_WORKER-Thread-20 INFO:Local step 12000, global step 192218: loss 2.0343
[2019-03-22 22:37:49,162] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 12000, global step 192218: learning rate 0.0010
[2019-03-22 22:37:49,467] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.4851662e-38 1.0000000e+00 5.2696420e-34 1.9792986e-31 2.2461665e-34], sum to 1.0000
[2019-03-22 22:37:49,473] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5431
[2019-03-22 22:37:49,479] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.46666666666667, 51.66666666666667, 1.0, 2.0, 0.5249600223217463, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 570172.2780651575, 570172.2780651575, 122856.8347861835], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7208400.0000, 
sim time next is 7209000.0000, 
raw observation next is [21.65, 51.0, 1.0, 2.0, 0.5238294256168187, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 568943.5898739728, 568943.589873973, 123222.6516170113], 
processed observation next is [1.0, 0.43478260869565216, 0.6204545454545454, 0.51, 1.0, 1.0, 0.4047867820210233, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2107198481014714, 0.21071984810147149, 0.30054305272441784], 
reward next is 0.6995, 
noisyNet noise sample is [array([-2.2257786], dtype=float32), -0.7197028]. 
=============================================
[2019-03-22 22:37:49,510] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[67.62746]
 [67.33227]
 [67.02032]
 [66.66097]
 [66.33999]], R is [[67.89258575]
 [67.91400909]
 [67.92939758]
 [67.9479599 ]
 [67.96579742]].
[2019-03-22 22:37:54,023] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.1817492e-38 0.0000000e+00], sum to 1.0000
[2019-03-22 22:37:54,034] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9223
[2019-03-22 22:37:54,041] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.95, 78.0, 1.0, 2.0, 0.2159030953249356, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 234416.8626904767, 234416.8626904767, 74268.51364848802], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7283400.0000, 
sim time next is 7284000.0000, 
raw observation next is [15.5, 75.0, 1.0, 2.0, 0.2342758123674686, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 254370.2630565255, 254370.2630565255, 76647.16115181417], 
processed observation next is [1.0, 0.30434782608695654, 0.3409090909090909, 0.75, 1.0, 1.0, 0.04284476545933575, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09421120853945389, 0.09421120853945389, 0.18694429549222968], 
reward next is 0.8131, 
noisyNet noise sample is [array([0.26921278], dtype=float32), 0.953099]. 
=============================================
[2019-03-22 22:37:54,056] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[69.23279 ]
 [69.21432 ]
 [69.171394]
 [69.166435]
 [69.16319 ]], R is [[69.36346436]
 [69.48868561]
 [69.61647034]
 [69.74428558]
 [69.87228394]].
[2019-03-22 22:37:54,948] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 3.0766843e-36 3.6202525e-32 0.0000000e+00], sum to 1.0000
[2019-03-22 22:37:54,962] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2315
[2019-03-22 22:37:54,967] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.3, 55.0, 1.0, 2.0, 0.6239157501323502, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 693714.4128240601, 693714.4128240603, 144251.332419881], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7297200.0000, 
sim time next is 7297800.0000, 
raw observation next is [23.48333333333333, 54.16666666666667, 1.0, 2.0, 0.6541618984912589, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 728068.8285226012, 728068.8285226012, 147995.7401583294], 
processed observation next is [1.0, 0.4782608695652174, 0.7037878787878786, 0.5416666666666667, 1.0, 1.0, 0.5677023731140737, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.26965512167503747, 0.26965512167503747, 0.3609652198983644], 
reward next is 0.6390, 
noisyNet noise sample is [array([-0.48102328], dtype=float32), 1.606821]. 
=============================================
[2019-03-22 22:38:06,698] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 4.069108e-29 0.000000e+00], sum to 1.0000
[2019-03-22 22:38:06,709] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6188
[2019-03-22 22:38:06,715] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.03333333333333, 88.5, 1.0, 2.0, 0.3555883890692863, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 397541.1448824763, 397541.144882476, 119404.2769759259], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7458600.0000, 
sim time next is 7459200.0000, 
raw observation next is [19.4, 87.0, 1.0, 2.0, 0.3609300526984502, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 404458.9452599193, 404458.9452599193, 120279.062371921], 
processed observation next is [0.0, 0.34782608695652173, 0.5181818181818181, 0.87, 1.0, 1.0, 0.20116256587306272, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14979960935552566, 0.14979960935552566, 0.2933635667607829], 
reward next is 0.7066, 
noisyNet noise sample is [array([0.6406383], dtype=float32), 0.61615765]. 
=============================================
[2019-03-22 22:38:08,166] A3C_AGENT_WORKER-Thread-21 INFO:Local step 12500, global step 199651: loss 0.0159
[2019-03-22 22:38:08,169] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 12500, global step 199651: learning rate 0.0010
[2019-03-22 22:38:08,328] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.0913631e-33 0.0000000e+00], sum to 1.0000
[2019-03-22 22:38:08,341] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4000
[2019-03-22 22:38:08,349] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.9, 59.0, 1.0, 2.0, 0.5199796749313421, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 592113.7406778845, 592113.7406778845, 145432.5657201265], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7482000.0000, 
sim time next is 7482600.0000, 
raw observation next is [28.0, 58.0, 1.0, 2.0, 0.5165483996500125, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 588403.3335700224, 588403.3335700224, 144849.5180385669], 
processed observation next is [0.0, 0.6086956521739131, 0.9090909090909091, 0.58, 1.0, 1.0, 0.39568549956251564, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21792716058148975, 0.21792716058148975, 0.35329150741113874], 
reward next is 0.6467, 
noisyNet noise sample is [array([-0.3120063], dtype=float32), -0.044630025]. 
=============================================
[2019-03-22 22:38:08,649] A3C_AGENT_WORKER-Thread-3 INFO:Local step 12500, global step 199836: loss 0.0645
[2019-03-22 22:38:08,653] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 12500, global step 199836: learning rate 0.0010
[2019-03-22 22:38:08,733] A3C_AGENT_WORKER-Thread-2 INFO:Local step 12500, global step 199867: loss 0.0307
[2019-03-22 22:38:08,735] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 12500, global step 199867: learning rate 0.0010
[2019-03-22 22:38:08,789] A3C_AGENT_WORKER-Thread-14 INFO:Local step 12500, global step 199891: loss 0.0385
[2019-03-22 22:38:08,793] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 12500, global step 199891: learning rate 0.0010
[2019-03-22 22:38:08,865] A3C_AGENT_WORKER-Thread-19 INFO:Local step 12500, global step 199924: loss 0.0038
[2019-03-22 22:38:08,871] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 12500, global step 199926: learning rate 0.0010
[2019-03-22 22:38:08,956] A3C_AGENT_WORKER-Thread-16 INFO:Local step 12500, global step 199953: loss 0.0146
[2019-03-22 22:38:08,958] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 12500, global step 199954: learning rate 0.0010
[2019-03-22 22:38:09,037] A3C_AGENT_WORKER-Thread-10 INFO:Local step 12500, global step 199988: loss 0.0339
[2019-03-22 22:38:09,044] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 12500, global step 199990: learning rate 0.0010
[2019-03-22 22:38:09,072] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-22 22:38:09,072] A3C_AGENT_WORKER-Thread-11 INFO:Local step 12500, global step 200000: loss 0.0475
[2019-03-22 22:38:09,074] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 12500, global step 200000: learning rate 0.0010
[2019-03-22 22:38:09,075] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-22 22:38:09,078] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:38:09,078] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-22 22:38:09,078] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:38:09,080] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-22 22:38:09,080] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:38:09,082] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-22 22:38:09,083] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:38:09,084] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-22 22:38:09,085] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:38:09,106] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run9
[2019-03-22 22:38:09,106] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run9
[2019-03-22 22:38:09,123] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run9
[2019-03-22 22:38:09,125] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run9
[2019-03-22 22:38:09,160] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run9
[2019-03-22 22:38:27,402] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.11630003], dtype=float32), -0.20627742]
[2019-03-22 22:38:27,404] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.7, 90.0, 1.0, 2.0, 0.3910329020588126, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 441633.6080611654, 441633.6080611654, 128924.6802775176]
[2019-03-22 22:38:27,404] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 22:38:27,406] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.0745497e-33 0.0000000e+00], sampled 0.3800331889593497
[2019-03-22 22:38:34,691] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.11630003], dtype=float32), -0.20627742]
[2019-03-22 22:38:34,693] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [23.52454515, 87.12269488, 1.0, 2.0, 0.4960124467089539, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 564570.4513980435, 564570.4513980432, 146999.0892563255]
[2019-03-22 22:38:34,694] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 22:38:34,695] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.3532024e-32 3.7270190e-38], sampled 0.261447544130883
[2019-03-22 22:38:35,032] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.11630003], dtype=float32), -0.20627742]
[2019-03-22 22:38:35,035] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [25.66666666666667, 66.5, 1.0, 2.0, 0.9089119453541956, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1037360.607639513, 1037360.607639512, 201769.9195354933]
[2019-03-22 22:38:35,037] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 22:38:35,040] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 8.4784399e-32 7.8327306e-23 3.1773282e-29], sampled 0.22792537304827032
[2019-03-22 22:38:35,484] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.11630003], dtype=float32), -0.20627742]
[2019-03-22 22:38:35,485] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.0, 78.0, 1.0, 2.0, 0.4246618138523653, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 482499.4537468406, 482499.4537468406, 129611.0896374589]
[2019-03-22 22:38:35,487] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 22:38:35,491] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 4.393167e-35 0.000000e+00], sampled 0.6116225009557034
[2019-03-22 22:38:54,971] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.11630003], dtype=float32), -0.20627742]
[2019-03-22 22:38:54,972] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [26.86666666666667, 55.5, 1.0, 2.0, 0.4867511444264693, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 555127.6365237116, 555127.6365237116, 142683.2103514161]
[2019-03-22 22:38:54,975] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 22:38:54,979] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 4.935329e-32 4.593224e-37], sampled 0.8109820426046753
[2019-03-22 22:39:26,314] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.11630003], dtype=float32), -0.20627742]
[2019-03-22 22:39:26,314] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.66666666666666, 90.0, 1.0, 2.0, 0.7663534722333056, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 872366.3751490691, 872366.3751490691, 172393.6668257076]
[2019-03-22 22:39:26,315] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 22:39:26,320] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 1.0078377e-33 2.1289273e-24 3.0776196e-31], sampled 0.7341689851825044
[2019-03-22 22:39:28,172] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.11630003], dtype=float32), -0.20627742]
[2019-03-22 22:39:28,172] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [12.8, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 199493.5621724292, 199493.5621724292, 72019.39982052438]
[2019-03-22 22:39:28,173] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 22:39:28,176] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 1.523051e-37 0.000000e+00], sampled 0.9995175944325073
[2019-03-22 22:40:07,708] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.11630003], dtype=float32), -0.20627742]
[2019-03-22 22:40:07,708] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [28.2, 56.16666666666667, 1.0, 2.0, 0.5061700043625438, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 576893.0009884045, 576893.0009884045, 143291.9260216209]
[2019-03-22 22:40:07,709] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 22:40:07,712] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.1365982e-31 1.0511909e-36], sampled 0.03521835284738317
[2019-03-22 22:40:12,552] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1147 1656209757.7786 80.0000
[2019-03-22 22:40:12,808] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.1205 1706011712.0071 465.0000
[2019-03-22 22:40:12,813] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-22 22:40:12,950] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2492 1773187030.7201 173.0000
[2019-03-22 22:40:13,050] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3485 1683325900.1134 214.0000
[2019-03-22 22:40:14,065] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 200000, evaluation results [200000.0, 8512.249193409023, 1773187030.7201214, 173.0, 9061.114669779829, 1656209757.7786272, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8596.120523818729, 1706011712.007094, 465.0, 8574.348472942609, 1683325900.1133502, 214.0]
[2019-03-22 22:40:14,092] A3C_AGENT_WORKER-Thread-13 INFO:Local step 12500, global step 200016: loss 0.0434
[2019-03-22 22:40:14,095] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 12500, global step 200017: learning rate 0.0010
[2019-03-22 22:40:14,106] A3C_AGENT_WORKER-Thread-22 INFO:Local step 12500, global step 200021: loss 0.0543
[2019-03-22 22:40:14,113] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 12500, global step 200022: learning rate 0.0010
[2019-03-22 22:40:14,115] A3C_AGENT_WORKER-Thread-9 INFO:Local step 12500, global step 200024: loss 0.0752
[2019-03-22 22:40:14,120] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 12500, global step 200024: learning rate 0.0010
[2019-03-22 22:40:14,125] A3C_AGENT_WORKER-Thread-15 INFO:Local step 12500, global step 200028: loss 0.0027
[2019-03-22 22:40:14,128] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 12500, global step 200028: learning rate 0.0010
[2019-03-22 22:40:14,136] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 2.3732832e-35 1.8173997e-33 7.0110706e-38], sum to 1.0000
[2019-03-22 22:40:14,147] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9173
[2019-03-22 22:40:14,155] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.2, 70.66666666666667, 1.0, 2.0, 0.4525117243922129, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 516082.6810059867, 516082.6810059867, 134589.2335200417], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7507200.0000, 
sim time next is 7507800.0000, 
raw observation next is [24.1, 71.5, 1.0, 2.0, 0.4540598878160192, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 517879.6437557714, 517879.6437557714, 134819.2941018456], 
processed observation next is [0.0, 0.9130434782608695, 0.7318181818181819, 0.715, 1.0, 1.0, 0.317574859770024, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1918072754651005, 0.1918072754651005, 0.3288275465898673], 
reward next is 0.6712, 
noisyNet noise sample is [array([0.06850356], dtype=float32), -1.2818223]. 
=============================================
[2019-03-22 22:40:14,410] A3C_AGENT_WORKER-Thread-18 INFO:Local step 12500, global step 200137: loss 0.0282
[2019-03-22 22:40:14,413] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 12500, global step 200138: learning rate 0.0010
[2019-03-22 22:40:14,424] A3C_AGENT_WORKER-Thread-12 INFO:Local step 12500, global step 200142: loss 0.0660
[2019-03-22 22:40:14,428] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 12500, global step 200142: learning rate 0.0010
[2019-03-22 22:40:14,476] A3C_AGENT_WORKER-Thread-17 INFO:Local step 12500, global step 200161: loss 0.1233
[2019-03-22 22:40:14,479] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 12500, global step 200162: learning rate 0.0010
[2019-03-22 22:40:14,549] A3C_AGENT_WORKER-Thread-20 INFO:Local step 12500, global step 200188: loss 0.0897
[2019-03-22 22:40:14,553] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 12500, global step 200190: learning rate 0.0010
[2019-03-22 22:40:20,741] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 3.808671e-30 8.015494e-35], sum to 1.0000
[2019-03-22 22:40:20,749] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4804
[2019-03-22 22:40:20,760] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 94.0, 1.0, 2.0, 0.4260671260385807, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 483981.3286240124, 483981.3286240124, 129656.836226231], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7593600.0000, 
sim time next is 7594200.0000, 
raw observation next is [20.0, 94.5, 1.0, 2.0, 0.4296281300568536, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 488201.9236421685, 488201.9236421685, 130147.7679519947], 
processed observation next is [0.0, 0.9130434782608695, 0.5454545454545454, 0.945, 1.0, 1.0, 0.2870351625710669, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18081552727487724, 0.18081552727487724, 0.3174335803707188], 
reward next is 0.6826, 
noisyNet noise sample is [array([0.39952362], dtype=float32), 0.639317]. 
=============================================
[2019-03-22 22:40:27,086] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.5197878e-31 0.0000000e+00], sum to 1.0000
[2019-03-22 22:40:27,103] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6824
[2019-03-22 22:40:27,110] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 93.0, 1.0, 2.0, 0.4407139699946828, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 501734.1074849449, 501734.1074849449, 132108.725417749], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7689600.0000, 
sim time next is 7690200.0000, 
raw observation next is [20.5, 92.5, 1.0, 2.0, 0.4368992372754404, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 497232.2300953661, 497232.2300953664, 131558.7512803515], 
processed observation next is [1.0, 0.0, 0.5681818181818182, 0.925, 1.0, 1.0, 0.29612404659430047, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18416008522050595, 0.1841600852205061, 0.3208750031228086], 
reward next is 0.6791, 
noisyNet noise sample is [array([0.97455084], dtype=float32), 0.0043105907]. 
=============================================
[2019-03-22 22:40:31,443] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.00000e+00 1.00000e+00 0.00000e+00 3.00391e-37 0.00000e+00], sum to 1.0000
[2019-03-22 22:40:31,459] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3822
[2019-03-22 22:40:31,470] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.6, 49.0, 1.0, 2.0, 0.3013042007309557, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 327172.3318229844, 327172.3318229844, 95682.64743009555], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7754400.0000, 
sim time next is 7755000.0000, 
raw observation next is [21.23333333333334, 50.16666666666667, 1.0, 2.0, 0.3007723331743212, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 326594.6074472924, 326594.6074472927, 94383.26778052784], 
processed observation next is [1.0, 0.782608695652174, 0.6015151515151519, 0.5016666666666667, 1.0, 1.0, 0.12596541646790152, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12096096572121942, 0.12096096572121952, 0.23020309214762888], 
reward next is 0.7698, 
noisyNet noise sample is [array([0.12507884], dtype=float32), 1.9256876]. 
=============================================
[2019-03-22 22:40:31,487] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[71.63384 ]
 [71.638084]
 [71.678246]
 [71.72111 ]
 [71.68263 ]], R is [[71.70630646]
 [71.755867  ]
 [71.80718231]
 [71.86034393]
 [71.9146347 ]].
[2019-03-22 22:40:31,966] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 22:40:31,980] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2319
[2019-03-22 22:40:31,988] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 57.0, 1.0, 2.0, 0.2634547819740115, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 286061.3065405964, 286061.3065405966, 82893.75139396286], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7762200.0000, 
sim time next is 7762800.0000, 
raw observation next is [18.8, 57.00000000000001, 1.0, 2.0, 0.2637373726887939, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 286368.2361327061, 286368.2361327064, 82922.64395202066], 
processed observation next is [1.0, 0.8695652173913043, 0.49090909090909096, 0.5700000000000001, 1.0, 1.0, 0.07967171586099234, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10606230967878004, 0.10606230967878015, 0.20225035110248943], 
reward next is 0.7977, 
noisyNet noise sample is [array([0.33339852], dtype=float32), 0.7715253]. 
=============================================
[2019-03-22 22:40:33,483] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 2.417211e-37 0.000000e+00], sum to 1.0000
[2019-03-22 22:40:33,494] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2063
[2019-03-22 22:40:33,497] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.1, 71.5, 1.0, 2.0, 0.2272084861113551, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 246694.8076583036, 246694.8076583033, 76584.23276568142], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7776600.0000, 
sim time next is 7777200.0000, 
raw observation next is [16.1, 71.0, 1.0, 2.0, 0.2264193013020804, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 245837.722608995, 245837.7226089953, 76315.42309985054], 
processed observation next is [1.0, 0.0, 0.3681818181818182, 0.71, 1.0, 1.0, 0.03302412662760049, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09105100837370185, 0.09105100837370196, 0.18613517829231838], 
reward next is 0.8139, 
noisyNet noise sample is [array([0.25229442], dtype=float32), 1.7041545]. 
=============================================
[2019-03-22 22:40:33,707] A3C_AGENT_WORKER-Thread-21 INFO:Local step 13000, global step 207669: loss 0.4762
[2019-03-22 22:40:33,712] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 13000, global step 207669: learning rate 0.0010
[2019-03-22 22:40:34,187] A3C_AGENT_WORKER-Thread-3 INFO:Local step 13000, global step 207857: loss 0.1124
[2019-03-22 22:40:34,190] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 13000, global step 207857: learning rate 0.0010
[2019-03-22 22:40:34,220] A3C_AGENT_WORKER-Thread-14 INFO:Local step 13000, global step 207869: loss 0.1664
[2019-03-22 22:40:34,223] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 13000, global step 207870: learning rate 0.0010
[2019-03-22 22:40:34,223] A3C_AGENT_WORKER-Thread-2 INFO:Local step 13000, global step 207870: loss 0.1206
[2019-03-22 22:40:34,230] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 13000, global step 207870: learning rate 0.0010
[2019-03-22 22:40:34,321] A3C_AGENT_WORKER-Thread-19 INFO:Local step 13000, global step 207907: loss 0.1997
[2019-03-22 22:40:34,323] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 13000, global step 207908: learning rate 0.0010
[2019-03-22 22:40:34,414] A3C_AGENT_WORKER-Thread-11 INFO:Local step 13000, global step 207946: loss 0.2152
[2019-03-22 22:40:34,420] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 13000, global step 207946: learning rate 0.0010
[2019-03-22 22:40:34,459] A3C_AGENT_WORKER-Thread-16 INFO:Local step 13000, global step 207959: loss 0.2656
[2019-03-22 22:40:34,466] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 13000, global step 207959: learning rate 0.0010
[2019-03-22 22:40:34,499] A3C_AGENT_WORKER-Thread-9 INFO:Local step 13000, global step 207973: loss 0.3333
[2019-03-22 22:40:34,506] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 13000, global step 207976: learning rate 0.0010
[2019-03-22 22:40:34,557] A3C_AGENT_WORKER-Thread-13 INFO:Local step 13000, global step 207998: loss 0.2850
[2019-03-22 22:40:34,562] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 13000, global step 207999: learning rate 0.0010
[2019-03-22 22:40:34,613] A3C_AGENT_WORKER-Thread-22 INFO:Local step 13000, global step 208019: loss 0.2310
[2019-03-22 22:40:34,626] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 13000, global step 208021: learning rate 0.0010
[2019-03-22 22:40:34,641] A3C_AGENT_WORKER-Thread-10 INFO:Local step 13000, global step 208027: loss 0.3094
[2019-03-22 22:40:34,645] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 13000, global step 208027: learning rate 0.0010
[2019-03-22 22:40:34,734] A3C_AGENT_WORKER-Thread-15 INFO:Local step 13000, global step 208064: loss 0.2351
[2019-03-22 22:40:34,736] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 13000, global step 208064: learning rate 0.0010
[2019-03-22 22:40:34,891] A3C_AGENT_WORKER-Thread-18 INFO:Local step 13000, global step 208123: loss 0.2219
[2019-03-22 22:40:34,895] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 13000, global step 208124: learning rate 0.0010
[2019-03-22 22:40:34,960] A3C_AGENT_WORKER-Thread-12 INFO:Local step 13000, global step 208150: loss 0.2134
[2019-03-22 22:40:34,964] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 13000, global step 208150: learning rate 0.0010
[2019-03-22 22:40:35,003] A3C_AGENT_WORKER-Thread-17 INFO:Local step 13000, global step 208169: loss 0.1923
[2019-03-22 22:40:35,006] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 13000, global step 208170: learning rate 0.0010
[2019-03-22 22:40:35,074] A3C_AGENT_WORKER-Thread-20 INFO:Local step 13000, global step 208196: loss 0.2201
[2019-03-22 22:40:35,077] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 13000, global step 208196: learning rate 0.0010
[2019-03-22 22:40:44,320] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.0177784e-33 1.0000000e+00 2.8266493e-32 6.9192096e-11 3.9842544e-24], sum to 1.0000
[2019-03-22 22:40:44,330] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7222
[2019-03-22 22:40:44,336] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.2, 80.0, 1.0, 2.0, 0.3433032002095644, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 379559.5120849389, 379559.5120849389, 116619.7040335433], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7946400.0000, 
sim time next is 7947000.0000, 
raw observation next is [19.1, 79.5, 1.0, 2.0, 0.3364177068271973, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 370945.6715920239, 370945.6715920242, 115708.5361232433], 
processed observation next is [1.0, 1.0, 0.5045454545454546, 0.795, 1.0, 1.0, 0.1705221335339966, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13738728577482368, 0.1373872857748238, 0.28221594176400805], 
reward next is 0.7178, 
noisyNet noise sample is [array([-0.6049031], dtype=float32), -0.78362817]. 
=============================================
[2019-03-22 22:40:44,352] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[65.2368  ]
 [65.28678 ]
 [65.33013 ]
 [65.360756]
 [65.40778 ]], R is [[65.25011444]
 [65.31317139]
 [65.37313843]
 [65.42933655]
 [65.48014832]].
[2019-03-22 22:40:44,898] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 22:40:44,899] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:40:44,900] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run2
[2019-03-22 22:40:45,331] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 22:40:45,332] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:40:45,334] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run2
[2019-03-22 22:40:45,389] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 22:40:45,389] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:40:45,391] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run2
[2019-03-22 22:40:45,437] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 22:40:45,437] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:40:45,439] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run2
[2019-03-22 22:40:45,462] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 22:40:45,462] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:40:45,464] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run2
[2019-03-22 22:40:45,492] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 22:40:45,492] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:40:45,494] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run2
[2019-03-22 22:40:45,509] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 22:40:45,509] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:40:45,512] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run2
[2019-03-22 22:40:45,537] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 22:40:45,537] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:40:45,539] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run2
[2019-03-22 22:40:45,588] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 22:40:45,589] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:40:45,590] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run2
[2019-03-22 22:40:45,607] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 22:40:45,608] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 22:40:45,608] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:40:45,608] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:40:45,610] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run2
[2019-03-22 22:40:45,611] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run2
[2019-03-22 22:40:45,643] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 22:40:45,645] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:40:45,646] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run2
[2019-03-22 22:40:45,662] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 22:40:45,663] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:40:45,664] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run2
[2019-03-22 22:40:45,686] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 22:40:45,686] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:40:45,688] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run2
[2019-03-22 22:40:45,710] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 22:40:45,710] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:40:45,712] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run2
[2019-03-22 22:40:45,731] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 22:40:45,732] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:40:45,734] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run2
[2019-03-22 22:40:47,858] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.1842891e-24 0.0000000e+00], sum to 1.0000
[2019-03-22 22:40:47,865] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4491
[2019-03-22 22:40:47,870] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.16666666666667, 99.00000000000001, 1.0, 2.0, 0.3982470326265929, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 441226.6053496612, 441226.6053496615, 121346.4317065424], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 15000.0000, 
sim time next is 15600.0000, 
raw observation next is [17.33333333333334, 98.0, 1.0, 2.0, 0.3831273535372345, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 424926.6573616679, 424926.6573616679, 120271.6975321613], 
processed observation next is [1.0, 0.17391304347826086, 0.42424242424242453, 0.98, 1.0, 1.0, 0.22890919192154308, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1573802434672844, 0.1573802434672844, 0.29334560373697877], 
reward next is 0.7067, 
noisyNet noise sample is [array([-0.0566441], dtype=float32), -0.8964049]. 
=============================================
[2019-03-22 22:40:48,258] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.1804877e-25 2.4905650e-38], sum to 1.0000
[2019-03-22 22:40:48,270] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5580
[2019-03-22 22:40:48,282] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.2, 92.0, 1.0, 2.0, 0.3388304157663543, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 370374.5747171245, 370374.5747171245, 114710.5160800163], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 12000.0000, 
sim time next is 12600.0000, 
raw observation next is [17.15, 94.0, 1.0, 2.0, 0.3412905856755625, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 374197.0404064208, 374197.0404064211, 115291.5377216183], 
processed observation next is [1.0, 0.13043478260869565, 0.41590909090909084, 0.94, 1.0, 1.0, 0.17661323209445307, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13859149644682253, 0.13859149644682264, 0.28119887249175196], 
reward next is 0.7188, 
noisyNet noise sample is [array([-0.8586448], dtype=float32), -0.4597604]. 
=============================================
[2019-03-22 22:40:50,604] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.6940470e-37 9.7022969e-01 3.1253111e-33 2.9770283e-02 8.2201263e-27], sum to 1.0000
[2019-03-22 22:40:50,616] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0776
[2019-03-22 22:40:50,622] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 78.0, 1.0, 2.0, 0.7976717250269119, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 900781.1432157028, 900781.1432157028, 172018.5576469767], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 48000.0000, 
sim time next is 48600.0000, 
raw observation next is [21.0, 78.0, 1.0, 2.0, 0.8597977885455421, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 971353.5013658251, 971353.5013658251, 181422.0536080012], 
processed observation next is [1.0, 0.5652173913043478, 0.5909090909090909, 0.78, 1.0, 1.0, 0.8247472356819276, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3597605560614167, 0.3597605560614167, 0.4424928136780517], 
reward next is 0.5575, 
noisyNet noise sample is [array([-0.9917693], dtype=float32), 0.357661]. 
=============================================
[2019-03-22 22:40:57,332] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.2822851e-33 1.0000000e+00 1.1139487e-28 2.2733152e-08 3.4484432e-22], sum to 1.0000
[2019-03-22 22:40:57,348] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5576
[2019-03-22 22:40:57,363] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 40.5, 1.0, 2.0, 0.7292823569229089, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 792272.808342057, 792272.8083420567, 140042.3745130112], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 145800.0000, 
sim time next is 146400.0000, 
raw observation next is [22.33333333333334, 41.33333333333333, 1.0, 2.0, 0.721375858075303, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 783676.4723637482, 783676.4723637486, 139024.9072993421], 
processed observation next is [1.0, 0.6956521739130435, 0.6515151515151518, 0.4133333333333333, 1.0, 1.0, 0.6517198225941286, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.29025054531990674, 0.2902505453199069, 0.33908513975449295], 
reward next is 0.6609, 
noisyNet noise sample is [array([-0.14192739], dtype=float32), -1.0945746]. 
=============================================
[2019-03-22 22:41:08,397] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 4.9496087e-29 4.7667505e-22 4.1502092e-26], sum to 1.0000
[2019-03-22 22:41:08,412] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4629
[2019-03-22 22:41:08,421] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 47.0, 1.0, 2.0, 0.2544651459166911, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 276297.5152451047, 276297.5152451047, 84340.84794374097], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 307200.0000, 
sim time next is 307800.0000, 
raw observation next is [21.0, 46.0, 1.0, 2.0, 0.2546378112402543, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 276485.0480412148, 276485.0480412148, 83481.32024831037], 
processed observation next is [0.0, 0.5652173913043478, 0.5909090909090909, 0.46, 1.0, 1.0, 0.06829726405031787, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10240186964489438, 0.10240186964489438, 0.20361297621539115], 
reward next is 0.7964, 
noisyNet noise sample is [array([-0.2056741], dtype=float32), 0.3030778]. 
=============================================
[2019-03-22 22:41:11,414] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.5928609e-35 1.0000000e+00 5.3259680e-33 3.6689990e-23 2.0094468e-25], sum to 1.0000
[2019-03-22 22:41:11,424] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7188
[2019-03-22 22:41:11,428] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.33333333333333, 73.0, 1.0, 2.0, 0.4013425615439996, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 435848.0570052839, 435848.0570052839, 87132.82908379873], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 355200.0000, 
sim time next is 355800.0000, 
raw observation next is [12.16666666666667, 74.5, 1.0, 2.0, 0.3989642651722201, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 433264.1353941091, 433264.1353941091, 86884.34481548284], 
processed observation next is [1.0, 0.08695652173913043, 0.18939393939393953, 0.745, 1.0, 1.0, 0.24870533146527513, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1604681982941145, 0.1604681982941145, 0.211913036135324], 
reward next is 0.7881, 
noisyNet noise sample is [array([1.289538], dtype=float32), 0.6101239]. 
=============================================
[2019-03-22 22:41:12,156] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.8702832e-32 1.0000000e+00 4.5955304e-25 2.5913343e-12 2.2075861e-17], sum to 1.0000
[2019-03-22 22:41:12,165] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5656
[2019-03-22 22:41:12,170] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.0, 76.0, 1.0, 2.0, 0.4036793678666473, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 438386.9147525621, 438386.9147525624, 87338.52293764117], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 366000.0000, 
sim time next is 366600.0000, 
raw observation next is [12.0, 76.0, 1.0, 2.0, 0.4045741202479435, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 439359.0352040612, 439359.0352040612, 87422.60501869289], 
processed observation next is [1.0, 0.21739130434782608, 0.18181818181818182, 0.76, 1.0, 1.0, 0.2557176503099293, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16272556859409673, 0.16272556859409673, 0.21322586589925097], 
reward next is 0.7868, 
noisyNet noise sample is [array([-0.35558113], dtype=float32), -1.4617553]. 
=============================================
[2019-03-22 22:41:12,987] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 3.5157452e-38 1.2595659e-21 3.5875283e-27], sum to 1.0000
[2019-03-22 22:41:12,995] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8363
[2019-03-22 22:41:12,999] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.33333333333333, 52.66666666666667, 1.0, 2.0, 0.3134383769773016, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 340352.8849060478, 340352.8849060478, 84373.13666761125], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 385800.0000, 
sim time next is 386400.0000, 
raw observation next is [18.66666666666667, 53.33333333333334, 1.0, 2.0, 0.3273420636274033, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 355455.9793134736, 355455.9793134733, 87035.19037939725], 
processed observation next is [1.0, 0.4782608695652174, 0.4848484848484851, 0.5333333333333334, 1.0, 1.0, 0.15917757953425413, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13165036270869393, 0.13165036270869382, 0.21228095214487133], 
reward next is 0.7877, 
noisyNet noise sample is [array([0.10069977], dtype=float32), 0.5194127]. 
=============================================
[2019-03-22 22:41:14,958] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.51023841e-34 1.00000000e+00 1.07813121e-31 1.09757005e-13
 5.96834278e-21], sum to 1.0000
[2019-03-22 22:41:14,965] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6722
[2019-03-22 22:41:14,977] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 100.0, 1.0, 2.0, 0.3681674054140427, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 399805.8486275278, 399805.8486275278, 96160.51015611415], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 484800.0000, 
sim time next is 485400.0000, 
raw observation next is [14.0, 100.0, 1.0, 2.0, 0.3655832532680859, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 396998.4819075973, 396998.4819075976, 95814.59698060619], 
processed observation next is [1.0, 0.6086956521739131, 0.2727272727272727, 1.0, 1.0, 1.0, 0.20697906658510734, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1470364747805916, 0.1470364747805917, 0.23369413897708827], 
reward next is 0.7663, 
noisyNet noise sample is [array([-0.19612314], dtype=float32), -1.2156885]. 
=============================================
[2019-03-22 22:41:19,860] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-22 22:41:19,868] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-22 22:41:19,871] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:41:19,872] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-22 22:41:19,874] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-22 22:41:19,875] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:41:19,875] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:41:19,878] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-22 22:41:19,877] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-22 22:41:19,879] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:41:19,880] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:41:19,885] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run10
[2019-03-22 22:41:19,904] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run10
[2019-03-22 22:41:19,906] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run10
[2019-03-22 22:41:19,922] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run10
[2019-03-22 22:41:19,943] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run10
[2019-03-22 22:42:19,243] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.3174083], dtype=float32), -0.0988662]
[2019-03-22 22:42:19,244] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.53313127, 85.25627339000002, 1.0, 2.0, 0.4149905183623588, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 471855.7766409019, 471855.7766409019, 133314.4343687252]
[2019-03-22 22:42:19,245] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 22:42:19,249] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 5.5562635e-26 5.6363353e-35], sampled 0.6700521004426954
[2019-03-22 22:42:40,310] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.3174083], dtype=float32), -0.0988662]
[2019-03-22 22:42:40,310] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [26.66666666666667, 65.66666666666667, 1.0, 2.0, 0.5218380826145657, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 594123.4860657229, 594123.4860657229, 145742.1117716992]
[2019-03-22 22:42:40,311] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 22:42:40,315] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 6.3930593e-38 9.2920533e-24 2.4535399e-33], sampled 0.6920078581791245
[2019-03-22 22:43:23,461] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8511.2006 1773125597.9331 173.0000
[2019-03-22 22:43:23,563] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-22 22:43:23,566] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.6114 1705915178.0512 463.0000
[2019-03-22 22:43:23,670] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1147 1656209757.7786 80.0000
[2019-03-22 22:43:23,713] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8576.5099 1683038559.7237 211.0000
[2019-03-22 22:43:24,728] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 225000, evaluation results [225000.0, 8511.200619874178, 1773125597.933107, 173.0, 9061.114669779829, 1656209757.7786272, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.61139901066, 1705915178.0512094, 463.0, 8576.509925841292, 1683038559.723658, 211.0]
[2019-03-22 22:43:25,220] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.2089893e-38 9.8660477e-25 9.7637949e-33], sum to 1.0000
[2019-03-22 22:43:25,229] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7130
[2019-03-22 22:43:25,236] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.83333333333333, 95.0, 1.0, 2.0, 0.2174339369115658, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 236079.3778573271, 236079.3778573269, 76652.31302033232], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 533400.0000, 
sim time next is 534000.0000, 
raw observation next is [13.66666666666667, 96.0, 1.0, 2.0, 0.2124579870288766, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 230675.4481465858, 230675.4481465855, 75963.14582182984], 
processed observation next is [1.0, 0.17391304347826086, 0.25757575757575774, 0.96, 1.0, 1.0, 0.015572483786095749, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08543535116540216, 0.08543535116540203, 0.18527596541909716], 
reward next is 0.8147, 
noisyNet noise sample is [array([-0.12808278], dtype=float32), 1.2332531]. 
=============================================
[2019-03-22 22:43:25,245] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[71.66761 ]
 [71.70558 ]
 [71.742325]
 [71.79266 ]
 [71.84027 ]], R is [[71.74243164]
 [71.83805084]
 [71.93331909]
 [72.02754211]
 [72.12069702]].
[2019-03-22 22:43:31,649] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.0017138e-35 1.0000000e+00 1.8488513e-27 1.4280965e-11 7.3494581e-27], sum to 1.0000
[2019-03-22 22:43:31,663] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4775
[2019-03-22 22:43:31,668] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.83333333333334, 51.16666666666667, 1.0, 2.0, 0.8761942696788816, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 985407.5946260479, 985407.5946260479, 181557.6298455923], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 658200.0000, 
sim time next is 658800.0000, 
raw observation next is [25.0, 50.0, 1.0, 2.0, 0.8691320172362696, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 976901.4015197947, 976901.4015197947, 180218.2552593128], 
processed observation next is [1.0, 0.6521739130434783, 0.7727272727272727, 0.5, 1.0, 1.0, 0.836415021545337, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3618153338962203, 0.3618153338962203, 0.4395567201446654], 
reward next is 0.5604, 
noisyNet noise sample is [array([0.76830715], dtype=float32), -0.95537275]. 
=============================================
[2019-03-22 22:43:34,727] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 2.254453e-24 6.116350e-32], sum to 1.0000
[2019-03-22 22:43:34,746] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0521
[2019-03-22 22:43:34,755] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 54.00000000000001, 1.0, 2.0, 0.3570614532631875, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 398743.653440301, 398743.6534403013, 119323.6220791017], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 674400.0000, 
sim time next is 675000.0000, 
raw observation next is [24.0, 54.0, 1.0, 2.0, 0.3603318432004838, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 402399.7669560779, 402399.7669560777, 119591.2852842359], 
processed observation next is [1.0, 0.8260869565217391, 0.7272727272727273, 0.54, 1.0, 1.0, 0.2004148040006047, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1490369507244733, 0.14903695072447323, 0.29168606166886807], 
reward next is 0.7083, 
noisyNet noise sample is [array([0.46590644], dtype=float32), -0.90665346]. 
=============================================
[2019-03-22 22:43:34,766] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[78.073555]
 [78.111855]
 [78.0827  ]
 [78.1363  ]
 [78.26779 ]], R is [[77.92948914]
 [77.85916138]
 [77.78951263]
 [77.7202301 ]
 [77.65103149]].
[2019-03-22 22:43:36,536] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 6.3166193e-25 4.8244237e-17 1.0973086e-24], sum to 1.0000
[2019-03-22 22:43:36,546] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8919
[2019-03-22 22:43:36,560] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 54.5, 1.0, 2.0, 0.4207321994038681, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 470742.1919842254, 470742.1919842256, 125130.4178360193], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 651000.0000, 
sim time next is 651600.0000, 
raw observation next is [24.0, 54.0, 1.0, 2.0, 0.4696473163292594, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 525076.7476214888, 525076.7476214888, 129507.3613147756], 
processed observation next is [1.0, 0.5652173913043478, 0.7272727272727273, 0.54, 1.0, 1.0, 0.33705914541157417, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1944728694894403, 0.1944728694894403, 0.3158716129628673], 
reward next is 0.6841, 
noisyNet noise sample is [array([0.7301281], dtype=float32), 0.15795068]. 
=============================================
[2019-03-22 22:43:51,718] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 6.4488335e-30 5.7409909e-36], sum to 1.0000
[2019-03-22 22:43:51,726] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1139
[2019-03-22 22:43:51,733] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.5, 91.0, 1.0, 2.0, 0.397842992404662, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 448927.8060381822, 448927.8060381825, 124986.4763372672], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 869400.0000, 
sim time next is 870000.0000, 
raw observation next is [19.66666666666666, 90.0, 1.0, 2.0, 0.398400083759033, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 449757.1277672657, 449757.1277672654, 125149.6602856817], 
processed observation next is [0.0, 0.043478260869565216, 0.53030303030303, 0.9, 1.0, 1.0, 0.24800010469879125, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16657671398787618, 0.16657671398787607, 0.30524307386751637], 
reward next is 0.6948, 
noisyNet noise sample is [array([2.2121782], dtype=float32), 0.8082078]. 
=============================================
[2019-03-22 22:43:51,758] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[70.578606]
 [70.651405]
 [70.65166 ]
 [70.674355]
 [70.64516 ]], R is [[70.49539185]
 [70.48558807]
 [70.47632599]
 [70.4675827 ]
 [70.45875549]].
[2019-03-22 22:43:54,526] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.3372638e-28 1.8188623e-34], sum to 1.0000
[2019-03-22 22:43:54,539] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0541
[2019-03-22 22:43:54,548] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 78.0, 1.0, 2.0, 0.4207531146341484, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 477854.9397061106, 477854.9397061106, 129067.7339261814], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 922800.0000, 
sim time next is 923400.0000, 
raw observation next is [22.0, 78.0, 1.0, 2.0, 0.4205261525713064, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 477596.632462753, 477596.632462753, 129045.3115916112], 
processed observation next is [0.0, 0.6956521739130435, 0.6363636363636364, 0.78, 1.0, 1.0, 0.27565769071413293, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17688764165287146, 0.17688764165287146, 0.3147446624185639], 
reward next is 0.6853, 
noisyNet noise sample is [array([-0.1599008], dtype=float32), -0.6253754]. 
=============================================
[2019-03-22 22:44:01,788] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.8911365e-27 6.8367774e-32], sum to 1.0000
[2019-03-22 22:44:01,794] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0863
[2019-03-22 22:44:01,803] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 94.0, 1.0, 2.0, 0.2007832028598781, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 217996.7552727728, 217996.7552727731, 72219.32742409389], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1029600.0000, 
sim time next is 1030200.0000, 
raw observation next is [13.0, 94.00000000000001, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 214758.466735268, 214758.4667352683, 71717.11296587366], 
processed observation next is [1.0, 0.9565217391304348, 0.22727272727272727, 0.9400000000000002, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07954017286491408, 0.07954017286491419, 0.17491978772164307], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2563788], dtype=float32), 1.500507]. 
=============================================
[2019-03-22 22:44:04,234] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.3742833e-37 4.7274138e-24 2.4416655e-24], sum to 1.0000
[2019-03-22 22:44:04,248] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1144
[2019-03-22 22:44:04,254] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.83333333333333, 89.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 204860.326698278, 204860.3266982783, 70792.40557364283], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1061400.0000, 
sim time next is 1062000.0000, 
raw observation next is [14.0, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 206347.7515168814, 206347.7515168817, 71223.34684343611], 
processed observation next is [1.0, 0.30434782608695654, 0.2727272727272727, 0.88, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07642509315440052, 0.07642509315440063, 0.17371548010594173], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.06499957], dtype=float32), -0.28278914]. 
=============================================
[2019-03-22 22:44:04,288] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[57.03105 ]
 [57.052204]
 [57.11521 ]
 [57.128967]
 [57.018417]], R is [[56.48512268]
 [55.92027283]
 [55.36106873]
 [54.80745697]
 [54.25938416]].
[2019-03-22 22:44:15,044] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.0547980e-32 2.3490285e-34], sum to 1.0000
[2019-03-22 22:44:15,054] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8085
[2019-03-22 22:44:15,058] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 97.0, 1.0, 2.0, 0.3749921202029073, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 419469.2839158336, 419469.2839158339, 121110.6124046775], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1290600.0000, 
sim time next is 1291200.0000, 
raw observation next is [18.0, 96.0, 1.0, 2.0, 0.3725725530435011, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 416158.528658566, 416158.5286585663, 120637.4910260988], 
processed observation next is [1.0, 0.9565217391304348, 0.45454545454545453, 0.96, 1.0, 1.0, 0.21571569130437637, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1541327883920615, 0.1541327883920616, 0.29423778299048486], 
reward next is 0.7058, 
noisyNet noise sample is [array([0.6991235], dtype=float32), 1.6204447]. 
=============================================
[2019-03-22 22:44:18,261] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.5875886e-36 1.5807058e-28 3.4970261e-34], sum to 1.0000
[2019-03-22 22:44:18,269] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0186
[2019-03-22 22:44:18,277] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 62.0, 1.0, 2.0, 0.4881269404630141, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 556416.7832407503, 556416.7832407501, 141059.6510149435], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1273200.0000, 
sim time next is 1273800.0000, 
raw observation next is [27.0, 62.0, 1.0, 2.0, 0.4918959455501623, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 560715.0427291199, 560715.0427291199, 141497.9863878386], 
processed observation next is [1.0, 0.7391304347826086, 0.8636363636363636, 0.62, 1.0, 1.0, 0.36486993193770284, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20767223804782217, 0.20767223804782217, 0.34511703997033805], 
reward next is 0.6549, 
noisyNet noise sample is [array([0.31157005], dtype=float32), -0.9605341]. 
=============================================
[2019-03-22 22:44:25,925] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.1949625e-32 5.1155843e-34], sum to 1.0000
[2019-03-22 22:44:25,938] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7517
[2019-03-22 22:44:25,946] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4900237159042586, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 559093.2280906494, 559093.2280906494, 140339.440657704], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1387800.0000, 
sim time next is 1388400.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.4903943248721098, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 559516.2396494407, 559516.2396494405, 140382.1529747561], 
processed observation next is [0.0, 0.043478260869565216, 0.5909090909090909, 1.0, 1.0, 1.0, 0.36299290609013724, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20722823690720027, 0.2072282369072002, 0.34239549506038075], 
reward next is 0.6576, 
noisyNet noise sample is [array([0.9513045], dtype=float32), 1.2628461]. 
=============================================
[2019-03-22 22:44:28,326] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.5522878e-35 2.2162748e-34], sum to 1.0000
[2019-03-22 22:44:28,338] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9184
[2019-03-22 22:44:28,345] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.83333333333333, 84.0, 1.0, 2.0, 0.5163759435443515, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 587938.3514546127, 587938.3514546123, 145049.4242709595], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1421400.0000, 
sim time next is 1422000.0000, 
raw observation next is [24.0, 83.0, 1.0, 2.0, 0.5168726633754579, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 588438.3445232944, 588438.3445232946, 145159.603319414], 
processed observation next is [0.0, 0.4782608695652174, 0.7272727272727273, 0.83, 1.0, 1.0, 0.3960908292193223, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21794012760122014, 0.21794012760122022, 0.3540478129741805], 
reward next is 0.6460, 
noisyNet noise sample is [array([1.4253383], dtype=float32), 0.80591476]. 
=============================================
[2019-03-22 22:44:28,358] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[63.489418]
 [63.49819 ]
 [63.50503 ]
 [63.511326]
 [63.51853 ]], R is [[63.5059433 ]
 [63.5171051 ]
 [63.52830505]
 [63.539505  ]
 [63.55092621]].
[2019-03-22 22:44:28,525] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-22 22:44:28,529] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-22 22:44:28,531] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:44:28,533] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-22 22:44:28,535] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-22 22:44:28,534] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-22 22:44:28,538] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-22 22:44:28,537] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:44:28,539] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:44:28,542] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:44:28,540] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:44:28,557] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run11
[2019-03-22 22:44:28,574] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run11
[2019-03-22 22:44:28,575] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run11
[2019-03-22 22:44:28,612] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run11
[2019-03-22 22:44:28,612] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run11
[2019-03-22 22:45:08,991] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.09133355], dtype=float32), -0.0954981]
[2019-03-22 22:45:08,992] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [28.31666666666667, 62.16666666666666, 1.0, 2.0, 0.5703485617287087, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9108637804897056, 7.010072958777482, 6.9112, 95.55300057982711, 1192114.221173821, 1152434.268046766, 270443.0827368022]
[2019-03-22 22:45:08,995] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 22:45:08,997] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 9.2151710e-24 4.8854395e-35], sampled 0.4710421385047273
[2019-03-22 22:45:08,999] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1192114.221173821 W.
[2019-03-22 22:45:20,492] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.09133355], dtype=float32), -0.0954981]
[2019-03-22 22:45:20,492] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [14.26398828166667, 90.01861517333334, 1.0, 2.0, 0.2480237495429999, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 269287.3105564056, 269287.3105564052, 84681.72580169281]
[2019-03-22 22:45:20,492] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 22:45:20,494] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.7577996230002445
[2019-03-22 22:45:45,034] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.09133355], dtype=float32), -0.0954981]
[2019-03-22 22:45:45,037] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [25.32034728666667, 60.11321990833333, 1.0, 2.0, 0.4281072661836893, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 486848.4060613294, 486848.4060613294, 134670.002006326]
[2019-03-22 22:45:45,037] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 22:45:45,040] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.0599564e-37 0.0000000e+00], sampled 0.17852957898156752
[2019-03-22 22:46:24,392] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.09133355], dtype=float32), -0.0954981]
[2019-03-22 22:46:24,394] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.510572665, 84.52825591000001, 1.0, 2.0, 0.3514590130844674, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 388436.6489448725, 388436.6489448722, 121509.119777716]
[2019-03-22 22:46:24,395] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 22:46:24,400] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.7917328936711516
[2019-03-22 22:46:32,416] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2492 1773187030.7201 173.0000
[2019-03-22 22:46:32,506] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-22 22:46:32,576] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1147 1656209757.7786 80.0000
[2019-03-22 22:46:32,727] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9309 1705967916.6745 465.0000
[2019-03-22 22:46:32,865] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-22 22:46:33,879] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 250000, evaluation results [250000.0, 8512.249193409023, 1773187030.7201214, 173.0, 9061.114669779829, 1656209757.7786272, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8596.930884973775, 1705967916.6744611, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-22 22:46:38,721] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 3.6469098e-38 7.6442375e-35 5.2204618e-34], sum to 1.0000
[2019-03-22 22:46:38,730] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8432
[2019-03-22 22:46:38,738] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 100.0, 1.0, 2.0, 0.4393252832915737, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 500687.5591286489, 500687.5591286492, 132614.6647174618], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1486200.0000, 
sim time next is 1486800.0000, 
raw observation next is [20.0, 100.0, 1.0, 2.0, 0.4401578927354424, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 501637.3154195556, 501637.3154195556, 132701.0575883019], 
processed observation next is [0.0, 0.21739130434782608, 0.5454545454545454, 1.0, 1.0, 1.0, 0.300197365919303, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1857915983035391, 0.1857915983035391, 0.323661116069029], 
reward next is 0.6763, 
noisyNet noise sample is [array([1.4727938], dtype=float32), -0.64637136]. 
=============================================
[2019-03-22 22:46:47,020] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.38448683e-36 1.00000000e+00 3.35090453e-19 1.02917705e-14
 2.37730881e-18], sum to 1.0000
[2019-03-22 22:46:47,031] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9910
[2019-03-22 22:46:47,040] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1151293.828606835 W.
[2019-03-22 22:46:47,045] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.0, 62.0, 1.0, 2.0, 0.5297182008872661, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9627589687595719, 6.932430471869117, 6.9112, 77.32839380130991, 1151293.828606835, 1144398.611791848, 263851.3723728245], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1605600.0000, 
sim time next is 1606200.0000, 
raw observation next is [27.0, 62.0, 1.0, 2.0, 0.7221337101938852, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9754343735610613, 6.911199999999999, 6.9112, 79.9714070182785, 1370308.76270012, 1370308.76270012, 294648.9406981179], 
processed observation next is [1.0, 0.6086956521739131, 0.8636363636363636, 0.62, 1.0, 1.0, 0.6526671377423565, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9649062479443733, -8.881784197001253e-17, 0.0, 0.5258059675217038, 0.5075217639630074, 0.5075217639630074, 0.7186559529222387], 
reward next is 0.2813, 
noisyNet noise sample is [array([0.3984583], dtype=float32), 0.054001987]. 
=============================================
[2019-03-22 22:46:50,993] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 9.266147e-38 1.080603e-36], sum to 1.0000
[2019-03-22 22:46:51,003] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6418
[2019-03-22 22:46:51,013] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.33333333333334, 86.66666666666667, 1.0, 2.0, 0.5099413959795429, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 571837.7592976615, 571837.7592976615, 134209.6560856178], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1671600.0000, 
sim time next is 1672200.0000, 
raw observation next is [19.0, 88.5, 1.0, 2.0, 0.5868703835635005, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 657681.9496089137, 657681.949608914, 142259.283505335], 
processed observation next is [1.0, 0.34782608695652173, 0.5, 0.885, 1.0, 1.0, 0.4835879794543756, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.24358590726256063, 0.24358590726256074, 0.3469738622081342], 
reward next is 0.6530, 
noisyNet noise sample is [array([-2.4876444], dtype=float32), -0.45955336]. 
=============================================
[2019-03-22 22:46:55,161] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 2.2568217e-37], sum to 1.0000
[2019-03-22 22:46:55,175] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8246
[2019-03-22 22:46:55,182] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [9.0, 71.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 148761.7633045556, 148761.7633045556, 57692.69487715534], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1734000.0000, 
sim time next is 1734600.0000, 
raw observation next is [9.0, 71.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 148598.1639636967, 148598.1639636969, 57666.618675635], 
processed observation next is [1.0, 0.043478260869565216, 0.045454545454545456, 0.71, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.055036357023591366, 0.05503635702359144, 0.14065028945276828], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.4605052], dtype=float32), -2.7760317]. 
=============================================
[2019-03-22 22:46:55,392] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 3.4341153e-33], sum to 1.0000
[2019-03-22 22:46:55,398] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8087
[2019-03-22 22:46:55,404] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [8.0, 81.0, 1.0, 2.0, 0.3290618638575187, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 357324.1714810968, 357324.1714810965, 77200.29902041587], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1740000.0000, 
sim time next is 1740600.0000, 
raw observation next is [8.0, 81.0, 1.0, 2.0, 0.3289944173467223, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 357250.9052531076, 357250.9052531073, 77202.99928950048], 
processed observation next is [1.0, 0.13043478260869565, 0.0, 0.81, 1.0, 1.0, 0.16124302168340285, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13231515009374356, 0.13231515009374345, 0.18829999826707436], 
reward next is 0.8117, 
noisyNet noise sample is [array([-0.89062685], dtype=float32), 0.5005695]. 
=============================================
[2019-03-22 22:47:04,580] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.3627195e-38 3.8353148e-34 3.5551327e-34], sum to 1.0000
[2019-03-22 22:47:04,591] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3616
[2019-03-22 22:47:04,602] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 47.33333333333334, 1.0, 2.0, 0.4352191223864313, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 472655.0440725543, 472655.0440725543, 113792.3284437084], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1862400.0000, 
sim time next is 1863000.0000, 
raw observation next is [22.5, 48.0, 1.0, 2.0, 0.4914315241354952, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 533736.1398290531, 533736.1398290531, 122972.4837889017], 
processed observation next is [1.0, 0.5652173913043478, 0.6590909090909091, 0.48, 1.0, 1.0, 0.3642894051693689, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19768005178853817, 0.19768005178853817, 0.29993288729000417], 
reward next is 0.7001, 
noisyNet noise sample is [array([-1.7235938], dtype=float32), -0.05643559]. 
=============================================
[2019-03-22 22:47:04,617] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[64.929665]
 [65.0245  ]
 [64.95506 ]
 [64.93375 ]
 [64.94766 ]], R is [[64.88305664]
 [64.95668793]
 [65.05091095]
 [65.1466217 ]
 [65.23755646]].
[2019-03-22 22:47:06,841] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 22:47:06,855] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9370
[2019-03-22 22:47:06,859] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 71.33333333333333, 1.0, 2.0, 0.2852572488578103, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 309742.1379636796, 309742.1379636799, 107085.9293260492], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1906800.0000, 
sim time next is 1907400.0000, 
raw observation next is [19.0, 72.16666666666667, 1.0, 2.0, 0.2888374084542975, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 313630.8520011691, 313630.8520011694, 109999.0954940097], 
processed observation next is [1.0, 0.043478260869565216, 0.5, 0.7216666666666667, 1.0, 1.0, 0.11104676056787187, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11615957481524782, 0.11615957481524793, 0.2682904768146578], 
reward next is 0.7317, 
noisyNet noise sample is [array([0.57965326], dtype=float32), 1.3130301]. 
=============================================
[2019-03-22 22:47:09,381] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 3.6019342e-23 7.4322721e-17 1.6189601e-24], sum to 1.0000
[2019-03-22 22:47:09,383] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6936
[2019-03-22 22:47:09,386] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1218400.181923689 W.
[2019-03-22 22:47:09,391] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.66666666666666, 76.33333333333334, 1.0, 2.0, 0.5348928042354174, 1.0, 2.0, 0.5348928042354174, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344351869, 1218400.181923689, 1218400.181923689, 238802.5802431914], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1943400.0000, 
sim time next is 1944000.0000, 
raw observation next is [24.0, 74.0, 1.0, 2.0, 0.6039810301192988, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9710269305385165, 6.911199999999999, 6.9112, 77.32846344354091, 1237524.342572536, 1237524.342572536, 272353.7899919759], 
processed observation next is [1.0, 0.5217391304347826, 0.7272727272727273, 0.74, 1.0, 1.0, 0.5049762876491235, 0.0, 0.5, -0.25, 1.0, 0.5, 0.9586099007693095, -8.881784197001253e-17, 0.0, 0.5084288129206532, 0.4583423491009393, 0.4583423491009393, 0.6642775365657948], 
reward next is 0.3357, 
noisyNet noise sample is [array([-0.7790167], dtype=float32), 0.61256945]. 
=============================================
[2019-03-22 22:47:09,430] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[48.8512  ]
 [48.43313 ]
 [47.85975 ]
 [47.02122 ]
 [47.365265]], R is [[48.2626152 ]
 [48.1975441 ]
 [48.13188934]
 [47.96274948]
 [47.80270004]].
[2019-03-22 22:47:14,510] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 22:47:14,519] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4153
[2019-03-22 22:47:14,523] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.7, 51.5, 1.0, 2.0, 0.302540847628208, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 328515.6032048526, 328515.6032048526, 101857.8654947354], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2057400.0000, 
sim time next is 2058000.0000, 
raw observation next is [21.46666666666667, 52.0, 1.0, 2.0, 0.2989033880609099, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 324564.5301464162, 324564.530146416, 99710.21119717359], 
processed observation next is [0.0, 0.8260869565217391, 0.6121212121212122, 0.52, 1.0, 1.0, 0.12362923507613734, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12020908523941341, 0.12020908523941333, 0.24319563706627703], 
reward next is 0.7568, 
noisyNet noise sample is [array([1.4038594], dtype=float32), -1.1587155]. 
=============================================
[2019-03-22 22:47:14,540] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[78.54567 ]
 [78.510086]
 [78.4732  ]
 [78.433464]
 [78.37985 ]], R is [[78.56045532]
 [78.52641296]
 [78.48723602]
 [78.44273376]
 [78.39229584]].
[2019-03-22 22:47:16,651] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 22:47:16,667] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9403
[2019-03-22 22:47:16,674] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 50.0, 1.0, 2.0, 0.3062407257859033, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 333129.9888656656, 333129.9888656659, 111820.5866665606], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2035800.0000, 
sim time next is 2036400.0000, 
raw observation next is [23.0, 51.0, 1.0, 2.0, 0.3055668565939638, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 333443.2306736806, 333443.2306736803, 112146.1514458017], 
processed observation next is [0.0, 0.5652173913043478, 0.6818181818181818, 0.51, 1.0, 1.0, 0.13195857074245476, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12349749284210393, 0.12349749284210382, 0.27352719864829683], 
reward next is 0.7265, 
noisyNet noise sample is [array([-0.8833441], dtype=float32), -0.035215117]. 
=============================================
[2019-03-22 22:47:23,117] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.3559842e-37 9.0821416e-38], sum to 1.0000
[2019-03-22 22:47:23,128] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5297
[2019-03-22 22:47:23,134] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 57.5, 1.0, 2.0, 0.4066450148784183, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 461026.6945226644, 461026.6945226647, 127118.4752269735], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2140200.0000, 
sim time next is 2140800.0000, 
raw observation next is [24.66666666666667, 58.66666666666667, 1.0, 2.0, 0.4034230153898311, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 457021.5594731956, 457021.5594731959, 126577.4475576583], 
processed observation next is [0.0, 0.782608695652174, 0.7575757575757578, 0.5866666666666667, 1.0, 1.0, 0.25427876923728887, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1692672442493317, 0.16926724424933182, 0.30872548184794707], 
reward next is 0.6913, 
noisyNet noise sample is [array([0.6032111], dtype=float32), 2.4886937]. 
=============================================
[2019-03-22 22:47:25,196] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.3549382e-36 4.9489844e-37], sum to 1.0000
[2019-03-22 22:47:25,210] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1332
[2019-03-22 22:47:25,218] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.33333333333333, 92.0, 1.0, 2.0, 0.2925533324136691, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 317667.0640787348, 317667.0640787348, 104572.8205716028], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2169600.0000, 
sim time next is 2170200.0000, 
raw observation next is [16.16666666666667, 93.0, 1.0, 2.0, 0.2903003716646869, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 315219.9089858207, 315219.9089858204, 103238.5737234071], 
processed observation next is [1.0, 0.08695652173913043, 0.37121212121212144, 0.93, 1.0, 1.0, 0.11287546458085863, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11674811443919286, 0.11674811443919275, 0.25180139932538315], 
reward next is 0.7482, 
noisyNet noise sample is [array([1.1290157], dtype=float32), 0.92948145]. 
=============================================
[2019-03-22 22:47:30,331] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 6.1312940e-34 1.7986066e-32], sum to 1.0000
[2019-03-22 22:47:30,348] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4509
[2019-03-22 22:47:30,352] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.33333333333334, 90.0, 1.0, 2.0, 0.3620586376727502, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 402596.5531961287, 402596.553196129, 118989.8332839525], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2236800.0000, 
sim time next is 2237400.0000, 
raw observation next is [18.0, 91.0, 1.0, 2.0, 0.3563380626768728, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 394938.3102833663, 394938.3102833663, 118004.2577244148], 
processed observation next is [1.0, 0.9130434782608695, 0.45454545454545453, 0.91, 1.0, 1.0, 0.19542257834609097, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14627344825309863, 0.14627344825309863, 0.2878152627424751], 
reward next is 0.7122, 
noisyNet noise sample is [array([-0.13502061], dtype=float32), 0.375749]. 
=============================================
[2019-03-22 22:47:31,558] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.0833253e-34 1.0293197e-34], sum to 1.0000
[2019-03-22 22:47:31,568] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9622
[2019-03-22 22:47:31,576] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.5, 79.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 208184.6357216056, 208184.6357216054, 68781.07007607991], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2266200.0000, 
sim time next is 2266800.0000, 
raw observation next is [13.33333333333333, 78.66666666666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 206301.6512992327, 206301.651299233, 68081.35380338714], 
processed observation next is [1.0, 0.21739130434782608, 0.2424242424242423, 0.7866666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07640801899971582, 0.07640801899971593, 0.16605208244728573], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.05627782], dtype=float32), 0.9642608]. 
=============================================
[2019-03-22 22:47:38,024] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-22 22:47:38,025] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-22 22:47:38,025] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:47:38,027] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-22 22:47:38,028] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:47:38,029] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-22 22:47:38,032] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-22 22:47:38,035] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:47:38,035] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:47:38,035] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-22 22:47:38,037] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:47:38,058] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run12
[2019-03-22 22:47:38,059] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run12
[2019-03-22 22:47:38,059] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run12
[2019-03-22 22:47:38,060] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run12
[2019-03-22 22:47:38,135] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run12
[2019-03-22 22:47:43,151] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.14257883], dtype=float32), -0.1384757]
[2019-03-22 22:47:43,153] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [13.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 208843.8812389034, 208843.8812389034, 72176.7859448839]
[2019-03-22 22:47:43,153] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 22:47:43,156] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 2.137163e-38 0.000000e+00], sampled 0.28118457320123924
[2019-03-22 22:48:29,661] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.14257883], dtype=float32), -0.1384757]
[2019-03-22 22:48:29,662] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.7, 57.5, 1.0, 2.0, 0.3457179678488476, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 383051.2544352637, 383051.2544352633, 121447.2432500256]
[2019-03-22 22:48:29,664] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 22:48:29,666] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.0070009114067494105
[2019-03-22 22:48:47,758] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.14257883], dtype=float32), -0.1384757]
[2019-03-22 22:48:47,759] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.5, 81.0, 1.0, 2.0, 0.4567682410844019, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 520774.3644148069, 520774.3644148067, 134734.4428809145]
[2019-03-22 22:48:47,759] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 22:48:47,761] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 5.052929e-38 0.000000e+00], sampled 0.6963680236345486
[2019-03-22 22:49:11,353] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.14257883], dtype=float32), -0.1384757]
[2019-03-22 22:49:11,356] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.08333333333334, 50.33333333333334, 1.0, 2.0, 0.2589688699922936, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 281173.5571912065, 281173.5571912061, 84328.39910216419]
[2019-03-22 22:49:11,360] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 22:49:11,363] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.6131048972929897
[2019-03-22 22:49:17,294] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.14257883], dtype=float32), -0.1384757]
[2019-03-22 22:49:17,294] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.98214991166667, 82.33964595666667, 1.0, 2.0, 0.3437530462758926, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 379663.4612944278, 379663.4612944275, 120819.5391242577]
[2019-03-22 22:49:17,297] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 22:49:17,302] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 7.192329e-37 0.000000e+00], sampled 0.9079408603231466
[2019-03-22 22:49:17,924] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.14257883], dtype=float32), -0.1384757]
[2019-03-22 22:49:17,927] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [30.26898872, 70.96595116, 1.0, 2.0, 0.7424309597316114, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 834291.7417654452, 834291.7417654452, 184668.3927750869]
[2019-03-22 22:49:17,927] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 22:49:17,930] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.2430603e-35 0.0000000e+00], sampled 0.7548807836711933
[2019-03-22 22:49:41,254] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-22 22:49:41,778] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5598 1663796639.0689 105.0000
[2019-03-22 22:49:41,843] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9309 1705967916.6745 465.0000
[2019-03-22 22:49:41,934] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2492 1773187030.7201 173.0000
[2019-03-22 22:49:41,962] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-22 22:49:42,979] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 275000, evaluation results [275000.0, 8512.249193409023, 1773187030.7201214, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8856.559759326878, 1663796639.0688558, 105.0, 8596.930884973775, 1705967916.6744611, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-22 22:49:52,601] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 22:49:52,615] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4065
[2019-03-22 22:49:52,620] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.66666666666667, 96.0, 1.0, 2.0, 0.2298017837542441, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 249511.239254183, 249511.239254183, 77761.96465695878], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2492400.0000, 
sim time next is 2493000.0000, 
raw observation next is [13.5, 97.0, 1.0, 2.0, 0.228056143231091, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 247615.3975675354, 247615.3975675357, 77320.18341793786], 
processed observation next is [1.0, 0.8695652173913043, 0.25, 0.97, 1.0, 1.0, 0.03507017903886373, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09170940650649459, 0.0917094065064947, 0.1885858132144826], 
reward next is 0.8114, 
noisyNet noise sample is [array([0.5240401], dtype=float32), 0.012690109]. 
=============================================
[2019-03-22 22:49:52,632] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[79.10885 ]
 [79.14111 ]
 [79.202194]
 [79.27542 ]
 [79.37714 ]], R is [[79.10168457]
 [79.1210022 ]
 [79.13911438]
 [79.15607452]
 [79.17269135]].
[2019-03-22 22:49:52,686] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 22:49:52,695] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8264
[2019-03-22 22:49:52,702] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 99.0, 1.0, 2.0, 0.2080465194059355, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 225884.6018387255, 225884.6018387258, 74169.50239568285], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2501400.0000, 
sim time next is 2502000.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.2106226913409049, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 228682.3144302696, 228682.3144302693, 74714.27643076492], 
processed observation next is [1.0, 1.0, 0.22727272727272727, 1.0, 1.0, 1.0, 0.013278364176131097, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08469715349269244, 0.08469715349269233, 0.18222994251406077], 
reward next is 0.8178, 
noisyNet noise sample is [array([0.46350536], dtype=float32), -0.81443626]. 
=============================================
[2019-03-22 22:49:52,731] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[76.63258]
 [76.61348]
 [76.59589]
 [76.58367]
 [76.58738]], R is [[76.72473907]
 [76.77658844]
 [76.82888794]
 [76.88134766]
 [76.93408203]].
[2019-03-22 22:49:53,343] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 22:49:53,354] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5537
[2019-03-22 22:49:53,361] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.03333333333333, 72.83333333333334, 1.0, 2.0, 0.2704506271629876, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 293659.744473611, 293659.744473611, 93692.17717937451], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2589000.0000, 
sim time next is 2589600.0000, 
raw observation next is [17.96666666666667, 72.66666666666667, 1.0, 2.0, 0.2689957622498824, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 292079.5538256, 292079.5538256003, 92613.73274041944], 
processed observation next is [1.0, 1.0, 0.4530303030303031, 0.7266666666666667, 1.0, 1.0, 0.08624470281235301, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10817761252800001, 0.10817761252800011, 0.22588715302541326], 
reward next is 0.7741, 
noisyNet noise sample is [array([1.9352756], dtype=float32), 0.91013193]. 
=============================================
[2019-03-22 22:49:55,625] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.2149652e-36 2.3622459e-35], sum to 1.0000
[2019-03-22 22:49:55,637] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1677
[2019-03-22 22:49:55,642] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.5, 97.0, 1.0, 2.0, 0.3548798373433263, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 385370.6961087743, 385370.696108774, 90200.22303614173], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2536200.0000, 
sim time next is 2536800.0000, 
raw observation next is [13.66666666666667, 96.0, 1.0, 2.0, 0.3704849794754739, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 402323.6244982646, 402323.6244982646, 92453.41329469038], 
processed observation next is [1.0, 0.34782608695652173, 0.25757575757575774, 0.96, 1.0, 1.0, 0.21310622434434232, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14900874981417206, 0.14900874981417206, 0.2254961299870497], 
reward next is 0.7745, 
noisyNet noise sample is [array([1.0479518], dtype=float32), -0.6465037]. 
=============================================
[2019-03-22 22:49:58,075] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 22:49:58,083] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2029
[2019-03-22 22:49:58,090] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 53.0, 1.0, 2.0, 0.3004900835019469, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 326288.0229123501, 326288.0229123498, 111223.6385874089], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2570400.0000, 
sim time next is 2571000.0000, 
raw observation next is [21.83333333333334, 53.5, 1.0, 2.0, 0.2994166606624122, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 325122.0539989893, 325122.053998989, 109604.1437926083], 
processed observation next is [1.0, 0.782608695652174, 0.628787878787879, 0.535, 1.0, 1.0, 0.12427082582801521, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12041557555518122, 0.1204155755551811, 0.2673271799819715], 
reward next is 0.7327, 
noisyNet noise sample is [array([-1.2746292], dtype=float32), -0.33449343]. 
=============================================
[2019-03-22 22:49:58,110] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[75.2272  ]
 [75.107605]
 [75.001076]
 [74.87856 ]
 [74.64775 ]], R is [[75.30319977]
 [75.27889252]
 [75.25437927]
 [75.22956085]
 [75.20478058]].
[2019-03-22 22:49:58,783] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 22:49:58,793] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9160
[2019-03-22 22:49:58,801] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.5, 44.5, 1.0, 2.0, 0.3365027540866403, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 373957.9669475067, 373957.966947507, 116883.9812712907], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2633400.0000, 
sim time next is 2634000.0000, 
raw observation next is [25.66666666666666, 43.66666666666667, 1.0, 2.0, 0.3354314050176002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 372687.9675948397, 372687.9675948397, 116768.1307959988], 
processed observation next is [0.0, 0.4782608695652174, 0.8030303030303028, 0.4366666666666667, 1.0, 1.0, 0.16928925627200025, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13803258059068138, 0.13803258059068138, 0.2848003190146312], 
reward next is 0.7152, 
noisyNet noise sample is [array([-0.05932846], dtype=float32), -1.1240467]. 
=============================================
[2019-03-22 22:49:58,817] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[73.24882 ]
 [73.23387 ]
 [73.217995]
 [73.19336 ]
 [73.153015]], R is [[73.23703003]
 [73.2195816 ]
 [73.2019043 ]
 [73.18379211]
 [73.16448975]].
[2019-03-22 22:50:11,577] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 5.513005e-33 9.705229e-34], sum to 1.0000
[2019-03-22 22:50:11,592] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8811
[2019-03-22 22:50:11,597] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.66666666666667, 84.66666666666667, 1.0, 2.0, 0.4225183278159551, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 467828.2884330085, 467828.2884330085, 123303.539291293], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2773200.0000, 
sim time next is 2773800.0000, 
raw observation next is [18.5, 85.5, 1.0, 2.0, 0.372814955211629, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 412156.6682671129, 412156.6682671126, 118913.7250003651], 
processed observation next is [1.0, 0.08695652173913043, 0.4772727272727273, 0.855, 1.0, 1.0, 0.21601869401453622, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1526506178767085, 0.15265061787670836, 0.2900334756106466], 
reward next is 0.7100, 
noisyNet noise sample is [array([-1.0758506], dtype=float32), 0.66346955]. 
=============================================
[2019-03-22 22:50:12,864] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 22:50:12,876] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0125
[2019-03-22 22:50:12,881] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.16666666666666, 53.5, 1.0, 2.0, 0.4539434750516321, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 517622.3969420854, 517622.3969420857, 134557.6573431547], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2832600.0000, 
sim time next is 2833200.0000, 
raw observation next is [27.0, 54.0, 1.0, 2.0, 0.4534432325591438, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 516981.9379101463, 516981.9379101463, 134383.1450693497], 
processed observation next is [1.0, 0.8260869565217391, 0.8636363636363636, 0.54, 1.0, 1.0, 0.31680404069892976, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19147479181857271, 0.19147479181857271, 0.32776376846182853], 
reward next is 0.6722, 
noisyNet noise sample is [array([-0.8426658], dtype=float32), 0.0021382226]. 
=============================================
[2019-03-22 22:50:14,437] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.0534798e-27 1.1570142e-24 1.5193349e-25], sum to 1.0000
[2019-03-22 22:50:14,444] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7429
[2019-03-22 22:50:14,448] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 58.0, 1.0, 2.0, 0.3125194795185743, 1.0, 1.0, 0.3125194795185743, 1.0, 2.0, 0.6327268656963743, 6.911199999999999, 6.9112, 77.3421103, 1061338.098291254, 1061338.098291254, 266493.5573931006], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2812200.0000, 
sim time next is 2812800.0000, 
raw observation next is [28.0, 58.0, 1.0, 2.0, 0.9985322255105104, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.108010052088998, 6.9112, 77.32807287351511, 1200131.164387672, 1136211.607776923, 222130.5319880825], 
processed observation next is [1.0, 0.5652173913043478, 0.9090909090909091, 0.58, 1.0, 1.0, 0.9981652818881378, 0.0, 0.5, -0.25, 0.0, 0.5, -0.4285714285714286, 0.019681005208899816, 0.0, 0.508426244952201, 0.4444930238472859, 0.420819113991453, 0.5417817853367866], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2046844], dtype=float32), -0.29365337]. 
=============================================
[2019-03-22 22:50:17,694] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.3069799e-38], sum to 1.0000
[2019-03-22 22:50:17,704] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9849
[2019-03-22 22:50:17,709] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 88.0, 1.0, 2.0, 0.4306204356474761, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 489912.9799970651, 489912.9799970651, 130759.8451974902], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2868600.0000, 
sim time next is 2869200.0000, 
raw observation next is [21.0, 88.0, 1.0, 2.0, 0.4290373977863206, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 488108.1295351337, 488108.1295351337, 130598.8121108446], 
processed observation next is [1.0, 0.21739130434782608, 0.5909090909090909, 0.88, 1.0, 1.0, 0.2862967472329007, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18078078871671618, 0.18078078871671618, 0.31853368807523075], 
reward next is 0.6815, 
noisyNet noise sample is [array([-0.85336614], dtype=float32), -0.13739128]. 
=============================================
[2019-03-22 22:50:20,982] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 22:50:20,991] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3138
[2019-03-22 22:50:21,000] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1258679.717636341 W.
[2019-03-22 22:50:21,005] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.0, 85.66666666666666, 1.0, 2.0, 0.5595370789421235, 1.0, 2.0, 0.5595370789421235, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1258679.717636341, 1258679.717636341, 250770.8015930712], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2911200.0000, 
sim time next is 2911800.0000, 
raw observation next is [23.5, 87.33333333333334, 1.0, 2.0, 0.5480225363594815, 1.0, 2.0, 0.5480225363594815, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1236679.386720908, 1236679.386720908, 246814.1169487069], 
processed observation next is [1.0, 0.6956521739130435, 0.7045454545454546, 0.8733333333333334, 1.0, 1.0, 0.4350281704493518, 1.0, 1.0, 0.4350281704493518, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.45802940248922525, 0.45802940248922525, 0.6019856510944072], 
reward next is 0.3980, 
noisyNet noise sample is [array([0.74760824], dtype=float32), -0.95664644]. 
=============================================
[2019-03-22 22:50:22,189] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.4174692e-37 1.2903219e-35], sum to 1.0000
[2019-03-22 22:50:22,197] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5261
[2019-03-22 22:50:22,204] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 100.0, 1.0, 2.0, 0.5347879761405113, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 608365.5635725994, 608365.5635725994, 147686.8222854604], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2930400.0000, 
sim time next is 2931000.0000, 
raw observation next is [22.0, 100.0, 1.0, 2.0, 0.5387412197649603, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 612770.6160130345, 612770.6160130348, 148238.9721753299], 
processed observation next is [1.0, 0.9565217391304348, 0.6363636363636364, 1.0, 1.0, 1.0, 0.4234265247062003, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22695208000482758, 0.22695208000482772, 0.36155846872031683], 
reward next is 0.6384, 
noisyNet noise sample is [array([-1.6991955], dtype=float32), 0.25591844]. 
=============================================
[2019-03-22 22:50:22,223] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[51.01097]
 [51.05495]
 [51.10695]
 [51.14469]
 [51.17321]], R is [[51.07762527]
 [51.20663834]
 [51.33652878]
 [51.46717453]
 [51.59842682]].
[2019-03-22 22:50:30,432] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 22:50:30,445] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0911
[2019-03-22 22:50:30,451] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.66666666666667, 90.33333333333334, 1.0, 2.0, 0.5151619809911334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 566928.0022361483, 566928.0022361481, 130612.805272925], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3054000.0000, 
sim time next is 3054600.0000, 
raw observation next is [18.0, 88.5, 1.0, 2.0, 0.5971463425209921, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 659216.9347269076, 659216.9347269076, 139555.353085059], 
processed observation next is [1.0, 0.34782608695652173, 0.45454545454545453, 0.885, 1.0, 1.0, 0.49643292815124007, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.24415442026922504, 0.24415442026922504, 0.3403789099635585], 
reward next is 0.6596, 
noisyNet noise sample is [array([0.7150317], dtype=float32), -1.0567824]. 
=============================================
[2019-03-22 22:50:30,601] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.3276934e-38], sum to 1.0000
[2019-03-22 22:50:30,610] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1700
[2019-03-22 22:50:30,616] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.66666666666667, 84.83333333333333, 1.0, 2.0, 0.6708715562364163, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 744099.6701978096, 744099.6701978096, 148992.5632211259], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3055800.0000, 
sim time next is 3056400.0000, 
raw observation next is [19.0, 83.0, 1.0, 2.0, 0.637339368367105, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 707971.1381887508, 707971.1381887508, 145521.5284168232], 
processed observation next is [1.0, 0.391304347826087, 0.5, 0.83, 1.0, 1.0, 0.5466742104588812, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2622115326625003, 0.2622115326625003, 0.3549305571142029], 
reward next is 0.6451, 
noisyNet noise sample is [array([0.26998076], dtype=float32), -0.18148904]. 
=============================================
[2019-03-22 22:50:30,654] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 22:50:30,668] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9576
[2019-03-22 22:50:30,679] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 94.0, 1.0, 2.0, 0.3600210623058818, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 394142.466407791, 394142.4664077907, 116488.2947526514], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3051000.0000, 
sim time next is 3051600.0000, 
raw observation next is [17.0, 94.0, 1.0, 2.0, 0.3600933062669908, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 394191.1064212906, 394191.1064212906, 116483.1888988426], 
processed observation next is [1.0, 0.30434782608695654, 0.4090909090909091, 0.94, 1.0, 1.0, 0.2001166328337385, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14599670608195947, 0.14599670608195947, 0.2841053387776649], 
reward next is 0.7159, 
noisyNet noise sample is [array([-0.44440624], dtype=float32), 0.40930578]. 
=============================================
[2019-03-22 22:50:39,022] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.2576776e-38 5.1351255e-38], sum to 1.0000
[2019-03-22 22:50:39,036] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2084
[2019-03-22 22:50:39,043] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.33333333333334, 81.33333333333334, 1.0, 2.0, 0.342507099184474, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 379922.3204154904, 379922.3204154907, 117056.193512522], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3222600.0000, 
sim time next is 3223200.0000, 
raw observation next is [19.66666666666667, 79.66666666666667, 1.0, 2.0, 0.346075628026196, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 384551.010362335, 384551.010362335, 117608.1172950291], 
processed observation next is [0.0, 0.30434782608695654, 0.5303030303030305, 0.7966666666666667, 1.0, 1.0, 0.182594535032745, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14242630013419816, 0.14242630013419816, 0.2868490665732417], 
reward next is 0.7132, 
noisyNet noise sample is [array([-0.91313165], dtype=float32), 0.582647]. 
=============================================
[2019-03-22 22:50:41,597] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 22:50:41,607] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4172
[2019-03-22 22:50:41,613] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.5, 85.5, 1.0, 2.0, 0.3347106426395264, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 369515.2290233215, 369515.2290233218, 115755.7572529381], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3220200.0000, 
sim time next is 3220800.0000, 
raw observation next is [18.66666666666667, 84.66666666666666, 1.0, 2.0, 0.3361326417527807, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 371483.8775799058, 371483.8775799061, 116017.8437109445], 
processed observation next is [0.0, 0.2608695652173913, 0.4848484848484851, 0.8466666666666666, 1.0, 1.0, 0.17016580219097582, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13758662132589103, 0.13758662132589114, 0.28297035051449876], 
reward next is 0.7170, 
noisyNet noise sample is [array([0.25659332], dtype=float32), 1.4916928]. 
=============================================
[2019-03-22 22:50:46,038] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 22:50:46,053] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6165
[2019-03-22 22:50:46,058] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.16666666666666, 63.33333333333334, 1.0, 2.0, 0.3282302873860313, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 360380.6544991916, 360380.6544991918, 114520.8501141153], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3275400.0000, 
sim time next is 3276000.0000, 
raw observation next is [21.0, 64.0, 1.0, 2.0, 0.3267167580758213, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 358350.8647250884, 358350.8647250881, 114275.557592501], 
processed observation next is [0.0, 0.9565217391304348, 0.5909090909090909, 0.64, 1.0, 1.0, 0.1583959475947766, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13272254249077348, 0.13272254249077337, 0.2787208721768317], 
reward next is 0.7213, 
noisyNet noise sample is [array([-0.7367628], dtype=float32), -0.8181682]. 
=============================================
[2019-03-22 22:50:46,084] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[72.757645]
 [72.73881 ]
 [72.72256 ]
 [72.71242 ]
 [72.71255 ]], R is [[72.79623413]
 [72.78895569]
 [72.78115082]
 [72.77277374]
 [72.7637558 ]].
[2019-03-22 22:50:47,041] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-22 22:50:47,044] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-22 22:50:47,045] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:50:47,046] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-22 22:50:47,046] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:50:47,048] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-22 22:50:47,049] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:50:47,050] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-22 22:50:47,051] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-22 22:50:47,052] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:50:47,053] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:50:47,077] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run13
[2019-03-22 22:50:47,077] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run13
[2019-03-22 22:50:47,096] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run13
[2019-03-22 22:50:47,118] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run13
[2019-03-22 22:50:47,158] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run13
[2019-03-22 22:50:58,567] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.2287642], dtype=float32), -0.17636956]
[2019-03-22 22:50:58,569] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [15.5, 97.0, 1.0, 2.0, 0.284225209023529, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 308621.1580152831, 308621.1580152833, 98590.95506391548]
[2019-03-22 22:50:58,571] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 22:50:58,574] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.40558718163396457
[2019-03-22 22:51:56,165] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.2287642], dtype=float32), -0.17636956]
[2019-03-22 22:51:56,167] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.93543459666667, 89.87562375666667, 1.0, 2.0, 0.4549569597546461, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 518193.442101634, 518193.442101634, 138205.3800089988]
[2019-03-22 22:51:56,169] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 22:51:56,173] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.2291009859805846
[2019-03-22 22:51:58,454] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.2287642], dtype=float32), -0.17636956]
[2019-03-22 22:51:58,455] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [26.85545212, 98.36921483, 1.0, 2.0, 0.7221804232073832, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 811520.2352537748, 811520.2352537744, 181438.5043737086]
[2019-03-22 22:51:58,455] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 22:51:58,457] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.13534877649998434
[2019-03-22 22:52:10,200] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.2287642], dtype=float32), -0.17636956]
[2019-03-22 22:52:10,202] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [17.4, 90.0, 1.0, 2.0, 0.3841912306953381, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 420444.2444658649, 420444.2444658653, 122615.6451383038]
[2019-03-22 22:52:10,204] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 22:52:10,207] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.8134012092596987
[2019-03-22 22:52:24,447] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.2287642], dtype=float32), -0.17636956]
[2019-03-22 22:52:24,447] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.15, 61.5, 1.0, 2.0, 0.4140213166153907, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 468824.8877978684, 468824.8877978681, 131773.92332737]
[2019-03-22 22:52:24,448] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 22:52:24,450] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.6912911260029148
[2019-03-22 22:52:49,656] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.2287642], dtype=float32), -0.17636956]
[2019-03-22 22:52:49,656] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [17.26999735333333, 62.87802595833334, 1.0, 2.0, 0.251206593796163, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 272743.8103426193, 272743.8103426193, 83759.64970116019]
[2019-03-22 22:52:49,656] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 22:52:49,657] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.382030288052551
[2019-03-22 22:52:51,027] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-22 22:52:51,039] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-22 22:52:51,207] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-22 22:52:51,254] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-22 22:52:51,285] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1147 1656209757.7786 80.0000
[2019-03-22 22:52:52,301] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 300000, evaluation results [300000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.114669779829, 1656209757.7786272, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-22 22:52:54,085] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 22:52:54,098] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7113
[2019-03-22 22:52:54,106] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 64.33333333333334, 1.0, 2.0, 0.2859606606910335, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 310506.1705741361, 310506.1705741361, 107082.2427293034], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3316800.0000, 
sim time next is 3317400.0000, 
raw observation next is [20.5, 62.5, 1.0, 2.0, 0.2918493521509614, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 316902.4027919875, 316902.4027919878, 110649.7960178242], 
processed observation next is [0.0, 0.391304347826087, 0.5681818181818182, 0.625, 1.0, 1.0, 0.11481169018870176, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11737126029332871, 0.11737126029332882, 0.26987755126298585], 
reward next is 0.7301, 
noisyNet noise sample is [array([1.5064864], dtype=float32), 0.37123728]. 
=============================================
[2019-03-22 22:52:56,110] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 22:52:56,122] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1641
[2019-03-22 22:52:56,126] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.83333333333333, 57.66666666666666, 1.0, 2.0, 0.3708213607793349, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 416481.600271365, 416481.600271365, 121556.9777359468], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3348600.0000, 
sim time next is 3349200.0000, 
raw observation next is [23.66666666666666, 58.33333333333334, 1.0, 2.0, 0.3698788242839443, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 415231.9830190928, 415231.9830190928, 121382.7265581327], 
processed observation next is [0.0, 0.782608695652174, 0.7121212121212118, 0.5833333333333335, 1.0, 1.0, 0.21234853035493037, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15378962334040475, 0.15378962334040475, 0.29605543062959194], 
reward next is 0.7039, 
noisyNet noise sample is [array([-0.650794], dtype=float32), -0.3577584]. 
=============================================
[2019-03-22 22:53:07,842] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.6739222e-36 1.0000000e+00 3.8416999e-26 6.5350698e-28 1.2536097e-25], sum to 1.0000
[2019-03-22 22:53:07,855] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5275
[2019-03-22 22:53:07,866] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.3, 59.0, 1.0, 2.0, 0.5263861284300337, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 598256.7646738593, 598256.7646738593, 146957.3922189923], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3519000.0000, 
sim time next is 3519600.0000, 
raw observation next is [28.2, 58.66666666666667, 1.0, 2.0, 0.5232106983933746, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 595148.2117016345, 595148.2117016345, 146276.8255444508], 
processed observation next is [1.0, 0.7391304347826086, 0.9181818181818181, 0.5866666666666667, 1.0, 1.0, 0.40401337299171824, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22042526359319795, 0.22042526359319795, 0.35677274523036784], 
reward next is 0.6432, 
noisyNet noise sample is [array([2.065015], dtype=float32), 2.6005611]. 
=============================================
[2019-03-22 22:53:09,915] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.2682881e-37 1.0000000e+00 1.0242891e-29 5.9385283e-27 1.5322177e-22], sum to 1.0000
[2019-03-22 22:53:09,925] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5213
[2019-03-22 22:53:09,932] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 89.0, 1.0, 2.0, 0.5200956688984502, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 592517.5530709184, 592517.5530709182, 145215.8398494398], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3546000.0000, 
sim time next is 3546600.0000, 
raw observation next is [23.0, 89.0, 1.0, 2.0, 0.5194324076624407, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 591762.0347431514, 591762.0347431514, 145134.9000248478], 
processed observation next is [1.0, 0.043478260869565216, 0.6818181818181818, 0.89, 1.0, 1.0, 0.39929050957805085, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21917112397894495, 0.21917112397894495, 0.35398756103621415], 
reward next is 0.6460, 
noisyNet noise sample is [array([-0.21956304], dtype=float32), -0.08631991]. 
=============================================
[2019-03-22 22:53:14,983] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.3069101e-38 4.8643151e-27], sum to 1.0000
[2019-03-22 22:53:14,992] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3025
[2019-03-22 22:53:15,000] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4909441627371197, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 560144.4145530548, 560144.4145530548, 140443.4164300306], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3634200.0000, 
sim time next is 3634800.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.4908950554917673, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 560088.3960884822, 560088.3960884825, 140437.6339953282], 
processed observation next is [1.0, 0.043478260869565216, 0.5909090909090909, 1.0, 1.0, 1.0, 0.36361881936470913, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20744014669943786, 0.20744014669943794, 0.3425308146227517], 
reward next is 0.6575, 
noisyNet noise sample is [array([0.61828065], dtype=float32), 0.102515794]. 
=============================================
[2019-03-22 22:53:18,874] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.1248164e-20 1.0000000e+00 6.7548912e-15 2.1772757e-11 9.4455893e-12], sum to 1.0000
[2019-03-22 22:53:18,885] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8101
[2019-03-22 22:53:18,895] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1501509.651948165 W.
[2019-03-22 22:53:18,900] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.0, 55.0, 1.0, 2.0, 0.6675699785278162, 1.0, 2.0, 0.6675699785278162, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1501509.651948165, 1501509.651948166, 281746.3060763963], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3682800.0000, 
sim time next is 3683400.0000, 
raw observation next is [29.0, 54.5, 1.0, 2.0, 0.7554349000303339, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9792026210117866, 6.911200000000001, 6.9112, 77.32846344354104, 1404931.38988113, 1404931.389881129, 302584.9258355026], 
processed observation next is [1.0, 0.6521739130434783, 0.9545454545454546, 0.545, 1.0, 1.0, 0.6942936250379173, 0.0, 0.5, -0.25, 1.0, 0.5, 0.9702894585882665, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.5203449592152334, 0.5203449592152329, 0.7380120142329333], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.24700509], dtype=float32), -0.887641]. 
=============================================
[2019-03-22 22:53:25,166] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 3.4437065e-32], sum to 1.0000
[2019-03-22 22:53:25,177] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1705
[2019-03-22 22:53:25,189] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 61.33333333333334, 1.0, 2.0, 0.3502664164084716, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 385923.1959674479, 385923.1959674479, 116645.7701271802], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3777600.0000, 
sim time next is 3778200.0000, 
raw observation next is [21.5, 62.0, 1.0, 2.0, 0.338840473992072, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 372731.1374586791, 372731.1374586794, 115556.7777223553], 
processed observation next is [1.0, 0.7391304347826086, 0.6136363636363636, 0.62, 1.0, 1.0, 0.17355059249009, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1380485694291404, 0.1380485694291405, 0.2818457993228178], 
reward next is 0.7182, 
noisyNet noise sample is [array([0.3587444], dtype=float32), 0.4947918]. 
=============================================
[2019-03-22 22:53:28,766] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 22:53:28,775] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2622
[2019-03-22 22:53:28,787] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 91.0, 1.0, 2.0, 0.3035894200521386, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 329664.7430723908, 329664.7430723908, 111437.9921957529], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3828600.0000, 
sim time next is 3829200.0000, 
raw observation next is [17.0, 92.0, 1.0, 2.0, 0.3059755500244424, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 333014.0746635186, 333014.0746635189, 111863.0364523563], 
processed observation next is [0.0, 0.30434782608695654, 0.4090909090909091, 0.92, 1.0, 1.0, 0.13246943753055296, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12333854617167354, 0.12333854617167368, 0.2728366742740398], 
reward next is 0.7272, 
noisyNet noise sample is [array([0.45952797], dtype=float32), 0.0320044]. 
=============================================
[2019-03-22 22:53:49,112] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.8091485e-25 9.9999893e-01 6.2593884e-15 4.5055203e-11 1.0376508e-06], sum to 1.0000
[2019-03-22 22:53:49,125] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9075
[2019-03-22 22:53:49,134] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 61.0, 1.0, 2.0, 0.7787311099919151, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 882194.3048339175, 882194.3048339178, 170973.5633573097], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4204800.0000, 
sim time next is 4205400.0000, 
raw observation next is [23.83333333333333, 62.33333333333334, 1.0, 2.0, 0.9299526526207123, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.80011322483053, 1054171.47627914, 1054171.476279139, 194830.4418325239], 
processed observation next is [1.0, 0.6956521739130435, 0.7196969696969695, 0.6233333333333334, 1.0, 1.0, 0.9124408157758903, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5115298746479492, 0.3904338801033852, 0.3904338801033848, 0.4751961995915217], 
reward next is 0.5248, 
noisyNet noise sample is [array([-0.3283063], dtype=float32), 0.60082495]. 
=============================================
[2019-03-22 22:53:49,546] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 5.6702489e-38 2.9309423e-32], sum to 1.0000
[2019-03-22 22:53:49,558] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1065
[2019-03-22 22:53:49,563] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.01666666666667, 93.83333333333334, 1.0, 2.0, 0.387194063649728, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 436268.4387637442, 436268.4387637442, 123678.8869751588], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4132200.0000, 
sim time next is 4132800.0000, 
raw observation next is [19.0, 94.0, 1.0, 2.0, 0.3897315702250438, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 439144.6452877032, 439144.6452877029, 123912.5768618318], 
processed observation next is [1.0, 0.8695652173913043, 0.5, 0.94, 1.0, 1.0, 0.2371644627813047, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16264616492137154, 0.16264616492137146, 0.30222579722397996], 
reward next is 0.6978, 
noisyNet noise sample is [array([0.9784012], dtype=float32), -0.48138985]. 
=============================================
[2019-03-22 22:53:51,777] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.7378667e-37 1.7434062e-35], sum to 1.0000
[2019-03-22 22:53:51,789] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5421
[2019-03-22 22:53:51,795] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 100.0, 1.0, 2.0, 0.3476129454877033, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 384745.5986814389, 384745.5986814389, 117115.3510552561], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4164000.0000, 
sim time next is 4164600.0000, 
raw observation next is [17.0, 100.0, 1.0, 2.0, 0.3414421557515168, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 377893.0332580754, 377893.0332580751, 116632.4574402677], 
processed observation next is [1.0, 0.17391304347826086, 0.4090909090909091, 1.0, 1.0, 1.0, 0.176802694689396, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1399603826881761, 0.13996038268817598, 0.2844694083908968], 
reward next is 0.7155, 
noisyNet noise sample is [array([1.4704212], dtype=float32), 2.0600305]. 
=============================================
[2019-03-22 22:53:52,928] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 2.2957644e-38 9.5919825e-33 1.8644570e-24], sum to 1.0000
[2019-03-22 22:53:52,938] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9124
[2019-03-22 22:53:52,944] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 88.0, 1.0, 2.0, 0.60041602885514, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 672287.2169718116, 672287.2169718116, 143534.6176156666], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4182600.0000, 
sim time next is 4183200.0000, 
raw observation next is [19.0, 88.0, 1.0, 2.0, 0.632546321756383, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 708378.406584792, 708378.406584792, 147279.545905466], 
processed observation next is [1.0, 0.43478260869565216, 0.5, 0.88, 1.0, 1.0, 0.5406829021954788, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.26236237280918223, 0.26236237280918223, 0.359218404647478], 
reward next is 0.6408, 
noisyNet noise sample is [array([0.78998196], dtype=float32), -1.4678777]. 
=============================================
[2019-03-22 22:53:53,553] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.9890625e-29 1.0000000e+00 2.8603013e-21 3.3399544e-08 6.9663986e-09], sum to 1.0000
[2019-03-22 22:53:53,562] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0221
[2019-03-22 22:53:53,570] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 73.66666666666667, 1.0, 2.0, 0.6873739079803649, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 776324.9240734034, 776324.9240734037, 157045.2751916531], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4188000.0000, 
sim time next is 4188600.0000, 
raw observation next is [22.0, 71.5, 1.0, 2.0, 0.711742953954235, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 803961.5186584187, 803961.5186584187, 160292.1537693249], 
processed observation next is [1.0, 0.4782608695652174, 0.6363636363636364, 0.715, 1.0, 1.0, 0.6396786924427939, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.29776352542904394, 0.29776352542904394, 0.39095647260810956], 
reward next is 0.6090, 
noisyNet noise sample is [array([-1.8044786], dtype=float32), -0.29524758]. 
=============================================
[2019-03-22 22:53:54,406] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.1900133e-37 1.0000000e+00 1.0767220e-30 1.8670950e-19 4.7637849e-23], sum to 1.0000
[2019-03-22 22:53:54,415] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0721
[2019-03-22 22:53:54,422] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 94.0, 1.0, 2.0, 0.3068004210912782, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 333142.4682113059, 333142.4682113059, 103826.8948120292], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4251600.0000, 
sim time next is 4252200.0000, 
raw observation next is [16.0, 95.0, 1.0, 2.0, 0.2942196758952476, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 319477.0462490141, 319477.0462490144, 104538.7488213434], 
processed observation next is [1.0, 0.21739130434782608, 0.36363636363636365, 0.95, 1.0, 1.0, 0.1177745948690595, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11832483194407929, 0.1183248319440794, 0.2549725581008376], 
reward next is 0.7450, 
noisyNet noise sample is [array([-0.3171812], dtype=float32), 0.3456266]. 
=============================================
[2019-03-22 22:53:56,239] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-22 22:53:56,240] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-22 22:53:56,241] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:53:56,241] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-22 22:53:56,243] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-22 22:53:56,244] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:53:56,246] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:53:56,245] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-22 22:53:56,249] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-22 22:53:56,252] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:53:56,253] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:53:56,268] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run14
[2019-03-22 22:53:56,290] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run14
[2019-03-22 22:53:56,309] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run14
[2019-03-22 22:53:56,311] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run14
[2019-03-22 22:53:56,311] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run14
[2019-03-22 22:54:19,197] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.2222578], dtype=float32), -0.12535939]
[2019-03-22 22:54:19,198] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.40169682, 95.84190797, 1.0, 2.0, 0.4806350259757756, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 547989.0642970108, 547989.0642970108, 141691.6861568913]
[2019-03-22 22:54:19,199] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 22:54:19,203] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 6.0145793e-36 1.2791407e-31], sampled 0.43637793576310646
[2019-03-22 22:54:21,965] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.2222578], dtype=float32), -0.12535939]
[2019-03-22 22:54:21,967] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [28.05427703666667, 50.99922475666666, 1.0, 2.0, 0.8262421813208202, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 943025.4582921584, 943025.4582921584, 190503.7473928989]
[2019-03-22 22:54:21,968] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 22:54:21,973] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 4.7029538e-38 3.7761082e-29 2.7535777e-23], sampled 0.6054967859038748
[2019-03-22 22:54:31,937] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.2222578], dtype=float32), -0.12535939]
[2019-03-22 22:54:31,938] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [16.9, 56.5, 1.0, 2.0, 0.2346418876028867, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 254755.1163640545, 254755.1163640548, 79058.11864901704]
[2019-03-22 22:54:31,940] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 22:54:31,943] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.8411706320279446
[2019-03-22 22:54:36,749] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.2222578], dtype=float32), -0.12535939]
[2019-03-22 22:54:36,750] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.5, 51.5, 1.0, 2.0, 0.3077902368861069, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 334217.6394587437, 334217.6394587437, 111717.6878319394]
[2019-03-22 22:54:36,750] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 22:54:36,753] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.5057771e-36 3.0266248e-31], sampled 0.7046383621022204
[2019-03-22 22:54:36,778] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.2222578], dtype=float32), -0.12535939]
[2019-03-22 22:54:36,779] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.19860473666667, 42.4822296, 1.0, 2.0, 0.3578546560614218, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 388572.7854391027, 388572.7854391027, 96832.80340343351]
[2019-03-22 22:54:36,780] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 22:54:36,783] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.4915963e-34], sampled 0.32762896802273067
[2019-03-22 22:54:56,447] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.2222578], dtype=float32), -0.12535939]
[2019-03-22 22:54:56,449] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.0, 92.0, 1.0, 2.0, 0.3059755500244424, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 333014.0746635186, 333014.0746635189, 111863.0364523563]
[2019-03-22 22:54:56,450] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 22:54:56,453] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.1388268e-38 8.3431291e-35], sampled 0.03295697420286081
[2019-03-22 22:55:13,240] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.2222578], dtype=float32), -0.12535939]
[2019-03-22 22:55:13,242] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [26.33333333333334, 62.0, 1.0, 2.0, 0.5007431505240222, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 571326.2133349403, 571326.2133349403, 145585.6910204482]
[2019-03-22 22:55:13,242] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 22:55:13,246] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.0643266e-38 2.5998823e-32], sampled 0.38338313950516156
[2019-03-22 22:55:45,924] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.2222578], dtype=float32), -0.12535939]
[2019-03-22 22:55:45,925] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.6, 79.33333333333334, 1.0, 2.0, 0.4142636210118869, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 460185.8168507281, 460185.8168507278, 127493.5266204349]
[2019-03-22 22:55:45,925] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 22:55:45,928] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.5969096e-35 1.0974308e-30], sampled 0.17724888343959444
[2019-03-22 22:55:59,821] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-22 22:55:59,924] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-22 22:56:00,150] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3485 1683325900.1134 214.0000
[2019-03-22 22:56:00,188] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-22 22:56:00,251] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5598 1663796639.0689 105.0000
[2019-03-22 22:56:01,266] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 325000, evaluation results [325000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8856.559759326878, 1663796639.0688558, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8574.348472942609, 1683325900.1133502, 214.0]
[2019-03-22 22:56:13,663] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.4864209e-35 1.0000000e+00 2.7841822e-34 4.7646647e-20 3.6998382e-14], sum to 1.0000
[2019-03-22 22:56:13,675] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5366
[2019-03-22 22:56:13,681] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.16666666666667, 82.33333333333333, 1.0, 2.0, 0.4519359174699271, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 515058.2956889392, 515058.2956889389, 133913.3874377168], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4408800.0000, 
sim time next is 4409400.0000, 
raw observation next is [22.08333333333334, 82.66666666666667, 1.0, 2.0, 0.4501315958248431, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 512940.0684763797, 512940.0684763797, 133641.2210744674], 
processed observation next is [0.0, 0.0, 0.6401515151515155, 0.8266666666666667, 1.0, 1.0, 0.3126644947810538, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18997780313939988, 0.18997780313939988, 0.3259541977426034], 
reward next is 0.6740, 
noisyNet noise sample is [array([1.0128852], dtype=float32), -0.7220186]. 
=============================================
[2019-03-22 22:56:15,310] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.1806510e-29 4.7245907e-21], sum to 1.0000
[2019-03-22 22:56:15,321] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3043
[2019-03-22 22:56:15,328] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 78.0, 1.0, 2.0, 0.4507269448755032, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 513946.6334416406, 513946.6334416409, 134206.9373651471], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4438800.0000, 
sim time next is 4439400.0000, 
raw observation next is [23.16666666666667, 77.33333333333333, 1.0, 2.0, 0.4528364569371474, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 516424.3005388851, 516424.3005388851, 134564.4740044223], 
processed observation next is [0.0, 0.391304347826087, 0.6893939393939396, 0.7733333333333333, 1.0, 1.0, 0.3160455711714342, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19126825945884635, 0.19126825945884635, 0.32820603415712757], 
reward next is 0.6718, 
noisyNet noise sample is [array([1.4372755], dtype=float32), 0.35238278]. 
=============================================
[2019-03-22 22:56:17,011] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 3.869358e-37 8.650349e-24 8.747565e-19], sum to 1.0000
[2019-03-22 22:56:17,022] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2518
[2019-03-22 22:56:17,029] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.83333333333334, 70.66666666666667, 1.0, 2.0, 0.5232435374464531, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 595782.0606361036, 595782.0606361036, 145870.3612189721], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4453800.0000, 
sim time next is 4454400.0000, 
raw observation next is [25.66666666666667, 71.33333333333334, 1.0, 2.0, 0.5234923997765956, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 596190.3507727259, 596190.3507727257, 145801.2488793267], 
processed observation next is [0.0, 0.5652173913043478, 0.8030303030303032, 0.7133333333333334, 1.0, 1.0, 0.4043654997207444, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2208112410269355, 0.22081124102693542, 0.3556128021446993], 
reward next is 0.6444, 
noisyNet noise sample is [array([-0.11976085], dtype=float32), 0.7209921]. 
=============================================
[2019-03-22 22:56:20,156] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 7.3290133e-29 2.2651377e-28], sum to 1.0000
[2019-03-22 22:56:20,169] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1051
[2019-03-22 22:56:20,176] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.4115835389797709, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 466568.9707149618, 466568.9707149621, 127545.2985791925], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4510800.0000, 
sim time next is 4511400.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4113768146016772, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 466334.5678638094, 466334.5678638094, 127525.714095674], 
processed observation next is [0.0, 0.21739130434782608, 0.5, 1.0, 1.0, 1.0, 0.26422101825209643, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1727165066162257, 0.1727165066162257, 0.3110383270626195], 
reward next is 0.6890, 
noisyNet noise sample is [array([-1.8886302], dtype=float32), -0.47925612]. 
=============================================
[2019-03-22 22:56:21,475] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.00000000e+00 1.00000000e+00 1.98562143e-38 3.97920334e-28
 1.19876756e-29], sum to 1.0000
[2019-03-22 22:56:21,488] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4380
[2019-03-22 22:56:21,497] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.5000855555840359, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 570316.6669871402, 570316.6669871402, 142096.0399269016], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4528200.0000, 
sim time next is 4528800.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.5011842725540635, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 571569.7665009546, 571569.7665009544, 142225.7567633785], 
processed observation next is [0.0, 0.43478260869565216, 0.6363636363636364, 0.94, 1.0, 1.0, 0.37648034069257935, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21169250611146467, 0.2116925061114646, 0.34689208966677687], 
reward next is 0.6531, 
noisyNet noise sample is [array([-0.6445104], dtype=float32), -1.0447576]. 
=============================================
[2019-03-22 22:56:23,331] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 2.6260973e-32], sum to 1.0000
[2019-03-22 22:56:23,337] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8291
[2019-03-22 22:56:23,342] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 61.0, 1.0, 2.0, 0.394285823898136, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 445763.2176520425, 445763.2176520422, 125158.3583429876], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4557600.0000, 
sim time next is 4558200.0000, 
raw observation next is [23.66666666666667, 61.5, 1.0, 2.0, 0.3916464178770229, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 442134.3473048862, 442134.3473048862, 124540.634238768], 
processed observation next is [0.0, 0.782608695652174, 0.7121212121212124, 0.615, 1.0, 1.0, 0.23955802234627863, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16375346196477267, 0.16375346196477267, 0.3037576444848], 
reward next is 0.6962, 
noisyNet noise sample is [array([-0.11604779], dtype=float32), 2.0313673]. 
=============================================
[2019-03-22 22:56:32,870] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 9.9461192e-33 2.5337225e-26 3.0711038e-13], sum to 1.0000
[2019-03-22 22:56:32,879] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2217
[2019-03-22 22:56:32,884] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 61.33333333333333, 1.0, 2.0, 0.5300316826756711, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 575683.9979979505, 575683.9979979503, 129618.3491055833], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4701000.0000, 
sim time next is 4701600.0000, 
raw observation next is [21.0, 60.0, 1.0, 2.0, 0.5201519362201849, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 565164.3220961037, 565164.3220961037, 128770.2886701927], 
processed observation next is [1.0, 0.43478260869565216, 0.5909090909090909, 0.6, 1.0, 1.0, 0.40018992027523104, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20932011929485322, 0.20932011929485322, 0.31407387480534804], 
reward next is 0.6859, 
noisyNet noise sample is [array([-0.24700446], dtype=float32), 1.1700495]. 
=============================================
[2019-03-22 22:56:37,270] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 3.4574793e-37 2.3699226e-31 3.0286505e-28], sum to 1.0000
[2019-03-22 22:56:37,284] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2788
[2019-03-22 22:56:37,288] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 88.0, 1.0, 2.0, 0.3733073735179695, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 417253.5642220335, 417253.5642220338, 120820.615024676], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4762200.0000, 
sim time next is 4762800.0000, 
raw observation next is [19.0, 88.0, 1.0, 2.0, 0.3725841335426084, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 416434.4870345797, 416434.4870345797, 120755.520941281], 
processed observation next is [1.0, 0.13043478260869565, 0.5, 0.88, 1.0, 1.0, 0.21573016692826047, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15423499519799247, 0.15423499519799247, 0.2945256608323927], 
reward next is 0.7055, 
noisyNet noise sample is [array([0.24967954], dtype=float32), -0.2568065]. 
=============================================
[2019-03-22 22:56:40,637] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0015665e-35 1.0000000e+00 1.8750410e-32 1.3018175e-19 3.0703009e-17], sum to 1.0000
[2019-03-22 22:56:40,649] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9895
[2019-03-22 22:56:40,654] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.2922170487562445, 1.0, 1.0, 0.2922170487562445, 1.0, 2.0, 0.5919247585385456, 6.9112, 6.9112, 77.3421103, 995284.690843704, 995284.690843704, 257562.1207831599], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4806000.0000, 
sim time next is 4806600.0000, 
raw observation next is [22.0, 95.0, 1.0, 2.0, 0.8397288464402703, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846332382694, 956727.6273755782, 956727.6273755782, 191957.3641737721], 
processed observation next is [1.0, 0.6521739130434783, 0.6363636363636364, 0.95, 1.0, 1.0, 0.7996610580503379, 0.0, 0.5, -0.25, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.508428812133543, 0.3543435656946586, 0.3543435656946586, 0.46818869310676126], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.00033291], dtype=float32), 0.51797736]. 
=============================================
[2019-03-22 22:56:46,153] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 9.2646321e-37 5.0487776e-34 9.4793982e-26], sum to 1.0000
[2019-03-22 22:56:46,160] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0505
[2019-03-22 22:56:46,166] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 73.0, 1.0, 2.0, 0.451454307156508, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 490295.6098316061, 490295.6098316061, 122643.1556273166], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4970400.0000, 
sim time next is 4971000.0000, 
raw observation next is [19.0, 73.0, 1.0, 2.0, 0.4175922576878713, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 453503.0538684455, 453503.0538684452, 119854.6015666464], 
processed observation next is [1.0, 0.5217391304347826, 0.5, 0.73, 1.0, 1.0, 0.2719903221098391, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1679640940253502, 0.1679640940253501, 0.2923282965040156], 
reward next is 0.7077, 
noisyNet noise sample is [array([0.8943856], dtype=float32), -0.6934661]. 
=============================================
[2019-03-22 22:56:46,193] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[61.58395 ]
 [61.282448]
 [61.113346]
 [60.857037]
 [60.766857]], R is [[61.89448929]
 [61.97641373]
 [62.0402832 ]
 [62.09690475]
 [62.13264084]].
[2019-03-22 22:56:46,680] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 8.6514686e-32 7.0092042e-29 2.5531909e-22], sum to 1.0000
[2019-03-22 22:56:46,690] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0573
[2019-03-22 22:56:46,698] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 82.16666666666667, 1.0, 2.0, 0.9122416741472431, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1040238.859719652, 1040238.859719652, 197318.6827937914], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4889400.0000, 
sim time next is 4890000.0000, 
raw observation next is [22.0, 81.33333333333334, 1.0, 2.0, 0.908648665886109, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1035805.686494122, 1035805.686494122, 196246.1589008042], 
processed observation next is [1.0, 0.6086956521739131, 0.6363636363636364, 0.8133333333333335, 1.0, 1.0, 0.8858108323576364, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.38363173573856374, 0.38363173573856374, 0.478649168050742], 
reward next is 0.5214, 
noisyNet noise sample is [array([0.78116184], dtype=float32), 1.5439751]. 
=============================================
[2019-03-22 22:56:46,710] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[53.846535]
 [54.294014]
 [54.898746]
 [55.14989 ]
 [55.431885]], R is [[53.56997299]
 [53.55300903]
 [53.54636765]
 [53.57778168]
 [53.61346054]].
[2019-03-22 22:56:47,799] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.5290936e-36 1.0425047e-37], sum to 1.0000
[2019-03-22 22:56:47,808] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1453
[2019-03-22 22:56:47,818] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 94.0, 1.0, 2.0, 0.3915224532148444, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 441312.3786047756, 441312.3786047759, 124151.7704161575], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4919400.0000, 
sim time next is 4920000.0000, 
raw observation next is [18.66666666666667, 96.0, 1.0, 2.0, 0.3883494562087395, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 437259.0299480187, 437259.0299480187, 123616.1909732122], 
processed observation next is [1.0, 0.9565217391304348, 0.4848484848484851, 0.96, 1.0, 1.0, 0.23543682026092436, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16194778886963657, 0.16194778886963657, 0.3015029048127127], 
reward next is 0.6985, 
noisyNet noise sample is [array([-0.5581996], dtype=float32), -0.13935316]. 
=============================================
[2019-03-22 22:56:47,830] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[68.86029 ]
 [68.83788 ]
 [68.80896 ]
 [68.798546]
 [68.78707 ]], R is [[68.89043427]
 [68.89871979]
 [68.90536499]
 [68.91015625]
 [68.91321564]].
[2019-03-22 22:56:50,466] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.7227118e-31 2.6902906e-33], sum to 1.0000
[2019-03-22 22:56:50,470] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4303
[2019-03-22 22:56:50,477] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.66666666666666, 96.0, 1.0, 2.0, 0.3186770620333149, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 347715.9353761618, 347715.9353761618, 113042.6516407595], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4948800.0000, 
sim time next is 4949400.0000, 
raw observation next is [16.83333333333334, 95.0, 1.0, 2.0, 0.3230682688909025, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 352947.4073236616, 352947.4073236613, 113506.7247491548], 
processed observation next is [1.0, 0.2608695652173913, 0.40151515151515177, 0.95, 1.0, 1.0, 0.15383533611362812, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1307212619717265, 0.13072126197172643, 0.27684567011988975], 
reward next is 0.7232, 
noisyNet noise sample is [array([1.8368791], dtype=float32), -1.5093304]. 
=============================================
[2019-03-22 22:56:55,356] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 22:56:55,366] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8110
[2019-03-22 22:56:55,372] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 100.0, 1.0, 2.0, 0.2396032199161574, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 260156.1633263934, 260156.1633263934, 82221.0953935364], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5023800.0000, 
sim time next is 5024400.0000, 
raw observation next is [14.0, 100.0, 1.0, 2.0, 0.2403248374617912, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 260939.8907420854, 260939.8907420854, 82295.60234217563], 
processed observation next is [0.0, 0.13043478260869565, 0.2727272727272727, 1.0, 1.0, 1.0, 0.05040604682723899, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09664440397855015, 0.09664440397855015, 0.20072098132237956], 
reward next is 0.7993, 
noisyNet noise sample is [array([-2.095604], dtype=float32), 1.0653573]. 
=============================================
[2019-03-22 22:56:59,960] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.9390132e-33 1.7312512e-28], sum to 1.0000
[2019-03-22 22:56:59,971] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8813
[2019-03-22 22:56:59,977] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.83333333333334, 75.5, 1.0, 2.0, 0.4970978800757197, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 566506.8998635687, 566506.8998635684, 142264.4322041772], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5137800.0000, 
sim time next is 5138400.0000, 
raw observation next is [24.66666666666667, 77.0, 1.0, 2.0, 0.5006073544442183, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 570390.3987810084, 570390.3987810081, 142797.5310649717], 
processed observation next is [0.0, 0.4782608695652174, 0.7575757575757578, 0.77, 1.0, 1.0, 0.3757591930552729, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21125570325222534, 0.21125570325222523, 0.3482866611340773], 
reward next is 0.6517, 
noisyNet noise sample is [array([-1.9643605], dtype=float32), 0.7854725]. 
=============================================
[2019-03-22 22:57:05,202] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-22 22:57:05,205] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-22 22:57:05,207] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-22 22:57:05,207] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:57:05,207] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:57:05,208] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-22 22:57:05,211] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-22 22:57:05,212] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-22 22:57:05,212] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:57:05,215] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:57:05,214] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:57:05,235] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run15
[2019-03-22 22:57:05,253] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run15
[2019-03-22 22:57:05,271] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run15
[2019-03-22 22:57:05,294] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run15
[2019-03-22 22:57:05,310] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run15
[2019-03-22 22:57:41,313] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.34762833], dtype=float32), -0.14144413]
[2019-03-22 22:57:41,314] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [17.3, 51.0, 1.0, 2.0, 0.3109775985148606, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 337657.5163806478, 337657.5163806478, 85590.47077238429]
[2019-03-22 22:57:41,314] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 22:57:41,320] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 2.1943254e-35], sampled 0.5917436180073365
[2019-03-22 22:58:28,482] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.34762833], dtype=float32), -0.14144413]
[2019-03-22 22:58:28,482] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [25.3, 49.0, 1.0, 2.0, 0.3743337284839511, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 419634.8586446171, 419634.8586446175, 125795.7326900273]
[2019-03-22 22:58:28,482] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 22:58:28,484] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 5.3288606e-38], sampled 0.4621618472410668
[2019-03-22 22:58:31,119] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.34762833], dtype=float32), -0.14144413]
[2019-03-22 22:58:31,121] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [26.1, 56.5, 1.0, 2.0, 0.4407213397510574, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 501828.2810824841, 501828.2810824841, 136563.300434016]
[2019-03-22 22:58:31,122] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 22:58:31,125] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 2.0991092e-36], sampled 0.7126368266545873
[2019-03-22 22:58:31,926] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.34762833], dtype=float32), -0.14144413]
[2019-03-22 22:58:31,927] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [25.70057667, 63.28874145, 1.0, 2.0, 0.4824773330446243, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 550436.6983236442, 550436.6983236442, 142755.5430062443]
[2019-03-22 22:58:31,928] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 22:58:31,930] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 2.3366417e-34], sampled 0.8631613838068609
[2019-03-22 22:58:51,501] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.34762833], dtype=float32), -0.14144413]
[2019-03-22 22:58:51,502] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.76666666666667, 70.33333333333333, 1.0, 2.0, 0.3792224764391993, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 425854.6748331828, 425854.6748331828, 126567.8602739887]
[2019-03-22 22:58:51,503] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 22:58:51,507] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.8813996e-36], sampled 0.3344191765809773
[2019-03-22 22:58:59,686] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.34762833], dtype=float32), -0.14144413]
[2019-03-22 22:58:59,687] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [25.71699191333333, 41.61297087999999, 1.0, 2.0, 0.7910679885867222, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 877308.3888002393, 877308.3888002393, 168309.3960681349]
[2019-03-22 22:58:59,688] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 22:58:59,691] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 2.2022656e-36 4.3746278e-32 3.6794092e-25], sampled 0.5231941889034862
[2019-03-22 22:59:08,847] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9310 1705987275.5940 465.0000
[2019-03-22 22:59:08,919] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2494 1773207034.4548 173.0000
[2019-03-22 22:59:09,189] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3485 1683325900.1134 214.0000
[2019-03-22 22:59:09,297] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1147 1656209757.7786 80.0000
[2019-03-22 22:59:09,305] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5598 1663796639.0689 105.0000
[2019-03-22 22:59:10,323] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 350000, evaluation results [350000.0, 8512.249429056992, 1773207034.4547563, 173.0, 9061.114669779829, 1656209757.7786272, 80.0, 8856.559759326878, 1663796639.0688558, 105.0, 8596.931041181726, 1705987275.594041, 465.0, 8574.348472942609, 1683325900.1133502, 214.0]
[2019-03-22 22:59:18,118] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.3333976e-29 9.9999094e-01 8.0697472e-22 9.0597759e-06 2.1731579e-10], sum to 1.0000
[2019-03-22 22:59:18,131] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5635
[2019-03-22 22:59:18,136] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.03333333333333, 73.0, 1.0, 2.0, 0.3372064789246605, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 372113.1516304688, 372113.1516304688, 115881.8677688317], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5275200.0000, 
sim time next is 5275800.0000, 
raw observation next is [19.95, 73.0, 1.0, 2.0, 0.3314884391501637, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 365239.7284622306, 365239.7284622303, 115238.0096597298], 
processed observation next is [1.0, 0.043478260869565216, 0.5431818181818181, 0.73, 1.0, 1.0, 0.16436054893770458, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13527397350452985, 0.13527397350452974, 0.2810683162432434], 
reward next is 0.7189, 
noisyNet noise sample is [array([0.18058044], dtype=float32), -0.6042696]. 
=============================================
[2019-03-22 22:59:18,444] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.4669363e-30 1.5557128e-09 1.4309159e-22 9.5495775e-14 1.0000000e+00], sum to 1.0000
[2019-03-22 22:59:18,457] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3720
[2019-03-22 22:59:18,463] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [18.8, 89.0, 1.0, 2.0, 0.3488247498972732, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 389454.8216068432, 389454.8216068435, 118619.1428547765], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5286000.0000, 
sim time next is 5286600.0000, 
raw observation next is [18.8, 88.5, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 1.0, 0.3, 6.911199999999999, 6.9112, 77.3421103, 386382.6334656695, 386382.6334656698, 173405.1950875618], 
processed observation next is [1.0, 0.17391304347826086, 0.49090909090909096, 0.885, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 0.5, 0.0, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.1431046790613591, 0.14310467906135918, 0.42293950021356536], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0619277], dtype=float32), 0.0443161]. 
=============================================
[2019-03-22 22:59:18,936] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.7213813e-28 1.0000000e+00 5.2926686e-19 3.2973912e-09 3.1632170e-09], sum to 1.0000
[2019-03-22 22:59:18,951] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2025
[2019-03-22 22:59:18,955] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 88.0, 1.0, 2.0, 0.344817918708679, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 384382.3004495944, 384382.3004495944, 118034.0926126718], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5287200.0000, 
sim time next is 5287800.0000, 
raw observation next is [18.8, 87.5, 1.0, 2.0, 0.3433468143561927, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 382398.1299351614, 382398.1299351614, 117768.2579528532], 
processed observation next is [1.0, 0.17391304347826086, 0.49090909090909096, 0.875, 1.0, 1.0, 0.17918351794524084, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14162893701302273, 0.14162893701302273, 0.28723965354354436], 
reward next is 0.7128, 
noisyNet noise sample is [array([-2.4319599], dtype=float32), -1.1356223]. 
=============================================
[2019-03-22 22:59:24,010] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 8.5948745e-28 4.0125998e-21 2.8540648e-15], sum to 1.0000
[2019-03-22 22:59:24,019] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9636
[2019-03-22 22:59:24,024] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.11666666666667, 79.33333333333334, 1.0, 2.0, 0.4659635051582689, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 531633.2535090592, 531633.2535090592, 136582.0090406086], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5361000.0000, 
sim time next is 5361600.0000, 
raw observation next is [22.93333333333333, 79.66666666666667, 1.0, 2.0, 0.4624986099105453, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 527594.4086957108, 527594.4086957106, 135930.1338090384], 
processed observation next is [1.0, 0.043478260869565216, 0.6787878787878786, 0.7966666666666667, 1.0, 1.0, 0.3281232623881816, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19540533655396697, 0.19540533655396689, 0.33153691172936195], 
reward next is 0.6685, 
noisyNet noise sample is [array([0.06883572], dtype=float32), 1.7833048]. 
=============================================
[2019-03-22 22:59:34,051] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 5.521658e-32], sum to 1.0000
[2019-03-22 22:59:34,060] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3812
[2019-03-22 22:59:34,066] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.06666666666667, 63.66666666666667, 1.0, 2.0, 0.4794442009617305, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 547070.1049327882, 547070.1049327882, 138872.1390800025], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5512800.0000, 
sim time next is 5513400.0000, 
raw observation next is [25.8, 65.5, 1.0, 2.0, 0.481388225503187, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 549271.6752122573, 549271.675212257, 139199.9087801524], 
processed observation next is [1.0, 0.8260869565217391, 0.8090909090909091, 0.655, 1.0, 1.0, 0.35173528187898373, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20343395378231752, 0.2034339537823174, 0.339511972634518], 
reward next is 0.6605, 
noisyNet noise sample is [array([-0.5134418], dtype=float32), 1.5175436]. 
=============================================
[2019-03-22 22:59:34,598] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 6.3043310e-36 7.4966041e-30 2.1393147e-17], sum to 1.0000
[2019-03-22 22:59:34,607] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7285
[2019-03-22 22:59:34,616] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.15, 81.5, 1.0, 2.0, 0.4463129999856838, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 508438.2413994059, 508438.2413994059, 133053.3941472343], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5527800.0000, 
sim time next is 5528400.0000, 
raw observation next is [21.96666666666667, 82.33333333333334, 1.0, 2.0, 0.4439149907131262, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 505576.9033397907, 505576.9033397904, 132653.1193118897], 
processed observation next is [1.0, 1.0, 0.6348484848484849, 0.8233333333333335, 1.0, 1.0, 0.3048937383914077, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18725070494066323, 0.18725070494066312, 0.3235441934436334], 
reward next is 0.6765, 
noisyNet noise sample is [array([0.43555716], dtype=float32), 0.8369759]. 
=============================================
[2019-03-22 22:59:38,945] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 2.0832734e-37 0.0000000e+00 4.0979708e-30], sum to 1.0000
[2019-03-22 22:59:38,956] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6593
[2019-03-22 22:59:38,959] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.7, 82.0, 1.0, 2.0, 0.4393059081802318, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 499921.5128512738, 499921.5128512738, 131751.1010463098], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5597400.0000, 
sim time next is 5598000.0000, 
raw observation next is [20.5, 87.0, 1.0, 2.0, 0.4245287692314325, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 481669.434549061, 481669.434549061, 129077.6790261347], 
processed observation next is [1.0, 0.8260869565217391, 0.5681818181818182, 0.87, 1.0, 1.0, 0.2806609615392906, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1783960868700226, 0.1783960868700226, 0.31482360738081633], 
reward next is 0.6852, 
noisyNet noise sample is [array([0.23418014], dtype=float32), 0.06096115]. 
=============================================
[2019-03-22 22:59:38,971] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[49.053314]
 [48.71266 ]
 [48.438007]
 [47.590088]
 [46.90332 ]], R is [[49.88581085]
 [50.06560898]
 [50.23753357]
 [50.40172195]
 [50.5588913 ]].
[2019-03-22 22:59:42,853] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 5.4312150e-35 4.6321874e-27], sum to 1.0000
[2019-03-22 22:59:42,865] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4103
[2019-03-22 22:59:42,869] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.43333333333333, 97.0, 1.0, 2.0, 0.3842121643695404, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 432121.6260765143, 432121.6260765143, 123004.8795526978], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5635200.0000, 
sim time next is 5635800.0000, 
raw observation next is [18.25, 97.0, 1.0, 2.0, 0.3786374002901878, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 424959.6156763367, 424959.615676337, 122077.3357094135], 
processed observation next is [0.0, 0.21739130434782608, 0.4659090909090909, 0.97, 1.0, 1.0, 0.2232967503627347, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15739245025049506, 0.15739245025049517, 0.29774959929125244], 
reward next is 0.7023, 
noisyNet noise sample is [array([0.53229827], dtype=float32), 2.658701]. 
=============================================
[2019-03-22 22:59:43,135] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 9.703208e-31], sum to 1.0000
[2019-03-22 22:59:43,150] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3407
[2019-03-22 22:59:43,157] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.8, 88.0, 1.0, 2.0, 0.2578950711482401, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 280022.7902179685, 280022.7902179688, 88273.61305290573], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5661000.0000, 
sim time next is 5661600.0000, 
raw observation next is [15.9, 87.33333333333333, 1.0, 2.0, 0.2579427562230403, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 280074.5816400938, 280074.5816400941, 88509.1945888216], 
processed observation next is [0.0, 0.5217391304347826, 0.3590909090909091, 0.8733333333333333, 1.0, 1.0, 0.07242844527880037, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10373132653336808, 0.1037313265333682, 0.2158760843629795], 
reward next is 0.7841, 
noisyNet noise sample is [array([-0.37378153], dtype=float32), -0.30920306]. 
=============================================
[2019-03-22 22:59:44,926] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 1.624226e-37], sum to 1.0000
[2019-03-22 22:59:44,935] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1774
[2019-03-22 22:59:44,942] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.6, 74.0, 1.0, 2.0, 0.2116034279376582, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 229747.3947471854, 229747.3947471857, 74391.79374336688], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5677800.0000, 
sim time next is 5678400.0000, 
raw observation next is [15.7, 73.0, 1.0, 2.0, 0.21366325472341, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 231984.3750128008, 231984.3750128005, 74537.32473470323], 
processed observation next is [0.0, 0.7391304347826086, 0.35, 0.73, 1.0, 1.0, 0.01707906840426248, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08592013889362993, 0.08592013889362982, 0.1817983530114713], 
reward next is 0.8182, 
noisyNet noise sample is [array([0.77468544], dtype=float32), -0.88718665]. 
=============================================
[2019-03-22 23:00:00,307] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 2.0389639e-20], sum to 1.0000
[2019-03-22 23:00:00,318] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9122
[2019-03-22 23:00:00,327] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.2, 76.5, 1.0, 2.0, 0.2503044072005459, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 271778.5349785483, 271778.5349785483, 87907.36971247607], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5895000.0000, 
sim time next is 5895600.0000, 
raw observation next is [17.2, 76.0, 1.0, 2.0, 0.2481930609325699, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 269485.4168681987, 269485.4168681987, 87155.96487345401], 
processed observation next is [1.0, 0.21739130434782608, 0.41818181818181815, 0.76, 1.0, 1.0, 0.060241326165712365, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09980941365488842, 0.09980941365488842, 0.21257552408159514], 
reward next is 0.7874, 
noisyNet noise sample is [array([-1.0862964], dtype=float32), 2.24484]. 
=============================================
[2019-03-22 23:00:02,161] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.8897269e-38 1.0000000e+00 7.5021955e-34 9.7390754e-37 7.4355525e-27], sum to 1.0000
[2019-03-22 23:00:02,172] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4905
[2019-03-22 23:00:02,181] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.63333333333333, 51.33333333333334, 1.0, 2.0, 0.8416515847427172, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 957670.7667713922, 957670.7667713922, 183413.5135892179], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5923200.0000, 
sim time next is 5923800.0000, 
raw observation next is [26.9, 50.0, 1.0, 2.0, 0.8787530682669181, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 999982.4502289703, 999982.4502289703, 189390.0657191497], 
processed observation next is [1.0, 0.5652173913043478, 0.859090909090909, 0.5, 1.0, 1.0, 0.8484413353336475, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.37036387045517416, 0.37036387045517416, 0.46192698955890166], 
reward next is 0.5381, 
noisyNet noise sample is [array([-0.44262847], dtype=float32), -0.07514109]. 
=============================================
[2019-03-22 23:00:14,283] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-22 23:00:14,284] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-22 23:00:14,285] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:00:14,286] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-22 23:00:14,287] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-22 23:00:14,288] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:00:14,288] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:00:14,291] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-22 23:00:14,292] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-22 23:00:14,293] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:00:14,294] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:00:14,319] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run16
[2019-03-22 23:00:14,336] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run16
[2019-03-22 23:00:14,338] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run16
[2019-03-22 23:00:14,388] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run16
[2019-03-22 23:00:14,389] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run16
[2019-03-22 23:00:29,559] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.5896836], dtype=float32), 0.08843139]
[2019-03-22 23:00:29,560] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.0, 94.0, 1.0, 2.0, 0.3883298200932211, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 437734.1677225465, 437734.1677225465, 123879.1313302246]
[2019-03-22 23:00:29,564] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:00:29,567] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.3342135e-29], sampled 0.9978800508667045
[2019-03-22 23:00:52,297] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.5896836], dtype=float32), 0.08843139]
[2019-03-22 23:00:52,299] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.24964065, 73.118169765, 1.0, 2.0, 0.2783562634490807, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 302228.5703753644, 302228.5703753644, 101882.0407258049]
[2019-03-22 23:00:52,301] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:00:52,304] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 3.2182426e-36], sampled 0.577116775862122
[2019-03-22 23:01:10,067] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.5896836], dtype=float32), 0.08843139]
[2019-03-22 23:01:10,069] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [23.23758114333333, 91.01657463666666, 1.0, 2.0, 0.5456882703671553, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 620109.4012401093, 620109.4012401093, 153697.9387202508]
[2019-03-22 23:01:10,069] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:01:10,074] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 9.6862906e-27], sampled 0.20110750753403106
[2019-03-22 23:01:25,427] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.5896836], dtype=float32), 0.08843139]
[2019-03-22 23:01:25,430] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.178321485, 94.21691036499999, 1.0, 2.0, 0.3223183604178075, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 349974.8296093236, 349974.8296093236, 114443.9167293482]
[2019-03-22 23:01:25,433] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:01:25,438] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 3.7275869e-31], sampled 0.015315977790933522
[2019-03-22 23:02:17,401] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-22 23:02:17,486] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9513 1705935940.2592 465.0000
[2019-03-22 23:02:17,673] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1148 1656229146.4555 80.0000
[2019-03-22 23:02:17,706] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2494 1773207034.4548 173.0000
[2019-03-22 23:02:17,752] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3791 1683296663.2329 214.0000
[2019-03-22 23:02:18,767] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 375000, evaluation results [375000.0, 8512.249429056992, 1773207034.4547563, 173.0, 9061.114827412715, 1656229146.4555063, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8596.951295847348, 1705935940.259201, 465.0, 8574.379088229873, 1683296663.232874, 214.0]
[2019-03-22 23:02:31,102] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.3025458e-35 1.0935288e-28], sum to 1.0000
[2019-03-22 23:02:31,114] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3149
[2019-03-22 23:02:31,119] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.2, 87.0, 1.0, 2.0, 0.4681175417543252, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 534133.1537381273, 534133.1537381273, 137025.6336151569], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6328800.0000, 
sim time next is 6329400.0000, 
raw observation next is [22.28333333333333, 87.0, 1.0, 2.0, 0.4701628329898694, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 536483.7820127475, 536483.7820127471, 137381.8144449272], 
processed observation next is [0.0, 0.2608695652173913, 0.6492424242424242, 0.87, 1.0, 1.0, 0.3377035412373367, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19869769704175833, 0.1986976970417582, 0.3350775962071395], 
reward next is 0.6649, 
noisyNet noise sample is [array([-0.09026147], dtype=float32), 0.3647951]. 
=============================================
[2019-03-22 23:02:36,104] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 2.3683138e-31], sum to 1.0000
[2019-03-22 23:02:36,111] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8697
[2019-03-22 23:02:36,116] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.2, 67.0, 1.0, 2.0, 0.550042919360701, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 623976.0803555283, 623976.0803555286, 150485.0832039163], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6352800.0000, 
sim time next is 6353400.0000, 
raw observation next is [27.2, 67.0, 1.0, 2.0, 0.550490128503446, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 624483.2287971501, 624483.2287971501, 150542.7905304362], 
processed observation next is [0.0, 0.5217391304347826, 0.8727272727272727, 0.67, 1.0, 1.0, 0.4381126606293075, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2312900847396852, 0.2312900847396852, 0.3671775378791127], 
reward next is 0.6328, 
noisyNet noise sample is [array([-0.88067096], dtype=float32), 0.69400215]. 
=============================================
[2019-03-22 23:02:38,315] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.00000000e+00 1.00000000e+00 0.00000000e+00 1.09775037e-35
 1.19323796e-29], sum to 1.0000
[2019-03-22 23:02:38,325] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4044
[2019-03-22 23:02:38,331] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 76.0, 1.0, 2.0, 0.5306374092415602, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 604106.6554694513, 604106.6554694513, 146853.6684796929], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6386400.0000, 
sim time next is 6387000.0000, 
raw observation next is [25.0, 76.0, 1.0, 2.0, 0.5270084509968368, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 600051.6713762527, 600051.6713762527, 146347.2077498414], 
processed observation next is [0.0, 0.9565217391304348, 0.7727272727272727, 0.76, 1.0, 1.0, 0.40876056374604597, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22224135976898246, 0.22224135976898246, 0.3569444091459546], 
reward next is 0.6431, 
noisyNet noise sample is [array([-0.02497444], dtype=float32), -0.031062204]. 
=============================================
[2019-03-22 23:02:38,343] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[61.373203]
 [61.36045 ]
 [61.364452]
 [61.368515]
 [61.376255]], R is [[61.39836502]
 [61.42620087]
 [61.45139313]
 [61.47423172]
 [61.49502182]].
[2019-03-22 23:02:41,424] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.5794504e-30 1.4177487e-25 1.3088682e-27], sum to 1.0000
[2019-03-22 23:02:41,440] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4946
[2019-03-22 23:02:41,449] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.43333333333333, 97.66666666666667, 1.0, 2.0, 0.6454321332224735, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 727851.0400586452, 727851.0400586452, 151163.1067690374], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6441600.0000, 
sim time next is 6442200.0000, 
raw observation next is [18.25, 96.5, 1.0, 2.0, 0.685815237600987, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 771109.5708998215, 771109.5708998211, 155091.8846550043], 
processed observation next is [1.0, 0.5652173913043478, 0.4659090909090909, 0.965, 1.0, 1.0, 0.6072690470012336, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.28559613737030426, 0.2855961373703041, 0.3782728894024495], 
reward next is 0.6217, 
noisyNet noise sample is [array([-0.00640877], dtype=float32), 1.1844528]. 
=============================================
[2019-03-22 23:02:42,601] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.2776102e-32 1.0656486e-37], sum to 1.0000
[2019-03-22 23:02:42,612] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5627
[2019-03-22 23:02:42,619] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 72.33333333333334, 1.0, 2.0, 0.3568955481932563, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 393536.5653918713, 393536.5653918713, 117268.8249083241], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6456000.0000, 
sim time next is 6456600.0000, 
raw observation next is [20.0, 71.0, 1.0, 2.0, 0.3431822689477147, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 377000.5856255842, 377000.5856255842, 115694.5253542133], 
processed observation next is [1.0, 0.7391304347826086, 0.5454545454545454, 0.71, 1.0, 1.0, 0.17897783618464336, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13962984652799415, 0.13962984652799415, 0.2821817691566178], 
reward next is 0.7178, 
noisyNet noise sample is [array([-0.28759637], dtype=float32), -1.1717846]. 
=============================================
[2019-03-22 23:02:49,881] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.3775319e-36 3.8245704e-37], sum to 1.0000
[2019-03-22 23:02:49,890] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0571
[2019-03-22 23:02:49,897] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.81666666666667, 69.66666666666667, 1.0, 2.0, 0.2220422816768761, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 241084.1384045786, 241084.1384045788, 74669.809151459], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6567000.0000, 
sim time next is 6567600.0000, 
raw observation next is [15.53333333333333, 72.33333333333334, 1.0, 2.0, 0.2191455298933444, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 237938.198271567, 237938.1982715668, 74503.39042978284], 
processed observation next is [1.0, 0.0, 0.34242424242424224, 0.7233333333333334, 1.0, 1.0, 0.02393191236668049, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0881252586190989, 0.08812525861909881, 0.18171558641410449], 
reward next is 0.8183, 
noisyNet noise sample is [array([0.9977669], dtype=float32), -0.8109942]. 
=============================================
[2019-03-22 23:03:10,053] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 3.582259e-37 0.000000e+00], sum to 1.0000
[2019-03-22 23:03:10,066] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1176
[2019-03-22 23:03:10,077] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.66666666666667, 83.0, 1.0, 2.0, 0.3859867166942655, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 436057.7829173497, 436057.7829173494, 124216.844483614], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6856800.0000, 
sim time next is 6857400.0000, 
raw observation next is [21.13333333333334, 80.5, 1.0, 2.0, 0.3906567917194714, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 441856.3276353395, 441856.3276353395, 124949.6191654665], 
processed observation next is [0.0, 0.34782608695652173, 0.5969696969696973, 0.805, 1.0, 1.0, 0.2383209896493392, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1636504917167924, 0.1636504917167924, 0.30475516869625974], 
reward next is 0.6952, 
noisyNet noise sample is [array([0.30671066], dtype=float32), -0.26976442]. 
=============================================
[2019-03-22 23:03:17,264] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 3.694659e-38 9.498861e-36 2.864264e-29], sum to 1.0000
[2019-03-22 23:03:17,274] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5841
[2019-03-22 23:03:17,277] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.7, 58.0, 1.0, 2.0, 0.4967064981049163, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 566314.1229057565, 566314.1229057565, 141917.8560337452], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6956400.0000, 
sim time next is 6957000.0000, 
raw observation next is [27.7, 58.0, 1.0, 2.0, 0.4972360187250106, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 566917.837599674, 566917.837599674, 141980.2583644099], 
processed observation next is [0.0, 0.5217391304347826, 0.8954545454545454, 0.58, 1.0, 1.0, 0.3715450234062632, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20996956948136075, 0.20996956948136075, 0.3462933130839266], 
reward next is 0.6537, 
noisyNet noise sample is [array([0.52875865], dtype=float32), -0.7539013]. 
=============================================
[2019-03-22 23:03:17,296] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[67.677956]
 [67.61442 ]
 [67.56492 ]
 [67.51405 ]
 [67.47973 ]], R is [[67.72125244]
 [67.69789886]
 [67.67488098]
 [67.6524353 ]
 [67.63121796]].
[2019-03-22 23:03:21,259] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 8.252151e-37], sum to 1.0000
[2019-03-22 23:03:21,271] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4343
[2019-03-22 23:03:21,281] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 96.0, 1.0, 2.0, 0.4328517320730246, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 490583.7373656559, 490583.7373656556, 129522.880800824], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7017600.0000, 
sim time next is 7018200.0000, 
raw observation next is [19.4, 96.0, 1.0, 2.0, 0.4164821455198286, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 471978.468900367, 471978.468900367, 127912.8348188421], 
processed observation next is [1.0, 0.21739130434782608, 0.5181818181818181, 0.96, 1.0, 1.0, 0.2706026818997857, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17480684033346924, 0.17480684033346924, 0.3119825239483954], 
reward next is 0.6880, 
noisyNet noise sample is [array([0.91550446], dtype=float32), 1.4888232]. 
=============================================
[2019-03-22 23:03:22,227] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 6.6264470e-35 1.7367701e-33 4.7009236e-32], sum to 1.0000
[2019-03-22 23:03:22,235] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9036
[2019-03-22 23:03:22,239] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.3, 91.5, 1.0, 2.0, 0.3579503458705839, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 398541.8136338969, 398541.8136338966, 118876.7831089272], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7079400.0000, 
sim time next is 7080000.0000, 
raw observation next is [18.3, 91.0, 1.0, 2.0, 0.3549638959779459, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 394882.5952383589, 394882.5952383587, 118496.5870456925], 
processed observation next is [1.0, 0.9565217391304348, 0.4681818181818182, 0.91, 1.0, 1.0, 0.1937048699724324, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14625281305124405, 0.14625281305124396, 0.28901606596510365], 
reward next is 0.7110, 
noisyNet noise sample is [array([0.01547741], dtype=float32), 1.6641523]. 
=============================================
[2019-03-22 23:03:22,256] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[59.62194 ]
 [59.606857]
 [59.595745]
 [59.589577]
 [59.56186 ]], R is [[59.7541275 ]
 [59.866642  ]
 [59.97714615]
 [60.08575439]
 [60.19246674]].
[2019-03-22 23:03:22,704] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-22 23:03:22,706] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-22 23:03:22,707] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:03:22,709] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-22 23:03:22,712] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-22 23:03:22,714] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:03:22,713] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-22 23:03:22,715] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:03:22,718] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:03:22,717] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-22 23:03:22,721] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:03:22,744] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run17
[2019-03-22 23:03:22,745] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run17
[2019-03-22 23:03:22,782] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run17
[2019-03-22 23:03:22,800] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run17
[2019-03-22 23:03:22,801] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run17
[2019-03-22 23:05:16,159] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.5759985], dtype=float32), 0.10377901]
[2019-03-22 23:05:16,161] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.73660413, 93.83919522333333, 1.0, 2.0, 0.3425950574946798, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 379748.2294900888, 379748.2294900888, 121269.9632795155]
[2019-03-22 23:05:16,162] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:05:16,165] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.5903861e-37 3.3886582e-34], sampled 0.6328780540425122
[2019-03-22 23:05:25,151] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-22 23:05:25,500] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2492 1773187030.7201 173.0000
[2019-03-22 23:05:25,799] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-22 23:05:25,938] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5599 1663815647.6096 105.0000
[2019-03-22 23:05:25,951] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9309 1705967916.6745 465.0000
[2019-03-22 23:05:26,969] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 400000, evaluation results [400000.0, 8512.249193409023, 1773187030.7201214, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8856.559925897878, 1663815647.6095803, 105.0, 8596.930884973775, 1705967916.6744611, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-22 23:05:29,356] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.2691143e-37 0.0000000e+00], sum to 1.0000
[2019-03-22 23:05:29,364] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6414
[2019-03-22 23:05:29,368] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 92.0, 1.0, 2.0, 0.3803812412426033, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 426480.7519735183, 426480.7519735183, 122018.9246141035], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7072800.0000, 
sim time next is 7073400.0000, 
raw observation next is [18.8, 92.5, 1.0, 2.0, 0.3811428879522196, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 427635.4516747369, 427635.4516747372, 122227.2655873203], 
processed observation next is [1.0, 0.8695652173913043, 0.49090909090909096, 0.925, 1.0, 1.0, 0.2264286099402745, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15838350062027293, 0.15838350062027304, 0.2981152819202934], 
reward next is 0.7019, 
noisyNet noise sample is [array([-1.5916107], dtype=float32), -1.5607474]. 
=============================================
[2019-03-22 23:05:38,219] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 5.2603803e-35 6.6831167e-25 2.5531909e-22], sum to 1.0000
[2019-03-22 23:05:38,229] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8234
[2019-03-22 23:05:38,234] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.9, 67.0, 1.0, 2.0, 0.4031471280923986, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 437808.6538219318, 437808.6538219318, 100427.6633211725], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7202400.0000, 
sim time next is 7203000.0000, 
raw observation next is [18.35, 65.0, 1.0, 2.0, 0.4156810941984856, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 451426.5765175346, 451426.5765175346, 102911.3263784887], 
processed observation next is [1.0, 0.34782608695652173, 0.4704545454545455, 0.65, 1.0, 1.0, 0.26960136774810695, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16719502833982763, 0.16719502833982763, 0.25100323506948463], 
reward next is 0.7490, 
noisyNet noise sample is [array([1.5690349], dtype=float32), 0.5968492]. 
=============================================
[2019-03-22 23:05:38,248] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[55.917305]
 [55.964935]
 [56.154232]
 [56.31739 ]
 [56.281826]], R is [[56.16145706]
 [56.35489655]
 [56.55562973]
 [56.77378845]
 [57.01044083]].
[2019-03-22 23:05:44,405] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.5640688e-38 1.0000000e+00 1.7792827e-37 3.4581345e-32 1.8191773e-31], sum to 1.0000
[2019-03-22 23:05:44,414] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4403
[2019-03-22 23:05:44,419] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 46.0, 1.0, 2.0, 0.4642284765516339, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 515373.3937662491, 515373.3937662491, 127524.4245233088], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7304400.0000, 
sim time next is 7305000.0000, 
raw observation next is [25.18333333333334, 45.5, 1.0, 2.0, 0.5630220458679718, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 625691.989744781, 625691.989744781, 137496.6502664478], 
processed observation next is [1.0, 0.5652173913043478, 0.7810606060606063, 0.455, 1.0, 1.0, 0.45377755733496467, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23173777397954853, 0.23173777397954853, 0.335357683576702], 
reward next is 0.6646, 
noisyNet noise sample is [array([-0.54404616], dtype=float32), 0.17301801]. 
=============================================
[2019-03-22 23:05:44,439] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[80.10618 ]
 [80.0718  ]
 [80.14822 ]
 [80.121254]
 [79.68755 ]], R is [[79.66173553]
 [79.55408478]
 [79.43929291]
 [79.33068085]
 [79.22848511]].
[2019-03-22 23:05:49,607] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.6615635e-30 3.4226211e-32 6.4726721e-28], sum to 1.0000
[2019-03-22 23:05:49,623] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9414
[2019-03-22 23:05:49,628] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666666, 71.16666666666667, 1.0, 2.0, 0.8692718157800038, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 986604.6346777448, 986604.6346777448, 185763.6218621689], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7377000.0000, 
sim time next is 7377600.0000, 
raw observation next is [23.13333333333333, 69.33333333333334, 1.0, 2.0, 0.8241360033544222, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 936358.1759241133, 936358.1759241135, 179536.7853590552], 
processed observation next is [1.0, 0.391304347826087, 0.6878787878787876, 0.6933333333333335, 1.0, 1.0, 0.7801700041930276, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.34679932441633826, 0.3467993244163383, 0.43789459843672], 
reward next is 0.5621, 
noisyNet noise sample is [array([-0.8151597], dtype=float32), 2.1460211]. 
=============================================
[2019-03-22 23:05:51,691] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:05:51,701] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1523
[2019-03-22 23:05:51,707] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.16666666666667, 68.0, 1.0, 2.0, 0.4791114716166387, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 546665.227444737, 546665.227444737, 138976.5654148711], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7406400.0000, 
sim time next is 7407000.0000, 
raw observation next is [24.15, 72.0, 1.0, 2.0, 0.4443708584850745, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 506986.7386376961, 506986.7386376961, 134270.2380343258], 
processed observation next is [1.0, 0.7391304347826086, 0.734090909090909, 0.72, 1.0, 1.0, 0.3054635731063431, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18777286616210967, 0.18777286616210967, 0.3274883854495751], 
reward next is 0.6725, 
noisyNet noise sample is [array([0.5898989], dtype=float32), -0.96201634]. 
=============================================
[2019-03-22 23:05:51,719] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[52.832733]
 [50.786278]
 [47.952206]
 [47.57752 ]
 [47.74209 ]], R is [[53.74087524]
 [53.86450195]
 [53.79047012]
 [53.41415405]
 [53.13178635]].
[2019-03-22 23:05:52,158] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:05:52,169] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3182
[2019-03-22 23:05:52,178] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.6, 83.66666666666667, 1.0, 2.0, 0.4376473911660486, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 498025.2525524452, 498025.2525524452, 131576.1662350282], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7413000.0000, 
sim time next is 7413600.0000, 
raw observation next is [21.6, 83.33333333333334, 1.0, 2.0, 0.4391496702711206, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 499640.4693795475, 499640.4693795475, 131636.304487179], 
processed observation next is [1.0, 0.8260869565217391, 0.6181818181818183, 0.8333333333333335, 1.0, 1.0, 0.2989370878389007, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18505202569612872, 0.18505202569612872, 0.32106415728580245], 
reward next is 0.6789, 
noisyNet noise sample is [array([-1.6000453], dtype=float32), -0.5832828]. 
=============================================
[2019-03-22 23:05:56,519] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.8008410e-36 2.4941832e-34 6.3323914e-27], sum to 1.0000
[2019-03-22 23:05:56,531] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9922
[2019-03-22 23:05:56,538] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.15, 65.0, 1.0, 2.0, 0.5327459462694448, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 605695.1948700343, 605695.1948700347, 147636.8027553156], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7475400.0000, 
sim time next is 7476000.0000, 
raw observation next is [27.33333333333334, 63.66666666666667, 1.0, 2.0, 0.530969659239717, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 603845.5365854681, 603845.5365854681, 147316.7683450024], 
processed observation next is [0.0, 0.5217391304347826, 0.878787878787879, 0.6366666666666667, 1.0, 1.0, 0.41371207404964616, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22364649503165485, 0.22364649503165485, 0.35930919108537174], 
reward next is 0.6407, 
noisyNet noise sample is [array([0.06306286], dtype=float32), -0.34380022]. 
=============================================
[2019-03-22 23:05:56,547] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[65.17934 ]
 [65.17891 ]
 [65.19615 ]
 [65.229996]
 [65.257904]], R is [[65.18223572]
 [65.1703186 ]
 [65.15822601]
 [65.14659882]
 [65.13640594]].
[2019-03-22 23:05:56,996] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:05:57,006] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7519
[2019-03-22 23:05:57,009] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.36666666666667, 61.16666666666667, 1.0, 2.0, 0.4783238998506125, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 545808.2865918113, 545808.2865918113, 138544.2010422015], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7494600.0000, 
sim time next is 7495200.0000, 
raw observation next is [26.1, 62.0, 1.0, 2.0, 0.4752412647219403, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 542285.1186328741, 542285.1186328741, 137985.1391010228], 
processed observation next is [0.0, 0.782608695652174, 0.8227272727272728, 0.62, 1.0, 1.0, 0.3440515809024253, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20084634023439782, 0.20084634023439782, 0.3365491197585922], 
reward next is 0.6635, 
noisyNet noise sample is [array([-0.4011638], dtype=float32), -0.61392814]. 
=============================================
[2019-03-22 23:06:04,891] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.6293746e-32 4.4977048e-29], sum to 1.0000
[2019-03-22 23:06:04,901] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3016
[2019-03-22 23:06:04,906] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.05, 96.0, 1.0, 2.0, 0.4364758971397096, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 496616.6179523598, 496616.6179523601, 131385.0327189366], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7597800.0000, 
sim time next is 7598400.0000, 
raw observation next is [20.06666666666667, 96.0, 1.0, 2.0, 0.4366455857491289, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 496849.2294847692, 496849.2294847689, 131440.2816305559], 
processed observation next is [0.0, 0.9565217391304348, 0.5484848484848487, 0.96, 1.0, 1.0, 0.29580698218641105, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18401823314250712, 0.18401823314250698, 0.3205860527574534], 
reward next is 0.6794, 
noisyNet noise sample is [array([-0.69587594], dtype=float32), 0.16424441]. 
=============================================
[2019-03-22 23:06:10,410] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 1.115756e-36], sum to 1.0000
[2019-03-22 23:06:10,421] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3352
[2019-03-22 23:06:10,426] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 87.66666666666667, 1.0, 2.0, 0.4801964000530251, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 547941.5427234143, 547941.5427234146, 138837.3613164925], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7676400.0000, 
sim time next is 7677000.0000, 
raw observation next is [22.15, 89.0, 1.0, 2.0, 0.480173045748175, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 547916.299239073, 547916.299239073, 138814.8170976414], 
processed observation next is [1.0, 0.8695652173913043, 0.6431818181818181, 0.89, 1.0, 1.0, 0.3502163071852187, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20293196268113814, 0.20293196268113814, 0.33857272462839366], 
reward next is 0.6614, 
noisyNet noise sample is [array([-1.1365945], dtype=float32), -0.88111097]. 
=============================================
[2019-03-22 23:06:10,455] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[69.43242]
 [69.34048]
 [69.55903]
 [69.91324]
 [69.78653]], R is [[69.29374695]
 [69.26217651]
 [69.2305603 ]
 [69.19868469]
 [69.16629791]].
[2019-03-22 23:06:18,538] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:06:18,546] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4014
[2019-03-22 23:06:18,554] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.73333333333333, 78.0, 1.0, 2.0, 0.2581353653524849, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 280283.7771472135, 280283.7771472135, 86620.47034872555], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7804200.0000, 
sim time next is 7804800.0000, 
raw observation next is [17.2, 75.0, 1.0, 2.0, 0.2772305623653217, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 301023.7881197027, 301023.7881197027, 89284.79496065024], 
processed observation next is [1.0, 0.34782608695652173, 0.41818181818181815, 0.75, 1.0, 1.0, 0.09653820295665208, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11149029189618619, 0.11149029189618619, 0.2177677925869518], 
reward next is 0.7822, 
noisyNet noise sample is [array([-0.5486742], dtype=float32), 0.19579393]. 
=============================================
[2019-03-22 23:06:23,650] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:06:23,651] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:06:23,700] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run3
[2019-03-22 23:06:26,529] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:06:26,530] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:06:26,569] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run3
[2019-03-22 23:06:28,246] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:06:28,246] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:06:28,256] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run3
[2019-03-22 23:06:28,331] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:06:28,331] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:06:28,338] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run3
[2019-03-22 23:06:28,420] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:06:28,420] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:06:28,432] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run3
[2019-03-22 23:06:28,597] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:06:28,597] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:06:28,606] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run3
[2019-03-22 23:06:28,686] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:06:28,687] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:06:28,693] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run3
[2019-03-22 23:06:28,894] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:06:28,895] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:06:28,904] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run3
[2019-03-22 23:06:28,958] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:06:28,958] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:06:28,965] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run3
[2019-03-22 23:06:28,983] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:06:28,984] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:06:28,989] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:06:28,990] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:06:28,999] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run3
[2019-03-22 23:06:29,018] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:06:29,019] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:06:29,022] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run3
[2019-03-22 23:06:29,037] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:06:29,039] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:06:29,039] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:06:29,041] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:06:29,045] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run3
[2019-03-22 23:06:29,066] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run3
[2019-03-22 23:06:29,081] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:06:29,081] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:06:29,087] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run3
[2019-03-22 23:06:29,104] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run3
[2019-03-22 23:06:29,125] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:06:29,126] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:06:29,127] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run3
[2019-03-22 23:06:30,212] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-22 23:06:30,213] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-22 23:06:30,219] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-22 23:06:30,221] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:06:30,221] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-22 23:06:30,222] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:06:30,223] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:06:30,226] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run18
[2019-03-22 23:06:30,241] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-22 23:06:30,243] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:06:30,244] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run18
[2019-03-22 23:06:30,264] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-22 23:06:30,265] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:06:30,266] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run18
[2019-03-22 23:06:30,283] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run18
[2019-03-22 23:06:30,305] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run18
[2019-03-22 23:06:39,870] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.35270676], dtype=float32), 0.007890927]
[2019-03-22 23:06:39,874] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.76768779, 69.79145202999999, 1.0, 2.0, 0.3932264669581655, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 436444.1581301268, 436444.1581301264, 125551.7064330988]
[2019-03-22 23:06:39,874] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:06:39,877] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.07830342858250394
[2019-03-22 23:07:14,940] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.35270676], dtype=float32), 0.007890927]
[2019-03-22 23:07:14,941] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [30.84513682666667, 66.25025775333333, 1.0, 2.0, 0.757932195183162, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9684127518861766, 6.936314787157817, 6.9112, 95.55330086476866, 1400248.244836741, 1390169.08142027, 310197.5627974763]
[2019-03-22 23:07:14,943] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:07:14,946] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.9728037278510062
[2019-03-22 23:07:14,947] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1400248.244836741 W.
[2019-03-22 23:07:31,652] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.35270676], dtype=float32), 0.007890927]
[2019-03-22 23:07:31,653] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [25.46666666666667, 54.66666666666667, 1.0, 2.0, 0.4054421548634141, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 459301.1135418376, 459301.1135418373, 131094.6228738112]
[2019-03-22 23:07:31,653] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:07:31,655] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.1709685979928528
[2019-03-22 23:07:39,207] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.35270676], dtype=float32), 0.007890927]
[2019-03-22 23:07:39,208] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [29.76666666666667, 58.66666666666667, 1.0, 2.0, 0.8066018456570228, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9823142678909691, 6.91690230676235, 6.9112, 95.55334016325322, 1455021.366212855, 1452732.893490188, 320697.5273697834]
[2019-03-22 23:07:39,210] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:07:39,213] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.13370469712059252
[2019-03-22 23:07:39,216] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1455021.366212855 W.
[2019-03-22 23:08:07,344] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.35270676], dtype=float32), 0.007890927]
[2019-03-22 23:08:07,349] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.8, 65.0, 1.0, 2.0, 0.7399584999928879, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 834530.2526303837, 834530.252630384, 163379.8761383714]
[2019-03-22 23:08:07,350] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:08:07,353] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.6908579688418149
[2019-03-22 23:08:27,937] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.35270676], dtype=float32), 0.007890927]
[2019-03-22 23:08:27,937] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.98333333333333, 56.83333333333333, 1.0, 2.0, 0.371199399105191, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 417015.211197045, 417015.211197045, 125966.4482468061]
[2019-03-22 23:08:27,937] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:08:27,942] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.3579749024034372
[2019-03-22 23:08:33,734] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1147 1656209757.7786 80.0000
[2019-03-22 23:08:33,905] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3485 1683325900.1134 214.0000
[2019-03-22 23:08:34,271] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2492 1773187030.7201 173.0000
[2019-03-22 23:08:34,305] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9309 1705967916.6745 465.0000
[2019-03-22 23:08:34,327] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5598 1663796639.0689 105.0000
[2019-03-22 23:08:35,342] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 425000, evaluation results [425000.0, 8512.249193409023, 1773187030.7201214, 173.0, 9061.114669779829, 1656209757.7786272, 80.0, 8856.559759326878, 1663796639.0688558, 105.0, 8596.930884973775, 1705967916.6744611, 465.0, 8574.348472942609, 1683325900.1133502, 214.0]
[2019-03-22 23:08:41,991] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 6.3543584e-36], sum to 1.0000
[2019-03-22 23:08:42,002] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4605
[2019-03-22 23:08:42,009] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 45.33333333333334, 1.0, 2.0, 0.5034682804334641, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 546816.4268587272, 546816.4268587272, 117563.5642722662], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 134400.0000, 
sim time next is 135000.0000, 
raw observation next is [22.5, 45.0, 1.0, 2.0, 0.549294069083331, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 596618.3193232376, 596618.3193232379, 123414.1199568784], 
processed observation next is [1.0, 0.5652173913043478, 0.6590909090909091, 0.45, 1.0, 1.0, 0.4366175863541637, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22096974789749543, 0.22096974789749552, 0.30101004867531317], 
reward next is 0.6990, 
noisyNet noise sample is [array([-0.68398094], dtype=float32), 0.56329036]. 
=============================================
[2019-03-22 23:08:42,019] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[63.687725]
 [63.844772]
 [64.005486]
 [63.8176  ]
 [63.657116]], R is [[63.40542984]
 [63.48463821]
 [63.57130051]
 [63.6699791 ]
 [63.76899719]].
[2019-03-22 23:08:42,643] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.00000e+00 1.00000e+00 0.00000e+00 0.00000e+00 7.46462e-36], sum to 1.0000
[2019-03-22 23:08:42,651] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1875
[2019-03-22 23:08:42,656] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.16666666666667, 81.16666666666667, 1.0, 2.0, 0.2179299627227795, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 236618.0699777342, 236618.0699777339, 71552.29938191458], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 105000.0000, 
sim time next is 105600.0000, 
raw observation next is [13.33333333333333, 80.33333333333334, 1.0, 2.0, 0.2040620959460709, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 221557.5653196349, 221557.5653196349, 70616.69212668146], 
processed observation next is [1.0, 0.21739130434782608, 0.2424242424242423, 0.8033333333333335, 1.0, 1.0, 0.005077619932588595, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.0820583575257907, 0.0820583575257907, 0.17223583445532065], 
reward next is 0.8278, 
noisyNet noise sample is [array([-0.9627044], dtype=float32), 1.4682075]. 
=============================================
[2019-03-22 23:08:46,491] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:08:46,500] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8077
[2019-03-22 23:08:46,506] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 214612.8955391621, 214612.8955391624, 72657.42617681305], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 187200.0000, 
sim time next is 187800.0000, 
raw observation next is [13.83333333333333, 89.00000000000001, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 214108.1917454251, 214108.1917454248, 72418.21090997373], 
processed observation next is [0.0, 0.17391304347826086, 0.265151515151515, 0.8900000000000001, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07929933027608338, 0.07929933027608325, 0.176629782707253], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.2858346], dtype=float32), 2.4573042]. 
=============================================
[2019-03-22 23:08:53,451] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:08:53,463] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9665
[2019-03-22 23:08:53,470] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.5, 60.0, 1.0, 2.0, 0.2358030444268437, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 256028.926264074, 256028.926264074, 86538.04332669434], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 300600.0000, 
sim time next is 301200.0000, 
raw observation next is [19.66666666666666, 58.66666666666666, 1.0, 2.0, 0.2384791834871076, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 258935.3832114004, 258935.3832114002, 86528.41864877228], 
processed observation next is [0.0, 0.4782608695652174, 0.53030303030303, 0.5866666666666666, 1.0, 1.0, 0.04809897935888447, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09590199378200015, 0.09590199378200008, 0.21104492353359092], 
reward next is 0.7890, 
noisyNet noise sample is [array([1.4961138], dtype=float32), -1.3006798]. 
=============================================
[2019-03-22 23:08:56,460] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:08:56,461] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3185
[2019-03-22 23:08:56,469] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.33333333333334, 78.0, 1.0, 2.0, 0.3338839464651738, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 368405.8839521983, 368405.883952198, 115617.1847371731], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 589200.0000, 
sim time next is 589800.0000, 
raw observation next is [19.16666666666667, 78.0, 1.0, 2.0, 0.329323214129508, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 362372.2059997437, 362372.2059997437, 114895.1213015903], 
processed observation next is [1.0, 0.8260869565217391, 0.5075757575757578, 0.78, 1.0, 1.0, 0.16165401766188497, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13421192814805322, 0.13421192814805322, 0.2802320031746105], 
reward next is 0.7198, 
noisyNet noise sample is [array([-1.1826538], dtype=float32), -0.95750517]. 
=============================================
[2019-03-22 23:08:58,513] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.7768911e-37 1.8872652e-36], sum to 1.0000
[2019-03-22 23:08:58,525] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0763
[2019-03-22 23:08:58,532] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.66666666666667, 70.0, 1.0, 2.0, 0.4020820652749905, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 436651.5003234555, 436651.5003234555, 86871.54180559152], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 354000.0000, 
sim time next is 354600.0000, 
raw observation next is [12.5, 71.5, 1.0, 2.0, 0.4041894618642209, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 438941.1156739252, 438941.1156739252, 87395.81485484118], 
processed observation next is [1.0, 0.08695652173913043, 0.20454545454545456, 0.715, 1.0, 1.0, 0.2552368273302761, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16257078358293525, 0.16257078358293525, 0.213160524036198], 
reward next is 0.7868, 
noisyNet noise sample is [array([1.0329367], dtype=float32), 0.26230633]. 
=============================================
[2019-03-22 23:09:14,271] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:09:14,278] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0641
[2019-03-22 23:09:14,283] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.33333333333334, 93.00000000000001, 1.0, 2.0, 0.3886544649159174, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 438634.255897726, 438634.2558977258, 124204.0760112324], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 799800.0000, 
sim time next is 800400.0000, 
raw observation next is [19.66666666666667, 92.0, 1.0, 2.0, 0.3950171694603548, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 446675.0952701232, 446675.0952701232, 125276.7800462557], 
processed observation next is [0.0, 0.2608695652173913, 0.5303030303030305, 0.92, 1.0, 1.0, 0.2437714618254435, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.165435220470416, 0.165435220470416, 0.3055531220640383], 
reward next is 0.6944, 
noisyNet noise sample is [array([-1.0065681], dtype=float32), 1.2576011]. 
=============================================
[2019-03-22 23:09:16,247] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:09:16,259] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4159
[2019-03-22 23:09:16,264] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 83.0, 1.0, 2.0, 0.3090515487600479, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 336381.7657014254, 336381.7657014257, 112079.4184215995], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 599400.0000, 
sim time next is 600000.0000, 
raw observation next is [18.0, 83.0, 1.0, 2.0, 0.3082229669572233, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 335473.6806785108, 335473.6806785105, 112020.6322384634], 
processed observation next is [1.0, 0.9565217391304348, 0.45454545454545453, 0.83, 1.0, 1.0, 0.13527870869652908, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12424951136241141, 0.1242495113624113, 0.27322105424015464], 
reward next is 0.7268, 
noisyNet noise sample is [array([0.42389], dtype=float32), -0.26638213]. 
=============================================
[2019-03-22 23:09:16,283] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[71.98976]
 [71.99468]
 [72.00576]
 [72.02775]
 [72.03265]], R is [[71.99108124]
 [71.99781036]
 [72.00423431]
 [72.01037598]
 [72.01647949]].
[2019-03-22 23:09:18,815] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 5.1636188e-34 1.6661899e-31], sum to 1.0000
[2019-03-22 23:09:18,822] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4831
[2019-03-22 23:09:18,834] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 78.0, 1.0, 2.0, 0.5463303557785397, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 608946.6629538839, 608946.6629538842, 136462.1287462997], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 637200.0000, 
sim time next is 637800.0000, 
raw observation next is [20.33333333333334, 76.5, 1.0, 2.0, 0.6315616232192878, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 705701.734411776, 705701.734411776, 146500.2643616847], 
processed observation next is [1.0, 0.391304347826087, 0.5606060606060609, 0.765, 1.0, 1.0, 0.5394520290241097, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2613710127451022, 0.2613710127451022, 0.3573177179553286], 
reward next is 0.6427, 
noisyNet noise sample is [array([0.14068647], dtype=float32), -0.5001565]. 
=============================================
[2019-03-22 23:09:26,954] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.7050206e-37], sum to 1.0000
[2019-03-22 23:09:26,964] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2316
[2019-03-22 23:09:26,972] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 69.0, 1.0, 2.0, 0.4454684337838318, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 507457.4713057235, 507457.4713057235, 132944.0150970208], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 772200.0000, 
sim time next is 772800.0000, 
raw observation next is [24.0, 69.0, 1.0, 2.0, 0.4439931461398561, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 505774.9920237183, 505774.9920237183, 132790.3793027496], 
processed observation next is [1.0, 0.9565217391304348, 0.7272727272727273, 0.69, 1.0, 1.0, 0.30499143267482004, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18732407111989566, 0.18732407111989566, 0.3238789739091454], 
reward next is 0.6761, 
noisyNet noise sample is [array([1.6020788], dtype=float32), 0.12450355]. 
=============================================
[2019-03-22 23:09:34,314] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.4486387e-38 0.0000000e+00], sum to 1.0000
[2019-03-22 23:09:34,323] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9122
[2019-03-22 23:09:34,331] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.66666666666667, 84.83333333333334, 1.0, 2.0, 0.4143074187384453, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 469293.7190316743, 469293.7190316743, 127560.360537297], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 864600.0000, 
sim time next is 865200.0000, 
raw observation next is [20.33333333333334, 86.66666666666667, 1.0, 2.0, 0.4116634911824745, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 465949.9574798418, 465949.9574798418, 127087.0489482878], 
processed observation next is [0.0, 0.0, 0.5606060606060609, 0.8666666666666667, 1.0, 1.0, 0.26457936397809306, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17257405832586734, 0.17257405832586734, 0.30996841206899467], 
reward next is 0.6900, 
noisyNet noise sample is [array([0.07169473], dtype=float32), 0.62372017]. 
=============================================
[2019-03-22 23:09:39,299] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-22 23:09:39,300] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-22 23:09:39,302] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-22 23:09:39,304] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-22 23:09:39,305] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:09:39,306] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-22 23:09:39,306] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:09:39,303] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-22 23:09:39,309] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:09:39,311] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:09:39,312] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:09:39,328] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run19
[2019-03-22 23:09:39,346] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run19
[2019-03-22 23:09:39,347] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run19
[2019-03-22 23:09:39,379] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run19
[2019-03-22 23:09:39,415] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run19
[2019-03-22 23:10:00,340] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.09092371], dtype=float32), -0.04644357]
[2019-03-22 23:10:00,340] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.286405595, 95.00363825, 1.0, 2.0, 0.3580785179508121, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 399910.7228236995, 399910.7228236991, 123741.573160617]
[2019-03-22 23:10:00,340] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:10:00,342] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 5.4215094e-34 2.3377805e-36], sampled 0.1841077388004817
[2019-03-22 23:10:15,332] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.09092371], dtype=float32), -0.04644357]
[2019-03-22 23:10:15,333] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [12.57986897666667, 83.415708775, 1.0, 2.0, 0.2048311561777582, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 222383.0565306139, 222383.0565306135, 74457.44290726542]
[2019-03-22 23:10:15,336] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:10:15,340] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.2253353e-34 2.5968243e-36], sampled 0.3150669772775997
[2019-03-22 23:10:31,808] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.09092371], dtype=float32), -0.04644357]
[2019-03-22 23:10:31,811] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [23.948106085, 56.38086945, 1.0, 2.0, 0.3705959474940336, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 416053.1598851246, 416053.1598851242, 125773.8050496885]
[2019-03-22 23:10:31,813] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:10:31,815] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.38351898820141606
[2019-03-22 23:10:33,840] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.09092371], dtype=float32), -0.04644357]
[2019-03-22 23:10:33,840] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.24845036666667, 90.1464837, 1.0, 2.0, 0.4856226834693103, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 554023.987325473, 554023.9873254726, 144086.0619225822]
[2019-03-22 23:10:33,841] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:10:33,844] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.9427322e-33 1.0435767e-34], sampled 0.009650532114204746
[2019-03-22 23:10:51,753] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.09092371], dtype=float32), -0.04644357]
[2019-03-22 23:10:51,754] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [15.14112696, 88.43382073, 1.0, 2.0, 0.2653664505711165, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 288121.3484403372, 288121.3484403368, 89554.74078993405]
[2019-03-22 23:10:51,756] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:10:51,759] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.6153464e-35 6.8799544e-37], sampled 0.346825945228286
[2019-03-22 23:11:43,026] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1147 1656209757.7786 80.0000
[2019-03-22 23:11:43,105] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2492 1773187030.7201 173.0000
[2019-03-22 23:11:43,431] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-22 23:11:43,440] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3485 1683325900.1134 214.0000
[2019-03-22 23:11:43,468] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5599 1663815647.6096 105.0000
[2019-03-22 23:11:44,482] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 450000, evaluation results [450000.0, 8512.249193409023, 1773187030.7201214, 173.0, 9061.114669779829, 1656209757.7786272, 80.0, 8856.559925897878, 1663815647.6095803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8574.348472942609, 1683325900.1133502, 214.0]
[2019-03-22 23:11:49,248] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.8066267e-37 1.3215440e-23 1.2226313e-20], sum to 1.0000
[2019-03-22 23:11:49,258] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7407
[2019-03-22 23:11:49,265] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 95.0, 1.0, 2.0, 0.2538127178594478, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 275588.9100510245, 275588.9100510248, 77222.12043549075], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1044600.0000, 
sim time next is 1045200.0000, 
raw observation next is [13.0, 96.0, 1.0, 2.0, 0.2331403962920159, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 253137.1385556061, 253137.1385556058, 76114.36011376113], 
processed observation next is [1.0, 0.08695652173913043, 0.22727272727272727, 0.96, 1.0, 1.0, 0.041425495365019875, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0937544957613356, 0.09375449576133549, 0.18564478076527105], 
reward next is 0.8144, 
noisyNet noise sample is [array([-0.5638809], dtype=float32), 0.5881535]. 
=============================================
[2019-03-22 23:11:50,618] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.7465992e-30 9.8127318e-36], sum to 1.0000
[2019-03-22 23:11:50,629] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8623
[2019-03-22 23:11:50,637] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.2183762793758613, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 237102.7776516576, 237102.7776516579, 75565.10749927536], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1026000.0000, 
sim time next is 1026600.0000, 
raw observation next is [13.0, 99.00000000000001, 1.0, 2.0, 0.2171047667991586, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 235721.8940763198, 235721.8940763195, 75130.6892695007], 
processed observation next is [1.0, 0.9130434782608695, 0.22727272727272727, 0.9900000000000001, 1.0, 1.0, 0.021380958498948242, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08730440521345177, 0.08730440521345166, 0.18324558358414805], 
reward next is 0.8168, 
noisyNet noise sample is [array([-0.21229918], dtype=float32), -1.626335]. 
=============================================
[2019-03-22 23:11:52,233] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 6.5114036e-36 6.7636701e-34], sum to 1.0000
[2019-03-22 23:11:52,245] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2729
[2019-03-22 23:11:52,251] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.2103458055161532, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 228381.616741498, 228381.616741498, 74711.9384266465], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1050000.0000, 
sim time next is 1050600.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.2106566671909558, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 228719.2121773427, 228719.212177343, 74739.9931597964], 
processed observation next is [1.0, 0.13043478260869565, 0.22727272727272727, 1.0, 1.0, 1.0, 0.013320833988694734, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08471081932494175, 0.08471081932494184, 0.18229266624340587], 
reward next is 0.8177, 
noisyNet noise sample is [array([1.0075573], dtype=float32), 0.3448099]. 
=============================================
[2019-03-22 23:11:56,154] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.2635772e-32 0.0000000e+00], sum to 1.0000
[2019-03-22 23:11:56,164] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2386
[2019-03-22 23:11:56,175] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 88.0, 1.0, 2.0, 0.4723908245916151, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 538987.4454171299, 538987.4454171297, 137360.7091459497], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1377600.0000, 
sim time next is 1378200.0000, 
raw observation next is [22.0, 88.0, 1.0, 2.0, 0.4718678408199585, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 538390.3324297393, 538390.3324297395, 137302.8325949929], 
processed observation next is [1.0, 0.9565217391304348, 0.6363636363636364, 0.88, 1.0, 1.0, 0.33983480102494806, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19940382682582936, 0.19940382682582947, 0.3348849575487632], 
reward next is 0.6651, 
noisyNet noise sample is [array([-1.120786], dtype=float32), -2.214473]. 
=============================================
[2019-03-22 23:12:06,855] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.5709440e-35 8.7439354e-25 2.2719004e-32], sum to 1.0000
[2019-03-22 23:12:06,867] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5317
[2019-03-22 23:12:06,872] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.16666666666667, 99.0, 1.0, 2.0, 0.3497153406719635, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 387578.0292217608, 387578.0292217605, 117478.4418744882], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1302600.0000, 
sim time next is 1303200.0000, 
raw observation next is [17.0, 100.0, 1.0, 2.0, 0.3485047797178193, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 385853.2730918831, 385853.2730918831, 117231.7214344386], 
processed observation next is [1.0, 0.08695652173913043, 0.4090909090909091, 1.0, 1.0, 1.0, 0.1856309746472741, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14290861966366042, 0.14290861966366042, 0.28593102788887464], 
reward next is 0.7141, 
noisyNet noise sample is [array([-0.06697569], dtype=float32), 0.2991508]. 
=============================================
[2019-03-22 23:12:10,992] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.9895899e-35 1.0000000e+00 5.9205169e-29 1.5354349e-23 1.2979735e-28], sum to 1.0000
[2019-03-22 23:12:11,001] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1349
[2019-03-22 23:12:11,011] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1235461.939800404 W.
[2019-03-22 23:12:11,017] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.83333333333333, 89.0, 1.0, 2.0, 0.549416963803102, 1.0, 2.0, 0.549416963803102, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846344338547, 1235461.939800404, 1235461.939800404, 248166.9251075019], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1331400.0000, 
sim time next is 1332000.0000, 
raw observation next is [24.0, 89.0, 1.0, 2.0, 0.4073206814525417, 1.0, 2.0, 0.4073206814525417, 1.0, 1.0, 0.8234247699309626, 6.9112, 6.9112, 77.3421103, 1374067.340135716, 1374067.340135716, 310527.2434566068], 
processed observation next is [1.0, 0.43478260869565216, 0.7272727272727273, 0.89, 1.0, 1.0, 0.2591508518156771, 1.0, 1.0, 0.2591508518156771, 1.0, 0.5, 0.7477496713299467, 0.0, 0.0, 0.5085185399722538, 0.5089138296798947, 0.5089138296798947, 0.7573835206258702], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2292497], dtype=float32), 0.60330045]. 
=============================================
[2019-03-22 23:12:11,035] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[53.43446 ]
 [53.454365]
 [52.791275]
 [53.009007]
 [53.41864 ]], R is [[52.39860153]
 [52.26932907]
 [52.03957367]
 [51.82157516]
 [51.69940567]].
[2019-03-22 23:12:14,446] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.2068565e-37 2.9178582e-31], sum to 1.0000
[2019-03-22 23:12:14,456] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9055
[2019-03-22 23:12:14,463] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 88.0, 1.0, 2.0, 0.4725131786463901, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 539127.2168520706, 539127.2168520706, 137374.6078489301], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1377000.0000, 
sim time next is 1377600.0000, 
raw observation next is [22.0, 88.0, 1.0, 2.0, 0.4723908245916151, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 538987.4454171299, 538987.4454171297, 137360.7091459497], 
processed observation next is [1.0, 0.9565217391304348, 0.6363636363636364, 0.88, 1.0, 1.0, 0.3404885307395188, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1996249797841222, 0.1996249797841221, 0.33502611986817], 
reward next is 0.6650, 
noisyNet noise sample is [array([-1.5646554], dtype=float32), -0.83789366]. 
=============================================
[2019-03-22 23:12:23,072] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.4270612e-38 2.5528304e-37], sum to 1.0000
[2019-03-22 23:12:23,082] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1500
[2019-03-22 23:12:23,087] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.5, 74.5, 1.0, 2.0, 0.6191868178795072, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 695813.4065992214, 695813.4065992214, 161599.2810034892], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1510200.0000, 
sim time next is 1510800.0000, 
raw observation next is [27.66666666666666, 73.0, 1.0, 2.0, 0.6147844078796242, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 690862.6657883872, 690862.6657883872, 160973.3350896789], 
processed observation next is [0.0, 0.4782608695652174, 0.8939393939393937, 0.73, 1.0, 1.0, 0.5184805098495302, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.25587506140310634, 0.25587506140310634, 0.39261789046263146], 
reward next is 0.6074, 
noisyNet noise sample is [array([1.2663888], dtype=float32), 2.9554083]. 
=============================================
[2019-03-22 23:12:23,584] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:12:23,595] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9204
[2019-03-22 23:12:23,600] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 83.0, 1.0, 2.0, 0.5280178341762001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 600927.1305036757, 600927.1305036757, 146669.6466276669], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1537200.0000, 
sim time next is 1537800.0000, 
raw observation next is [23.83333333333333, 83.0, 1.0, 2.0, 0.5195216299752871, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 591708.3866010632, 591708.3866010634, 145281.41620854], 
processed observation next is [0.0, 0.8260869565217391, 0.7196969696969695, 0.83, 1.0, 1.0, 0.3994020374691088, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21915125429669008, 0.21915125429669016, 0.35434491758180486], 
reward next is 0.6457, 
noisyNet noise sample is [array([-0.47442287], dtype=float32), 1.0469052]. 
=============================================
[2019-03-22 23:12:27,117] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 3.3073766e-38 2.0893309e-36 9.9059298e-36], sum to 1.0000
[2019-03-22 23:12:27,126] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7119
[2019-03-22 23:12:27,131] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.4133360006749084, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 468596.3374331864, 468596.3374331864, 127739.1804569113], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1567200.0000, 
sim time next is 1567800.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4118452584959689, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 466881.7560643575, 466881.7560643578, 127581.0889667423], 
processed observation next is [1.0, 0.13043478260869565, 0.5, 1.0, 1.0, 1.0, 0.26480657311996114, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17291916891272502, 0.17291916891272513, 0.31117338772376174], 
reward next is 0.6888, 
noisyNet noise sample is [array([0.9237818], dtype=float32), -0.57100195]. 
=============================================
[2019-03-22 23:12:29,269] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.7341600e-35 1.0000000e+00 2.3100909e-32 8.7569632e-23 1.2712843e-24], sum to 1.0000
[2019-03-22 23:12:29,282] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5809
[2019-03-22 23:12:29,290] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 77.33333333333333, 1.0, 2.0, 0.435104706808237, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 494981.2308277451, 494981.2308277451, 131175.3896127745], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1626600.0000, 
sim time next is 1627200.0000, 
raw observation next is [22.0, 78.0, 1.0, 2.0, 0.4246618138523647, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 482499.4537468406, 482499.4537468406, 129611.0896374595], 
processed observation next is [1.0, 0.8695652173913043, 0.6363636363636364, 0.78, 1.0, 1.0, 0.2808272673154558, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17870350138771873, 0.17870350138771873, 0.31612460887185245], 
reward next is 0.6839, 
noisyNet noise sample is [array([0.8312749], dtype=float32), 0.810271]. 
=============================================
[2019-03-22 23:12:45,597] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-22 23:12:45,600] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-22 23:12:45,602] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-22 23:12:45,602] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:12:45,603] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:12:45,604] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-22 23:12:45,603] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-22 23:12:45,607] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:12:45,605] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-22 23:12:45,608] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:12:45,609] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:12:45,625] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run20
[2019-03-22 23:12:45,625] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run20
[2019-03-22 23:12:45,625] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run20
[2019-03-22 23:12:45,670] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run20
[2019-03-22 23:12:45,683] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run20
[2019-03-22 23:12:48,349] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02594814], dtype=float32), -0.046146687]
[2019-03-22 23:12:48,351] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.3, 32.0, 1.0, 2.0, 0.44993097003302, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 488593.5493708466, 488593.5493708462, 106441.0005949644]
[2019-03-22 23:12:48,353] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:12:48,359] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 5.277195e-38], sampled 0.6137254659568837
[2019-03-22 23:12:50,209] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02594814], dtype=float32), -0.046146687]
[2019-03-22 23:12:50,211] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [14.0, 100.0, 1.0, 2.0, 0.2165895910683857, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 235162.4058737841, 235162.4058737838, 79659.84258211734]
[2019-03-22 23:12:50,212] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:12:50,214] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.1463789e-38 2.2843751e-36], sampled 0.4675540411706145
[2019-03-22 23:13:08,507] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02594814], dtype=float32), -0.046146687]
[2019-03-22 23:13:08,509] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.21778486833333, 48.02931000833334, 1.0, 2.0, 0.3413304408389755, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 376812.5780538575, 376812.5780538572, 120566.6641757672]
[2019-03-22 23:13:08,510] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:13:08,513] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.8909325985853228
[2019-03-22 23:13:12,068] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02594814], dtype=float32), -0.046146687]
[2019-03-22 23:13:12,070] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [13.63333333333333, 75.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 212654.1571905318, 212654.1571905321, 73584.85464166896]
[2019-03-22 23:13:12,071] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:13:12,073] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 8.513026e-38], sampled 0.6530911250782051
[2019-03-22 23:13:39,076] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02594814], dtype=float32), -0.046146687]
[2019-03-22 23:13:39,077] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [26.03333333333333, 67.0, 1.0, 2.0, 0.5170655484794257, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 589440.5643561084, 589440.5643561081, 148676.3315607735]
[2019-03-22 23:13:39,079] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:13:39,084] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 7.824884e-36], sampled 0.11501011583269427
[2019-03-22 23:13:49,667] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02594814], dtype=float32), -0.046146687]
[2019-03-22 23:13:49,669] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.39027531, 89.79195553000001, 1.0, 2.0, 0.3279986302175271, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 362705.3821372176, 362705.3821372173, 119811.5873147149]
[2019-03-22 23:13:49,670] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:13:49,672] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 5.1326581e-38 4.1071116e-37], sampled 0.4303824041716684
[2019-03-22 23:14:11,463] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02594814], dtype=float32), -0.046146687]
[2019-03-22 23:14:11,464] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [10.98157264, 98.95865333666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 189767.3627816797, 189767.3627816793, 69302.44390893966]
[2019-03-22 23:14:11,465] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:14:11,471] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 4.5549913e-38], sampled 0.28200803430924215
[2019-03-22 23:14:24,004] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02594814], dtype=float32), -0.046146687]
[2019-03-22 23:14:24,005] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.94296631166667, 100.0, 1.0, 2.0, 0.4343583063937161, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 494729.7689429778, 494729.7689429775, 136090.4820948377]
[2019-03-22 23:14:24,006] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:14:24,011] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 3.989218e-36], sampled 0.16051668306831046
[2019-03-22 23:14:29,679] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5598 1663796639.0689 105.0000
[2019-03-22 23:14:29,750] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9513 1705935940.2592 465.0000
[2019-03-22 23:14:29,829] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2492 1773187030.7201 173.0000
[2019-03-22 23:14:29,926] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3485 1683325900.1134 214.0000
[2019-03-22 23:14:29,953] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-22 23:14:30,970] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 475000, evaluation results [475000.0, 8512.249193409023, 1773187030.7201214, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8856.559759326878, 1663796639.0688558, 105.0, 8596.951295847348, 1705935940.259201, 465.0, 8574.348472942609, 1683325900.1133502, 214.0]
[2019-03-22 23:14:42,185] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.7667405e-37 0.0000000e+00], sum to 1.0000
[2019-03-22 23:14:42,193] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1449
[2019-03-22 23:14:42,198] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 62.0, 1.0, 2.0, 0.2644885912613343, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 287184.1563457995, 287184.1563457995, 88203.91022268523], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2068200.0000, 
sim time next is 2068800.0000, 
raw observation next is [19.0, 61.33333333333334, 1.0, 2.0, 0.2640895725558325, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 286750.7704217014, 286750.7704217017, 87476.38076381951], 
processed observation next is [0.0, 0.9565217391304348, 0.5, 0.6133333333333334, 1.0, 1.0, 0.0801119656947906, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1062039890450746, 0.1062039890450747, 0.21335702625321834], 
reward next is 0.7866, 
noisyNet noise sample is [array([0.04145205], dtype=float32), 0.15931888]. 
=============================================
[2019-03-22 23:14:50,214] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 7.7062393e-30 2.3685458e-26 6.3131986e-25], sum to 1.0000
[2019-03-22 23:14:50,222] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2022
[2019-03-22 23:14:50,231] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 88.0, 1.0, 2.0, 0.2068176744543286, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 224550.0867219673, 224550.086721967, 73866.35059509781], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2259000.0000, 
sim time next is 2259600.0000, 
raw observation next is [14.0, 86.0, 1.0, 2.0, 0.2007183842717476, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 217926.3638899961, 217926.3638899961, 72695.78707766421], 
processed observation next is [1.0, 0.13043478260869565, 0.2727272727272727, 0.86, 1.0, 1.0, 0.0008979803396844815, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08071346810740597, 0.08071346810740597, 0.1773067977504005], 
reward next is 0.8227, 
noisyNet noise sample is [array([1.4539864], dtype=float32), 0.12522188]. 
=============================================
[2019-03-22 23:14:55,019] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 3.323688e-33], sum to 1.0000
[2019-03-22 23:14:55,031] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9427
[2019-03-22 23:14:55,035] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 50.33333333333334, 1.0, 2.0, 0.4432515561294963, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 481382.7166398385, 481382.7166398385, 102728.5243073171], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2298000.0000, 
sim time next is 2298600.0000, 
raw observation next is [20.0, 51.0, 1.0, 2.0, 0.4382627629221416, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 475962.1052652029, 475962.1052652029, 102608.0105089959], 
processed observation next is [1.0, 0.6086956521739131, 0.5454545454545454, 0.51, 1.0, 1.0, 0.29782845365267696, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1762822612093344, 0.1762822612093344, 0.25026344026584363], 
reward next is 0.7497, 
noisyNet noise sample is [array([0.94939536], dtype=float32), 0.15732403]. 
=============================================
[2019-03-22 23:14:56,016] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 2.8203290e-38 2.4077314e-30 3.1123268e-18], sum to 1.0000
[2019-03-22 23:14:56,027] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3060
[2019-03-22 23:14:56,033] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 49.0, 1.0, 2.0, 0.66783722568083, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 729005.7919091202, 729005.7919091198, 144653.7262074559], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2560800.0000, 
sim time next is 2561400.0000, 
raw observation next is [23.0, 48.5, 1.0, 2.0, 0.6752108454484443, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 735933.8831511517, 735933.8831511517, 145121.9819652691], 
processed observation next is [1.0, 0.6521739130434783, 0.6818181818181818, 0.485, 1.0, 1.0, 0.5940135568105553, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2725681048707969, 0.2725681048707969, 0.3539560535738271], 
reward next is 0.6460, 
noisyNet noise sample is [array([-0.60088164], dtype=float32), -0.15724476]. 
=============================================
[2019-03-22 23:14:59,294] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.6517396e-34 2.4887334e-37], sum to 1.0000
[2019-03-22 23:14:59,304] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1441
[2019-03-22 23:14:59,309] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 94.0, 1.0, 2.0, 0.2256888858049184, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 245044.4646382963, 245044.4646382965, 77859.71286907907], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2422800.0000, 
sim time next is 2423400.0000, 
raw observation next is [14.0, 93.00000000000001, 1.0, 2.0, 0.222592565278794, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 241681.7615560542, 241681.7615560539, 77139.50474541729], 
processed observation next is [1.0, 0.043478260869565216, 0.2727272727272727, 0.9300000000000002, 1.0, 1.0, 0.028240706598492496, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08951176353927934, 0.08951176353927923, 0.18814513352540801], 
reward next is 0.8119, 
noisyNet noise sample is [array([1.1458817], dtype=float32), -1.0412465]. 
=============================================
[2019-03-22 23:15:06,603] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 7.463001e-35], sum to 1.0000
[2019-03-22 23:15:06,613] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3835
[2019-03-22 23:15:06,616] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 73.83333333333333, 1.0, 2.0, 0.4352927615585795, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 495440.4586287397, 495440.4586287397, 131433.9917251087], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2757000.0000, 
sim time next is 2757600.0000, 
raw observation next is [23.0, 73.0, 1.0, 2.0, 0.4306256816267961, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 489852.8281156737, 489852.8281156737, 130697.7673557353], 
processed observation next is [0.0, 0.9565217391304348, 0.6818181818181818, 0.73, 1.0, 1.0, 0.2882821020334951, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18142697337617544, 0.18142697337617544, 0.3187750423310617], 
reward next is 0.6812, 
noisyNet noise sample is [array([0.8625165], dtype=float32), 0.75084484]. 
=============================================
[2019-03-22 23:15:13,799] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.8053979e-36 1.0000000e+00 1.2131509e-32 1.7941971e-28 6.2938303e-21], sum to 1.0000
[2019-03-22 23:15:13,806] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9256
[2019-03-22 23:15:13,818] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1362366.21834463 W.
[2019-03-22 23:15:13,823] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.0, 74.0, 1.0, 2.0, 0.7197102007623072, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9810377492881246, 6.911199999999999, 6.9112, 77.32846344354104, 1362366.21834463, 1362366.21834463, 298625.4493343608], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2884800.0000, 
sim time next is 2885400.0000, 
raw observation next is [26.0, 74.0, 1.0, 2.0, 0.7563668047223268, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9810620813301292, 6.9112, 6.9112, 77.32846344354104, 1403852.008748179, 1403852.008748179, 304482.1864427709], 
processed observation next is [1.0, 0.391304347826087, 0.8181818181818182, 0.74, 1.0, 1.0, 0.6954585059029084, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9729458304716131, 0.0, 0.0, 0.5084288129206541, 0.5199451884252515, 0.5199451884252515, 0.7426394791287094], 
reward next is 0.2574, 
noisyNet noise sample is [array([0.16645823], dtype=float32), 1.1536307]. 
=============================================
[2019-03-22 23:15:15,895] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 2.4420418e-36], sum to 1.0000
[2019-03-22 23:15:15,904] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1826
[2019-03-22 23:15:15,910] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.13333333333333, 86.5, 1.0, 2.0, 0.3337410210009448, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 367219.0439096661, 367219.0439096658, 115215.2644516828], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2688600.0000, 
sim time next is 2689200.0000, 
raw observation next is [18.0, 87.0, 1.0, 2.0, 0.3313946150528904, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 364161.6539481933, 364161.6539481935, 114864.6702881015], 
processed observation next is [0.0, 0.13043478260869565, 0.45454545454545453, 0.87, 1.0, 1.0, 0.164243268816113, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.134874686647479, 0.13487468664747906, 0.28015773241000363], 
reward next is 0.7198, 
noisyNet noise sample is [array([0.86742425], dtype=float32), 0.5668009]. 
=============================================
[2019-03-22 23:15:16,245] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.2499447e-31 1.1318880e-28], sum to 1.0000
[2019-03-22 23:15:16,255] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6924
[2019-03-22 23:15:16,261] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.33333333333333, 95.83333333333334, 1.0, 2.0, 0.3901628728109616, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 441413.7162250432, 441413.7162250429, 124977.5258011693], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2706600.0000, 
sim time next is 2707200.0000, 
raw observation next is [19.8, 95.0, 1.0, 2.0, 0.4025271629625695, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 456707.5714443323, 456707.5714443323, 126983.2167137312], 
processed observation next is [0.0, 0.34782608695652173, 0.5363636363636364, 0.95, 1.0, 1.0, 0.25315895370321184, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16915095238678973, 0.16915095238678973, 0.3097151627164176], 
reward next is 0.6903, 
noisyNet noise sample is [array([0.11949085], dtype=float32), -0.30631676]. 
=============================================
[2019-03-22 23:15:19,897] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.1377498e-35], sum to 1.0000
[2019-03-22 23:15:19,904] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5873
[2019-03-22 23:15:19,909] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 77.16666666666667, 1.0, 2.0, 0.4558523252216941, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 519717.6403145128, 519717.6403145128, 134617.2083243223], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2754600.0000, 
sim time next is 2755200.0000, 
raw observation next is [23.0, 76.33333333333334, 1.0, 2.0, 0.449454701619887, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 512247.4449161446, 512247.4449161446, 133679.3111002813], 
processed observation next is [0.0, 0.9130434782608695, 0.6818181818181818, 0.7633333333333334, 1.0, 1.0, 0.3118183770248587, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18972127589486837, 0.18972127589486837, 0.32604710024458855], 
reward next is 0.6740, 
noisyNet noise sample is [array([1.7115661], dtype=float32), -0.76528007]. 
=============================================
[2019-03-22 23:15:22,753] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-22 23:15:22,755] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-22 23:15:22,755] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:15:22,756] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-22 23:15:22,757] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:15:22,757] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-22 23:15:22,758] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-22 23:15:22,759] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-22 23:15:22,760] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:15:22,761] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:15:22,761] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:15:22,768] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run21
[2019-03-22 23:15:22,769] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run21
[2019-03-22 23:15:22,808] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run21
[2019-03-22 23:15:22,809] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run21
[2019-03-22 23:15:22,823] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run21
[2019-03-22 23:15:43,001] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.0795663], dtype=float32), 0.06871208]
[2019-03-22 23:15:43,001] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [29.2, 51.5, 1.0, 2.0, 0.5159532626866289, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 588007.5918647599, 588007.5918647596, 148739.604593846]
[2019-03-22 23:15:43,002] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:15:43,007] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 6.996163e-38], sampled 0.3481801906710419
[2019-03-22 23:15:50,683] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.0795663], dtype=float32), 0.06871208]
[2019-03-22 23:15:50,684] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.9, 44.5, 1.0, 2.0, 0.3301405848777875, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 358546.5878690833, 358546.5878690833, 117593.9951625148]
[2019-03-22 23:15:50,685] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:15:50,688] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.40977822095318295
[2019-03-22 23:15:57,078] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.0795663], dtype=float32), 0.06871208]
[2019-03-22 23:15:57,081] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.2, 83.0, 1.0, 2.0, 0.362801880636035, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 402943.1151232622, 402943.1151232618, 123172.6863235036]
[2019-03-22 23:15:57,082] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:15:57,085] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 8.589309e-34], sampled 0.834649284014615
[2019-03-22 23:16:30,194] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.0795663], dtype=float32), 0.06871208]
[2019-03-22 23:16:30,195] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.21315408166667, 93.79817648666666, 1.0, 2.0, 0.36800593206181, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 411052.8092965586, 411052.8092965583, 124577.7232443044]
[2019-03-22 23:16:30,196] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:16:30,201] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 7.0401224e-38 6.3107378e-34], sampled 0.20974977293264419
[2019-03-22 23:17:04,481] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.0795663], dtype=float32), 0.06871208]
[2019-03-22 23:17:04,483] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.0, 53.66666666666667, 1.0, 2.0, 0.4302555030401666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 467219.061715302, 467219.061715302, 108541.1357576411]
[2019-03-22 23:17:04,485] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:17:04,488] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.1910475e-34], sampled 0.9849765450773712
[2019-03-22 23:17:11,506] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3485 1683325900.1134 214.0000
[2019-03-22 23:17:11,726] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2492 1773187030.7201 173.0000
[2019-03-22 23:17:11,731] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1147 1656209757.7786 80.0000
[2019-03-22 23:17:11,818] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9309 1705967916.6745 465.0000
[2019-03-22 23:17:11,855] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5598 1663796639.0689 105.0000
[2019-03-22 23:17:12,867] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 500000, evaluation results [500000.0, 8512.249193409023, 1773187030.7201214, 173.0, 9061.114669779829, 1656209757.7786272, 80.0, 8856.559759326878, 1663796639.0688558, 105.0, 8596.930884973775, 1705967916.6744611, 465.0, 8574.348472942609, 1683325900.1133502, 214.0]
[2019-03-22 23:17:21,808] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:17:21,814] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8732
[2019-03-22 23:17:21,820] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1612227.092768802 W.
[2019-03-22 23:17:21,824] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.0, 58.0, 1.0, 2.0, 0.4757951672464321, 1.0, 1.0, 0.4757951672464321, 1.0, 1.0, 0.9625265862533281, 6.9112, 6.9112, 79.40912272735903, 1612227.092768802, 1612227.092768802, 345150.1202220471], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2985600.0000, 
sim time next is 2986200.0000, 
raw observation next is [28.0, 58.0, 1.0, 2.0, 0.7526288810683355, 1.0, 2.0, 0.7526288810683355, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846205732638, 1697172.266349678, 1697172.266349678, 307939.0669225747], 
processed observation next is [1.0, 0.5652173913043478, 0.9090909090909091, 0.58, 1.0, 1.0, 0.6907861013354194, 1.0, 1.0, 0.6907861013354194, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288038063973, 0.6285823208702511, 0.6285823208702511, 0.7510708949331091], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.4015409], dtype=float32), -0.087794565]. 
=============================================
[2019-03-22 23:17:22,241] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:17:22,254] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2871
[2019-03-22 23:17:22,263] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1309345.397437549 W.
[2019-03-22 23:17:22,267] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.0, 56.5, 1.0, 2.0, 0.385977615673035, 1.0, 2.0, 0.385977615673035, 1.0, 2.0, 0.7811641259048551, 6.9112, 6.9112, 77.3421103, 1309345.397437549, 1309345.397437549, 297816.1339389728], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2989800.0000, 
sim time next is 2990400.0000, 
raw observation next is [28.0, 56.0, 1.0, 2.0, 0.3904591235151531, 1.0, 2.0, 0.3904591235151531, 1.0, 2.0, 0.7903479469186069, 6.911199999999999, 6.9112, 77.3421103, 1325224.837731988, 1325224.837731988, 299632.8792800267], 
processed observation next is [1.0, 0.6086956521739131, 0.9090909090909091, 0.56, 1.0, 1.0, 0.23807390439394135, 1.0, 1.0, 0.23807390439394135, 1.0, 1.0, 0.7004970670265813, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.49082401397481035, 0.49082401397481035, 0.730811900682992], 
reward next is 0.2692, 
noisyNet noise sample is [array([0.2605467], dtype=float32), 0.20281787]. 
=============================================
[2019-03-22 23:17:29,237] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.9092430e-35 1.0000000e+00 1.4501692e-32 2.8118245e-28 6.9867268e-29], sum to 1.0000
[2019-03-22 23:17:29,245] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5835
[2019-03-22 23:17:29,255] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1116566.497690658 W.
[2019-03-22 23:17:29,259] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.0, 73.0, 1.0, 2.0, 0.326001995697633, 1.0, 2.0, 0.326001995697633, 1.0, 1.0, 0.6580315806121142, 6.911200000000001, 6.9112, 77.3421103, 1116566.497690658, 1116566.497690658, 263085.3136904248], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3142800.0000, 
sim time next is 3143400.0000, 
raw observation next is [23.16666666666667, 72.33333333333334, 1.0, 2.0, 0.2681146035024405, 1.0, 2.0, 0.2681146035024405, 1.0, 2.0, 0.5410669397548309, 6.911199999999999, 6.9112, 77.3421103, 918150.3900139563, 918150.3900139566, 243093.8369372734], 
processed observation next is [1.0, 0.391304347826087, 0.6893939393939396, 0.7233333333333334, 1.0, 1.0, 0.08514325437805059, 1.0, 1.0, 0.08514325437805059, 1.0, 1.0, 0.34438134250690133, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.340055700005169, 0.3400557000051691, 0.5929117974079838], 
reward next is 0.4071, 
noisyNet noise sample is [array([1.1685936], dtype=float32), 0.0017019403]. 
=============================================
[2019-03-22 23:17:35,747] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:17:35,756] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8261
[2019-03-22 23:17:35,764] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 94.0, 1.0, 2.0, 0.3645855074911151, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 406043.0221035048, 406043.0221035051, 119459.646047894], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3211200.0000, 
sim time next is 3211800.0000, 
raw observation next is [18.0, 93.00000000000001, 1.0, 2.0, 0.3601109401147968, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 400312.99613095, 400312.9961309497, 118785.0320296126], 
processed observation next is [0.0, 0.17391304347826086, 0.45454545454545453, 0.9300000000000002, 1.0, 1.0, 0.20013867514349595, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1482640726410926, 0.14826407264109248, 0.2897195903161283], 
reward next is 0.7103, 
noisyNet noise sample is [array([1.8817517], dtype=float32), -0.38109747]. 
=============================================
[2019-03-22 23:17:39,848] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.7906164e-33 3.4564815e-27], sum to 1.0000
[2019-03-22 23:17:39,858] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5692
[2019-03-22 23:17:39,865] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.5, 52.0, 1.0, 2.0, 0.3539829664932418, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 395815.8042386255, 395815.8042386255, 119305.3243197409], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3331800.0000, 
sim time next is 3332400.0000, 
raw observation next is [24.66666666666666, 51.33333333333333, 1.0, 2.0, 0.3545308839610326, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 396586.1177366619, 396586.1177366622, 119422.1978878781], 
processed observation next is [0.0, 0.5652173913043478, 0.7575757575757573, 0.5133333333333333, 1.0, 1.0, 0.19316360495129073, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14688374730987477, 0.14688374730987488, 0.2912736533850685], 
reward next is 0.7087, 
noisyNet noise sample is [array([0.04069864], dtype=float32), -0.9908741]. 
=============================================
[2019-03-22 23:17:52,914] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.0000000e+00 1.5418366e-14 1.6482667e-32 1.0000000e+00 2.0713629e-11], sum to 1.0000
[2019-03-22 23:17:52,925] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3300
[2019-03-22 23:17:52,930] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.0, 89.0, 1.0, 2.0, 0.261527486393537, 1.0, 2.0, 0.261527486393537, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 594297.3061063971, 594297.3061063968, 182886.2108075572], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3543600.0000, 
sim time next is 3544200.0000, 
raw observation next is [23.0, 89.0, 1.0, 2.0, 0.2615934906690494, 1.0, 2.0, 0.2615934906690494, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 594446.6126932054, 594446.6126932054, 182897.6943394502], 
processed observation next is [1.0, 0.0, 0.6818181818181818, 0.89, 1.0, 1.0, 0.07699186333631175, 1.0, 1.0, 0.07699186333631175, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22016541210859458, 0.22016541210859458, 0.4460919374132931], 
reward next is 0.5539, 
noisyNet noise sample is [array([-0.1700154], dtype=float32), -0.69710326]. 
=============================================
[2019-03-22 23:17:56,501] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.1171981e-22 2.0743256e-17 3.6889470e-20 1.0000000e+00 1.0153256e-11], sum to 1.0000
[2019-03-22 23:17:56,509] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9944
[2019-03-22 23:17:56,513] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.0, 70.0, 1.0, 2.0, 0.7229429344931744, 1.0, 2.0, 0.7229429344931744, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1626226.354878452, 1626226.354878452, 299101.0440352823], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3602400.0000, 
sim time next is 3603000.0000, 
raw observation next is [27.0, 70.0, 1.0, 2.0, 0.6978141626823593, 1.0, 2.0, 0.6978141626823593, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1569621.985146333, 1569621.985146333, 291103.4192570247], 
processed observation next is [1.0, 0.6956521739130435, 0.8636363636363636, 0.7, 1.0, 1.0, 0.6222677033529491, 1.0, 1.0, 0.6222677033529491, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.5813414759801233, 0.5813414759801233, 0.7100083396512797], 
reward next is 0.2900, 
noisyNet noise sample is [array([-0.5960799], dtype=float32), 0.3782213]. 
=============================================
[2019-03-22 23:17:56,522] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[44.343204]
 [44.001072]
 [44.030106]
 [43.955475]
 [43.689663]], R is [[44.55724716]
 [44.38216019]
 [44.17367935]
 [43.98083496]
 [43.80047226]].
[2019-03-22 23:17:59,149] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.2374043e-27 2.1740991e-09 1.2597430e-22 1.0000000e+00 3.3337197e-14], sum to 1.0000
[2019-03-22 23:17:59,156] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2643
[2019-03-22 23:17:59,161] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.33333333333334, 57.0, 1.0, 2.0, 0.6826243702856282, 1.0, 2.0, 0.6826243702856282, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1539961.390127318, 1539961.390127317, 285370.755456323], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3680400.0000, 
sim time next is 3681000.0000, 
raw observation next is [28.5, 56.5, 1.0, 2.0, 0.7033128485197163, 1.0, 2.0, 0.7033128485197163, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1585259.94240751, 1585259.942407509, 292137.5495127194], 
processed observation next is [1.0, 0.6086956521739131, 0.9318181818181818, 0.565, 1.0, 1.0, 0.6291410606496453, 1.0, 1.0, 0.6291410606496453, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.5871333120027815, 0.5871333120027812, 0.7125306085676083], 
reward next is 0.2875, 
noisyNet noise sample is [array([-0.13484497], dtype=float32), -1.8604325]. 
=============================================
[2019-03-22 23:17:59,171] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[47.343773]
 [47.557167]
 [47.653442]
 [47.604134]
 [47.76065 ]], R is [[46.89672089]
 [46.7317276 ]
 [46.58255005]
 [46.44225693]
 [46.2946701 ]].
[2019-03-22 23:18:05,021] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-22 23:18:05,023] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-22 23:18:05,023] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:18:05,024] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-22 23:18:05,024] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-22 23:18:05,025] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:18:05,026] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-22 23:18:05,027] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-22 23:18:05,028] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:18:05,032] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:18:05,033] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:18:05,049] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run22
[2019-03-22 23:18:05,067] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run22
[2019-03-22 23:18:05,087] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run22
[2019-03-22 23:18:05,090] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run22
[2019-03-22 23:18:05,128] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run22
[2019-03-22 23:18:07,801] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.03164644], dtype=float32), 0.08467609]
[2019-03-22 23:18:07,802] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.33333333333334, 44.0, 1.0, 2.0, 0.2963405640984612, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 321780.7646069791, 321780.7646069794, 87671.68328800777]
[2019-03-22 23:18:07,805] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:18:07,809] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.3604796e-37 9.9932277e-01 1.4275002e-29 6.7720457e-04 1.4069000e-18], sampled 0.6851596014214669
[2019-03-22 23:18:20,123] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.03164644], dtype=float32), 0.08467609]
[2019-03-22 23:18:20,124] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.97106271333333, 75.14164871666667, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 410770.0296012584, 410770.0296012581, 141055.2474251748]
[2019-03-22 23:18:20,126] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:18:20,131] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [7.5332106e-34 4.3621153e-01 2.2062258e-25 5.6378841e-01 3.6341690e-15], sampled 0.2502878652635182
[2019-03-22 23:18:56,511] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.03164644], dtype=float32), 0.08467609]
[2019-03-22 23:18:56,512] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [17.94955186, 88.859403645, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 373199.5235095904, 373199.5235095901, 153285.6400552536]
[2019-03-22 23:18:56,513] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:18:56,516] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0.0000000e+00 1.7856441e-05 2.9717376e-30 9.9998212e-01 1.7725079e-17], sampled 0.7830461164120944
[2019-03-22 23:19:42,238] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.03164644], dtype=float32), 0.08467609]
[2019-03-22 23:19:42,242] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.35, 86.0, 1.0, 2.0, 0.2941064223886962, 1.0, 2.0, 0.2941064223886962, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 671048.6811917028, 671048.6811917028, 188684.8759216385]
[2019-03-22 23:19:42,244] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:19:42,248] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.1280174e-32 6.6914927e-04 1.0639270e-25 9.9933088e-01 9.5557461e-16], sampled 0.5064826995955235
[2019-03-22 23:19:52,633] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.03164644], dtype=float32), 0.08467609]
[2019-03-22 23:19:52,636] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.0, 71.0, 1.0, 2.0, 0.3655838100484462, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 407930.9998164004, 407930.9998164001, 124193.8789229324]
[2019-03-22 23:19:52,638] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:19:52,640] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.6472111e-38 9.9918717e-01 4.3715956e-29 8.1283279e-04 1.6503349e-18], sampled 0.11888423656323821
[2019-03-22 23:19:53,278] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 6304.4909 1891257805.6733 49.0000
[2019-03-22 23:19:53,366] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 6563.3840 1887428167.7050 25.0000
[2019-03-22 23:19:53,410] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 6451.5121 1890857867.3856 168.0000
[2019-03-22 23:19:53,555] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 6816.9960 1865444409.8794 19.0000
[2019-03-22 23:19:53,563] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 6374.7194 1956031021.0756 50.0000
[2019-03-22 23:19:54,583] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 525000, evaluation results [525000.0, 6374.71936925417, 1956031021.0755954, 50.0, 6816.996039320486, 1865444409.879366, 19.0, 6563.38399352708, 1887428167.7049737, 25.0, 6451.512128668883, 1890857867.3856187, 168.0, 6304.490852093805, 1891257805.673279, 49.0]
[2019-03-22 23:19:58,683] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.6792609e-35 9.9610484e-01 2.2219175e-29 3.8952301e-03 3.1104184e-12], sum to 1.0000
[2019-03-22 23:19:58,692] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0905
[2019-03-22 23:19:58,699] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 94.0, 1.0, 2.0, 0.3275885088853079, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 358442.2080257083, 358442.2080257086, 114025.8127586152], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4054800.0000, 
sim time next is 4055400.0000, 
raw observation next is [17.0, 94.0, 1.0, 2.0, 0.3240118310927082, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 354511.8315758604, 354511.8315758601, 113763.8922943915], 
processed observation next is [1.0, 0.9565217391304348, 0.4090909090909091, 0.94, 1.0, 1.0, 0.15501478886588524, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13130067836142978, 0.13130067836142967, 0.2774729080351012], 
reward next is 0.7225, 
noisyNet noise sample is [array([0.81599045], dtype=float32), -1.4891669]. 
=============================================
[2019-03-22 23:20:00,430] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.9297724e-30 6.0795884e-27], sum to 1.0000
[2019-03-22 23:20:00,439] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7402
[2019-03-22 23:20:00,444] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 77.0, 1.0, 2.0, 0.281362457399602, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 305511.7109732488, 305511.710973249, 101643.3464513569], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3894600.0000, 
sim time next is 3895200.0000, 
raw observation next is [18.0, 77.0, 1.0, 2.0, 0.2816331722128767, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 305805.7535760876, 305805.7535760876, 101667.6814641793], 
processed observation next is [0.0, 0.08695652173913043, 0.45454545454545453, 0.77, 1.0, 1.0, 0.10204146526609587, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11326139021336577, 0.11326139021336577, 0.24796995479068124], 
reward next is 0.7520, 
noisyNet noise sample is [array([1.559273], dtype=float32), -0.56399524]. 
=============================================
[2019-03-22 23:20:02,391] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.5098297e-31 5.1687086e-32], sum to 1.0000
[2019-03-22 23:20:02,403] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8016
[2019-03-22 23:20:02,406] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.66666666666667, 65.33333333333334, 1.0, 2.0, 0.2840223197589025, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 308400.7842698295, 308400.7842698292, 103096.5108253885], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3882000.0000, 
sim time next is 3882600.0000, 
raw observation next is [19.5, 66.0, 1.0, 2.0, 0.2814211908837305, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 305575.5055704106, 305575.5055704109, 101681.064408825], 
processed observation next is [0.0, 0.9565217391304348, 0.5227272727272727, 0.66, 1.0, 1.0, 0.10177648860466314, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11317611317422614, 0.11317611317422627, 0.24800259611908537], 
reward next is 0.7520, 
noisyNet noise sample is [array([-1.6077605], dtype=float32), 0.563894]. 
=============================================
[2019-03-22 23:20:07,898] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.1192348e-33 1.0000000e+00 6.4377187e-24 1.6997781e-09 1.0425036e-09], sum to 1.0000
[2019-03-22 23:20:07,906] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3316
[2019-03-22 23:20:07,914] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.6248095501886834, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 702660.8492792225, 702660.8492792229, 147708.1369978712], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4027800.0000, 
sim time next is 4028400.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.5559538064592562, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 625048.1083154102, 625048.1083154102, 139782.7034766708], 
processed observation next is [1.0, 0.6521739130434783, 0.45454545454545453, 1.0, 1.0, 1.0, 0.4449422580740702, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23149929937607786, 0.23149929937607786, 0.34093342311383124], 
reward next is 0.6591, 
noisyNet noise sample is [array([-0.42858785], dtype=float32), 1.2740451]. 
=============================================
[2019-03-22 23:20:11,462] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.1977919e-22 3.6313683e-27], sum to 1.0000
[2019-03-22 23:20:11,471] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3919
[2019-03-22 23:20:11,475] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 94.0, 1.0, 2.0, 0.3203920165441284, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 350534.1715083456, 350534.1715083456, 113500.329389377], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4056000.0000, 
sim time next is 4056600.0000, 
raw observation next is [17.0, 94.0, 1.0, 2.0, 0.3183658651175765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 348304.471991756, 348304.471991756, 113352.2780809082], 
processed observation next is [1.0, 0.9565217391304348, 0.4090909090909091, 0.94, 1.0, 1.0, 0.14795733139697057, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12900165629324295, 0.12900165629324295, 0.2764689709290444], 
reward next is 0.7235, 
noisyNet noise sample is [array([0.9732431], dtype=float32), 0.42723987]. 
=============================================
[2019-03-22 23:20:13,475] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.0323598e-29 3.5340852e-31], sum to 1.0000
[2019-03-22 23:20:13,484] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5808
[2019-03-22 23:20:13,490] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.03333333333333, 93.66666666666667, 1.0, 2.0, 0.3950727021860171, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 445161.5284507537, 445161.5284507534, 124387.3081308146], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4126800.0000, 
sim time next is 4127400.0000, 
raw observation next is [19.05, 93.5, 1.0, 2.0, 0.39456541663106, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 444578.7129983312, 444578.7129983312, 124336.0125386583], 
processed observation next is [1.0, 0.782608695652174, 0.5022727272727273, 0.935, 1.0, 1.0, 0.24320677078882497, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1646587825919745, 0.1646587825919745, 0.30325856716745925], 
reward next is 0.6967, 
noisyNet noise sample is [array([0.10683767], dtype=float32), 0.34251028]. 
=============================================
[2019-03-22 23:20:17,712] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 3.6734460e-34 3.1845360e-29 1.8301638e-28], sum to 1.0000
[2019-03-22 23:20:17,722] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8041
[2019-03-22 23:20:17,728] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.33333333333333, 100.0, 1.0, 2.0, 0.3564747640241976, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 396904.1222395512, 396904.1222395512, 118760.473071331], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4160400.0000, 
sim time next is 4161000.0000, 
raw observation next is [17.16666666666667, 100.0, 1.0, 2.0, 0.3506536856992221, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 389439.7549645434, 389439.7549645437, 117884.6045559631], 
processed observation next is [1.0, 0.13043478260869565, 0.4166666666666669, 1.0, 1.0, 1.0, 0.18831710712402763, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14423694628316422, 0.14423694628316433, 0.28752342574625145], 
reward next is 0.7125, 
noisyNet noise sample is [array([-0.23036502], dtype=float32), -0.9556042]. 
=============================================
[2019-03-22 23:20:17,753] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[68.27204 ]
 [68.1969  ]
 [68.086235]
 [68.11952 ]
 [68.34263 ]], R is [[68.38942719]
 [68.4158783 ]
 [68.44042206]
 [68.46193695]
 [68.47497559]].
[2019-03-22 23:20:19,657] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 2.5418601e-29 2.4340904e-28 4.9802580e-27], sum to 1.0000
[2019-03-22 23:20:19,665] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8505
[2019-03-22 23:20:19,671] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 73.0, 1.0, 2.0, 0.3722995342442969, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 416520.5610183658, 416520.5610183658, 120913.6645891307], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4219200.0000, 
sim time next is 4219800.0000, 
raw observation next is [21.0, 73.0, 1.0, 2.0, 0.3694187056996227, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 413068.2036801926, 413068.2036801929, 120569.4749687512], 
processed observation next is [1.0, 0.8695652173913043, 0.5909090909090909, 0.73, 1.0, 1.0, 0.21177338212452837, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15298822358525652, 0.15298822358525663, 0.2940718901676858], 
reward next is 0.7059, 
noisyNet noise sample is [array([0.07985949], dtype=float32), 1.055654]. 
=============================================
[2019-03-22 23:20:24,663] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:20:24,670] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6241
[2019-03-22 23:20:24,679] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1231678.495341404 W.
[2019-03-22 23:20:24,682] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.0, 47.0, 1.0, 2.0, 0.5998837851535661, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9623653899829537, 6.911200000000001, 6.9112, 77.32846344354104, 1231678.495341404, 1231678.495341404, 262510.9767043666], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4293600.0000, 
sim time next is 4294200.0000, 
raw observation next is [27.0, 46.0, 1.0, 2.0, 0.5893909381421979, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9606156790537997, 6.911199999999999, 6.9112, 77.32846344354104, 1218658.988632371, 1218658.988632371, 259067.8873389098], 
processed observation next is [1.0, 0.6956521739130435, 0.8636363636363636, 0.46, 1.0, 1.0, 0.48673867267774734, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9437366843625712, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.4513551809749522, 0.4513551809749522, 0.6318728959485604], 
reward next is 0.3681, 
noisyNet noise sample is [array([0.2812689], dtype=float32), -0.040909797]. 
=============================================
[2019-03-22 23:20:28,474] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 2.6458382e-38 1.9226933e-33 1.1841485e-33], sum to 1.0000
[2019-03-22 23:20:28,482] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0436
[2019-03-22 23:20:28,486] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.71666666666667, 66.16666666666667, 1.0, 2.0, 0.4887500771652356, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 557643.9623406285, 557643.9623406285, 140176.1758741798], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4392600.0000, 
sim time next is 4393200.0000, 
raw observation next is [25.43333333333334, 67.33333333333334, 1.0, 2.0, 0.4872124733008381, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 555923.6936237278, 555923.6936237278, 139845.5044243959], 
processed observation next is [1.0, 0.8695652173913043, 0.7924242424242428, 0.6733333333333335, 1.0, 1.0, 0.3590155916260476, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20589766430508435, 0.20589766430508435, 0.3410865961570632], 
reward next is 0.6589, 
noisyNet noise sample is [array([-0.9743647], dtype=float32), 1.4110777]. 
=============================================
[2019-03-22 23:20:33,683] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.1685989e-34 1.4073824e-31], sum to 1.0000
[2019-03-22 23:20:33,694] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4591
[2019-03-22 23:20:33,699] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 94.0, 1.0, 2.0, 0.4658377317987498, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 531325.9048920163, 531325.9048920163, 136095.0528246023], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4486800.0000, 
sim time next is 4487400.0000, 
raw observation next is [21.0, 94.0, 1.0, 2.0, 0.4665026708271701, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 532084.7747815601, 532084.7747815601, 136167.0684927535], 
processed observation next is [0.0, 0.9565217391304348, 0.5909090909090909, 0.94, 1.0, 1.0, 0.3331283385339626, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19706843510428151, 0.19706843510428151, 0.3321148012018378], 
reward next is 0.6679, 
noisyNet noise sample is [array([1.0704576], dtype=float32), -0.60010076]. 
=============================================
[2019-03-22 23:20:34,947] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:20:34,957] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9845
[2019-03-22 23:20:34,961] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.4113712844941463, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 466327.9541286997, 466327.9541286997, 127524.9551303941], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4510200.0000, 
sim time next is 4510800.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4115835389797709, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 466568.9707149618, 466568.9707149621, 127545.2985791925], 
processed observation next is [0.0, 0.21739130434782608, 0.5, 1.0, 1.0, 1.0, 0.2644794237247136, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1728033224870229, 0.17280332248702301, 0.31108609409559146], 
reward next is 0.6889, 
noisyNet noise sample is [array([-1.6211092], dtype=float32), 1.4212108]. 
=============================================
[2019-03-22 23:20:39,635] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 3.3229415e-32], sum to 1.0000
[2019-03-22 23:20:39,645] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2657
[2019-03-22 23:20:39,657] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.66666666666667, 61.5, 1.0, 2.0, 0.3916464178770229, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 442134.3473048862, 442134.3473048862, 124540.634238768], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4558200.0000, 
sim time next is 4558800.0000, 
raw observation next is [23.33333333333333, 62.0, 1.0, 2.0, 0.385802221056345, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 434612.0813089209, 434612.0813089206, 123508.5103774434], 
processed observation next is [0.0, 0.782608695652174, 0.6969696969696968, 0.62, 1.0, 1.0, 0.2322527763204312, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16096743752182258, 0.16096743752182244, 0.30124026921327657], 
reward next is 0.6988, 
noisyNet noise sample is [array([1.2199955], dtype=float32), -0.21350452]. 
=============================================
[2019-03-22 23:20:41,626] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:20:41,635] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2654
[2019-03-22 23:20:41,640] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.83333333333333, 46.5, 1.0, 2.0, 0.6317883361924831, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 692024.1951508492, 692024.1951508494, 141495.6057775584], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4629000.0000, 
sim time next is 4629600.0000, 
raw observation next is [24.0, 47.0, 1.0, 2.0, 0.6520553433708458, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 717218.7433849239, 717218.7433849239, 144689.0339296748], 
processed observation next is [1.0, 0.6086956521739131, 0.7272727272727273, 0.47, 1.0, 1.0, 0.5650691792135573, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2656365716240459, 0.2656365716240459, 0.3529000827553044], 
reward next is 0.6471, 
noisyNet noise sample is [array([0.7421251], dtype=float32), -0.73175853]. 
=============================================
[2019-03-22 23:20:45,459] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.4300540e-36 2.4782063e-31], sum to 1.0000
[2019-03-22 23:20:45,466] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5364
[2019-03-22 23:20:45,472] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 64.0, 1.0, 2.0, 0.2623934285852774, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 284908.542996777, 284908.5429967767, 90439.90025318418], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4657800.0000, 
sim time next is 4658400.0000, 
raw observation next is [19.0, 64.0, 1.0, 2.0, 0.2625592744363857, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 285088.6723127135, 285088.6723127138, 90457.66656843868], 
processed observation next is [1.0, 0.9565217391304348, 0.5, 0.64, 1.0, 1.0, 0.07819909304548213, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10558839715285685, 0.10558839715285696, 0.2206284550449724], 
reward next is 0.7794, 
noisyNet noise sample is [array([-1.4398652], dtype=float32), -0.3342095]. 
=============================================
[2019-03-22 23:20:46,885] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-22 23:20:46,887] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-22 23:20:46,888] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:20:46,890] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-22 23:20:46,890] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-22 23:20:46,892] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-22 23:20:46,893] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:20:46,894] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:20:46,894] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-22 23:20:46,895] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:20:46,899] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:20:46,911] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run23
[2019-03-22 23:20:46,912] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run23
[2019-03-22 23:20:46,929] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run23
[2019-03-22 23:20:46,967] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run23
[2019-03-22 23:20:46,985] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run23
[2019-03-22 23:20:54,676] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.15401715], dtype=float32), 0.009034989]
[2019-03-22 23:20:54,679] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.99781933666667, 90.45809224666667, 1.0, 2.0, 0.3332101436362357, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 367875.8378539062, 367875.8378539062, 119967.4790754076]
[2019-03-22 23:20:54,680] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:20:54,685] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.1563385131970082
[2019-03-22 23:20:55,188] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.15401715], dtype=float32), 0.009034989]
[2019-03-22 23:20:55,189] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [14.977030735, 79.37975765, 1.0, 2.0, 0.2578572914207317, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 61.63163626896797, 280002.2855354256, 280002.2855354256, 69936.90747132264]
[2019-03-22 23:20:55,190] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:20:55,193] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.6669711627137269
[2019-03-22 23:21:13,757] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.15401715], dtype=float32), 0.009034989]
[2019-03-22 23:21:13,758] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [26.06158131166666, 70.97009700333334, 1.0, 2.0, 0.5260469014638866, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 598588.5057239042, 598588.5057239038, 150751.8105989957]
[2019-03-22 23:21:13,758] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:21:13,762] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.5576202429410938
[2019-03-22 23:21:25,297] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.15401715], dtype=float32), 0.009034989]
[2019-03-22 23:21:25,299] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [27.56380803, 52.97376048333334, 1.0, 2.0, 0.445234936844045, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 507662.1706961438, 507662.1706961438, 137997.1431851865]
[2019-03-22 23:21:25,301] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:21:25,305] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.0166933419949018
[2019-03-22 23:21:34,028] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.15401715], dtype=float32), 0.009034989]
[2019-03-22 23:21:34,028] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [27.6, 66.0, 1.0, 2.0, 0.5488671785502495, 0.0, 2.0, 0.0, 1.0, 2.0, 0.904550109894152, 7.018612419075069, 6.9112, 95.55297159003605, 1168008.908424363, 1124901.889945516, 266515.7168846969]
[2019-03-22 23:21:34,030] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:21:34,033] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.4807554679511602
[2019-03-22 23:21:34,035] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1168008.908424363 W.
[2019-03-22 23:21:41,169] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.15401715], dtype=float32), 0.009034989]
[2019-03-22 23:21:41,170] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [15.15879324, 92.68145222, 1.0, 2.0, 0.2504113264512448, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 271880.1654017458, 271880.1654017454, 90828.33560039733]
[2019-03-22 23:21:41,172] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:21:41,174] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.5846625122118709
[2019-03-22 23:21:51,977] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.15401715], dtype=float32), 0.009034989]
[2019-03-22 23:21:51,978] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.67593365333333, 97.94561300000001, 1.0, 2.0, 0.3833886966769186, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 432586.0677243407, 432586.0677243404, 128002.8258479726]
[2019-03-22 23:21:51,980] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:21:51,983] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.29309168861690815
[2019-03-22 23:22:09,030] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.15401715], dtype=float32), 0.009034989]
[2019-03-22 23:22:09,033] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [18.06666666666667, 65.0, 1.0, 2.0, 0.2604767318123636, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 282811.0923107989, 282811.0923107985, 89269.60198206529]
[2019-03-22 23:22:09,036] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:22:09,039] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.14834606868962075
[2019-03-22 23:22:14,357] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.15401715], dtype=float32), 0.009034989]
[2019-03-22 23:22:14,358] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.6, 66.0, 1.0, 2.0, 0.4267281686356003, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 483856.8010232613, 483856.8010232613, 133413.1918194233]
[2019-03-22 23:22:14,359] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:22:14,363] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.10645676909556334
[2019-03-22 23:22:18,330] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.15401715], dtype=float32), 0.009034989]
[2019-03-22 23:22:18,332] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.93852823833333, 98.65624038666667, 1.0, 2.0, 0.4816632899328148, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 548632.4407428331, 548632.4407428327, 141060.2895738234]
[2019-03-22 23:22:18,336] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:22:18,339] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.0698831484411877
[2019-03-22 23:22:35,053] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9309 1705967916.6745 465.0000
[2019-03-22 23:22:35,108] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1147 1656209757.7786 80.0000
[2019-03-22 23:22:35,309] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3485 1683325900.1134 214.0000
[2019-03-22 23:22:35,346] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5598 1663796639.0689 105.0000
[2019-03-22 23:22:35,362] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-22 23:22:36,378] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 550000, evaluation results [550000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.114669779829, 1656209757.7786272, 80.0, 8856.559759326878, 1663796639.0688558, 105.0, 8596.930884973775, 1705967916.6744611, 465.0, 8574.348472942609, 1683325900.1133502, 214.0]
[2019-03-22 23:22:39,788] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 5.2967284e-34 1.1913483e-25 6.6760739e-28], sum to 1.0000
[2019-03-22 23:22:39,800] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5302
[2019-03-22 23:22:39,805] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 76.33333333333334, 1.0, 2.0, 0.4049217289042442, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 458276.484005087, 458276.4840050873, 126431.0794457696], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4740000.0000, 
sim time next is 4740600.0000, 
raw observation next is [21.33333333333333, 77.16666666666666, 1.0, 2.0, 0.3988258622279365, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 450580.7021191473, 450580.7021191471, 125384.8336583239], 
processed observation next is [1.0, 0.8695652173913043, 0.6060606060606059, 0.7716666666666666, 1.0, 1.0, 0.24853232778492057, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1668817415256101, 0.16688174152561006, 0.30581666745932656], 
reward next is 0.6942, 
noisyNet noise sample is [array([-2.8372705], dtype=float32), 0.8561733]. 
=============================================
[2019-03-22 23:22:40,658] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 4.9452202e-33 5.0480781e-29 1.2265506e-20], sum to 1.0000
[2019-03-22 23:22:40,669] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5970
[2019-03-22 23:22:40,680] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 88.0, 1.0, 2.0, 0.3631303394337053, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 405833.5393905484, 405833.5393905484, 119957.6590568011], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4758000.0000, 
sim time next is 4758600.0000, 
raw observation next is [19.0, 88.0, 1.0, 2.0, 0.3626766045012074, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 405324.367637117, 405324.3676371168, 119919.4738540799], 
processed observation next is [1.0, 0.043478260869565216, 0.5, 0.88, 1.0, 1.0, 0.20334575562650925, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15012013616189518, 0.15012013616189512, 0.29248652159531685], 
reward next is 0.7075, 
noisyNet noise sample is [array([1.4378535], dtype=float32), -1.7167628]. 
=============================================
[2019-03-22 23:22:42,463] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 6.503354e-38 9.127520e-34], sum to 1.0000
[2019-03-22 23:22:42,473] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8630
[2019-03-22 23:22:42,478] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 54.0, 1.0, 2.0, 0.4104290692738911, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 466192.9422165355, 466192.9422165353, 128124.3672719698], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5068800.0000, 
sim time next is 5069400.0000, 
raw observation next is [26.16666666666667, 53.5, 1.0, 2.0, 0.4102529054731964, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 466069.7535352261, 466069.7535352261, 128169.7922333078], 
processed observation next is [0.0, 0.6956521739130435, 0.825757575757576, 0.535, 1.0, 1.0, 0.2628161318414955, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17261842723526893, 0.17261842723526893, 0.3126092493495312], 
reward next is 0.6874, 
noisyNet noise sample is [array([0.59916073], dtype=float32), -0.77031434]. 
=============================================
[2019-03-22 23:23:09,117] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.1179143e-36 1.0000000e+00 3.4090098e-29 6.6968516e-16 1.2700444e-15], sum to 1.0000
[2019-03-22 23:23:09,130] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0422
[2019-03-22 23:23:09,134] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 88.5, 1.0, 2.0, 0.3463383450589265, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 386364.8930751084, 386364.8930751081, 118280.8254743329], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5286600.0000, 
sim time next is 5287200.0000, 
raw observation next is [18.8, 88.0, 1.0, 2.0, 0.3448448837378084, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 384382.3768627165, 384382.3768627162, 118023.1314280397], 
processed observation next is [1.0, 0.17391304347826086, 0.49090909090909096, 0.88, 1.0, 1.0, 0.1810561046722605, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1423638432824876, 0.1423638432824875, 0.2878612961659505], 
reward next is 0.7121, 
noisyNet noise sample is [array([1.213735], dtype=float32), 0.32052815]. 
=============================================
[2019-03-22 23:23:10,196] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.7347727e-23 2.7613517e-06 3.5907992e-15 9.9999726e-01 4.6278630e-09], sum to 1.0000
[2019-03-22 23:23:10,208] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0721
[2019-03-22 23:23:10,215] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.15, 52.5, 1.0, 2.0, 0.4863681506593135, 1.0, 2.0, 0.4863681506593135, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1110311.221889808, 1110311.221889808, 223975.902344228], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5308200.0000, 
sim time next is 5308800.0000, 
raw observation next is [27.33333333333334, 52.0, 1.0, 2.0, 0.4982651921123975, 1.0, 2.0, 0.4982651921123975, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1137242.739643378, 1137242.739643378, 227289.6747432472], 
processed observation next is [1.0, 0.43478260869565216, 0.878787878787879, 0.52, 1.0, 1.0, 0.3728314901404968, 1.0, 1.0, 0.3728314901404968, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.4212010146827326, 0.4212010146827326, 0.5543650603493834], 
reward next is 0.4456, 
noisyNet noise sample is [array([-0.26734617], dtype=float32), 0.22247046]. 
=============================================
[2019-03-22 23:23:10,281] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.4869219e-38 1.0000000e+00 2.1748722e-30 7.6082915e-17 9.3350351e-18], sum to 1.0000
[2019-03-22 23:23:10,289] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4912
[2019-03-22 23:23:10,295] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 87.0, 1.0, 2.0, 0.3654690796483525, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 409798.6016070553, 409798.6016070553, 120776.3513155978], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5292600.0000, 
sim time next is 5293200.0000, 
raw observation next is [19.4, 87.0, 1.0, 2.0, 0.3600727966504393, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 403759.4451947517, 403759.445194752, 120332.7219176318], 
processed observation next is [1.0, 0.2608695652173913, 0.5181818181818181, 0.87, 1.0, 1.0, 0.2000909958130491, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14954053525731545, 0.14954053525731556, 0.293494443701541], 
reward next is 0.7065, 
noisyNet noise sample is [array([0.44081402], dtype=float32), -0.9190671]. 
=============================================
[2019-03-22 23:23:19,472] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.8476076e-30 1.3539098e-17 3.3769195e-24], sum to 1.0000
[2019-03-22 23:23:19,481] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5077
[2019-03-22 23:23:19,486] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.2, 98.33333333333334, 1.0, 2.0, 0.367187016179823, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 406955.1389708584, 406955.1389708587, 118861.8228177175], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5458200.0000, 
sim time next is 5458800.0000, 
raw observation next is [17.2, 96.66666666666667, 1.0, 2.0, 0.3486163038528191, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 385243.85949181, 385243.85949181, 116953.3028510193], 
processed observation next is [1.0, 0.17391304347826086, 0.41818181818181815, 0.9666666666666667, 1.0, 1.0, 0.18577037981602387, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1426829109228926, 0.1426829109228926, 0.2852519581732178], 
reward next is 0.7147, 
noisyNet noise sample is [array([-0.17886858], dtype=float32), 1.4788488]. 
=============================================
[2019-03-22 23:23:25,150] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.3355289e-31 1.0000000e+00 2.1924708e-25 1.6564332e-20 9.0481865e-11], sum to 1.0000
[2019-03-22 23:23:25,155] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5745
[2019-03-22 23:23:25,164] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.91666666666666, 85.0, 1.0, 2.0, 0.4819242261284669, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 549357.0145560117, 549357.0145560119, 137269.8572336963], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5557800.0000, 
sim time next is 5558400.0000, 
raw observation next is [22.2, 84.0, 1.0, 2.0, 0.4748860031107675, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 541532.4642420349, 541532.4642420349, 136838.2826110884], 
processed observation next is [1.0, 0.34782608695652173, 0.6454545454545454, 0.84, 1.0, 1.0, 0.34360750388845934, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20056757934890182, 0.20056757934890182, 0.33375190880753264], 
reward next is 0.6662, 
noisyNet noise sample is [array([1.0879773], dtype=float32), -1.3770207]. 
=============================================
[2019-03-22 23:23:25,847] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.4451155e-27 1.0000000e+00 2.9670100e-23 1.5820210e-28 3.3441697e-22], sum to 1.0000
[2019-03-22 23:23:25,854] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3217
[2019-03-22 23:23:25,861] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1307893.904801889 W.
[2019-03-22 23:23:25,867] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.65, 64.5, 1.0, 2.0, 0.3858936830494317, 1.0, 2.0, 0.3858936830494317, 1.0, 2.0, 0.7807766015910004, 6.9112, 6.9112, 77.3421103, 1307893.904801889, 1307893.904801889, 298188.7159372959], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5571000.0000, 
sim time next is 5571600.0000, 
raw observation next is [26.83333333333334, 63.66666666666666, 1.0, 2.0, 0.5329774776655101, 1.0, 2.0, 0.5329774776655101, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1206287.681576027, 1206287.681576027, 241883.5354320726], 
processed observation next is [1.0, 0.4782608695652174, 0.8560606060606063, 0.6366666666666666, 1.0, 1.0, 0.41622184708188753, 1.0, 1.0, 0.41622184708188753, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.44677321539852854, 0.44677321539852854, 0.5899598425172502], 
reward next is 0.4100, 
noisyNet noise sample is [array([1.6420487], dtype=float32), 0.19979301]. 
=============================================
[2019-03-22 23:23:27,251] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.3940027e-37 1.0000000e+00 6.6978005e-30 5.9317814e-27 2.2692523e-15], sum to 1.0000
[2019-03-22 23:23:27,262] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9288
[2019-03-22 23:23:27,270] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 97.0, 1.0, 2.0, 0.3589811782144647, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 399992.3133341134, 399992.3133341137, 119088.2580765155], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5637600.0000, 
sim time next is 5638200.0000, 
raw observation next is [17.61666666666667, 97.5, 1.0, 2.0, 0.3552354329223684, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 395406.4689061129, 395406.4689061129, 118611.7071059617], 
processed observation next is [0.0, 0.2608695652173913, 0.4371212121212123, 0.975, 1.0, 1.0, 0.1940442911529605, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14644684033559738, 0.14644684033559738, 0.28929684659990657], 
reward next is 0.7107, 
noisyNet noise sample is [array([-2.5919583], dtype=float32), 0.72842133]. 
=============================================
[2019-03-22 23:23:28,696] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-22 23:23:28,698] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-22 23:23:28,699] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:23:28,700] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-22 23:23:28,700] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:23:28,701] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-22 23:23:28,701] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-22 23:23:28,703] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-22 23:23:28,702] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:23:28,704] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:23:28,705] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:23:28,719] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run24
[2019-03-22 23:23:28,720] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run24
[2019-03-22 23:23:28,748] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run24
[2019-03-22 23:23:28,749] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run24
[2019-03-22 23:23:28,783] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run24
[2019-03-22 23:23:42,799] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13206756], dtype=float32), -0.0059191966]
[2019-03-22 23:23:42,802] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [16.0, 100.0, 1.0, 2.0, 0.5225369270488095, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 569166.4259660146, 569166.4259660146, 129421.4137858291]
[2019-03-22 23:23:42,802] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:23:42,805] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 4.8961593e-38 3.1050921e-26 1.3547999e-15], sampled 0.48686913205613724
[2019-03-22 23:23:55,837] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13206756], dtype=float32), -0.0059191966]
[2019-03-22 23:23:55,838] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.95316761, 57.56723973, 1.0, 2.0, 0.3460662318431242, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 384233.0101608636, 384233.0101608632, 121798.4710282572]
[2019-03-22 23:23:55,839] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:23:55,844] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 5.4740153e-37 5.0806771e-26], sampled 0.2982445186250785
[2019-03-22 23:24:32,170] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.13206756], dtype=float32), -0.0059191966]
[2019-03-22 23:24:32,172] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.1, 61.66666666666666, 1.0, 2.0, 0.3473135517976789, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 377123.2446276966, 377123.2446276963, 112272.6370282795]
[2019-03-22 23:24:32,175] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:24:32,179] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.1773465e-37 9.6665790e-27], sampled 0.4767456127798354
[2019-03-22 23:24:54,529] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13206756], dtype=float32), -0.0059191966]
[2019-03-22 23:24:54,531] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [28.28601718, 44.51390163, 1.0, 2.0, 0.4481559374122705, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 510019.9928070154, 510019.9928070151, 137033.2255227216]
[2019-03-22 23:24:54,532] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:24:54,533] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.1631729e-34 3.8941017e-22], sampled 0.506600000829033
[2019-03-22 23:25:16,492] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1148 1656229146.4555 80.0000
[2019-03-22 23:25:16,754] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8510.7981 1774069077.9369 171.0000
[2019-03-22 23:25:16,761] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.7166 1663843543.7098 104.0000
[2019-03-22 23:25:16,858] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8598.6070 1706111692.2664 458.0000
[2019-03-22 23:25:16,902] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8576.7572 1683994991.3295 202.0000
[2019-03-22 23:25:17,918] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 575000, evaluation results [575000.0, 8510.7981115222, 1774069077.9368825, 171.0, 9061.114827412715, 1656229146.4555063, 80.0, 8856.71664715407, 1663843543.7098331, 104.0, 8598.607003464262, 1706111692.2663853, 458.0, 8576.757213360988, 1683994991.3294787, 202.0]
[2019-03-22 23:25:23,878] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 2.1352790e-32 6.4512164e-31 5.0482953e-27], sum to 1.0000
[2019-03-22 23:25:23,887] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9772
[2019-03-22 23:25:23,893] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.2, 80.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 163825.1198455309, 163825.1198455306, 59662.14610197004], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5729400.0000, 
sim time next is 5730000.0000, 
raw observation next is [12.56666666666667, 78.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 168400.7160472721, 168400.7160472718, 60264.87630088159], 
processed observation next is [0.0, 0.30434782608695654, 0.20757575757575772, 0.78, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.062370635573063736, 0.062370635573063625, 0.14698750317288192], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0359409], dtype=float32), -1.4149635]. 
=============================================
[2019-03-22 23:25:23,905] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[12.273302]
 [12.284451]
 [12.338953]
 [12.42605 ]
 [12.498313]], R is [[12.16527271]
 [12.04362011]
 [11.92318439]
 [11.80395222]
 [11.68591309]].
[2019-03-22 23:25:28,171] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.1968813e-37 1.0000000e+00 1.0215511e-34 2.3548419e-27 1.8873323e-11], sum to 1.0000
[2019-03-22 23:25:28,182] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9238
[2019-03-22 23:25:28,188] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.1, 40.0, 1.0, 2.0, 0.6306286421085451, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 699188.1758646414, 699188.1758646414, 144264.9951820124], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5846400.0000, 
sim time next is 5847000.0000, 
raw observation next is [26.1, 40.0, 1.0, 2.0, 0.6536154876647402, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 724592.7691808047, 724592.7691808047, 146849.2125700663], 
processed observation next is [1.0, 0.6956521739130435, 0.8227272727272728, 0.4, 1.0, 1.0, 0.5670193595809252, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.26836769228918694, 0.26836769228918694, 0.3581688111465032], 
reward next is 0.6418, 
noisyNet noise sample is [array([-1.5853364], dtype=float32), 0.1487027]. 
=============================================
[2019-03-22 23:25:28,196] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[89.40533 ]
 [89.362976]
 [89.14625 ]
 [88.89124 ]
 [88.91405 ]], R is [[89.1241684 ]
 [88.88105774]
 [88.64474487]
 [88.40608978]
 [88.1612854 ]].
[2019-03-22 23:25:36,818] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 5.8840696e-35], sum to 1.0000
[2019-03-22 23:25:36,826] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8889
[2019-03-22 23:25:36,833] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.9, 86.0, 1.0, 2.0, 0.3596648097439566, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 400047.4688087259, 400047.4688087259, 118845.3233514278], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5971800.0000, 
sim time next is 5972400.0000, 
raw observation next is [18.8, 87.0, 1.0, 2.0, 0.3623252315029062, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 403125.8987719535, 403125.8987719535, 119108.6854888294], 
processed observation next is [1.0, 0.13043478260869565, 0.49090909090909096, 0.87, 1.0, 1.0, 0.2029065393786327, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14930588843405684, 0.14930588843405684, 0.2905089889971449], 
reward next is 0.7095, 
noisyNet noise sample is [array([0.91871214], dtype=float32), -0.42348528]. 
=============================================
[2019-03-22 23:25:39,002] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.00000000e+00 1.00000000e+00 0.00000000e+00 1.15097795e-33
 3.90505106e-29], sum to 1.0000
[2019-03-22 23:25:39,012] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4428
[2019-03-22 23:25:39,015] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.18333333333334, 57.33333333333334, 1.0, 2.0, 0.5425585023612614, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 618447.8603398817, 618447.8603398817, 144062.2070800166], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6007800.0000, 
sim time next is 6008400.0000, 
raw observation next is [26.1, 58.0, 1.0, 2.0, 0.5720666394398197, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 652171.7836738107, 652171.7836738104, 147697.0861364275], 
processed observation next is [1.0, 0.5652173913043478, 0.8227272727272728, 0.58, 1.0, 1.0, 0.4650832992997746, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.24154510506437432, 0.24154510506437424, 0.3602367954547012], 
reward next is 0.6398, 
noisyNet noise sample is [array([-0.19548707], dtype=float32), 0.56484437]. 
=============================================
[2019-03-22 23:25:39,043] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 6.0155095e-32], sum to 1.0000
[2019-03-22 23:25:39,050] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1909
[2019-03-22 23:25:39,058] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 93.0, 1.0, 2.0, 0.3730914719869907, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 418937.6158976897, 418937.6158976897, 121703.9032088505], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6232800.0000, 
sim time next is 6233400.0000, 
raw observation next is [18.8, 93.0, 1.0, 2.0, 0.3726212670907644, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 418407.5580881356, 418407.5580881356, 121662.8808242553], 
processed observation next is [0.0, 0.13043478260869565, 0.49090909090909096, 0.93, 1.0, 1.0, 0.21577658386345544, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15496576225486505, 0.15496576225486505, 0.2967387337176959], 
reward next is 0.7033, 
noisyNet noise sample is [array([-1.4591615], dtype=float32), -0.0024176587]. 
=============================================
[2019-03-22 23:25:39,963] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.1292785e-36 9.4096053e-20], sum to 1.0000
[2019-03-22 23:25:39,969] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4860
[2019-03-22 23:25:39,973] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.21666666666667, 79.5, 1.0, 2.0, 0.222952192437141, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 242072.3269541627, 242072.3269541624, 76342.89285292955], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6059400.0000, 
sim time next is 6060000.0000, 
raw observation next is [14.93333333333333, 81.0, 1.0, 2.0, 0.2146084313724729, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 233010.8441407656, 233010.8441407659, 75210.82078903647], 
processed observation next is [1.0, 0.13043478260869565, 0.315151515151515, 0.81, 1.0, 1.0, 0.018260539215591114, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.086300312644728, 0.08630031264472811, 0.18344102631472312], 
reward next is 0.8166, 
noisyNet noise sample is [array([0.06127866], dtype=float32), -1.7353648]. 
=============================================
[2019-03-22 23:25:39,981] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[64.689476]
 [64.61298 ]
 [64.55168 ]
 [64.510826]
 [64.48317 ]], R is [[64.84275818]
 [65.00812531]
 [65.17136383]
 [65.33117676]
 [65.48628998]].
[2019-03-22 23:25:40,513] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.0778193e-31 2.9802764e-19], sum to 1.0000
[2019-03-22 23:25:40,524] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6043
[2019-03-22 23:25:40,528] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.08333333333334, 78.0, 1.0, 2.0, 0.3614013664797929, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 403041.3700029799, 403041.3700029802, 119435.7380630513], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6033000.0000, 
sim time next is 6033600.0000, 
raw observation next is [20.0, 78.0, 1.0, 2.0, 0.3585110038058201, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 399367.7840600715, 399367.7840600715, 119007.5550599395], 
processed observation next is [1.0, 0.8695652173913043, 0.5454545454545454, 0.78, 1.0, 1.0, 0.19813875475727513, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14791399409632278, 0.14791399409632278, 0.2902623294144866], 
reward next is 0.7097, 
noisyNet noise sample is [array([-0.5201346], dtype=float32), 0.16613051]. 
=============================================
[2019-03-22 23:25:43,156] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 2.5833212e-26], sum to 1.0000
[2019-03-22 23:25:43,168] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7241
[2019-03-22 23:25:43,173] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.98333333333333, 64.0, 1.0, 2.0, 0.4048433545346309, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 439651.5502084343, 439651.5502084346, 98996.34648637447], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6081000.0000, 
sim time next is 6081600.0000, 
raw observation next is [18.26666666666667, 63.0, 1.0, 2.0, 0.4057018061961669, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 440584.2334525276, 440584.2334525276, 99752.77436433031], 
processed observation next is [1.0, 0.391304347826087, 0.4666666666666668, 0.63, 1.0, 1.0, 0.2571272577452086, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16317934572315837, 0.16317934572315837, 0.24329944966909833], 
reward next is 0.7567, 
noisyNet noise sample is [array([0.15535246], dtype=float32), -2.194627]. 
=============================================
[2019-03-22 23:25:44,975] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:25:44,982] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3816
[2019-03-22 23:25:44,988] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.5, 78.50000000000001, 1.0, 2.0, 0.5110364669248925, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 582153.9823542649, 582153.9823542652, 144156.4392360478], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6340200.0000, 
sim time next is 6340800.0000, 
raw observation next is [24.6, 78.0, 1.0, 2.0, 0.5150617458155319, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 586685.3482929809, 586685.3482929809, 144690.8589337199], 
processed observation next is [0.0, 0.391304347826087, 0.7545454545454546, 0.78, 1.0, 1.0, 0.3938271822694148, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21729086973814107, 0.21729086973814107, 0.3529045339846827], 
reward next is 0.6471, 
noisyNet noise sample is [array([0.40462163], dtype=float32), 0.68709874]. 
=============================================
[2019-03-22 23:25:49,479] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.2615014e-38 1.0000000e+00 1.2528709e-29 2.7765452e-27 1.6318906e-21], sum to 1.0000
[2019-03-22 23:25:49,488] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0977
[2019-03-22 23:25:49,493] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.36666666666667, 76.0, 1.0, 2.0, 0.6174881692839621, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 689727.9462602743, 689727.9462602743, 144779.0078720468], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6172800.0000, 
sim time next is 6173400.0000, 
raw observation next is [20.18333333333333, 78.5, 1.0, 2.0, 0.607136479421419, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 679379.2565546185, 679379.2565546185, 144112.2768819263], 
processed observation next is [1.0, 0.43478260869565216, 0.5537878787878786, 0.785, 1.0, 1.0, 0.5089205992767737, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2516219468720809, 0.2516219468720809, 0.3514933582486007], 
reward next is 0.6485, 
noisyNet noise sample is [array([-0.57251275], dtype=float32), 0.7431929]. 
=============================================
[2019-03-22 23:25:53,298] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 7.2551166e-33], sum to 1.0000
[2019-03-22 23:25:53,307] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8642
[2019-03-22 23:25:53,313] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.3, 95.0, 1.0, 2.0, 0.3648163523906655, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 408363.9273135548, 408363.9273135545, 120390.5969732762], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6240000.0000, 
sim time next is 6240600.0000, 
raw observation next is [18.3, 94.5, 1.0, 2.0, 0.3623117237766121, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 405265.1532556924, 405265.1532556924, 120047.474171607], 
processed observation next is [0.0, 0.21739130434782608, 0.4681818181818182, 0.945, 1.0, 1.0, 0.2028896547207651, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1500982049095157, 0.1500982049095157, 0.29279871749172437], 
reward next is 0.7072, 
noisyNet noise sample is [array([-1.1966615], dtype=float32), -0.128128]. 
=============================================
[2019-03-22 23:25:54,084] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 2.6346813e-36], sum to 1.0000
[2019-03-22 23:25:54,092] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1578
[2019-03-22 23:25:54,099] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.2, 89.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 193864.3179972029, 193864.3179972026, 65901.30770244595], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6501600.0000, 
sim time next is 6502200.0000, 
raw observation next is [12.38333333333333, 89.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 205942.0933168971, 205942.0933168968, 68067.63350489954], 
processed observation next is [1.0, 0.2608695652173913, 0.19924242424242405, 0.89, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07627484937662855, 0.07627484937662844, 0.16601861830463302], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.8585595], dtype=float32), 0.11297673]. 
=============================================
[2019-03-22 23:26:00,630] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.5664295e-36 1.0000000e+00 6.4105149e-32 5.4849855e-31 2.2344578e-27], sum to 1.0000
[2019-03-22 23:26:00,642] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4192
[2019-03-22 23:26:00,649] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.6, 91.0, 1.0, 2.0, 0.8006128884854756, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 913902.5402597273, 913902.5402597273, 181799.0309368665], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6426000.0000, 
sim time next is 6426600.0000, 
raw observation next is [21.33333333333334, 91.33333333333334, 1.0, 2.0, 0.969147303010344, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 82.73331824632892, 1106301.080583458, 1106301.080583458, 211706.8050501671], 
processed observation next is [1.0, 0.391304347826087, 0.6060606060606063, 0.9133333333333334, 1.0, 1.0, 0.9614341287629299, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.543965325467503, 0.40974114095683634, 0.40974114095683634, 0.5163580610979686], 
reward next is 0.4836, 
noisyNet noise sample is [array([1.4947501], dtype=float32), 1.6497499]. 
=============================================
[2019-03-22 23:26:02,361] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 6.2771871e-37 1.8352413e-26], sum to 1.0000
[2019-03-22 23:26:02,370] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9707
[2019-03-22 23:26:02,383] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 69.66666666666667, 1.0, 2.0, 0.3387713363795454, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 370892.8106745802, 370892.8106745805, 114911.097322427], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6457200.0000, 
sim time next is 6457800.0000, 
raw observation next is [20.0, 68.33333333333333, 1.0, 2.0, 0.3313716016734754, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 361536.328370843, 361536.3283708433, 113929.7773570245], 
processed observation next is [1.0, 0.7391304347826086, 0.5454545454545454, 0.6833333333333332, 1.0, 1.0, 0.16421450209184424, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13390234384105298, 0.13390234384105307, 0.27787750574884024], 
reward next is 0.7221, 
noisyNet noise sample is [array([-2.0369177], dtype=float32), -0.86486536]. 
=============================================
[2019-03-22 23:26:02,481] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 6.8870968e-37 3.2317047e-34 6.4694518e-24], sum to 1.0000
[2019-03-22 23:26:02,489] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8268
[2019-03-22 23:26:02,492] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.6, 73.0, 1.0, 2.0, 0.5078891182024328, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 579492.9837543307, 579492.9837543307, 142392.9261750766], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6421200.0000, 
sim time next is 6421800.0000, 
raw observation next is [24.5, 73.5, 1.0, 2.0, 0.4875527366354728, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 556291.5873972651, 556291.5873972651, 139981.9098529117], 
processed observation next is [1.0, 0.30434782608695654, 0.75, 0.735, 1.0, 1.0, 0.359440920794341, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20603392125824635, 0.20603392125824635, 0.34141929232417484], 
reward next is 0.6586, 
noisyNet noise sample is [array([-1.1633126], dtype=float32), 2.0627549]. 
=============================================
[2019-03-22 23:26:05,559] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:26:05,569] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4006
[2019-03-22 23:26:05,576] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.5, 75.0, 1.0, 2.0, 0.2186431782385491, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 237392.6347049871, 237392.6347049874, 75188.25774682713], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6474000.0000, 
sim time next is 6474600.0000, 
raw observation next is [15.5, 75.0, 1.0, 2.0, 0.2184418313415192, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 237173.9682709924, 237173.9682709927, 75164.1622824411], 
processed observation next is [1.0, 0.9565217391304348, 0.3409090909090909, 0.75, 1.0, 1.0, 0.023052289176898992, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08784221047073792, 0.08784221047073804, 0.18332722507912463], 
reward next is 0.8167, 
noisyNet noise sample is [array([-1.3317825], dtype=float32), 1.2697957]. 
=============================================
[2019-03-22 23:26:06,687] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:26:06,702] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0902
[2019-03-22 23:26:06,709] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.41666666666667, 75.83333333333333, 1.0, 2.0, 0.2179004204796491, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 236585.9866031965, 236585.9866031965, 75149.08572564187], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6477000.0000, 
sim time next is 6477600.0000, 
raw observation next is [15.33333333333333, 76.66666666666667, 1.0, 2.0, 0.2182949285429692, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 237014.4291914853, 237014.4291914853, 75229.76846226396], 
processed observation next is [1.0, 1.0, 0.3333333333333332, 0.7666666666666667, 1.0, 1.0, 0.022868660678711482, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08778312192277234, 0.08778312192277234, 0.18348724015186332], 
reward next is 0.8165, 
noisyNet noise sample is [array([0.30282003], dtype=float32), 0.38702333]. 
=============================================
[2019-03-22 23:26:07,927] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.1902608e-28], sum to 1.0000
[2019-03-22 23:26:07,936] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4058
[2019-03-22 23:26:07,940] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 57.0, 1.0, 2.0, 0.4353145576061355, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 472758.7386672294, 472758.7386672294, 101307.8654451065], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6516000.0000, 
sim time next is 6516600.0000, 
raw observation next is [18.71666666666667, 57.5, 1.0, 2.0, 0.4510384059444616, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 489843.6985975142, 489843.6985975142, 102847.9012556882], 
processed observation next is [1.0, 0.43478260869565216, 0.48712121212121223, 0.575, 1.0, 1.0, 0.31379800743057695, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1814235920731534, 0.1814235920731534, 0.25084853964802], 
reward next is 0.7492, 
noisyNet noise sample is [array([-1.0277175], dtype=float32), 0.28354385]. 
=============================================
[2019-03-22 23:26:09,273] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.0016888e-35 4.9420015e-23], sum to 1.0000
[2019-03-22 23:26:09,282] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0055
[2019-03-22 23:26:09,290] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.23333333333333, 77.33333333333333, 1.0, 2.0, 0.5909098276717671, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 650118.9431124664, 650118.9431124664, 138136.6186362879], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6770400.0000, 
sim time next is 6771000.0000, 
raw observation next is [19.61666666666667, 77.16666666666667, 1.0, 2.0, 0.6117938129872159, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 677163.7648368177, 677163.7648368181, 141757.5626392849], 
processed observation next is [1.0, 0.34782608695652173, 0.5280303030303032, 0.7716666666666667, 1.0, 1.0, 0.5147422662340199, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.25080139438400656, 0.2508013943840067, 0.34575015277874366], 
reward next is 0.6542, 
noisyNet noise sample is [array([0.03805622], dtype=float32), 0.35956064]. 
=============================================
[2019-03-22 23:26:09,309] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[79.82707 ]
 [80.15522 ]
 [80.767715]
 [81.40436 ]
 [81.65253 ]], R is [[79.52189636]
 [79.38975525]
 [79.2711792 ]
 [79.17836761]
 [79.11958313]].
[2019-03-22 23:26:10,638] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-22 23:26:10,639] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-22 23:26:10,641] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-22 23:26:10,641] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:26:10,642] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-22 23:26:10,643] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:26:10,642] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-22 23:26:10,646] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:26:10,647] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:26:10,641] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-22 23:26:10,652] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:26:10,666] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run25
[2019-03-22 23:26:10,667] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run25
[2019-03-22 23:26:10,703] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run25
[2019-03-22 23:26:10,705] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run25
[2019-03-22 23:26:10,722] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run25
[2019-03-22 23:26:17,309] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.07928191], dtype=float32), 0.022730641]
[2019-03-22 23:26:17,311] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.41250432833333, 51.75007118166667, 1.0, 2.0, 0.2291808490577049, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 248824.7367121816, 248824.7367121816, 76765.42832078332]
[2019-03-22 23:26:17,313] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:26:17,314] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.7384358152841662
[2019-03-22 23:26:18,323] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.07928191], dtype=float32), 0.022730641]
[2019-03-22 23:26:18,324] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [14.83333333333333, 89.00000000000001, 1.0, 2.0, 0.2345604325951616, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 254679.376816901, 254679.3768169013, 80254.30294790174]
[2019-03-22 23:26:18,325] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:26:18,332] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.863993600922194
[2019-03-22 23:26:20,440] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.07928191], dtype=float32), 0.022730641]
[2019-03-22 23:26:20,441] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [26.0, 49.0, 1.0, 2.0, 0.9625467646528522, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1089310.147527853, 1089310.147527853, 198879.6903166499]
[2019-03-22 23:26:20,443] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:26:20,446] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.6026856e-33 2.0549102e-26], sampled 0.07930028785821164
[2019-03-22 23:26:20,447] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1089310.147527853 W.
[2019-03-22 23:26:21,242] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.07928191], dtype=float32), 0.022730641]
[2019-03-22 23:26:21,244] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.2, 39.0, 1.0, 2.0, 0.3883602532843591, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 421708.5963649246, 421708.5963649249, 114503.6877381404]
[2019-03-22 23:26:21,246] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:26:21,247] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.7328445472338923
[2019-03-22 23:26:28,993] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.07928191], dtype=float32), 0.022730641]
[2019-03-22 23:26:28,995] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.25, 86.0, 1.0, 2.0, 0.4702262102638826, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 536426.183746273, 536426.1837462727, 141290.2866111378]
[2019-03-22 23:26:28,997] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:26:29,000] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 9.340604e-38], sampled 0.2898965650468144
[2019-03-22 23:26:29,710] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.07928191], dtype=float32), 0.022730641]
[2019-03-22 23:26:29,712] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.31714996, 80.35448539, 1.0, 2.0, 0.4858617647562593, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 553776.8247900858, 553776.8247900858, 141989.2766836965]
[2019-03-22 23:26:29,713] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:26:29,716] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 3.6377988e-36], sampled 0.4368636834210702
[2019-03-22 23:26:55,970] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.07928191], dtype=float32), 0.022730641]
[2019-03-22 23:26:55,971] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.547146405, 92.90110440000001, 1.0, 2.0, 0.3246121020527587, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 353974.1993135199, 353974.1993135199, 117695.9823762001]
[2019-03-22 23:26:55,972] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:26:55,976] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.23152229993227313
[2019-03-22 23:27:04,179] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.07928191], dtype=float32), 0.022730641]
[2019-03-22 23:27:04,179] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.598345795, 54.63074352, 1.0, 2.0, 0.3233541052303061, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 354208.0301198314, 354208.0301198311, 118183.1366725447]
[2019-03-22 23:27:04,180] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:27:04,184] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.3515601755610067
[2019-03-22 23:27:11,828] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.07928191], dtype=float32), 0.022730641]
[2019-03-22 23:27:11,830] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.0, 90.0, 1.0, 2.0, 0.4084261488867494, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 462388.4454970419, 462388.4454970416, 131182.881633042]
[2019-03-22 23:27:11,832] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:27:11,834] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 3.9342046e-38], sampled 0.9522681605066475
[2019-03-22 23:27:22,675] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.07928191], dtype=float32), 0.022730641]
[2019-03-22 23:27:22,676] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.64892118, 92.11981135333333, 1.0, 2.0, 0.3565648651936961, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 399053.0961922347, 399053.0961922347, 123997.4073871064]
[2019-03-22 23:27:22,677] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:27:22,679] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.5480462042353083
[2019-03-22 23:27:39,160] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.07928191], dtype=float32), 0.022730641]
[2019-03-22 23:27:39,161] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [12.89298876, 84.13195631, 1.0, 2.0, 0.201556511111431, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 218827.1612911561, 218827.1612911561, 74826.64364809674]
[2019-03-22 23:27:39,164] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:27:39,168] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.866288942652971
[2019-03-22 23:27:45,322] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.07928191], dtype=float32), 0.022730641]
[2019-03-22 23:27:45,323] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.9, 65.0, 1.0, 2.0, 0.3834802665825162, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 432014.236849494, 432014.236849494, 127640.2473294011]
[2019-03-22 23:27:45,325] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:27:45,330] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.18033429736244877
[2019-03-22 23:27:57,956] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9309 1705967916.6745 465.0000
[2019-03-22 23:27:58,251] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1148 1656229146.4555 80.0000
[2019-03-22 23:27:58,260] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2492 1773187030.7201 173.0000
[2019-03-22 23:27:58,532] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5599 1663815647.6096 105.0000
[2019-03-22 23:27:58,567] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3485 1683325900.1134 214.0000
[2019-03-22 23:27:59,584] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 600000, evaluation results [600000.0, 8512.249193409023, 1773187030.7201214, 173.0, 9061.114827412715, 1656229146.4555063, 80.0, 8856.559925897878, 1663815647.6095803, 105.0, 8596.930884973775, 1705967916.6744611, 465.0, 8574.348472942609, 1683325900.1133502, 214.0]
[2019-03-22 23:28:01,567] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.7077172e-35], sum to 1.0000
[2019-03-22 23:28:01,575] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4198
[2019-03-22 23:28:01,580] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 63.0, 1.0, 2.0, 0.3764471005033654, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 408800.8385666298, 408800.8385666301, 104562.6630565849], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6602400.0000, 
sim time next is 6603000.0000, 
raw observation next is [19.68333333333333, 62.33333333333333, 1.0, 2.0, 0.4664964862048044, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 506640.4699528163, 506640.4699528163, 115663.1891734445], 
processed observation next is [1.0, 0.43478260869565216, 0.5310606060606059, 0.6233333333333333, 1.0, 1.0, 0.33312060775600544, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18764461850104308, 0.18764461850104308, 0.2821053394474256], 
reward next is 0.7179, 
noisyNet noise sample is [array([-1.1416501], dtype=float32), -1.2888021]. 
=============================================
[2019-03-22 23:28:01,605] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[58.11296 ]
 [57.750286]
 [57.157665]
 [56.48415 ]
 [55.970154]], R is [[58.21103287]
 [58.37388992]
 [58.54374695]
 [58.71009827]
 [58.86783981]].
[2019-03-22 23:28:06,301] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 2.4553702e-37 3.5651093e-37 1.0834946e-32], sum to 1.0000
[2019-03-22 23:28:06,309] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2755
[2019-03-22 23:28:06,315] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.8, 82.0, 1.0, 2.0, 0.6308139089435315, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 706999.0456158122, 706999.0456158122, 147320.4838007579], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6685800.0000, 
sim time next is 6686400.0000, 
raw observation next is [19.6, 83.0, 1.0, 2.0, 0.5276803137566501, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 590708.9990413617, 590708.9990413614, 135594.6654839713], 
processed observation next is [1.0, 0.391304347826087, 0.5272727272727273, 0.83, 1.0, 1.0, 0.4096003921958126, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2187811107560599, 0.21878111075605977, 0.33071869630236905], 
reward next is 0.6693, 
noisyNet noise sample is [array([1.3188405], dtype=float32), 1.2499287]. 
=============================================
[2019-03-22 23:28:09,048] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 4.5634278e-30], sum to 1.0000
[2019-03-22 23:28:09,057] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5041
[2019-03-22 23:28:09,063] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.3, 93.0, 1.0, 2.0, 0.3681859759762563, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 410849.3698832141, 410849.3698832141, 120094.4352903036], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6718200.0000, 
sim time next is 6718800.0000, 
raw observation next is [18.3, 93.0, 1.0, 2.0, 0.3661041197434904, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 408521.7013301789, 408521.7013301786, 119921.4914555787], 
processed observation next is [1.0, 0.782608695652174, 0.4681818181818182, 0.93, 1.0, 1.0, 0.20763014967936297, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15130433382599218, 0.15130433382599207, 0.2924914425745822], 
reward next is 0.7075, 
noisyNet noise sample is [array([-0.9232092], dtype=float32), 0.08116525]. 
=============================================
[2019-03-22 23:28:09,374] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 6.360213e-33], sum to 1.0000
[2019-03-22 23:28:09,384] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1784
[2019-03-22 23:28:09,387] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.53333333333333, 98.66666666666667, 1.0, 2.0, 0.3639510070105123, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 405565.9464399148, 405565.9464399145, 119505.8757424804], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6733200.0000, 
sim time next is 6733800.0000, 
raw observation next is [17.45, 98.0, 1.0, 2.0, 0.3582718134634832, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 398332.9101059245, 398332.9101059248, 118664.6720466662], 
processed observation next is [1.0, 0.9565217391304348, 0.4295454545454545, 0.98, 1.0, 1.0, 0.19783976682935397, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14753070744663868, 0.14753070744663882, 0.28942602938211265], 
reward next is 0.7106, 
noisyNet noise sample is [array([-0.7137488], dtype=float32), -1.9525995]. 
=============================================
[2019-03-22 23:28:10,315] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 4.3108674e-31], sum to 1.0000
[2019-03-22 23:28:10,322] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5075
[2019-03-22 23:28:10,330] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.2, 90.0, 1.0, 2.0, 0.3265575088015993, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 355750.8621235488, 355750.8621235485, 113402.0108787447], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6757200.0000, 
sim time next is 6757800.0000, 
raw observation next is [17.16666666666667, 89.0, 1.0, 2.0, 0.3154883412537207, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 342819.1929298263, 342819.1929298266, 112325.1447113402], 
processed observation next is [1.0, 0.21739130434782608, 0.4166666666666669, 0.89, 1.0, 1.0, 0.14436042656715087, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12697007145549125, 0.12697007145549133, 0.2739637675886346], 
reward next is 0.7260, 
noisyNet noise sample is [array([-0.5571231], dtype=float32), -1.8828037]. 
=============================================
[2019-03-22 23:28:11,050] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 2.1292858e-38], sum to 1.0000
[2019-03-22 23:28:11,059] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5639
[2019-03-22 23:28:11,062] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.2, 93.0, 1.0, 2.0, 0.3216150273591896, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 352466.5883604378, 352466.5883604381, 113802.7531004965], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6753600.0000, 
sim time next is 6754200.0000, 
raw observation next is [17.2, 92.5, 1.0, 2.0, 0.3592081464821024, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 393478.911608036, 393478.911608036, 116505.8107564511], 
processed observation next is [1.0, 0.17391304347826086, 0.41818181818181815, 0.925, 1.0, 1.0, 0.199010183102628, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14573293022519854, 0.14573293022519854, 0.28416051404012466], 
reward next is 0.7158, 
noisyNet noise sample is [array([-1.262571], dtype=float32), -0.24467236]. 
=============================================
[2019-03-22 23:28:11,267] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 6.0269877e-34], sum to 1.0000
[2019-03-22 23:28:11,276] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9440
[2019-03-22 23:28:11,284] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.16666666666667, 89.0, 1.0, 2.0, 0.3154883412537207, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 342819.1929298263, 342819.1929298266, 112325.1447113402], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6757800.0000, 
sim time next is 6758400.0000, 
raw observation next is [17.13333333333333, 88.0, 1.0, 2.0, 0.2986826663400237, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 324324.7793338061, 324324.7793338058, 111103.646914126], 
processed observation next is [1.0, 0.21739130434782608, 0.415151515151515, 0.88, 1.0, 1.0, 0.12335333292502963, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1201202886421504, 0.12012028864215028, 0.2709845046686], 
reward next is 0.7290, 
noisyNet noise sample is [array([1.711168], dtype=float32), -0.926958]. 
=============================================
[2019-03-22 23:28:25,427] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.0207098e-37 1.0000000e+00 1.9778193e-31 1.0457059e-24 7.3091474e-18], sum to 1.0000
[2019-03-22 23:28:25,436] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2911
[2019-03-22 23:28:25,442] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 97.0, 1.0, 2.0, 0.4942499567241984, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 557922.7358343714, 557922.7358343714, 134424.8859271218], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7028400.0000, 
sim time next is 7029000.0000, 
raw observation next is [18.8, 97.0, 1.0, 2.0, 0.5903960097014547, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 666808.4837820142, 666808.4837820145, 145155.3578883803], 
processed observation next is [1.0, 0.34782608695652173, 0.49090909090909096, 0.97, 1.0, 1.0, 0.4879950121268183, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.24696610510444972, 0.2469661051044498, 0.3540374582643422], 
reward next is 0.6460, 
noisyNet noise sample is [array([1.1517872], dtype=float32), -0.9624026]. 
=============================================
[2019-03-22 23:28:25,453] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[67.19502 ]
 [67.83306 ]
 [67.81608 ]
 [67.78287 ]
 [67.700066]], R is [[66.30902863]
 [66.31807709]
 [66.35016632]
 [66.382164  ]
 [66.41374207]].
[2019-03-22 23:28:34,413] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.8694220e-34 1.0000000e+00 1.6781967e-29 2.6120256e-28 7.7484139e-17], sum to 1.0000
[2019-03-22 23:28:34,425] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9811
[2019-03-22 23:28:34,431] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.3, 44.66666666666666, 1.0, 2.0, 0.7769412797872727, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 853558.8635240407, 853558.8635240407, 159207.7011483223], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7228200.0000, 
sim time next is 7228800.0000, 
raw observation next is [24.4, 45.0, 1.0, 2.0, 0.8100081966237735, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 892182.0018925531, 892182.0018925531, 164231.8794847278], 
processed observation next is [1.0, 0.6956521739130435, 0.7454545454545454, 0.45, 1.0, 1.0, 0.7625102457797169, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.33043777847872335, 0.33043777847872335, 0.40056555971884833], 
reward next is 0.5994, 
noisyNet noise sample is [array([-0.33188054], dtype=float32), -0.20102644]. 
=============================================
[2019-03-22 23:28:34,583] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 2.6028534e-29], sum to 1.0000
[2019-03-22 23:28:34,594] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7076
[2019-03-22 23:28:34,600] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.9, 98.0, 1.0, 2.0, 0.3303368309730801, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 363572.8956297837, 363572.8956297837, 115002.1656544499], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7453800.0000, 
sim time next is 7454400.0000, 
raw observation next is [17.0, 97.33333333333334, 1.0, 2.0, 0.3311451201359346, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 364653.6879245663, 364653.6879245663, 115133.9148289881], 
processed observation next is [0.0, 0.2608695652173913, 0.4090909090909091, 0.9733333333333334, 1.0, 1.0, 0.16393140016991825, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13505692145354306, 0.13505692145354306, 0.2808144264121661], 
reward next is 0.7192, 
noisyNet noise sample is [array([0.81915486], dtype=float32), -1.2101871]. 
=============================================
[2019-03-22 23:28:36,984] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.2681205e-33 1.0000000e+00 9.1510109e-28 1.4918877e-25 2.3317015e-10], sum to 1.0000
[2019-03-22 23:28:36,994] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0713
[2019-03-22 23:28:36,999] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.9, 43.33333333333334, 1.0, 2.0, 0.7850076798930545, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 853624.2656079446, 853624.2656079449, 157368.6043812418], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7225800.0000, 
sim time next is 7226400.0000, 
raw observation next is [24.0, 43.66666666666667, 1.0, 2.0, 0.7900278830005295, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 861457.7595928891, 861457.7595928891, 158733.883059541], 
processed observation next is [1.0, 0.6521739130434783, 0.7272727272727273, 0.4366666666666667, 1.0, 1.0, 0.7375348537506617, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3190584294788478, 0.3190584294788478, 0.3871558123403439], 
reward next is 0.6128, 
noisyNet noise sample is [array([0.45612326], dtype=float32), 0.99886674]. 
=============================================
[2019-03-22 23:28:37,676] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.5658656e-26], sum to 1.0000
[2019-03-22 23:28:37,684] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8745
[2019-03-22 23:28:37,689] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.16666666666667, 52.0, 1.0, 2.0, 0.3059426331513106, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 332210.7119884035, 332210.7119884032, 111322.8554638674], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7238400.0000, 
sim time next is 7239000.0000, 
raw observation next is [21.88333333333334, 53.5, 1.0, 2.0, 0.3037000757149186, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 329774.7840462131, 329774.7840462134, 110816.393410165], 
processed observation next is [1.0, 0.782608695652174, 0.6310606060606063, 0.535, 1.0, 1.0, 0.12962509464364821, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12213880890600484, 0.12213880890600495, 0.2702838863662561], 
reward next is 0.7297, 
noisyNet noise sample is [array([-0.5686148], dtype=float32), 1.144826]. 
=============================================
[2019-03-22 23:28:37,722] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[70.51633]
 [70.67769]
 [70.87432]
 [71.13874]
 [71.49824]], R is [[70.39080811]
 [70.41537476]
 [70.43786621]
 [70.45904541]
 [70.47947693]].
[2019-03-22 23:28:39,755] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 8.853756e-33 6.306722e-33 8.649211e-20], sum to 1.0000
[2019-03-22 23:28:39,765] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2140
[2019-03-22 23:28:39,769] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.18333333333333, 62.66666666666666, 1.0, 2.0, 0.430988492086108, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 468058.2990259976, 468058.2990259976, 108003.523079349], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7290600.0000, 
sim time next is 7291200.0000, 
raw observation next is [19.56666666666667, 62.33333333333334, 1.0, 2.0, 0.4590376567941428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 498535.623159236, 498535.623159236, 114012.7726571581], 
processed observation next is [1.0, 0.391304347826087, 0.5257575757575759, 0.6233333333333334, 1.0, 1.0, 0.3237970709926785, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1846428233923096, 0.1846428233923096, 0.2780799333101417], 
reward next is 0.7219, 
noisyNet noise sample is [array([0.35531402], dtype=float32), 1.4418627]. 
=============================================
[2019-03-22 23:28:43,974] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.2877606e-34], sum to 1.0000
[2019-03-22 23:28:43,982] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0086
[2019-03-22 23:28:43,987] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.13333333333333, 91.0, 1.0, 2.0, 0.5039877562917138, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 574946.8118413716, 574946.8118413716, 142206.6411741319], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7582800.0000, 
sim time next is 7583400.0000, 
raw observation next is [21.85, 91.0, 1.0, 2.0, 0.4950602386115943, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 564907.62761187, 564907.62761187, 140573.3972594918], 
processed observation next is [0.0, 0.782608695652174, 0.6295454545454546, 0.91, 1.0, 1.0, 0.36882529826449284, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20922504726365554, 0.20922504726365554, 0.3428619445353458], 
reward next is 0.6571, 
noisyNet noise sample is [array([-0.85954857], dtype=float32), 0.089347795]. 
=============================================
[2019-03-22 23:28:47,544] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.8438836e-36 1.5944394e-30], sum to 1.0000
[2019-03-22 23:28:47,556] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7234
[2019-03-22 23:28:47,564] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.35, 92.0, 1.0, 2.0, 0.4733233603294595, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 539971.8632725861, 539971.8632725865, 137171.4383427846], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7684200.0000, 
sim time next is 7684800.0000, 
raw observation next is [21.26666666666667, 92.33333333333334, 1.0, 2.0, 0.4694875148423834, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 535559.9652041629, 535559.9652041629, 136657.9127043033], 
processed observation next is [1.0, 0.9565217391304348, 0.6030303030303031, 0.9233333333333335, 1.0, 1.0, 0.33685939355297917, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19835554266820848, 0.19835554266820848, 0.3333119822056178], 
reward next is 0.6667, 
noisyNet noise sample is [array([-0.17246574], dtype=float32), 1.4574003]. 
=============================================
[2019-03-22 23:28:48,536] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 3.6011073e-32], sum to 1.0000
[2019-03-22 23:28:48,545] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3548
[2019-03-22 23:28:48,550] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.86666666666667, 98.5, 1.0, 2.0, 0.3337298015087308, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 367534.4966217313, 367534.4966217316, 115338.0015511576], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7447800.0000, 
sim time next is 7448400.0000, 
raw observation next is [16.8, 99.0, 1.0, 2.0, 0.3330412526856016, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 366682.7148065521, 366682.7148065524, 115251.6484719345], 
processed observation next is [0.0, 0.21739130434782608, 0.4, 0.99, 1.0, 1.0, 0.16630156585700195, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1358084128913156, 0.1358084128913157, 0.2811015816388646], 
reward next is 0.7189, 
noisyNet noise sample is [array([0.7031873], dtype=float32), -1.1159415]. 
=============================================
[2019-03-22 23:28:52,196] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-22 23:28:52,198] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-22 23:28:52,199] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-22 23:28:52,200] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:28:52,201] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:28:52,202] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-22 23:28:52,203] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-22 23:28:52,204] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-22 23:28:52,207] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:28:52,208] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:28:52,208] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:28:52,228] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run26
[2019-03-22 23:28:52,249] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run26
[2019-03-22 23:28:52,251] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run26
[2019-03-22 23:28:52,272] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run26
[2019-03-22 23:28:52,312] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run26
[2019-03-22 23:29:00,002] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.27074707], dtype=float32), 0.0064885165]
[2019-03-22 23:29:00,003] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [14.0, 94.0, 1.0, 2.0, 0.211704010206047, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 229856.6272607542, 229856.6272607542, 76358.68356001898]
[2019-03-22 23:29:00,004] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:29:00,007] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 2.4302766e-36], sampled 0.10180964369223544
[2019-03-22 23:29:03,215] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.27074707], dtype=float32), 0.0064885165]
[2019-03-22 23:29:03,216] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.11666666666667, 43.16666666666667, 1.0, 2.0, 0.306047337883558, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 332302.7904673467, 332302.7904673467, 96199.54303467838]
[2019-03-22 23:29:03,217] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:29:03,220] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.6080180641763611
[2019-03-22 23:29:11,137] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.27074707], dtype=float32), 0.0064885165]
[2019-03-22 23:29:11,138] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [27.90975707333333, 74.86441198666668, 1.0, 2.0, 0.8412109530752008, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 945381.1442428398, 945381.1442428398, 201387.0163105768]
[2019-03-22 23:29:11,140] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:29:11,144] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.9250177e-37 6.6109178e-28], sampled 0.9505538372718131
[2019-03-22 23:29:17,496] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.27074707], dtype=float32), 0.0064885165]
[2019-03-22 23:29:17,498] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.0, 90.0, 1.0, 2.0, 0.3776623395012781, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 423297.5514513781, 423297.5514513781, 126046.1637093766]
[2019-03-22 23:29:17,501] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:29:17,504] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 8.317707e-35], sampled 0.01580545182993165
[2019-03-22 23:29:39,424] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.27074707], dtype=float32), 0.0064885165]
[2019-03-22 23:29:39,426] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.9, 89.0, 1.0, 2.0, 0.3546017523447813, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 396228.9036424035, 396228.9036424035, 123549.1711935959]
[2019-03-22 23:29:39,427] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:29:39,428] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 3.1821114e-34], sampled 0.8614185781053422
[2019-03-22 23:29:54,869] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.27074707], dtype=float32), 0.0064885165]
[2019-03-22 23:29:54,871] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.83333333333334, 57.33333333333334, 1.0, 2.0, 0.2751662792696297, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 298781.65004457, 298781.65004457, 90449.28975431381]
[2019-03-22 23:29:54,872] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:29:54,875] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.4430828196814679
[2019-03-22 23:30:00,129] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.27074707], dtype=float32), 0.0064885165]
[2019-03-22 23:30:00,132] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [13.89759198, 96.249075085, 1.0, 2.0, 0.2231572062110335, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 242283.4684042317, 242283.4684042317, 82546.02197115264]
[2019-03-22 23:30:00,135] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:30:00,139] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.16770886223945847
[2019-03-22 23:30:01,521] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.27074707], dtype=float32), 0.0064885165]
[2019-03-22 23:30:01,523] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [23.33520372, 86.97900564, 1.0, 2.0, 0.4994592100889692, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 568925.7808313243, 568925.7808313239, 147055.6781146864]
[2019-03-22 23:30:01,525] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:30:01,528] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 5.0162573e-34], sampled 0.9075166560199978
[2019-03-22 23:30:02,343] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.27074707], dtype=float32), 0.0064885165]
[2019-03-22 23:30:02,345] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.0, 83.0, 1.0, 2.0, 0.4371479130335169, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 498049.0336379699, 498049.0336379702, 132181.8080656275]
[2019-03-22 23:30:02,345] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:30:02,348] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.3100244e-31], sampled 0.5321917137662987
[2019-03-22 23:30:18,019] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.27074707], dtype=float32), 0.0064885165]
[2019-03-22 23:30:18,021] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [25.11425369333334, 72.82597500666668, 1.0, 2.0, 0.5147775193464567, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 586705.0258119879, 586705.0258119876, 148554.7449898474]
[2019-03-22 23:30:18,024] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:30:18,028] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 2.1359073e-31], sampled 0.8570323967184053
[2019-03-22 23:30:40,325] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1147 1656209757.7786 80.0000
[2019-03-22 23:30:40,390] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9310 1705987275.5940 465.0000
[2019-03-22 23:30:40,434] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5598 1663796639.0689 105.0000
[2019-03-22 23:30:40,444] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3485 1683325900.1134 214.0000
[2019-03-22 23:30:40,462] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2494 1773207034.4548 173.0000
[2019-03-22 23:30:41,477] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 625000, evaluation results [625000.0, 8512.249429056992, 1773207034.4547563, 173.0, 9061.114669779829, 1656209757.7786272, 80.0, 8856.559759326878, 1663796639.0688558, 105.0, 8596.931041181726, 1705987275.594041, 465.0, 8574.348472942609, 1683325900.1133502, 214.0]
[2019-03-22 23:30:44,186] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.1154564e-37 1.0000000e+00 2.2943431e-33 1.0697819e-31 1.1686657e-19], sum to 1.0000
[2019-03-22 23:30:44,196] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3137
[2019-03-22 23:30:44,202] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.88333333333334, 52.16666666666667, 1.0, 2.0, 0.5324168176856131, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 578276.1088357155, 578276.1088357155, 129111.6087984236], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7816200.0000, 
sim time next is 7816800.0000, 
raw observation next is [22.16666666666667, 51.33333333333334, 1.0, 2.0, 0.5307422687356788, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 576456.2454268778, 576456.2454268778, 129684.2508464807], 
processed observation next is [1.0, 0.4782608695652174, 0.6439393939393941, 0.5133333333333334, 1.0, 1.0, 0.4134278359195984, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21350231312106582, 0.21350231312106582, 0.3163030508450749], 
reward next is 0.6837, 
noisyNet noise sample is [array([-0.5628992], dtype=float32), 0.06921377]. 
=============================================
[2019-03-22 23:30:52,383] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:30:52,385] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:30:52,428] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run4
[2019-03-22 23:30:54,122] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:30:54,123] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:30:54,160] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run4
[2019-03-22 23:31:04,397] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:31:04,398] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:31:04,434] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run4
[2019-03-22 23:31:04,503] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:31:04,505] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:31:04,531] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run4
[2019-03-22 23:31:05,533] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:31:05,534] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:31:05,547] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run4
[2019-03-22 23:31:05,885] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:31:05,885] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:31:05,898] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run4
[2019-03-22 23:31:05,912] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:31:05,915] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:31:05,940] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run4
[2019-03-22 23:31:05,961] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:31:05,962] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:31:05,975] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run4
[2019-03-22 23:31:05,994] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:31:05,995] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:31:06,017] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run4
[2019-03-22 23:31:06,043] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:31:06,045] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:31:06,055] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run4
[2019-03-22 23:31:06,111] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:31:06,112] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:31:06,119] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run4
[2019-03-22 23:31:06,140] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:31:06,140] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:31:06,144] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run4
[2019-03-22 23:31:06,188] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:31:06,188] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:31:06,190] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run4
[2019-03-22 23:31:06,225] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:31:06,226] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:31:06,228] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run4
[2019-03-22 23:31:06,254] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:31:06,254] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:31:06,267] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run4
[2019-03-22 23:31:06,315] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:31:06,320] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:31:06,323] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run4
[2019-03-22 23:31:07,492] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.0489032e-37 4.7312253e-37 0.0000000e+00], sum to 1.0000
[2019-03-22 23:31:07,492] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6833
[2019-03-22 23:31:07,499] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.8, 90.33333333333334, 1.0, 2.0, 0.3283026773660909, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 361444.063750102, 361444.063750102, 114894.7602144249], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6000.0000, 
sim time next is 6600.0000, 
raw observation next is [17.75, 92.16666666666667, 1.0, 2.0, 0.3328626004379693, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 367466.3072438791, 367466.3072438791, 115614.3906471943], 
processed observation next is [1.0, 0.043478260869565216, 0.4431818181818182, 0.9216666666666667, 1.0, 1.0, 0.1660782505474616, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13609863231254782, 0.13609863231254782, 0.28198631865169344], 
reward next is 0.7180, 
noisyNet noise sample is [array([-1.3493569], dtype=float32), -0.9945143]. 
=============================================
[2019-03-22 23:31:07,954] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.1504227e-35 1.2864293e-35], sum to 1.0000
[2019-03-22 23:31:07,957] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5654
[2019-03-22 23:31:07,961] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.3, 87.5, 1.0, 2.0, 0.8086087739816027, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 917089.1860781237, 917089.1860781237, 176008.7295427828], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 34200.0000, 
sim time next is 34800.0000, 
raw observation next is [20.53333333333333, 86.0, 1.0, 2.0, 0.7514199133160946, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 852386.5117498012, 852386.5117498016, 167848.6027280441], 
processed observation next is [1.0, 0.391304347826087, 0.5696969696969696, 0.86, 1.0, 1.0, 0.6892748916451182, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.31569870805548195, 0.31569870805548206, 0.40938683592205877], 
reward next is 0.5906, 
noisyNet noise sample is [array([0.6108868], dtype=float32), -0.4590372]. 
=============================================
[2019-03-22 23:31:08,922] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.2043335e-34 7.4226109e-32], sum to 1.0000
[2019-03-22 23:31:08,934] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1645
[2019-03-22 23:31:08,937] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.5, 62.66666666666667, 1.0, 2.0, 0.5027630886267299, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 546050.0884987417, 546050.0884987417, 111444.9751243851], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 119400.0000, 
sim time next is 120000.0000, 
raw observation next is [19.0, 61.33333333333334, 1.0, 2.0, 0.4991750342260038, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 542150.9358102024, 542150.9358102027, 113064.0230000756], 
processed observation next is [1.0, 0.391304347826087, 0.5, 0.6133333333333334, 1.0, 1.0, 0.3739687927825047, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20079664289266755, 0.2007966428926677, 0.27576590975628196], 
reward next is 0.7242, 
noisyNet noise sample is [array([-0.37217474], dtype=float32), 1.8374001]. 
=============================================
[2019-03-22 23:31:08,945] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[62.988655]
 [63.27871 ]
 [63.45305 ]
 [63.792828]
 [64.32411 ]], R is [[63.05899429]
 [63.15658951]
 [63.26564789]
 [63.37678146]
 [63.49259567]].
[2019-03-22 23:31:18,809] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 6.6882737e-31 3.2759644e-09 4.9088385e-12], sum to 1.0000
[2019-03-22 23:31:18,818] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5431
[2019-03-22 23:31:18,823] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 83.0, 1.0, 2.0, 0.3046101367155888, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 331520.6916012447, 331520.6916012444, 111767.4649504162], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 602400.0000, 
sim time next is 603000.0000, 
raw observation next is [18.0, 83.0, 1.0, 2.0, 0.3046434892528854, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 331555.6471144638, 331555.6471144636, 111769.2550915364], 
processed observation next is [1.0, 1.0, 0.45454545454545453, 0.83, 1.0, 1.0, 0.13080436156610675, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12279838782017177, 0.1227983878201717, 0.27260793924764976], 
reward next is 0.7274, 
noisyNet noise sample is [array([-1.6495551], dtype=float32), -0.8247843]. 
=============================================
[2019-03-22 23:31:18,839] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[68.68874]
 [68.67575]
 [68.67039]
 [68.6386 ]
 [68.63231]], R is [[68.74008179]
 [68.78007507]
 [68.81957245]
 [68.85852051]
 [68.89688873]].
[2019-03-22 23:31:19,666] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.0125983e-23 7.8742670e-27], sum to 1.0000
[2019-03-22 23:31:19,675] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0295
[2019-03-22 23:31:19,684] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.33333333333334, 69.0, 1.0, 2.0, 0.2815254242352801, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 305688.7208169056, 305688.7208169053, 106909.0406400628], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 234600.0000, 
sim time next is 235200.0000, 
raw observation next is [18.66666666666667, 74.0, 1.0, 2.0, 0.283334489679721, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 307653.6794868903, 307653.6794868903, 107466.9080343884], 
processed observation next is [0.0, 0.7391304347826086, 0.4848484848484851, 0.74, 1.0, 1.0, 0.10416811209965127, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11394580721736679, 0.11394580721736679, 0.2621144098399717], 
reward next is 0.7379, 
noisyNet noise sample is [array([1.3317473], dtype=float32), -0.22505435]. 
=============================================
[2019-03-22 23:31:23,092] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 3.7722957e-35 3.6764508e-24 7.5993054e-23], sum to 1.0000
[2019-03-22 23:31:23,100] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8977
[2019-03-22 23:31:23,106] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.66666666666666, 55.00000000000001, 1.0, 2.0, 0.3546590966063494, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 395468.6744896457, 395468.6744896454, 118867.8198843345], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 678000.0000, 
sim time next is 678600.0000, 
raw observation next is [23.5, 55.5, 1.0, 2.0, 0.3521409941842671, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 392303.5166022091, 392303.5166022094, 118511.1596716252], 
processed observation next is [1.0, 0.8695652173913043, 0.7045454545454546, 0.555, 1.0, 1.0, 0.19017624273033384, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14529759874155893, 0.14529759874155904, 0.2890516089551834], 
reward next is 0.7109, 
noisyNet noise sample is [array([0.44998315], dtype=float32), -1.3427101]. 
=============================================
[2019-03-22 23:31:33,617] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-22 23:31:33,622] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-22 23:31:33,622] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:31:33,624] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-22 23:31:33,625] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-22 23:31:33,628] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:31:33,627] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-22 23:31:33,630] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:31:33,630] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-22 23:31:33,631] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:31:33,634] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:31:33,655] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run27
[2019-03-22 23:31:33,676] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run27
[2019-03-22 23:31:33,696] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run27
[2019-03-22 23:31:33,697] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run27
[2019-03-22 23:31:33,698] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run27
[2019-03-22 23:32:03,767] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08709571], dtype=float32), -0.08548309]
[2019-03-22 23:32:03,768] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [15.63333333333333, 52.66666666666667, 1.0, 2.0, 0.2182135406592891, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 236915.035505458, 236915.0355054584, 75014.39733530415]
[2019-03-22 23:32:03,771] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:32:03,772] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 8.6522344e-38 6.4519976e-33], sampled 0.08085287647934603
[2019-03-22 23:32:04,658] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08709571], dtype=float32), -0.08548309]
[2019-03-22 23:32:04,659] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.0, 83.0, 1.0, 2.0, 0.3831842627687571, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 430324.9633657968, 430324.963365797, 122595.8501004071]
[2019-03-22 23:32:04,659] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:32:04,665] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 2.439317e-26 2.842937e-23], sampled 0.8988968416886598
[2019-03-22 23:32:22,069] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08709571], dtype=float32), -0.08548309]
[2019-03-22 23:32:22,071] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.86666666666667, 78.66666666666667, 1.0, 2.0, 0.573349278581334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 653889.7379266912, 653889.7379266908, 155293.2880825112]
[2019-03-22 23:32:22,072] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:32:22,076] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 3.8829745e-38 7.6050840e-21 4.3421221e-18], sampled 0.2186688830708633
[2019-03-22 23:32:58,014] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08709571], dtype=float32), -0.08548309]
[2019-03-22 23:32:58,015] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.44284466333334, 67.83603668, 1.0, 2.0, 0.4113657805875268, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 458967.1898591414, 458967.1898591414, 128058.0392396772]
[2019-03-22 23:32:58,017] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:32:58,021] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.0332061e-28 3.4428912e-25], sampled 0.28357655307675245
[2019-03-22 23:33:04,213] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08709571], dtype=float32), -0.08548309]
[2019-03-22 23:33:04,214] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.76542517, 49.10774322666667, 1.0, 2.0, 0.5589049043390242, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 623818.4337284906, 623818.4337284906, 142461.4685499019]
[2019-03-22 23:33:04,217] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:33:04,219] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.8491538e-25 1.7015574e-22], sampled 0.6881563059595315
[2019-03-22 23:33:21,436] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5598 1663796639.0689 105.0000
[2019-03-22 23:33:21,873] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2492 1773187030.7201 173.0000
[2019-03-22 23:33:21,874] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9309 1705967916.6745 465.0000
[2019-03-22 23:33:22,130] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.6166 1683282454.6264 214.0000
[2019-03-22 23:33:22,150] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1147 1656209757.7786 80.0000
[2019-03-22 23:33:23,166] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 650000, evaluation results [650000.0, 8512.249193409023, 1773187030.7201214, 173.0, 9061.114669779829, 1656209757.7786272, 80.0, 8856.559759326878, 1663796639.0688558, 105.0, 8596.930884973775, 1705967916.6744611, 465.0, 8574.616569649173, 1683282454.6264086, 214.0]
[2019-03-22 23:33:25,369] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 7.8428443e-21 1.3150647e-26], sum to 1.0000
[2019-03-22 23:33:25,377] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6267
[2019-03-22 23:33:25,383] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.5, 91.0, 1.0, 2.0, 0.269937531616472, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 293102.4489958705, 293102.4489958703, 89944.50596835648], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 498600.0000, 
sim time next is 499200.0000, 
raw observation next is [15.33333333333333, 92.0, 1.0, 2.0, 0.2651514992907338, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 287904.1610614254, 287904.1610614251, 88883.56395309416], 
processed observation next is [1.0, 0.782608695652174, 0.3333333333333332, 0.92, 1.0, 1.0, 0.08143937411341721, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10663117076349089, 0.10663117076349078, 0.2167891803734004], 
reward next is 0.7832, 
noisyNet noise sample is [array([0.08656623], dtype=float32), 0.16766933]. 
=============================================
[2019-03-22 23:33:31,462] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.3626224e-28 1.2052254e-26], sum to 1.0000
[2019-03-22 23:33:31,469] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4650
[2019-03-22 23:33:31,473] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.66666666666667, 82.66666666666667, 1.0, 2.0, 0.2978207712674755, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 323388.5787942487, 323388.578794249, 111045.2712561978], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 606000.0000, 
sim time next is 606600.0000, 
raw observation next is [17.5, 82.5, 1.0, 2.0, 0.2921716766551349, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 317252.5105693174, 317252.5105693171, 106335.309973859], 
processed observation next is [1.0, 0.0, 0.4318181818181818, 0.825, 1.0, 1.0, 0.11521459581891859, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11750092984048792, 0.11750092984048781, 0.25935441457038777], 
reward next is 0.7406, 
noisyNet noise sample is [array([0.9372154], dtype=float32), -0.7145384]. 
=============================================
[2019-03-22 23:33:34,497] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.6579457e-37 8.8175747e-29], sum to 1.0000
[2019-03-22 23:33:34,507] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7295
[2019-03-22 23:33:34,515] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.33333333333333, 49.33333333333333, 1.0, 2.0, 0.3570670266541407, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 400628.2014294617, 400628.2014294617, 120200.3128425167], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 668400.0000, 
sim time next is 669000.0000, 
raw observation next is [25.16666666666667, 49.66666666666667, 1.0, 2.0, 0.3557345737944984, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 398734.2405109353, 398734.240510935, 119896.6321566705], 
processed observation next is [1.0, 0.7391304347826086, 0.7803030303030305, 0.4966666666666667, 1.0, 1.0, 0.194668217243123, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14767934833738344, 0.14767934833738333, 0.29243081013822075], 
reward next is 0.7076, 
noisyNet noise sample is [array([-0.4822428], dtype=float32), -0.32575873]. 
=============================================
[2019-03-22 23:33:34,526] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[49.433105]
 [48.214165]
 [46.445724]
 [44.115738]
 [41.136864]], R is [[51.03647232]
 [51.23293686]
 [51.42704391]
 [51.61453629]
 [51.75892258]].
[2019-03-22 23:33:35,664] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.6720412e-36 7.1504716e-30], sum to 1.0000
[2019-03-22 23:33:35,671] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6911
[2019-03-22 23:33:35,676] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.83333333333334, 73.83333333333334, 1.0, 2.0, 0.4262215540744966, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 484693.9777531825, 484693.9777531822, 130124.8197263539], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 778200.0000, 
sim time next is 778800.0000, 
raw observation next is [22.66666666666667, 74.66666666666667, 1.0, 2.0, 0.4245079565911599, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 482638.7408401244, 482638.7408401244, 129861.5666511574], 
processed observation next is [0.0, 0.0, 0.6666666666666669, 0.7466666666666667, 1.0, 1.0, 0.28063494573894987, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17875508920004607, 0.17875508920004607, 0.31673552841745706], 
reward next is 0.6833, 
noisyNet noise sample is [array([1.1390101], dtype=float32), 1.6961164]. 
=============================================
[2019-03-22 23:33:46,307] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.5824077e-35 9.3576275e-28 5.6005427e-20], sum to 1.0000
[2019-03-22 23:33:46,310] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0108
[2019-03-22 23:33:46,314] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 94.0, 1.0, 2.0, 0.3973816380588974, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 447967.610409422, 447967.610409422, 124703.2344385727], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 867600.0000, 
sim time next is 868200.0000, 
raw observation next is [19.16666666666667, 93.00000000000001, 1.0, 2.0, 0.3964403217125555, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 446931.3163672245, 446931.3163672248, 124632.4948233106], 
processed observation next is [0.0, 0.043478260869565216, 0.5075757575757578, 0.9300000000000002, 1.0, 1.0, 0.24555040214069435, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1655301171730461, 0.16553011717304622, 0.30398169469100145], 
reward next is 0.6960, 
noisyNet noise sample is [array([-0.5834305], dtype=float32), -0.76870614]. 
=============================================
[2019-03-22 23:33:51,728] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.7588847e-34 3.7850419e-33 1.3054693e-24], sum to 1.0000
[2019-03-22 23:33:51,738] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9304
[2019-03-22 23:33:51,742] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.4037840598119037, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 457721.0301406559, 457721.0301406559, 126807.5164927755], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 964200.0000, 
sim time next is 964800.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4035722058976944, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 457478.0937093977, 457478.0937093977, 126785.8008715732], 
processed observation next is [1.0, 0.17391304347826086, 0.5, 1.0, 1.0, 1.0, 0.25446525737211795, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16943633100348063, 0.16943633100348063, 0.3092336606623737], 
reward next is 0.6908, 
noisyNet noise sample is [array([0.27004522], dtype=float32), -0.18212387]. 
=============================================
[2019-03-22 23:34:00,319] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 2.4406658e-34], sum to 1.0000
[2019-03-22 23:34:00,328] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3191
[2019-03-22 23:34:00,335] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 88.0, 1.0, 2.0, 0.3187681011604869, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 350472.040807142, 350472.040807142, 114019.5130803875], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1130400.0000, 
sim time next is 1131000.0000, 
raw observation next is [18.0, 88.00000000000001, 1.0, 2.0, 0.3542486664005419, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 389891.347963838, 389891.3479638383, 116795.3823514859], 
processed observation next is [1.0, 0.08695652173913043, 0.45454545454545453, 0.8800000000000001, 1.0, 1.0, 0.1928108330006774, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14440420294956963, 0.14440420294956974, 0.2848667862231363], 
reward next is 0.7151, 
noisyNet noise sample is [array([-0.46838135], dtype=float32), 0.6078167]. 
=============================================
[2019-03-22 23:34:00,351] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[73.2319  ]
 [73.103035]
 [72.98305 ]
 [72.82858 ]
 [72.64688 ]], R is [[73.39073181]
 [73.37872314]
 [73.36847687]
 [73.3600235 ]
 [73.35338593]].
[2019-03-22 23:34:05,899] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 1.142498e-37], sum to 1.0000
[2019-03-22 23:34:05,909] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6046
[2019-03-22 23:34:05,916] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.16666666666667, 100.0, 1.0, 2.0, 0.3866448887817771, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 434711.5299646939, 434711.5299646936, 123144.2789557678], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1314600.0000, 
sim time next is 1315200.0000, 
raw observation next is [18.33333333333334, 100.0, 1.0, 2.0, 0.3953364935859477, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 445281.1869832939, 445281.1869832939, 124317.3155118235], 
processed observation next is [1.0, 0.21739130434782608, 0.46969696969696995, 1.0, 1.0, 1.0, 0.24417061698243459, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1649189581419607, 0.1649189581419607, 0.30321296466298414], 
reward next is 0.6968, 
noisyNet noise sample is [array([1.0306605], dtype=float32), 0.53346694]. 
=============================================
[2019-03-22 23:34:06,969] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.2958223e-26 1.0000000e+00 3.4478497e-23 4.1687752e-18 4.0028736e-15], sum to 1.0000
[2019-03-22 23:34:06,974] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7223
[2019-03-22 23:34:06,983] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1191628.202394985 W.
[2019-03-22 23:34:06,987] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.0, 86.0, 1.0, 2.0, 0.3503887393998046, 1.0, 2.0, 0.3503887393998046, 1.0, 2.0, 0.7095985293928871, 6.911199999999999, 6.9112, 77.3421103, 1191628.202394985, 1191628.202394986, 280911.7379036336], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1243800.0000, 
sim time next is 1244400.0000, 
raw observation next is [23.33333333333334, 83.33333333333334, 1.0, 2.0, 0.5238070629033219, 1.0, 2.0, 0.5238070629033219, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846343378287, 1188995.746635513, 1188995.746635514, 238279.2603088442], 
processed observation next is [1.0, 0.391304347826087, 0.6969696969696972, 0.8333333333333335, 1.0, 1.0, 0.40475882862915236, 1.0, 1.0, 0.40475882862915236, 0.0, 0.5, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288128564949, 0.44036879505018994, 0.4403687950501904, 0.5811689275825469], 
reward next is 0.4188, 
noisyNet noise sample is [array([-0.743799], dtype=float32), 0.9795744]. 
=============================================
[2019-03-22 23:34:12,145] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 7.392062e-33], sum to 1.0000
[2019-03-22 23:34:12,154] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6920
[2019-03-22 23:34:12,163] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1783547.171408305 W.
[2019-03-22 23:34:12,167] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.66666666666666, 70.0, 1.0, 2.0, 0.5694504358665337, 1.0, 2.0, 0.528513654874874, 1.0, 2.0, 0.9865530188920543, 6.911199999999998, 6.9112, 77.3421103, 1783547.171408305, 1783547.171408305, 368562.3445443334], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1345200.0000, 
sim time next is 1345800.0000, 
raw observation next is [27.83333333333334, 70.0, 1.0, 2.0, 0.5630740118040224, 1.0, 2.0, 0.5253254428436186, 1.0, 2.0, 0.9865530188920543, 6.911199999999999, 6.9112, 77.3421103, 1772771.230131658, 1772771.230131658, 367341.1157696248], 
processed observation next is [1.0, 0.5652173913043478, 0.9015151515151518, 0.7, 1.0, 1.0, 0.45384251475502796, 1.0, 1.0, 0.4066568035545232, 1.0, 1.0, 0.9807900269886491, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.6565819370857993, 0.6565819370857993, 0.8959539409015239], 
reward next is 0.1040, 
noisyNet noise sample is [array([0.5100438], dtype=float32), 0.8108742]. 
=============================================
[2019-03-22 23:34:16,081] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-22 23:34:16,084] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-22 23:34:16,085] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:34:16,086] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-22 23:34:16,087] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-22 23:34:16,088] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:34:16,091] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-22 23:34:16,090] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-22 23:34:16,092] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:34:16,094] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:34:16,095] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:34:16,109] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run28
[2019-03-22 23:34:16,109] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run28
[2019-03-22 23:34:16,151] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run28
[2019-03-22 23:34:16,151] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run28
[2019-03-22 23:34:16,152] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run28
[2019-03-22 23:34:22,659] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.20122123], dtype=float32), -0.07595031]
[2019-03-22 23:34:22,662] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [16.0, 72.0, 1.0, 2.0, 0.2134411880630266, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 231743.2092218061, 231743.2092218059, 75062.76469372556]
[2019-03-22 23:34:22,663] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:34:22,666] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.5167349962613954
[2019-03-22 23:34:29,215] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.20122123], dtype=float32), -0.07595031]
[2019-03-22 23:34:29,219] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.0, 94.0, 1.0, 2.0, 0.3968974137275388, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 447268.2773017752, 447268.2773017752, 124577.6318029966]
[2019-03-22 23:34:29,220] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:34:29,222] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.20459772665039844
[2019-03-22 23:34:34,677] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.20122123], dtype=float32), -0.07595031]
[2019-03-22 23:34:34,678] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.5, 82.0, 1.0, 2.0, 0.5019691124791721, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 572501.520894948, 572501.520894948, 146444.7409781678]
[2019-03-22 23:34:34,680] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:34:34,683] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 7.5158722e-38 3.7483082e-37], sampled 0.10656797145426011
[2019-03-22 23:34:35,268] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.20122123], dtype=float32), -0.07595031]
[2019-03-22 23:34:35,268] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.5, 89.0, 1.0, 2.0, 0.5848958770694448, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9787608881909172, 6.911199999999999, 6.9112, 77.32845937619504, 1211695.322870021, 1211695.322870021, 276774.4417203172]
[2019-03-22 23:34:35,270] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:34:35,271] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.22169752e-37 1.00000000e+00 1.01167856e-32 3.04791633e-26
 1.71946039e-24], sampled 0.5591820742687532
[2019-03-22 23:34:35,274] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1211695.322870021 W.
[2019-03-22 23:34:36,896] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.20122123], dtype=float32), -0.07595031]
[2019-03-22 23:34:36,897] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [29.3, 52.0, 1.0, 2.0, 0.5176857691134724, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 589621.8160833674, 589621.8160833671, 149302.2540806688]
[2019-03-22 23:34:36,899] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:34:36,901] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.1583469917487066
[2019-03-22 23:34:52,162] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.20122123], dtype=float32), -0.07595031]
[2019-03-22 23:34:52,163] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.8, 79.0, 1.0, 2.0, 0.4633905680756907, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 528299.7898496737, 528299.7898496734, 139790.199622259]
[2019-03-22 23:34:52,164] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:34:52,166] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.30212808768036103
[2019-03-22 23:35:20,913] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.20122123], dtype=float32), -0.07595031]
[2019-03-22 23:35:20,915] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.0, 75.5, 1.0, 2.0, 0.4109997911643531, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 465888.201940909, 465888.201940909, 127476.618261315]
[2019-03-22 23:35:20,916] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:35:20,919] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.8356566924720171
[2019-03-22 23:35:34,985] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.20122123], dtype=float32), -0.07595031]
[2019-03-22 23:35:34,987] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [13.67814612333333, 80.61390165, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 194446.260716189, 194446.2607161886, 71340.7511091258]
[2019-03-22 23:35:34,987] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:35:34,990] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.6281457094555624
[2019-03-22 23:35:38,512] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.20122123], dtype=float32), -0.07595031]
[2019-03-22 23:35:38,514] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.691626825, 81.94107307666667, 1.0, 2.0, 0.2855596361077509, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 310051.733937508, 310051.7339375084, 97673.05518005887]
[2019-03-22 23:35:38,514] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:35:38,516] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.23518084031896502
[2019-03-22 23:35:55,142] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.20122123], dtype=float32), -0.07595031]
[2019-03-22 23:35:55,142] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.13333333333334, 59.66666666666667, 1.0, 2.0, 0.2778990973117507, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 301732.0722927636, 301732.0722927633, 92635.31677221772]
[2019-03-22 23:35:55,144] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:35:55,148] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.8183073543857936
[2019-03-22 23:36:04,815] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-22 23:36:04,851] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2492 1773187030.7201 173.0000
[2019-03-22 23:36:04,852] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3485 1683325900.1134 214.0000
[2019-03-22 23:36:04,874] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1147 1656209757.7786 80.0000
[2019-03-22 23:36:04,907] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9309 1705967916.6745 465.0000
[2019-03-22 23:36:05,920] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 675000, evaluation results [675000.0, 8512.249193409023, 1773187030.7201214, 173.0, 9061.114669779829, 1656209757.7786272, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8596.930884973775, 1705967916.6744611, 465.0, 8574.348472942609, 1683325900.1133502, 214.0]
[2019-03-22 23:36:07,002] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.4376995e-37 4.9936089e-36], sum to 1.0000
[2019-03-22 23:36:07,008] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1239
[2019-03-22 23:36:07,015] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.83333333333334, 89.83333333333333, 1.0, 2.0, 0.5095866048450346, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 580689.2642840884, 580689.2642840884, 143803.9165157384], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1414200.0000, 
sim time next is 1414800.0000, 
raw observation next is [23.0, 89.0, 1.0, 2.0, 0.5106320915119257, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 581764.8880698587, 581764.8880698587, 144042.1791593184], 
processed observation next is [0.0, 0.391304347826087, 0.6818181818181818, 0.89, 1.0, 1.0, 0.38829011438990707, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2154684770629106, 0.2154684770629106, 0.35132238819345946], 
reward next is 0.6487, 
noisyNet noise sample is [array([-1.1621643], dtype=float32), -1.1833446]. 
=============================================
[2019-03-22 23:36:09,317] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.2953442e-36 2.8980058e-36], sum to 1.0000
[2019-03-22 23:36:09,326] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4544
[2019-03-22 23:36:09,331] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4795200614083098, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 547103.4982555248, 547103.4982555251, 139141.1342918906], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1474200.0000, 
sim time next is 1474800.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.4796548861777623, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 547257.3457211268, 547257.3457211268, 139156.5975824313], 
processed observation next is [0.0, 0.043478260869565216, 0.5909090909090909, 1.0, 1.0, 1.0, 0.34956860772220283, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20268790582263954, 0.20268790582263954, 0.33940633556690564], 
reward next is 0.6606, 
noisyNet noise sample is [array([-0.40636346], dtype=float32), 0.95599663]. 
=============================================
[2019-03-22 23:36:11,739] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 9.4253905e-32 7.5380621e-32], sum to 1.0000
[2019-03-22 23:36:11,749] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9118
[2019-03-22 23:36:11,754] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 83.0, 1.0, 2.0, 0.5171125550062422, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 588677.044754659, 588677.044754659, 145214.2793242243], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1525200.0000, 
sim time next is 1525800.0000, 
raw observation next is [24.0, 83.0, 1.0, 2.0, 0.5169159529019093, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 588453.6895724321, 588453.6895724321, 145189.9616189466], 
processed observation next is [0.0, 0.6521739130434783, 0.7272727272727273, 0.83, 1.0, 1.0, 0.3961449411273866, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21794581095275262, 0.21794581095275262, 0.35412185760718684], 
reward next is 0.6459, 
noisyNet noise sample is [array([0.49469548], dtype=float32), 0.47225103]. 
=============================================
[2019-03-22 23:36:12,458] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.6716616e-35 1.5426527e-35], sum to 1.0000
[2019-03-22 23:36:12,466] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0907
[2019-03-22 23:36:12,472] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 83.0, 1.0, 2.0, 0.5173895005407687, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 588991.8875350053, 588991.8875350053, 145248.3893840361], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1524600.0000, 
sim time next is 1525200.0000, 
raw observation next is [24.0, 83.0, 1.0, 2.0, 0.5171125550062422, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 588677.044754659, 588677.044754659, 145214.2793242243], 
processed observation next is [0.0, 0.6521739130434783, 0.7272727272727273, 0.83, 1.0, 1.0, 0.3963906937578027, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21802853509431813, 0.21802853509431813, 0.3541811690834739], 
reward next is 0.6458, 
noisyNet noise sample is [array([0.22368631], dtype=float32), 2.4349341]. 
=============================================
[2019-03-22 23:36:14,679] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 2.5055452e-38 0.0000000e+00 2.0618026e-35], sum to 1.0000
[2019-03-22 23:36:14,692] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1172
[2019-03-22 23:36:14,696] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.5, 97.0, 1.0, 2.0, 0.4097371484134872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 465090.1615321406, 465090.1615321409, 127812.172276992], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1564200.0000, 
sim time next is 1564800.0000, 
raw observation next is [19.33333333333334, 98.0, 1.0, 2.0, 0.4034527608565712, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 457761.6987657626, 457761.6987657628, 127071.9953535845], 
processed observation next is [1.0, 0.08695652173913043, 0.5151515151515155, 0.98, 1.0, 1.0, 0.254315951070714, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16954136991324542, 0.16954136991324548, 0.30993169598435244], 
reward next is 0.6901, 
noisyNet noise sample is [array([-2.688209], dtype=float32), 0.9123959]. 
=============================================
[2019-03-22 23:36:20,494] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.8513755e-38 1.0000000e+00 3.5494534e-35 1.3489995e-28 8.0921738e-21], sum to 1.0000
[2019-03-22 23:36:20,497] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0144
[2019-03-22 23:36:20,503] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [11.83333333333333, 67.66666666666667, 1.0, 2.0, 0.3498293371033401, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 379884.1204316977, 379884.1204316977, 80894.25596262216], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1756200.0000, 
sim time next is 1756800.0000, 
raw observation next is [12.0, 67.0, 1.0, 2.0, 0.3198090102308421, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 347273.0254660732, 347273.0254660735, 78390.37939883879], 
processed observation next is [1.0, 0.34782608695652173, 0.18181818181818182, 0.67, 1.0, 1.0, 0.14976126278855256, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12861963906150858, 0.1286196390615087, 0.19119604731424095], 
reward next is 0.8088, 
noisyNet noise sample is [array([1.050387], dtype=float32), 0.3111526]. 
=============================================
[2019-03-22 23:36:32,463] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.00000000e+00 1.00000000e+00 0.00000000e+00 1.17638635e-33
 1.93408905e-32], sum to 1.0000
[2019-03-22 23:36:32,475] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8526
[2019-03-22 23:36:32,482] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 47.0, 1.0, 2.0, 0.2926590305459958, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 317781.873182393, 317781.8731823933, 92606.77470753247], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1884000.0000, 
sim time next is 1884600.0000, 
raw observation next is [21.5, 47.5, 1.0, 2.0, 0.2905007508038699, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 315437.5593408735, 315437.5593408732, 91855.82729417612], 
processed observation next is [1.0, 0.8260869565217391, 0.6136363636363636, 0.475, 1.0, 1.0, 0.11312593850483735, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.116828725681805, 0.1168287256818049, 0.22403860315652713], 
reward next is 0.7760, 
noisyNet noise sample is [array([-1.2149069], dtype=float32), -0.2899972]. 
=============================================
[2019-03-22 23:36:33,439] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 5.690592e-32], sum to 1.0000
[2019-03-22 23:36:33,447] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7334
[2019-03-22 23:36:33,452] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 62.66666666666667, 1.0, 2.0, 0.3185895329045737, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 347899.4605713063, 347899.4605713063, 113135.4576459969], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1982400.0000, 
sim time next is 1983000.0000, 
raw observation next is [21.0, 63.33333333333334, 1.0, 2.0, 0.3199383960239821, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 350002.444053184, 350002.444053184, 113455.6366983611], 
processed observation next is [1.0, 0.9565217391304348, 0.5909090909090909, 0.6333333333333334, 1.0, 1.0, 0.1499229950299776, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1296305348345126, 0.1296305348345126, 0.2767210651179539], 
reward next is 0.7233, 
noisyNet noise sample is [array([-0.43029177], dtype=float32), 0.23224732]. 
=============================================
[2019-03-22 23:36:33,462] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[84.2284  ]
 [84.232216]
 [84.24343 ]
 [84.255775]
 [84.27115 ]], R is [[84.10751343]
 [83.9905014 ]
 [83.87526703]
 [83.76190948]
 [83.65054321]].
[2019-03-22 23:36:36,050] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.9952527e-38 1.0000000e+00 7.6336305e-35 4.6107029e-32 9.8252796e-21], sum to 1.0000
[2019-03-22 23:36:36,061] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9482
[2019-03-22 23:36:36,068] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1213832.85191478 W.
[2019-03-22 23:36:36,074] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.5, 59.0, 1.0, 2.0, 0.53157334213381, 1.0, 1.0, 0.53157334213381, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846219938884, 1213832.85191478, 1213832.85191478, 233995.6374278521], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1960200.0000, 
sim time next is 1960800.0000, 
raw observation next is [25.33333333333333, 58.33333333333334, 1.0, 2.0, 0.3485856448123138, 1.0, 2.0, 0.3485856448123138, 1.0, 1.0, 0.7039564345680467, 6.911199999999999, 6.9112, 77.3421103, 1193900.264541524, 1193900.264541524, 272242.0086177441], 
processed observation next is [1.0, 0.6956521739130435, 0.7878787878787876, 0.5833333333333335, 1.0, 1.0, 0.18573205601539222, 1.0, 1.0, 0.18573205601539222, 1.0, 0.5, 0.5770806208114954, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.4421852831635274, 0.4421852831635274, 0.6640048990676685], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.696632], dtype=float32), -0.16911854]. 
=============================================
[2019-03-22 23:36:43,005] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:36:43,012] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9533
[2019-03-22 23:36:43,017] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.83333333333333, 53.5, 1.0, 2.0, 0.2891996545530016, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 314024.3198489147, 314024.3198489144, 94823.98857258345], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2059800.0000, 
sim time next is 2060400.0000, 
raw observation next is [20.66666666666667, 54.0, 1.0, 2.0, 0.2870705815993807, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 311711.7480839394, 311711.7480839391, 93865.72858879293], 
processed observation next is [0.0, 0.8695652173913043, 0.575757575757576, 0.54, 1.0, 1.0, 0.10883822699922586, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11544879558664423, 0.1154487955866441, 0.2289408014360803], 
reward next is 0.7711, 
noisyNet noise sample is [array([0.1702618], dtype=float32), 0.6141532]. 
=============================================
[2019-03-22 23:36:48,558] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 4.542046e-31 7.053461e-29], sum to 1.0000
[2019-03-22 23:36:48,571] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5491
[2019-03-22 23:36:48,575] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.83333333333334, 66.33333333333333, 1.0, 2.0, 0.3990155798460281, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 450675.481824262, 450675.481824262, 125332.0199746338], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2149800.0000, 
sim time next is 2150400.0000, 
raw observation next is [22.66666666666667, 63.66666666666667, 1.0, 2.0, 0.3843124371951248, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 431724.8638178151, 431724.8638178149, 122757.663670957], 
processed observation next is [0.0, 0.9130434782608695, 0.6666666666666669, 0.6366666666666667, 1.0, 1.0, 0.230390546493906, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1598980977103019, 0.1598980977103018, 0.29940893578282196], 
reward next is 0.7006, 
noisyNet noise sample is [array([0.44200313], dtype=float32), -0.35234746]. 
=============================================
[2019-03-22 23:36:52,970] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 7.4573098e-35 2.8005375e-31 7.5672014e-29], sum to 1.0000
[2019-03-22 23:36:52,985] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7120
[2019-03-22 23:36:52,991] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.33333333333333, 88.0, 1.0, 2.0, 0.251172741984909, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 272721.6303271385, 272721.6303271385, 84235.3245141737], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2248800.0000, 
sim time next is 2249400.0000, 
raw observation next is [15.16666666666667, 88.0, 1.0, 2.0, 0.245471373000391, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 266529.4269847108, 266529.4269847105, 82629.28908373471], 
processed observation next is [1.0, 0.0, 0.3257575757575759, 0.88, 1.0, 1.0, 0.05683921625048875, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09871460258692992, 0.09871460258692981, 0.2015348514237432], 
reward next is 0.7985, 
noisyNet noise sample is [array([-0.25096786], dtype=float32), 0.44030377]. 
=============================================
[2019-03-22 23:36:55,247] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 7.5248705e-33 3.0267264e-25 4.4625978e-23], sum to 1.0000
[2019-03-22 23:36:55,258] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1339
[2019-03-22 23:36:55,264] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 49.0, 1.0, 2.0, 0.4775696281607517, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 518672.9180760542, 518672.9180760542, 105329.8919374796], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2373000.0000, 
sim time next is 2373600.0000, 
raw observation next is [20.0, 49.0, 1.0, 2.0, 0.4514325599324419, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 490271.9796547513, 490271.9796547513, 102623.3222844337], 
processed observation next is [1.0, 0.4782608695652174, 0.5454545454545454, 0.49, 1.0, 1.0, 0.31429069991555236, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18158221468694494, 0.18158221468694494, 0.2503007860595944], 
reward next is 0.7497, 
noisyNet noise sample is [array([-1.359049], dtype=float32), 0.015212957]. 
=============================================
[2019-03-22 23:36:55,414] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 2.7636449e-33 2.0110966e-24 6.6009452e-26], sum to 1.0000
[2019-03-22 23:36:55,427] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1282
[2019-03-22 23:36:55,432] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 49.0, 1.0, 2.0, 0.4579874057043435, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 497394.4195252951, 497394.4195252951, 103097.7578915724], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2376000.0000, 
sim time next is 2376600.0000, 
raw observation next is [20.16666666666667, 49.0, 1.0, 2.0, 0.5281241436045295, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 573610.937584163, 573610.937584163, 111508.6633198299], 
processed observation next is [1.0, 0.5217391304347826, 0.5530303030303032, 0.49, 1.0, 1.0, 0.4101551795056619, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21244849540154187, 0.21244849540154187, 0.2719723495605607], 
reward next is 0.7280, 
noisyNet noise sample is [array([-0.3009403], dtype=float32), 0.19291973]. 
=============================================
[2019-03-22 23:36:55,732] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 9.849011e-33 1.185264e-34], sum to 1.0000
[2019-03-22 23:36:55,739] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8965
[2019-03-22 23:36:55,745] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.33333333333333, 65.0, 1.0, 2.0, 0.2132344119431555, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 231518.649161564, 231518.6491615637, 71653.8768136338], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2274000.0000, 
sim time next is 2274600.0000, 
raw observation next is [15.66666666666667, 62.0, 1.0, 2.0, 0.222307766814425, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 241372.4624861468, 241372.4624861465, 72440.69674194157], 
processed observation next is [1.0, 0.30434782608695654, 0.3484848484848486, 0.62, 1.0, 1.0, 0.027884708518031223, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08939720832820253, 0.08939720832820242, 0.1766846261998575], 
reward next is 0.8233, 
noisyNet noise sample is [array([-0.20911755], dtype=float32), -0.4526321]. 
=============================================
[2019-03-22 23:36:58,814] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-22 23:36:58,815] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-22 23:36:58,816] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-22 23:36:58,817] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:36:58,820] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:36:58,819] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-22 23:36:58,822] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-22 23:36:58,823] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:36:58,820] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-22 23:36:58,824] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:36:58,825] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:36:58,843] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run29
[2019-03-22 23:36:58,865] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run29
[2019-03-22 23:36:58,866] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run29
[2019-03-22 23:36:58,884] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run29
[2019-03-22 23:36:58,929] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run29
[2019-03-22 23:37:04,924] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.27768707], dtype=float32), -0.12004728]
[2019-03-22 23:37:04,926] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.94534212333333, 58.55658386333334, 1.0, 2.0, 0.4353726845618516, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 472778.0501647929, 472778.0501647929, 107621.6056358666]
[2019-03-22 23:37:04,933] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:37:04,935] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 8.460033e-30 3.805111e-31], sampled 0.1147379092844456
[2019-03-22 23:37:40,212] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.27768707], dtype=float32), -0.12004728]
[2019-03-22 23:37:40,213] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.50701901333333, 95.16698388, 1.0, 2.0, 0.4822931252934618, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 550210.1632663801, 550210.1632663797, 143758.9779817565]
[2019-03-22 23:37:40,214] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:37:40,219] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 6.2637694e-29 2.2895468e-30], sampled 0.3757965949634403
[2019-03-22 23:37:46,819] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.27768707], dtype=float32), -0.12004728]
[2019-03-22 23:37:46,822] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.07281315166667, 99.21683696166667, 1.0, 2.0, 0.5537201625792697, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 631035.5696895049, 631035.5696895049, 149603.8265569423]
[2019-03-22 23:37:46,822] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:37:46,826] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0.0000000e+00 1.0000000e+00 2.5566982e-38 4.0414504e-28 7.9347426e-30], sampled 0.9911745085683569
[2019-03-22 23:38:00,722] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.27768707], dtype=float32), -0.12004728]
[2019-03-22 23:38:00,723] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [25.78185707, 75.172840615, 1.0, 2.0, 0.529493180329554, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 601562.565460114, 601562.5654601137, 151734.3268299504]
[2019-03-22 23:38:00,724] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:38:00,728] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.2065616e-30 2.1940621e-31], sampled 0.9203268322342143
[2019-03-22 23:38:12,899] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.27768707], dtype=float32), -0.12004728]
[2019-03-22 23:38:12,900] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.72545291666667, 87.02377434, 1.0, 2.0, 0.4000416356167019, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 449477.2533787345, 449477.2533787342, 128506.5259275438]
[2019-03-22 23:38:12,901] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:38:12,904] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0.00000000e+00 1.00000000e+00 0.00000000e+00 2.74378789e-28
 1.17900346e-29], sampled 0.2406033801620886
[2019-03-22 23:38:37,348] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.27768707], dtype=float32), -0.12004728]
[2019-03-22 23:38:37,348] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.886889595, 44.57187142833333, 1.0, 2.0, 0.3217554979859295, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 349363.4932229783, 349363.4932229779, 106679.6272337318]
[2019-03-22 23:38:37,349] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:38:37,353] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.8090163e-36 5.5646987e-36], sampled 0.6458792358214334
[2019-03-22 23:38:47,033] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2492 1773187030.7201 173.0000
[2019-03-22 23:38:47,404] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1147 1656209757.7786 80.0000
[2019-03-22 23:38:47,427] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5598 1663796639.0689 105.0000
[2019-03-22 23:38:47,455] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9309 1705967916.6745 465.0000
[2019-03-22 23:38:47,499] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3485 1683325900.1134 214.0000
[2019-03-22 23:38:48,513] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 700000, evaluation results [700000.0, 8512.249193409023, 1773187030.7201214, 173.0, 9061.114669779829, 1656209757.7786272, 80.0, 8856.559759326878, 1663796639.0688558, 105.0, 8596.930884973775, 1705967916.6744611, 465.0, 8574.348472942609, 1683325900.1133502, 214.0]
[2019-03-22 23:38:48,652] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.3220258e-33 2.5212931e-27], sum to 1.0000
[2019-03-22 23:38:48,661] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6097
[2019-03-22 23:38:48,667] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.5, 60.0, 1.0, 2.0, 0.2280086640041034, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 247563.8331610166, 247563.8331610163, 74020.7684770285], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2331000.0000, 
sim time next is 2331600.0000, 
raw observation next is [16.33333333333333, 62.66666666666666, 1.0, 2.0, 0.2251962912502317, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 244509.4896483058, 244509.4896483058, 74126.92849449825], 
processed observation next is [1.0, 1.0, 0.37878787878787856, 0.6266666666666666, 1.0, 1.0, 0.0314953640627896, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09055907024011327, 0.09055907024011327, 0.18079738657194694], 
reward next is 0.8192, 
noisyNet noise sample is [array([0.87979084], dtype=float32), -0.72058135]. 
=============================================
[2019-03-22 23:39:03,429] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.9208369e-35 1.5034865e-31], sum to 1.0000
[2019-03-22 23:39:03,438] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6043
[2019-03-22 23:39:03,444] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333334, 65.0, 1.0, 2.0, 0.385714962007895, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 436095.4351498336, 436095.4351498336, 124398.348831439], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2626800.0000, 
sim time next is 2627400.0000, 
raw observation next is [23.66666666666666, 63.0, 1.0, 2.0, 0.3856553894711949, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 436041.9658796682, 436041.9658796682, 124401.4356588352], 
processed observation next is [0.0, 0.391304347826087, 0.7121212121212118, 0.63, 1.0, 1.0, 0.23206923683899358, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16149702439987712, 0.16149702439987712, 0.30341813575325655], 
reward next is 0.6966, 
noisyNet noise sample is [array([0.54018676], dtype=float32), -0.6298323]. 
=============================================
[2019-03-22 23:39:14,202] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0615456e-24 1.0000000e+00 1.0555693e-24 3.9158624e-12 1.6057017e-14], sum to 1.0000
[2019-03-22 23:39:14,214] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5417
[2019-03-22 23:39:14,219] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.66666666666667, 70.33333333333334, 1.0, 2.0, 0.8545573430584206, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 974085.9132189885, 974085.9132189885, 187291.6801772783], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2799600.0000, 
sim time next is 2800200.0000, 
raw observation next is [23.83333333333333, 69.66666666666666, 1.0, 2.0, 0.8327067659312388, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 949303.6042604332, 949303.6042604332, 183989.2453981549], 
processed observation next is [1.0, 0.391304347826087, 0.7196969696969695, 0.6966666666666665, 1.0, 1.0, 0.7908834574140485, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.35159392750386415, 0.35159392750386415, 0.44875425706867045], 
reward next is 0.5512, 
noisyNet noise sample is [array([0.93071884], dtype=float32), -0.21062957]. 
=============================================
[2019-03-22 23:39:19,025] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.2275360e-35 1.0000000e+00 8.0875486e-35 1.2309276e-29 6.4133639e-21], sum to 1.0000
[2019-03-22 23:39:19,030] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9479
[2019-03-22 23:39:19,037] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1507353.981827444 W.
[2019-03-22 23:39:19,041] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.0, 74.0, 1.0, 2.0, 0.4467788994924498, 1.0, 1.0, 0.4467788994924498, 1.0, 2.0, 0.9040032365791008, 6.911199999999999, 6.9112, 77.3421103, 1507353.981827444, 1507353.981827444, 330984.6728030471], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2890800.0000, 
sim time next is 2891400.0000, 
raw observation next is [27.16666666666666, 73.33333333333334, 1.0, 2.0, 0.4537398154906694, 1.0, 2.0, 0.4537398154906694, 1.0, 2.0, 0.9180878108485983, 6.9112, 6.9112, 77.3421103, 1530870.643957538, 1530870.643957538, 334702.4788274909], 
processed observation next is [1.0, 0.4782608695652174, 0.871212121212121, 0.7333333333333334, 1.0, 1.0, 0.3171747693633367, 1.0, 1.0, 0.3171747693633367, 1.0, 1.0, 0.8829825869265691, 0.0, 0.0, 0.5085185399722538, 0.5669891273916807, 0.5669891273916807, 0.8163475093353436], 
reward next is 0.1837, 
noisyNet noise sample is [array([0.7195148], dtype=float32), 1.0030558]. 
=============================================
[2019-03-22 23:39:26,859] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.00000000e+00 1.00000000e+00 1.63562205e-38 1.03141755e-36
 5.41070646e-33], sum to 1.0000
[2019-03-22 23:39:26,870] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9261
[2019-03-22 23:39:26,875] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.5, 91.0, 1.0, 2.0, 0.3940419402645693, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 433069.2221214545, 433069.2221214548, 119710.9644436762], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3033000.0000, 
sim time next is 3033600.0000, 
raw observation next is [17.33333333333333, 92.0, 1.0, 2.0, 0.3740748820799013, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 410596.1727665297, 410596.17276653, 117935.0126010674], 
processed observation next is [1.0, 0.08695652173913043, 0.42424242424242403, 0.92, 1.0, 1.0, 0.21759360259987662, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1520726565801962, 0.1520726565801963, 0.2876463721977254], 
reward next is 0.7124, 
noisyNet noise sample is [array([-0.3285636], dtype=float32), 2.506444]. 
=============================================
[2019-03-22 23:39:31,035] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.7981535e-31 9.3569177e-01 9.2674285e-25 6.4308204e-02 3.4971787e-12], sum to 1.0000
[2019-03-22 23:39:31,046] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2817
[2019-03-22 23:39:31,049] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.66666666666667, 75.5, 1.0, 2.0, 0.2820036572344925, 1.0, 2.0, 0.2820036572344925, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 637300.1421179833, 637300.142117983, 188030.8984609138], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3093000.0000, 
sim time next is 3093600.0000, 
raw observation next is [25.33333333333334, 77.0, 1.0, 2.0, 0.5583339321444494, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 633590.8453979105, 633590.8453979102, 151468.9430013572], 
processed observation next is [1.0, 0.8260869565217391, 0.7878787878787882, 0.77, 1.0, 1.0, 0.44791741518056166, 0.0, 0.5, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.23466327607330018, 0.2346632760733001, 0.36943644634477363], 
reward next is 0.6306, 
noisyNet noise sample is [array([-0.8157476], dtype=float32), -1.5625312]. 
=============================================
[2019-03-22 23:39:33,038] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.3521650e-28 1.3242985e-07 1.1722081e-23 9.9999976e-01 8.8260130e-08], sum to 1.0000
[2019-03-22 23:39:33,048] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2948
[2019-03-22 23:39:33,054] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.0, 73.0, 1.0, 2.0, 0.4069118940185464, 1.0, 1.0, 0.4069118940185464, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 928513.9307163517, 928513.930716352, 203255.3771028489], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3140400.0000, 
sim time next is 3141000.0000, 
raw observation next is [23.0, 73.0, 1.0, 2.0, 0.4702161149358338, 1.0, 2.0, 0.4702161149358338, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1073633.969822726, 1073633.969822727, 218090.6099491758], 
processed observation next is [1.0, 0.34782608695652173, 0.6818181818181818, 0.73, 1.0, 1.0, 0.33777014366979224, 1.0, 1.0, 0.33777014366979224, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.39764221104545405, 0.3976422110454544, 0.5319283169492093], 
reward next is 0.4681, 
noisyNet noise sample is [array([-0.91855556], dtype=float32), -0.5360958]. 
=============================================
[2019-03-22 23:39:33,072] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[55.82529 ]
 [57.91203 ]
 [58.22462 ]
 [58.040844]
 [57.84909 ]], R is [[54.59069443]
 [54.54904175]
 [54.65405655]
 [54.77375412]
 [54.89122391]].
[2019-03-22 23:39:41,282] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-22 23:39:41,286] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-22 23:39:41,287] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:39:41,288] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-22 23:39:41,289] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:39:41,290] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-22 23:39:41,291] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-22 23:39:41,291] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:39:41,292] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:39:41,292] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-22 23:39:41,293] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:39:41,306] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run30
[2019-03-22 23:39:41,307] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run30
[2019-03-22 23:39:41,308] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run30
[2019-03-22 23:39:41,363] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run30
[2019-03-22 23:39:41,382] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run30
[2019-03-22 23:40:02,492] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.15747637], dtype=float32), -0.20875423]
[2019-03-22 23:40:02,494] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.81666666666667, 74.0, 1.0, 2.0, 0.475873668627157, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 542817.0756666809, 542817.0756666806, 141734.6516847993]
[2019-03-22 23:40:02,495] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:40:02,498] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 3.919272e-37], sampled 0.17766780593291853
[2019-03-22 23:40:35,478] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.15747637], dtype=float32), -0.20875423]
[2019-03-22 23:40:35,480] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.61201855666667, 78.74067073, 1.0, 2.0, 0.335795462430695, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 371986.3668190666, 371986.3668190663, 120658.3212341519]
[2019-03-22 23:40:35,480] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:40:35,482] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.7735629566456562
[2019-03-22 23:40:59,267] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.15747637], dtype=float32), -0.20875423]
[2019-03-22 23:40:59,269] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [11.1, 77.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 162228.5255568689, 162228.5255568689, 59449.46271651904]
[2019-03-22 23:40:59,269] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:40:59,274] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.5071923907026713
[2019-03-22 23:41:00,788] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.15747637], dtype=float32), -0.20875423]
[2019-03-22 23:41:00,789] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [16.53333333333333, 92.0, 1.0, 2.0, 0.3061567139234039, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 332421.5825976938, 332421.5825976938, 114303.581312536]
[2019-03-22 23:41:00,792] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:41:00,794] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.9607448161751642
[2019-03-22 23:41:02,921] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.15747637], dtype=float32), -0.20875423]
[2019-03-22 23:41:02,922] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [14.75195548, 81.833071765, 1.0, 2.0, 0.2098400947433741, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 227822.239620233, 227822.2396202327, 78990.18191745061]
[2019-03-22 23:41:02,924] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:41:02,926] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.15772334867768523
[2019-03-22 23:41:09,284] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.15747637], dtype=float32), -0.20875423]
[2019-03-22 23:41:09,286] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.746186525, 60.142421615, 1.0, 2.0, 0.3740700412392658, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 406186.0448580802, 406186.0448580802, 96488.45775205431]
[2019-03-22 23:41:09,287] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:41:09,290] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.14259838735199193
[2019-03-22 23:41:28,866] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3485 1683325900.1134 214.0000
[2019-03-22 23:41:29,141] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1147 1656209757.7786 80.0000
[2019-03-22 23:41:29,279] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2492 1773187030.7201 173.0000
[2019-03-22 23:41:29,300] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5598 1663796639.0689 105.0000
[2019-03-22 23:41:29,366] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9309 1705967916.6745 465.0000
[2019-03-22 23:41:30,381] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 725000, evaluation results [725000.0, 8512.249193409023, 1773187030.7201214, 173.0, 9061.114669779829, 1656209757.7786272, 80.0, 8856.559759326878, 1663796639.0688558, 105.0, 8596.930884973775, 1705967916.6744611, 465.0, 8574.348472942609, 1683325900.1133502, 214.0]
[2019-03-22 23:41:37,480] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.5218423e-28 1.0000000e+00 2.7848918e-28 5.4168896e-15 4.3197897e-16], sum to 1.0000
[2019-03-22 23:41:37,487] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7211
[2019-03-22 23:41:37,493] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1088993.762974493 W.
[2019-03-22 23:41:37,499] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.0, 65.0, 1.0, 2.0, 0.4769231506055157, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9361023119095141, 6.954955443791988, 6.9112, 77.32832873285868, 1088993.762974493, 1074782.914540617, 247413.1930739362], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3411000.0000, 
sim time next is 3411600.0000, 
raw observation next is [25.0, 65.0, 1.0, 2.0, 0.5155002189743041, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9509779570922535, 6.94031640783156, 6.9112, 77.32836452689378, 1136721.33749262, 1127264.935858867, 254457.5917335571], 
processed observation next is [1.0, 0.4782608695652174, 0.7727272727272727, 0.65, 1.0, 1.0, 0.39437527371788006, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9299685101317909, 0.0029116407831559776, 0.0, 0.5084281625511614, 0.42100790277504446, 0.41750553179958033, 0.620628272520871], 
reward next is 0.2338, 
noisyNet noise sample is [array([1.0041133], dtype=float32), 0.06992888]. 
=============================================
[2019-03-22 23:41:42,460] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.1901986e-35 1.0000000e+00 5.7271288e-34 5.4925651e-31 9.4575055e-27], sum to 1.0000
[2019-03-22 23:41:42,467] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4213
[2019-03-22 23:41:42,474] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1532845.861940311 W.
[2019-03-22 23:41:42,479] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.0, 62.0, 1.0, 2.0, 0.4543244655094427, 1.0, 2.0, 0.4543244655094427, 1.0, 2.0, 0.9192707796724112, 6.911199999999999, 6.9112, 77.3421103, 1532845.861940311, 1532845.861940311, 335017.095883277], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3508200.0000, 
sim time next is 3508800.0000, 
raw observation next is [28.0, 62.0, 1.0, 2.0, 0.690015477100775, 1.0, 2.0, 0.690015477100775, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1552056.03460679, 1552056.034606789, 288658.8287852854], 
processed observation next is [1.0, 0.6086956521739131, 0.9090909090909091, 0.62, 1.0, 1.0, 0.6125193463759687, 1.0, 1.0, 0.6125193463759687, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.5748355683728852, 0.5748355683728849, 0.7040459238665497], 
reward next is 0.2960, 
noisyNet noise sample is [array([-0.96672475], dtype=float32), -0.3017493]. 
=============================================
[2019-03-22 23:41:49,903] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.0559298e-31 2.6102798e-15 5.1103223e-25 1.5618452e-18 1.0000000e+00], sum to 1.0000
[2019-03-22 23:41:49,913] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4839
[2019-03-22 23:41:49,917] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3334395516243016, 6.911199999999999, 6.9112, 77.3421103, 562887.6613035155, 562887.6613035158, 210977.8167476677], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3628200.0000, 
sim time next is 3628800.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3331633563224898, 6.9112, 6.9112, 77.3421103, 562423.5917135655, 562423.5917135655, 210915.5111168785], 
processed observation next is [1.0, 0.0, 0.5909090909090909, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.04737622331784256, 0.0, 0.0, 0.5085185399722538, 0.20830503396798722, 0.20830503396798722, 0.5144280758948256], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.86060846], dtype=float32), 0.27920136]. 
=============================================
[2019-03-22 23:41:53,605] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.2977163e-23 9.9996865e-01 3.1577741e-22 1.1008737e-20 3.1305928e-05], sum to 1.0000
[2019-03-22 23:41:53,613] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2934
[2019-03-22 23:41:53,619] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1612640.157842976 W.
[2019-03-22 23:41:53,626] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.0, 52.5, 1.0, 2.0, 0.9364958766352388, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9774992687630617, 6.911200000000001, 6.9112, 77.32846344354104, 1612640.157842976, 1612640.157842976, 332366.772190173], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3685800.0000, 
sim time next is 3686400.0000, 
raw observation next is [29.0, 52.0, 1.0, 2.0, 0.4750454229553738, 1.0, 1.0, 0.4750454229553738, 1.0, 2.0, 0.9608807856968613, 6.911199999999999, 6.9112, 77.3421103, 1609115.81429929, 1609115.814299291, 343693.5633430448], 
processed observation next is [1.0, 0.6956521739130435, 0.9545454545454546, 0.52, 1.0, 1.0, 0.34380677869421716, 1.0, 0.5, 0.34380677869421716, 1.0, 1.0, 0.9441154081383732, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.5959688201108482, 0.5959688201108485, 0.8382769837635239], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.6822516], dtype=float32), -0.016268086]. 
=============================================
[2019-03-22 23:41:55,784] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.5891216e-36 1.0000000e+00 8.1538054e-36 1.5665100e-27 2.5306185e-21], sum to 1.0000
[2019-03-22 23:41:55,793] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2136
[2019-03-22 23:41:55,796] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 73.0, 1.0, 2.0, 0.4979845432941101, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 566471.1982369834, 566471.1982369836, 137703.3712796796], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3741600.0000, 
sim time next is 3742200.0000, 
raw observation next is [23.0, 73.0, 1.0, 2.0, 0.496638861981465, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 564934.6802743151, 564934.6802743151, 137552.0235782385], 
processed observation next is [1.0, 0.30434782608695654, 0.6818181818181818, 0.73, 1.0, 1.0, 0.3707985774768312, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20923506676826484, 0.20923506676826484, 0.33549274043472804], 
reward next is 0.6645, 
noisyNet noise sample is [array([-0.19189756], dtype=float32), -0.4246797]. 
=============================================
[2019-03-22 23:41:57,871] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.7698764e-31 1.0000000e+00 5.7715113e-29 4.5800514e-21 3.2746421e-19], sum to 1.0000
[2019-03-22 23:41:57,879] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8680
[2019-03-22 23:41:57,884] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 54.66666666666666, 1.0, 2.0, 0.6556134778846244, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 745746.9379086051, 745746.9379086054, 156519.108478048], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3761400.0000, 
sim time next is 3762000.0000, 
raw observation next is [26.0, 54.0, 1.0, 2.0, 0.6583121628900295, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 748368.3572888302, 748368.3572888299, 156495.0882001111], 
processed observation next is [1.0, 0.5652173913043478, 0.8181818181818182, 0.54, 1.0, 1.0, 0.5728902036125368, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2771734656625297, 0.2771734656625296, 0.38169533707344167], 
reward next is 0.6183, 
noisyNet noise sample is [array([1.0700228], dtype=float32), 0.9806149]. 
=============================================
[2019-03-22 23:41:57,896] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[44.597614]
 [44.12047 ]
 [43.426746]
 [42.367313]
 [40.328854]], R is [[45.23363113]
 [45.39954376]
 [45.56509781]
 [45.72877884]
 [45.78157043]].
[2019-03-22 23:42:12,479] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 3.5442269e-37 1.4125325e-27 1.2921358e-33], sum to 1.0000
[2019-03-22 23:42:12,489] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5208
[2019-03-22 23:42:12,497] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.6248095502053795, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 702660.8492792225, 702660.8492792229, 147708.136990939], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4027800.0000, 
sim time next is 4028400.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.5559538064643551, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 625048.1083154102, 625048.1083154102, 139782.7034745242], 
processed observation next is [1.0, 0.6521739130434783, 0.45454545454545453, 1.0, 1.0, 1.0, 0.44494225808044385, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23149929937607786, 0.23149929937607786, 0.3409334231085956], 
reward next is 0.6591, 
noisyNet noise sample is [array([-1.418349], dtype=float32), -2.5424554]. 
=============================================
[2019-03-22 23:42:19,124] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 4.2661881e-32 1.1544568e-32 9.4280224e-38], sum to 1.0000
[2019-03-22 23:42:19,135] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3344
[2019-03-22 23:42:19,139] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 94.0, 1.0, 2.0, 0.3233467958571533, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 353783.3540624561, 353783.3540624561, 113716.1826719446], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4238400.0000, 
sim time next is 4239000.0000, 
raw observation next is [17.0, 94.0, 1.0, 2.0, 0.3222822818910813, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 352606.1782801722, 352606.1782801719, 113635.9357746284], 
processed observation next is [1.0, 0.043478260869565216, 0.4090909090909091, 0.94, 1.0, 1.0, 0.15285285236385163, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1305948808445082, 0.1305948808445081, 0.27716081896250827], 
reward next is 0.7228, 
noisyNet noise sample is [array([-1.2591581], dtype=float32), -0.43542254]. 
=============================================
[2019-03-22 23:42:19,149] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[59.023304]
 [59.03818 ]
 [59.144333]
 [59.097466]
 [59.053585]], R is [[59.13898849]
 [59.2702446 ]
 [59.39983749]
 [59.52713776]
 [59.65071106]].
[2019-03-22 23:42:23,275] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-22 23:42:23,277] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-22 23:42:23,279] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:42:23,280] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-22 23:42:23,280] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-22 23:42:23,281] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-22 23:42:23,282] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:42:23,283] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:42:23,281] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:42:23,286] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-22 23:42:23,288] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:42:23,307] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run31
[2019-03-22 23:42:23,307] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run31
[2019-03-22 23:42:23,307] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run31
[2019-03-22 23:42:23,378] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run31
[2019-03-22 23:42:23,379] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run31
[2019-03-22 23:42:40,880] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05762751], dtype=float32), -0.12197161]
[2019-03-22 23:42:40,883] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.0, 100.0, 1.0, 2.0, 0.417511172905341, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 473297.5456650748, 473297.5456650748, 128114.3003765524]
[2019-03-22 23:42:40,883] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:42:40,888] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.417431419802172
[2019-03-22 23:42:56,651] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05762751], dtype=float32), -0.12197161]
[2019-03-22 23:42:56,652] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [14.37547080333333, 84.34824332, 1.0, 2.0, 0.4730475875263688, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 513707.3101382867, 513707.3101382863, 106007.4481927018]
[2019-03-22 23:42:56,654] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:42:56,655] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.6577390312470562
[2019-03-22 23:43:10,450] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05762751], dtype=float32), -0.12197161]
[2019-03-22 23:43:10,452] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.3, 61.0, 1.0, 2.0, 0.2660501228869527, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 288863.8233280518, 288863.8233280515, 94024.16912398755]
[2019-03-22 23:43:10,454] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:43:10,459] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.14131464784606362
[2019-03-22 23:43:24,112] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05762751], dtype=float32), -0.12197161]
[2019-03-22 23:43:24,113] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.37058883, 78.31674023, 1.0, 2.0, 0.3479551283283089, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 378855.296847392, 378855.2968473917, 119183.6695015379]
[2019-03-22 23:43:24,114] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:43:24,121] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.9610713121739954
[2019-03-22 23:43:33,921] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05762751], dtype=float32), -0.12197161]
[2019-03-22 23:43:33,922] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.7, 50.66666666666667, 1.0, 2.0, 0.2885706582033782, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 313321.8598707663, 313321.859870766, 102937.0498103712]
[2019-03-22 23:43:33,923] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:43:33,926] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.3550009643036207
[2019-03-22 23:43:34,587] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05762751], dtype=float32), -0.12197161]
[2019-03-22 23:43:34,588] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.15, 62.0, 1.0, 2.0, 0.3286382496286463, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 364700.4556364336, 364700.4556364333, 120382.0323289839]
[2019-03-22 23:43:34,591] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:43:34,593] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.1931114667987036
[2019-03-22 23:43:51,216] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05762751], dtype=float32), -0.12197161]
[2019-03-22 23:43:51,219] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [15.0, 78.0, 1.0, 2.0, 0.2101189782432851, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 228135.2827212985, 228135.2827212982, 73904.17749299668]
[2019-03-22 23:43:51,221] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:43:51,224] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.6809353754405276
[2019-03-22 23:43:51,628] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05762751], dtype=float32), -0.12197161]
[2019-03-22 23:43:51,630] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.85, 75.5, 1.0, 2.0, 0.4124216488615392, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 456145.7580713874, 456145.758071387, 126570.6603961776]
[2019-03-22 23:43:51,631] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:43:51,635] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.5013472694528189
[2019-03-22 23:43:53,661] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05762751], dtype=float32), -0.12197161]
[2019-03-22 23:43:53,662] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [28.33333333333334, 42.33333333333334, 1.0, 2.0, 0.6748349445413401, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 766151.3600280838, 766151.3600280834, 162291.5848829263]
[2019-03-22 23:43:53,664] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:43:53,669] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.00000e+00 1.00000e+00 0.00000e+00 0.00000e+00 9.59624e-38], sampled 0.02429115094251999
[2019-03-22 23:44:11,214] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3485 1683325900.1134 214.0000
[2019-03-22 23:44:11,407] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5598 1663796639.0689 105.0000
[2019-03-22 23:44:11,488] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2492 1773187030.7201 173.0000
[2019-03-22 23:44:11,579] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1147 1656209757.7786 80.0000
[2019-03-22 23:44:11,756] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9309 1705967916.6745 465.0000
[2019-03-22 23:44:12,775] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 750000, evaluation results [750000.0, 8512.249193409023, 1773187030.7201214, 173.0, 9061.114669779829, 1656209757.7786272, 80.0, 8856.559759326878, 1663796639.0688558, 105.0, 8596.930884973775, 1705967916.6744611, 465.0, 8574.348472942609, 1683325900.1133502, 214.0]
[2019-03-22 23:44:25,824] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 6.0653080e-38 5.1497809e-30 4.6828455e-25], sum to 1.0000
[2019-03-22 23:44:25,830] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1978
[2019-03-22 23:44:25,836] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 74.0, 1.0, 2.0, 0.4656966369495772, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 531347.9162433195, 531347.9162433193, 136639.6898242805], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4442400.0000, 
sim time next is 4443000.0000, 
raw observation next is [24.0, 74.0, 1.0, 2.0, 0.4671966534209401, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 533067.0538699378, 533067.0538699378, 136837.4633476663], 
processed observation next is [0.0, 0.43478260869565216, 0.7272727272727273, 0.74, 1.0, 1.0, 0.33399581677617507, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19743224217405103, 0.19743224217405103, 0.3337499106040641], 
reward next is 0.6663, 
noisyNet noise sample is [array([-0.7726436], dtype=float32), 0.8226557]. 
=============================================
[2019-03-22 23:44:25,854] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[64.52395 ]
 [64.51939 ]
 [64.524826]
 [64.5238  ]
 [64.52346 ]], R is [[64.5497818 ]
 [64.5710144 ]
 [64.5931778 ]
 [64.61618042]
 [64.63989258]].
[2019-03-22 23:44:30,179] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 6.2225427e-37 1.0388366e-37], sum to 1.0000
[2019-03-22 23:44:30,185] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9579
[2019-03-22 23:44:30,189] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.16666666666667, 100.0, 1.0, 2.0, 0.4449557909459974, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 507284.966883476, 507284.966883476, 133467.11256976], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4518600.0000, 
sim time next is 4519200.0000, 
raw observation next is [20.33333333333334, 100.0, 1.0, 2.0, 0.4511348534099952, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 514532.581520561, 514532.581520561, 134488.909614847], 
processed observation next is [0.0, 0.30434782608695654, 0.5606060606060609, 1.0, 1.0, 1.0, 0.31391856676249397, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19056762278539296, 0.19056762278539296, 0.3280217307679195], 
reward next is 0.6720, 
noisyNet noise sample is [array([0.6306169], dtype=float32), 0.5785943]. 
=============================================
[2019-03-22 23:44:31,394] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.0436084e-36 1.1624265e-36], sum to 1.0000
[2019-03-22 23:44:31,402] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4447
[2019-03-22 23:44:31,406] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 61.0, 1.0, 2.0, 0.3920858247548311, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 443272.4404316834, 443272.4404316834, 124956.748800857], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4555800.0000, 
sim time next is 4556400.0000, 
raw observation next is [24.0, 61.0, 1.0, 2.0, 0.3919146581026086, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 443078.2587879354, 443078.2587879357, 124940.8538533637], 
processed observation next is [0.0, 0.7391304347826086, 0.7272727272727273, 0.61, 1.0, 1.0, 0.23989332262826074, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16410305881034645, 0.16410305881034656, 0.30473378988625294], 
reward next is 0.6953, 
noisyNet noise sample is [array([-1.9092672], dtype=float32), -0.06604851]. 
=============================================
[2019-03-22 23:44:32,697] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 2.5735927e-34], sum to 1.0000
[2019-03-22 23:44:32,704] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8279
[2019-03-22 23:44:32,709] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.2, 66.5, 1.0, 2.0, 0.3423534170074698, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 379123.8651269781, 379123.8651269784, 116790.2951851773], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4563000.0000, 
sim time next is 4563600.0000, 
raw observation next is [20.93333333333333, 67.33333333333334, 1.0, 2.0, 0.3381004059802352, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 373633.9483600216, 373633.9483600219, 116156.2684696315], 
processed observation next is [0.0, 0.8260869565217391, 0.5878787878787878, 0.6733333333333335, 1.0, 1.0, 0.172625507475294, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13838294383704502, 0.13838294383704516, 0.28330797187715], 
reward next is 0.7167, 
noisyNet noise sample is [array([1.5531994], dtype=float32), 0.513096]. 
=============================================
[2019-03-22 23:44:34,216] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 2.7347900e-36 3.6946676e-26 6.6407614e-30], sum to 1.0000
[2019-03-22 23:44:34,226] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3290
[2019-03-22 23:44:34,233] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.66666666666667, 67.0, 1.0, 2.0, 0.4769368671368446, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 517985.3306623686, 517985.3306623686, 114339.4439905226], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4614000.0000, 
sim time next is 4614600.0000, 
raw observation next is [18.83333333333333, 65.5, 1.0, 2.0, 0.4768876951464195, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 517931.8981425468, 517931.8981425468, 113949.9874655151], 
processed observation next is [1.0, 0.391304347826087, 0.4924242424242422, 0.655, 1.0, 1.0, 0.34610961893302433, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.191826628941684, 0.191826628941684, 0.2779267986963783], 
reward next is 0.7221, 
noisyNet noise sample is [array([1.1649288], dtype=float32), -1.2533963]. 
=============================================
[2019-03-22 23:44:38,349] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:44:38,358] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2468
[2019-03-22 23:44:38,361] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.16666666666666, 71.5, 1.0, 2.0, 0.2713445375397821, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 294630.6610925209, 294630.6610925212, 93463.95625335885], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4661400.0000, 
sim time next is 4662000.0000, 
raw observation next is [18.0, 73.0, 1.0, 2.0, 0.271330701424718, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 294615.6330454065, 294615.6330454065, 93795.8601171539], 
processed observation next is [1.0, 1.0, 0.45454545454545453, 0.73, 1.0, 1.0, 0.08916337678089747, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10911690112792832, 0.10911690112792832, 0.22877039052964368], 
reward next is 0.7712, 
noisyNet noise sample is [array([-1.2737534], dtype=float32), -1.1645257]. 
=============================================
[2019-03-22 23:44:38,376] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[76.33011 ]
 [76.33126 ]
 [76.332115]
 [76.33696 ]
 [76.356476]], R is [[76.36335754]
 [76.37176514]
 [76.38102722]
 [76.39134216]
 [76.40296936]].
[2019-03-22 23:44:43,438] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 3.1213701e-36 2.2952758e-29 1.7369675e-27], sum to 1.0000
[2019-03-22 23:44:43,445] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3121
[2019-03-22 23:44:43,453] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.3953641430104596, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 443939.5993233135, 443939.5993233137, 123627.7004669477], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4767600.0000, 
sim time next is 4768200.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.3869987012530124, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 434510.9341381144, 434510.9341381144, 122879.0777390965], 
processed observation next is [1.0, 0.17391304347826086, 0.45454545454545453, 1.0, 1.0, 1.0, 0.23374837656626546, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16092997560670905, 0.16092997560670905, 0.2997050676563329], 
reward next is 0.7003, 
noisyNet noise sample is [array([0.9151949], dtype=float32), 0.028866751]. 
=============================================
[2019-03-22 23:44:44,194] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.9989298e-37 1.0000000e+00 4.9447773e-29 3.1840040e-20 3.6860091e-19], sum to 1.0000
[2019-03-22 23:44:44,202] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9475
[2019-03-22 23:44:44,211] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.4348517041375213, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 492995.6457677584, 492995.6457677584, 129815.7426434156], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4780800.0000, 
sim time next is 4781400.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4954007559871142, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 561752.2466626638, 561752.2466626638, 136056.625884002], 
processed observation next is [1.0, 0.34782608695652173, 0.5, 1.0, 1.0, 1.0, 0.3692509449838927, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20805638765283843, 0.20805638765283843, 0.3318454289853707], 
reward next is 0.6682, 
noisyNet noise sample is [array([1.0846262], dtype=float32), 0.41362587]. 
=============================================
[2019-03-22 23:44:47,281] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.2041970e-33 5.1384565e-12 4.4755658e-18 6.2126250e-12 1.0000000e+00], sum to 1.0000
[2019-03-22 23:44:47,292] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9381
[2019-03-22 23:44:47,299] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [21.0, 94.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3105774296011332, 6.9112, 6.9112, 77.3421103, 526581.29751033, 526581.29751033, 204111.9356831611], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4832400.0000, 
sim time next is 4833000.0000, 
raw observation next is [21.0, 94.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3098437237804084, 6.9112, 6.9112, 77.3421103, 525341.7001854717, 525341.7001854717, 203953.8125444226], 
processed observation next is [1.0, 0.9565217391304348, 0.5909090909090909, 0.94, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.014062462543440617, 0.0, 0.0, 0.5085185399722538, 0.1945710000686932, 0.1945710000686932, 0.4974483232790795], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2261523], dtype=float32), -0.28392965]. 
=============================================
[2019-03-22 23:44:47,308] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[39.06227 ]
 [39.160988]
 [39.134567]
 [38.9282  ]
 [40.547695]], R is [[38.85122299]
 [38.46271133]
 [38.07808304]
 [37.69730377]
 [37.32033157]].
[2019-03-22 23:45:01,072] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.3910515e-37 4.0565461e-33], sum to 1.0000
[2019-03-22 23:45:01,085] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1058
[2019-03-22 23:45:01,087] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.33333333333333, 63.83333333333334, 1.0, 2.0, 0.4185759729005124, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 475827.4721132774, 475827.4721132774, 129223.0133811333], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5082600.0000, 
sim time next is 5083200.0000, 
raw observation next is [24.0, 65.0, 1.0, 2.0, 0.4146797079580976, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 471063.2728545679, 471063.2728545679, 128565.6206473902], 
processed observation next is [0.0, 0.8695652173913043, 0.7272727272727273, 0.65, 1.0, 1.0, 0.268349634947622, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17446787883502515, 0.17446787883502515, 0.31357468450582976], 
reward next is 0.6864, 
noisyNet noise sample is [array([0.1129597], dtype=float32), 0.3509142]. 
=============================================
[2019-03-22 23:45:05,694] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-22 23:45:05,697] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-22 23:45:05,698] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-22 23:45:05,699] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-22 23:45:05,700] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-22 23:45:05,701] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:45:05,700] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:45:05,702] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-22 23:45:05,703] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:45:05,703] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:45:05,705] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:45:05,722] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run32
[2019-03-22 23:45:05,745] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run32
[2019-03-22 23:45:05,745] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run32
[2019-03-22 23:45:05,789] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run32
[2019-03-22 23:45:05,806] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run32
[2019-03-22 23:45:37,841] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.10631415], dtype=float32), -0.103490986]
[2019-03-22 23:45:37,844] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [14.50266923666667, 99.664520345, 1.0, 2.0, 0.2400835489986611, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 260664.5117269498, 260664.5117269498, 89852.1515753465]
[2019-03-22 23:45:37,847] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:45:37,850] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.42718631676625285
[2019-03-22 23:46:02,878] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.10631415], dtype=float32), -0.103490986]
[2019-03-22 23:46:02,880] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [28.9, 53.0, 1.0, 2.0, 0.8133852271138542, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 926843.6953904758, 926843.6953904758, 191546.957038004]
[2019-03-22 23:46:02,882] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:46:02,888] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.3731706e-32 1.0000000e+00 1.4724921e-28 2.8156401e-17 3.9402024e-13], sampled 0.9909743798475442
[2019-03-22 23:46:21,177] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10631415], dtype=float32), -0.103490986]
[2019-03-22 23:46:21,177] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.2, 80.0, 1.0, 2.0, 0.3708973221167883, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 415419.3743083589, 415419.3743083593, 125334.5420579741]
[2019-03-22 23:46:21,178] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:46:21,182] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.5933661e-34 6.8016369e-31], sampled 0.6719297994170174
[2019-03-22 23:46:36,897] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.10631415], dtype=float32), -0.103490986]
[2019-03-22 23:46:36,898] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.1626757, 89.10594768, 1.0, 2.0, 0.314774248430682, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 342578.7956159973, 342578.7956159973, 116774.9074355799]
[2019-03-22 23:46:36,900] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:46:36,903] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.5247268e-35 4.0046565e-32], sampled 0.03469233418414153
[2019-03-22 23:46:39,056] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.10631415], dtype=float32), -0.103490986]
[2019-03-22 23:46:39,059] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.81772779666667, 96.22208277166668, 1.0, 2.0, 0.4522144170027805, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 515791.1552794317, 515791.1552794317, 139098.2071258513]
[2019-03-22 23:46:39,061] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:46:39,066] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 6.891526e-33 3.365748e-29], sampled 0.8899637705938462
[2019-03-22 23:46:40,423] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.10631415], dtype=float32), -0.103490986]
[2019-03-22 23:46:40,424] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [28.87981790666667, 61.99676677333333, 1.0, 2.0, 0.5946894222681633, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 669800.1633545101, 669800.1633545101, 162118.8487433254]
[2019-03-22 23:46:40,427] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:46:40,430] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 3.7899630e-36 1.5299000e-28 1.5347915e-22], sampled 0.928061412973604
[2019-03-22 23:46:49,046] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.10631415], dtype=float32), -0.103490986]
[2019-03-22 23:46:49,047] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [27.13313725, 76.21207249, 1.0, 2.0, 0.6228871209192458, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 699878.499252457, 699878.4992524567, 166431.8335349342]
[2019-03-22 23:46:49,047] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:46:49,049] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0.0000000e+00 1.0000000e+00 6.3625354e-35 3.3630709e-26 2.0783065e-20], sampled 0.10048501143745703
[2019-03-22 23:46:53,873] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.1148 1683769448.3564 211.0000
[2019-03-22 23:46:53,938] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8511.5130 1773248123.2886 173.0000
[2019-03-22 23:46:53,962] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7153 1706022735.7380 462.0000
[2019-03-22 23:46:53,994] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1147 1656209757.7786 80.0000
[2019-03-22 23:46:54,025] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5599 1663815647.6096 105.0000
[2019-03-22 23:46:55,043] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 775000, evaluation results [775000.0, 8511.513039158031, 1773248123.2886405, 173.0, 9061.114669779829, 1656209757.7786272, 80.0, 8856.559925897878, 1663815647.6095803, 105.0, 8597.715314517782, 1706022735.7380106, 462.0, 8574.114802843751, 1683769448.3564365, 211.0]
[2019-03-22 23:47:00,336] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.1745351e-32 1.0000000e+00 1.3029542e-28 2.7529997e-12 7.0978545e-16], sum to 1.0000
[2019-03-22 23:47:00,346] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6869
[2019-03-22 23:47:00,351] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666666, 98.0, 1.0, 2.0, 0.2534526470295483, 1.0, 2.0, 0.2534526470295483, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 576672.2709430654, 576672.270943065, 181004.8365259165], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5262000.0000, 
sim time next is 5262600.0000, 
raw observation next is [21.58333333333334, 99.0, 1.0, 2.0, 0.5084619539386082, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 579391.3993883285, 579391.3993883285, 143683.5529981905], 
processed observation next is [1.0, 0.9130434782608695, 0.6174242424242427, 0.99, 1.0, 1.0, 0.38557744242326014, 0.0, 0.5, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21458940718086242, 0.21458940718086242, 0.3504476902394891], 
reward next is 0.6496, 
noisyNet noise sample is [array([-0.28211054], dtype=float32), 0.12494674]. 
=============================================
[2019-03-22 23:47:01,331] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.1713106e-31 1.0000000e+00 7.7646380e-22 5.4366760e-09 1.4515614e-09], sum to 1.0000
[2019-03-22 23:47:01,341] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1284
[2019-03-22 23:47:01,349] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.75, 97.0, 1.0, 2.0, 0.501996970511029, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 572350.5364314921, 572350.5364314923, 142537.1257191903], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5261400.0000, 
sim time next is 5262000.0000, 
raw observation next is [21.66666666666666, 98.0, 1.0, 2.0, 0.5058364066148405, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 576672.2709430654, 576672.2709430654, 143065.83348937], 
processed observation next is [1.0, 0.9130434782608695, 0.621212121212121, 0.98, 1.0, 1.0, 0.38229550826855063, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2135823225715057, 0.2135823225715057, 0.3489410572911464], 
reward next is 0.6511, 
noisyNet noise sample is [array([0.1581498], dtype=float32), -0.46916297]. 
=============================================
[2019-03-22 23:47:01,367] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[70.03076]
 [69.95233]
 [69.79014]
 [69.55113]
 [69.42818]], R is [[70.15343475]
 [70.10425568]
 [70.05635834]
 [70.00912476]
 [69.96264648]].
[2019-03-22 23:47:01,978] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.00000000e+00 1.00000000e+00 4.27560962e-30 4.88646938e-18
 1.26093175e-20], sum to 1.0000
[2019-03-22 23:47:01,988] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7983
[2019-03-22 23:47:01,996] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.53333333333333, 95.50000000000001, 1.0, 2.0, 0.456989340514413, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 521076.4940981691, 521076.4940981691, 134841.9180862928], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5271000.0000, 
sim time next is 5271600.0000, 
raw observation next is [20.46666666666667, 91.0, 1.0, 2.0, 0.4388699437748358, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 499331.1433509759, 499331.1433509759, 131615.3541176119], 
processed observation next is [1.0, 0.0, 0.5666666666666668, 0.91, 1.0, 1.0, 0.2985874297185447, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18493746050036144, 0.18493746050036144, 0.3210130588234436], 
reward next is 0.6790, 
noisyNet noise sample is [array([-1.2728009], dtype=float32), -0.1975973]. 
=============================================
[2019-03-22 23:47:03,377] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.4438698e-26 1.0000000e+00 8.7849880e-26 8.6617352e-14 1.1238063e-09], sum to 1.0000
[2019-03-22 23:47:03,386] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0501
[2019-03-22 23:47:03,394] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1095888.589571409 W.
[2019-03-22 23:47:03,397] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.8, 51.66666666666666, 1.0, 2.0, 0.4805657384073008, 1.0, 2.0, 0.4805657384073008, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846335610695, 1095888.589571409, 1095888.589571409, 224451.679418681], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5310600.0000, 
sim time next is 5311200.0000, 
raw observation next is [27.9, 52.33333333333334, 1.0, 2.0, 0.496682392777726, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9468420153770797, 6.952035734469702, 6.9112, 77.3283621135107, 1115065.684799101, 1101803.090857674, 253570.3743812568], 
processed observation next is [1.0, 0.4782608695652174, 0.9045454545454544, 0.5233333333333334, 1.0, 1.0, 0.3708529909721575, 0.0, 0.5, -0.25, 1.0, 0.5, 0.9240600219672569, 0.004083573446970234, 0.0, 0.5084281466833498, 0.4129872906663337, 0.40807521883617554, 0.6184643277591629], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.22133295], dtype=float32), -0.03031995]. 
=============================================
[2019-03-22 23:47:05,498] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.1527131e-34 1.0000000e+00 2.5785657e-26 4.9520703e-19 1.9911357e-23], sum to 1.0000
[2019-03-22 23:47:05,509] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3604
[2019-03-22 23:47:05,515] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.3, 46.0, 1.0, 2.0, 0.4382676588829048, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 499171.5162843823, 499171.5162843823, 132107.9648686245], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5338800.0000, 
sim time next is 5339400.0000, 
raw observation next is [27.93333333333334, 47.33333333333334, 1.0, 2.0, 0.4324641424019862, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 492333.4743460142, 492333.4743460142, 131267.3257015943], 
processed observation next is [1.0, 0.8260869565217391, 0.9060606060606063, 0.47333333333333344, 1.0, 1.0, 0.29058017800248276, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1823457312392645, 0.1823457312392645, 0.32016420902827875], 
reward next is 0.6798, 
noisyNet noise sample is [array([0.66877675], dtype=float32), -0.72544324]. 
=============================================
[2019-03-22 23:47:07,732] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.2144860e-37 1.0000000e+00 3.6542861e-33 2.9208167e-26 2.6347134e-27], sum to 1.0000
[2019-03-22 23:47:07,742] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3893
[2019-03-22 23:47:07,746] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.93333333333333, 92.0, 1.0, 2.0, 0.3518032575916891, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 389649.6757228731, 389649.6757228731, 117545.0443791511], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5470800.0000, 
sim time next is 5471400.0000, 
raw observation next is [18.11666666666667, 91.0, 1.0, 2.0, 0.3498332119065929, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 387883.0020734861, 387883.0020734858, 117557.9158269835], 
processed observation next is [1.0, 0.30434782608695654, 0.459848484848485, 0.91, 1.0, 1.0, 0.18729151488324108, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1436603711383282, 0.14366037113832808, 0.28672662396825244], 
reward next is 0.7133, 
noisyNet noise sample is [array([-0.16486242], dtype=float32), 0.55456334]. 
=============================================
[2019-03-22 23:47:24,789] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 9.612360e-38 8.836578e-34], sum to 1.0000
[2019-03-22 23:47:24,796] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8052
[2019-03-22 23:47:24,801] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.1, 67.33333333333334, 1.0, 2.0, 0.2162510434541037, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 234794.7386791859, 234794.7386791856, 74044.73906437184], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5682000.0000, 
sim time next is 5682600.0000, 
raw observation next is [16.1, 66.5, 1.0, 2.0, 0.2154935001095687, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 233972.0375768875, 233972.0375768872, 73723.28705125193], 
processed observation next is [0.0, 0.782608695652174, 0.3681818181818182, 0.665, 1.0, 1.0, 0.01936687513696085, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08665631021366203, 0.08665631021366192, 0.17981289524695593], 
reward next is 0.8202, 
noisyNet noise sample is [array([1.2489326], dtype=float32), -1.7679375]. 
=============================================
[2019-03-22 23:47:28,375] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 3.6050547e-38 5.6960724e-37 7.6770002e-34], sum to 1.0000
[2019-03-22 23:47:28,383] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4987
[2019-03-22 23:47:28,390] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.6, 44.66666666666667, 1.0, 2.0, 0.2635062868501601, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 286117.247396831, 286117.2473968313, 85982.3348165472], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5754000.0000, 
sim time next is 5754600.0000, 
raw observation next is [21.6, 44.0, 1.0, 2.0, 0.2637696549332583, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 286403.298783711, 286403.298783711, 85351.95854995919], 
processed observation next is [0.0, 0.6086956521739131, 0.6181818181818183, 0.44, 1.0, 1.0, 0.07971206866657289, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10607529584581889, 0.10607529584581889, 0.20817550865843706], 
reward next is 0.7918, 
noisyNet noise sample is [array([0.64070773], dtype=float32), -1.7132244]. 
=============================================
[2019-03-22 23:47:30,247] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.7034136e-31 8.4147240e-28 5.7524853e-26], sum to 1.0000
[2019-03-22 23:47:30,255] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2375
[2019-03-22 23:47:30,261] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.16666666666667, 59.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 198118.4631819413, 198118.463181941, 65289.58035960855], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5790000.0000, 
sim time next is 5790600.0000, 
raw observation next is [13.95, 59.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 195131.8243712529, 195131.8243712529, 64575.91349236379], 
processed observation next is [1.0, 0.0, 0.27045454545454545, 0.59, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.072271046063427, 0.072271046063427, 0.1575022280301556], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.16599815], dtype=float32), 0.27926725]. 
=============================================
[2019-03-22 23:47:31,039] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.7094306e-36 9.3263814e-34 1.7340219e-34], sum to 1.0000
[2019-03-22 23:47:31,048] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2285
[2019-03-22 23:47:31,055] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [11.6, 86.0, 1.0, 2.0, 0.3843669964197777, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 417405.1014805901, 417405.1014805898, 86249.13341938303], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5808000.0000, 
sim time next is 5808600.0000, 
raw observation next is [11.6, 86.0, 1.0, 2.0, 0.3835354935600098, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 416501.7403817616, 416501.7403817616, 86152.28665494948], 
processed observation next is [1.0, 0.21739130434782608, 0.1636363636363636, 0.86, 1.0, 1.0, 0.22941936695001225, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1542599038450969, 0.1542599038450969, 0.21012752842670604], 
reward next is 0.7899, 
noisyNet noise sample is [array([-1.1956657], dtype=float32), 0.31079572]. 
=============================================
[2019-03-22 23:47:33,388] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 2.4108385e-37 2.7750330e-33 1.2705354e-20], sum to 1.0000
[2019-03-22 23:47:33,398] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2850
[2019-03-22 23:47:33,403] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.55, 51.5, 1.0, 2.0, 0.5203649098200159, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 574606.5656912666, 574606.5656912666, 131785.7267437475], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5830200.0000, 
sim time next is 5830800.0000, 
raw observation next is [23.83333333333333, 51.66666666666667, 1.0, 2.0, 0.5467068271760119, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 606332.9451821918, 606332.9451821921, 135340.9749438456], 
processed observation next is [1.0, 0.4782608695652174, 0.7196969696969695, 0.5166666666666667, 1.0, 1.0, 0.4333835339700149, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22456775747488586, 0.22456775747488597, 0.3300999388874283], 
reward next is 0.6699, 
noisyNet noise sample is [array([0.2736058], dtype=float32), 1.7571126]. 
=============================================
[2019-03-22 23:47:37,466] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:47:37,474] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7670
[2019-03-22 23:47:37,481] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 78.0, 1.0, 2.0, 0.2751438139095884, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 298757.2491657132, 298757.2491657132, 103332.1416403499], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5902200.0000, 
sim time next is 5902800.0000, 
raw observation next is [18.26666666666667, 77.33333333333334, 1.0, 2.0, 0.2832275259413657, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 307537.4981042835, 307537.4981042838, 108018.1155877664], 
processed observation next is [1.0, 0.30434782608695654, 0.4666666666666668, 0.7733333333333334, 1.0, 1.0, 0.1040344074267071, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11390277707566057, 0.11390277707566067, 0.2634588185067473], 
reward next is 0.7365, 
noisyNet noise sample is [array([1.3644787], dtype=float32), -0.37705603]. 
=============================================
[2019-03-22 23:47:41,437] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.7224434e-36 7.5762227e-34 3.7193004e-34], sum to 1.0000
[2019-03-22 23:47:41,445] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0715
[2019-03-22 23:47:41,451] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.05, 73.5, 1.0, 2.0, 0.6727169408303043, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 754541.0401853174, 754541.0401853172, 152605.0408732859], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5992200.0000, 
sim time next is 5992800.0000, 
raw observation next is [21.23333333333333, 72.66666666666666, 1.0, 2.0, 0.696261420215147, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 781838.3346676693, 781838.3346676693, 155941.6953197869], 
processed observation next is [1.0, 0.34782608695652173, 0.6015151515151514, 0.7266666666666666, 1.0, 1.0, 0.6203267752689338, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.28956975358061826, 0.28956975358061826, 0.38034559834094367], 
reward next is 0.6197, 
noisyNet noise sample is [array([-1.2315191], dtype=float32), -1.0494858]. 
=============================================
[2019-03-22 23:47:47,713] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-22 23:47:47,714] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-22 23:47:47,715] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-22 23:47:47,717] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-22 23:47:47,717] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:47:47,716] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-22 23:47:47,722] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:47:47,720] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:47:47,719] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-22 23:47:47,725] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:47:47,729] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:47:47,747] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run33
[2019-03-22 23:47:47,748] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run33
[2019-03-22 23:47:47,767] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run33
[2019-03-22 23:47:47,810] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run33
[2019-03-22 23:47:47,831] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run33
[2019-03-22 23:48:33,824] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.14134954], dtype=float32), -0.11231462]
[2019-03-22 23:48:33,825] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.03333333333333, 69.0, 1.0, 2.0, 0.2543417186074037, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 276148.507283554, 276148.507283554, 91822.03093612788]
[2019-03-22 23:48:33,826] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:48:33,827] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.0003630711877607995
[2019-03-22 23:49:09,448] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.14134954], dtype=float32), -0.11231462]
[2019-03-22 23:49:09,449] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [16.9, 65.5, 1.0, 2.0, 0.235056617452829, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 255205.4919652527, 255205.4919652527, 82087.48893174589]
[2019-03-22 23:49:09,451] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:49:09,454] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.6426600694104152
[2019-03-22 23:49:27,745] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.14134954], dtype=float32), -0.11231462]
[2019-03-22 23:49:27,746] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [17.83333333333333, 67.66666666666667, 1.0, 2.0, 0.2517052811707765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 273285.3758103579, 273285.3758103575, 89019.01895667046]
[2019-03-22 23:49:27,747] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:49:27,752] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.0470424994184353
[2019-03-22 23:49:34,849] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2494 1773207034.4548 173.0000
[2019-03-22 23:49:35,324] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3485 1683325900.1134 214.0000
[2019-03-22 23:49:35,343] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9309 1705967916.6745 465.0000
[2019-03-22 23:49:35,491] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1147 1656209757.7786 80.0000
[2019-03-22 23:49:35,534] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5598 1663796639.0689 105.0000
[2019-03-22 23:49:36,549] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 800000, evaluation results [800000.0, 8512.249429056992, 1773207034.4547563, 173.0, 9061.114669779829, 1656209757.7786272, 80.0, 8856.559759326878, 1663796639.0688558, 105.0, 8596.930884973775, 1705967916.6744611, 465.0, 8574.348472942609, 1683325900.1133502, 214.0]
[2019-03-22 23:49:37,305] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:49:37,312] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3814
[2019-03-22 23:49:37,321] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.23333333333333, 74.33333333333334, 1.0, 2.0, 0.3047623738166435, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 330928.6801185993, 330928.6801185996, 85953.0659444408], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6510000.0000, 
sim time next is 6510600.0000, 
raw observation next is [16.6, 72.5, 1.0, 2.0, 0.3603728374510388, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 391338.0487111797, 391338.04871118, 92570.44622069082], 
processed observation next is [1.0, 0.34782608695652173, 0.390909090909091, 0.725, 1.0, 1.0, 0.2004660468137985, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14494001804117768, 0.1449400180411778, 0.22578157614802638], 
reward next is 0.7742, 
noisyNet noise sample is [array([0.05150741], dtype=float32), 0.6049196]. 
=============================================
[2019-03-22 23:49:41,996] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.49591100e-27 9.99999881e-01 9.59288594e-20 8.29961166e-08
 1.05256893e-10], sum to 1.0000
[2019-03-22 23:49:42,003] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9521
[2019-03-22 23:49:42,008] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.7, 59.33333333333334, 1.0, 2.0, 0.8030477331876708, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 897151.8221003935, 897151.8221003937, 168157.277990934], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6194400.0000, 
sim time next is 6195000.0000, 
raw observation next is [22.7, 58.16666666666666, 1.0, 2.0, 0.7919119269971999, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 882595.4293117553, 882595.4293117553, 165759.633021353], 
processed observation next is [1.0, 0.6956521739130435, 0.6681818181818181, 0.5816666666666666, 1.0, 1.0, 0.7398899087465, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3268871960413909, 0.3268871960413909, 0.4042917878569585], 
reward next is 0.5957, 
noisyNet noise sample is [array([-0.97776943], dtype=float32), 0.5905757]. 
=============================================
[2019-03-22 23:49:42,017] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[56.10258 ]
 [56.04485 ]
 [55.919186]
 [55.44804 ]
 [55.88306 ]], R is [[56.30771637]
 [56.33449936]
 [56.35832977]
 [56.38026428]
 [56.37628555]].
[2019-03-22 23:49:43,903] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 5.4466218e-38 0.0000000e+00 1.2274005e-38], sum to 1.0000
[2019-03-22 23:49:43,915] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9220
[2019-03-22 23:49:43,922] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 90.0, 1.0, 2.0, 0.380256785741901, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 428143.4395354501, 428143.4395354498, 122905.183814356], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6221400.0000, 
sim time next is 6222000.0000, 
raw observation next is [19.4, 90.0, 1.0, 2.0, 0.3803906800847105, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 428300.1522868263, 428300.1522868266, 122919.9767905589], 
processed observation next is [0.0, 0.0, 0.5181818181818181, 0.9, 1.0, 1.0, 0.2254883501058881, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15862968603215788, 0.158629686032158, 0.29980482144038756], 
reward next is 0.7002, 
noisyNet noise sample is [array([0.40650257], dtype=float32), -0.8185837]. 
=============================================
[2019-03-22 23:49:43,936] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[65.71606 ]
 [65.78878 ]
 [65.921906]
 [65.961426]
 [66.00187 ]], R is [[65.88002777]
 [65.92146301]
 [65.962677  ]
 [66.00408936]
 [66.04584503]].
[2019-03-22 23:49:49,354] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 7.075284e-38 8.814530e-33], sum to 1.0000
[2019-03-22 23:49:49,364] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7460
[2019-03-22 23:49:49,372] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.7, 85.0, 1.0, 2.0, 0.480688355695413, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 548499.9041544797, 548499.9041544797, 138931.1401921162], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6318000.0000, 
sim time next is 6318600.0000, 
raw observation next is [22.7, 85.00000000000001, 1.0, 2.0, 0.4794394293299687, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 547075.5558893878, 547075.5558893878, 138773.7109742645], 
processed observation next is [0.0, 0.13043478260869565, 0.6681818181818181, 0.8500000000000001, 1.0, 1.0, 0.34929928666246085, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20262057625532884, 0.20262057625532884, 0.3384724657908891], 
reward next is 0.6615, 
noisyNet noise sample is [array([-0.3603988], dtype=float32), 1.5344712]. 
=============================================
[2019-03-22 23:50:07,424] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:50:07,430] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6045
[2019-03-22 23:50:07,439] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 87.0, 1.0, 2.0, 0.3546811154972031, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 394626.879989803, 394626.879989803, 118498.9633035187], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6646800.0000, 
sim time next is 6647400.0000, 
raw observation next is [18.8, 87.0, 1.0, 2.0, 0.3539400499467937, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 393802.0607554178, 393802.0607554181, 118439.8755832229], 
processed observation next is [1.0, 0.9565217391304348, 0.49090909090909096, 0.87, 1.0, 1.0, 0.19242506243349208, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14585261509459918, 0.1458526150945993, 0.28887774532493393], 
reward next is 0.7111, 
noisyNet noise sample is [array([-0.8530348], dtype=float32), -1.7808076]. 
=============================================
[2019-03-22 23:50:07,814] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.5399306e-37 0.0000000e+00], sum to 1.0000
[2019-03-22 23:50:07,821] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0425
[2019-03-22 23:50:07,826] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 81.0, 1.0, 2.0, 0.3503321829841609, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 389135.5371804103, 389135.53718041, 117881.302196748], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6642000.0000, 
sim time next is 6642600.0000, 
raw observation next is [19.3, 82.0, 1.0, 2.0, 0.3510860570259114, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 389933.466036078, 389933.4660360777, 117924.5876472589], 
processed observation next is [1.0, 0.9130434782608695, 0.5136363636363637, 0.82, 1.0, 1.0, 0.18885757128238922, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14441980223558445, 0.14441980223558434, 0.2876209454811193], 
reward next is 0.7124, 
noisyNet noise sample is [array([-0.2002823], dtype=float32), 0.51637197]. 
=============================================
[2019-03-22 23:50:08,113] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.9100016e-37 0.0000000e+00], sum to 1.0000
[2019-03-22 23:50:08,121] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6304
[2019-03-22 23:50:08,127] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.1, 88.5, 1.0, 2.0, 0.3735551285688242, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 418395.6395305334, 418395.6395305331, 121235.2961611246], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6679800.0000, 
sim time next is 6680400.0000, 
raw observation next is [19.0, 89.0, 1.0, 2.0, 0.3716850397377511, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 416086.551290492, 416086.551290492, 120978.6557607885], 
processed observation next is [1.0, 0.30434782608695654, 0.5, 0.89, 1.0, 1.0, 0.21460629967218883, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15410613010758964, 0.15410613010758964, 0.29506989209948414], 
reward next is 0.7049, 
noisyNet noise sample is [array([-1.1810743], dtype=float32), 0.20895182]. 
=============================================
[2019-03-22 23:50:08,494] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 6.4255557e-37 1.8620234e-27 3.8078621e-35], sum to 1.0000
[2019-03-22 23:50:08,506] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8817
[2019-03-22 23:50:08,509] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.36666666666667, 83.16666666666666, 1.0, 2.0, 0.4017418652030438, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 453239.4138405949, 453239.4138405946, 125290.4405125337], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7062600.0000, 
sim time next is 7063200.0000, 
raw observation next is [20.0, 84.0, 1.0, 2.0, 0.3978911757420431, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 447754.3705668236, 447754.3705668236, 124335.2827988064], 
processed observation next is [1.0, 0.782608695652174, 0.5454545454545454, 0.84, 1.0, 1.0, 0.24736396967755384, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1658349520617865, 0.1658349520617865, 0.30325678731416195], 
reward next is 0.6967, 
noisyNet noise sample is [array([1.0524633], dtype=float32), 1.0632722]. 
=============================================
[2019-03-22 23:50:20,996] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:50:21,004] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3628
[2019-03-22 23:50:21,008] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.01666666666667, 50.16666666666667, 1.0, 2.0, 0.4489230770831815, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 511995.1692648393, 511995.1692648393, 134225.3021221694], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6875400.0000, 
sim time next is 6876000.0000, 
raw observation next is [28.3, 49.0, 1.0, 2.0, 0.4496585873620294, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 512856.4319574132, 512856.4319574132, 134350.9044932619], 
processed observation next is [0.0, 0.6086956521739131, 0.9227272727272727, 0.49, 1.0, 1.0, 0.31207323420253674, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18994682665089377, 0.18994682665089377, 0.3276851329103949], 
reward next is 0.6723, 
noisyNet noise sample is [array([-0.23339364], dtype=float32), -1.1240541]. 
=============================================
[2019-03-22 23:50:21,024] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[72.39512 ]
 [72.37146 ]
 [72.342575]
 [72.30647 ]
 [72.255516]], R is [[72.38374329]
 [72.33252716]
 [72.28211975]
 [72.23246765]
 [72.18358612]].
[2019-03-22 23:50:22,774] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:50:22,778] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3323
[2019-03-22 23:50:22,785] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.7, 75.5, 1.0, 2.0, 0.3967638941618714, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 448493.8240224267, 448493.8240224267, 125341.1558277779], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6911400.0000, 
sim time next is 6912000.0000, 
raw observation next is [21.6, 76.0, 1.0, 2.0, 0.3960999828481452, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 447635.6409918158, 447635.6409918158, 125216.6373911098], 
processed observation next is [0.0, 0.0, 0.6181818181818183, 0.76, 1.0, 1.0, 0.24512497856018145, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16579097814511695, 0.16579097814511695, 0.30540643266124345], 
reward next is 0.6946, 
noisyNet noise sample is [array([-0.37898996], dtype=float32), -0.41862348]. 
=============================================
[2019-03-22 23:50:22,806] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[69.86545 ]
 [69.843124]
 [69.81856 ]
 [69.79599 ]
 [69.7685  ]], R is [[69.63484192]
 [69.63278198]
 [69.63043213]
 [69.62775421]
 [69.62470245]].
[2019-03-22 23:50:23,607] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 8.485735e-36 2.055231e-34], sum to 1.0000
[2019-03-22 23:50:23,613] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1677
[2019-03-22 23:50:23,619] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.7, 73.0, 1.0, 2.0, 0.40616657910601, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 461029.0853858349, 461029.0853858349, 127467.9363543071], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6944400.0000, 
sim time next is 6945000.0000, 
raw observation next is [22.98333333333333, 72.33333333333334, 1.0, 2.0, 0.4124970964526269, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 468706.0787372441, 468706.0787372441, 128456.2558659949], 
processed observation next is [0.0, 0.391304347826087, 0.6810606060606059, 0.7233333333333334, 1.0, 1.0, 0.26562137056578355, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1735948439767571, 0.1735948439767571, 0.3133079411365729], 
reward next is 0.6867, 
noisyNet noise sample is [array([1.0801371], dtype=float32), -1.2334377]. 
=============================================
[2019-03-22 23:50:23,638] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[68.16044 ]
 [68.16487 ]
 [68.18574 ]
 [68.208534]
 [68.23475 ]], R is [[68.14385223]
 [68.15151978]
 [68.16134644]
 [68.17334747]
 [68.18750763]].
[2019-03-22 23:50:29,199] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-22 23:50:29,199] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-22 23:50:29,200] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:50:29,201] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-22 23:50:29,201] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:50:29,202] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-22 23:50:29,203] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:50:29,204] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-22 23:50:29,205] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-22 23:50:29,205] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:50:29,206] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:50:29,229] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run34
[2019-03-22 23:50:29,247] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run34
[2019-03-22 23:50:29,270] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run34
[2019-03-22 23:50:29,298] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run34
[2019-03-22 23:50:29,299] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run34
[2019-03-22 23:50:43,334] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.12127197], dtype=float32), -0.09273525]
[2019-03-22 23:50:43,335] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.49069849, 92.13880262, 1.0, 2.0, 0.3614925587407489, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 403632.2343833736, 403632.2343833739, 123978.5359833293]
[2019-03-22 23:50:43,337] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:50:43,340] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00
 1.16593105e-35], sampled 0.5304036571679853
[2019-03-22 23:51:04,420] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.12127197], dtype=float32), -0.09273525]
[2019-03-22 23:51:04,421] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [28.01666666666667, 49.33333333333334, 1.0, 2.0, 0.4816168025811256, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 549161.6696841405, 549161.6696841401, 141896.5947079282]
[2019-03-22 23:51:04,423] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:51:04,428] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0.0000000e+00 1.0000000e+00 5.4214982e-38 3.6931488e-32 9.9188594e-29], sampled 0.7757906946876838
[2019-03-22 23:51:31,097] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.12127197], dtype=float32), -0.09273525]
[2019-03-22 23:51:31,097] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.75, 75.5, 1.0, 2.0, 0.524700629631703, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 598014.0010189416, 598014.0010189413, 149760.009526589]
[2019-03-22 23:51:31,098] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:51:31,101] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 1.6393700e-38 4.8308226e-36 2.5599264e-32], sampled 0.2609339311207928
[2019-03-22 23:52:11,685] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.12127197], dtype=float32), -0.09273525]
[2019-03-22 23:52:11,687] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [17.95, 59.0, 1.0, 2.0, 0.2402128949383955, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 260804.9762078609, 260804.9762078606, 83049.59720067732]
[2019-03-22 23:52:11,689] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:52:11,692] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.17999646472625408
[2019-03-22 23:52:14,743] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.12127197], dtype=float32), -0.09273525]
[2019-03-22 23:52:14,745] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.88333333333333, 62.0, 1.0, 2.0, 0.2512859703225243, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 272844.6073602961, 272844.6073602958, 80910.63413861017]
[2019-03-22 23:52:14,746] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:52:14,749] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.15928095411408993
[2019-03-22 23:52:16,865] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5598 1663796639.0689 105.0000
[2019-03-22 23:52:16,975] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1147 1656209757.7786 80.0000
[2019-03-22 23:52:17,033] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9309 1705967916.6745 465.0000
[2019-03-22 23:52:17,065] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2492 1773187030.7201 173.0000
[2019-03-22 23:52:17,102] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-22 23:52:18,119] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 825000, evaluation results [825000.0, 8512.249193409023, 1773187030.7201214, 173.0, 9061.114669779829, 1656209757.7786272, 80.0, 8856.559759326878, 1663796639.0688558, 105.0, 8596.930884973775, 1705967916.6744611, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-22 23:52:31,614] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.2066468e-38 1.0000000e+00 7.4697397e-38 1.7316008e-21 1.3051178e-21], sum to 1.0000
[2019-03-22 23:52:31,622] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3102
[2019-03-22 23:52:31,628] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 96.0, 1.0, 2.0, 0.4507615392728437, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 512783.5124364225, 512783.5124364225, 132751.4167379587], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7620000.0000, 
sim time next is 7620600.0000, 
raw observation next is [20.0, 96.0, 1.0, 2.0, 0.4432919125899546, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 504275.2511788327, 504275.251178833, 131981.4748362347], 
processed observation next is [1.0, 0.17391304347826086, 0.5454545454545454, 0.96, 1.0, 1.0, 0.3041148907374432, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18676861154771582, 0.18676861154771593, 0.32190603618593827], 
reward next is 0.6781, 
noisyNet noise sample is [array([0.05203114], dtype=float32), -1.4040554]. 
=============================================
[2019-03-22 23:52:33,949] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.1618629e-37 1.0000000e+00 7.9536446e-32 3.7950950e-23 1.8428511e-28], sum to 1.0000
[2019-03-22 23:52:33,959] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9205
[2019-03-22 23:52:33,966] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.55, 44.5, 1.0, 2.0, 0.9281228769052476, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1036321.652059497, 1036321.652059497, 186078.9973958394], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7306200.0000, 
sim time next is 7306800.0000, 
raw observation next is [25.73333333333333, 44.0, 1.0, 2.0, 0.946288603644319, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1057946.324428792, 1057946.324428793, 189467.1445150287], 
processed observation next is [1.0, 0.5652173913043478, 0.8060606060606059, 0.44, 1.0, 1.0, 0.9328607545553987, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3918319720106637, 0.3918319720106641, 0.4621149866220212], 
reward next is 0.5379, 
noisyNet noise sample is [array([-2.6519907], dtype=float32), 0.8335427]. 
=============================================
[2019-03-22 23:52:35,540] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:52:35,550] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3273
[2019-03-22 23:52:35,558] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.56666666666667, 64.0, 1.0, 2.0, 0.3460219646549009, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 382720.0924864077, 382720.0924864077, 116888.6733455548], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7334400.0000, 
sim time next is 7335000.0000, 
raw observation next is [21.45, 65.0, 1.0, 2.0, 0.3482366799740802, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 385406.0895297232, 385406.0895297232, 117151.8298110812], 
processed observation next is [1.0, 0.9130434782608695, 0.6113636363636363, 0.65, 1.0, 1.0, 0.18529584996760023, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14274299612211971, 0.14274299612211971, 0.2857361702709298], 
reward next is 0.7143, 
noisyNet noise sample is [array([-1.0514339], dtype=float32), -1.7744054]. 
=============================================
[2019-03-22 23:52:35,569] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[69.36311]
 [69.37948]
 [69.39939]
 [69.39743]
 [69.42148]], R is [[69.35778046]
 [69.37910461]
 [69.40093231]
 [69.42311859]
 [69.44550323]].
[2019-03-22 23:52:36,506] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 8.333896e-37 0.000000e+00], sum to 1.0000
[2019-03-22 23:52:36,516] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3390
[2019-03-22 23:52:36,522] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.23333333333333, 50.33333333333333, 1.0, 2.0, 0.2931929871096225, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 318361.8561670016, 318361.8561670013, 93795.13015765889], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7753200.0000, 
sim time next is 7753800.0000, 
raw observation next is [21.41666666666667, 49.66666666666667, 1.0, 2.0, 0.297559723490116, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 323105.025991474, 323105.0259914738, 94760.36186428656], 
processed observation next is [1.0, 0.7391304347826086, 0.6098484848484851, 0.4966666666666667, 1.0, 1.0, 0.12194965436264499, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11966852814499036, 0.11966852814499031, 0.23112283381533308], 
reward next is 0.7689, 
noisyNet noise sample is [array([2.3566287], dtype=float32), 0.14077748]. 
=============================================
[2019-03-22 23:52:45,780] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.1704024e-32 9.6910898e-28 3.5455521e-22], sum to 1.0000
[2019-03-22 23:52:45,790] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4805
[2019-03-22 23:52:45,795] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.36666666666667, 97.66666666666666, 1.0, 2.0, 0.4515701834948514, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 514821.1712968913, 514821.1712968913, 134145.6738456565], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7533600.0000, 
sim time next is 7534200.0000, 
raw observation next is [20.18333333333333, 98.83333333333334, 1.0, 2.0, 0.4498093771873603, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 512743.2269326216, 512743.2269326216, 133850.8807998749], 
processed observation next is [0.0, 0.17391304347826086, 0.5537878787878786, 0.9883333333333334, 1.0, 1.0, 0.31226172148420034, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18990489886393394, 0.18990489886393394, 0.3264655629265241], 
reward next is 0.6735, 
noisyNet noise sample is [array([-0.5263098], dtype=float32), -1.2669237]. 
=============================================
[2019-03-22 23:52:48,307] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:52:48,308] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:52:48,347] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run5
[2019-03-22 23:52:50,360] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.00000000e+00 1.00000000e+00 0.00000000e+00 1.06743985e-35
 0.00000000e+00], sum to 1.0000
[2019-03-22 23:52:50,368] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0245
[2019-03-22 23:52:50,375] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 96.0, 1.0, 2.0, 0.4942522916645378, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 562303.283348729, 562303.2833487287, 137369.4274253843], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7618200.0000, 
sim time next is 7618800.0000, 
raw observation next is [20.0, 96.0, 1.0, 2.0, 0.4492539438612752, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 511081.6595593743, 511081.6595593743, 132609.6928125504], 
processed observation next is [1.0, 0.17391304347826086, 0.5454545454545454, 0.96, 1.0, 1.0, 0.31156742982659397, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.189289503540509, 0.189289503540509, 0.32343827515256196], 
reward next is 0.6766, 
noisyNet noise sample is [array([-0.38006237], dtype=float32), 0.20901963]. 
=============================================
[2019-03-22 23:52:50,695] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:52:50,697] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:52:50,737] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run5
[2019-03-22 23:52:52,404] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:52:52,412] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8707
[2019-03-22 23:52:52,417] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.2, 92.0, 1.0, 2.0, 0.3388304157663543, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 370374.5747171245, 370374.5747171245, 114710.5160800163], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 12000.0000, 
sim time next is 12600.0000, 
raw observation next is [17.15, 94.0, 1.0, 2.0, 0.3412905856755625, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 374197.0404064208, 374197.0404064211, 115291.5377216183], 
processed observation next is [1.0, 0.13043478260869565, 0.41590909090909084, 0.94, 1.0, 1.0, 0.17661323209445307, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13859149644682253, 0.13859149644682264, 0.28119887249175196], 
reward next is 0.7188, 
noisyNet noise sample is [array([-0.92544264], dtype=float32), 0.77268076]. 
=============================================
[2019-03-22 23:52:55,416] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:52:55,423] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3514
[2019-03-22 23:52:55,430] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.55, 98.5, 1.0, 2.0, 0.3865303722301818, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 435821.9960464936, 435821.9960464934, 123783.3296016119], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7702200.0000, 
sim time next is 7702800.0000, 
raw observation next is [18.46666666666667, 99.0, 1.0, 2.0, 0.3847707133363872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 433706.648248483, 433706.6482484833, 123556.1284471774], 
processed observation next is [1.0, 0.13043478260869565, 0.4757575757575758, 0.99, 1.0, 1.0, 0.23096339167048396, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1606320919438826, 0.1606320919438827, 0.3013564108467741], 
reward next is 0.6986, 
noisyNet noise sample is [array([0.46058837], dtype=float32), 0.18026385]. 
=============================================
[2019-03-22 23:52:56,812] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:52:56,820] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6737
[2019-03-22 23:52:56,824] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.31666666666667, 64.16666666666666, 1.0, 2.0, 0.5693184755325924, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 619152.7825665998, 619152.7825665998, 133606.6788435992], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7725000.0000, 
sim time next is 7725600.0000, 
raw observation next is [20.5, 63.0, 1.0, 2.0, 0.5725455457118394, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 622777.9667844238, 622777.9667844238, 133958.6089821036], 
processed observation next is [1.0, 0.43478260869565216, 0.5681818181818182, 0.63, 1.0, 1.0, 0.46568193213979914, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23065850621645326, 0.23065850621645326, 0.32672831459049656], 
reward next is 0.6733, 
noisyNet noise sample is [array([0.27400097], dtype=float32), -0.94938713]. 
=============================================
[2019-03-22 23:53:01,825] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:53:01,835] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2490
[2019-03-22 23:53:01,842] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 88.0, 1.0, 2.0, 0.2021783428299338, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 219511.845226851, 219511.8452268513, 73345.06017512913], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 180000.0000, 
sim time next is 180600.0000, 
raw observation next is [13.83333333333333, 89.00000000000001, 1.0, 2.0, 0.2008235813382162, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 218040.6053062343, 218040.6053062343, 73038.65774945846], 
processed observation next is [0.0, 0.08695652173913043, 0.265151515151515, 0.8900000000000001, 1.0, 1.0, 0.0010294766727702437, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08075577974304975, 0.08075577974304975, 0.178143067681606], 
reward next is 0.8219, 
noisyNet noise sample is [array([0.19206958], dtype=float32), -0.7249175]. 
=============================================
[2019-03-22 23:53:03,990] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:53:03,990] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:53:04,045] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run5
[2019-03-22 23:53:04,115] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:53:04,124] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4902
[2019-03-22 23:53:04,131] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 75.5, 1.0, 2.0, 0.3139364942141804, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 344346.3121472817, 344346.3121472817, 113367.0955649175], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7883400.0000, 
sim time next is 7884000.0000, 
raw observation next is [19.4, 76.0, 1.0, 2.0, 0.3151232930001099, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 346049.1007995286, 346049.1007995283, 113600.9403405605], 
processed observation next is [1.0, 0.2608695652173913, 0.5181818181818181, 0.76, 1.0, 1.0, 0.14390411625013733, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12816633362945504, 0.12816633362945493, 0.2770754642452695], 
reward next is 0.7229, 
noisyNet noise sample is [array([0.18953021], dtype=float32), -1.4207525]. 
=============================================
[2019-03-22 23:53:04,145] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[73.82487 ]
 [73.821144]
 [73.8013  ]
 [73.79831 ]
 [73.75326 ]], R is [[73.81124115]
 [73.79662323]
 [73.78274536]
 [73.76947021]
 [73.75643921]].
[2019-03-22 23:53:04,681] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:53:04,682] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:53:04,715] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run5
[2019-03-22 23:53:07,660] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:53:07,661] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:53:07,699] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run5
[2019-03-22 23:53:08,027] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:53:08,028] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:53:08,041] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run5
[2019-03-22 23:53:08,388] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:53:08,389] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:53:08,412] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run5
[2019-03-22 23:53:08,489] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:53:08,490] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:53:08,510] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run5
[2019-03-22 23:53:08,593] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:53:08,593] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:53:08,604] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run5
[2019-03-22 23:53:08,740] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:53:08,741] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:53:08,754] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run5
[2019-03-22 23:53:08,846] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:53:08,847] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:53:08,854] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run5
[2019-03-22 23:53:08,988] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:53:08,989] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:53:08,997] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:53:08,998] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:53:08,999] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run5
[2019-03-22 23:53:09,017] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:53:09,019] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:53:09,028] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run5
[2019-03-22 23:53:09,045] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:53:09,046] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:53:09,046] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run5
[2019-03-22 23:53:09,050] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:53:09,046] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:53:09,053] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run5
[2019-03-22 23:53:09,076] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run5
[2019-03-22 23:53:09,669] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-22 23:53:09,674] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-22 23:53:09,675] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:53:09,676] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run35
[2019-03-22 23:53:09,695] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-22 23:53:09,696] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:53:09,697] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run35
[2019-03-22 23:53:09,722] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-22 23:53:09,723] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:53:09,724] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-22 23:53:09,725] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:53:09,726] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run35
[2019-03-22 23:53:09,743] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-22 23:53:09,744] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:53:09,745] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run35
[2019-03-22 23:53:09,822] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run35
[2019-03-22 23:53:23,043] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.03660117], dtype=float32), -0.042737916]
[2019-03-22 23:53:23,044] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.48333333333333, 42.5, 1.0, 2.0, 0.3948404320536469, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 445488.9129230489, 445488.9129230485, 129015.289528677]
[2019-03-22 23:53:23,045] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:53:23,048] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.8815578447187657
[2019-03-22 23:53:23,387] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.03660117], dtype=float32), -0.042737916]
[2019-03-22 23:53:23,388] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.2, 64.0, 1.0, 2.0, 0.3652719402805684, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 407622.5795366474, 407622.5795366471, 124186.7867109967]
[2019-03-22 23:53:23,390] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:53:23,392] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.9375221710117936
[2019-03-22 23:53:45,940] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.03660117], dtype=float32), -0.042737916]
[2019-03-22 23:53:45,941] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.66666666666667, 61.33333333333334, 1.0, 2.0, 0.2722952579524694, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 295663.2837960519, 295663.2837960519, 93969.29366637472]
[2019-03-22 23:53:45,942] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:53:45,945] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.3317753374229727
[2019-03-22 23:54:22,010] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.03660117], dtype=float32), -0.042737916]
[2019-03-22 23:54:22,011] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.0, 94.0, 1.0, 2.0, 0.8650348871531187, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 986667.3008319283, 986667.3008319283, 195154.2851728709]
[2019-03-22 23:54:22,013] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:54:22,017] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 2.2342855e-36 5.3931440e-35 6.5408211e-31], sampled 0.12265260783116683
[2019-03-22 23:54:24,788] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.03660117], dtype=float32), -0.042737916]
[2019-03-22 23:54:24,789] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.9, 71.0, 1.0, 2.0, 0.3856943682009786, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 434046.127764455, 434046.127764455, 127592.1925211134]
[2019-03-22 23:54:24,791] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:54:24,794] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.5451713784440103
[2019-03-22 23:54:35,109] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.03660117], dtype=float32), -0.042737916]
[2019-03-22 23:54:35,110] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.78333333333333, 86.16666666666667, 1.0, 2.0, 0.4038463609519071, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 458129.5891245663, 458129.5891245659, 131388.2569854233]
[2019-03-22 23:54:35,111] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:54:35,114] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.7827877612538381
[2019-03-22 23:54:57,644] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9309 1705967916.6745 465.0000
[2019-03-22 23:54:57,757] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-22 23:54:57,885] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1148 1656229146.4555 80.0000
[2019-03-22 23:54:57,915] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5599 1663815647.6096 105.0000
[2019-03-22 23:54:57,980] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-22 23:54:58,995] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 850000, evaluation results [850000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.114827412715, 1656229146.4555063, 80.0, 8856.559925897878, 1663815647.6095803, 105.0, 8596.930884973775, 1705967916.6744611, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-22 23:55:06,311] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:55:06,320] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0941
[2019-03-22 23:55:06,327] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.5, 74.5, 1.0, 2.0, 0.2256779712720656, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 245032.6110658438, 245032.6110658441, 75766.57837474128], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 167400.0000, 
sim time next is 168000.0000, 
raw observation next is [15.33333333333333, 75.33333333333333, 1.0, 2.0, 0.2238209589298302, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 243015.833551317, 243015.833551317, 75388.60300259451], 
processed observation next is [1.0, 0.9565217391304348, 0.3333333333333332, 0.7533333333333333, 1.0, 1.0, 0.029776198662287735, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09000586427826555, 0.09000586427826555, 0.1838746414697427], 
reward next is 0.8161, 
noisyNet noise sample is [array([1.1848669], dtype=float32), -0.013178071]. 
=============================================
[2019-03-22 23:55:06,340] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[80.66186 ]
 [80.678986]
 [80.681335]
 [80.69404 ]
 [80.67649 ]], R is [[80.64997101]
 [80.65867615]
 [80.66629791]
 [80.67277527]
 [80.67816162]].
[2019-03-22 23:55:09,545] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 9.193815e-33 0.000000e+00 7.883876e-37], sum to 1.0000
[2019-03-22 23:55:09,555] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5419
[2019-03-22 23:55:09,560] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.83333333333334, 83.00000000000001, 1.0, 2.0, 0.2699893623549307, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 293158.7445951381, 293158.7445951384, 94393.69028527121], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 609000.0000, 
sim time next is 609600.0000, 
raw observation next is [16.66666666666667, 84.0, 1.0, 2.0, 0.2685948626334028, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 291644.1206068355, 291644.1206068358, 93632.45578171941], 
processed observation next is [1.0, 0.043478260869565216, 0.39393939393939414, 0.84, 1.0, 1.0, 0.08574357829175351, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10801634096549464, 0.10801634096549474, 0.22837184337004734], 
reward next is 0.7716, 
noisyNet noise sample is [array([0.5639541], dtype=float32), -0.9041499]. 
=============================================
[2019-03-22 23:55:13,083] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:55:13,091] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4269
[2019-03-22 23:55:13,098] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.33333333333333, 90.0, 1.0, 2.0, 0.2011668168460657, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 218413.3507778091, 218413.3507778091, 74934.44187954202], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 423600.0000, 
sim time next is 424200.0000, 
raw observation next is [14.16666666666667, 92.0, 1.0, 2.0, 0.2041997106052938, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 221707.0125621005, 221707.0125621002, 75397.84862086344], 
processed observation next is [1.0, 0.9130434782608695, 0.28030303030303044, 0.92, 1.0, 1.0, 0.005249638256617228, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08211370835633353, 0.0821137083563334, 0.18389719175820352], 
reward next is 0.8161, 
noisyNet noise sample is [array([0.43149933], dtype=float32), 0.0023020892]. 
=============================================
[2019-03-22 23:55:13,156] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:55:13,167] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7181
[2019-03-22 23:55:13,171] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.0, 94.0, 1.0, 2.0, 0.2463069781024801, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 267436.9649127378, 267436.9649127378, 85732.40060586583], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 252000.0000, 
sim time next is 252600.0000, 
raw observation next is [15.0, 94.00000000000001, 1.0, 2.0, 0.2437072559932109, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 264613.4520316194, 264613.4520316191, 85422.90767882968], 
processed observation next is [0.0, 0.9565217391304348, 0.3181818181818182, 0.9400000000000002, 1.0, 1.0, 0.054634069991513594, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0980049822339331, 0.098004982233933, 0.20834855531421873], 
reward next is 0.7917, 
noisyNet noise sample is [array([0.27261433], dtype=float32), -1.1427792]. 
=============================================
[2019-03-22 23:55:15,006] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:55:15,018] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8059
[2019-03-22 23:55:15,022] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.83333333333333, 95.0, 1.0, 2.0, 0.2269581269975035, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 246422.907870062, 246422.9078700623, 83007.64098141323], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 287400.0000, 
sim time next is 288000.0000, 
raw observation next is [15.0, 94.0, 1.0, 2.0, 0.2284793649009284, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 248075.034067205, 248075.0340672053, 83661.67162527377], 
processed observation next is [0.0, 0.34782608695652173, 0.3181818181818182, 0.94, 1.0, 1.0, 0.03559920612616049, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09187964224711297, 0.09187964224711308, 0.20405285762261893], 
reward next is 0.7959, 
noisyNet noise sample is [array([-0.07632412], dtype=float32), 0.16549516]. 
=============================================
[2019-03-22 23:55:15,030] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[72.41563 ]
 [72.414055]
 [72.406334]
 [72.395706]
 [72.38569 ]], R is [[72.53038788]
 [72.60262299]
 [72.67580414]
 [72.74996185]
 [72.82495117]].
[2019-03-22 23:55:15,905] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:55:15,914] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3035
[2019-03-22 23:55:15,918] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 75.5, 1.0, 2.0, 0.4235049734200075, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 481386.7778962652, 481386.7778962652, 129666.7031989274], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 779400.0000, 
sim time next is 780000.0000, 
raw observation next is [22.33333333333334, 76.33333333333334, 1.0, 2.0, 0.4230024210718045, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 480697.6906396446, 480697.6906396446, 129518.3513997626], 
processed observation next is [0.0, 0.0, 0.6515151515151518, 0.7633333333333334, 1.0, 1.0, 0.2787530263397556, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1780361817183869, 0.1780361817183869, 0.31589841804820146], 
reward next is 0.6841, 
noisyNet noise sample is [array([0.8558804], dtype=float32), 2.2634363]. 
=============================================
[2019-03-22 23:55:15,930] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[90.64469 ]
 [91.06683 ]
 [91.524605]
 [92.19121 ]
 [93.02214 ]], R is [[90.12137604]
 [89.90390015]
 [89.68812561]
 [89.47386932]
 [89.26103973]].
[2019-03-22 23:55:17,889] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:55:17,898] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3130
[2019-03-22 23:55:17,902] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.0, 76.0, 1.0, 2.0, 0.3914037029598057, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 425049.9853888366, 425049.9853888364, 86124.05385047401], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 357600.0000, 
sim time next is 358200.0000, 
raw observation next is [12.0, 76.0, 1.0, 2.0, 0.3908563955191692, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 424455.3702577138, 424455.3702577138, 86054.00842794692], 
processed observation next is [1.0, 0.13043478260869565, 0.18181818181818182, 0.76, 1.0, 1.0, 0.23857049439896144, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15720569268804213, 0.15720569268804213, 0.20988782543401688], 
reward next is 0.7901, 
noisyNet noise sample is [array([0.23515448], dtype=float32), -0.8185829]. 
=============================================
[2019-03-22 23:55:37,360] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:55:37,368] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8492
[2019-03-22 23:55:37,375] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.66666666666667, 74.66666666666667, 1.0, 2.0, 0.3600831026558202, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 402240.5332759476, 402240.5332759476, 119623.6659494875], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 688200.0000, 
sim time next is 688800.0000, 
raw observation next is [20.33333333333334, 76.33333333333334, 1.0, 2.0, 0.3578492893087705, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 399243.5721201141, 399243.5721201141, 119219.4990833936], 
processed observation next is [1.0, 1.0, 0.5606060606060609, 0.7633333333333334, 1.0, 1.0, 0.19731161163596314, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14786798967411635, 0.14786798967411635, 0.29077926605705756], 
reward next is 0.7092, 
noisyNet noise sample is [array([-0.08866471], dtype=float32), -0.3474985]. 
=============================================
[2019-03-22 23:55:37,613] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:55:37,621] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2895
[2019-03-22 23:55:37,627] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.83333333333334, 83.83333333333334, 1.0, 2.0, 0.3430907700542853, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 379844.7589729943, 379844.7589729946, 116808.903981164], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 691800.0000, 
sim time next is 692400.0000, 
raw observation next is [18.66666666666667, 84.66666666666667, 1.0, 2.0, 0.3409301821398987, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 377059.6369506057, 377059.6369506057, 116487.7460345273], 
processed observation next is [1.0, 0.0, 0.4848484848484851, 0.8466666666666667, 1.0, 1.0, 0.17616272767487332, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13965171738911322, 0.13965171738911322, 0.2841164537427495], 
reward next is 0.7159, 
noisyNet noise sample is [array([-1.1372515], dtype=float32), 1.9146079]. 
=============================================
[2019-03-22 23:55:40,994] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.9921285e-33 1.9999905e-29 3.7088470e-25], sum to 1.0000
[2019-03-22 23:55:41,002] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5875
[2019-03-22 23:55:41,007] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 65.0, 1.0, 2.0, 0.4881343267555268, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 556894.8919247905, 556894.8919247901, 140256.09526002], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 907200.0000, 
sim time next is 907800.0000, 
raw observation next is [25.5, 67.16666666666667, 1.0, 2.0, 0.4856384270775086, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 554101.0813451242, 554101.0813451242, 139784.6981616789], 
processed observation next is [0.0, 0.5217391304347826, 0.7954545454545454, 0.6716666666666667, 1.0, 1.0, 0.3570480338468857, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20522262272041636, 0.20522262272041636, 0.34093828819921684], 
reward next is 0.6591, 
noisyNet noise sample is [array([0.46272993], dtype=float32), -0.030181866]. 
=============================================
[2019-03-22 23:55:42,945] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:55:42,958] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2028
[2019-03-22 23:55:42,962] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 88.00000000000001, 1.0, 2.0, 0.3986569959993617, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 450470.500832469, 450470.500832469, 125417.1214424027], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 785400.0000, 
sim time next is 786000.0000, 
raw observation next is [20.0, 88.0, 1.0, 2.0, 0.3980543219520277, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 449777.8037989632, 449777.8037989632, 125355.3590414407], 
processed observation next is [0.0, 0.08695652173913043, 0.5454545454545454, 0.88, 1.0, 1.0, 0.24756790244003463, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16658437177739377, 0.16658437177739377, 0.30574477814985535], 
reward next is 0.6943, 
noisyNet noise sample is [array([0.33416456], dtype=float32), -0.33841825]. 
=============================================
[2019-03-22 23:55:42,979] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[69.726395]
 [69.81817 ]
 [69.867004]
 [69.86859 ]
 [69.839005]], R is [[69.53314209]
 [69.53192139]
 [69.53005981]
 [69.5265274 ]
 [69.52136993]].
[2019-03-22 23:55:43,681] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:55:43,693] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8057
[2019-03-22 23:55:43,699] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 55.0, 1.0, 2.0, 0.531194505350845, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 604198.2683923801, 604198.2683923803, 147286.7435828523], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 835800.0000, 
sim time next is 836400.0000, 
raw observation next is [29.0, 55.0, 1.0, 2.0, 0.5298450363106281, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 602663.7507349009, 602663.7507349009, 147118.3968395567], 
processed observation next is [0.0, 0.6956521739130435, 0.9545454545454546, 0.55, 1.0, 1.0, 0.41230629538828506, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22320879656848183, 0.22320879656848183, 0.35882535814526023], 
reward next is 0.6412, 
noisyNet noise sample is [array([-0.8541857], dtype=float32), -2.1591344]. 
=============================================
[2019-03-22 23:55:45,164] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:55:45,176] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1102
[2019-03-22 23:55:45,180] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.16666666666667, 87.16666666666667, 1.0, 2.0, 0.4076093213860184, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 460796.874983707, 460796.8749837073, 126362.7373423741], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 861000.0000, 
sim time next is 861600.0000, 
raw observation next is [20.33333333333334, 86.33333333333334, 1.0, 2.0, 0.4074473655745044, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 460845.7517401295, 460845.7517401298, 126487.5470642552], 
processed observation next is [0.0, 1.0, 0.5606060606060609, 0.8633333333333334, 1.0, 1.0, 0.2593092069681305, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1706836117556035, 0.17068361175560362, 0.30850621235184195], 
reward next is 0.6915, 
noisyNet noise sample is [array([-0.9956252], dtype=float32), 0.2201377]. 
=============================================
[2019-03-22 23:55:46,638] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:55:46,650] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5355
[2019-03-22 23:55:46,657] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 94.0, 1.0, 2.0, 0.41987497021637, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 476957.1112210065, 476957.1112210065, 129061.6418138541], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1321200.0000, 
sim time next is 1321800.0000, 
raw observation next is [20.33333333333334, 94.00000000000001, 1.0, 2.0, 0.4480783693847389, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 509752.1005246878, 509752.1005246875, 132497.9028448156], 
processed observation next is [1.0, 0.30434782608695654, 0.5606060606060609, 0.9400000000000002, 1.0, 1.0, 0.3100979617309236, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1887970742684029, 0.18879707426840278, 0.3231656166946722], 
reward next is 0.6768, 
noisyNet noise sample is [array([-1.040003], dtype=float32), -0.67312026]. 
=============================================
[2019-03-22 23:55:51,542] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-22 23:55:51,544] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-22 23:55:51,544] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:55:51,546] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-22 23:55:51,549] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:55:51,550] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-22 23:55:51,552] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-22 23:55:51,554] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:55:51,555] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:55:51,552] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-22 23:55:51,557] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:55:51,569] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run36
[2019-03-22 23:55:51,591] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run36
[2019-03-22 23:55:51,593] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run36
[2019-03-22 23:55:51,611] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run36
[2019-03-22 23:55:51,655] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run36
[2019-03-22 23:55:56,559] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.28617972], dtype=float32), 0.031024802]
[2019-03-22 23:55:56,562] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.66666666666667, 44.5, 1.0, 2.0, 0.2428107824801744, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 263639.8115714522, 263639.8115714525, 77047.3411479671]
[2019-03-22 23:55:56,565] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:55:56,571] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.6901221370752673
[2019-03-22 23:56:00,486] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.28617972], dtype=float32), 0.031024802]
[2019-03-22 23:56:00,488] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.76768779, 69.79145202999999, 1.0, 2.0, 0.3932264669581655, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 436444.1581301268, 436444.1581301264, 125551.7064330988]
[2019-03-22 23:56:00,489] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:56:00,492] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.6859934895267925
[2019-03-22 23:56:01,951] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.28617972], dtype=float32), 0.031024802]
[2019-03-22 23:56:01,952] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [24.47021263666667, 61.21201806666667, 1.0, 2.0, 0.4238877272600762, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 480881.0828924395, 480881.0828924392, 133311.9500956451]
[2019-03-22 23:56:01,955] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:56:01,957] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.6515568901879054
[2019-03-22 23:56:27,036] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.28617972], dtype=float32), 0.031024802]
[2019-03-22 23:56:27,038] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.31666666666667, 78.5, 1.0, 2.0, 0.4794043650970952, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 546941.1090636455, 546941.1090636455, 142469.7509944109]
[2019-03-22 23:56:27,039] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:56:27,041] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.026401246200572825
[2019-03-22 23:56:27,632] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.28617972], dtype=float32), 0.031024802]
[2019-03-22 23:56:27,633] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.4, 82.0, 1.0, 2.0, 0.3522753489609249, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 392063.5171252995, 392063.5171252993, 118355.4410452336]
[2019-03-22 23:56:27,634] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:56:27,637] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.15229251932732701
[2019-03-22 23:56:59,325] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.28617972], dtype=float32), 0.031024802]
[2019-03-22 23:56:59,326] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.4, 51.33333333333333, 1.0, 2.0, 0.2849507405916038, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 309390.4440358506, 309390.4440358503, 100568.7876369121]
[2019-03-22 23:56:59,328] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:56:59,331] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.4377121834925223
[2019-03-22 23:57:01,523] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.28617972], dtype=float32), 0.031024802]
[2019-03-22 23:57:01,523] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [25.06563587666667, 56.66476692000001, 1.0, 2.0, 0.5968274907638561, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 676630.3563285196, 676630.3563285196, 151785.6880769579]
[2019-03-22 23:57:01,524] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:57:01,528] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.6924068812957527
[2019-03-22 23:57:13,611] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.28617972], dtype=float32), 0.031024802]
[2019-03-22 23:57:13,612] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [26.31600992333333, 72.04154212, 1.0, 2.0, 0.5347166796747116, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 606924.2254746928, 606924.2254746924, 152660.9454988916]
[2019-03-22 23:57:13,614] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:57:13,617] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.8966051304605333
[2019-03-22 23:57:20,300] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.28617972], dtype=float32), 0.031024802]
[2019-03-22 23:57:20,302] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.90398016333333, 78.27129496166667, 1.0, 2.0, 0.580736233592337, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 662505.1926775912, 662505.1926775909, 154086.9141744304]
[2019-03-22 23:57:20,303] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:57:20,305] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.4955532955315215
[2019-03-22 23:57:25,705] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.28617972], dtype=float32), 0.031024802]
[2019-03-22 23:57:25,707] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [14.0, 81.66666666666667, 1.0, 2.0, 0.2036498208738833, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 221109.8416890171, 221109.8416890168, 71891.3873732303]
[2019-03-22 23:57:25,708] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:57:25,709] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.9081729368727278
[2019-03-22 23:57:28,644] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.28617972], dtype=float32), 0.031024802]
[2019-03-22 23:57:28,647] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.06815658333333, 85.90507715000001, 1.0, 2.0, 0.4397140028163821, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 501310.333806242, 501310.3338062417, 137321.6308016318]
[2019-03-22 23:57:28,648] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:57:28,650] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.09642146758872938
[2019-03-22 23:57:34,010] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-22 23:57:34,303] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-22 23:57:34,343] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5599 1663815647.6096 105.0000
[2019-03-22 23:57:34,407] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3485 1683325900.1134 214.0000
[2019-03-22 23:57:34,508] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-22 23:57:35,524] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 875000, evaluation results [875000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8856.559925897878, 1663815647.6095803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8574.348472942609, 1683325900.1133502, 214.0]
[2019-03-22 23:57:42,701] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:57:42,715] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1148
[2019-03-22 23:57:42,723] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 68.0, 1.0, 2.0, 0.5352648060348963, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 584083.2482022295, 584083.2482022295, 130943.3937046399], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1076400.0000, 
sim time next is 1077000.0000, 
raw observation next is [20.16666666666667, 67.33333333333334, 1.0, 2.0, 0.5077212812016749, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 554917.679269824, 554917.679269824, 128648.111976205], 
processed observation next is [1.0, 0.4782608695652174, 0.5530303030303032, 0.6733333333333335, 1.0, 1.0, 0.3846516015020936, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20552506639623108, 0.20552506639623108, 0.31377588286879265], 
reward next is 0.6862, 
noisyNet noise sample is [array([-0.35632882], dtype=float32), 0.19239306]. 
=============================================
[2019-03-22 23:57:42,732] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[64.06165]
 [64.05118]
 [63.78925]
 [63.48183]
 [63.27471]], R is [[64.3860321 ]
 [64.42279816]
 [64.46762085]
 [64.51070404]
 [64.54858398]].
[2019-03-22 23:57:48,855] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:57:48,865] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8552
[2019-03-22 23:57:48,871] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.4099865123135145, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 464760.4840604985, 464760.4840604988, 127395.7751818506], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1225800.0000, 
sim time next is 1226400.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4091689747754452, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 463831.2561950829, 463831.2561950831, 127317.0055032597], 
processed observation next is [1.0, 0.17391304347826086, 0.5, 1.0, 1.0, 1.0, 0.2614612184693065, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.171789354146327, 0.17178935414632707, 0.31052928171526756], 
reward next is 0.6895, 
noisyNet noise sample is [array([-1.8774903], dtype=float32), -0.3984167]. 
=============================================
[2019-03-22 23:57:50,534] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.1299028e-37 1.0532412e-30 6.1255307e-38], sum to 1.0000
[2019-03-22 23:57:50,541] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0528
[2019-03-22 23:57:50,547] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.5, 88.5, 1.0, 2.0, 0.4726254261312315, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 539054.171994824, 539054.1719948243, 136791.0029858685], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1215000.0000, 
sim time next is 1215600.0000, 
raw observation next is [20.66666666666666, 90.33333333333334, 1.0, 2.0, 0.4527535463168793, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 515420.719629058, 515420.719629058, 133318.3911050434], 
processed observation next is [1.0, 0.043478260869565216, 0.5757575757575755, 0.9033333333333334, 1.0, 1.0, 0.3159419328960991, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19089656282557702, 0.19089656282557702, 0.3251668075732766], 
reward next is 0.6748, 
noisyNet noise sample is [array([0.41507447], dtype=float32), -1.9164604]. 
=============================================
[2019-03-22 23:57:50,748] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.6274217e-35 3.3062554e-37], sum to 1.0000
[2019-03-22 23:57:50,759] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3365
[2019-03-22 23:57:50,765] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.4360682108899899, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 494360.4383644059, 494360.4383644059, 129925.0117971821], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1221000.0000, 
sim time next is 1221600.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4125276860313772, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 467658.9076647232, 467658.9076647229, 127648.0980897031], 
processed observation next is [1.0, 0.13043478260869565, 0.5, 1.0, 1.0, 1.0, 0.26565960753922147, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17320700283878637, 0.17320700283878626, 0.31133682460903195], 
reward next is 0.6887, 
noisyNet noise sample is [array([0.50034463], dtype=float32), -0.21726543]. 
=============================================
[2019-03-22 23:57:51,796] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 8.9636501e-35 8.1101446e-32 1.8004206e-30], sum to 1.0000
[2019-03-22 23:57:51,807] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4721
[2019-03-22 23:57:51,811] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.7468624646131665, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 851888.2817081978, 851888.2817081978, 175685.3793948263], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1239600.0000, 
sim time next is 1240200.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.8664473313985614, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 988316.718605617, 988316.7186056172, 195346.4174840604], 
processed observation next is [1.0, 0.34782608695652173, 0.6363636363636364, 0.94, 1.0, 1.0, 0.8330591642482018, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3660432291131915, 0.36604322911319154, 0.4764546767903912], 
reward next is 0.5235, 
noisyNet noise sample is [array([-0.9657023], dtype=float32), 0.20826383]. 
=============================================
[2019-03-22 23:57:51,937] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.7869147e-37 1.0000000e+00 3.0515166e-30 2.0438585e-16 1.4512911e-19], sum to 1.0000
[2019-03-22 23:57:51,943] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2963
[2019-03-22 23:57:51,948] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.8788403882652275, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1002401.101332834, 1002401.101332834, 197584.1189473901], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1242000.0000, 
sim time next is 1242600.0000, 
raw observation next is [22.33333333333334, 91.33333333333334, 1.0, 2.0, 0.9960317095720309, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.335767632339839, 6.9112, 77.32762103376, 1274175.183528612, 1136285.802626154, 219105.9657126178], 
processed observation next is [1.0, 0.391304347826087, 0.6515151515151518, 0.9133333333333334, 1.0, 1.0, 0.9950396369650385, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.04245676323398388, 0.0, 0.5084232741399013, 0.47191673464022665, 0.4208465935652422, 0.534404794421019], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.1535546], dtype=float32), -0.62244207]. 
=============================================
[2019-03-22 23:57:57,584] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 6.6907591e-28 1.6287375e-21 7.5563535e-22], sum to 1.0000
[2019-03-22 23:57:57,591] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7646
[2019-03-22 23:57:57,597] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 88.0, 1.0, 2.0, 0.4725131786463901, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 539127.2168520706, 539127.2168520706, 137374.6078489301], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1377000.0000, 
sim time next is 1377600.0000, 
raw observation next is [22.0, 88.0, 1.0, 2.0, 0.4723908245916151, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 538987.4454171299, 538987.4454171297, 137360.7091459497], 
processed observation next is [1.0, 0.9565217391304348, 0.6363636363636364, 0.88, 1.0, 1.0, 0.3404885307395188, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1996249797841222, 0.1996249797841221, 0.33502611986817], 
reward next is 0.6650, 
noisyNet noise sample is [array([0.07663823], dtype=float32), 0.06526815]. 
=============================================
[2019-03-22 23:57:58,135] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.00000000e+00 1.00000000e+00 3.84104534e-31 1.22363629e-17
 1.10106164e-16], sum to 1.0000
[2019-03-22 23:57:58,145] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4484
[2019-03-22 23:57:58,152] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1414551.227276963 W.
[2019-03-22 23:57:58,160] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.5, 79.5, 1.0, 2.0, 0.6289596501671024, 1.0, 1.0, 0.6289596501671024, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1414551.227276963, 1414551.227276963, 270287.2278161202], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1348200.0000, 
sim time next is 1348800.0000, 
raw observation next is [26.0, 82.66666666666666, 1.0, 2.0, 0.7059068701574247, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9865530188920543, 6.911199999999999, 6.9112, 77.32846344354104, 1342006.509459971, 1342006.509459972, 300672.6356712496], 
processed observation next is [1.0, 0.6086956521739131, 0.8181818181818182, 0.8266666666666665, 1.0, 1.0, 0.6323835876967809, 0.0, 0.5, -0.25, 1.0, 0.5, 0.9807900269886491, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.4970394479481374, 0.49703944794813776, 0.7333478918810966], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.3650515], dtype=float32), 0.861794]. 
=============================================
[2019-03-22 23:57:59,012] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.3293129e-36 1.0000000e+00 1.4878759e-24 8.5744923e-16 4.7252538e-15], sum to 1.0000
[2019-03-22 23:57:59,020] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2756
[2019-03-22 23:57:59,024] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.5, 91.0, 1.0, 2.0, 0.4384379172198824, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 476152.4194818587, 476152.4194818587, 94518.8340625178], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1837800.0000, 
sim time next is 1838400.0000, 
raw observation next is [13.0, 88.0, 1.0, 2.0, 0.4434670359627658, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 481616.8492606614, 481616.8492606617, 95526.92839380637], 
processed observation next is [1.0, 0.2608695652173913, 0.22727272727272727, 0.88, 1.0, 1.0, 0.30433379495345725, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.178376610837282, 0.1783766108372821, 0.23299250827757653], 
reward next is 0.7670, 
noisyNet noise sample is [array([-0.23281218], dtype=float32), 0.71344334]. 
=============================================
[2019-03-22 23:58:06,630] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 5.0331917e-38 9.3884820e-36 2.3527670e-35], sum to 1.0000
[2019-03-22 23:58:06,640] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7633
[2019-03-22 23:58:06,645] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.5, 52.0, 1.0, 2.0, 0.3681490475738001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 411772.0510112105, 411772.0510112105, 120519.9967915456], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1967400.0000, 
sim time next is 1968000.0000, 
raw observation next is [24.33333333333334, 52.66666666666667, 1.0, 2.0, 0.3651611460312692, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 408254.5140936523, 408254.5140936526, 120192.7794245454], 
processed observation next is [1.0, 0.782608695652174, 0.7424242424242427, 0.5266666666666667, 1.0, 1.0, 0.2064514325390865, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1512053755902416, 0.1512053755902417, 0.29315312054767173], 
reward next is 0.7068, 
noisyNet noise sample is [array([-0.13863094], dtype=float32), 1.9388589]. 
=============================================
[2019-03-22 23:58:06,659] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[64.6181 ]
 [64.51038]
 [64.19547]
 [63.72041]
 [63.17506]], R is [[65.42771149]
 [65.47948456]
 [65.53004456]
 [65.58001709]
 [65.62905121]].
[2019-03-22 23:58:09,251] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:58:09,263] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9731
[2019-03-22 23:58:09,268] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 94.0, 1.0, 2.0, 0.4561006737326888, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 520228.1700588644, 520228.1700588644, 135081.2070962243], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1548000.0000, 
sim time next is 1548600.0000, 
raw observation next is [21.0, 93.00000000000001, 1.0, 2.0, 0.4522942512675315, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 515778.5479736477, 515778.5479736474, 134453.4033167354], 
processed observation next is [0.0, 0.9565217391304348, 0.5909090909090909, 0.9300000000000002, 1.0, 1.0, 0.31536781408441433, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19102909184209174, 0.19102909184209163, 0.3279351300408181], 
reward next is 0.6721, 
noisyNet noise sample is [array([-2.0688012], dtype=float32), -0.25124648]. 
=============================================
[2019-03-22 23:58:12,230] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:58:12,233] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6379
[2019-03-22 23:58:12,238] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 60.0, 1.0, 2.0, 0.2630175866488781, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 285586.4569862969, 285586.4569862972, 86100.89655130086], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2073000.0000, 
sim time next is 2073600.0000, 
raw observation next is [19.0, 60.0, 1.0, 2.0, 0.2620660031506959, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 284552.9182604818, 284552.9182604816, 85997.94488570564], 
processed observation next is [0.0, 0.0, 0.5, 0.6, 1.0, 1.0, 0.07758250393836985, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10538996972610437, 0.1053899697261043, 0.20975108508708692], 
reward next is 0.7902, 
noisyNet noise sample is [array([-0.6651613], dtype=float32), 0.93890256]. 
=============================================
[2019-03-22 23:58:12,284] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 6.2670965e-35 1.6428954e-37 1.7279109e-30], sum to 1.0000
[2019-03-22 23:58:12,289] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6212
[2019-03-22 23:58:12,295] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1106629.443870411 W.
[2019-03-22 23:58:12,302] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.86666666666667, 62.33333333333333, 1.0, 2.0, 0.9705376544959071, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1106629.443870411, 1106629.443870411, 214767.6002404718], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1604400.0000, 
sim time next is 1605000.0000, 
raw observation next is [26.93333333333333, 62.16666666666667, 1.0, 2.0, 0.5165608247894562, 0.0, 2.0, 0.0, 1.0, 1.0, 0.957638695681437, 6.940419449638542, 6.9112, 77.32839133217135, 1136531.306383234, 1127041.435631362, 260928.4454415352], 
processed observation next is [1.0, 0.5652173913043478, 0.8606060606060605, 0.6216666666666667, 1.0, 1.0, 0.3957010309868202, 0.0, 1.0, -0.25, 1.0, 0.5, 0.9394838509734816, 0.002921944963854184, 0.0, 0.508428338793839, 0.4209375208826793, 0.41742275393754147, 0.6364108425403298], 
reward next is 0.2175, 
noisyNet noise sample is [array([-0.68159854], dtype=float32), 1.7540644]. 
=============================================
[2019-03-22 23:58:12,309] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[56.80802 ]
 [57.400833]
 [58.085186]
 [58.274303]
 [57.673225]], R is [[56.34439468]
 [56.25712967]
 [56.19684982]
 [56.17119598]
 [56.18772125]].
[2019-03-22 23:58:17,272] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.5243363e-36 0.0000000e+00 2.5738113e-32], sum to 1.0000
[2019-03-22 23:58:17,281] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9497
[2019-03-22 23:58:17,286] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 54.5, 1.0, 2.0, 0.6321479621177325, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 686674.0396170457, 686674.0396170457, 135603.8489246689], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1697400.0000, 
sim time next is 1698000.0000, 
raw observation next is [21.0, 54.0, 1.0, 2.0, 0.6246369218587067, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 678509.436721098, 678509.436721098, 133981.1564954658], 
processed observation next is [1.0, 0.6521739130434783, 0.5909090909090909, 0.54, 1.0, 1.0, 0.5307961523233833, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2512997913781845, 0.2512997913781845, 0.32678330852552634], 
reward next is 0.6732, 
noisyNet noise sample is [array([-1.1742195], dtype=float32), -1.0903342]. 
=============================================
[2019-03-22 23:58:17,301] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[63.903214]
 [63.8306  ]
 [63.76073 ]
 [63.944176]
 [63.858345]], R is [[64.00114441]
 [64.03039551]
 [64.05479431]
 [64.07242584]
 [64.09522247]].
[2019-03-22 23:58:21,019] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:58:21,027] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7613
[2019-03-22 23:58:21,035] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 53.0, 1.0, 2.0, 0.227627174603489, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 247149.520073736, 247149.520073736, 73143.03669706995], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1804800.0000, 
sim time next is 1805400.0000, 
raw observation next is [17.0, 53.5, 1.0, 2.0, 0.2288781527294273, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 248508.134786957, 248508.1347869573, 73380.79923756095], 
processed observation next is [1.0, 0.9130434782608695, 0.4090909090909091, 0.535, 1.0, 1.0, 0.03609769091178411, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09204004992109519, 0.0920400499210953, 0.1789775591160023], 
reward next is 0.8210, 
noisyNet noise sample is [array([0.30298683], dtype=float32), 0.24181002]. 
=============================================
[2019-03-22 23:58:22,688] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:58:22,695] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9395
[2019-03-22 23:58:22,700] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.1, 44.0, 1.0, 2.0, 0.2677365625702288, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 290711.8876529776, 290711.8876529773, 78314.99297565546], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1791000.0000, 
sim time next is 1791600.0000, 
raw observation next is [19.06666666666667, 44.66666666666666, 1.0, 2.0, 0.2659353480595206, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 288755.5245939007, 288755.5245939007, 78259.3171105027], 
processed observation next is [1.0, 0.7391304347826086, 0.5030303030303032, 0.44666666666666655, 1.0, 1.0, 0.08241918507440077, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10694649059033359, 0.10694649059033359, 0.19087638319634806], 
reward next is 0.8091, 
noisyNet noise sample is [array([0.6488771], dtype=float32), 2.4495428]. 
=============================================
[2019-03-22 23:58:23,590] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.3801584e-35 6.4555789e-37], sum to 1.0000
[2019-03-22 23:58:23,603] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8803
[2019-03-22 23:58:23,611] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1132212.090837824 W.
[2019-03-22 23:58:23,616] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.0, 57.0, 1.0, 2.0, 0.330654835594847, 1.0, 1.0, 0.330654835594847, 1.0, 2.0, 0.6650377582476604, 6.911199999999999, 6.9112, 77.3421103, 1132212.090837824, 1132212.090837825, 261710.9902975857], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1962000.0000, 
sim time next is 1962600.0000, 
raw observation next is [25.0, 55.83333333333333, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3903241718930743, 6.911199999999999, 6.9112, 77.3421103, 665453.338961521, 665453.3389615213, 218380.6452728368], 
processed observation next is [1.0, 0.7391304347826086, 0.7727272727272727, 0.5583333333333332, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.12903453127582043, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.24646419961537816, 0.24646419961537824, 0.5326357201776507], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.91145194], dtype=float32), 0.19988692]. 
=============================================
[2019-03-22 23:58:27,335] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-22 23:58:27,338] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-22 23:58:27,338] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-22 23:58:27,340] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:58:27,340] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-22 23:58:27,342] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:58:27,342] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-22 23:58:27,345] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:58:27,343] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-22 23:58:27,348] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:58:27,350] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:58:27,367] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run37
[2019-03-22 23:58:27,367] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run37
[2019-03-22 23:58:27,367] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run37
[2019-03-22 23:58:27,430] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run37
[2019-03-22 23:58:27,430] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run37
[2019-03-22 23:58:50,509] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.27811432], dtype=float32), 0.039801925]
[2019-03-22 23:58:50,509] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [27.541248705, 65.25502589833334, 1.0, 2.0, 0.8337494220988251, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 944520.5300154244, 944520.5300154244, 198028.7297129164]
[2019-03-22 23:58:50,511] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:58:50,515] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 4.6770978e-32 1.8437456e-34 9.0148195e-26], sampled 0.8958556162169411
[2019-03-22 23:58:51,696] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.27811432], dtype=float32), 0.039801925]
[2019-03-22 23:58:51,697] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.4, 64.0, 1.0, 2.0, 0.5587578680199821, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 608197.7997584784, 608197.7997584784, 132740.0796030096]
[2019-03-22 23:58:51,698] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:58:51,701] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 6.9031639e-38 0.0000000e+00 1.7114607e-35], sampled 0.26417456094215586
[2019-03-22 23:59:04,273] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.27811432], dtype=float32), 0.039801925]
[2019-03-22 23:59:04,274] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.031095855, 77.02633681, 1.0, 2.0, 0.3269070352443058, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 358304.057625012, 358304.0576250124, 118511.0242924165]
[2019-03-22 23:59:04,275] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:59:04,278] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.08090740409749153
[2019-03-22 23:59:23,126] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.27811432], dtype=float32), 0.039801925]
[2019-03-22 23:59:23,127] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [26.96666666666667, 58.66666666666667, 1.0, 2.0, 0.7678257387371034, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 876226.1276259014, 876226.127625901, 181990.0547235561]
[2019-03-22 23:59:23,129] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:59:23,131] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0.0000000e+00 1.0000000e+00 3.2509548e-35 3.1249070e-37 4.9135105e-28], sampled 0.16398597671249604
[2019-03-22 23:59:48,980] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.27811432], dtype=float32), 0.039801925]
[2019-03-22 23:59:48,980] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.09741957, 56.22707721, 1.0, 2.0, 0.2967401170010593, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 322194.4048422927, 322194.4048422927, 108543.6214429581]
[2019-03-22 23:59:48,982] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:59:48,986] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.5336422749167781
[2019-03-22 23:59:55,640] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.27811432], dtype=float32), 0.039801925]
[2019-03-22 23:59:55,643] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.6, 74.5, 1.0, 2.0, 0.4233681712373819, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 481035.22631694, 481035.22631694, 133833.3930813475]
[2019-03-22 23:59:55,644] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:59:55,646] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.6197180101566986
[2019-03-23 00:00:07,627] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.27811432], dtype=float32), 0.039801925]
[2019-03-23 00:00:07,631] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.41924973166667, 46.19822782333333, 1.0, 2.0, 0.3124461531022806, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 339252.5137571549, 339252.5137571549, 103911.4754232367]
[2019-03-23 00:00:07,633] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 00:00:07,636] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.5662272089513523
[2019-03-23 00:00:15,173] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9309 1705967916.6745 465.0000
[2019-03-23 00:00:15,803] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 00:00:16,147] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2492 1773187030.7201 173.0000
[2019-03-23 00:00:16,166] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 00:00:16,369] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5598 1663796639.0689 105.0000
[2019-03-23 00:00:17,385] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 900000, evaluation results [900000.0, 8512.249193409023, 1773187030.7201214, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8856.559759326878, 1663796639.0688558, 105.0, 8596.930884973775, 1705967916.6744611, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 00:00:21,385] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 4.7650028e-38 0.0000000e+00 1.9929143e-30], sum to 1.0000
[2019-03-23 00:00:21,392] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2082
[2019-03-23 00:00:21,396] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.91666666666667, 52.33333333333334, 1.0, 2.0, 0.3622544917487403, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 406934.1289469494, 406934.1289469497, 120871.9247336197], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2119800.0000, 
sim time next is 2120400.0000, 
raw observation next is [25.1, 52.0, 1.0, 2.0, 0.3657485028920236, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 411323.713325369, 411323.713325369, 121401.5683932003], 
processed observation next is [0.0, 0.5652173913043478, 0.7772727272727273, 0.52, 1.0, 1.0, 0.20718562861502948, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15234211604643297, 0.15234211604643297, 0.29610138632487876], 
reward next is 0.7039, 
noisyNet noise sample is [array([0.7242206], dtype=float32), -1.5770655]. 
=============================================
[2019-03-23 00:00:26,148] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.2745732e-29], sum to 1.0000
[2019-03-23 00:00:26,149] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2950
[2019-03-23 00:00:26,197] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.46666666666667, 52.0, 1.0, 2.0, 0.2989033880609099, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 324564.5301464162, 324564.530146416, 99710.21119717359], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2058000.0000, 
sim time next is 2058600.0000, 
raw observation next is [21.23333333333333, 52.5, 1.0, 2.0, 0.2952254124686775, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 320569.4805029693, 320569.480502969, 97706.48345740304], 
processed observation next is [0.0, 0.8260869565217391, 0.6015151515151514, 0.525, 1.0, 1.0, 0.11903176558584687, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11872943722332197, 0.11872943722332185, 0.2383084962375684], 
reward next is 0.7617, 
noisyNet noise sample is [array([-0.80571675], dtype=float32), -0.17528288]. 
=============================================
[2019-03-23 00:00:30,813] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.1395927e-33 1.6408491e-20 1.6927678e-27], sum to 1.0000
[2019-03-23 00:00:30,823] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8002
[2019-03-23 00:00:30,827] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 49.0, 1.0, 2.0, 0.4650070331718907, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 505022.002964083, 505022.002964083, 103737.6719687098], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2294400.0000, 
sim time next is 2295000.0000, 
raw observation next is [20.0, 49.0, 1.0, 2.0, 0.4948099645601208, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 537407.439777597, 537407.4397775967, 107234.946901141], 
processed observation next is [1.0, 0.5652173913043478, 0.5454545454545454, 0.49, 1.0, 1.0, 0.36851245570015095, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1990397925102211, 0.19903979251022103, 0.2615486509783927], 
reward next is 0.7385, 
noisyNet noise sample is [array([-0.79081184], dtype=float32), 2.044588]. 
=============================================
[2019-03-23 00:00:30,838] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[64.928246]
 [65.2798  ]
 [65.30147 ]
 [65.5895  ]
 [65.43786 ]], R is [[64.75015259]
 [64.84963226]
 [64.96125793]
 [65.07283783]
 [65.1998291 ]].
[2019-03-23 00:00:42,026] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:00:42,037] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5629
[2019-03-23 00:00:42,042] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.16666666666667, 75.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 215276.7118204366, 215276.7118204366, 70261.29068350175], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2339400.0000, 
sim time next is 2340000.0000, 
raw observation next is [14.0, 77.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 213660.4955176907, 213660.495517691, 70021.81739961472], 
processed observation next is [1.0, 0.08695652173913043, 0.2727272727272727, 0.77, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07913351685840396, 0.07913351685840407, 0.17078492048686517], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.16561142], dtype=float32), 0.2452908]. 
=============================================
[2019-03-23 00:00:42,061] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[79.03503]
 [79.18934]
 [79.31152]
 [79.40517]
 [79.47867]], R is [[78.12866974]
 [77.34738159]
 [76.57390594]
 [76.63574982]
 [76.69659424]].
[2019-03-23 00:00:46,731] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:00:46,739] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9509
[2019-03-23 00:00:46,743] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 93.00000000000001, 1.0, 2.0, 0.222592565278794, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 241681.7615560542, 241681.7615560539, 77139.50474541729], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2423400.0000, 
sim time next is 2424000.0000, 
raw observation next is [14.0, 92.0, 1.0, 2.0, 0.2193408980886541, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 238150.3720574715, 238150.3720574718, 76426.80978017775], 
processed observation next is [1.0, 0.043478260869565216, 0.2727272727272727, 0.92, 1.0, 1.0, 0.0241761226108176, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08820384150276722, 0.08820384150276733, 0.18640685312238475], 
reward next is 0.8136, 
noisyNet noise sample is [array([0.05359735], dtype=float32), -0.85487485]. 
=============================================
[2019-03-23 00:00:46,754] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[77.994896]
 [78.29252 ]
 [78.491425]
 [78.74901 ]
 [79.02358 ]], R is [[77.8505249 ]
 [77.88387299]
 [77.91513062]
 [77.9440155 ]
 [77.9706192 ]].
[2019-03-23 00:00:48,121] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:00:48,136] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4030
[2019-03-23 00:00:48,141] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.0, 90.0, 1.0, 2.0, 0.3729120936565895, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 404960.4170021755, 404960.4170021758, 96078.7219492847], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2449200.0000, 
sim time next is 2449800.0000, 
raw observation next is [15.0, 91.0, 1.0, 2.0, 0.4141449191381268, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 449757.5301746753, 449757.5301746753, 101329.3303649206], 
processed observation next is [1.0, 0.34782608695652173, 0.3181818181818182, 0.91, 1.0, 1.0, 0.26768114892265843, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1665768630276575, 0.1665768630276575, 0.24714470820712342], 
reward next is 0.7529, 
noisyNet noise sample is [array([0.14969863], dtype=float32), 0.7606457]. 
=============================================
[2019-03-23 00:00:49,693] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 4.3336220e-38 0.0000000e+00 7.8404734e-38], sum to 1.0000
[2019-03-23 00:00:49,702] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9283
[2019-03-23 00:00:49,707] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 75.66666666666667, 1.0, 2.0, 0.5449265319071951, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 591871.6099955554, 591871.6099955556, 125980.0008344665], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2467200.0000, 
sim time next is 2467800.0000, 
raw observation next is [18.0, 75.0, 1.0, 2.0, 0.613426190913632, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 666323.4749055696, 666323.4749055699, 133077.4177067456], 
processed observation next is [1.0, 0.5652173913043478, 0.45454545454545453, 0.75, 1.0, 1.0, 0.51678273864204, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.246786472187248, 0.2467864721872481, 0.32457906757742827], 
reward next is 0.6754, 
noisyNet noise sample is [array([-0.32436365], dtype=float32), -2.6907442]. 
=============================================
[2019-03-23 00:00:49,713] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.7886307e-32 1.9445967e-37 4.3433767e-35], sum to 1.0000
[2019-03-23 00:00:49,723] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4212
[2019-03-23 00:00:49,728] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 73.66666666666667, 1.0, 2.0, 0.6043450257388427, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 656452.5555839988, 656452.5555839984, 130634.0619787425], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2469000.0000, 
sim time next is 2469600.0000, 
raw observation next is [18.0, 73.0, 1.0, 2.0, 0.6123071370490724, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 665107.09038206, 665107.09038206, 130764.46486008], 
processed observation next is [1.0, 0.6086956521739131, 0.45454545454545453, 0.73, 1.0, 1.0, 0.5153839213113404, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.24633595940076297, 0.24633595940076297, 0.31893771917092684], 
reward next is 0.6811, 
noisyNet noise sample is [array([0.585539], dtype=float32), 0.0194396]. 
=============================================
[2019-03-23 00:00:50,632] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:00:50,639] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2807
[2019-03-23 00:00:50,646] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.0, 94.0, 1.0, 2.0, 0.2816138102885158, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 305784.7232077667, 305784.723207767, 89727.14862047588], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2485800.0000, 
sim time next is 2486400.0000, 
raw observation next is [14.66666666666667, 94.0, 1.0, 2.0, 0.2739100969535493, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 297417.2423416916, 297417.2423416916, 86558.18688821569], 
processed observation next is [1.0, 0.782608695652174, 0.30303030303030315, 0.94, 1.0, 1.0, 0.0923876211919366, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11015453420062653, 0.11015453420062653, 0.211117528995648], 
reward next is 0.7889, 
noisyNet noise sample is [array([-0.39530206], dtype=float32), 0.39713904]. 
=============================================
[2019-03-23 00:00:51,257] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:00:51,266] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:00:51,268] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0786
[2019-03-23 00:00:51,274] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.2129305200287874, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 231188.620975836, 231188.6209758357, 74984.5745007623], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2505600.0000, 
sim time next is 2506200.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.2116243851471648, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 229770.1543101279, 229770.1543101282, 74854.19923879036], 
processed observation next is [1.0, 0.0, 0.22727272727272727, 1.0, 1.0, 1.0, 0.014530481433955994, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08510005715189922, 0.08510005715189933, 0.18257121765558623], 
reward next is 0.8174, 
noisyNet noise sample is [array([-0.23720261], dtype=float32), 0.3475128]. 
=============================================
[2019-03-23 00:00:51,278] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2888
[2019-03-23 00:00:51,285] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 97.0, 1.0, 2.0, 0.2066950632205906, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 224416.9321707518, 224416.9321707515, 73493.93151235975], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2500200.0000, 
sim time next is 2500800.0000, 
raw observation next is [13.0, 98.0, 1.0, 2.0, 0.206761995939943, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 224489.620417834, 224489.6204178337, 73771.44702927579], 
processed observation next is [1.0, 0.9565217391304348, 0.22727272727272727, 0.98, 1.0, 1.0, 0.008452494924928722, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08314430385845703, 0.08314430385845693, 0.17993035860798973], 
reward next is 0.8201, 
noisyNet noise sample is [array([0.14967434], dtype=float32), -0.3815895]. 
=============================================
[2019-03-23 00:01:00,698] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.9577915e-38 1.0000000e+00 3.0358035e-25 2.4765455e-29 7.3470460e-20], sum to 1.0000
[2019-03-23 00:01:00,709] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8334
[2019-03-23 00:01:00,716] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333334, 69.0, 1.0, 2.0, 0.8588592760189916, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 977828.1326517614, 977828.1326517614, 186672.0098526246], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3064800.0000, 
sim time next is 3065400.0000, 
raw observation next is [23.5, 69.0, 1.0, 2.0, 0.8901198059496782, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1013164.216727191, 1013164.216727191, 191469.2428253769], 
processed observation next is [1.0, 0.4782608695652174, 0.7045454545454546, 0.69, 1.0, 1.0, 0.8626497574370978, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.37524600619525594, 0.37524600619525594, 0.46699815323262656], 
reward next is 0.5330, 
noisyNet noise sample is [array([-1.4142256], dtype=float32), -0.04024218]. 
=============================================
[2019-03-23 00:01:08,863] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-23 00:01:08,866] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 00:01:08,868] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:01:08,869] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 00:01:08,870] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 00:01:08,871] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 00:01:08,871] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:01:08,872] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 00:01:08,871] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:01:08,873] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:01:08,873] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:01:08,892] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run38
[2019-03-23 00:01:08,894] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run38
[2019-03-23 00:01:08,914] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run38
[2019-03-23 00:01:08,947] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run38
[2019-03-23 00:01:08,967] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run38
[2019-03-23 00:02:12,420] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.32224026], dtype=float32), 0.062332824]
[2019-03-23 00:02:12,422] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.56605722, 68.33661907, 1.0, 2.0, 0.4509621044745243, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 514237.0243374525, 514237.0243374525, 138679.1099628113]
[2019-03-23 00:02:12,424] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 00:02:12,426] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 9.5613072e-38 1.4559164e-33 3.6055496e-38], sampled 0.18152533330059406
[2019-03-23 00:02:17,337] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.32224026], dtype=float32), 0.062332824]
[2019-03-23 00:02:17,341] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [26.0, 64.0, 1.0, 2.0, 0.4983931260431571, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 568636.5300165507, 568636.5300165503, 145365.7565088394]
[2019-03-23 00:02:17,342] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 00:02:17,343] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 4.7582918e-34 3.1553107e-28 2.1143394e-35], sampled 0.7188275220078286
[2019-03-23 00:02:18,500] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.32224026], dtype=float32), 0.062332824]
[2019-03-23 00:02:18,502] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.51607681, 66.99368318333333, 1.0, 2.0, 0.3031872524462881, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 329196.4910353492, 329196.4910353489, 111148.8080440859]
[2019-03-23 00:02:18,503] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 00:02:18,508] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.5327511e-35 0.0000000e+00], sampled 0.6491659813507696
[2019-03-23 00:02:57,125] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9309 1705967916.6745 465.0000
[2019-03-23 00:02:57,723] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1147 1656209757.7786 80.0000
[2019-03-23 00:02:57,831] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5598 1663796639.0689 105.0000
[2019-03-23 00:02:57,864] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.0078 1683195778.0079 214.0000
[2019-03-23 00:02:57,972] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2492 1773187030.7201 173.0000
[2019-03-23 00:02:58,989] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 925000, evaluation results [925000.0, 8512.249193409023, 1773187030.7201214, 173.0, 9061.114669779829, 1656209757.7786272, 80.0, 8856.559759326878, 1663796639.0688558, 105.0, 8596.930884973775, 1705967916.6744611, 465.0, 8575.007765154833, 1683195778.007893, 214.0]
[2019-03-23 00:03:05,829] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.1479811e-29 1.1536321e-27 2.4700335e-38], sum to 1.0000
[2019-03-23 00:03:05,837] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5836
[2019-03-23 00:03:05,843] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.66666666666667, 75.5, 1.0, 2.0, 0.5614800172858484, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 637300.1421179833, 637300.142117983, 151820.2705343552], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3093000.0000, 
sim time next is 3093600.0000, 
raw observation next is [25.33333333333334, 77.0, 1.0, 2.0, 0.5578802341350971, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 633590.8453979105, 633590.8453979102, 151180.179538831], 
processed observation next is [1.0, 0.8260869565217391, 0.7878787878787882, 0.77, 1.0, 1.0, 0.4473502926688714, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.23466327607330018, 0.2346632760733001, 0.368732145216661], 
reward next is 0.6313, 
noisyNet noise sample is [array([-0.35575226], dtype=float32), 1.0393565]. 
=============================================
[2019-03-23 00:03:09,575] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 4.1532649e-34 4.2089367e-30 9.6919007e-36], sum to 1.0000
[2019-03-23 00:03:09,582] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5435
[2019-03-23 00:03:09,587] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 60.0, 1.0, 2.0, 0.4911103125124053, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 560242.5596029278, 560242.5596029278, 140726.0979148648], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3004200.0000, 
sim time next is 3004800.0000, 
raw observation next is [26.66666666666666, 61.66666666666666, 1.0, 2.0, 0.4914329671542999, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 560624.7008966026, 560624.7008966026, 140729.465812803], 
processed observation next is [1.0, 0.782608695652174, 0.8484848484848482, 0.6166666666666666, 1.0, 1.0, 0.36429120894287487, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20763877810985282, 0.20763877810985282, 0.343242599543422], 
reward next is 0.6568, 
noisyNet noise sample is [array([2.547095], dtype=float32), -0.07887758]. 
=============================================
[2019-03-23 00:03:10,026] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.7134618e-37 9.9999976e-01 1.1567183e-24 2.7232170e-07 2.8365018e-23], sum to 1.0000
[2019-03-23 00:03:10,036] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4845
[2019-03-23 00:03:10,040] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.83333333333333, 73.83333333333334, 1.0, 2.0, 0.213303896351323, 1.0, 2.0, 0.213303896351323, 1.0, 1.0, 0.4317041545344344, 6.911199999999999, 6.9112, 77.3421103, 729287.7331729096, 729287.7331729099, 230148.6863178491], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3172200.0000, 
sim time next is 3172800.0000, 
raw observation next is [23.66666666666666, 73.66666666666667, 1.0, 2.0, 0.4603828765828037, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 525260.4093256887, 525260.4093256891, 135963.3238728292], 
processed observation next is [1.0, 0.7391304347826086, 0.7121212121212118, 0.7366666666666667, 1.0, 1.0, 0.32547859572850457, 0.0, 0.5, -0.25, 0.0, 0.5, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1945408923428477, 0.1945408923428478, 0.33161786310446145], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.210418], dtype=float32), 0.26277688]. 
=============================================
[2019-03-23 00:03:14,088] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.28775055e-26 1.01406236e-04 1.00924708e-21 9.67658460e-01
 3.22400890e-02], sum to 1.0000
[2019-03-23 00:03:14,096] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6029
[2019-03-23 00:03:14,101] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.0, 89.0, 1.0, 2.0, 0.9983523576346099, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.13673233646973, 6.9112, 77.32801594256065, 1209468.829943528, 1136220.963881133, 221961.9639620186], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3492000.0000, 
sim time next is 3492600.0000, 
raw observation next is [23.5, 86.5, 1.0, 2.0, 0.5782201341498113, 1.0, 1.0, 0.5782201341498113, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.3283279190817, 1308679.679199126, 1308679.679199126, 253845.5396558393], 
processed observation next is [1.0, 0.43478260869565216, 0.7045454545454546, 0.865, 1.0, 1.0, 0.47277516768726413, 1.0, 0.5, 0.47277516768726413, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084279218575589, 0.4846961774811578, 0.4846961774811578, 0.6191354625752178], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.0008067], dtype=float32), 2.369208]. 
=============================================
[2019-03-23 00:03:16,883] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.1673706e-38 1.0000000e+00 8.1345067e-30 1.5820406e-11 2.2994111e-15], sum to 1.0000
[2019-03-23 00:03:16,894] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9299
[2019-03-23 00:03:16,904] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1086842.868774544 W.
[2019-03-23 00:03:16,912] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [21.5, 87.16666666666667, 1.0, 2.0, 0.4760067087760186, 1.0, 1.0, 0.4760067087760186, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32843707756656, 1086842.868774544, 1086842.868774544, 220889.4144129636], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3154200.0000, 
sim time next is 3154800.0000, 
raw observation next is [22.0, 86.33333333333334, 1.0, 2.0, 0.2919508655825569, 1.0, 2.0, 0.2919508655825569, 1.0, 1.0, 0.5906512095473008, 6.9112, 6.9112, 77.3421103, 998873.700149013, 998873.700149013, 253560.5137268693], 
processed observation next is [1.0, 0.5217391304347826, 0.6363636363636364, 0.8633333333333334, 1.0, 1.0, 0.1149385819781961, 1.0, 1.0, 0.1149385819781961, 1.0, 0.5, 0.4152160136390011, 0.0, 0.0, 0.5085185399722538, 0.36995322227741223, 0.36995322227741223, 0.6184402773826081], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.42111775], dtype=float32), -0.5156635]. 
=============================================
[2019-03-23 00:03:18,198] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:03:18,205] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3457
[2019-03-23 00:03:18,210] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.33333333333334, 94.0, 1.0, 2.0, 0.3724700195631535, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 416709.1826010507, 416709.1826010509, 120926.9434992958], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3210000.0000, 
sim time next is 3210600.0000, 
raw observation next is [18.16666666666666, 94.0, 1.0, 2.0, 0.3684737707978485, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 411329.6014890438, 411329.6014890435, 120187.2195959746], 
processed observation next is [0.0, 0.13043478260869565, 0.4621212121212119, 0.94, 1.0, 1.0, 0.21059221349731058, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.152344296847794, 0.15234429684779388, 0.29313955999018193], 
reward next is 0.7069, 
noisyNet noise sample is [array([-0.9288247], dtype=float32), 1.7165066]. 
=============================================
[2019-03-23 00:03:23,341] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:03:23,351] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3437
[2019-03-23 00:03:23,355] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 47.0, 1.0, 2.0, 0.3248884545620374, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 356139.3910098441, 356139.3910098441, 114068.3587553682], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3260400.0000, 
sim time next is 3261000.0000, 
raw observation next is [24.0, 47.0, 1.0, 2.0, 0.3244971128404946, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 355707.4243855517, 355707.4243855514, 114039.1491095525], 
processed observation next is [0.0, 0.7391304347826086, 0.7272727272727273, 0.47, 1.0, 1.0, 0.15562139105061823, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1317434905131673, 0.1317434905131672, 0.27814426612085974], 
reward next is 0.7219, 
noisyNet noise sample is [array([-1.266966], dtype=float32), 0.08659506]. 
=============================================
[2019-03-23 00:03:23,365] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[74.74421]
 [74.70361]
 [74.65362]
 [74.589  ]
 [74.54613]], R is [[74.75470734]
 [74.7289505 ]
 [74.70330048]
 [74.67765045]
 [74.65185547]].
[2019-03-23 00:03:26,770] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.3459127e-32 4.8767884e-32 5.6520396e-32], sum to 1.0000
[2019-03-23 00:03:26,780] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3514
[2019-03-23 00:03:26,785] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333334, 98.0, 1.0, 2.0, 0.5433569660395856, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 619892.3285408183, 619892.3285408183, 146916.5473965119], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3482400.0000, 
sim time next is 3483000.0000, 
raw observation next is [21.5, 97.0, 1.0, 2.0, 0.5221878109062527, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 595690.5581517944, 595690.5581517946, 144433.5763131564], 
processed observation next is [1.0, 0.30434782608695654, 0.6136363636363636, 0.97, 1.0, 1.0, 0.4027347636328158, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22062613264881273, 0.2206261326488128, 0.35227701539794243], 
reward next is 0.6477, 
noisyNet noise sample is [array([0.06706915], dtype=float32), 0.28772023]. 
=============================================
[2019-03-23 00:03:26,798] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[56.893158]
 [56.724766]
 [57.98692 ]
 [57.95271 ]
 [57.984764]], R is [[57.13141632]
 [57.20177078]
 [57.25250244]
 [57.33680344]
 [57.41872025]].
[2019-03-23 00:03:35,882] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.8828145e-28 1.0000000e+00 1.6048561e-22 1.4732109e-21 5.5890847e-19], sum to 1.0000
[2019-03-23 00:03:35,894] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8814
[2019-03-23 00:03:35,900] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4903413221059565, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 559456.3815732728, 559456.3815732728, 140373.7262774648], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3636000.0000, 
sim time next is 3636600.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.7859531975154918, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 82.24921059666127, 896938.4120291183, 896938.4120291183, 182597.6614909248], 
processed observation next is [1.0, 0.08695652173913043, 0.5909090909090909, 1.0, 1.0, 1.0, 0.7324414968943646, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5407823541955336, 0.3321994118626364, 0.3321994118626364, 0.4453601499778654], 
reward next is 0.5546, 
noisyNet noise sample is [array([-0.5082311], dtype=float32), -2.462691]. 
=============================================
[2019-03-23 00:03:37,877] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.4362263e-36 1.0000000e+00 2.4055440e-32 1.6413006e-19 3.3397450e-15], sum to 1.0000
[2019-03-23 00:03:37,884] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5135
[2019-03-23 00:03:37,891] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 78.0, 1.0, 2.0, 0.5462911373742648, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 621068.0197065485, 621068.0197065488, 149361.1610925381], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3531600.0000, 
sim time next is 3532200.0000, 
raw observation next is [24.83333333333334, 78.83333333333333, 1.0, 2.0, 0.5436593962453911, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 618226.9862816253, 618226.9862816253, 148941.0976399362], 
processed observation next is [1.0, 0.9130434782608695, 0.7651515151515155, 0.7883333333333333, 1.0, 1.0, 0.42957424530673877, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22897295788208347, 0.22897295788208347, 0.36327096985350293], 
reward next is 0.6367, 
noisyNet noise sample is [array([0.5258829], dtype=float32), -0.8881017]. 
=============================================
[2019-03-23 00:03:42,508] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.0296048e-37 4.6522474e-36 1.0147377e-36], sum to 1.0000
[2019-03-23 00:03:42,514] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4379
[2019-03-23 00:03:42,520] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.16666666666667, 82.16666666666667, 1.0, 2.0, 0.4904825884409206, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 559657.7154331133, 559657.7154331133, 140215.1722066574], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3613800.0000, 
sim time next is 3614400.0000, 
raw observation next is [23.0, 83.0, 1.0, 2.0, 0.491958692099859, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 561359.2457679696, 561359.2457679696, 140281.0212448875], 
processed observation next is [1.0, 0.8695652173913043, 0.6818181818181818, 0.83, 1.0, 1.0, 0.3649483651248237, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20791083176591468, 0.20791083176591468, 0.34214883230460363], 
reward next is 0.6579, 
noisyNet noise sample is [array([-0.9124274], dtype=float32), -0.7774102]. 
=============================================
[2019-03-23 00:03:43,643] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.7789425e-37 1.0000000e+00 1.1781288e-33 4.9483046e-37 8.2341979e-29], sum to 1.0000
[2019-03-23 00:03:43,651] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7218
[2019-03-23 00:03:43,658] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.5853571967340944, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 667905.5293936396, 667905.52939364, 152032.0826702287], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3637800.0000, 
sim time next is 3638400.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.5587067949922615, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 637488.7957034763, 637488.7957034761, 148616.6073612014], 
processed observation next is [1.0, 0.08695652173913043, 0.5909090909090909, 1.0, 1.0, 1.0, 0.4483834937403268, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.23610696137165788, 0.2361069613716578, 0.3624795301492717], 
reward next is 0.6375, 
noisyNet noise sample is [array([1.0014871], dtype=float32), 1.9335114]. 
=============================================
[2019-03-23 00:03:44,979] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.4207138e-35 2.6537337e-37 3.0955165e-31], sum to 1.0000
[2019-03-23 00:03:44,988] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2728
[2019-03-23 00:03:44,998] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.503475310802977, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 574447.2328400918, 574447.2328400918, 141901.9906912884], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3649800.0000, 
sim time next is 3650400.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.4920431996357769, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 561397.7327374378, 561397.7327374378, 140574.3244553651], 
processed observation next is [1.0, 0.2608695652173913, 0.5909090909090909, 1.0, 1.0, 1.0, 0.3650539995447211, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20792508619905103, 0.20792508619905103, 0.3428642059886954], 
reward next is 0.6571, 
noisyNet noise sample is [array([0.2700241], dtype=float32), 0.4827022]. 
=============================================
[2019-03-23 00:03:50,772] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-23 00:03:50,774] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 00:03:50,775] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 00:03:50,775] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:03:50,776] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:03:50,776] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 00:03:50,778] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 00:03:50,779] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:03:50,780] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:03:50,777] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 00:03:50,784] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:03:50,794] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run39
[2019-03-23 00:03:50,815] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run39
[2019-03-23 00:03:50,815] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run39
[2019-03-23 00:03:50,856] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run39
[2019-03-23 00:03:50,874] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run39
[2019-03-23 00:04:03,403] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.27265203], dtype=float32), 0.098832324]
[2019-03-23 00:04:03,405] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [28.07910084333333, 60.44823052, 1.0, 2.0, 0.5374926478025681, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 611017.3341017732, 611017.3341017729, 152540.6529567785]
[2019-03-23 00:04:03,405] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 00:04:03,407] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.7247543006031376
[2019-03-23 00:04:47,378] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.27265203], dtype=float32), 0.098832324]
[2019-03-23 00:04:47,380] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.556959775, 96.02584431, 1.0, 2.0, 0.4802050604908497, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 546003.0664754005, 546003.0664754005, 139931.741491582]
[2019-03-23 00:04:47,381] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 00:04:47,386] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.08131538848523678
[2019-03-23 00:04:56,614] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.27265203], dtype=float32), 0.098832324]
[2019-03-23 00:04:56,615] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [15.93333333333333, 87.5, 1.0, 2.0, 0.4356918334824317, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 97.50023847740809, 473121.0359857532, 473121.0359857532, 111678.8283004074]
[2019-03-23 00:04:56,617] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 00:04:56,621] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.3945313445768234
[2019-03-23 00:04:58,406] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.27265203], dtype=float32), 0.098832324]
[2019-03-23 00:04:58,408] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.05, 99.5, 1.0, 2.0, 0.4919122644723248, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 561253.7516029003, 561253.7516029003, 140539.1896962316]
[2019-03-23 00:04:58,410] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 00:04:58,412] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 1.6828769e-36 0.0000000e+00 8.0560979e-38], sampled 0.8325771519951646
[2019-03-23 00:05:21,030] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.27265203], dtype=float32), 0.098832324]
[2019-03-23 00:05:21,030] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.93872439, 89.30423538, 1.0, 2.0, 0.3220450504497027, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 354673.391212648, 354673.391212648, 118799.0105162889]
[2019-03-23 00:05:21,031] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 00:05:21,033] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.5623797051949886
[2019-03-23 00:05:37,405] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3485 1683325900.1134 214.0000
[2019-03-23 00:05:37,689] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1147 1656209757.7786 80.0000
[2019-03-23 00:05:38,187] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5599 1663815647.6096 105.0000
[2019-03-23 00:05:38,225] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2492 1773187030.7201 173.0000
[2019-03-23 00:05:38,286] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9310 1705987275.5940 465.0000
[2019-03-23 00:05:39,300] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 950000, evaluation results [950000.0, 8512.249193409023, 1773187030.7201214, 173.0, 9061.114669779829, 1656209757.7786272, 80.0, 8856.559925897878, 1663815647.6095803, 105.0, 8596.931041181726, 1705987275.594041, 465.0, 8574.348472942609, 1683325900.1133502, 214.0]
[2019-03-23 00:05:52,848] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.5807046e-37 1.0000000e+00 1.4413354e-30 6.0657244e-38 1.4692953e-26], sum to 1.0000
[2019-03-23 00:05:52,862] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9257
[2019-03-23 00:05:52,865] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 94.0, 1.0, 2.0, 0.5791426731428048, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 645666.1116514105, 645666.1116514105, 140003.6734729022], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4017600.0000, 
sim time next is 4018200.0000, 
raw observation next is [17.83333333333333, 95.0, 1.0, 2.0, 0.6377590322023717, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 711006.6419953099, 711006.6419953099, 146563.6751310715], 
processed observation next is [1.0, 0.5217391304347826, 0.44696969696969674, 0.95, 1.0, 1.0, 0.5471987902529646, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.26333579333159624, 0.26333579333159624, 0.35747237836846707], 
reward next is 0.6425, 
noisyNet noise sample is [array([-0.11340766], dtype=float32), 1.2239355]. 
=============================================
[2019-03-23 00:05:54,005] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 3.7937981e-35 0.0000000e+00 2.8199905e-34], sum to 1.0000
[2019-03-23 00:05:54,017] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4030
[2019-03-23 00:05:54,023] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 69.0, 1.0, 2.0, 0.4007835677211128, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 454134.9739829489, 454134.9739829489, 126401.7112110999], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4212000.0000, 
sim time next is 4212600.0000, 
raw observation next is [22.83333333333334, 69.66666666666667, 1.0, 2.0, 0.408207494400151, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 462411.0649646061, 462411.0649646064, 127004.2611248787], 
processed observation next is [1.0, 0.782608695652174, 0.6742424242424245, 0.6966666666666668, 1.0, 1.0, 0.26025936800018873, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17126335739429854, 0.17126335739429868, 0.30976649054848465], 
reward next is 0.6902, 
noisyNet noise sample is [array([0.54935193], dtype=float32), 0.87200665]. 
=============================================
[2019-03-23 00:06:01,498] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.0970602e-34 0.0000000e+00], sum to 1.0000
[2019-03-23 00:06:01,508] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1748
[2019-03-23 00:06:01,510] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 94.0, 1.0, 2.0, 0.3436081693543291, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 382334.9903288567, 382334.990328857, 117637.0279435347], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4174800.0000, 
sim time next is 4175400.0000, 
raw observation next is [18.0, 94.0, 1.0, 2.0, 0.3442650793531009, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 383067.4905217611, 383067.4905217608, 117689.1246891393], 
processed observation next is [1.0, 0.30434782608695654, 0.45454545454545453, 0.94, 1.0, 1.0, 0.1803313491913761, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.141876848341393, 0.14187684834139289, 0.2870466455832666], 
reward next is 0.7130, 
noisyNet noise sample is [array([-0.11659794], dtype=float32), 0.8191941]. 
=============================================
[2019-03-23 00:06:01,697] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.3482313e-38 1.0000000e+00 7.7513996e-32 1.2207633e-26 6.0185700e-22], sum to 1.0000
[2019-03-23 00:06:01,708] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8508
[2019-03-23 00:06:01,716] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 65.0, 1.0, 2.0, 0.7973976540788824, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 901112.9020266846, 901112.9020266846, 172338.3461385176], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4190400.0000, 
sim time next is 4191000.0000, 
raw observation next is [23.16666666666667, 64.33333333333334, 1.0, 2.0, 0.7510857763044918, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 848927.3917071573, 848927.3917071573, 165896.4426727243], 
processed observation next is [1.0, 0.5217391304347826, 0.6893939393939396, 0.6433333333333334, 1.0, 1.0, 0.6888572203806148, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.31441755248413233, 0.31441755248413233, 0.4046254699334739], 
reward next is 0.5954, 
noisyNet noise sample is [array([1.7288098], dtype=float32), -0.07744832]. 
=============================================
[2019-03-23 00:06:01,723] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[59.32006 ]
 [59.606487]
 [60.029972]
 [60.621098]
 [60.858765]], R is [[59.60156631]
 [59.58521271]
 [59.5725174 ]
 [59.56768036]
 [59.58104706]].
[2019-03-23 00:06:07,840] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 9.096982e-38], sum to 1.0000
[2019-03-23 00:06:07,850] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6706
[2019-03-23 00:06:07,854] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 61.0, 1.0, 2.0, 0.400429618653768, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 452717.5122305367, 452717.5122305367, 125723.8324646054], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4309200.0000, 
sim time next is 4309800.0000, 
raw observation next is [23.5, 63.83333333333334, 1.0, 2.0, 0.3998224157466044, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 451983.9589764533, 451983.9589764533, 125639.9513960596], 
processed observation next is [1.0, 0.9130434782608695, 0.7045454545454546, 0.6383333333333334, 1.0, 1.0, 0.24977801968325544, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1674014662875753, 0.1674014662875753, 0.3064389058440478], 
reward next is 0.6936, 
noisyNet noise sample is [array([1.2732027], dtype=float32), 0.7534635]. 
=============================================
[2019-03-23 00:06:12,174] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 2.3634692e-37], sum to 1.0000
[2019-03-23 00:06:12,184] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0596
[2019-03-23 00:06:12,188] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 83.83333333333334, 1.0, 2.0, 0.4175147718062993, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 473612.1697829647, 473612.169782965, 128331.450336436], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4420200.0000, 
sim time next is 4420800.0000, 
raw observation next is [21.0, 83.0, 1.0, 2.0, 0.4132752629070427, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 468444.6084590276, 468444.6084590276, 127676.4365039124], 
processed observation next is [0.0, 0.17391304347826086, 0.5909090909090909, 0.83, 1.0, 1.0, 0.26659407863380336, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17349800313297317, 0.17349800313297317, 0.31140594269246924], 
reward next is 0.6886, 
noisyNet noise sample is [array([0.31898633], dtype=float32), -2.2747211]. 
=============================================
[2019-03-23 00:06:13,152] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:06:13,162] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9791
[2019-03-23 00:06:13,168] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.83333333333334, 84.0, 1.0, 2.0, 0.444736154132969, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 506656.0683562321, 506656.0683562321, 132909.0572235334], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4411200.0000, 
sim time next is 4411800.0000, 
raw observation next is [21.75, 84.5, 1.0, 2.0, 0.4437408906411728, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 505490.7058245658, 505490.7058245661, 132768.2244387925], 
processed observation next is [0.0, 0.043478260869565216, 0.625, 0.845, 1.0, 1.0, 0.30467611330146593, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18721877993502437, 0.18721877993502448, 0.32382493765559145], 
reward next is 0.6762, 
noisyNet noise sample is [array([0.11100227], dtype=float32), -0.5607395]. 
=============================================
[2019-03-23 00:06:18,695] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.7791487e-35 3.0336165e-32 0.0000000e+00], sum to 1.0000
[2019-03-23 00:06:18,702] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8162
[2019-03-23 00:06:18,708] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.16666666666667, 99.00000000000001, 1.0, 2.0, 0.4831416061259409, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 551217.0563625415, 551217.0563625415, 139622.0109555085], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4522200.0000, 
sim time next is 4522800.0000, 
raw observation next is [21.33333333333334, 98.0, 1.0, 2.0, 0.4860127727475587, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 554457.5656681363, 554457.5656681361, 140057.071307155], 
processed observation next is [0.0, 0.34782608695652173, 0.6060606060606063, 0.98, 1.0, 1.0, 0.35751596593444834, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20535465395116162, 0.20535465395116154, 0.3416026129442805], 
reward next is 0.6584, 
noisyNet noise sample is [array([0.3405042], dtype=float32), -0.8896172]. 
=============================================
[2019-03-23 00:06:19,057] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.5291171e-37], sum to 1.0000
[2019-03-23 00:06:19,065] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3600
[2019-03-23 00:06:19,069] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.16666666666667, 99.00000000000001, 1.0, 2.0, 0.4831416061259409, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 551217.0563625415, 551217.0563625415, 139622.0109555085], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4522200.0000, 
sim time next is 4522800.0000, 
raw observation next is [21.33333333333334, 98.0, 1.0, 2.0, 0.4860127727475587, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 554457.5656681363, 554457.5656681361, 140057.071307155], 
processed observation next is [0.0, 0.34782608695652173, 0.6060606060606063, 0.98, 1.0, 1.0, 0.35751596593444834, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20535465395116162, 0.20535465395116154, 0.3416026129442805], 
reward next is 0.6584, 
noisyNet noise sample is [array([-0.27835086], dtype=float32), 0.8465578]. 
=============================================
[2019-03-23 00:06:19,701] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:06:19,705] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7806
[2019-03-23 00:06:19,709] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.16666666666667, 69.66666666666667, 1.0, 2.0, 0.3272732373828879, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 359215.3535285077, 359215.353528508, 114408.9228751921], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4565400.0000, 
sim time next is 4566000.0000, 
raw observation next is [19.93333333333333, 70.33333333333334, 1.0, 2.0, 0.3232424249795995, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 353947.7067840899, 353947.7067840896, 113808.9538762306], 
processed observation next is [0.0, 0.8695652173913043, 0.5424242424242423, 0.7033333333333335, 1.0, 1.0, 0.15405303122449934, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13109174325336664, 0.13109174325336653, 0.2775828143322698], 
reward next is 0.7224, 
noisyNet noise sample is [array([0.67254114], dtype=float32), -0.34205735]. 
=============================================
[2019-03-23 00:06:19,726] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[70.99853 ]
 [71.008766]
 [70.98852 ]
 [70.97971 ]
 [70.96722 ]], R is [[71.01554108]
 [71.0263443 ]
 [71.03562164]
 [71.04341125]
 [71.04966736]].
[2019-03-23 00:06:22,670] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:06:22,678] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0326
[2019-03-23 00:06:22,682] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 88.0, 1.0, 2.0, 0.2627669099553908, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 285314.1905234528, 285314.1905234528, 90699.50996197858], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4584600.0000, 
sim time next is 4585200.0000, 
raw observation next is [16.0, 88.0, 1.0, 2.0, 0.2629119086361528, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 285471.6773353315, 285471.6773353315, 90712.96408123567], 
processed observation next is [1.0, 0.043478260869565216, 0.36363636363636365, 0.88, 1.0, 1.0, 0.07863988579519102, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10573025086493759, 0.10573025086493759, 0.22125113190545284], 
reward next is 0.7787, 
noisyNet noise sample is [array([-0.06082349], dtype=float32), -0.024540748]. 
=============================================
[2019-03-23 00:06:28,652] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-23 00:06:28,654] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 00:06:28,654] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 00:06:28,654] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:06:28,656] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:06:28,655] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 00:06:28,656] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 00:06:28,660] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:06:28,658] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 00:06:28,661] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:06:28,662] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:06:28,687] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run40
[2019-03-23 00:06:28,708] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run40
[2019-03-23 00:06:28,729] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run40
[2019-03-23 00:06:28,746] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run40
[2019-03-23 00:06:28,774] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run40
[2019-03-23 00:06:51,832] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.19815882], dtype=float32), 0.13049799]
[2019-03-23 00:06:51,833] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.83333333333334, 89.00000000000001, 1.0, 2.0, 0.3648473871287252, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 407582.7296545219, 407582.7296545221, 120022.847708057]
[2019-03-23 00:06:51,835] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 00:06:51,839] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.5968724841213187
[2019-03-23 00:07:28,638] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.19815882], dtype=float32), 0.13049799]
[2019-03-23 00:07:28,656] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.33333333333334, 92.16666666666667, 1.0, 2.0, 0.4007372324115107, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 451971.2740533173, 451971.2740533173, 125126.0474606362]
[2019-03-23 00:07:28,660] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 00:07:28,663] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.49295396115252743
[2019-03-23 00:07:31,365] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.19815882], dtype=float32), 0.13049799]
[2019-03-23 00:07:31,367] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.144628625, 92.40347988166666, 1.0, 2.0, 0.3520396894363033, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 391449.1749990284, 391449.1749990284, 122507.8782537276]
[2019-03-23 00:07:31,368] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 00:07:31,370] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.4222806443428838
[2019-03-23 00:07:48,853] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.19815882], dtype=float32), 0.13049799]
[2019-03-23 00:07:48,854] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.2, 39.0, 1.0, 2.0, 0.3038888432643019, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 329958.4776811024, 329958.4776811024, 88930.4339254289]
[2019-03-23 00:07:48,856] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 00:07:48,860] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.6929367666390999
[2019-03-23 00:08:15,534] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1147 1656209757.7786 80.0000
[2019-03-23 00:08:15,691] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5599 1663815647.6096 105.0000
[2019-03-23 00:08:15,886] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3486 1683344882.4587 214.0000
[2019-03-23 00:08:15,948] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9309 1705967916.6745 465.0000
[2019-03-23 00:08:15,983] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 00:08:16,998] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 975000, evaluation results [975000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.114669779829, 1656209757.7786272, 80.0, 8856.559925897878, 1663815647.6095803, 105.0, 8596.930884973775, 1705967916.6744611, 465.0, 8574.348638023737, 1683344882.4586744, 214.0]
[2019-03-23 00:08:21,884] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.5261023e-37 1.0000000e+00 7.4892291e-30 1.3100874e-19 8.2341203e-25], sum to 1.0000
[2019-03-23 00:08:21,894] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3491
[2019-03-23 00:08:21,899] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.7397966229188008, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 839833.6673420384, 839833.6673420384, 166662.8141682965], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4784400.0000, 
sim time next is 4785000.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.6573863613017588, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 746110.7504468913, 746110.7504468913, 155467.9147090999], 
processed observation next is [1.0, 0.391304347826087, 0.5, 1.0, 1.0, 1.0, 0.5717329516271984, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2763373149803301, 0.2763373149803301, 0.37919003587585337], 
reward next is 0.6208, 
noisyNet noise sample is [array([0.13175982], dtype=float32), 0.2532455]. 
=============================================
[2019-03-23 00:08:21,912] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[55.032528]
 [55.31043 ]
 [55.75525 ]
 [56.470627]
 [57.78    ]], R is [[55.75133133]
 [55.787323  ]
 [55.82374191]
 [55.85976791]
 [55.8985672 ]].
[2019-03-23 00:08:29,142] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:08:29,149] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1013
[2019-03-23 00:08:29,155] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.16666666666666, 99.0, 1.0, 2.0, 0.3797904063730254, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 426746.7340303683, 426746.734030368, 122418.4679263412], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4927800.0000, 
sim time next is 4928400.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.3779177637786099, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 424353.388339521, 424353.3883395207, 122114.2450156143], 
processed observation next is [1.0, 0.043478260869565216, 0.45454545454545453, 1.0, 1.0, 1.0, 0.22239720472326238, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15716792160723, 0.1571679216072299, 0.2978396219893032], 
reward next is 0.7022, 
noisyNet noise sample is [array([1.1992912], dtype=float32), 0.9606191]. 
=============================================
[2019-03-23 00:08:33,731] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:08:33,741] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7664
[2019-03-23 00:08:33,749] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 82.0, 1.0, 2.0, 0.2806492166611334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 304737.0103567261, 304737.0103567261, 96215.29007976975], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5007600.0000, 
sim time next is 5008200.0000, 
raw observation next is [17.0, 82.00000000000001, 1.0, 2.0, 0.2789452900537836, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 302886.2615718028, 302886.2615718031, 96000.95130887427], 
processed observation next is [1.0, 1.0, 0.4090909090909091, 0.8200000000000002, 1.0, 1.0, 0.09868161256722949, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11218009687844548, 0.11218009687844559, 0.23414866172896162], 
reward next is 0.7659, 
noisyNet noise sample is [array([-0.7611063], dtype=float32), -1.0641313]. 
=============================================
[2019-03-23 00:08:40,803] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 5.5437229e-36 5.9223049e-28 7.5937495e-36], sum to 1.0000
[2019-03-23 00:08:40,811] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4729
[2019-03-23 00:08:40,815] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 74.0, 1.0, 2.0, 0.457347639388105, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 521818.2474313041, 521818.2474313041, 135740.8212650963], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5133600.0000, 
sim time next is 5134200.0000, 
raw observation next is [24.16666666666666, 74.0, 1.0, 2.0, 0.4615923300512149, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 526702.0508976564, 526702.050897656, 136481.0637562475], 
processed observation next is [0.0, 0.43478260869565216, 0.7348484848484845, 0.74, 1.0, 1.0, 0.3269904125640186, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19507483366579864, 0.19507483366579853, 0.3328806433079207], 
reward next is 0.6671, 
noisyNet noise sample is [array([-0.24753787], dtype=float32), -0.07953792]. 
=============================================
[2019-03-23 00:08:58,821] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:08:58,829] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0604
[2019-03-23 00:08:58,835] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.25, 97.0, 1.0, 2.0, 0.3786374002901878, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 424959.6156763367, 424959.615676337, 122077.3357094135], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5635800.0000, 
sim time next is 5636400.0000, 
raw observation next is [18.06666666666667, 97.0, 1.0, 2.0, 0.3720204568517857, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 416590.861662794, 416590.8616627937, 121065.958856409], 
processed observation next is [0.0, 0.21739130434782608, 0.45757575757575775, 0.97, 1.0, 1.0, 0.2150255710647321, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15429291172696075, 0.1542929117269606, 0.2952828264790463], 
reward next is 0.7047, 
noisyNet noise sample is [array([0.37250262], dtype=float32), 0.41972628]. 
=============================================
[2019-03-23 00:09:01,771] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:09:01,780] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9738
[2019-03-23 00:09:01,784] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 87.0, 1.0, 2.0, 0.5113375543290112, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 579833.6967855933, 579833.6967855935, 137770.6553405102], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5538600.0000, 
sim time next is 5539200.0000, 
raw observation next is [20.5, 87.0, 1.0, 2.0, 0.4808859199157585, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 545219.4799410984, 545219.4799410986, 134481.6802267567], 
processed observation next is [1.0, 0.08695652173913043, 0.5681818181818182, 0.87, 1.0, 1.0, 0.35110739989469814, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20193314071892532, 0.2019331407189254, 0.32800409811404074], 
reward next is 0.6720, 
noisyNet noise sample is [array([-0.4224129], dtype=float32), -1.8840955]. 
=============================================
[2019-03-23 00:09:04,436] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:09:04,443] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5537
[2019-03-23 00:09:04,448] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.45, 53.0, 1.0, 2.0, 0.2131073388395338, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 231380.6470886599, 231380.6470886602, 72401.18713327941], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5740200.0000, 
sim time next is 5740800.0000, 
raw observation next is [17.53333333333333, 52.0, 1.0, 2.0, 0.2139153105133494, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 232258.1093321508, 232258.109332151, 72359.02473436242], 
processed observation next is [0.0, 0.43478260869565216, 0.43333333333333324, 0.52, 1.0, 1.0, 0.01739413814168672, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08602152197487067, 0.08602152197487074, 0.17648542618137175], 
reward next is 0.8235, 
noisyNet noise sample is [array([0.6450393], dtype=float32), 1.2081739]. 
=============================================
[2019-03-23 00:09:06,599] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 3.7290991e-36 1.6498415e-37 0.0000000e+00], sum to 1.0000
[2019-03-23 00:09:06,607] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2712
[2019-03-23 00:09:06,613] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 91.5, 1.0, 2.0, 0.3895672628925617, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 439363.868177032, 439363.8681770323, 124117.6170671172], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5614200.0000, 
sim time next is 5614800.0000, 
raw observation next is [19.4, 92.0, 1.0, 2.0, 0.3907268593826262, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 440921.751352232, 440921.7513522323, 124360.0384875916], 
processed observation next is [1.0, 1.0, 0.5181818181818181, 0.92, 1.0, 1.0, 0.2384085742282827, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1633043523526785, 0.16330435235267862, 0.30331716704290634], 
reward next is 0.6967, 
noisyNet noise sample is [array([-0.895582], dtype=float32), 1.7690967]. 
=============================================
[2019-03-23 00:09:07,058] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-23 00:09:07,060] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 00:09:07,061] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:09:07,061] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 00:09:07,063] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 00:09:07,064] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:09:07,066] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 00:09:07,067] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:09:07,065] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 00:09:07,077] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:09:07,083] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:09:07,492] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run41
[2019-03-23 00:09:07,592] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run41
[2019-03-23 00:09:07,616] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run41
[2019-03-23 00:09:07,634] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run41
[2019-03-23 00:09:07,663] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run41
[2019-03-23 00:09:16,129] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.24980795], dtype=float32), 0.14085317]
[2019-03-23 00:09:16,130] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [15.76666666666667, 66.33333333333333, 1.0, 2.0, 0.2239746213230548, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 243171.1216991811, 243171.1216991814, 78350.57901029006]
[2019-03-23 00:09:16,132] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 00:09:16,136] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.9881196048246955
[2019-03-23 00:10:02,447] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.24980795], dtype=float32), 0.14085317]
[2019-03-23 00:10:02,449] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [26.1, 51.0, 1.0, 2.0, 0.4024634759469925, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 455610.3196248452, 455610.3196248449, 130609.9822099062]
[2019-03-23 00:10:02,451] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 00:10:02,454] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.8704538405322675
[2019-03-23 00:10:31,840] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.24980795], dtype=float32), 0.14085317]
[2019-03-23 00:10:31,841] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [25.6, 60.5, 1.0, 2.0, 0.5505393131410345, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 627576.0116235429, 627576.0116235429, 149462.311016214]
[2019-03-23 00:10:31,843] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 00:10:31,846] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.15356265902574062
[2019-03-23 00:10:54,182] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 00:10:54,589] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9310 1705987275.5940 465.0000
[2019-03-23 00:10:54,670] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1148 1656229146.4555 80.0000
[2019-03-23 00:10:54,701] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2492 1773187030.7201 173.0000
[2019-03-23 00:10:54,733] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3485 1683325900.1134 214.0000
[2019-03-23 00:10:55,751] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 1000000, evaluation results [1000000.0, 8512.249193409023, 1773187030.7201214, 173.0, 9061.114827412715, 1656229146.4555063, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8596.931041181726, 1705987275.594041, 465.0, 8574.348472942609, 1683325900.1133502, 214.0]
[2019-03-23 00:10:56,109] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:10:56,121] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9378
[2019-03-23 00:10:56,128] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.35, 96.5, 1.0, 2.0, 0.3130413679245364, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 340076.7710994083, 340076.7710994083, 112128.7185875865], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5646600.0000, 
sim time next is 5647200.0000, 
raw observation next is [16.26666666666667, 96.33333333333334, 1.0, 2.0, 0.3090274332171252, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 335561.5271174674, 335561.5271174671, 111800.9897377082], 
processed observation next is [0.0, 0.34782608695652173, 0.3757575757575759, 0.9633333333333334, 1.0, 1.0, 0.1362842915214065, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1242820470805435, 0.12428204708054336, 0.2726853408236785], 
reward next is 0.7273, 
noisyNet noise sample is [array([-1.1099877], dtype=float32), 1.0284431]. 
=============================================
[2019-03-23 00:10:58,207] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:10:58,215] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0040
[2019-03-23 00:10:58,219] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.7, 86.66666666666667, 1.0, 2.0, 0.2497257116065806, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 271150.01674923, 271150.0167492303, 85482.47477309477], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5665200.0000, 
sim time next is 5665800.0000, 
raw observation next is [15.6, 86.83333333333333, 1.0, 2.0, 0.2470333098154122, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 268225.8240589416, 268225.8240589419, 84621.62668347491], 
processed observation next is [0.0, 0.5652173913043478, 0.34545454545454546, 0.8683333333333333, 1.0, 1.0, 0.05879163726926522, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.099342897799608, 0.09934289779960812, 0.20639421142310954], 
reward next is 0.7936, 
noisyNet noise sample is [array([-0.5873417], dtype=float32), 0.49795032]. 
=============================================
[2019-03-23 00:10:58,372] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:10:58,381] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7657
[2019-03-23 00:10:58,386] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.5, 75.0, 1.0, 2.0, 0.2104843852547318, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 228532.1141557465, 228532.1141557465, 74348.03230675879], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5677200.0000, 
sim time next is 5677800.0000, 
raw observation next is [15.6, 74.0, 1.0, 2.0, 0.2116034279376582, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 229747.3947471854, 229747.3947471857, 74391.79374336688], 
processed observation next is [0.0, 0.7391304347826086, 0.34545454545454546, 0.74, 1.0, 1.0, 0.01450428492207275, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08509162768414275, 0.08509162768414286, 0.18144339937406556], 
reward next is 0.8186, 
noisyNet noise sample is [array([-0.36380777], dtype=float32), -1.2398913]. 
=============================================
[2019-03-23 00:11:01,006] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:11:01,019] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7250
[2019-03-23 00:11:01,025] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [9.0, 88.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 132961.066995444, 132961.0669954443, 55632.38761097036], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5719200.0000, 
sim time next is 5719800.0000, 
raw observation next is [8.9, 89.33333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 131456.6506483555, 131456.6506483555, 55446.34579719703], 
processed observation next is [0.0, 0.17391304347826086, 0.04090909090909092, 0.8933333333333333, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.04868764838827982, 0.04868764838827982, 0.13523498974926104], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.777649], dtype=float32), -1.8979416]. 
=============================================
[2019-03-23 00:11:03,126] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:11:03,136] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1088
[2019-03-23 00:11:03,144] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.7, 40.0, 1.0, 2.0, 0.2802851914638642, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 304341.6176228497, 304341.6176228497, 88677.37829512997], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5763600.0000, 
sim time next is 5764200.0000, 
raw observation next is [22.51666666666667, 40.66666666666667, 1.0, 2.0, 0.2803633622487603, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 304426.5242466624, 304426.5242466624, 88473.46086391475], 
processed observation next is [0.0, 0.7391304347826086, 0.659848484848485, 0.40666666666666673, 1.0, 1.0, 0.10045420281095035, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11275056453580089, 0.11275056453580089, 0.21578892893637744], 
reward next is 0.7842, 
noisyNet noise sample is [array([-2.7498267], dtype=float32), 0.6648627]. 
=============================================
[2019-03-23 00:11:07,236] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.5960422e-35 1.0000000e+00 1.8924698e-29 5.0631454e-27 2.2016190e-21], sum to 1.0000
[2019-03-23 00:11:07,243] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8129
[2019-03-23 00:11:07,250] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1165719.773210011 W.
[2019-03-23 00:11:07,256] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.35, 55.0, 1.0, 2.0, 0.9964960894708761, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.002162354637602, 6.9112, 77.32828295426684, 1165719.773210011, 1136177.129880079, 211809.8106033439], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6003000.0000, 
sim time next is 6003600.0000, 
raw observation next is [26.43333333333334, 54.66666666666667, 1.0, 2.0, 0.5037178575017753, 1.0, 1.0, 0.5037178575017753, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32840878347326, 1150245.424432622, 1150245.424432622, 226794.0625461946], 
processed observation next is [1.0, 0.4782608695652174, 0.8378787878787882, 0.5466666666666667, 1.0, 1.0, 0.3796473218772191, 1.0, 0.5, 0.3796473218772191, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084284535348325, 0.4260168238639341, 0.4260168238639341, 0.5531562501126698], 
reward next is 0.4468, 
noisyNet noise sample is [array([-0.1274806], dtype=float32), 0.9585371]. 
=============================================
[2019-03-23 00:11:10,390] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.1102718e-37 1.0000000e+00 4.2538604e-29 2.2101341e-14 1.7855617e-26], sum to 1.0000
[2019-03-23 00:11:10,401] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6211
[2019-03-23 00:11:10,409] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 60.0, 1.0, 2.0, 0.7532517813207026, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 856938.5945414561, 856938.5945414561, 170012.5845312773], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5914800.0000, 
sim time next is 5915400.0000, 
raw observation next is [25.26666666666667, 58.83333333333333, 1.0, 2.0, 0.9082307701043172, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1033923.92094801, 1033923.92094801, 194592.5029776561], 
processed observation next is [1.0, 0.4782608695652174, 0.784848484848485, 0.5883333333333333, 1.0, 1.0, 0.8852884626303964, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3829347855363, 0.3829347855363, 0.47461586092111246], 
reward next is 0.5254, 
noisyNet noise sample is [array([-1.183546], dtype=float32), -0.3916287]. 
=============================================
[2019-03-23 00:11:16,070] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 4.1895869e-37 2.5572783e-27 2.7219794e-35], sum to 1.0000
[2019-03-23 00:11:16,077] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5426
[2019-03-23 00:11:16,082] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.18333333333334, 57.33333333333334, 1.0, 2.0, 0.5425585088758812, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354103, 618447.8604554834, 618447.8604554838, 144062.1976135082], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6007800.0000, 
sim time next is 6008400.0000, 
raw observation next is [26.1, 58.0, 1.0, 2.0, 0.5720666396601984, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 652171.7836747037, 652171.7836747037, 147697.0857977844], 
processed observation next is [1.0, 0.5652173913043478, 0.8227272727272728, 0.58, 1.0, 1.0, 0.465083299575248, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.24154510506470506, 0.24154510506470506, 0.3602367946287425], 
reward next is 0.6398, 
noisyNet noise sample is [array([-0.2996321], dtype=float32), 0.49923253]. 
=============================================
[2019-03-23 00:11:16,510] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:11:16,516] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6852
[2019-03-23 00:11:16,520] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 78.66666666666667, 1.0, 2.0, 0.4435059535606314, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 505332.2363411403, 505332.2363411401, 132878.4494398063], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6024000.0000, 
sim time next is 6024600.0000, 
raw observation next is [22.15, 78.5, 1.0, 2.0, 0.4211334556686485, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 478998.4832059041, 478998.4832059041, 129707.2863533747], 
processed observation next is [1.0, 0.7391304347826086, 0.6431818181818181, 0.785, 1.0, 1.0, 0.2764168195858106, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17740684563181633, 0.17740684563181633, 0.316359235008231], 
reward next is 0.6836, 
noisyNet noise sample is [array([0.9855844], dtype=float32), -0.863416]. 
=============================================
[2019-03-23 00:11:16,693] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:11:16,701] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5777
[2019-03-23 00:11:16,707] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.08333333333334, 78.0, 1.0, 2.0, 0.3614013664797965, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 403041.3700029799, 403041.3700029802, 119435.7380630499], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6033000.0000, 
sim time next is 6033600.0000, 
raw observation next is [20.0, 78.0, 1.0, 2.0, 0.3585110038058215, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 399367.7840600715, 399367.7840600715, 119007.5550599391], 
processed observation next is [1.0, 0.8695652173913043, 0.5454545454545454, 0.78, 1.0, 1.0, 0.19813875475727688, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14791399409632278, 0.14791399409632278, 0.2902623294144856], 
reward next is 0.7097, 
noisyNet noise sample is [array([1.8169163], dtype=float32), -0.12553568]. 
=============================================
[2019-03-23 00:11:23,478] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:11:23,483] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8280
[2019-03-23 00:11:23,490] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.28333333333333, 83.0, 1.0, 2.0, 0.301446725863713, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 327327.1453744636, 327327.1453744639, 104100.9307799062], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6151800.0000, 
sim time next is 6152400.0000, 
raw observation next is [17.2, 84.0, 1.0, 2.0, 0.3005237349475137, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 326324.5756914483, 326324.5756914483, 104609.3654432452], 
processed observation next is [1.0, 0.21739130434782608, 0.41818181818181815, 0.84, 1.0, 1.0, 0.12565466868439212, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12086095395979567, 0.12086095395979567, 0.25514479376401267], 
reward next is 0.7449, 
noisyNet noise sample is [array([0.20532987], dtype=float32), 1.2064819]. 
=============================================
[2019-03-23 00:11:25,490] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.5257546e-35 1.0000000e+00 7.6123167e-27 3.1283914e-21 7.1332211e-24], sum to 1.0000
[2019-03-23 00:11:25,510] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3085
[2019-03-23 00:11:25,520] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.7, 62.83333333333334, 1.0, 2.0, 0.8696301762642151, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 977830.1510261882, 977830.1510261882, 180473.6499604234], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6192600.0000, 
sim time next is 6193200.0000, 
raw observation next is [22.7, 61.66666666666667, 1.0, 2.0, 0.8032887417565142, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 901376.305422245, 901376.305422245, 169937.1445397969], 
processed observation next is [1.0, 0.6956521739130435, 0.6681818181818181, 0.6166666666666667, 1.0, 1.0, 0.7541109271956428, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.33384307608231295, 0.33384307608231295, 0.41448084034096805], 
reward next is 0.5855, 
noisyNet noise sample is [array([0.6393959], dtype=float32), 2.4432194]. 
=============================================
[2019-03-23 00:11:26,119] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.3814125e-35 1.0000000e+00 9.1638760e-26 1.0171614e-33 8.0277315e-28], sum to 1.0000
[2019-03-23 00:11:26,129] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8514
[2019-03-23 00:11:26,133] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 63.0, 1.0, 2.0, 0.7974092338583135, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 898733.225115499, 898733.225115499, 171044.4216257751], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6186600.0000, 
sim time next is 6187200.0000, 
raw observation next is [23.1, 62.0, 1.0, 2.0, 0.7976801594589442, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 898545.3379758967, 898545.3379758967, 170829.6250690989], 
processed observation next is [1.0, 0.6086956521739131, 0.6863636363636364, 0.62, 1.0, 1.0, 0.7471001993236803, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3327945696207025, 0.3327945696207025, 0.4166576221197534], 
reward next is 0.5833, 
noisyNet noise sample is [array([-2.8298259], dtype=float32), 0.25183222]. 
=============================================
[2019-03-23 00:11:43,385] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.0705272e-37 0.0000000e+00], sum to 1.0000
[2019-03-23 00:11:43,388] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4483
[2019-03-23 00:11:43,392] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 51.0, 1.0, 2.0, 0.4532876499776428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 492287.6941906651, 492287.6941906651, 106779.5530718124], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6534600.0000, 
sim time next is 6535200.0000, 
raw observation next is [20.5, 51.00000000000001, 1.0, 2.0, 0.4515697544751163, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 490421.0530130503, 490421.0530130503, 106648.6816045663], 
processed observation next is [1.0, 0.6521739130434783, 0.5681818181818182, 0.5100000000000001, 1.0, 1.0, 0.3144621930938954, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18163742704187047, 0.18163742704187047, 0.26011873562089344], 
reward next is 0.7399, 
noisyNet noise sample is [array([0.74144375], dtype=float32), -0.6855493]. 
=============================================
[2019-03-23 00:11:44,874] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:11:44,884] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2460
[2019-03-23 00:11:44,889] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.7, 58.0, 1.0, 2.0, 0.4972360187250106, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 566917.837599674, 566917.837599674, 141980.2583644099], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6957000.0000, 
sim time next is 6957600.0000, 
raw observation next is [27.7, 58.0, 1.0, 2.0, 0.4979496732111359, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 567731.652745638, 567731.652745638, 142064.205959798], 
processed observation next is [0.0, 0.5217391304347826, 0.8954545454545454, 0.58, 1.0, 1.0, 0.37243709151391985, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21027098249838447, 0.21027098249838447, 0.3464980633165805], 
reward next is 0.6535, 
noisyNet noise sample is [array([1.5956111], dtype=float32), -0.26971933]. 
=============================================
[2019-03-23 00:11:45,762] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-23 00:11:45,764] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 00:11:45,765] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:11:45,766] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 00:11:45,768] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 00:11:45,769] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 00:11:45,768] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 00:11:45,771] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:11:45,772] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:11:45,773] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:11:45,772] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:11:45,790] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run42
[2019-03-23 00:11:45,791] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run42
[2019-03-23 00:11:45,791] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run42
[2019-03-23 00:11:45,813] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run42
[2019-03-23 00:11:45,854] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run42
[2019-03-23 00:12:08,798] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.3762295], dtype=float32), 0.12224171]
[2019-03-23 00:12:08,799] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.851743495, 88.94590449, 1.0, 2.0, 0.4088183778596122, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 462161.8506949283, 462161.8506949283, 130804.1589987651]
[2019-03-23 00:12:08,800] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 00:12:08,804] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.2792021947439539
[2019-03-23 00:12:37,947] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.3762295], dtype=float32), 0.12224171]
[2019-03-23 00:12:37,950] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.72967686, 82.83500008, 1.0, 2.0, 0.3730064524126205, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 418315.5237918857, 418315.5237918854, 125762.3635523607]
[2019-03-23 00:12:37,951] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 00:12:37,958] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.3481860292059281
[2019-03-23 00:12:46,163] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.3762295], dtype=float32), 0.12224171]
[2019-03-23 00:12:46,165] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.38971473833333, 86.92509982166668, 1.0, 2.0, 0.4068285976683907, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 460727.6110880777, 460727.6110880773, 131129.0325768515]
[2019-03-23 00:12:46,166] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 00:12:46,168] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.5614219435999251
[2019-03-23 00:12:55,714] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.3762295], dtype=float32), 0.12224171]
[2019-03-23 00:12:55,718] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [25.78333333333333, 45.5, 1.0, 2.0, 0.4031887118884837, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 450855.1405651059, 450855.1405651055, 127783.568160504]
[2019-03-23 00:12:55,721] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 00:12:55,726] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.6487767145423673
[2019-03-23 00:13:06,515] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.3762295], dtype=float32), 0.12224171]
[2019-03-23 00:13:06,516] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.41878502666667, 70.53651396333333, 1.0, 2.0, 0.3722337381079715, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 416665.181256627, 416665.1812566267, 125330.0650115733]
[2019-03-23 00:13:06,518] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 00:13:06,520] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.17383965448605565
[2019-03-23 00:13:22,519] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.3762295], dtype=float32), 0.12224171]
[2019-03-23 00:13:22,523] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.8, 85.5, 1.0, 2.0, 0.4666054229038904, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 531874.1369296007, 531874.1369296007, 139984.0796114333]
[2019-03-23 00:13:22,524] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 00:13:22,528] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 1.205593e-34 0.000000e+00], sampled 0.3118483459160827
[2019-03-23 00:13:32,316] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1148 1656229146.4555 80.0000
[2019-03-23 00:13:32,509] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2492 1773187030.7201 173.0000
[2019-03-23 00:13:32,608] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3485 1683325900.1134 214.0000
[2019-03-23 00:13:32,680] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 00:13:32,715] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 00:13:33,730] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 1025000, evaluation results [1025000.0, 8512.249193409023, 1773187030.7201214, 173.0, 9061.114827412715, 1656229146.4555063, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8574.348472942609, 1683325900.1133502, 214.0]
[2019-03-23 00:13:33,967] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:13:33,976] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2775
[2019-03-23 00:13:33,981] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [11.26666666666667, 99.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 186876.5911965371, 186876.5911965374, 64731.04202530918], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6583200.0000, 
sim time next is 6583800.0000, 
raw observation next is [11.18333333333333, 99.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 185921.5127625856, 185921.5127625856, 64517.16664973696], 
processed observation next is [1.0, 0.17391304347826086, 0.14469696969696955, 0.995, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.06885981954169837, 0.06885981954169837, 0.1573589430481389], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.1866182], dtype=float32), -0.45142642]. 
=============================================
[2019-03-23 00:13:37,369] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:13:37,377] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6567
[2019-03-23 00:13:37,381] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.68333333333334, 76.83333333333333, 1.0, 2.0, 0.3702617503533388, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 415088.5302391734, 415088.5302391734, 121138.3205511607], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6634200.0000, 
sim time next is 6634800.0000, 
raw observation next is [20.5, 78.0, 1.0, 2.0, 0.3681872300484931, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 412644.4206890118, 412644.4206890121, 120907.825879663], 
processed observation next is [1.0, 0.8260869565217391, 0.5681818181818182, 0.78, 1.0, 1.0, 0.21023403756061632, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15283126692185622, 0.15283126692185633, 0.294897136291861], 
reward next is 0.7051, 
noisyNet noise sample is [array([-0.21421239], dtype=float32), -1.1897117]. 
=============================================
[2019-03-23 00:13:39,958] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:13:39,971] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0464
[2019-03-23 00:13:39,977] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 96.33333333333334, 1.0, 2.0, 0.3478259850001545, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 386683.3622214906, 386683.3622214906, 117823.1405383825], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7087800.0000, 
sim time next is 7088400.0000, 
raw observation next is [17.7, 97.0, 1.0, 2.0, 0.3502792967285521, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 389835.4046399841, 389835.4046399841, 118194.8286733788], 
processed observation next is [1.0, 0.043478260869565216, 0.44090909090909086, 0.97, 1.0, 1.0, 0.18784912091069014, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1443834831999941, 0.1443834831999941, 0.2882800699350702], 
reward next is 0.7117, 
noisyNet noise sample is [array([0.5719134], dtype=float32), -1.19846]. 
=============================================
[2019-03-23 00:13:42,299] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.0502003e-37 0.0000000e+00], sum to 1.0000
[2019-03-23 00:13:42,307] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2772
[2019-03-23 00:13:42,311] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.1, 94.33333333333334, 1.0, 2.0, 0.3636546725966947, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 405541.5288514088, 405541.5288514088, 119613.6200996865], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6722400.0000, 
sim time next is 6723000.0000, 
raw observation next is [18.0, 95.0, 1.0, 2.0, 0.3622510180098581, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 403832.1682905148, 403832.1682905151, 119437.1688019426], 
processed observation next is [1.0, 0.8260869565217391, 0.45454545454545453, 0.95, 1.0, 1.0, 0.2028137725123226, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1495674697372277, 0.14956746973722782, 0.2913101678096161], 
reward next is 0.7087, 
noisyNet noise sample is [array([0.65215623], dtype=float32), -0.22720325]. 
=============================================
[2019-03-23 00:13:42,320] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[72.52715 ]
 [72.40455 ]
 [72.28292 ]
 [72.1003  ]
 [71.940765]], R is [[72.61465454]
 [72.59677124]
 [72.57894897]
 [72.56147003]
 [72.54455566]].
[2019-03-23 00:13:45,176] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:13:45,183] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2546
[2019-03-23 00:13:45,194] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.41666666666667, 55.66666666666667, 1.0, 2.0, 0.3013995961975344, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 327275.9522154936, 327275.9522154933, 108800.826360246], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7240200.0000, 
sim time next is 7240800.0000, 
raw observation next is [21.23333333333333, 56.33333333333334, 1.0, 2.0, 0.298231520409854, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 323834.7391068159, 323834.7391068159, 107184.2036219408], 
processed observation next is [1.0, 0.8260869565217391, 0.6015151515151514, 0.5633333333333335, 1.0, 1.0, 0.1227894005123175, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11993879226178367, 0.11993879226178367, 0.2614248868827824], 
reward next is 0.7386, 
noisyNet noise sample is [array([0.5205998], dtype=float32), 1.0093162]. 
=============================================
[2019-03-23 00:13:47,261] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:13:47,268] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5636
[2019-03-23 00:13:47,273] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.91666666666667, 76.0, 1.0, 2.0, 0.3767972894353036, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 423025.568578032, 423025.5685780317, 121984.1893526061], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6826200.0000, 
sim time next is 6826800.0000, 
raw observation next is [20.73333333333333, 77.0, 1.0, 2.0, 0.3740592079225367, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 419732.4190587202, 419732.4190587199, 121643.8429275819], 
processed observation next is [0.0, 0.0, 0.5787878787878786, 0.77, 1.0, 1.0, 0.21757400990317088, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1554564515032297, 0.1554564515032296, 0.29669229982337053], 
reward next is 0.7033, 
noisyNet noise sample is [array([0.21971342], dtype=float32), 0.39876014]. 
=============================================
[2019-03-23 00:13:47,308] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:13:47,317] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3519
[2019-03-23 00:13:47,322] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.51666666666667, 75.83333333333334, 1.0, 2.0, 0.3968957413269532, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 448213.447759939, 448213.4477599387, 125101.3588696333], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6822600.0000, 
sim time next is 6823200.0000, 
raw observation next is [21.43333333333334, 75.66666666666667, 1.0, 2.0, 0.3930157224411909, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 443409.8779582518, 443409.8779582518, 124511.8430197089], 
processed observation next is [1.0, 1.0, 0.6106060606060609, 0.7566666666666667, 1.0, 1.0, 0.24126965305148856, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16422588072527844, 0.16422588072527844, 0.30368742199929], 
reward next is 0.6963, 
noisyNet noise sample is [array([0.02287792], dtype=float32), -0.8805018]. 
=============================================
[2019-03-23 00:13:47,511] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:13:47,520] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7883
[2019-03-23 00:13:47,529] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.46666666666667, 95.5, 1.0, 2.0, 0.3340835884599344, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 369275.9006172193, 369275.900617219, 115886.2611264943], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6851400.0000, 
sim time next is 6852000.0000, 
raw observation next is [17.73333333333333, 95.0, 1.0, 2.0, 0.338642414237675, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 375566.0118740706, 375566.0118740706, 116730.6358912148], 
processed observation next is [0.0, 0.30434782608695654, 0.44242424242424233, 0.95, 1.0, 1.0, 0.17330301779709373, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13909852291632246, 0.13909852291632246, 0.2847088680273532], 
reward next is 0.7153, 
noisyNet noise sample is [array([1.0443782], dtype=float32), -0.747113]. 
=============================================
[2019-03-23 00:13:47,536] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[65.92931 ]
 [65.934975]
 [65.89995 ]
 [65.89634 ]
 [65.88897 ]], R is [[65.97759247]
 [66.03517151]
 [66.09356689]
 [66.15135193]
 [66.20851898]].
[2019-03-23 00:13:49,915] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:13:49,922] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1963
[2019-03-23 00:13:49,927] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.46666666666667, 60.66666666666667, 1.0, 2.0, 0.4703362550775331, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 536689.5540262271, 536689.5540262271, 137545.7683330101], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6867600.0000, 
sim time next is 6868200.0000, 
raw observation next is [26.83333333333334, 59.33333333333334, 1.0, 2.0, 0.4738451890068294, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 540688.0024880238, 540688.0024880238, 138154.8452315489], 
processed observation next is [0.0, 0.4782608695652174, 0.8560606060606063, 0.5933333333333334, 1.0, 1.0, 0.34230648625853677, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20025481573630513, 0.20025481573630513, 0.33696303715011927], 
reward next is 0.6630, 
noisyNet noise sample is [array([0.17929725], dtype=float32), 1.1906785]. 
=============================================
[2019-03-23 00:13:51,186] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:13:51,193] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2725
[2019-03-23 00:13:51,198] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.1, 48.33333333333333, 1.0, 2.0, 0.44668386604078, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 509127.8089092245, 509127.8089092245, 133447.9565004793], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6884400.0000, 
sim time next is 6885000.0000, 
raw observation next is [28.0, 48.5, 1.0, 2.0, 0.4447161404168565, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 506802.1577135654, 506802.1577135654, 133127.1096649294], 
processed observation next is [0.0, 0.6956521739130435, 0.9090909090909091, 0.485, 1.0, 1.0, 0.30589517552107054, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18770450285687607, 0.18770450285687607, 0.32470026747543757], 
reward next is 0.6753, 
noisyNet noise sample is [array([-0.66010696], dtype=float32), -0.05189095]. 
=============================================
[2019-03-23 00:13:51,205] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[69.9628  ]
 [69.93722 ]
 [69.91356 ]
 [69.834175]
 [69.75988 ]], R is [[69.9617157 ]
 [69.93661499]
 [69.91125488]
 [69.88531494]
 [69.85769653]].
[2019-03-23 00:13:51,738] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:13:51,748] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6136
[2019-03-23 00:13:51,752] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.73333333333333, 87.33333333333334, 1.0, 2.0, 0.3867595079578893, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 435673.5527790856, 435673.5527790859, 123584.1313514843], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6914400.0000, 
sim time next is 6915000.0000, 
raw observation next is [19.26666666666667, 90.16666666666666, 1.0, 2.0, 0.3839326271964281, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 431948.1401891761, 431948.1401891761, 123052.6574553733], 
processed observation next is [0.0, 0.0, 0.5121212121212122, 0.9016666666666666, 1.0, 1.0, 0.22991578399553514, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1599807926626578, 0.1599807926626578, 0.3001284328179836], 
reward next is 0.6999, 
noisyNet noise sample is [array([-0.5322026], dtype=float32), -1.096779]. 
=============================================
[2019-03-23 00:13:51,765] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[66.11812 ]
 [66.1847  ]
 [66.247055]
 [66.34671 ]
 [66.64222 ]], R is [[66.11962891]
 [66.15701294]
 [66.19281769]
 [66.22714996]
 [66.26016235]].
[2019-03-23 00:13:52,847] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:13:52,859] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3474
[2019-03-23 00:13:52,863] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333334, 66.0, 1.0, 2.0, 0.3497802282563948, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 387337.4399177128, 387337.4399177128, 117359.251648451], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7335600.0000, 
sim time next is 7336200.0000, 
raw observation next is [21.21666666666667, 67.0, 1.0, 2.0, 0.3495370716908358, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 387273.6315223775, 387273.6315223775, 117422.092802038], 
processed observation next is [1.0, 0.9130434782608695, 0.6007575757575758, 0.67, 1.0, 1.0, 0.18692133961354473, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1434346783416213, 0.1434346783416213, 0.2863953482976536], 
reward next is 0.7136, 
noisyNet noise sample is [array([1.9674151], dtype=float32), -0.7943811]. 
=============================================
[2019-03-23 00:13:53,521] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.4102264e-37 0.0000000e+00], sum to 1.0000
[2019-03-23 00:13:53,530] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2257
[2019-03-23 00:13:53,539] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 97.0, 1.0, 2.0, 0.3459509416531273, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 385125.0405190943, 385125.0405190943, 117898.8272986615], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7106400.0000, 
sim time next is 7107000.0000, 
raw observation next is [17.7, 96.33333333333334, 1.0, 2.0, 0.3529078109244196, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 392580.289784138, 392580.2897841383, 118326.8678711814], 
processed observation next is [1.0, 0.2608695652173913, 0.44090909090909086, 0.9633333333333334, 1.0, 1.0, 0.19113476365552445, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1454001073274585, 0.14540010732745864, 0.288602116758979], 
reward next is 0.7114, 
noisyNet noise sample is [array([1.0122176], dtype=float32), -1.6301953]. 
=============================================
[2019-03-23 00:13:53,551] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[70.081985]
 [70.07421 ]
 [70.04999 ]
 [70.02198 ]
 [69.94081 ]], R is [[70.0186615 ]
 [70.03091431]
 [70.04293823]
 [70.05463409]
 [70.06581879]].
[2019-03-23 00:14:04,489] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0.0000000e+00 9.9999583e-01 5.3159226e-24 4.1593476e-06 8.5128130e-19], sum to 1.0000
[2019-03-23 00:14:04,498] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2022
[2019-03-23 00:14:04,502] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.08333333333334, 96.0, 1.0, 2.0, 0.4368728137061176, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 497166.600525184, 497166.600525184, 131520.7631851669], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7600200.0000, 
sim time next is 7600800.0000, 
raw observation next is [20.06666666666667, 96.0, 1.0, 2.0, 0.43627419483389, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 496447.2813604468, 496447.2813604468, 131423.0424030426], 
processed observation next is [0.0, 1.0, 0.5484848484848487, 0.96, 1.0, 1.0, 0.2953427435423625, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18386936346683216, 0.18386936346683216, 0.3205440058610795], 
reward next is 0.6795, 
noisyNet noise sample is [array([1.0305501], dtype=float32), 1.0018786]. 
=============================================
[2019-03-23 00:14:11,748] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 7.617904e-32 0.000000e+00], sum to 1.0000
[2019-03-23 00:14:11,762] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2176
[2019-03-23 00:14:11,765] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.6, 69.0, 1.0, 2.0, 0.2415457885249883, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 262265.9323588029, 262265.9323588026, 78795.63358934512], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7285200.0000, 
sim time next is 7285800.0000, 
raw observation next is [17.15, 66.0, 1.0, 2.0, 0.2352081873699877, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 255382.8760878678, 255382.8760878681, 78574.92772731403], 
processed observation next is [1.0, 0.30434782608695654, 0.41590909090909084, 0.66, 1.0, 1.0, 0.0440102342124846, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.094586250402914, 0.0945862504029141, 0.1916461651885708], 
reward next is 0.8084, 
noisyNet noise sample is [array([0.01196969], dtype=float32), -0.05567239]. 
=============================================
[2019-03-23 00:14:16,181] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 3.228726e-32 0.000000e+00], sum to 1.0000
[2019-03-23 00:14:16,189] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3317
[2019-03-23 00:14:16,195] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.43333333333333, 80.0, 1.0, 2.0, 0.3578949916325798, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 396558.6845474225, 396558.6845474227, 118085.9504579061], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7371600.0000, 
sim time next is 7372200.0000, 
raw observation next is [19.71666666666667, 79.0, 1.0, 2.0, 0.3678748440158748, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 408570.521243733, 408570.521243733, 119258.4074623213], 
processed observation next is [1.0, 0.30434782608695654, 0.5325757575757577, 0.79, 1.0, 1.0, 0.20984355501984345, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15132241527545667, 0.15132241527545667, 0.29087416454224707], 
reward next is 0.7091, 
noisyNet noise sample is [array([0.99794525], dtype=float32), 0.024949884]. 
=============================================
[2019-03-23 00:14:22,970] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-23 00:14:22,972] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 00:14:22,974] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:14:22,976] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 00:14:22,977] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 00:14:22,977] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:14:22,978] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:14:22,978] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 00:14:22,979] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 00:14:22,980] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:14:22,981] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:14:23,001] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run43
[2019-03-23 00:14:23,021] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run43
[2019-03-23 00:14:23,045] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run43
[2019-03-23 00:14:23,069] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run43
[2019-03-23 00:14:23,070] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run43
[2019-03-23 00:14:23,342] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:14:23,343] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:14:23,346] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run6
[2019-03-23 00:14:29,851] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.23254219], dtype=float32), 0.13102977]
[2019-03-23 00:14:29,852] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [11.40237270833333, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 176675.5879625558, 176675.5879625558, 67743.89290124059]
[2019-03-23 00:14:29,854] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 00:14:29,858] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.10834112278817043
[2019-03-23 00:14:54,985] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.23254219], dtype=float32), 0.13102977]
[2019-03-23 00:14:54,986] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [15.46666666666667, 55.33333333333334, 1.0, 2.0, 0.216040504555139, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 234555.3039671204, 234555.3039671204, 75025.11077642806]
[2019-03-23 00:14:54,987] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 00:14:54,988] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.7887483635680161
[2019-03-23 00:15:06,002] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.23254219], dtype=float32), 0.13102977]
[2019-03-23 00:15:06,004] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.2, 84.0, 1.0, 2.0, 0.5225888436204038, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 595902.3233735891, 595902.3233735887, 146523.451987333]
[2019-03-23 00:15:06,006] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 00:15:06,009] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 1.3972937e-38 6.3063309e-35 1.6206063e-36], sampled 0.06350915562110793
[2019-03-23 00:15:29,513] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.23254219], dtype=float32), 0.13102977]
[2019-03-23 00:15:29,516] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.04776507333333, 91.96272271333333, 1.0, 2.0, 0.4360977768463776, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 496868.9001809963, 496868.9001809959, 136467.4659803043]
[2019-03-23 00:15:29,516] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 00:15:29,518] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0.0000000e+00 1.0000000e+00 1.1892121e-36 2.7737484e-36 2.8641213e-37], sampled 0.1187900485424579
[2019-03-23 00:15:49,271] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.23254219], dtype=float32), 0.13102977]
[2019-03-23 00:15:49,272] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [27.8, 64.33333333333334, 1.0, 2.0, 0.5578757538048139, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 632353.1355673892, 632353.1355673892, 151698.8923582014]
[2019-03-23 00:15:49,274] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 00:15:49,277] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 6.9087633e-34 5.1518755e-33 5.9085022e-33], sampled 0.25339457349408057
[2019-03-23 00:15:56,942] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.23254219], dtype=float32), 0.13102977]
[2019-03-23 00:15:56,945] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [14.9, 93.0, 1.0, 2.0, 0.2515413644659047, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 273107.3651802297, 273107.3651802293, 89413.8281186126]
[2019-03-23 00:15:56,945] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 00:15:56,948] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.33485102897993113
[2019-03-23 00:16:01,928] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.23254219], dtype=float32), 0.13102977]
[2019-03-23 00:16:01,929] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.41898222666667, 63.55172895333334, 1.0, 2.0, 0.2881050327928195, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 312816.1653976719, 312816.1653976719, 101383.5613171242]
[2019-03-23 00:16:01,931] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 00:16:01,936] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.837073229101586
[2019-03-23 00:16:05,183] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.23254219], dtype=float32), 0.13102977]
[2019-03-23 00:16:05,185] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [15.0, 81.0, 1.0, 2.0, 0.2049771786315231, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 95.55338769695034, 222541.6209374441, 222541.6209374434, 78884.5404042597]
[2019-03-23 00:16:05,187] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 00:16:05,189] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.23726332887347534
[2019-03-23 00:16:10,705] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2492 1773187030.7201 173.0000
[2019-03-23 00:16:10,708] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1148 1656229146.4555 80.0000
[2019-03-23 00:16:10,809] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9310 1705987275.5940 465.0000
[2019-03-23 00:16:10,811] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8855.7542 1663858414.4981 105.0000
[2019-03-23 00:16:10,834] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3485 1683325900.1134 214.0000
[2019-03-23 00:16:11,850] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 1050000, evaluation results [1050000.0, 8512.249193409023, 1773187030.7201214, 173.0, 9061.114827412715, 1656229146.4555063, 80.0, 8855.754186439062, 1663858414.498091, 105.0, 8596.931041181726, 1705987275.594041, 465.0, 8574.348472942609, 1683325900.1133502, 214.0]
[2019-03-23 00:16:14,803] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.8495600e-31 2.0249738e-34], sum to 1.0000
[2019-03-23 00:16:14,809] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1979
[2019-03-23 00:16:14,813] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 63.0, 1.0, 2.0, 0.5725455457118394, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 622777.9667844238, 622777.9667844238, 133958.6089821036], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7725600.0000, 
sim time next is 7726200.0000, 
raw observation next is [20.68333333333334, 62.0, 1.0, 2.0, 0.5791404196935401, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 630242.3334193669, 630242.3334193669, 134698.7865690122], 
processed observation next is [1.0, 0.43478260869565216, 0.5765151515151519, 0.62, 1.0, 1.0, 0.4739255246169251, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23342308645161736, 0.23342308645161736, 0.32853362577807854], 
reward next is 0.6715, 
noisyNet noise sample is [array([-0.37479508], dtype=float32), 0.39642918]. 
=============================================
[2019-03-23 00:16:14,869] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:16:14,870] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:16:14,944] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run6
[2019-03-23 00:16:19,801] A3C_AGENT_WORKER-Thread-21 INFO:Local step 66500, global step 1054021: loss 0.4904
[2019-03-23 00:16:19,802] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 66500, global step 1054021: learning rate 0.0010
[2019-03-23 00:16:20,115] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.5897860e-38 1.6085009e-01 5.4524583e-24 1.9852524e-20 8.3914989e-01], sum to 1.0000
[2019-03-23 00:16:20,122] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7029
[2019-03-23 00:16:20,127] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.63333333333333, 53.66666666666666, 1.0, 2.0, 0.6118464589534433, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9749861547740958, 6.911199999999999, 6.9112, 77.32846239902521, 1244927.979757715, 1244927.979757715, 277269.6487535921], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7659600.0000, 
sim time next is 7660200.0000, 
raw observation next is [28.71666666666667, 53.33333333333334, 1.0, 2.0, 0.3745067698692794, 1.0, 1.0, 0.3745067698692794, 1.0, 2.0, 0.7582923690952149, 6.911199999999999, 6.9112, 77.3421103, 1272548.840843176, 1272548.840843176, 291802.2688030332], 
processed observation next is [1.0, 0.6521739130434783, 0.9416666666666668, 0.5333333333333334, 1.0, 1.0, 0.21813346233659922, 1.0, 0.5, 0.21813346233659922, 1.0, 1.0, 0.6547033844217357, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.4713143854974726, 0.4713143854974726, 0.7117128507391054], 
reward next is 0.2883, 
noisyNet noise sample is [array([-0.2220441], dtype=float32), 0.1903823]. 
=============================================
[2019-03-23 00:16:24,347] A3C_AGENT_WORKER-Thread-3 INFO:Local step 66500, global step 1056233: loss 1.1835
[2019-03-23 00:16:24,351] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 66500, global step 1056235: learning rate 0.0010
[2019-03-23 00:16:27,284] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:16:27,284] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:16:27,338] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run6
[2019-03-23 00:16:27,694] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:16:27,695] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:16:27,741] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run6
[2019-03-23 00:16:28,361] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.5273809e-28 2.0339143e-35], sum to 1.0000
[2019-03-23 00:16:28,366] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9001
[2019-03-23 00:16:28,369] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.3, 65.5, 1.0, 2.0, 0.2844885489632176, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 308907.1920701596, 308907.1920701599, 98197.78574834878], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7863000.0000, 
sim time next is 7863600.0000, 
raw observation next is [19.2, 66.0, 1.0, 2.0, 0.2812109115149653, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 305347.1062927122, 305347.1062927125, 97498.09123523139], 
processed observation next is [1.0, 0.0, 0.509090909090909, 0.66, 1.0, 1.0, 0.10151363939370661, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11309152084915267, 0.11309152084915278, 0.2378002225249546], 
reward next is 0.7622, 
noisyNet noise sample is [array([0.7621562], dtype=float32), -1.0111935]. 
=============================================
[2019-03-23 00:16:33,812] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:16:33,813] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:16:33,866] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run6
[2019-03-23 00:16:34,359] A3C_AGENT_WORKER-Thread-21 INFO:Local step 67000, global step 1061601: loss 0.8624
[2019-03-23 00:16:34,360] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 67000, global step 1061602: learning rate 0.0010
[2019-03-23 00:16:34,698] A3C_AGENT_WORKER-Thread-14 INFO:Local step 66500, global step 1061835: loss 0.0061
[2019-03-23 00:16:34,698] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 66500, global step 1061835: learning rate 0.0010
[2019-03-23 00:16:34,793] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:16:34,793] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:16:34,801] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run6
[2019-03-23 00:16:34,827] A3C_AGENT_WORKER-Thread-9 INFO:Local step 66500, global step 1061906: loss 0.1082
[2019-03-23 00:16:34,828] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 66500, global step 1061906: learning rate 0.0010
[2019-03-23 00:16:34,895] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:16:34,895] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:16:34,935] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run6
[2019-03-23 00:16:35,065] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:16:35,067] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:16:35,094] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run6
[2019-03-23 00:16:35,131] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:16:35,132] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:16:35,166] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run6
[2019-03-23 00:16:35,182] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:16:35,183] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:16:35,185] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:16:35,186] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:16:35,201] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run6
[2019-03-23 00:16:35,226] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:16:35,226] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:16:35,231] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run6
[2019-03-23 00:16:35,256] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run6
[2019-03-23 00:16:35,331] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:16:35,331] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:16:35,337] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run6
[2019-03-23 00:16:35,373] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:16:35,373] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:16:35,385] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:16:35,385] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:16:35,386] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run6
[2019-03-23 00:16:35,419] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:16:35,420] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:16:35,425] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run6
[2019-03-23 00:16:35,485] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run6
[2019-03-23 00:16:35,846] A3C_AGENT_WORKER-Thread-3 INFO:Local step 67000, global step 1062259: loss 0.9483
[2019-03-23 00:16:35,847] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 67000, global step 1062259: learning rate 0.0010
[2019-03-23 00:16:36,595] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.7149176e-07 1.7200866e-04 8.3201115e-07 9.9844688e-01 1.3795599e-03], sum to 1.0000
[2019-03-23 00:16:36,595] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7027
[2019-03-23 00:16:36,599] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [16.0, 77.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.3421103, 248870.1657131537, 248870.165713154, 123315.4862049807], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 0.0000, 
sim time next is 600.0000, 
raw observation next is [16.33333333333334, 78.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 260416.6534407383, 260416.6534407383, 107957.3741427992], 
processed observation next is [1.0, 0.0, 0.37878787878787906, 0.78, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09645061238545863, 0.09645061238545863, 0.2633106686409737], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.5900556], dtype=float32), 0.7075102]. 
=============================================
[2019-03-23 00:16:38,328] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.0008691e-32 2.4223851e-33 4.4540060e-32], sum to 1.0000
[2019-03-23 00:16:38,338] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6751
[2019-03-23 00:16:38,344] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 82.0, 1.0, 2.0, 0.2731502582549608, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 296591.9422032624, 296591.9422032624, 95370.44861418247], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 608400.0000, 
sim time next is 609000.0000, 
raw observation next is [16.83333333333334, 83.00000000000001, 1.0, 2.0, 0.2699893623549307, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 293158.7445951381, 293158.7445951384, 94393.69028527121], 
processed observation next is [1.0, 0.043478260869565216, 0.40151515151515177, 0.8300000000000002, 1.0, 1.0, 0.08748670294366337, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10857731281301412, 0.10857731281301422, 0.23022851289090537], 
reward next is 0.7698, 
noisyNet noise sample is [array([0.36701226], dtype=float32), -1.3861508]. 
=============================================
[2019-03-23 00:16:38,360] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[64.69757 ]
 [64.67729 ]
 [64.5795  ]
 [64.47813 ]
 [64.311935]], R is [[64.70040894]
 [64.82079315]
 [64.93215942]
 [65.03361511]
 [65.12392426]].
[2019-03-23 00:16:38,972] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.4581389e-35 6.4549485e-20 1.8852678e-19 9.9998152e-01 1.8429195e-05], sum to 1.0000
[2019-03-23 00:16:38,979] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7553
[2019-03-23 00:16:38,989] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.33333333333334, 90.33333333333334, 1.0, 2.0, 0.4330192166269496, 1.0, 2.0, 0.4330192166269496, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 988378.1427469407, 988378.1427469405, 209108.078312096], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 55200.0000, 
sim time next is 55800.0000, 
raw observation next is [20.5, 88.5, 1.0, 2.0, 0.4436751977687327, 1.0, 2.0, 0.4436751977687327, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1012610.768687609, 1012610.768687609, 211054.357995063], 
processed observation next is [1.0, 0.6521739130434783, 0.5681818181818182, 0.885, 1.0, 1.0, 0.30459399721091585, 1.0, 1.0, 0.30459399721091585, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3750410254398552, 0.3750410254398552, 0.5147667268172268], 
reward next is 0.4852, 
noisyNet noise sample is [array([-1.6243166], dtype=float32), -0.27898046]. 
=============================================
[2019-03-23 00:16:41,209] A3C_AGENT_WORKER-Thread-2 INFO:Local step 66500, global step 1065024: loss 11.1368
[2019-03-23 00:16:41,214] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 66500, global step 1065025: learning rate 0.0010
[2019-03-23 00:16:42,982] A3C_AGENT_WORKER-Thread-15 INFO:Local step 66500, global step 1066013: loss 7.2783
[2019-03-23 00:16:42,984] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 66500, global step 1066013: learning rate 0.0010
[2019-03-23 00:16:43,786] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.3945053e-36 9.9904984e-01 1.2185425e-27 9.5014722e-04 1.9328062e-15], sum to 1.0000
[2019-03-23 00:16:43,792] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0063
[2019-03-23 00:16:43,797] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 42.5, 1.0, 2.0, 0.6517314308310399, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 707962.1815320924, 707962.1815320924, 135615.846536263], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 138600.0000, 
sim time next is 139200.0000, 
raw observation next is [23.0, 42.0, 1.0, 2.0, 0.7342171632312736, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 797638.2505410004, 797638.2505410004, 144954.1303131757], 
processed observation next is [1.0, 0.6086956521739131, 0.6818181818181818, 0.42, 1.0, 1.0, 0.6677714540390919, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2954215742744446, 0.2954215742744446, 0.35354665930042856], 
reward next is 0.6465, 
noisyNet noise sample is [array([0.23244618], dtype=float32), -0.47310185]. 
=============================================
[2019-03-23 00:16:43,922] A3C_AGENT_WORKER-Thread-18 INFO:Local step 66500, global step 1066467: loss 0.8962
[2019-03-23 00:16:43,928] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 66500, global step 1066467: learning rate 0.0010
[2019-03-23 00:16:44,092] A3C_AGENT_WORKER-Thread-20 INFO:Local step 66500, global step 1066545: loss 0.5884
[2019-03-23 00:16:44,095] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 66500, global step 1066546: learning rate 0.0010
[2019-03-23 00:16:44,214] A3C_AGENT_WORKER-Thread-11 INFO:Local step 66500, global step 1066604: loss 1.1695
[2019-03-23 00:16:44,215] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 66500, global step 1066604: learning rate 0.0010
[2019-03-23 00:16:44,263] A3C_AGENT_WORKER-Thread-12 INFO:Local step 66500, global step 1066628: loss 1.1914
[2019-03-23 00:16:44,268] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 66500, global step 1066628: learning rate 0.0010
[2019-03-23 00:16:44,312] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.7112234e-30 3.5123295e-14 4.3990385e-19], sum to 1.0000
[2019-03-23 00:16:44,319] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3831
[2019-03-23 00:16:44,323] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333334, 44.0, 1.0, 2.0, 0.2963405640984612, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 321780.7646069791, 321780.7646069794, 87671.68328800793], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 152400.0000, 
sim time next is 153000.0000, 
raw observation next is [21.0, 44.5, 1.0, 2.0, 0.2926455876972428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 317767.2715849855, 317767.2715849853, 86301.49899866169], 
processed observation next is [1.0, 0.782608695652174, 0.5909090909090909, 0.445, 1.0, 1.0, 0.11580698462155349, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11769158206851314, 0.11769158206851307, 0.21049146097234558], 
reward next is 0.7895, 
noisyNet noise sample is [array([-0.17610352], dtype=float32), -0.42420942]. 
=============================================
[2019-03-23 00:16:44,333] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[71.56306]
 [71.1586 ]
 [70.9027 ]
 [70.72465]
 [70.75822]], R is [[71.92514038]
 [71.99205017]
 [72.05495453]
 [72.11392212]
 [72.17224884]].
[2019-03-23 00:16:44,383] A3C_AGENT_WORKER-Thread-19 INFO:Local step 66500, global step 1066692: loss 0.0627
[2019-03-23 00:16:44,386] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 66500, global step 1066693: learning rate 0.0010
[2019-03-23 00:16:44,469] A3C_AGENT_WORKER-Thread-16 INFO:Local step 66500, global step 1066733: loss 0.2923
[2019-03-23 00:16:44,471] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 66500, global step 1066733: learning rate 0.0010
[2019-03-23 00:16:44,508] A3C_AGENT_WORKER-Thread-22 INFO:Local step 66500, global step 1066752: loss 4.6016
[2019-03-23 00:16:44,511] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 66500, global step 1066752: learning rate 0.0010
[2019-03-23 00:16:44,678] A3C_AGENT_WORKER-Thread-13 INFO:Local step 66500, global step 1066836: loss 5.2087
[2019-03-23 00:16:44,680] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 66500, global step 1066836: learning rate 0.0010
[2019-03-23 00:16:44,822] A3C_AGENT_WORKER-Thread-17 INFO:Local step 66500, global step 1066908: loss 0.6253
[2019-03-23 00:16:44,828] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 66500, global step 1066909: learning rate 0.0010
[2019-03-23 00:16:44,947] A3C_AGENT_WORKER-Thread-10 INFO:Local step 66500, global step 1066962: loss 2.4848
[2019-03-23 00:16:44,950] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 66500, global step 1066962: learning rate 0.0010
[2019-03-23 00:16:45,895] A3C_AGENT_WORKER-Thread-21 INFO:Local step 67500, global step 1067428: loss 7.8981
[2019-03-23 00:16:45,897] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 67500, global step 1067428: learning rate 0.0010
[2019-03-23 00:16:47,286] A3C_AGENT_WORKER-Thread-14 INFO:Local step 67000, global step 1068113: loss 5.3860
[2019-03-23 00:16:47,290] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 67000, global step 1068113: learning rate 0.0010
[2019-03-23 00:16:47,901] A3C_AGENT_WORKER-Thread-9 INFO:Local step 67000, global step 1068413: loss 0.3975
[2019-03-23 00:16:47,904] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 67000, global step 1068413: learning rate 0.0010
[2019-03-23 00:16:50,634] A3C_AGENT_WORKER-Thread-3 INFO:Local step 67500, global step 1069745: loss 2.8227
[2019-03-23 00:16:50,635] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 67500, global step 1069745: learning rate 0.0010
[2019-03-23 00:16:56,743] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.5741745e-31 3.8998753e-19 2.4667982e-20], sum to 1.0000
[2019-03-23 00:16:56,754] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6459
[2019-03-23 00:16:56,760] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 94.0, 1.0, 2.0, 0.3971712909049521, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 447575.7079043476, 447575.7079043476, 124601.5513932718], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 876000.0000, 
sim time next is 876600.0000, 
raw observation next is [19.0, 94.0, 1.0, 2.0, 0.3963890669487806, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 446692.9677462039, 446692.9677462039, 124530.7606700649], 
processed observation next is [0.0, 0.13043478260869565, 0.5, 0.94, 1.0, 1.0, 0.24548633368597575, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16544183990600145, 0.16544183990600145, 0.3037335626099144], 
reward next is 0.6963, 
noisyNet noise sample is [array([0.13066007], dtype=float32), -0.68774724]. 
=============================================
[2019-03-23 00:16:56,954] A3C_AGENT_WORKER-Thread-2 INFO:Local step 67000, global step 1073039: loss 0.0803
[2019-03-23 00:16:56,956] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 67000, global step 1073039: learning rate 0.0010
[2019-03-23 00:16:58,893] A3C_AGENT_WORKER-Thread-15 INFO:Local step 67000, global step 1073962: loss 0.4606
[2019-03-23 00:16:58,897] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 67000, global step 1073964: learning rate 0.0010
[2019-03-23 00:16:59,932] A3C_AGENT_WORKER-Thread-18 INFO:Local step 67000, global step 1074491: loss 0.6187
[2019-03-23 00:16:59,932] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 67000, global step 1074492: learning rate 0.0010
[2019-03-23 00:17:00,013] A3C_AGENT_WORKER-Thread-20 INFO:Local step 67000, global step 1074538: loss 0.2876
[2019-03-23 00:17:00,014] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 67000, global step 1074538: learning rate 0.0010
[2019-03-23 00:17:00,032] A3C_AGENT_WORKER-Thread-11 INFO:Local step 67000, global step 1074548: loss 0.1863
[2019-03-23 00:17:00,035] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 67000, global step 1074549: learning rate 0.0010
[2019-03-23 00:17:00,143] A3C_AGENT_WORKER-Thread-12 INFO:Local step 67000, global step 1074619: loss 0.1814
[2019-03-23 00:17:00,150] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 67000, global step 1074619: learning rate 0.0010
[2019-03-23 00:17:00,178] A3C_AGENT_WORKER-Thread-19 INFO:Local step 67000, global step 1074638: loss 0.2971
[2019-03-23 00:17:00,178] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 67000, global step 1074638: learning rate 0.0010
[2019-03-23 00:17:00,273] A3C_AGENT_WORKER-Thread-22 INFO:Local step 67000, global step 1074702: loss 0.0859
[2019-03-23 00:17:00,276] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 67000, global step 1074705: learning rate 0.0010
[2019-03-23 00:17:00,283] A3C_AGENT_WORKER-Thread-16 INFO:Local step 67000, global step 1074707: loss 0.0856
[2019-03-23 00:17:00,287] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 67000, global step 1074707: learning rate 0.0010
[2019-03-23 00:17:00,623] A3C_AGENT_WORKER-Thread-13 INFO:Local step 67000, global step 1074905: loss 0.1513
[2019-03-23 00:17:00,625] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 67000, global step 1074905: learning rate 0.0010
[2019-03-23 00:17:00,667] A3C_AGENT_WORKER-Thread-17 INFO:Local step 67000, global step 1074933: loss 0.0874
[2019-03-23 00:17:00,668] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 67000, global step 1074934: learning rate 0.0010
[2019-03-23 00:17:00,755] A3C_AGENT_WORKER-Thread-10 INFO:Local step 67000, global step 1074985: loss 0.1268
[2019-03-23 00:17:00,758] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 67000, global step 1074987: learning rate 0.0010
[2019-03-23 00:17:00,781] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-23 00:17:00,784] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 00:17:00,784] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 00:17:00,785] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:17:00,785] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 00:17:00,785] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:17:00,788] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 00:17:00,788] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:17:00,790] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:17:00,787] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 00:17:00,793] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:17:00,805] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run44
[2019-03-23 00:17:00,823] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run44
[2019-03-23 00:17:00,855] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run44
[2019-03-23 00:17:00,855] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run44
[2019-03-23 00:17:00,855] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run44
[2019-03-23 00:17:15,533] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.33405474], dtype=float32), 0.21331096]
[2019-03-23 00:17:15,534] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [10.477395374, 93.73203850499999, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 180166.21989132, 180166.2198913197, 66710.29088158943]
[2019-03-23 00:17:15,535] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 00:17:15,538] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.7843043e-31 1.4151580e-36], sampled 0.8996730183254473
[2019-03-23 00:18:29,304] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.33405474], dtype=float32), 0.21331096]
[2019-03-23 00:18:29,304] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.55, 71.0, 1.0, 2.0, 0.4538377506449927, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 516730.3040449063, 516730.3040449063, 137874.3233943393]
[2019-03-23 00:18:29,305] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 00:18:29,309] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 1.3051932e-35 9.6461179e-23 6.8249353e-28], sampled 0.18997156077284694
[2019-03-23 00:18:37,445] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.33405474], dtype=float32), 0.21331096]
[2019-03-23 00:18:37,447] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.5, 59.0, 1.0, 2.0, 0.2965850659495595, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 322046.34432496, 322046.3443249597, 102223.5388557349]
[2019-03-23 00:18:37,448] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 00:18:37,451] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.4543016e-29 1.9506928e-33], sampled 0.502438425419322
[2019-03-23 00:18:46,019] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8583.7000 1683855284.3439 178.0000
[2019-03-23 00:18:46,236] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1147 1656209757.7786 80.0000
[2019-03-23 00:18:46,329] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8501.9763 1778141252.0086 157.0000
[2019-03-23 00:18:46,401] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8855.9041 1663892265.1130 104.0000
[2019-03-23 00:18:46,416] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8598.7192 1706360615.0410 452.0000
[2019-03-23 00:18:47,434] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 1075000, evaluation results [1075000.0, 8501.976340091449, 1778141252.0086281, 157.0, 9061.114669779829, 1656209757.7786272, 80.0, 8855.904103732992, 1663892265.1130486, 104.0, 8598.719197571165, 1706360615.0409527, 452.0, 8583.700044304887, 1683855284.3439043, 178.0]
[2019-03-23 00:18:48,324] A3C_AGENT_WORKER-Thread-21 INFO:Local step 68000, global step 1075452: loss 6.2364
[2019-03-23 00:18:48,329] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 68000, global step 1075455: learning rate 0.0010
[2019-03-23 00:18:49,871] A3C_AGENT_WORKER-Thread-14 INFO:Local step 67500, global step 1076196: loss 28.3368
[2019-03-23 00:18:49,873] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 67500, global step 1076196: learning rate 0.0010
[2019-03-23 00:18:50,502] A3C_AGENT_WORKER-Thread-9 INFO:Local step 67500, global step 1076507: loss 34.4059
[2019-03-23 00:18:50,506] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 67500, global step 1076508: learning rate 0.0010
[2019-03-23 00:18:52,978] A3C_AGENT_WORKER-Thread-3 INFO:Local step 68000, global step 1077720: loss 7.2676
[2019-03-23 00:18:52,984] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 68000, global step 1077720: learning rate 0.0010
[2019-03-23 00:18:58,735] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.0521765e-31 6.7718368e-24 7.8159445e-26], sum to 1.0000
[2019-03-23 00:18:58,741] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6156
[2019-03-23 00:18:58,746] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.66666666666666, 69.66666666666667, 1.0, 2.0, 0.6368251089217385, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 726023.0572199603, 726023.0572199603, 159971.5686288901], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1168800.0000, 
sim time next is 1169400.0000, 
raw observation next is [25.83333333333334, 69.83333333333333, 1.0, 2.0, 0.6295202847422946, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 717292.5309884605, 717292.5309884608, 159374.6049242349], 
processed observation next is [1.0, 0.5217391304347826, 0.8106060606060609, 0.6983333333333333, 1.0, 1.0, 0.5369003559278682, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2656639003660965, 0.26566390036609655, 0.3887185485956949], 
reward next is 0.6113, 
noisyNet noise sample is [array([0.97176594], dtype=float32), 2.112921]. 
=============================================
[2019-03-23 00:18:59,519] A3C_AGENT_WORKER-Thread-2 INFO:Local step 67500, global step 1081141: loss 39.9947
[2019-03-23 00:18:59,522] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 67500, global step 1081141: learning rate 0.0010
[2019-03-23 00:19:01,312] A3C_AGENT_WORKER-Thread-15 INFO:Local step 67500, global step 1082016: loss 22.0088
[2019-03-23 00:19:01,315] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 67500, global step 1082017: learning rate 0.0010
[2019-03-23 00:19:01,577] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 3.0122232e-26 1.3713354e-29 5.3729871e-17], sum to 1.0000
[2019-03-23 00:19:01,588] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1588
[2019-03-23 00:19:01,595] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1355328.007270749 W.
[2019-03-23 00:19:01,600] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.5, 56.5, 1.0, 2.0, 0.7079590690426799, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9735626810047452, 6.911199999999999, 6.9112, 77.32846344354104, 1355328.007270749, 1355328.007270749, 289609.8062599845], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 739800.0000, 
sim time next is 740400.0000, 
raw observation next is [27.33333333333334, 57.0, 1.0, 2.0, 0.5893619838099757, 1.0, 1.0, 0.5893619838099757, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1340254.27807883, 1340254.27807883, 254376.1242107963], 
processed observation next is [1.0, 0.5652173913043478, 0.878787878787879, 0.57, 1.0, 1.0, 0.4867024797624696, 1.0, 0.5, 0.4867024797624696, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.49639047336252967, 0.49639047336252967, 0.6204295712458446], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.7178859], dtype=float32), -0.11549236]. 
=============================================
[2019-03-23 00:19:02,384] A3C_AGENT_WORKER-Thread-18 INFO:Local step 67500, global step 1082536: loss 10.4739
[2019-03-23 00:19:02,389] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 67500, global step 1082536: learning rate 0.0010
[2019-03-23 00:19:02,498] A3C_AGENT_WORKER-Thread-11 INFO:Local step 67500, global step 1082593: loss 41.7730
[2019-03-23 00:19:02,500] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 67500, global step 1082594: learning rate 0.0010
[2019-03-23 00:19:02,519] A3C_AGENT_WORKER-Thread-20 INFO:Local step 67500, global step 1082601: loss 16.9253
[2019-03-23 00:19:02,521] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 67500, global step 1082601: learning rate 0.0010
[2019-03-23 00:19:02,564] A3C_AGENT_WORKER-Thread-12 INFO:Local step 67500, global step 1082621: loss 15.3562
[2019-03-23 00:19:02,568] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 67500, global step 1082622: learning rate 0.0010
[2019-03-23 00:19:02,611] A3C_AGENT_WORKER-Thread-19 INFO:Local step 67500, global step 1082643: loss 12.8098
[2019-03-23 00:19:02,615] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 67500, global step 1082644: learning rate 0.0010
[2019-03-23 00:19:02,680] A3C_AGENT_WORKER-Thread-22 INFO:Local step 67500, global step 1082680: loss 10.1963
[2019-03-23 00:19:02,682] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 67500, global step 1082680: learning rate 0.0010
[2019-03-23 00:19:02,731] A3C_AGENT_WORKER-Thread-16 INFO:Local step 67500, global step 1082700: loss 10.1748
[2019-03-23 00:19:02,734] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 67500, global step 1082701: learning rate 0.0010
[2019-03-23 00:19:03,016] A3C_AGENT_WORKER-Thread-17 INFO:Local step 67500, global step 1082844: loss 8.2832
[2019-03-23 00:19:03,020] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 67500, global step 1082845: learning rate 0.0010
[2019-03-23 00:19:03,258] A3C_AGENT_WORKER-Thread-13 INFO:Local step 67500, global step 1082969: loss 9.6347
[2019-03-23 00:19:03,260] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 67500, global step 1082969: learning rate 0.0010
[2019-03-23 00:19:03,363] A3C_AGENT_WORKER-Thread-10 INFO:Local step 67500, global step 1083028: loss 6.5674
[2019-03-23 00:19:03,365] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 67500, global step 1083028: learning rate 0.0010
[2019-03-23 00:19:04,300] A3C_AGENT_WORKER-Thread-21 INFO:Local step 68500, global step 1083562: loss -246.2160
[2019-03-23 00:19:04,303] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 68500, global step 1083563: learning rate 0.0010
[2019-03-23 00:19:05,136] A3C_AGENT_WORKER-Thread-14 INFO:Local step 68000, global step 1084070: loss 16.8782
[2019-03-23 00:19:05,137] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 68000, global step 1084070: learning rate 0.0010
[2019-03-23 00:19:05,674] A3C_AGENT_WORKER-Thread-9 INFO:Local step 68000, global step 1084407: loss 15.4272
[2019-03-23 00:19:05,677] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 68000, global step 1084408: learning rate 0.0010
[2019-03-23 00:19:08,665] A3C_AGENT_WORKER-Thread-3 INFO:Local step 68500, global step 1085909: loss -227.3648
[2019-03-23 00:19:08,666] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 68500, global step 1085910: learning rate 0.0010
[2019-03-23 00:19:10,420] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:19:10,433] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2737
[2019-03-23 00:19:10,440] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.83333333333333, 74.66666666666667, 1.0, 2.0, 0.4650822601430931, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 530623.6334780683, 530623.6334780683, 136471.8561311964], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 913800.0000, 
sim time next is 914400.0000, 
raw observation next is [24.0, 74.0, 1.0, 2.0, 0.4670462236261512, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 532894.9632400925, 532894.9632400925, 136819.3034674335], 
processed observation next is [0.0, 0.6086956521739131, 0.7272727272727273, 0.74, 1.0, 1.0, 0.333807779532689, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19736850490373797, 0.19736850490373797, 0.3337056182132524], 
reward next is 0.6663, 
noisyNet noise sample is [array([-0.25035268], dtype=float32), 0.28334454]. 
=============================================
[2019-03-23 00:19:13,795] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.0475937e-33 5.3856732e-38 0.0000000e+00], sum to 1.0000
[2019-03-23 00:19:13,802] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6144
[2019-03-23 00:19:13,808] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333333, 98.0, 1.0, 2.0, 0.4503761201835743, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 513471.1863817452, 513471.1863817452, 134039.8223614694], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1456800.0000, 
sim time next is 1457400.0000, 
raw observation next is [20.16666666666667, 99.0, 1.0, 2.0, 0.4480995387800268, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 510800.9225733961, 510800.9225733964, 133683.7454875029], 
processed observation next is [0.0, 0.8695652173913043, 0.5530303030303032, 0.99, 1.0, 1.0, 0.31012442347503344, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1891855268790356, 0.1891855268790357, 0.3260579158231778], 
reward next is 0.6739, 
noisyNet noise sample is [array([0.43905482], dtype=float32), -1.4784638]. 
=============================================
[2019-03-23 00:19:14,473] A3C_AGENT_WORKER-Thread-2 INFO:Local step 68000, global step 1089014: loss 9.6680
[2019-03-23 00:19:14,475] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 68000, global step 1089014: learning rate 0.0010
[2019-03-23 00:19:16,137] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:19:16,146] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0811
[2019-03-23 00:19:16,150] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 96.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 215955.5714983086, 215955.5714983089, 72406.91107287286], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1053600.0000, 
sim time next is 1054200.0000, 
raw observation next is [13.0, 95.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 211323.3780308952, 211323.3780308955, 71364.7503523428], 
processed observation next is [1.0, 0.17391304347826086, 0.22727272727272727, 0.95, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07826791778922045, 0.07826791778922056, 0.1740603667130312], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.17652796], dtype=float32), 0.100513116]. 
=============================================
[2019-03-23 00:19:16,225] A3C_AGENT_WORKER-Thread-15 INFO:Local step 68000, global step 1089901: loss 6.1876
[2019-03-23 00:19:16,227] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 68000, global step 1089901: learning rate 0.0010
[2019-03-23 00:19:17,261] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:19:17,268] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5194
[2019-03-23 00:19:17,276] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 97.0, 1.0, 2.0, 0.2034760282791062, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 220921.106046603, 220921.106046603, 73205.59540898693], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1053000.0000, 
sim time next is 1053600.0000, 
raw observation next is [13.0, 96.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 215955.5714983086, 215955.5714983089, 72406.91107287286], 
processed observation next is [1.0, 0.17391304347826086, 0.22727272727272727, 0.96, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07998354499937356, 0.07998354499937367, 0.17660222212895818], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.24602094], dtype=float32), -1.925073]. 
=============================================
[2019-03-23 00:19:17,396] A3C_AGENT_WORKER-Thread-18 INFO:Local step 68000, global step 1090473: loss 4.8734
[2019-03-23 00:19:17,400] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 68000, global step 1090474: learning rate 0.0010
[2019-03-23 00:19:17,456] A3C_AGENT_WORKER-Thread-11 INFO:Local step 68000, global step 1090501: loss 7.1863
[2019-03-23 00:19:17,463] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 68000, global step 1090502: learning rate 0.0010
[2019-03-23 00:19:17,484] A3C_AGENT_WORKER-Thread-20 INFO:Local step 68000, global step 1090511: loss 8.2185
[2019-03-23 00:19:17,486] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 68000, global step 1090511: learning rate 0.0010
[2019-03-23 00:19:17,557] A3C_AGENT_WORKER-Thread-12 INFO:Local step 68000, global step 1090551: loss 6.9199
[2019-03-23 00:19:17,558] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 68000, global step 1090551: learning rate 0.0010
[2019-03-23 00:19:17,618] A3C_AGENT_WORKER-Thread-19 INFO:Local step 68000, global step 1090579: loss 7.0271
[2019-03-23 00:19:17,621] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 68000, global step 1090579: learning rate 0.0010
[2019-03-23 00:19:17,726] A3C_AGENT_WORKER-Thread-22 INFO:Local step 68000, global step 1090630: loss 8.1887
[2019-03-23 00:19:17,729] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 68000, global step 1090630: learning rate 0.0010
[2019-03-23 00:19:17,774] A3C_AGENT_WORKER-Thread-16 INFO:Local step 68000, global step 1090652: loss 8.6141
[2019-03-23 00:19:17,776] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 68000, global step 1090652: learning rate 0.0010
[2019-03-23 00:19:18,026] A3C_AGENT_WORKER-Thread-17 INFO:Local step 68000, global step 1090774: loss 8.0351
[2019-03-23 00:19:18,029] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 68000, global step 1090774: learning rate 0.0010
[2019-03-23 00:19:18,251] A3C_AGENT_WORKER-Thread-13 INFO:Local step 68000, global step 1090884: loss 7.1216
[2019-03-23 00:19:18,253] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 68000, global step 1090884: learning rate 0.0010
[2019-03-23 00:19:18,562] A3C_AGENT_WORKER-Thread-10 INFO:Local step 68000, global step 1091036: loss 7.1117
[2019-03-23 00:19:18,566] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 68000, global step 1091037: learning rate 0.0010
[2019-03-23 00:19:19,074] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:19:19,085] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8689
[2019-03-23 00:19:19,091] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.66666666666667, 78.83333333333334, 1.0, 2.0, 0.2190767850747411, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 237863.5400391945, 237863.5400391942, 77227.29596428476], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1065000.0000, 
sim time next is 1065600.0000, 
raw observation next is [16.0, 77.0, 1.0, 2.0, 0.220358227092284, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 239255.2132937979, 239255.2132937982, 77886.35148916821], 
processed observation next is [1.0, 0.34782608695652173, 0.36363636363636365, 0.77, 1.0, 1.0, 0.02544778386535499, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08861304196066588, 0.08861304196066601, 0.18996671094919076], 
reward next is 0.8100, 
noisyNet noise sample is [array([-2.4257834], dtype=float32), 0.56546044]. 
=============================================
[2019-03-23 00:19:19,693] A3C_AGENT_WORKER-Thread-21 INFO:Local step 69000, global step 1091598: loss 0.0472
[2019-03-23 00:19:19,694] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 69000, global step 1091598: learning rate 0.0010
[2019-03-23 00:19:21,177] A3C_AGENT_WORKER-Thread-14 INFO:Local step 68500, global step 1092322: loss -25.8546
[2019-03-23 00:19:21,183] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 68500, global step 1092324: learning rate 0.0010
[2019-03-23 00:19:21,924] A3C_AGENT_WORKER-Thread-9 INFO:Local step 68500, global step 1092691: loss -147.1597
[2019-03-23 00:19:21,926] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 68500, global step 1092692: learning rate 0.0010
[2019-03-23 00:19:24,512] A3C_AGENT_WORKER-Thread-3 INFO:Local step 69000, global step 1093954: loss 0.0329
[2019-03-23 00:19:24,513] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 69000, global step 1093954: learning rate 0.0010
[2019-03-23 00:19:25,083] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:19:25,097] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1379
[2019-03-23 00:19:25,101] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.66666666666667, 64.66666666666667, 1.0, 2.0, 0.5121930624657361, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 583655.5592564526, 583655.5592564526, 144121.5186240712], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1189200.0000, 
sim time next is 1189800.0000, 
raw observation next is [26.5, 66.0, 1.0, 2.0, 0.5157976058536529, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 587630.9489207965, 587630.9489207967, 144684.1617101205], 
processed observation next is [1.0, 0.782608695652174, 0.8409090909090909, 0.66, 1.0, 1.0, 0.394747007317066, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2176410921928876, 0.2176410921928877, 0.3528881992929768], 
reward next is 0.6471, 
noisyNet noise sample is [array([1.821266], dtype=float32), 1.1617098]. 
=============================================
[2019-03-23 00:19:30,525] A3C_AGENT_WORKER-Thread-2 INFO:Local step 68500, global step 1097141: loss -214.0384
[2019-03-23 00:19:30,528] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 68500, global step 1097143: learning rate 0.0010
[2019-03-23 00:19:31,053] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:19:31,060] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6675
[2019-03-23 00:19:31,067] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.3749271288937751, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 420916.3839985394, 420916.3839985397, 121819.8999297152], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1308000.0000, 
sim time next is 1308600.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.3751892114712815, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 421202.104405626, 421202.104405626, 121838.0944100263], 
processed observation next is [1.0, 0.13043478260869565, 0.45454545454545453, 1.0, 1.0, 1.0, 0.21898651433910182, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1560007794094911, 0.1560007794094911, 0.2971660839268934], 
reward next is 0.7028, 
noisyNet noise sample is [array([2.5018442], dtype=float32), -0.16177304]. 
=============================================
[2019-03-23 00:19:32,320] A3C_AGENT_WORKER-Thread-15 INFO:Local step 68500, global step 1098016: loss -395.1338
[2019-03-23 00:19:32,322] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 68500, global step 1098016: learning rate 0.0010
[2019-03-23 00:19:33,265] A3C_AGENT_WORKER-Thread-18 INFO:Local step 68500, global step 1098479: loss -154.5332
[2019-03-23 00:19:33,266] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 68500, global step 1098479: learning rate 0.0010
[2019-03-23 00:19:33,356] A3C_AGENT_WORKER-Thread-11 INFO:Local step 68500, global step 1098526: loss 2.0571
[2019-03-23 00:19:33,358] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 68500, global step 1098527: learning rate 0.0010
[2019-03-23 00:19:33,411] A3C_AGENT_WORKER-Thread-20 INFO:Local step 68500, global step 1098550: loss -355.3249
[2019-03-23 00:19:33,413] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 68500, global step 1098551: learning rate 0.0010
[2019-03-23 00:19:33,472] A3C_AGENT_WORKER-Thread-12 INFO:Local step 68500, global step 1098580: loss -509.3967
[2019-03-23 00:19:33,474] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 68500, global step 1098580: learning rate 0.0010
[2019-03-23 00:19:33,726] A3C_AGENT_WORKER-Thread-22 INFO:Local step 68500, global step 1098701: loss -197.1201
[2019-03-23 00:19:33,729] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 68500, global step 1098703: learning rate 0.0010
[2019-03-23 00:19:33,757] A3C_AGENT_WORKER-Thread-19 INFO:Local step 68500, global step 1098718: loss 5.2226
[2019-03-23 00:19:33,758] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 68500, global step 1098718: learning rate 0.0010
[2019-03-23 00:19:33,808] A3C_AGENT_WORKER-Thread-16 INFO:Local step 68500, global step 1098744: loss -271.0933
[2019-03-23 00:19:33,811] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 68500, global step 1098744: learning rate 0.0010
[2019-03-23 00:19:33,950] A3C_AGENT_WORKER-Thread-17 INFO:Local step 68500, global step 1098816: loss 0.7597
[2019-03-23 00:19:33,952] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 68500, global step 1098816: learning rate 0.0010
[2019-03-23 00:19:34,212] A3C_AGENT_WORKER-Thread-13 INFO:Local step 68500, global step 1098941: loss -309.6854
[2019-03-23 00:19:34,214] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 68500, global step 1098941: learning rate 0.0010
[2019-03-23 00:19:34,398] A3C_AGENT_WORKER-Thread-10 INFO:Local step 68500, global step 1099028: loss -193.6724
[2019-03-23 00:19:34,399] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 68500, global step 1099028: learning rate 0.0010
[2019-03-23 00:19:35,030] A3C_AGENT_WORKER-Thread-21 INFO:Local step 69500, global step 1099415: loss -139.9715
[2019-03-23 00:19:35,035] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 69500, global step 1099416: learning rate 0.0010
[2019-03-23 00:19:35,962] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-23 00:19:35,963] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 00:19:35,965] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 00:19:35,966] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 00:19:35,966] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:19:35,968] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 00:19:35,969] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 00:19:35,972] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:19:35,972] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:19:35,971] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:19:35,973] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:19:35,996] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run45
[2019-03-23 00:19:36,017] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run45
[2019-03-23 00:19:36,020] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run45
[2019-03-23 00:19:36,041] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run45
[2019-03-23 00:19:36,090] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run45
[2019-03-23 00:20:04,152] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.19100997], dtype=float32), 0.19749422]
[2019-03-23 00:20:04,154] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [26.65513011, 60.2745177, 1.0, 2.0, 0.4567946734769333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 521174.1134786967, 521174.1134786967, 140313.169200873]
[2019-03-23 00:20:04,158] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 00:20:04,161] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.6303519359925603
[2019-03-23 00:20:06,787] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.19100997], dtype=float32), 0.19749422]
[2019-03-23 00:20:06,788] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.0, 54.5, 1.0, 2.0, 0.2335437166608098, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 253575.1663700052, 253575.1663700052, 74039.31417070846]
[2019-03-23 00:20:06,789] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 00:20:06,793] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.9907743597810185
[2019-03-23 00:20:09,185] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.19100997], dtype=float32), 0.19749422]
[2019-03-23 00:20:09,187] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [26.36666666666667, 55.00000000000001, 1.0, 2.0, 0.4370692706517686, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 497597.7753692255, 497597.7753692255, 136112.6909471015]
[2019-03-23 00:20:09,189] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 00:20:09,192] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.2640733249081234
[2019-03-23 00:20:48,052] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.19100997], dtype=float32), 0.19749422]
[2019-03-23 00:20:48,054] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.72022945666667, 94.34697406666666, 1.0, 2.0, 0.4722283218349591, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 538315.4039647783, 538315.403964778, 140635.6795277646]
[2019-03-23 00:20:48,054] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 00:20:48,056] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0.0000000e+00 1.0000000e+00 3.1680688e-37 0.0000000e+00 5.5683086e-36], sampled 0.41250651294108376
[2019-03-23 00:20:52,643] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.19100997], dtype=float32), 0.19749422]
[2019-03-23 00:20:52,647] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.91666666666667, 66.5, 1.0, 2.0, 0.3297503316096022, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 363351.0047123642, 363351.0047123638, 119436.09962793]
[2019-03-23 00:20:52,648] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 00:20:52,650] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.494944129565267
[2019-03-23 00:20:57,781] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.19100997], dtype=float32), 0.19749422]
[2019-03-23 00:20:57,784] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.16666666666667, 58.33333333333333, 1.0, 2.0, 0.5082914983095665, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 567817.8648680764, 567817.864868076, 137440.6832606065]
[2019-03-23 00:20:57,785] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 00:20:57,788] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.8390185561920762
[2019-03-23 00:21:22,491] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9060.3047 1656272944.4788 80.0000
[2019-03-23 00:21:22,571] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.1534 1773226307.0271 173.0000
[2019-03-23 00:21:22,633] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3485 1683325900.1134 214.0000
[2019-03-23 00:21:22,686] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5598 1663796639.0689 105.0000
[2019-03-23 00:21:22,843] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9309 1705967916.6745 465.0000
[2019-03-23 00:21:23,858] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1100000, evaluation results [1100000.0, 8512.153397538275, 1773226307.0271282, 173.0, 9060.304679780347, 1656272944.478839, 80.0, 8856.559759326878, 1663796639.0688558, 105.0, 8596.930884973775, 1705967916.6744611, 465.0, 8574.348472942609, 1683325900.1133502, 214.0]
[2019-03-23 00:21:24,208] A3C_AGENT_WORKER-Thread-14 INFO:Local step 69000, global step 1100171: loss 0.0260
[2019-03-23 00:21:24,211] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 69000, global step 1100172: learning rate 0.0010
[2019-03-23 00:21:25,039] A3C_AGENT_WORKER-Thread-9 INFO:Local step 69000, global step 1100575: loss 0.0460
[2019-03-23 00:21:25,043] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 69000, global step 1100575: learning rate 0.0010
[2019-03-23 00:21:27,411] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:21:27,420] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0490
[2019-03-23 00:21:27,424] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 52.0, 1.0, 2.0, 0.2386819358803137, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 259155.5858924663, 259155.585892466, 74035.97790056303], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1710000.0000, 
sim time next is 1710600.0000, 
raw observation next is [16.5, 53.83333333333334, 1.0, 2.0, 0.2348901899890669, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 255037.5123534655, 255037.5123534658, 73341.3144885714], 
processed observation next is [1.0, 0.8260869565217391, 0.38636363636363635, 0.5383333333333334, 1.0, 1.0, 0.043612737486333625, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09445833790869093, 0.09445833790869104, 0.17888125485017414], 
reward next is 0.8211, 
noisyNet noise sample is [array([-0.64703536], dtype=float32), -0.52444667]. 
=============================================
[2019-03-23 00:21:27,771] A3C_AGENT_WORKER-Thread-3 INFO:Local step 69500, global step 1101812: loss 96.8613
[2019-03-23 00:21:27,774] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 69500, global step 1101812: learning rate 0.0010
[2019-03-23 00:21:34,331] A3C_AGENT_WORKER-Thread-2 INFO:Local step 69000, global step 1105041: loss 0.1592
[2019-03-23 00:21:34,333] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 69000, global step 1105042: learning rate 0.0010
[2019-03-23 00:21:35,499] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.0000000e+00 7.2749193e-29 1.5256107e-28 0.0000000e+00 1.0000000e+00], sum to 1.0000
[2019-03-23 00:21:35,509] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9327
[2019-03-23 00:21:35,515] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.83333333333333, 62.5, 1.0, 2.0, 0.3445168042784519, 1.0, 2.0, 0.3445168042784519, 1.0, 2.0, 0.6974032130850556, 6.911199999999999, 6.9112, 77.3421103, 1169435.05693011, 1169435.05693011, 279415.482085158], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1613400.0000, 
sim time next is 1614000.0000, 
raw observation next is [26.66666666666667, 63.0, 1.0, 2.0, 0.3274584244362985, 1.0, 2.0, 0.3274584244362985, 1.0, 2.0, 0.6630605389330946, 6.9112, 6.9112, 77.3421103, 1112749.711248063, 1112749.711248063, 271993.5390023534], 
processed observation next is [1.0, 0.6956521739130435, 0.8484848484848487, 0.63, 1.0, 1.0, 0.15932303054537314, 1.0, 1.0, 0.15932303054537314, 1.0, 1.0, 0.5186579127615637, 0.0, 0.0, 0.5085185399722538, 0.4121295226844678, 0.4121295226844678, 0.663398875615496], 
reward next is 0.3366, 
noisyNet noise sample is [array([0.1361059], dtype=float32), 0.7346831]. 
=============================================
[2019-03-23 00:21:35,534] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[63.4554  ]
 [62.01127 ]
 [61.081894]
 [60.46751 ]
 [60.288544]], R is [[64.43081665]
 [64.10501099]
 [63.75334549]
 [63.40893555]
 [62.77484512]].
[2019-03-23 00:21:36,262] A3C_AGENT_WORKER-Thread-15 INFO:Local step 69000, global step 1105975: loss 0.0204
[2019-03-23 00:21:36,267] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 69000, global step 1105975: learning rate 0.0010
[2019-03-23 00:21:37,205] A3C_AGENT_WORKER-Thread-18 INFO:Local step 69000, global step 1106440: loss 0.0158
[2019-03-23 00:21:37,206] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 69000, global step 1106440: learning rate 0.0010
[2019-03-23 00:21:37,288] A3C_AGENT_WORKER-Thread-11 INFO:Local step 69000, global step 1106475: loss 0.0197
[2019-03-23 00:21:37,290] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 69000, global step 1106475: learning rate 0.0010
[2019-03-23 00:21:37,393] A3C_AGENT_WORKER-Thread-20 INFO:Local step 69000, global step 1106533: loss 0.0098
[2019-03-23 00:21:37,396] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 69000, global step 1106534: learning rate 0.0010
[2019-03-23 00:21:37,417] A3C_AGENT_WORKER-Thread-12 INFO:Local step 69000, global step 1106542: loss 0.0151
[2019-03-23 00:21:37,418] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 69000, global step 1106542: learning rate 0.0010
[2019-03-23 00:21:37,689] A3C_AGENT_WORKER-Thread-19 INFO:Local step 69000, global step 1106679: loss 0.0059
[2019-03-23 00:21:37,690] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 69000, global step 1106681: learning rate 0.0010
[2019-03-23 00:21:37,771] A3C_AGENT_WORKER-Thread-22 INFO:Local step 69000, global step 1106717: loss 0.0036
[2019-03-23 00:21:37,774] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 69000, global step 1106717: learning rate 0.0010
[2019-03-23 00:21:37,801] A3C_AGENT_WORKER-Thread-17 INFO:Local step 69000, global step 1106735: loss 0.0053
[2019-03-23 00:21:37,805] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 69000, global step 1106736: learning rate 0.0010
[2019-03-23 00:21:37,896] A3C_AGENT_WORKER-Thread-16 INFO:Local step 69000, global step 1106780: loss 0.0019
[2019-03-23 00:21:37,902] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 69000, global step 1106781: learning rate 0.0010
[2019-03-23 00:21:38,210] A3C_AGENT_WORKER-Thread-13 INFO:Local step 69000, global step 1106932: loss 0.0451
[2019-03-23 00:21:38,211] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 69000, global step 1106933: learning rate 0.0010
[2019-03-23 00:21:38,479] A3C_AGENT_WORKER-Thread-10 INFO:Local step 69000, global step 1107060: loss 0.1069
[2019-03-23 00:21:38,482] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 69000, global step 1107060: learning rate 0.0010
[2019-03-23 00:21:38,675] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.3982366e-29 1.0000000e+00 4.5014606e-23 1.8505110e-14 2.2892961e-09], sum to 1.0000
[2019-03-23 00:21:38,688] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4574
[2019-03-23 00:21:38,696] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 76.33333333333334, 1.0, 2.0, 0.6350833653754611, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 696763.5983335066, 696763.5983335066, 142217.7627203243], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1682400.0000, 
sim time next is 1683000.0000, 
raw observation next is [19.0, 75.5, 1.0, 2.0, 0.654140211462652, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 716540.4773454223, 716540.4773454226, 143941.5887809334], 
processed observation next is [1.0, 0.4782608695652174, 0.5, 0.755, 1.0, 1.0, 0.5676752643283149, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.265385361979786, 0.2653853619797861, 0.35107704580715465], 
reward next is 0.6489, 
noisyNet noise sample is [array([0.81715846], dtype=float32), -0.19396584]. 
=============================================
[2019-03-23 00:21:38,708] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[62.835365]
 [63.058132]
 [63.057888]
 [63.032944]
 [62.77594 ]], R is [[62.70244598]
 [62.72854614]
 [62.76192474]
 [62.79598618]
 [62.83242035]].
[2019-03-23 00:21:38,847] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.1011772e-27], sum to 1.0000
[2019-03-23 00:21:38,863] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5057
[2019-03-23 00:21:38,869] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.0, 88.0, 1.0, 2.0, 0.2399672737983971, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 260551.5512934966, 260551.5512934963, 81147.65184102397], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2250000.0000, 
sim time next is 2250600.0000, 
raw observation next is [14.83333333333333, 89.00000000000001, 1.0, 2.0, 0.2363924363373098, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 256669.041812319, 256669.0418123187, 80442.39484369896], 
processed observation next is [1.0, 0.043478260869565216, 0.3106060606060605, 0.8900000000000001, 1.0, 1.0, 0.04549054542163724, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09506260807863666, 0.09506260807863655, 0.19620096303341208], 
reward next is 0.8038, 
noisyNet noise sample is [array([-0.40683442], dtype=float32), 0.16000669]. 
=============================================
[2019-03-23 00:21:39,144] A3C_AGENT_WORKER-Thread-21 INFO:Local step 70000, global step 1107382: loss 0.2837
[2019-03-23 00:21:39,145] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 70000, global step 1107382: learning rate 0.0010
[2019-03-23 00:21:40,073] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.8848251e-37 1.1867776e-30 2.2900883e-30], sum to 1.0000
[2019-03-23 00:21:40,083] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3574
[2019-03-23 00:21:40,090] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 49.0, 1.0, 2.0, 0.2534514697517722, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 275196.5572193616, 275196.5572193613, 76373.64643826109], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1706400.0000, 
sim time next is 1707000.0000, 
raw observation next is [17.83333333333333, 49.5, 1.0, 2.0, 0.2524665903395181, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 274126.8778571115, 274126.8778571112, 76106.0220190197], 
processed observation next is [1.0, 0.782608695652174, 0.44696969696969674, 0.495, 1.0, 1.0, 0.06558323792439764, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10152847328041167, 0.10152847328041156, 0.18562444394882854], 
reward next is 0.8144, 
noisyNet noise sample is [array([-0.42671832], dtype=float32), -1.066959]. 
=============================================
[2019-03-23 00:21:40,108] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[70.356674]
 [70.202614]
 [69.981674]
 [69.65267 ]
 [69.11391 ]], R is [[70.59967041]
 [70.70739746]
 [70.81157684]
 [70.91205597]
 [71.00875092]].
[2019-03-23 00:21:40,909] A3C_AGENT_WORKER-Thread-14 INFO:Local step 69500, global step 1108247: loss -61.5582
[2019-03-23 00:21:40,910] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 69500, global step 1108247: learning rate 0.0010
[2019-03-23 00:21:41,359] A3C_AGENT_WORKER-Thread-9 INFO:Local step 69500, global step 1108461: loss 0.2042
[2019-03-23 00:21:41,360] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 69500, global step 1108461: learning rate 0.0010
[2019-03-23 00:21:44,115] A3C_AGENT_WORKER-Thread-3 INFO:Local step 70000, global step 1109806: loss 4.5801
[2019-03-23 00:21:44,116] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 70000, global step 1109806: learning rate 0.0010
[2019-03-23 00:21:50,903] A3C_AGENT_WORKER-Thread-2 INFO:Local step 69500, global step 1113136: loss -108.8066
[2019-03-23 00:21:50,905] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 69500, global step 1113136: learning rate 0.0010
[2019-03-23 00:21:51,725] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 2.242087e-38], sum to 1.0000
[2019-03-23 00:21:51,732] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2286
[2019-03-23 00:21:51,736] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 94.0, 1.0, 2.0, 0.3384032042513861, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 376151.8927272452, 376151.8927272449, 117065.6122214563], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1911600.0000, 
sim time next is 1912200.0000, 
raw observation next is [18.0, 95.0, 1.0, 2.0, 0.3427371908389372, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 381782.9556472254, 381782.9556472254, 117748.4646100777], 
processed observation next is [1.0, 0.13043478260869565, 0.45454545454545453, 0.95, 1.0, 1.0, 0.17842148854867151, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14140109468415754, 0.14140109468415754, 0.2871913770977505], 
reward next is 0.7128, 
noisyNet noise sample is [array([1.1078373], dtype=float32), 0.51885295]. 
=============================================
[2019-03-23 00:21:52,627] A3C_AGENT_WORKER-Thread-15 INFO:Local step 69500, global step 1113981: loss -266.7447
[2019-03-23 00:21:52,628] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 69500, global step 1113981: learning rate 0.0010
[2019-03-23 00:21:53,675] A3C_AGENT_WORKER-Thread-18 INFO:Local step 69500, global step 1114494: loss -171.7142
[2019-03-23 00:21:53,676] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 69500, global step 1114494: learning rate 0.0010
[2019-03-23 00:21:53,704] A3C_AGENT_WORKER-Thread-11 INFO:Local step 69500, global step 1114502: loss 0.4813
[2019-03-23 00:21:53,705] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 69500, global step 1114502: learning rate 0.0010
[2019-03-23 00:21:53,790] A3C_AGENT_WORKER-Thread-12 INFO:Local step 69500, global step 1114551: loss -147.5644
[2019-03-23 00:21:53,793] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 69500, global step 1114551: learning rate 0.0010
[2019-03-23 00:21:53,824] A3C_AGENT_WORKER-Thread-20 INFO:Local step 69500, global step 1114564: loss 44.7341
[2019-03-23 00:21:53,826] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 69500, global step 1114565: learning rate 0.0010
[2019-03-23 00:21:54,041] A3C_AGENT_WORKER-Thread-17 INFO:Local step 69500, global step 1114670: loss -15.1039
[2019-03-23 00:21:54,042] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 69500, global step 1114670: learning rate 0.0010
[2019-03-23 00:21:54,132] A3C_AGENT_WORKER-Thread-19 INFO:Local step 69500, global step 1114718: loss 0.3422
[2019-03-23 00:21:54,134] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 69500, global step 1114718: learning rate 0.0010
[2019-03-23 00:21:54,154] A3C_AGENT_WORKER-Thread-22 INFO:Local step 69500, global step 1114727: loss -0.2642
[2019-03-23 00:21:54,158] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 69500, global step 1114727: learning rate 0.0010
[2019-03-23 00:21:54,323] A3C_AGENT_WORKER-Thread-16 INFO:Local step 69500, global step 1114814: loss -239.4055
[2019-03-23 00:21:54,324] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 69500, global step 1114814: learning rate 0.0010
[2019-03-23 00:21:54,442] A3C_AGENT_WORKER-Thread-13 INFO:Local step 69500, global step 1114876: loss 3.9452
[2019-03-23 00:21:54,444] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 69500, global step 1114876: learning rate 0.0010
[2019-03-23 00:21:54,845] A3C_AGENT_WORKER-Thread-10 INFO:Local step 69500, global step 1115072: loss -403.4415
[2019-03-23 00:21:54,847] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 69500, global step 1115072: learning rate 0.0010
[2019-03-23 00:21:55,105] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 6.3202170e-38 0.0000000e+00 1.1566253e-25], sum to 1.0000
[2019-03-23 00:21:55,112] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3118
[2019-03-23 00:21:55,117] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 50.0, 1.0, 2.0, 0.3702215099999629, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 414796.42591912, 414796.4259191203, 121017.8430975234], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1965600.0000, 
sim time next is 1966200.0000, 
raw observation next is [24.83333333333334, 50.66666666666667, 1.0, 2.0, 0.3701715571927308, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 414367.7859867873, 414367.7859867871, 120840.6969860002], 
processed observation next is [1.0, 0.782608695652174, 0.7651515151515155, 0.5066666666666667, 1.0, 1.0, 0.2127144464909135, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15346955036547677, 0.15346955036547671, 0.2947334072829273], 
reward next is 0.7053, 
noisyNet noise sample is [array([-1.2949562], dtype=float32), 0.5144249]. 
=============================================
[2019-03-23 00:21:55,394] A3C_AGENT_WORKER-Thread-21 INFO:Local step 70500, global step 1115335: loss 2.1181
[2019-03-23 00:21:55,397] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 70500, global step 1115336: learning rate 0.0010
[2019-03-23 00:21:57,184] A3C_AGENT_WORKER-Thread-14 INFO:Local step 70000, global step 1116206: loss 0.0337
[2019-03-23 00:21:57,188] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 70000, global step 1116207: learning rate 0.0010
[2019-03-23 00:21:57,471] A3C_AGENT_WORKER-Thread-9 INFO:Local step 70000, global step 1116348: loss 0.0495
[2019-03-23 00:21:57,475] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 70000, global step 1116348: learning rate 0.0010
[2019-03-23 00:22:00,254] A3C_AGENT_WORKER-Thread-3 INFO:Local step 70500, global step 1117715: loss 1.3821
[2019-03-23 00:22:00,258] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 70500, global step 1117715: learning rate 0.0010
[2019-03-23 00:22:02,646] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 2.7248467e-35], sum to 1.0000
[2019-03-23 00:22:02,654] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0808
[2019-03-23 00:22:02,658] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.9, 94.0, 1.0, 2.0, 0.3148060980130679, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 343657.9039482377, 343657.9039482374, 112831.2465945915], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2599200.0000, 
sim time next is 2599800.0000, 
raw observation next is [16.81666666666667, 93.00000000000001, 1.0, 2.0, 0.3129092295128519, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 340723.7022249435, 340723.7022249432, 112393.5521589766], 
processed observation next is [0.0, 0.08695652173913043, 0.4007575757575759, 0.9300000000000002, 1.0, 1.0, 0.14113653689106484, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1261939637870161, 0.126193963787016, 0.2741306150218941], 
reward next is 0.7259, 
noisyNet noise sample is [array([0.23485024], dtype=float32), -0.4465692]. 
=============================================
[2019-03-23 00:22:06,972] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.7390129e-37 1.0000000e+00 2.6642267e-26 6.9775166e-20 3.0958897e-19], sum to 1.0000
[2019-03-23 00:22:06,983] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0994
[2019-03-23 00:22:06,987] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 73.0, 1.0, 2.0, 0.8260767006335038, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 935325.3264146689, 935325.3264146686, 177595.8958878291], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2220600.0000, 
sim time next is 2221200.0000, 
raw observation next is [22.0, 73.0, 1.0, 2.0, 0.8313090992250385, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 941299.8023453706, 941299.8023453706, 178410.1715208471], 
processed observation next is [1.0, 0.7391304347826086, 0.6363636363636364, 0.73, 1.0, 1.0, 0.7891363740312981, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.34862955642421134, 0.34862955642421134, 0.43514675980694417], 
reward next is 0.5649, 
noisyNet noise sample is [array([-1.0427849], dtype=float32), 0.26151782]. 
=============================================
[2019-03-23 00:22:07,296] A3C_AGENT_WORKER-Thread-2 INFO:Local step 70000, global step 1121152: loss 0.3495
[2019-03-23 00:22:07,299] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 70000, global step 1121152: learning rate 0.0010
[2019-03-23 00:22:07,667] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 5.221402e-25 0.000000e+00], sum to 1.0000
[2019-03-23 00:22:07,678] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2824
[2019-03-23 00:22:07,684] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.83333333333333, 89.0, 1.0, 2.0, 0.2287942530440167, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 248417.0160909588, 248417.0160909586, 79539.45063214243], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2443800.0000, 
sim time next is 2444400.0000, 
raw observation next is [15.0, 88.0, 1.0, 2.0, 0.2311675828366291, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 250994.5617346748, 250994.5617346748, 80073.8855185253], 
processed observation next is [1.0, 0.30434782608695654, 0.3181818181818182, 0.88, 1.0, 1.0, 0.03895947854578637, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09296094879062029, 0.09296094879062029, 0.19530215980128124], 
reward next is 0.8047, 
noisyNet noise sample is [array([-1.0403037], dtype=float32), 0.4273933]. 
=============================================
[2019-03-23 00:22:08,860] A3C_AGENT_WORKER-Thread-15 INFO:Local step 70000, global step 1121921: loss 0.3504
[2019-03-23 00:22:08,864] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 70000, global step 1121922: learning rate 0.0010
[2019-03-23 00:22:09,982] A3C_AGENT_WORKER-Thread-18 INFO:Local step 70000, global step 1122479: loss 0.6280
[2019-03-23 00:22:09,986] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 70000, global step 1122479: learning rate 0.0010
[2019-03-23 00:22:10,029] A3C_AGENT_WORKER-Thread-20 INFO:Local step 70000, global step 1122497: loss 0.1840
[2019-03-23 00:22:10,030] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 70000, global step 1122498: learning rate 0.0010
[2019-03-23 00:22:10,048] A3C_AGENT_WORKER-Thread-11 INFO:Local step 70000, global step 1122505: loss 0.0779
[2019-03-23 00:22:10,050] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 70000, global step 1122506: learning rate 0.0010
[2019-03-23 00:22:10,180] A3C_AGENT_WORKER-Thread-12 INFO:Local step 70000, global step 1122571: loss 0.1645
[2019-03-23 00:22:10,183] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 70000, global step 1122571: learning rate 0.0010
[2019-03-23 00:22:10,444] A3C_AGENT_WORKER-Thread-17 INFO:Local step 70000, global step 1122700: loss 0.1406
[2019-03-23 00:22:10,446] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 70000, global step 1122700: learning rate 0.0010
[2019-03-23 00:22:10,453] A3C_AGENT_WORKER-Thread-22 INFO:Local step 70000, global step 1122703: loss 0.0573
[2019-03-23 00:22:10,458] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 70000, global step 1122704: learning rate 0.0010
[2019-03-23 00:22:10,587] A3C_AGENT_WORKER-Thread-19 INFO:Local step 70000, global step 1122765: loss 0.0219
[2019-03-23 00:22:10,592] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 70000, global step 1122765: learning rate 0.0010
[2019-03-23 00:22:10,688] A3C_AGENT_WORKER-Thread-16 INFO:Local step 70000, global step 1122811: loss 0.0492
[2019-03-23 00:22:10,691] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 70000, global step 1122813: learning rate 0.0010
[2019-03-23 00:22:10,883] A3C_AGENT_WORKER-Thread-13 INFO:Local step 70000, global step 1122906: loss 0.0671
[2019-03-23 00:22:10,884] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 70000, global step 1122906: learning rate 0.0010
[2019-03-23 00:22:11,307] A3C_AGENT_WORKER-Thread-10 INFO:Local step 70000, global step 1123111: loss 0.0478
[2019-03-23 00:22:11,310] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 70000, global step 1123112: learning rate 0.0010
[2019-03-23 00:22:11,787] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.0000000e+00 9.9999785e-01 1.1460111e-34 2.1464830e-06 5.6264401e-28], sum to 1.0000
[2019-03-23 00:22:11,794] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4589
[2019-03-23 00:22:11,803] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 53.33333333333333, 1.0, 2.0, 0.4025451377196758, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 437154.6119993463, 437154.6119993463, 93051.03666086003], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2288400.0000, 
sim time next is 2289000.0000, 
raw observation next is [18.0, 52.66666666666667, 1.0, 2.0, 0.3983094147485205, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 432552.6696375455, 432552.6696375458, 92281.79013975486], 
processed observation next is [1.0, 0.4782608695652174, 0.45454545454545453, 0.5266666666666667, 1.0, 1.0, 0.2478867684356506, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16020469245835017, 0.1602046924583503, 0.22507753692623136], 
reward next is 0.7749, 
noisyNet noise sample is [array([1.2002021], dtype=float32), -0.17199962]. 
=============================================
[2019-03-23 00:22:11,821] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[68.03049 ]
 [67.89325 ]
 [67.89799 ]
 [67.79936 ]
 [67.519646]], R is [[68.23931122]
 [68.32996368]
 [68.41618347]
 [68.503685  ]
 [68.59030914]].
[2019-03-23 00:22:11,838] A3C_AGENT_WORKER-Thread-21 INFO:Local step 71000, global step 1123365: loss 0.0309
[2019-03-23 00:22:11,841] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 71000, global step 1123365: learning rate 0.0010
[2019-03-23 00:22:13,544] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 3.527462e-14 5.721702e-38], sum to 1.0000
[2019-03-23 00:22:13,552] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0294
[2019-03-23 00:22:13,557] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.66666666666667, 50.0, 1.0, 2.0, 0.257393594451175, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 279478.1297453453, 279478.129745345, 78371.42294886049], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2316000.0000, 
sim time next is 2316600.0000, 
raw observation next is [18.5, 50.5, 1.0, 2.0, 0.2568497716041949, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 278887.4772486778, 278887.4772486778, 78106.87618102557], 
processed observation next is [1.0, 0.8260869565217391, 0.4772727272727273, 0.505, 1.0, 1.0, 0.07106221450524364, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10329165824025104, 0.10329165824025104, 0.19050457605128188], 
reward next is 0.8095, 
noisyNet noise sample is [array([-0.5738223], dtype=float32), 0.8755896]. 
=============================================
[2019-03-23 00:22:13,809] A3C_AGENT_WORKER-Thread-14 INFO:Local step 70500, global step 1124330: loss 1.4018
[2019-03-23 00:22:13,817] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 70500, global step 1124333: learning rate 0.0010
[2019-03-23 00:22:13,819] A3C_AGENT_WORKER-Thread-9 INFO:Local step 70500, global step 1124334: loss -0.2783
[2019-03-23 00:22:13,823] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 70500, global step 1124335: learning rate 0.0010
[2019-03-23 00:22:15,178] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-23 00:22:15,180] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 00:22:15,181] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 00:22:15,181] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:22:15,181] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:22:15,182] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 00:22:15,185] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 00:22:15,183] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 00:22:15,188] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:22:15,189] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:22:15,189] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:22:15,217] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run46
[2019-03-23 00:22:15,240] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run46
[2019-03-23 00:22:15,241] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run46
[2019-03-23 00:22:15,242] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run46
[2019-03-23 00:22:15,311] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run46
[2019-03-23 00:23:02,220] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.09200576], dtype=float32), 0.08841803]
[2019-03-23 00:23:02,223] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [17.9, 68.5, 1.0, 2.0, 0.2439902418162536, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 264907.0372548784, 264907.0372548781, 89300.46571215843]
[2019-03-23 00:23:02,224] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 00:23:02,226] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.3606160164750908
[2019-03-23 00:23:02,841] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.09200576], dtype=float32), 0.08841803]
[2019-03-23 00:23:02,844] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [18.3, 90.0, 1.0, 2.0, 0.3555203125852142, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 394718.3163884397, 394718.3163884394, 122535.931202799]
[2019-03-23 00:23:02,844] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 00:23:02,847] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 3.6718975e-38 7.6838714e-30 0.0000000e+00], sampled 0.892757728572732
[2019-03-23 00:23:23,427] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.09200576], dtype=float32), 0.08841803]
[2019-03-23 00:23:23,433] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.9, 75.66666666666667, 1.0, 2.0, 0.4832889600020602, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 551417.9829124471, 551417.9829124467, 143280.8970290904]
[2019-03-23 00:23:23,434] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 00:23:23,437] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0.0000000e+00 1.0000000e+00 4.2316236e-36 1.3053821e-28 0.0000000e+00], sampled 0.5613059979723931
[2019-03-23 00:23:52,130] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.09200576], dtype=float32), 0.08841803]
[2019-03-23 00:23:52,135] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.19455687, 95.76915715499999, 1.0, 2.0, 0.3913056493265051, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 442363.4397708537, 442363.4397708537, 129199.7519991175]
[2019-03-23 00:23:52,136] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 00:23:52,139] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.7776752e-29 0.0000000e+00], sampled 0.7964366262129824
[2019-03-23 00:23:53,641] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.09200576], dtype=float32), 0.08841803]
[2019-03-23 00:23:53,643] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.31666666666667, 79.0, 1.0, 2.0, 0.4535490697833453, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 517442.0813192054, 517442.0813192051, 139707.383153066]
[2019-03-23 00:23:53,645] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 00:23:53,648] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 3.0319905e-36 1.2430239e-25 3.8248915e-37], sampled 0.6965978777085825
[2019-03-23 00:23:58,131] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.09200576], dtype=float32), 0.08841803]
[2019-03-23 00:23:58,132] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.358708095, 96.74488061, 1.0, 2.0, 0.3142850892162419, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 341560.7615413353, 341560.7615413349, 116573.815243366]
[2019-03-23 00:23:58,134] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 00:23:58,137] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 8.431949e-35 0.000000e+00], sampled 0.9434879194881312
[2019-03-23 00:23:58,817] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.09200576], dtype=float32), 0.08841803]
[2019-03-23 00:23:58,818] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [17.46666666666667, 71.33333333333334, 1.0, 2.0, 0.2287253345842809, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 248330.0763460314, 248330.076346031, 87209.62079717574]
[2019-03-23 00:23:58,819] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 00:23:58,824] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.9472905667708762
[2019-03-23 00:24:05,082] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.8133 1683298940.9133 213.0000
[2019-03-23 00:24:05,134] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1147 1656209757.7786 80.0000
[2019-03-23 00:24:05,228] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8511.1351 1773914827.1115 173.0000
[2019-03-23 00:24:05,279] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9309 1705967916.6745 465.0000
[2019-03-23 00:24:05,283] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5598 1663796639.0689 105.0000
[2019-03-23 00:24:06,299] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 1125000, evaluation results [1125000.0, 8511.135122093514, 1773914827.1114855, 173.0, 9061.114669779829, 1656209757.7786272, 80.0, 8856.559759326878, 1663796639.0688558, 105.0, 8596.930884973775, 1705967916.6744611, 465.0, 8575.813320273046, 1683298940.913256, 213.0]
[2019-03-23 00:24:07,429] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 9.2401682e-38 4.9651306e-23 1.8409404e-35], sum to 1.0000
[2019-03-23 00:24:07,439] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5654
[2019-03-23 00:24:07,444] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 45.0, 1.0, 2.0, 0.6707522177802365, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 728639.5550444791, 728639.5550444791, 141513.5646687186], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2389200.0000, 
sim time next is 2389800.0000, 
raw observation next is [23.0, 44.5, 1.0, 2.0, 0.714410550931776, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 776103.5725002049, 776103.5725002049, 146127.1206434316], 
processed observation next is [1.0, 0.6521739130434783, 0.6818181818181818, 0.445, 1.0, 1.0, 0.64301318866472, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2874457675926685, 0.2874457675926685, 0.35640761132544296], 
reward next is 0.6436, 
noisyNet noise sample is [array([0.900439], dtype=float32), 0.5540824]. 
=============================================
[2019-03-23 00:24:07,821] A3C_AGENT_WORKER-Thread-3 INFO:Local step 71000, global step 1125720: loss 1.5955
[2019-03-23 00:24:07,823] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 71000, global step 1125720: learning rate 0.0010
[2019-03-23 00:24:11,971] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 4.213605e-33 0.000000e+00], sum to 1.0000
[2019-03-23 00:24:11,979] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4649
[2019-03-23 00:24:11,989] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.33333333333333, 92.0, 1.0, 2.0, 0.224359500362138, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 243600.7066982863, 243600.7066982861, 78224.56828355015], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2442000.0000, 
sim time next is 2442600.0000, 
raw observation next is [14.5, 91.0, 1.0, 2.0, 0.226443354031475, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 245863.8447757002, 245863.8447757004, 78708.98932339865], 
processed observation next is [1.0, 0.2608695652173913, 0.29545454545454547, 0.91, 1.0, 1.0, 0.03305419253934374, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09106068325025934, 0.0910606832502594, 0.19197314469121624], 
reward next is 0.8080, 
noisyNet noise sample is [array([0.5303549], dtype=float32), -0.501321]. 
=============================================
[2019-03-23 00:24:15,153] A3C_AGENT_WORKER-Thread-2 INFO:Local step 70500, global step 1129148: loss 1.4978
[2019-03-23 00:24:15,155] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 70500, global step 1129149: learning rate 0.0010
[2019-03-23 00:24:16,817] A3C_AGENT_WORKER-Thread-15 INFO:Local step 70500, global step 1129959: loss 2.5036
[2019-03-23 00:24:16,820] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 70500, global step 1129959: learning rate 0.0010
[2019-03-23 00:24:17,725] A3C_AGENT_WORKER-Thread-20 INFO:Local step 70500, global step 1130400: loss 2.0290
[2019-03-23 00:24:17,728] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 70500, global step 1130400: learning rate 0.0010
[2019-03-23 00:24:17,886] A3C_AGENT_WORKER-Thread-11 INFO:Local step 70500, global step 1130478: loss 1.5811
[2019-03-23 00:24:17,891] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 70500, global step 1130479: learning rate 0.0010
[2019-03-23 00:24:17,957] A3C_AGENT_WORKER-Thread-18 INFO:Local step 70500, global step 1130514: loss 1.7849
[2019-03-23 00:24:17,960] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 70500, global step 1130515: learning rate 0.0010
[2019-03-23 00:24:17,970] A3C_AGENT_WORKER-Thread-12 INFO:Local step 70500, global step 1130521: loss 1.0559
[2019-03-23 00:24:17,971] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 70500, global step 1130522: learning rate 0.0010
[2019-03-23 00:24:18,155] A3C_AGENT_WORKER-Thread-17 INFO:Local step 70500, global step 1130609: loss 0.9738
[2019-03-23 00:24:18,159] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 70500, global step 1130609: learning rate 0.0010
[2019-03-23 00:24:18,274] A3C_AGENT_WORKER-Thread-22 INFO:Local step 70500, global step 1130663: loss 1.6578
[2019-03-23 00:24:18,276] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 70500, global step 1130663: learning rate 0.0010
[2019-03-23 00:24:18,303] A3C_AGENT_WORKER-Thread-19 INFO:Local step 70500, global step 1130681: loss 1.5503
[2019-03-23 00:24:18,309] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 70500, global step 1130682: learning rate 0.0010
[2019-03-23 00:24:18,480] A3C_AGENT_WORKER-Thread-16 INFO:Local step 70500, global step 1130766: loss 1.1723
[2019-03-23 00:24:18,483] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 70500, global step 1130766: learning rate 0.0010
[2019-03-23 00:24:18,687] A3C_AGENT_WORKER-Thread-13 INFO:Local step 70500, global step 1130864: loss 1.3405
[2019-03-23 00:24:18,690] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 70500, global step 1130865: learning rate 0.0010
[2019-03-23 00:24:19,002] A3C_AGENT_WORKER-Thread-10 INFO:Local step 70500, global step 1131018: loss 1.3604
[2019-03-23 00:24:19,005] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 70500, global step 1131019: learning rate 0.0010
[2019-03-23 00:24:20,263] A3C_AGENT_WORKER-Thread-21 INFO:Local step 71500, global step 1131641: loss -63.8515
[2019-03-23 00:24:20,265] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 71500, global step 1131641: learning rate 0.0010
[2019-03-23 00:24:20,509] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 4.1905920e-38 1.7785457e-34 0.0000000e+00], sum to 1.0000
[2019-03-23 00:24:20,517] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0333
[2019-03-23 00:24:20,524] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.83333333333333, 72.33333333333334, 1.0, 2.0, 0.2650432155680816, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 287786.5507206807, 287786.5507206804, 90486.5588616702], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2590800.0000, 
sim time next is 2591400.0000, 
raw observation next is [17.76666666666667, 72.16666666666666, 1.0, 2.0, 0.2626315192431038, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 285167.1392203081, 285167.1392203084, 89451.80186720358], 
processed observation next is [1.0, 1.0, 0.4439393939393941, 0.7216666666666666, 1.0, 1.0, 0.07828939905387973, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10561745897048448, 0.10561745897048459, 0.2181751265053746], 
reward next is 0.7818, 
noisyNet noise sample is [array([2.2001643], dtype=float32), 0.98158854]. 
=============================================
[2019-03-23 00:24:21,713] A3C_AGENT_WORKER-Thread-9 INFO:Local step 71000, global step 1132377: loss 0.0954
[2019-03-23 00:24:21,718] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 71000, global step 1132378: learning rate 0.0010
[2019-03-23 00:24:21,950] A3C_AGENT_WORKER-Thread-14 INFO:Local step 71000, global step 1132496: loss 0.0034
[2019-03-23 00:24:21,952] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 71000, global step 1132497: learning rate 0.0010
[2019-03-23 00:24:24,817] A3C_AGENT_WORKER-Thread-3 INFO:Local step 71500, global step 1134071: loss 110.5696
[2019-03-23 00:24:24,819] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 71500, global step 1134071: learning rate 0.0010
[2019-03-23 00:24:27,301] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:24:27,315] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6956
[2019-03-23 00:24:27,319] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.83333333333333, 51.5, 1.0, 2.0, 0.4264705289250591, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 485168.0296177401, 485168.0296177401, 130325.4047968041], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2740200.0000, 
sim time next is 2740800.0000, 
raw observation next is [26.66666666666667, 52.00000000000001, 1.0, 2.0, 0.4230729683726505, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 481165.9070706815, 481165.9070706818, 129862.643162159], 
processed observation next is [0.0, 0.7391304347826086, 0.8484848484848487, 0.52, 1.0, 1.0, 0.2788412104658131, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17820959521136354, 0.17820959521136362, 0.3167381540540464], 
reward next is 0.6833, 
noisyNet noise sample is [array([-0.43989173], dtype=float32), -0.59467494]. 
=============================================
[2019-03-23 00:24:28,531] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 7.2606946e-37 1.5457547e-38 0.0000000e+00], sum to 1.0000
[2019-03-23 00:24:28,537] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1932
[2019-03-23 00:24:28,543] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.16666666666666, 78.0, 1.0, 2.0, 0.3944305180428072, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 445335.2485362475, 445335.2485362475, 124824.171423069], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2764200.0000, 
sim time next is 2764800.0000, 
raw observation next is [21.0, 78.0, 1.0, 2.0, 0.388840104793974, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 438346.7055546999, 438346.7055547002, 123944.5388815618], 
processed observation next is [1.0, 0.0, 0.5909090909090909, 0.78, 1.0, 1.0, 0.2360501309924675, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16235063168692587, 0.162350631686926, 0.3023037533696629], 
reward next is 0.6977, 
noisyNet noise sample is [array([-0.67427135], dtype=float32), 0.35579953]. 
=============================================
[2019-03-23 00:24:31,305] A3C_AGENT_WORKER-Thread-2 INFO:Local step 71000, global step 1137193: loss 0.2950
[2019-03-23 00:24:31,307] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 71000, global step 1137193: learning rate 0.0010
[2019-03-23 00:24:32,763] A3C_AGENT_WORKER-Thread-15 INFO:Local step 71000, global step 1137902: loss 0.0220
[2019-03-23 00:24:32,765] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 71000, global step 1137902: learning rate 0.0010
[2019-03-23 00:24:33,615] A3C_AGENT_WORKER-Thread-20 INFO:Local step 71000, global step 1138315: loss 0.0210
[2019-03-23 00:24:33,617] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 71000, global step 1138315: learning rate 0.0010
[2019-03-23 00:24:33,688] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.8824607e-30 9.9961960e-01 9.8916965e-15 4.4306586e-17 3.8037158e-04], sum to 1.0000
[2019-03-23 00:24:33,697] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6323
[2019-03-23 00:24:33,703] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 74.0, 1.0, 2.0, 0.3137840712126639, 1.0, 2.0, 0.3137840712126639, 1.0, 2.0, 0.635353230298814, 6.9112, 6.9112, 77.3421103, 1072370.307358603, 1072370.307358603, 262844.2731229413], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3072000.0000, 
sim time next is 3072600.0000, 
raw observation next is [24.0, 74.0, 1.0, 2.0, 0.9952004317192733, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.123233091849427, 6.9112, 77.3280061545069, 1205080.171278338, 1136216.567106074, 216945.2098366918], 
processed observation next is [1.0, 0.5652173913043478, 0.7272727272727273, 0.74, 1.0, 1.0, 0.9940005396490916, 0.0, 0.5, -0.25, 0.0, 0.5, -0.4285714285714286, 0.021203309184942665, 0.0, 0.5084258062797558, 0.4463259893623474, 0.4208209507800274, 0.5291346581382727], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.922528], dtype=float32), 0.087719224]. 
=============================================
[2019-03-23 00:24:33,766] A3C_AGENT_WORKER-Thread-11 INFO:Local step 71000, global step 1138385: loss 0.1370
[2019-03-23 00:24:33,768] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 71000, global step 1138386: learning rate 0.0010
[2019-03-23 00:24:33,783] A3C_AGENT_WORKER-Thread-12 INFO:Local step 71000, global step 1138393: loss 0.1576
[2019-03-23 00:24:33,787] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 71000, global step 1138397: learning rate 0.0010
[2019-03-23 00:24:33,834] A3C_AGENT_WORKER-Thread-18 INFO:Local step 71000, global step 1138416: loss 0.0075
[2019-03-23 00:24:33,837] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 71000, global step 1138416: learning rate 0.0010
[2019-03-23 00:24:34,089] A3C_AGENT_WORKER-Thread-17 INFO:Local step 71000, global step 1138545: loss 0.2411
[2019-03-23 00:24:34,093] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 71000, global step 1138545: learning rate 0.0010
[2019-03-23 00:24:34,237] A3C_AGENT_WORKER-Thread-19 INFO:Local step 71000, global step 1138614: loss 0.0664
[2019-03-23 00:24:34,241] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 71000, global step 1138615: learning rate 0.0010
[2019-03-23 00:24:34,350] A3C_AGENT_WORKER-Thread-22 INFO:Local step 71000, global step 1138674: loss 0.0068
[2019-03-23 00:24:34,351] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 71000, global step 1138674: learning rate 0.0010
[2019-03-23 00:24:34,429] A3C_AGENT_WORKER-Thread-16 INFO:Local step 71000, global step 1138715: loss 0.0015
[2019-03-23 00:24:34,431] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 71000, global step 1138716: learning rate 0.0010
[2019-03-23 00:24:34,463] A3C_AGENT_WORKER-Thread-13 INFO:Local step 71000, global step 1138728: loss 0.0154
[2019-03-23 00:24:34,464] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 71000, global step 1138729: learning rate 0.0010
[2019-03-23 00:24:34,947] A3C_AGENT_WORKER-Thread-10 INFO:Local step 71000, global step 1138963: loss 0.0050
[2019-03-23 00:24:34,950] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 71000, global step 1138964: learning rate 0.0010
[2019-03-23 00:24:36,277] A3C_AGENT_WORKER-Thread-21 INFO:Local step 72000, global step 1139616: loss 0.0823
[2019-03-23 00:24:36,280] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 72000, global step 1139618: learning rate 0.0010
[2019-03-23 00:24:37,754] A3C_AGENT_WORKER-Thread-9 INFO:Local step 71500, global step 1140566: loss -229.8540
[2019-03-23 00:24:37,757] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 71500, global step 1140566: learning rate 0.0010
[2019-03-23 00:24:38,030] A3C_AGENT_WORKER-Thread-14 INFO:Local step 71500, global step 1140741: loss 27.4508
[2019-03-23 00:24:38,032] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 71500, global step 1140741: learning rate 0.0010
[2019-03-23 00:24:40,493] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.0000000e+00 2.7049795e-30 4.2293632e-29 4.1268998e-37 1.0000000e+00], sum to 1.0000
[2019-03-23 00:24:40,502] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3299
[2019-03-23 00:24:40,506] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.5, 60.0, 1.0, 2.0, 0.3827491042871495, 1.0, 2.0, 0.3827491042871495, 1.0, 2.0, 0.7743530403662291, 6.9112, 6.9112, 77.3421103, 1296913.494815702, 1296913.494815702, 296856.8458186427], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2979000.0000, 
sim time next is 2979600.0000, 
raw observation next is [27.66666666666666, 59.33333333333333, 1.0, 2.0, 0.4256897150008137, 1.0, 2.0, 0.4256897150008137, 1.0, 2.0, 0.860916118901108, 6.9112, 6.9112, 77.3421103, 1441098.851858793, 1441098.851858793, 317863.2481662655], 
processed observation next is [1.0, 0.4782608695652174, 0.8939393939393937, 0.5933333333333333, 1.0, 1.0, 0.2821121437510171, 1.0, 1.0, 0.2821121437510171, 1.0, 1.0, 0.8013087412872972, 0.0, 0.0, 0.5085185399722538, 0.5337403155032567, 0.5337403155032567, 0.7752762150396719], 
reward next is 0.2247, 
noisyNet noise sample is [array([2.1404748], dtype=float32), 0.6417714]. 
=============================================
[2019-03-23 00:24:40,665] A3C_AGENT_WORKER-Thread-3 INFO:Local step 72000, global step 1141973: loss 0.0530
[2019-03-23 00:24:40,668] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 72000, global step 1141973: learning rate 0.0010
[2019-03-23 00:24:47,512] A3C_AGENT_WORKER-Thread-2 INFO:Local step 71500, global step 1145305: loss 4.6649
[2019-03-23 00:24:47,516] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 71500, global step 1145306: learning rate 0.0010
[2019-03-23 00:24:48,623] A3C_AGENT_WORKER-Thread-15 INFO:Local step 71500, global step 1145843: loss 1.7713
[2019-03-23 00:24:48,627] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 71500, global step 1145843: learning rate 0.0010
[2019-03-23 00:24:49,515] A3C_AGENT_WORKER-Thread-20 INFO:Local step 71500, global step 1146281: loss 4.6073
[2019-03-23 00:24:49,519] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 71500, global step 1146283: learning rate 0.0010
[2019-03-23 00:24:49,711] A3C_AGENT_WORKER-Thread-18 INFO:Local step 71500, global step 1146381: loss -1.9607
[2019-03-23 00:24:49,712] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 71500, global step 1146382: learning rate 0.0010
[2019-03-23 00:24:49,796] A3C_AGENT_WORKER-Thread-11 INFO:Local step 71500, global step 1146421: loss 2.5593
[2019-03-23 00:24:49,798] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 71500, global step 1146422: learning rate 0.0010
[2019-03-23 00:24:50,105] A3C_AGENT_WORKER-Thread-12 INFO:Local step 71500, global step 1146574: loss 12.2521
[2019-03-23 00:24:50,110] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 71500, global step 1146577: learning rate 0.0010
[2019-03-23 00:24:50,131] A3C_AGENT_WORKER-Thread-19 INFO:Local step 71500, global step 1146586: loss -70.1015
[2019-03-23 00:24:50,137] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 71500, global step 1146588: learning rate 0.0010
[2019-03-23 00:24:50,266] A3C_AGENT_WORKER-Thread-17 INFO:Local step 71500, global step 1146651: loss -4.8979
[2019-03-23 00:24:50,267] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 71500, global step 1146651: learning rate 0.0010
[2019-03-23 00:24:50,367] A3C_AGENT_WORKER-Thread-13 INFO:Local step 71500, global step 1146701: loss -2.8728
[2019-03-23 00:24:50,371] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 71500, global step 1146702: learning rate 0.0010
[2019-03-23 00:24:50,397] A3C_AGENT_WORKER-Thread-22 INFO:Local step 71500, global step 1146713: loss 2.6031
[2019-03-23 00:24:50,399] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 71500, global step 1146713: learning rate 0.0010
[2019-03-23 00:24:50,459] A3C_AGENT_WORKER-Thread-16 INFO:Local step 71500, global step 1146741: loss 0.4402
[2019-03-23 00:24:50,461] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 71500, global step 1146741: learning rate 0.0010
[2019-03-23 00:24:50,846] A3C_AGENT_WORKER-Thread-10 INFO:Local step 71500, global step 1146928: loss -4.6719
[2019-03-23 00:24:50,849] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 71500, global step 1146929: learning rate 0.0010
[2019-03-23 00:24:50,980] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0606001e-36 1.0000000e+00 3.6171439e-26 7.2950744e-27 3.6872399e-15], sum to 1.0000
[2019-03-23 00:24:50,988] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2712
[2019-03-23 00:24:50,995] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1207948.237621545 W.
[2019-03-23 00:24:51,000] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.33333333333333, 78.33333333333334, 1.0, 2.0, 0.9967911923840472, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.132055052648568, 6.9112, 77.32802522657404, 1207948.237621545, 1136219.440274521, 220244.5990661782], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3158400.0000, 
sim time next is 3159000.0000, 
raw observation next is [24.5, 76.0, 1.0, 2.0, 0.3877234203572464, 1.0, 1.0, 0.3877234203572464, 1.0, 1.0, 0.7852106068633403, 6.911199999999999, 6.9112, 77.3421103, 1318771.989231234, 1318771.989231234, 297205.6618906563], 
processed observation next is [1.0, 0.5652173913043478, 0.75, 0.76, 1.0, 1.0, 0.23465427544655795, 1.0, 0.5, 0.23465427544655795, 1.0, 0.5, 0.6931580098047719, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.4884340700856422, 0.4884340700856422, 0.7248918582698933], 
reward next is 0.2751, 
noisyNet noise sample is [array([0.13363554], dtype=float32), -1.2044622]. 
=============================================
[2019-03-23 00:24:51,015] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[57.655266]
 [59.15066 ]
 [58.8308  ]
 [59.441967]
 [60.231808]], R is [[57.52952194]
 [56.95422745]
 [56.90554047]
 [56.83640671]
 [56.78439713]].
[2019-03-23 00:24:52,131] A3C_AGENT_WORKER-Thread-21 INFO:Local step 72500, global step 1147555: loss -13.5178
[2019-03-23 00:24:52,133] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 72500, global step 1147555: learning rate 0.0010
[2019-03-23 00:24:53,358] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:24:53,367] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8897
[2019-03-23 00:24:53,371] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.83333333333333, 48.0, 1.0, 2.0, 0.3223051351366666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 353534.8603688311, 353534.8603688314, 113966.4545415698], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3243000.0000, 
sim time next is 3243600.0000, 
raw observation next is [24.0, 47.0, 1.0, 2.0, 0.3203772412318492, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 351230.9218759258, 351230.9218759255, 113758.6759378232], 
processed observation next is [0.0, 0.5652173913043478, 0.7272727272727273, 0.47, 1.0, 1.0, 0.15047155153981145, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13008552662071327, 0.13008552662071315, 0.2774601852142029], 
reward next is 0.7225, 
noisyNet noise sample is [array([0.27984995], dtype=float32), -0.47256687]. 
=============================================
[2019-03-23 00:24:54,032] A3C_AGENT_WORKER-Thread-9 INFO:Local step 72000, global step 1148497: loss 0.0221
[2019-03-23 00:24:54,034] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 72000, global step 1148498: learning rate 0.0010
[2019-03-23 00:24:54,569] A3C_AGENT_WORKER-Thread-14 INFO:Local step 72000, global step 1148776: loss 0.0569
[2019-03-23 00:24:54,571] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 72000, global step 1148776: learning rate 0.0010
[2019-03-23 00:24:57,084] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-23 00:24:57,085] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 00:24:57,086] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:24:57,086] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 00:24:57,087] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:24:57,088] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 00:24:57,089] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:24:57,090] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 00:24:57,090] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 00:24:57,091] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:24:57,092] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:24:57,106] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run47
[2019-03-23 00:24:57,127] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run47
[2019-03-23 00:24:57,151] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run47
[2019-03-23 00:24:57,184] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run47
[2019-03-23 00:24:57,185] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run47
[2019-03-23 00:25:03,253] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.08723734], dtype=float32), 0.117361024]
[2019-03-23 00:25:03,254] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.1, 88.33333333333334, 1.0, 2.0, 0.3621635490589061, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 399508.7068933675, 399508.7068933678, 122057.2082175728]
[2019-03-23 00:25:03,255] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 00:25:03,259] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.10855176311883852
[2019-03-23 00:25:52,777] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.08723734], dtype=float32), 0.117361024]
[2019-03-23 00:25:52,777] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [28.36666666666667, 53.33333333333334, 1.0, 2.0, 0.7023517829701542, 0.0, 2.0, 0.0, 1.0, 2.0, 0.94259942573273, 6.95460775660891, 6.9112, 95.55321362924384, 1348633.319199163, 1331212.76650941, 288081.9244998329]
[2019-03-23 00:25:52,778] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 00:25:52,782] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0.0000000e+00 1.0000000e+00 2.0174640e-34 0.0000000e+00 2.4261576e-26], sampled 0.8075981175109557
[2019-03-23 00:25:52,784] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1348633.319199163 W.
[2019-03-23 00:25:54,505] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.08723734], dtype=float32), 0.117361024]
[2019-03-23 00:25:54,506] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.66666666666666, 89.5, 1.0, 2.0, 0.4597423242992125, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 524431.021069764, 524431.021069764, 140046.8805699097]
[2019-03-23 00:25:54,506] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 00:25:54,509] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.5326304568895541
[2019-03-23 00:26:31,502] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08723734], dtype=float32), 0.117361024]
[2019-03-23 00:26:31,503] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.16666666666666, 80.33333333333334, 1.0, 2.0, 0.382638855209501, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 428768.8934564604, 428768.89345646, 126421.1336951969]
[2019-03-23 00:26:31,506] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 00:26:31,510] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.019538591332862953
[2019-03-23 00:26:38,571] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.08723734], dtype=float32), 0.117361024]
[2019-03-23 00:26:38,572] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [17.415684975, 83.86850175000001, 1.0, 2.0, 0.3281509833977447, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 356309.797197813, 356309.797197813, 116423.7833663851]
[2019-03-23 00:26:38,574] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 00:26:38,576] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.723320710870246
[2019-03-23 00:26:46,318] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2492 1773187030.7201 173.0000
[2019-03-23 00:26:46,680] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9310 1705987275.5940 465.0000
[2019-03-23 00:26:46,734] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1148 1656229146.4555 80.0000
[2019-03-23 00:26:46,755] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5599 1663815647.6096 105.0000
[2019-03-23 00:26:46,820] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3485 1683325900.1134 214.0000
[2019-03-23 00:26:47,836] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 1150000, evaluation results [1150000.0, 8512.249193409023, 1773187030.7201214, 173.0, 9061.114827412715, 1656229146.4555063, 80.0, 8856.559925897878, 1663815647.6095803, 105.0, 8596.931041181726, 1705987275.594041, 465.0, 8574.348472942609, 1683325900.1133502, 214.0]
[2019-03-23 00:26:47,982] A3C_AGENT_WORKER-Thread-3 INFO:Local step 72500, global step 1150072: loss -42.7977
[2019-03-23 00:26:47,984] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 72500, global step 1150073: learning rate 0.0010
[2019-03-23 00:26:54,882] A3C_AGENT_WORKER-Thread-2 INFO:Local step 72000, global step 1153342: loss 0.1187
[2019-03-23 00:26:54,883] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 72000, global step 1153342: learning rate 0.0010
[2019-03-23 00:26:55,849] A3C_AGENT_WORKER-Thread-15 INFO:Local step 72000, global step 1153797: loss 0.0518
[2019-03-23 00:26:55,851] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 72000, global step 1153797: learning rate 0.0010
[2019-03-23 00:26:56,954] A3C_AGENT_WORKER-Thread-20 INFO:Local step 72000, global step 1154322: loss 0.0894
[2019-03-23 00:26:56,957] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 72000, global step 1154322: learning rate 0.0010
[2019-03-23 00:26:56,992] A3C_AGENT_WORKER-Thread-18 INFO:Local step 72000, global step 1154337: loss 0.1345
[2019-03-23 00:26:56,995] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 72000, global step 1154338: learning rate 0.0010
[2019-03-23 00:26:57,089] A3C_AGENT_WORKER-Thread-11 INFO:Local step 72000, global step 1154387: loss 0.0775
[2019-03-23 00:26:57,091] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 72000, global step 1154388: learning rate 0.0010
[2019-03-23 00:26:57,385] A3C_AGENT_WORKER-Thread-12 INFO:Local step 72000, global step 1154523: loss 0.0188
[2019-03-23 00:26:57,391] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 72000, global step 1154525: learning rate 0.0010
[2019-03-23 00:26:57,449] A3C_AGENT_WORKER-Thread-19 INFO:Local step 72000, global step 1154556: loss 0.0742
[2019-03-23 00:26:57,454] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 72000, global step 1154557: learning rate 0.0010
[2019-03-23 00:26:57,472] A3C_AGENT_WORKER-Thread-17 INFO:Local step 72000, global step 1154561: loss 0.0395
[2019-03-23 00:26:57,477] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 72000, global step 1154562: learning rate 0.0010
[2019-03-23 00:26:57,730] A3C_AGENT_WORKER-Thread-22 INFO:Local step 72000, global step 1154680: loss 0.0203
[2019-03-23 00:26:57,734] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 72000, global step 1154680: learning rate 0.0010
[2019-03-23 00:26:57,804] A3C_AGENT_WORKER-Thread-16 INFO:Local step 72000, global step 1154717: loss 0.0413
[2019-03-23 00:26:57,808] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 72000, global step 1154718: learning rate 0.0010
[2019-03-23 00:26:57,814] A3C_AGENT_WORKER-Thread-13 INFO:Local step 72000, global step 1154719: loss 0.1093
[2019-03-23 00:26:57,815] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 72000, global step 1154720: learning rate 0.0010
[2019-03-23 00:26:58,247] A3C_AGENT_WORKER-Thread-10 INFO:Local step 72000, global step 1154924: loss 0.0241
[2019-03-23 00:26:58,250] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 72000, global step 1154925: learning rate 0.0010
[2019-03-23 00:26:58,890] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.3698912e-38 1.0000000e+00 1.4820156e-28 8.7369782e-30 2.4718760e-27], sum to 1.0000
[2019-03-23 00:26:58,898] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2937
[2019-03-23 00:26:58,908] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.5681953912271305, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 648328.727673503, 648328.727673503, 149786.8412627921], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3467400.0000, 
sim time next is 3468000.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.5186241936909024, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 591733.669610122, 591733.669610122, 143712.1589968544], 
processed observation next is [1.0, 0.13043478260869565, 0.5909090909090909, 1.0, 1.0, 1.0, 0.39828024211362795, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21916061837411926, 0.21916061837411926, 0.3505174609679376], 
reward next is 0.6495, 
noisyNet noise sample is [array([1.822174], dtype=float32), -1.6028575]. 
=============================================
[2019-03-23 00:26:58,921] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[56.956474]
 [57.342686]
 [57.25608 ]
 [57.128086]
 [56.983093]], R is [[57.27745438]
 [57.33934784]
 [57.417099  ]
 [57.49515915]
 [57.57048035]].
[2019-03-23 00:26:59,202] A3C_AGENT_WORKER-Thread-21 INFO:Local step 73000, global step 1155372: loss 0.4602
[2019-03-23 00:26:59,205] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 73000, global step 1155372: learning rate 0.0010
[2019-03-23 00:27:02,053] A3C_AGENT_WORKER-Thread-9 INFO:Local step 72500, global step 1156661: loss 37.1671
[2019-03-23 00:27:02,057] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 72500, global step 1156661: learning rate 0.0010
[2019-03-23 00:27:02,278] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 2.4412029e-29 5.3989831e-30 5.5100434e-32], sum to 1.0000
[2019-03-23 00:27:02,285] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7129
[2019-03-23 00:27:02,289] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333333, 81.33333333333334, 1.0, 2.0, 0.7072368183230859, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 802957.6626443306, 802957.6626443306, 162239.8345725749], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4111800.0000, 
sim time next is 4112400.0000, 
raw observation next is [21.66666666666667, 79.66666666666667, 1.0, 2.0, 0.7582273573347489, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 861496.4242158275, 861496.4242158275, 169818.1368720131], 
processed observation next is [1.0, 0.6086956521739131, 0.6212121212121214, 0.7966666666666667, 1.0, 1.0, 0.6977841966684362, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.31907274970956573, 0.31907274970956573, 0.4141905777366173], 
reward next is 0.5858, 
noisyNet noise sample is [array([1.2696956], dtype=float32), 0.14962623]. 
=============================================
[2019-03-23 00:27:02,642] A3C_AGENT_WORKER-Thread-14 INFO:Local step 72500, global step 1156948: loss 31.1697
[2019-03-23 00:27:02,646] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 72500, global step 1156948: learning rate 0.0010
[2019-03-23 00:27:04,340] A3C_AGENT_WORKER-Thread-3 INFO:Local step 73000, global step 1157782: loss 0.1819
[2019-03-23 00:27:04,343] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 73000, global step 1157783: learning rate 0.0010
[2019-03-23 00:27:06,110] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:27:06,118] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1935
[2019-03-23 00:27:06,124] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.33333333333333, 83.33333333333334, 1.0, 2.0, 0.3188270938055018, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 349409.2784380185, 349409.2784380188, 113603.3710637333], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3832800.0000, 
sim time next is 3833400.0000, 
raw observation next is [18.66666666666667, 80.66666666666666, 1.0, 2.0, 0.3201890633480935, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 350937.7853066009, 350937.7853066011, 113713.458279182], 
processed observation next is [0.0, 0.34782608695652173, 0.4848484848484851, 0.8066666666666665, 1.0, 1.0, 0.15023632918511684, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1299769575209633, 0.12997695752096336, 0.2773498982419073], 
reward next is 0.7227, 
noisyNet noise sample is [array([-0.04078919], dtype=float32), -0.06755731]. 
=============================================
[2019-03-23 00:27:11,802] A3C_AGENT_WORKER-Thread-2 INFO:Local step 72500, global step 1161375: loss 48.7620
[2019-03-23 00:27:11,807] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 72500, global step 1161376: learning rate 0.0010
[2019-03-23 00:27:12,636] A3C_AGENT_WORKER-Thread-15 INFO:Local step 72500, global step 1161789: loss 0.1652
[2019-03-23 00:27:12,640] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 72500, global step 1161789: learning rate 0.0010
[2019-03-23 00:27:13,988] A3C_AGENT_WORKER-Thread-18 INFO:Local step 72500, global step 1162449: loss 0.8532
[2019-03-23 00:27:13,991] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 72500, global step 1162450: learning rate 0.0010
[2019-03-23 00:27:14,013] A3C_AGENT_WORKER-Thread-20 INFO:Local step 72500, global step 1162464: loss -135.3912
[2019-03-23 00:27:14,015] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 72500, global step 1162464: learning rate 0.0010
[2019-03-23 00:27:14,068] A3C_AGENT_WORKER-Thread-11 INFO:Local step 72500, global step 1162487: loss -93.5065
[2019-03-23 00:27:14,073] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 72500, global step 1162488: learning rate 0.0010
[2019-03-23 00:27:14,308] A3C_AGENT_WORKER-Thread-12 INFO:Local step 72500, global step 1162605: loss 0.0559
[2019-03-23 00:27:14,308] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 72500, global step 1162606: learning rate 0.0010
[2019-03-23 00:27:14,348] A3C_AGENT_WORKER-Thread-19 INFO:Local step 72500, global step 1162630: loss 0.2833
[2019-03-23 00:27:14,350] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 72500, global step 1162631: learning rate 0.0010
[2019-03-23 00:27:14,358] A3C_AGENT_WORKER-Thread-17 INFO:Local step 72500, global step 1162632: loss 1.3324
[2019-03-23 00:27:14,362] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 72500, global step 1162634: learning rate 0.0010
[2019-03-23 00:27:14,581] A3C_AGENT_WORKER-Thread-22 INFO:Local step 72500, global step 1162742: loss 0.8075
[2019-03-23 00:27:14,584] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 72500, global step 1162743: learning rate 0.0010
[2019-03-23 00:27:14,671] A3C_AGENT_WORKER-Thread-16 INFO:Local step 72500, global step 1162785: loss 0.5215
[2019-03-23 00:27:14,674] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 72500, global step 1162786: learning rate 0.0010
[2019-03-23 00:27:14,768] A3C_AGENT_WORKER-Thread-13 INFO:Local step 72500, global step 1162831: loss 0.1734
[2019-03-23 00:27:14,771] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 72500, global step 1162832: learning rate 0.0010
[2019-03-23 00:27:15,069] A3C_AGENT_WORKER-Thread-10 INFO:Local step 72500, global step 1162977: loss 0.3112
[2019-03-23 00:27:15,072] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 72500, global step 1162977: learning rate 0.0010
[2019-03-23 00:27:15,282] A3C_AGENT_WORKER-Thread-21 INFO:Local step 73500, global step 1163081: loss 31.0010
[2019-03-23 00:27:15,285] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 73500, global step 1163082: learning rate 0.0010
[2019-03-23 00:27:18,186] A3C_AGENT_WORKER-Thread-9 INFO:Local step 73000, global step 1164492: loss 0.1069
[2019-03-23 00:27:18,189] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 73000, global step 1164492: learning rate 0.0010
[2019-03-23 00:27:18,840] A3C_AGENT_WORKER-Thread-14 INFO:Local step 73000, global step 1164808: loss 0.0176
[2019-03-23 00:27:18,843] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 73000, global step 1164808: learning rate 0.0010
[2019-03-23 00:27:20,414] A3C_AGENT_WORKER-Thread-3 INFO:Local step 73500, global step 1165581: loss 3.1708
[2019-03-23 00:27:20,415] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 73500, global step 1165581: learning rate 0.0010
[2019-03-23 00:27:24,556] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:27:24,568] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3261
[2019-03-23 00:27:24,574] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 45.0, 1.0, 2.0, 0.3550412013223337, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 397130.5848288175, 397130.5848288175, 119451.50968396], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3941400.0000, 
sim time next is 3942000.0000, 
raw observation next is [26.0, 45.0, 1.0, 2.0, 0.354643604749413, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 396686.7902673273, 396686.7902673273, 119419.58710725], 
processed observation next is [0.0, 0.6521739130434783, 0.8181818181818182, 0.45, 1.0, 1.0, 0.1933045059367662, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14692103343234345, 0.14692103343234345, 0.29126728562743903], 
reward next is 0.7087, 
noisyNet noise sample is [array([1.5683051], dtype=float32), 1.577374]. 
=============================================
[2019-03-23 00:27:24,584] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[76.216286]
 [76.22028 ]
 [76.22854 ]
 [76.22382 ]
 [76.197655]], R is [[76.18573761]
 [76.13253784]
 [76.08008575]
 [76.02867889]
 [75.9781723 ]].
[2019-03-23 00:27:24,870] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:27:24,879] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6089
[2019-03-23 00:27:24,885] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.33333333333333, 44.33333333333334, 1.0, 2.0, 0.3376970503819751, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 374441.6210857527, 374441.6210857527, 116626.311863072], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3944400.0000, 
sim time next is 3945000.0000, 
raw observation next is [25.16666666666667, 44.16666666666667, 1.0, 2.0, 0.333669476876838, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 369003.3699749171, 369003.3699749171, 115927.4836683038], 
processed observation next is [0.0, 0.6521739130434783, 0.7803030303030305, 0.4416666666666667, 1.0, 1.0, 0.1670868460960475, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13666791480552484, 0.13666791480552484, 0.28274996016659465], 
reward next is 0.7173, 
noisyNet noise sample is [array([-1.9305872], dtype=float32), -1.3301771]. 
=============================================
[2019-03-23 00:27:24,898] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[72.742874]
 [72.6904  ]
 [72.64113 ]
 [72.59279 ]
 [72.586075]], R is [[72.7826767 ]
 [72.77039337]
 [72.75653839]
 [72.74102783]
 [72.72376251]].
[2019-03-23 00:27:26,133] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:27:26,142] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5606
[2019-03-23 00:27:26,151] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 66.5, 1.0, 2.0, 0.3015648326998657, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 327455.4353379763, 327455.4353379763, 111297.2591958274], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3969000.0000, 
sim time next is 3969600.0000, 
raw observation next is [19.66666666666667, 68.66666666666667, 1.0, 2.0, 0.302458020972562, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 328425.6350661692, 328425.6350661689, 111357.080960337], 
processed observation next is [0.0, 0.9565217391304348, 0.5303030303030305, 0.6866666666666668, 1.0, 1.0, 0.1280725262157025, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12163912409858119, 0.12163912409858108, 0.2716026364886268], 
reward next is 0.7284, 
noisyNet noise sample is [array([-0.16196002], dtype=float32), 2.5407279]. 
=============================================
[2019-03-23 00:27:28,124] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 5.5040184e-38 5.2685579e-26 2.8353688e-29], sum to 1.0000
[2019-03-23 00:27:28,131] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1821
[2019-03-23 00:27:28,135] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.5, 88.0, 1.0, 2.0, 0.2693943716769338, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 292512.49996392, 292512.4999639197, 97396.64314155928], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3997800.0000, 
sim time next is 3998400.0000, 
raw observation next is [16.66666666666666, 88.0, 1.0, 2.0, 0.2742587225008197, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 297795.903061524, 297795.9030615243, 100619.1279047544], 
processed observation next is [1.0, 0.2608695652173913, 0.39393939393939365, 0.88, 1.0, 1.0, 0.09282340312602458, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11029477891167555, 0.11029477891167568, 0.2454125070847668], 
reward next is 0.7546, 
noisyNet noise sample is [array([0.78024626], dtype=float32), 0.13604285]. 
=============================================
[2019-03-23 00:27:28,192] A3C_AGENT_WORKER-Thread-2 INFO:Local step 73000, global step 1169347: loss 0.1301
[2019-03-23 00:27:28,197] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 73000, global step 1169347: learning rate 0.0010
[2019-03-23 00:27:29,250] A3C_AGENT_WORKER-Thread-15 INFO:Local step 73000, global step 1169863: loss 0.0442
[2019-03-23 00:27:29,252] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 73000, global step 1169863: learning rate 0.0010
[2019-03-23 00:27:30,349] A3C_AGENT_WORKER-Thread-11 INFO:Local step 73000, global step 1170411: loss 0.0163
[2019-03-23 00:27:30,353] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 73000, global step 1170411: learning rate 0.0010
[2019-03-23 00:27:30,382] A3C_AGENT_WORKER-Thread-18 INFO:Local step 73000, global step 1170429: loss 0.0116
[2019-03-23 00:27:30,384] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 73000, global step 1170429: learning rate 0.0010
[2019-03-23 00:27:30,387] A3C_AGENT_WORKER-Thread-20 INFO:Local step 73000, global step 1170430: loss 0.0076
[2019-03-23 00:27:30,390] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 73000, global step 1170430: learning rate 0.0010
[2019-03-23 00:27:30,769] A3C_AGENT_WORKER-Thread-17 INFO:Local step 73000, global step 1170616: loss 0.0002
[2019-03-23 00:27:30,771] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 73000, global step 1170616: learning rate 0.0010
[2019-03-23 00:27:30,824] A3C_AGENT_WORKER-Thread-12 INFO:Local step 73000, global step 1170642: loss 0.0157
[2019-03-23 00:27:30,826] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 73000, global step 1170642: learning rate 0.0010
[2019-03-23 00:27:30,858] A3C_AGENT_WORKER-Thread-19 INFO:Local step 73000, global step 1170657: loss 0.0184
[2019-03-23 00:27:30,860] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 73000, global step 1170658: learning rate 0.0010
[2019-03-23 00:27:30,924] A3C_AGENT_WORKER-Thread-22 INFO:Local step 73000, global step 1170688: loss 0.0032
[2019-03-23 00:27:30,928] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 73000, global step 1170691: learning rate 0.0010
[2019-03-23 00:27:31,238] A3C_AGENT_WORKER-Thread-13 INFO:Local step 73000, global step 1170842: loss 0.0004
[2019-03-23 00:27:31,240] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 73000, global step 1170842: learning rate 0.0010
[2019-03-23 00:27:31,272] A3C_AGENT_WORKER-Thread-16 INFO:Local step 73000, global step 1170858: loss 0.0012
[2019-03-23 00:27:31,275] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 73000, global step 1170858: learning rate 0.0010
[2019-03-23 00:27:31,548] A3C_AGENT_WORKER-Thread-10 INFO:Local step 73000, global step 1170998: loss 0.0111
[2019-03-23 00:27:31,551] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 73000, global step 1171000: learning rate 0.0010
[2019-03-23 00:27:31,856] A3C_AGENT_WORKER-Thread-21 INFO:Local step 74000, global step 1171151: loss 0.0775
[2019-03-23 00:27:31,859] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 74000, global step 1171153: learning rate 0.0010
[2019-03-23 00:27:34,533] A3C_AGENT_WORKER-Thread-9 INFO:Local step 73500, global step 1172465: loss -52.0922
[2019-03-23 00:27:34,534] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 73500, global step 1172465: learning rate 0.0010
[2019-03-23 00:27:35,382] A3C_AGENT_WORKER-Thread-14 INFO:Local step 73500, global step 1172871: loss -7.5424
[2019-03-23 00:27:35,386] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 73500, global step 1172872: learning rate 0.0010
[2019-03-23 00:27:36,903] A3C_AGENT_WORKER-Thread-3 INFO:Local step 74000, global step 1173618: loss 0.0619
[2019-03-23 00:27:36,907] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 74000, global step 1173620: learning rate 0.0010
[2019-03-23 00:27:39,752] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-23 00:27:39,753] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 00:27:39,754] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 00:27:39,754] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:27:39,756] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 00:27:39,756] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:27:39,757] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:27:39,758] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 00:27:39,760] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 00:27:39,762] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:27:39,762] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:27:39,785] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run48
[2019-03-23 00:27:39,808] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run48
[2019-03-23 00:27:39,809] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run48
[2019-03-23 00:27:39,830] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run48
[2019-03-23 00:27:39,872] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run48
[2019-03-23 00:27:44,052] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02147089], dtype=float32), 0.13031386]
[2019-03-23 00:27:44,053] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.89639443, 85.92966406, 1.0, 2.0, 0.2977440422025599, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 324922.8745383716, 324922.8745383716, 115933.6181756131]
[2019-03-23 00:27:44,053] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 00:27:44,057] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.19493580107928543
[2019-03-23 00:27:46,051] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02147089], dtype=float32), 0.13031386]
[2019-03-23 00:27:46,052] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.22012760833333, 47.68618709, 1.0, 2.0, 0.3768985005052006, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 409258.3890381126, 409258.3890381122, 93197.3551206413]
[2019-03-23 00:27:46,054] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 00:27:46,057] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.2528512e-38 0.0000000e+00], sampled 0.7811477919376993
[2019-03-23 00:27:46,395] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02147089], dtype=float32), 0.13031386]
[2019-03-23 00:27:46,396] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [15.0, 77.0, 1.0, 2.0, 0.2209270438737523, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 239861.6811530432, 239861.6811530432, 79227.12043106012]
[2019-03-23 00:27:46,399] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 00:27:46,403] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.49700748491817826
[2019-03-23 00:28:31,564] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02147089], dtype=float32), 0.13031386]
[2019-03-23 00:28:31,565] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [24.86704708, 96.47203607, 1.0, 2.0, 0.7611948985768087, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9693528277791784, 6.935013341391412, 6.9112, 95.55327865410482, 1403919.977476061, 1394363.117524293, 310883.129214866]
[2019-03-23 00:28:31,569] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 00:28:31,572] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [6.1955275e-34 1.0000000e+00 1.0971004e-22 5.5698498e-17 6.4222157e-13], sampled 0.3256831386107486
[2019-03-23 00:28:31,572] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1403919.977476061 W.
[2019-03-23 00:28:56,128] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02147089], dtype=float32), 0.13031386]
[2019-03-23 00:28:56,130] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.26666666666667, 73.66666666666667, 1.0, 2.0, 0.3911156711287085, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 439325.2081780146, 439325.2081780146, 127655.8428451052]
[2019-03-23 00:28:56,132] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 00:28:56,138] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.15607697641347706
[2019-03-23 00:29:23,471] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02147089], dtype=float32), 0.13031386]
[2019-03-23 00:29:23,472] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [29.38004605, 65.59308929, 1.0, 2.0, 0.614581932843465, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 690541.3917840715, 690541.3917840711, 165255.4642812254]
[2019-03-23 00:29:23,474] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 00:29:23,478] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0.0000000e+00 1.0000000e+00 3.9378254e-37 2.9603147e-32 1.3441436e-38], sampled 0.6363135283725246
[2019-03-23 00:29:28,407] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9309 1705967916.6745 465.0000
[2019-03-23 00:29:28,682] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.0479 1773269573.6309 173.0000
[2019-03-23 00:29:29,051] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3486 1683344882.4587 214.0000
[2019-03-23 00:29:29,062] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1148 1656229146.4555 80.0000
[2019-03-23 00:29:29,180] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5598 1663796639.0689 105.0000
[2019-03-23 00:29:30,199] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 1175000, evaluation results [1175000.0, 8512.04786923644, 1773269573.6308813, 173.0, 9061.114827412715, 1656229146.4555063, 80.0, 8856.559759326878, 1663796639.0688558, 105.0, 8596.930884973775, 1705967916.6744611, 465.0, 8574.348638023737, 1683344882.4586744, 214.0]
[2019-03-23 00:29:32,649] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 2.2453731e-31 6.1044884e-31 1.0733021e-37], sum to 1.0000
[2019-03-23 00:29:32,657] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6605
[2019-03-23 00:29:32,664] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 83.0, 1.0, 2.0, 0.3746679383776181, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 420682.4972960377, 420682.497296038, 121825.7935257942], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4749600.0000, 
sim time next is 4750200.0000, 
raw observation next is [20.0, 83.0, 1.0, 2.0, 0.3743948593897641, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 420372.9200172487, 420372.920017249, 121801.0573494533], 
processed observation next is [1.0, 1.0, 0.5454545454545454, 0.83, 1.0, 1.0, 0.21799357423720508, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1556936740804625, 0.15569367408046259, 0.2970757496328129], 
reward next is 0.7029, 
noisyNet noise sample is [array([-0.7177104], dtype=float32), 0.67641056]. 
=============================================
[2019-03-23 00:29:32,821] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.0774747e-36 0.0000000e+00], sum to 1.0000
[2019-03-23 00:29:32,830] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6267
[2019-03-23 00:29:32,835] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 78.83333333333333, 1.0, 2.0, 0.4704535848964257, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 536631.928861673, 536631.928861673, 136685.0097551586], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4477800.0000, 
sim time next is 4478400.0000, 
raw observation next is [23.0, 78.0, 1.0, 2.0, 0.4647633300447079, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 530020.5831621346, 530020.5831621346, 135813.1826593141], 
processed observation next is [0.0, 0.8695652173913043, 0.6818181818181818, 0.78, 1.0, 1.0, 0.33095416255588483, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1963039196896795, 0.1963039196896795, 0.3312516650227173], 
reward next is 0.6687, 
noisyNet noise sample is [array([-0.4960082], dtype=float32), -0.8778127]. 
=============================================
[2019-03-23 00:29:34,163] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 3.2680713e-38 0.0000000e+00 8.2307433e-29], sum to 1.0000
[2019-03-23 00:29:34,170] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2730
[2019-03-23 00:29:34,174] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.66666666666667, 47.0, 1.0, 2.0, 0.383522450166649, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 434313.2553830777, 434313.2553830779, 124640.5555758272], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4296000.0000, 
sim time next is 4296600.0000, 
raw observation next is [26.5, 48.0, 1.0, 2.0, 0.3666856559285163, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 414482.7642988682, 414482.7642988685, 122655.4858138165], 
processed observation next is [1.0, 0.7391304347826086, 0.8409090909090909, 0.48, 1.0, 1.0, 0.20835706991064537, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15351213492550675, 0.15351213492550683, 0.2991597214971134], 
reward next is 0.7008, 
noisyNet noise sample is [array([0.00794629], dtype=float32), 1.484043]. 
=============================================
[2019-03-23 00:29:35,098] A3C_AGENT_WORKER-Thread-2 INFO:Local step 73500, global step 1177324: loss 19.5662
[2019-03-23 00:29:35,103] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 73500, global step 1177328: learning rate 0.0010
[2019-03-23 00:29:35,244] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.6149738e-26 1.1166720e-20 6.8482470e-29], sum to 1.0000
[2019-03-23 00:29:35,254] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2607
[2019-03-23 00:29:35,259] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 97.0, 1.0, 2.0, 0.6700763849470549, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 764756.1819262124, 764756.1819262124, 163016.8659049337], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4797000.0000, 
sim time next is 4797600.0000, 
raw observation next is [21.0, 98.0, 1.0, 2.0, 0.6546706199386193, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 747185.8392265181, 747185.8392265181, 160633.88758813], 
processed observation next is [1.0, 0.5217391304347826, 0.5909090909090909, 0.98, 1.0, 1.0, 0.568338274923274, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2767354960098215, 0.2767354960098215, 0.3917899697271463], 
reward next is 0.6082, 
noisyNet noise sample is [array([-1.9259648], dtype=float32), -0.062338512]. 
=============================================
[2019-03-23 00:29:36,190] A3C_AGENT_WORKER-Thread-15 INFO:Local step 73500, global step 1177851: loss 1.2172
[2019-03-23 00:29:36,193] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 73500, global step 1177851: learning rate 0.0010
[2019-03-23 00:29:37,222] A3C_AGENT_WORKER-Thread-11 INFO:Local step 73500, global step 1178338: loss 13.4630
[2019-03-23 00:29:37,224] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 73500, global step 1178339: learning rate 0.0010
[2019-03-23 00:29:37,316] A3C_AGENT_WORKER-Thread-18 INFO:Local step 73500, global step 1178381: loss 3.3653
[2019-03-23 00:29:37,318] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 73500, global step 1178381: learning rate 0.0010
[2019-03-23 00:29:37,410] A3C_AGENT_WORKER-Thread-20 INFO:Local step 73500, global step 1178425: loss -16.1657
[2019-03-23 00:29:37,414] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 73500, global step 1178426: learning rate 0.0010
[2019-03-23 00:29:37,762] A3C_AGENT_WORKER-Thread-17 INFO:Local step 73500, global step 1178593: loss 1.6562
[2019-03-23 00:29:37,763] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 73500, global step 1178593: learning rate 0.0010
[2019-03-23 00:29:37,771] A3C_AGENT_WORKER-Thread-22 INFO:Local step 73500, global step 1178596: loss 1.5795
[2019-03-23 00:29:37,774] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 73500, global step 1178596: learning rate 0.0010
[2019-03-23 00:29:37,800] A3C_AGENT_WORKER-Thread-12 INFO:Local step 73500, global step 1178608: loss -39.2011
[2019-03-23 00:29:37,801] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 73500, global step 1178608: learning rate 0.0010
[2019-03-23 00:29:37,888] A3C_AGENT_WORKER-Thread-19 INFO:Local step 73500, global step 1178648: loss -3.6922
[2019-03-23 00:29:37,892] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 73500, global step 1178650: learning rate 0.0010
[2019-03-23 00:29:38,231] A3C_AGENT_WORKER-Thread-16 INFO:Local step 73500, global step 1178809: loss 1.7856
[2019-03-23 00:29:38,232] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 73500, global step 1178810: learning rate 0.0010
[2019-03-23 00:29:38,275] A3C_AGENT_WORKER-Thread-13 INFO:Local step 73500, global step 1178830: loss -0.1709
[2019-03-23 00:29:38,278] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 73500, global step 1178830: learning rate 0.0010
[2019-03-23 00:29:38,514] A3C_AGENT_WORKER-Thread-10 INFO:Local step 73500, global step 1178943: loss -22.0199
[2019-03-23 00:29:38,518] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 73500, global step 1178943: learning rate 0.0010
[2019-03-23 00:29:38,712] A3C_AGENT_WORKER-Thread-21 INFO:Local step 74500, global step 1179035: loss 3.2189
[2019-03-23 00:29:38,715] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 74500, global step 1179036: learning rate 0.0010
[2019-03-23 00:29:41,510] A3C_AGENT_WORKER-Thread-9 INFO:Local step 74000, global step 1180366: loss 0.0275
[2019-03-23 00:29:41,513] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 74000, global step 1180367: learning rate 0.0010
[2019-03-23 00:29:42,341] A3C_AGENT_WORKER-Thread-14 INFO:Local step 74000, global step 1180759: loss 0.0615
[2019-03-23 00:29:42,342] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 74000, global step 1180759: learning rate 0.0010
[2019-03-23 00:29:44,035] A3C_AGENT_WORKER-Thread-3 INFO:Local step 74500, global step 1181560: loss 3.0305
[2019-03-23 00:29:44,040] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 74500, global step 1181564: learning rate 0.0010
[2019-03-23 00:29:45,557] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.8619162e-35 1.0000000e+00 2.5422726e-25 1.0616031e-15 9.5775866e-31], sum to 1.0000
[2019-03-23 00:29:45,561] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8402
[2019-03-23 00:29:45,568] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 52.5, 1.0, 2.0, 0.9179669158085854, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1042765.717878235, 1042765.717878235, 194260.0037522772], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4714200.0000, 
sim time next is 4714800.0000, 
raw observation next is [26.0, 53.0, 1.0, 2.0, 0.9416555804242314, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1070457.76532791, 1070457.76532791, 198838.3017782198], 
processed observation next is [1.0, 0.5652173913043478, 0.8181818181818182, 0.53, 1.0, 1.0, 0.9270694755302891, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.396465839010337, 0.396465839010337, 0.4849714677517556], 
reward next is 0.5150, 
noisyNet noise sample is [array([1.3692586], dtype=float32), 0.7831575]. 
=============================================
[2019-03-23 00:29:52,143] A3C_AGENT_WORKER-Thread-2 INFO:Local step 74000, global step 1185378: loss 0.0020
[2019-03-23 00:29:52,150] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 74000, global step 1185379: learning rate 0.0010
[2019-03-23 00:29:53,288] A3C_AGENT_WORKER-Thread-15 INFO:Local step 74000, global step 1185939: loss 0.0097
[2019-03-23 00:29:53,292] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 74000, global step 1185939: learning rate 0.0010
[2019-03-23 00:29:54,173] A3C_AGENT_WORKER-Thread-11 INFO:Local step 74000, global step 1186373: loss 0.0306
[2019-03-23 00:29:54,175] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 74000, global step 1186374: learning rate 0.0010
[2019-03-23 00:29:54,192] A3C_AGENT_WORKER-Thread-18 INFO:Local step 74000, global step 1186384: loss 0.0078
[2019-03-23 00:29:54,195] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 74000, global step 1186384: learning rate 0.0010
[2019-03-23 00:29:54,364] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 7.106909e-37 0.000000e+00], sum to 1.0000
[2019-03-23 00:29:54,368] A3C_AGENT_WORKER-Thread-20 INFO:Local step 74000, global step 1186470: loss 0.0172
[2019-03-23 00:29:54,370] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 74000, global step 1186471: learning rate 0.0010
[2019-03-23 00:29:54,371] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7350
[2019-03-23 00:29:54,376] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.66666666666667, 77.0, 1.0, 2.0, 0.5006073544442183, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 570390.3987810084, 570390.3987810081, 142797.5310649717], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5138400.0000, 
sim time next is 5139000.0000, 
raw observation next is [24.5, 78.5, 1.0, 2.0, 0.5036350978861786, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 573724.5070343501, 573724.5070343501, 143266.2989881079], 
processed observation next is [0.0, 0.4782608695652174, 0.75, 0.785, 1.0, 1.0, 0.37954387235772313, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2124905581608704, 0.2124905581608704, 0.3494299975319705], 
reward next is 0.6506, 
noisyNet noise sample is [array([1.3287905], dtype=float32), 0.47637478]. 
=============================================
[2019-03-23 00:29:54,391] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[69.15554 ]
 [69.1603  ]
 [69.211235]
 [69.263985]
 [69.3261  ]], R is [[69.11471558]
 [69.07527924]
 [69.03754425]
 [69.00197601]
 [68.96949005]].
[2019-03-23 00:29:54,646] A3C_AGENT_WORKER-Thread-12 INFO:Local step 74000, global step 1186611: loss 0.0444
[2019-03-23 00:29:54,648] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 74000, global step 1186611: learning rate 0.0010
[2019-03-23 00:29:54,676] A3C_AGENT_WORKER-Thread-22 INFO:Local step 74000, global step 1186623: loss 0.0207
[2019-03-23 00:29:54,678] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 74000, global step 1186624: learning rate 0.0010
[2019-03-23 00:29:54,780] A3C_AGENT_WORKER-Thread-19 INFO:Local step 74000, global step 1186676: loss 0.0013
[2019-03-23 00:29:54,787] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 74000, global step 1186678: learning rate 0.0010
[2019-03-23 00:29:54,795] A3C_AGENT_WORKER-Thread-17 INFO:Local step 74000, global step 1186682: loss 0.0020
[2019-03-23 00:29:54,796] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 74000, global step 1186683: learning rate 0.0010
[2019-03-23 00:29:55,110] A3C_AGENT_WORKER-Thread-16 INFO:Local step 74000, global step 1186842: loss 0.0010
[2019-03-23 00:29:55,117] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 74000, global step 1186843: learning rate 0.0010
[2019-03-23 00:29:55,145] A3C_AGENT_WORKER-Thread-13 INFO:Local step 74000, global step 1186856: loss 0.0031
[2019-03-23 00:29:55,150] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 74000, global step 1186857: learning rate 0.0010
[2019-03-23 00:29:55,478] A3C_AGENT_WORKER-Thread-21 INFO:Local step 75000, global step 1187016: loss 0.3482
[2019-03-23 00:29:55,481] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 75000, global step 1187017: learning rate 0.0010
[2019-03-23 00:29:55,546] A3C_AGENT_WORKER-Thread-10 INFO:Local step 74000, global step 1187048: loss 0.0114
[2019-03-23 00:29:55,548] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 74000, global step 1187050: learning rate 0.0010
[2019-03-23 00:29:56,239] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:29:56,246] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3738
[2019-03-23 00:29:56,250] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.33333333333334, 63.66666666666666, 1.0, 2.0, 0.4124670805466137, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 468780.561497637, 468780.561497637, 128543.6946776525], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4729200.0000, 
sim time next is 4729800.0000, 
raw observation next is [24.16666666666666, 64.33333333333334, 1.0, 2.0, 0.4144185396201743, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 470867.8784972291, 470867.8784972294, 128623.0111939104], 
processed observation next is [1.0, 0.7391304347826086, 0.7348484848484845, 0.6433333333333334, 1.0, 1.0, 0.2680231745252178, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1743955105545293, 0.17439551055452943, 0.3137146614485619], 
reward next is 0.6863, 
noisyNet noise sample is [array([-1.5537095], dtype=float32), 1.00831]. 
=============================================
[2019-03-23 00:29:58,126] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.6266182e-34 1.0000000e+00 7.6752488e-25 1.3405240e-22 1.8703371e-28], sum to 1.0000
[2019-03-23 00:29:58,135] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9173
[2019-03-23 00:29:58,149] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 54.00000000000001, 1.0, 2.0, 0.8390663699901788, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 954640.402541963, 954640.4025419633, 182929.2790390203], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4717200.0000, 
sim time next is 4717800.0000, 
raw observation next is [26.0, 54.0, 1.0, 2.0, 0.7963446035917295, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 905862.7258039399, 905862.7258039399, 176249.9948090637], 
processed observation next is [1.0, 0.6086956521739131, 0.8181818181818182, 0.54, 1.0, 1.0, 0.7454307544896618, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.33550471326071846, 0.33550471326071846, 0.4298780361196676], 
reward next is 0.5701, 
noisyNet noise sample is [array([-0.753554], dtype=float32), 0.5125473]. 
=============================================
[2019-03-23 00:29:58,238] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.8095351e-32 9.4281973e-24 3.9193361e-35], sum to 1.0000
[2019-03-23 00:29:58,249] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0518
[2019-03-23 00:29:58,253] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.86666666666667, 56.66666666666667, 1.0, 2.0, 0.739442167754945, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 841986.9733011556, 841986.9733011558, 168758.4893458234], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5305200.0000, 
sim time next is 5305800.0000, 
raw observation next is [26.23333333333333, 55.33333333333333, 1.0, 2.0, 0.7959758649053037, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 906871.5168621767, 906871.5168621765, 177611.2387369833], 
processed observation next is [1.0, 0.391304347826087, 0.8287878787878786, 0.5533333333333332, 1.0, 1.0, 0.7449698311316296, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.335878339578584, 0.3358783395785839, 0.43319814326093486], 
reward next is 0.5668, 
noisyNet noise sample is [array([1.0774134], dtype=float32), 0.0030248098]. 
=============================================
[2019-03-23 00:29:58,465] A3C_AGENT_WORKER-Thread-9 INFO:Local step 74500, global step 1188468: loss 3.3112
[2019-03-23 00:29:58,467] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 74500, global step 1188468: learning rate 0.0010
[2019-03-23 00:29:59,124] A3C_AGENT_WORKER-Thread-14 INFO:Local step 74500, global step 1188787: loss 3.3511
[2019-03-23 00:29:59,129] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 74500, global step 1188788: learning rate 0.0010
[2019-03-23 00:30:00,790] A3C_AGENT_WORKER-Thread-3 INFO:Local step 75000, global step 1189601: loss 0.6108
[2019-03-23 00:30:00,793] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 75000, global step 1189601: learning rate 0.0010
[2019-03-23 00:30:07,295] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.8799783e-26 9.9998808e-01 3.6076310e-20 1.1963934e-05 4.5616115e-13], sum to 1.0000
[2019-03-23 00:30:07,303] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9735
[2019-03-23 00:30:07,314] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.3728970260151543, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 418617.5189899665, 418617.5189899662, 121637.4029832347], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4930800.0000, 
sim time next is 4931400.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.372414366204482, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 418073.8163294232, 418073.8163294232, 121595.4861843346], 
processed observation next is [1.0, 0.043478260869565216, 0.45454545454545453, 1.0, 1.0, 1.0, 0.21551795775560245, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1548421541960827, 0.1548421541960827, 0.2965743565471576], 
reward next is 0.7034, 
noisyNet noise sample is [array([0.6669341], dtype=float32), -0.90613735]. 
=============================================
[2019-03-23 00:30:08,663] A3C_AGENT_WORKER-Thread-2 INFO:Local step 74500, global step 1193465: loss 2.2405
[2019-03-23 00:30:08,665] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 74500, global step 1193466: learning rate 0.0010
[2019-03-23 00:30:09,557] A3C_AGENT_WORKER-Thread-15 INFO:Local step 74500, global step 1193904: loss 2.0183
[2019-03-23 00:30:09,561] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 74500, global step 1193905: learning rate 0.0010
[2019-03-23 00:30:10,382] A3C_AGENT_WORKER-Thread-18 INFO:Local step 74500, global step 1194304: loss 2.7481
[2019-03-23 00:30:10,384] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 74500, global step 1194304: learning rate 0.0010
[2019-03-23 00:30:10,410] A3C_AGENT_WORKER-Thread-11 INFO:Local step 74500, global step 1194318: loss 2.1616
[2019-03-23 00:30:10,413] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 74500, global step 1194318: learning rate 0.0010
[2019-03-23 00:30:10,675] A3C_AGENT_WORKER-Thread-20 INFO:Local step 74500, global step 1194440: loss 1.8389
[2019-03-23 00:30:10,678] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 74500, global step 1194442: learning rate 0.0010
[2019-03-23 00:30:10,996] A3C_AGENT_WORKER-Thread-12 INFO:Local step 74500, global step 1194597: loss 2.3114
[2019-03-23 00:30:10,998] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 74500, global step 1194598: learning rate 0.0010
[2019-03-23 00:30:11,091] A3C_AGENT_WORKER-Thread-17 INFO:Local step 74500, global step 1194642: loss 1.8377
[2019-03-23 00:30:11,092] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 74500, global step 1194642: learning rate 0.0010
[2019-03-23 00:30:11,145] A3C_AGENT_WORKER-Thread-19 INFO:Local step 74500, global step 1194667: loss 1.8677
[2019-03-23 00:30:11,147] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 74500, global step 1194667: learning rate 0.0010
[2019-03-23 00:30:11,253] A3C_AGENT_WORKER-Thread-22 INFO:Local step 74500, global step 1194720: loss 2.0319
[2019-03-23 00:30:11,257] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 74500, global step 1194722: learning rate 0.0010
[2019-03-23 00:30:11,537] A3C_AGENT_WORKER-Thread-16 INFO:Local step 74500, global step 1194857: loss 1.5471
[2019-03-23 00:30:11,543] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 74500, global step 1194858: learning rate 0.0010
[2019-03-23 00:30:11,561] A3C_AGENT_WORKER-Thread-13 INFO:Local step 74500, global step 1194869: loss 1.9236
[2019-03-23 00:30:11,563] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 74500, global step 1194869: learning rate 0.0010
[2019-03-23 00:30:11,876] A3C_AGENT_WORKER-Thread-10 INFO:Local step 74500, global step 1195021: loss 1.7478
[2019-03-23 00:30:11,878] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 74500, global step 1195021: learning rate 0.0010
[2019-03-23 00:30:11,980] A3C_AGENT_WORKER-Thread-21 INFO:Local step 75500, global step 1195073: loss 0.0671
[2019-03-23 00:30:11,984] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 75500, global step 1195074: learning rate 0.0010
[2019-03-23 00:30:12,260] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 2.2045833e-38 9.2748733e-25 1.7062326e-35], sum to 1.0000
[2019-03-23 00:30:12,272] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9303
[2019-03-23 00:30:12,278] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.16666666666667, 72.16666666666667, 1.0, 2.0, 0.5139834950637387, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 558715.9498196769, 558715.9498196769, 128281.1610654024], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4975800.0000, 
sim time next is 4976400.0000, 
raw observation next is [19.33333333333334, 71.33333333333334, 1.0, 2.0, 0.5510643449944191, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 599648.4149634466, 599648.4149634466, 131943.2305498389], 
processed observation next is [1.0, 0.6086956521739131, 0.5151515151515155, 0.7133333333333334, 1.0, 1.0, 0.4388304312430239, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22209200554201725, 0.22209200554201725, 0.3218127574386314], 
reward next is 0.6782, 
noisyNet noise sample is [array([1.4925294], dtype=float32), -0.8969034]. 
=============================================
[2019-03-23 00:30:12,687] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 5.2190557e-31 4.6664420e-24 4.2191509e-27], sum to 1.0000
[2019-03-23 00:30:12,696] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0838
[2019-03-23 00:30:12,710] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.33333333333334, 71.33333333333334, 1.0, 2.0, 0.5510643449944191, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 599648.4149634466, 599648.4149634466, 131943.2305498389], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4976400.0000, 
sim time next is 4977000.0000, 
raw observation next is [19.5, 70.5, 1.0, 2.0, 0.5889042171568888, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 641722.9194488196, 641722.9194488198, 135936.4457229771], 
processed observation next is [1.0, 0.6086956521739131, 0.5227272727272727, 0.705, 1.0, 1.0, 0.48613027144611093, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.23767515535141467, 0.23767515535141476, 0.33155230664140756], 
reward next is 0.6684, 
noisyNet noise sample is [array([0.25471848], dtype=float32), -0.015327679]. 
=============================================
[2019-03-23 00:30:12,734] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[64.09594 ]
 [64.333824]
 [63.975277]
 [63.830536]
 [63.817924]], R is [[63.78637695]
 [63.82670212]
 [63.87555313]
 [63.91576004]
 [63.94998169]].
[2019-03-23 00:30:14,234] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:30:14,243] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9900
[2019-03-23 00:30:14,248] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 82.00000000000001, 1.0, 2.0, 0.2789452900537836, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 302886.2615718028, 302886.2615718031, 96000.95130887427], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5008200.0000, 
sim time next is 5008800.0000, 
raw observation next is [17.0, 82.0, 1.0, 2.0, 0.2791021241636032, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 303056.6093059492, 303056.6093059489, 96001.59345548457], 
processed observation next is [1.0, 1.0, 0.4090909090909091, 0.82, 1.0, 1.0, 0.09887765520450398, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11224318863183302, 0.11224318863183293, 0.2341502279402063], 
reward next is 0.7658, 
noisyNet noise sample is [array([0.46822888], dtype=float32), -0.069775015]. 
=============================================
[2019-03-23 00:30:14,818] A3C_AGENT_WORKER-Thread-9 INFO:Local step 75000, global step 1196444: loss 0.0390
[2019-03-23 00:30:14,819] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 75000, global step 1196444: learning rate 0.0010
[2019-03-23 00:30:15,543] A3C_AGENT_WORKER-Thread-14 INFO:Local step 75000, global step 1196798: loss 0.0706
[2019-03-23 00:30:15,547] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 75000, global step 1196798: learning rate 0.0010
[2019-03-23 00:30:16,478] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:30:16,485] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5637
[2019-03-23 00:30:16,493] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 55.5, 1.0, 2.0, 0.3757208258897861, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 424540.9147258562, 424540.9147258559, 123354.7472466461], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5056200.0000, 
sim time next is 5056800.0000, 
raw observation next is [25.33333333333333, 55.0, 1.0, 2.0, 0.382456672461094, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 432916.8780092187, 432916.8780092187, 124423.8305089621], 
processed observation next is [0.0, 0.5217391304347826, 0.7878787878787876, 0.55, 1.0, 1.0, 0.22807084057636748, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16033958444785879, 0.16033958444785879, 0.303472757338932], 
reward next is 0.6965, 
noisyNet noise sample is [array([-0.39629456], dtype=float32), -0.749844]. 
=============================================
[2019-03-23 00:30:17,550] A3C_AGENT_WORKER-Thread-3 INFO:Local step 75500, global step 1197780: loss 0.0805
[2019-03-23 00:30:17,555] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 75500, global step 1197782: learning rate 0.0010
[2019-03-23 00:30:22,106] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-23 00:30:22,106] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 00:30:22,108] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:30:22,109] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 00:30:22,110] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:30:22,111] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 00:30:22,112] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 00:30:22,112] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:30:22,114] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:30:22,114] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 00:30:22,117] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:30:22,138] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run49
[2019-03-23 00:30:22,139] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run49
[2019-03-23 00:30:22,139] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run49
[2019-03-23 00:30:22,205] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run49
[2019-03-23 00:30:22,231] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run49
[2019-03-23 00:30:31,485] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.03441343], dtype=float32), 0.13321471]
[2019-03-23 00:30:31,487] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [12.54190578333333, 96.06173776666665, 1.0, 2.0, 0.3776884311045041, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 410116.434492629, 410116.434492629, 93786.28118073715]
[2019-03-23 00:30:31,487] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 00:30:31,490] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.4732362894574563
[2019-03-23 00:30:39,977] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.03441343], dtype=float32), 0.13321471]
[2019-03-23 00:30:39,978] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [26.15610345, 68.30451711, 1.0, 2.0, 0.5307729054309954, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 604628.6500889013, 604628.6500889013, 150816.6757992263]
[2019-03-23 00:30:39,980] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 00:30:39,982] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.6694576927135706
[2019-03-23 00:30:52,153] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.03441343], dtype=float32), 0.13321471]
[2019-03-23 00:30:52,156] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.0, 75.5, 1.0, 2.0, 0.4133761141261911, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 451003.9041341418, 451003.9041341415, 120181.8362375997]
[2019-03-23 00:30:52,158] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 00:30:52,166] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.6729349668267055
[2019-03-23 00:30:53,798] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.03441343], dtype=float32), 0.13321471]
[2019-03-23 00:30:53,803] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.69703583666666, 50.38751485333334, 1.0, 2.0, 0.3273871529043537, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 355480.176699542, 355480.1766995416, 93096.09589031289]
[2019-03-23 00:30:53,804] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 00:30:53,808] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.7530019244264926
[2019-03-23 00:31:27,507] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.03441343], dtype=float32), 0.13321471]
[2019-03-23 00:31:27,509] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.184547165, 78.47175040333333, 1.0, 2.0, 0.4220820416369686, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 476676.2224911957, 476676.2224911954, 131769.2265075999]
[2019-03-23 00:31:27,511] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 00:31:27,514] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.3739515581110129
[2019-03-23 00:31:28,706] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.03441343], dtype=float32), 0.13321471]
[2019-03-23 00:31:28,706] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.15306038666667, 96.15689287666666, 1.0, 2.0, 0.4929049640387183, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 561803.0929355298, 561803.0929355294, 145925.713044626]
[2019-03-23 00:31:28,706] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 00:31:28,709] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.6383570190049278
[2019-03-23 00:31:32,582] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.03441343], dtype=float32), 0.13321471]
[2019-03-23 00:31:32,583] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [24.83333333333334, 74.0, 1.0, 2.0, 0.4852879149384731, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 553411.5666877675, 553411.5666877675, 140413.2481142719]
[2019-03-23 00:31:32,584] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 00:31:32,586] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.4174297520892327
[2019-03-23 00:31:54,899] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.03441343], dtype=float32), 0.13321471]
[2019-03-23 00:31:54,899] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.2, 91.0, 1.0, 2.0, 0.4832398152281271, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 551217.0795700316, 551217.0795700316, 144087.9708370421]
[2019-03-23 00:31:54,900] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 00:31:54,904] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.5571129057467261
[2019-03-23 00:32:11,107] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3485 1683325900.1134 214.0000
[2019-03-23 00:32:11,206] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2492 1773187030.7201 173.0000
[2019-03-23 00:32:11,273] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9310 1705987275.5940 465.0000
[2019-03-23 00:32:11,396] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1147 1656209757.7786 80.0000
[2019-03-23 00:32:11,414] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5598 1663796639.0689 105.0000
[2019-03-23 00:32:12,431] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1200000, evaluation results [1200000.0, 8512.249193409023, 1773187030.7201214, 173.0, 9061.114669779829, 1656209757.7786272, 80.0, 8856.559759326878, 1663796639.0688558, 105.0, 8596.931041181726, 1705987275.594041, 465.0, 8574.348472942609, 1683325900.1133502, 214.0]
[2019-03-23 00:32:15,498] A3C_AGENT_WORKER-Thread-2 INFO:Local step 75000, global step 1201469: loss 0.1784
[2019-03-23 00:32:15,500] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 75000, global step 1201470: learning rate 0.0010
[2019-03-23 00:32:16,282] A3C_AGENT_WORKER-Thread-15 INFO:Local step 75000, global step 1201832: loss 0.6488
[2019-03-23 00:32:16,285] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 75000, global step 1201833: learning rate 0.0010
[2019-03-23 00:32:17,221] A3C_AGENT_WORKER-Thread-18 INFO:Local step 75000, global step 1202282: loss 0.1047
[2019-03-23 00:32:17,226] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 75000, global step 1202283: learning rate 0.0010
[2019-03-23 00:32:17,228] A3C_AGENT_WORKER-Thread-11 INFO:Local step 75000, global step 1202283: loss 0.0351
[2019-03-23 00:32:17,233] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 75000, global step 1202284: learning rate 0.0010
[2019-03-23 00:32:17,375] A3C_AGENT_WORKER-Thread-20 INFO:Local step 75000, global step 1202350: loss 0.2312
[2019-03-23 00:32:17,376] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 75000, global step 1202350: learning rate 0.0010
[2019-03-23 00:32:17,750] A3C_AGENT_WORKER-Thread-19 INFO:Local step 75000, global step 1202527: loss 0.3786
[2019-03-23 00:32:17,754] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 75000, global step 1202528: learning rate 0.0010
[2019-03-23 00:32:17,769] A3C_AGENT_WORKER-Thread-12 INFO:Local step 75000, global step 1202534: loss -2.9933
[2019-03-23 00:32:17,772] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 75000, global step 1202536: learning rate 0.0010
[2019-03-23 00:32:17,937] A3C_AGENT_WORKER-Thread-17 INFO:Local step 75000, global step 1202613: loss 0.0180
[2019-03-23 00:32:17,944] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 75000, global step 1202615: learning rate 0.0010
[2019-03-23 00:32:18,102] A3C_AGENT_WORKER-Thread-22 INFO:Local step 75000, global step 1202691: loss 0.0334
[2019-03-23 00:32:18,103] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 75000, global step 1202692: learning rate 0.0010
[2019-03-23 00:32:18,153] A3C_AGENT_WORKER-Thread-16 INFO:Local step 75000, global step 1202715: loss 0.8531
[2019-03-23 00:32:18,156] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 75000, global step 1202715: learning rate 0.0010
[2019-03-23 00:32:18,326] A3C_AGENT_WORKER-Thread-13 INFO:Local step 75000, global step 1202795: loss 0.1507
[2019-03-23 00:32:18,330] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 75000, global step 1202796: learning rate 0.0010
[2019-03-23 00:32:18,561] A3C_AGENT_WORKER-Thread-10 INFO:Local step 75000, global step 1202902: loss 1.4461
[2019-03-23 00:32:18,563] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 75000, global step 1202903: learning rate 0.0010
[2019-03-23 00:32:18,984] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.0039468e-33 1.1048694e-16 9.1724956e-30], sum to 1.0000
[2019-03-23 00:32:18,994] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7205
[2019-03-23 00:32:19,001] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 88.5, 1.0, 2.0, 0.3463383450589265, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 386364.8930751084, 386364.8930751081, 118280.8254743329], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5286600.0000, 
sim time next is 5287200.0000, 
raw observation next is [18.8, 88.0, 1.0, 2.0, 0.3448448837378084, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 384382.3768627165, 384382.3768627162, 118023.1314280397], 
processed observation next is [1.0, 0.17391304347826086, 0.49090909090909096, 0.88, 1.0, 1.0, 0.1810561046722605, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1423638432824876, 0.1423638432824875, 0.2878612961659505], 
reward next is 0.7121, 
noisyNet noise sample is [array([0.543936], dtype=float32), -0.11524053]. 
=============================================
[2019-03-23 00:32:19,170] A3C_AGENT_WORKER-Thread-21 INFO:Local step 76000, global step 1203187: loss 1.3561
[2019-03-23 00:32:19,174] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 76000, global step 1203187: learning rate 0.0010
[2019-03-23 00:32:22,341] A3C_AGENT_WORKER-Thread-9 INFO:Local step 75500, global step 1204659: loss 0.0655
[2019-03-23 00:32:22,345] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 75500, global step 1204660: learning rate 0.0010
[2019-03-23 00:32:23,235] A3C_AGENT_WORKER-Thread-14 INFO:Local step 75500, global step 1205075: loss 0.0890
[2019-03-23 00:32:23,239] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 75500, global step 1205076: learning rate 0.0010
[2019-03-23 00:32:24,054] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.2853937e-36 1.0000000e+00 5.7997499e-33 2.0998268e-24 6.1066839e-29], sum to 1.0000
[2019-03-23 00:32:24,060] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7301
[2019-03-23 00:32:24,068] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.23333333333333, 87.0, 1.0, 2.0, 0.497357012946811, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 566341.5905240111, 566341.5905240111, 138206.330167127], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5368800.0000, 
sim time next is 5369400.0000, 
raw observation next is [21.05, 87.0, 1.0, 2.0, 0.4914333024727628, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 559138.0881158841, 559138.0881158841, 137103.0313572795], 
processed observation next is [1.0, 0.13043478260869565, 0.5931818181818183, 0.87, 1.0, 1.0, 0.36429162809095345, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20708818078366079, 0.20708818078366079, 0.3343976374567793], 
reward next is 0.6656, 
noisyNet noise sample is [array([-1.4636683], dtype=float32), 0.72180325]. 
=============================================
[2019-03-23 00:32:24,768] A3C_AGENT_WORKER-Thread-3 INFO:Local step 76000, global step 1205808: loss 1.0529
[2019-03-23 00:32:24,772] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 76000, global step 1205809: learning rate 0.0010
[2019-03-23 00:32:25,931] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 3.3299757e-37 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 00:32:25,938] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2844
[2019-03-23 00:32:25,942] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.25, 90.0, 1.0, 2.0, 0.4163995186047638, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 472304.7218239384, 472304.7218239384, 128194.8988262931], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5599800.0000, 
sim time next is 5600400.0000, 
raw observation next is [20.16666666666666, 91.0, 1.0, 2.0, 0.4175096940780791, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 473688.3538689913, 473688.3538689913, 128390.2368776907], 
processed observation next is [1.0, 0.8260869565217391, 0.5530303030303028, 0.91, 1.0, 1.0, 0.2718871175975988, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17544013106258938, 0.17544013106258938, 0.31314691921387977], 
reward next is 0.6869, 
noisyNet noise sample is [array([0.7567078], dtype=float32), 0.94053787]. 
=============================================
[2019-03-23 00:32:27,701] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 2.4004027e-31 3.4840685e-35 6.1476944e-32], sum to 1.0000
[2019-03-23 00:32:27,711] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3983
[2019-03-23 00:32:27,718] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.71666666666667, 93.5, 1.0, 2.0, 0.3869341765812577, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 434440.1270800389, 434440.1270800389, 122874.2156452616], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5433000.0000, 
sim time next is 5433600.0000, 
raw observation next is [18.63333333333333, 94.0, 1.0, 2.0, 0.3852747066436508, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 432437.145774332, 432437.1457743317, 122662.5329789096], 
processed observation next is [1.0, 0.9130434782608695, 0.48333333333333317, 0.94, 1.0, 1.0, 0.2315933833045635, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1601619058423452, 0.16016190584234508, 0.29917690970465755], 
reward next is 0.7008, 
noisyNet noise sample is [array([-0.08194599], dtype=float32), 0.66676235]. 
=============================================
[2019-03-23 00:32:32,306] A3C_AGENT_WORKER-Thread-2 INFO:Local step 75500, global step 1209386: loss 0.1386
[2019-03-23 00:32:32,309] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 75500, global step 1209388: learning rate 0.0010
[2019-03-23 00:32:33,400] A3C_AGENT_WORKER-Thread-15 INFO:Local step 75500, global step 1209900: loss 0.8601
[2019-03-23 00:32:33,403] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 75500, global step 1209902: learning rate 0.0010
[2019-03-23 00:32:34,278] A3C_AGENT_WORKER-Thread-11 INFO:Local step 75500, global step 1210309: loss 0.2220
[2019-03-23 00:32:34,281] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 75500, global step 1210309: learning rate 0.0010
[2019-03-23 00:32:34,295] A3C_AGENT_WORKER-Thread-18 INFO:Local step 75500, global step 1210314: loss 0.2021
[2019-03-23 00:32:34,301] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 75500, global step 1210316: learning rate 0.0010
[2019-03-23 00:32:34,409] A3C_AGENT_WORKER-Thread-20 INFO:Local step 75500, global step 1210372: loss 0.2538
[2019-03-23 00:32:34,411] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 75500, global step 1210372: learning rate 0.0010
[2019-03-23 00:32:34,472] A3C_AGENT_WORKER-Thread-19 INFO:Local step 75500, global step 1210408: loss 0.2455
[2019-03-23 00:32:34,473] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 75500, global step 1210408: learning rate 0.0010
[2019-03-23 00:32:34,650] A3C_AGENT_WORKER-Thread-12 INFO:Local step 75500, global step 1210492: loss 0.3253
[2019-03-23 00:32:34,653] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 75500, global step 1210492: learning rate 0.0010
[2019-03-23 00:32:35,073] A3C_AGENT_WORKER-Thread-22 INFO:Local step 75500, global step 1210697: loss 0.1612
[2019-03-23 00:32:35,075] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 75500, global step 1210697: learning rate 0.0010
[2019-03-23 00:32:35,110] A3C_AGENT_WORKER-Thread-17 INFO:Local step 75500, global step 1210713: loss 0.1919
[2019-03-23 00:32:35,112] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 75500, global step 1210713: learning rate 0.0010
[2019-03-23 00:32:35,195] A3C_AGENT_WORKER-Thread-16 INFO:Local step 75500, global step 1210753: loss 0.1507
[2019-03-23 00:32:35,199] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 75500, global step 1210753: learning rate 0.0010
[2019-03-23 00:32:35,396] A3C_AGENT_WORKER-Thread-13 INFO:Local step 75500, global step 1210847: loss 0.1891
[2019-03-23 00:32:35,400] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 75500, global step 1210848: learning rate 0.0010
[2019-03-23 00:32:35,603] A3C_AGENT_WORKER-Thread-10 INFO:Local step 75500, global step 1210939: loss 0.1263
[2019-03-23 00:32:35,606] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 75500, global step 1210940: learning rate 0.0010
[2019-03-23 00:32:35,893] A3C_AGENT_WORKER-Thread-21 INFO:Local step 76500, global step 1211084: loss 0.2873
[2019-03-23 00:32:35,895] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 76500, global step 1211085: learning rate 0.0010
[2019-03-23 00:32:39,177] A3C_AGENT_WORKER-Thread-9 INFO:Local step 76000, global step 1212588: loss 0.0079
[2019-03-23 00:32:39,179] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 76000, global step 1212588: learning rate 0.0010
[2019-03-23 00:32:40,039] A3C_AGENT_WORKER-Thread-14 INFO:Local step 76000, global step 1213010: loss 0.0240
[2019-03-23 00:32:40,042] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 76000, global step 1213010: learning rate 0.0010
[2019-03-23 00:32:41,579] A3C_AGENT_WORKER-Thread-3 INFO:Local step 76500, global step 1213757: loss 0.0458
[2019-03-23 00:32:41,584] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 76500, global step 1213760: learning rate 0.0010
[2019-03-23 00:32:43,758] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:32:43,767] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1654
[2019-03-23 00:32:43,772] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 67.33333333333334, 1.0, 2.0, 0.5068482734080222, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 577839.5588683551, 577839.5588683551, 143168.9495741549], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6297000.0000, 
sim time next is 6297600.0000, 
raw observation next is [25.9, 67.66666666666667, 1.0, 2.0, 0.5072026465808935, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 578303.4758069207, 578303.4758069207, 143132.3710029324], 
processed observation next is [0.0, 0.9130434782608695, 0.8136363636363636, 0.6766666666666667, 1.0, 1.0, 0.3840033082261169, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21418647252108172, 0.21418647252108172, 0.3491033439095912], 
reward next is 0.6509, 
noisyNet noise sample is [array([0.7625025], dtype=float32), -0.19115278]. 
=============================================
[2019-03-23 00:32:44,948] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.1979553e-34 0.0000000e+00], sum to 1.0000
[2019-03-23 00:32:44,960] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9546
[2019-03-23 00:32:44,966] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [11.83333333333333, 82.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 159234.0501139188, 159234.050113919, 59058.72735495125], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5728800.0000, 
sim time next is 5729400.0000, 
raw observation next is [12.2, 80.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 163825.1198455309, 163825.1198455306, 59662.14610197004], 
processed observation next is [0.0, 0.30434782608695654, 0.1909090909090909, 0.8, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.06067597031315959, 0.06067597031315948, 0.14551742951700009], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.6923898], dtype=float32), -0.81938535]. 
=============================================
[2019-03-23 00:32:47,203] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:32:47,211] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3957
[2019-03-23 00:32:47,218] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.96666666666667, 60.0, 1.0, 2.0, 0.2160776379385588, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 234606.4180994516, 234606.4180994513, 73760.75076979672], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5780400.0000, 
sim time next is 5781000.0000, 
raw observation next is [16.78333333333333, 61.0, 1.0, 2.0, 0.213809530154092, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 232143.2311165889, 232143.2311165886, 73442.35144947366], 
processed observation next is [0.0, 0.9130434782608695, 0.3992424242424242, 0.61, 1.0, 1.0, 0.01726191269261497, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08597897448762552, 0.08597897448762541, 0.17912768646213087], 
reward next is 0.8209, 
noisyNet noise sample is [array([-0.2374473], dtype=float32), -0.31082392]. 
=============================================
[2019-03-23 00:32:47,236] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[73.92    ]
 [74.060745]
 [74.232445]
 [74.460266]
 [74.78537 ]], R is [[73.86193848]
 [73.94342041]
 [74.02333069]
 [74.10177612]
 [74.17893982]].
[2019-03-23 00:32:47,868] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 6.1786895e-37 1.0524543e-37 0.0000000e+00], sum to 1.0000
[2019-03-23 00:32:47,876] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6236
[2019-03-23 00:32:47,882] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.1, 82.0, 1.0, 2.0, 0.5975235948013637, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 671452.4632413645, 671452.4632413645, 158550.5772401466], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6271200.0000, 
sim time next is 6271800.0000, 
raw observation next is [26.65, 78.16666666666667, 1.0, 2.0, 0.6033282074292295, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 677979.8042680224, 677979.8042680224, 159358.9342578356], 
processed observation next is [0.0, 0.6086956521739131, 0.8477272727272727, 0.7816666666666667, 1.0, 1.0, 0.5041602592865368, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.25110363121037865, 0.25110363121037865, 0.3886803274581356], 
reward next is 0.6113, 
noisyNet noise sample is [array([1.9629121], dtype=float32), 1.5249437]. 
=============================================
[2019-03-23 00:32:48,936] A3C_AGENT_WORKER-Thread-2 INFO:Local step 76000, global step 1217351: loss 4.8587
[2019-03-23 00:32:48,937] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 76000, global step 1217351: learning rate 0.0010
[2019-03-23 00:32:50,047] A3C_AGENT_WORKER-Thread-15 INFO:Local step 76000, global step 1217902: loss 4.8558
[2019-03-23 00:32:50,051] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 76000, global step 1217902: learning rate 0.0010
[2019-03-23 00:32:50,833] A3C_AGENT_WORKER-Thread-20 INFO:Local step 76000, global step 1218279: loss 3.5663
[2019-03-23 00:32:50,835] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 76000, global step 1218279: learning rate 0.0010
[2019-03-23 00:32:50,915] A3C_AGENT_WORKER-Thread-18 INFO:Local step 76000, global step 1218325: loss 2.4703
[2019-03-23 00:32:50,918] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 76000, global step 1218326: learning rate 0.0010
[2019-03-23 00:32:50,938] A3C_AGENT_WORKER-Thread-11 INFO:Local step 76000, global step 1218334: loss 4.7221
[2019-03-23 00:32:50,940] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 76000, global step 1218334: learning rate 0.0010
[2019-03-23 00:32:51,094] A3C_AGENT_WORKER-Thread-19 INFO:Local step 76000, global step 1218410: loss 0.6277
[2019-03-23 00:32:51,096] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 76000, global step 1218410: learning rate 0.0010
[2019-03-23 00:32:51,321] A3C_AGENT_WORKER-Thread-12 INFO:Local step 76000, global step 1218514: loss 2.2760
[2019-03-23 00:32:51,326] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 76000, global step 1218516: learning rate 0.0010
[2019-03-23 00:32:51,666] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.7524914e-31 1.0000000e+00 1.7704336e-22 2.6940603e-25 1.4482895e-17], sum to 1.0000
[2019-03-23 00:32:51,675] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5612
[2019-03-23 00:32:51,681] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.8, 92.5, 1.0, 2.0, 0.7128423349808054, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 791521.0735766836, 791521.0735766839, 154353.9156968214], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6444600.0000, 
sim time next is 6445200.0000, 
raw observation next is [17.9, 92.0, 1.0, 2.0, 0.6960954778638838, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 773417.8857200908, 773417.8857200905, 152497.0031597443], 
processed observation next is [1.0, 0.6086956521739131, 0.44999999999999996, 0.92, 1.0, 1.0, 0.6201193473298547, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2864510687852188, 0.2864510687852187, 0.37194391014571776], 
reward next is 0.6281, 
noisyNet noise sample is [array([0.62551135], dtype=float32), 0.35778722]. 
=============================================
[2019-03-23 00:32:51,745] A3C_AGENT_WORKER-Thread-22 INFO:Local step 76000, global step 1218721: loss 1.9230
[2019-03-23 00:32:51,748] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 76000, global step 1218721: learning rate 0.0010
[2019-03-23 00:32:51,845] A3C_AGENT_WORKER-Thread-16 INFO:Local step 76000, global step 1218769: loss 1.5712
[2019-03-23 00:32:51,847] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 76000, global step 1218769: learning rate 0.0010
[2019-03-23 00:32:51,865] A3C_AGENT_WORKER-Thread-17 INFO:Local step 76000, global step 1218776: loss 2.8685
[2019-03-23 00:32:51,868] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 76000, global step 1218777: learning rate 0.0010
[2019-03-23 00:32:52,075] A3C_AGENT_WORKER-Thread-13 INFO:Local step 76000, global step 1218880: loss 0.3212
[2019-03-23 00:32:52,079] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 76000, global step 1218880: learning rate 0.0010
[2019-03-23 00:32:52,230] A3C_AGENT_WORKER-Thread-10 INFO:Local step 76000, global step 1218953: loss 0.4038
[2019-03-23 00:32:52,234] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 76000, global step 1218953: learning rate 0.0010
[2019-03-23 00:32:52,272] A3C_AGENT_WORKER-Thread-21 INFO:Local step 77000, global step 1218975: loss 16.0926
[2019-03-23 00:32:52,273] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 77000, global step 1218976: learning rate 0.0010
[2019-03-23 00:32:55,433] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.9828387e-36 1.0000000e+00 6.6153930e-25 8.4267740e-27 2.6669728e-33], sum to 1.0000
[2019-03-23 00:32:55,439] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4865
[2019-03-23 00:32:55,444] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.36666666666667, 52.66666666666666, 1.0, 2.0, 0.7891931939010972, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 897760.8993709072, 897760.8993709072, 175212.6892468575], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5922600.0000, 
sim time next is 5923200.0000, 
raw observation next is [26.63333333333333, 51.33333333333334, 1.0, 2.0, 0.8416515846737774, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 957670.7667713922, 957670.7667713922, 183413.5136502634], 
processed observation next is [1.0, 0.5652173913043478, 0.8469696969696968, 0.5133333333333334, 1.0, 1.0, 0.8020644808422217, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3546928765819971, 0.3546928765819971, 0.44735003329332534], 
reward next is 0.5526, 
noisyNet noise sample is [array([-0.00598016], dtype=float32), 0.19426654]. 
=============================================
[2019-03-23 00:32:55,764] A3C_AGENT_WORKER-Thread-9 INFO:Local step 76500, global step 1220675: loss 0.1477
[2019-03-23 00:32:55,767] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 76500, global step 1220675: learning rate 0.0010
[2019-03-23 00:32:56,640] A3C_AGENT_WORKER-Thread-14 INFO:Local step 76500, global step 1221104: loss 0.0936
[2019-03-23 00:32:56,645] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 76500, global step 1221104: learning rate 0.0010
[2019-03-23 00:32:57,680] A3C_AGENT_WORKER-Thread-3 INFO:Local step 77000, global step 1221613: loss 16.0234
[2019-03-23 00:32:57,682] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 77000, global step 1221615: learning rate 0.0010
[2019-03-23 00:33:04,613] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-23 00:33:04,614] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 00:33:04,615] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:33:04,616] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 00:33:04,617] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:33:04,618] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 00:33:04,619] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 00:33:04,620] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:33:04,620] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:33:04,622] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 00:33:04,624] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:33:04,644] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run50
[2019-03-23 00:33:04,645] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run50
[2019-03-23 00:33:04,669] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run50
[2019-03-23 00:33:04,670] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run50
[2019-03-23 00:33:04,737] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run50
[2019-03-23 00:33:06,051] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.15607175], dtype=float32), 0.06332793]
[2019-03-23 00:33:06,053] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.67750118666667, 100.0, 1.0, 2.0, 0.3488373589401733, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 389258.7635614607, 389258.7635614603, 122847.2797016506]
[2019-03-23 00:33:06,055] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 00:33:06,058] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.5414050415938984
[2019-03-23 00:33:06,559] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.15607175], dtype=float32), 0.06332793]
[2019-03-23 00:33:06,561] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [17.2, 51.0, 1.0, 2.0, 0.2439861913791073, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 264902.6386127583, 264902.6386127583, 79138.99375678184]
[2019-03-23 00:33:06,562] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 00:33:06,569] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.16886214178890235
[2019-03-23 00:33:25,078] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.15607175], dtype=float32), 0.06332793]
[2019-03-23 00:33:25,079] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [28.08333333333333, 58.66666666666666, 1.0, 2.0, 0.5316527665343913, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 605098.6698791817, 605098.6698791817, 151353.1926009727]
[2019-03-23 00:33:25,080] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 00:33:25,083] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.6893660862943822
[2019-03-23 00:33:38,122] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.15607175], dtype=float32), 0.06332793]
[2019-03-23 00:33:38,124] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.25, 81.5, 1.0, 2.0, 0.3622942681566114, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 401636.9880581766, 401636.9880581766, 122833.0421127814]
[2019-03-23 00:33:38,125] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 00:33:38,130] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.34556060472822137
[2019-03-23 00:33:59,065] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.15607175], dtype=float32), 0.06332793]
[2019-03-23 00:33:59,068] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [27.38333333333333, 59.33333333333333, 1.0, 2.0, 0.8747000682275271, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 997256.8392202961, 997256.8392202961, 201452.5300527577]
[2019-03-23 00:33:59,070] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 00:33:59,073] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0.0000000e+00 1.0000000e+00 2.9461598e-28 1.3180472e-27 2.9371878e-32], sampled 0.34466080442883507
[2019-03-23 00:34:17,650] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.15607175], dtype=float32), 0.06332793]
[2019-03-23 00:34:17,651] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.9, 90.0, 1.0, 2.0, 0.3625080736482267, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 405721.936087509, 405721.9360875087, 124494.2080635819]
[2019-03-23 00:34:17,655] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 00:34:17,659] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.5290074099632348
[2019-03-23 00:34:30,368] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.15607175], dtype=float32), 0.06332793]
[2019-03-23 00:34:30,370] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.08333333333333, 59.16666666666666, 1.0, 2.0, 0.2759880930795942, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 299656.6606873874, 299656.660687387, 99585.99960174732]
[2019-03-23 00:34:30,373] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 00:34:30,376] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.7891397744407173
[2019-03-23 00:34:53,042] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 00:34:53,291] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1147 1656209757.7786 80.0000
[2019-03-23 00:34:53,387] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5599 1663815647.6096 105.0000
[2019-03-23 00:34:53,473] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3486 1683344882.4587 214.0000
[2019-03-23 00:34:53,494] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2494 1773207034.4548 173.0000
[2019-03-23 00:34:54,510] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 1225000, evaluation results [1225000.0, 8512.249429056992, 1773207034.4547563, 173.0, 9061.114669779829, 1656209757.7786272, 80.0, 8856.559925897878, 1663815647.6095803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8574.348638023737, 1683344882.4586744, 214.0]
[2019-03-23 00:34:55,404] A3C_AGENT_WORKER-Thread-2 INFO:Local step 76500, global step 1225427: loss 0.2605
[2019-03-23 00:34:55,410] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 76500, global step 1225427: learning rate 0.0010
[2019-03-23 00:34:56,548] A3C_AGENT_WORKER-Thread-15 INFO:Local step 76500, global step 1225971: loss 0.0447
[2019-03-23 00:34:56,550] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 76500, global step 1225971: learning rate 0.0010
[2019-03-23 00:34:56,611] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.3069001e-38 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 00:34:56,620] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1684
[2019-03-23 00:34:56,627] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.7, 65.0, 1.0, 2.0, 0.5568757027888104, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 631148.3911133218, 631148.3911133218, 151595.2739476465], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6359400.0000, 
sim time next is 6360000.0000, 
raw observation next is [27.7, 65.0, 1.0, 2.0, 0.5576137208325436, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 631984.5756895146, 631984.575689515, 151691.5546650293], 
processed observation next is [0.0, 0.6086956521739131, 0.8954545454545454, 0.65, 1.0, 1.0, 0.4470171510406794, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2340683613664869, 0.23406836136648704, 0.3699794016220227], 
reward next is 0.6300, 
noisyNet noise sample is [array([1.168621], dtype=float32), 1.6064193]. 
=============================================
[2019-03-23 00:34:56,647] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[66.1303 ]
 [66.10721]
 [66.07916]
 [66.07415]
 [66.0447 ]], R is [[66.11411285]
 [66.08322906]
 [66.05281067]
 [66.02275848]
 [65.99313354]].
[2019-03-23 00:34:57,270] A3C_AGENT_WORKER-Thread-20 INFO:Local step 76500, global step 1226311: loss 0.0631
[2019-03-23 00:34:57,273] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 76500, global step 1226313: learning rate 0.0010
[2019-03-23 00:34:57,298] A3C_AGENT_WORKER-Thread-11 INFO:Local step 76500, global step 1226319: loss 0.0277
[2019-03-23 00:34:57,302] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 76500, global step 1226321: learning rate 0.0010
[2019-03-23 00:34:57,456] A3C_AGENT_WORKER-Thread-18 INFO:Local step 76500, global step 1226395: loss 0.1178
[2019-03-23 00:34:57,461] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 76500, global step 1226396: learning rate 0.0010
[2019-03-23 00:34:57,516] A3C_AGENT_WORKER-Thread-19 INFO:Local step 76500, global step 1226422: loss 0.0243
[2019-03-23 00:34:57,518] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 76500, global step 1226423: learning rate 0.0010
[2019-03-23 00:34:57,688] A3C_AGENT_WORKER-Thread-12 INFO:Local step 76500, global step 1226505: loss 0.0251
[2019-03-23 00:34:57,690] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 76500, global step 1226505: learning rate 0.0010
[2019-03-23 00:34:58,222] A3C_AGENT_WORKER-Thread-22 INFO:Local step 76500, global step 1226760: loss 0.0901
[2019-03-23 00:34:58,223] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 76500, global step 1226760: learning rate 0.0010
[2019-03-23 00:34:58,406] A3C_AGENT_WORKER-Thread-17 INFO:Local step 76500, global step 1226846: loss 0.1939
[2019-03-23 00:34:58,408] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 76500, global step 1226846: learning rate 0.0010
[2019-03-23 00:34:58,456] A3C_AGENT_WORKER-Thread-21 INFO:Local step 77500, global step 1226867: loss 0.0300
[2019-03-23 00:34:58,456] A3C_AGENT_WORKER-Thread-16 INFO:Local step 76500, global step 1226867: loss 0.1140
[2019-03-23 00:34:58,458] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 77500, global step 1226869: learning rate 0.0010
[2019-03-23 00:34:58,463] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 76500, global step 1226869: learning rate 0.0010
[2019-03-23 00:34:58,666] A3C_AGENT_WORKER-Thread-13 INFO:Local step 76500, global step 1226966: loss 0.1320
[2019-03-23 00:34:58,669] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 76500, global step 1226967: learning rate 0.0010
[2019-03-23 00:34:58,726] A3C_AGENT_WORKER-Thread-10 INFO:Local step 76500, global step 1226995: loss 0.0323
[2019-03-23 00:34:58,729] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 76500, global step 1226997: learning rate 0.0010
[2019-03-23 00:35:02,102] A3C_AGENT_WORKER-Thread-9 INFO:Local step 77000, global step 1228608: loss 18.6823
[2019-03-23 00:35:02,105] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 77000, global step 1228609: learning rate 0.0010
[2019-03-23 00:35:02,968] A3C_AGENT_WORKER-Thread-14 INFO:Local step 77000, global step 1229013: loss 14.3260
[2019-03-23 00:35:02,970] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 77000, global step 1229014: learning rate 0.0010
[2019-03-23 00:35:04,019] A3C_AGENT_WORKER-Thread-3 INFO:Local step 77500, global step 1229510: loss 0.0221
[2019-03-23 00:35:04,021] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 77500, global step 1229511: learning rate 0.0010
[2019-03-23 00:35:10,318] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 2.0728639e-38], sum to 1.0000
[2019-03-23 00:35:10,323] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9527
[2019-03-23 00:35:10,328] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.33333333333334, 79.66666666666667, 1.0, 2.0, 0.5648490620174811, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 639867.6081783714, 639867.6081783717, 152753.8134690016], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6380400.0000, 
sim time next is 6381000.0000, 
raw observation next is [25.25, 80.0, 1.0, 2.0, 0.5634859468535822, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 638479.5795716877, 638479.5795716877, 152518.5975798556], 
processed observation next is [0.0, 0.8695652173913043, 0.7840909090909091, 0.8, 1.0, 1.0, 0.4543574335669777, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23647391835988435, 0.23647391835988435, 0.3719965794630624], 
reward next is 0.6280, 
noisyNet noise sample is [array([0.02931548], dtype=float32), -0.97173285]. 
=============================================
[2019-03-23 00:35:10,358] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[63.97586 ]
 [63.978714]
 [64.000916]
 [63.991768]
 [63.999   ]], R is [[63.95446014]
 [63.94234467]
 [63.92972183]
 [63.91657257]
 [63.9030304 ]].
[2019-03-23 00:35:12,284] A3C_AGENT_WORKER-Thread-2 INFO:Local step 77000, global step 1233409: loss 9.6461
[2019-03-23 00:35:12,287] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 77000, global step 1233409: learning rate 0.0010
[2019-03-23 00:35:13,495] A3C_AGENT_WORKER-Thread-15 INFO:Local step 77000, global step 1233978: loss 10.6494
[2019-03-23 00:35:13,496] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 77000, global step 1233978: learning rate 0.0010
[2019-03-23 00:35:14,332] A3C_AGENT_WORKER-Thread-20 INFO:Local step 77000, global step 1234371: loss 9.0970
[2019-03-23 00:35:14,334] A3C_AGENT_WORKER-Thread-18 INFO:Local step 77000, global step 1234371: loss 9.8587
[2019-03-23 00:35:14,336] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 77000, global step 1234371: learning rate 0.0010
[2019-03-23 00:35:14,337] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 77000, global step 1234372: learning rate 0.0010
[2019-03-23 00:35:14,383] A3C_AGENT_WORKER-Thread-11 INFO:Local step 77000, global step 1234394: loss 5.9242
[2019-03-23 00:35:14,388] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 77000, global step 1234395: learning rate 0.0010
[2019-03-23 00:35:14,435] A3C_AGENT_WORKER-Thread-19 INFO:Local step 77000, global step 1234418: loss 8.4675
[2019-03-23 00:35:14,436] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 77000, global step 1234418: learning rate 0.0010
[2019-03-23 00:35:14,544] A3C_AGENT_WORKER-Thread-12 INFO:Local step 77000, global step 1234479: loss 4.6675
[2019-03-23 00:35:14,547] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 77000, global step 1234480: learning rate 0.0010
[2019-03-23 00:35:14,762] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:35:14,770] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2920
[2019-03-23 00:35:14,778] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.45, 67.5, 1.0, 2.0, 0.2508622631756932, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 272384.4201767818, 272384.4201767821, 82291.7446723212], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6463800.0000, 
sim time next is 6464400.0000, 
raw observation next is [17.16666666666667, 68.33333333333333, 1.0, 2.0, 0.2446193142455069, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 265604.0207396875, 265604.0207396873, 80857.05326183427], 
processed observation next is [1.0, 0.8260869565217391, 0.4166666666666669, 0.6833333333333332, 1.0, 1.0, 0.05577414280688361, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09837185953321759, 0.09837185953321752, 0.19721232502886407], 
reward next is 0.8028, 
noisyNet noise sample is [array([1.5412271], dtype=float32), 1.4169362]. 
=============================================
[2019-03-23 00:35:15,120] A3C_AGENT_WORKER-Thread-22 INFO:Local step 77000, global step 1234746: loss 7.5767
[2019-03-23 00:35:15,121] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 77000, global step 1234746: learning rate 0.0010
[2019-03-23 00:35:15,202] A3C_AGENT_WORKER-Thread-17 INFO:Local step 77000, global step 1234782: loss 9.2437
[2019-03-23 00:35:15,206] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 77000, global step 1234782: learning rate 0.0010
[2019-03-23 00:35:15,351] A3C_AGENT_WORKER-Thread-16 INFO:Local step 77000, global step 1234855: loss 9.6549
[2019-03-23 00:35:15,355] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 77000, global step 1234857: learning rate 0.0010
[2019-03-23 00:35:15,492] A3C_AGENT_WORKER-Thread-21 INFO:Local step 78000, global step 1234927: loss -113.1296
[2019-03-23 00:35:15,494] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 78000, global step 1234927: learning rate 0.0010
[2019-03-23 00:35:15,523] A3C_AGENT_WORKER-Thread-13 INFO:Local step 77000, global step 1234938: loss 7.2759
[2019-03-23 00:35:15,525] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 77000, global step 1234938: learning rate 0.0010
[2019-03-23 00:35:15,611] A3C_AGENT_WORKER-Thread-10 INFO:Local step 77000, global step 1234983: loss 7.7295
[2019-03-23 00:35:15,614] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 77000, global step 1234985: learning rate 0.0010
[2019-03-23 00:35:18,112] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:35:18,113] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0155
[2019-03-23 00:35:18,117] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.36666666666667, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 196067.6815272181, 196067.6815272178, 66357.61353547499], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6500400.0000, 
sim time next is 6501000.0000, 
raw observation next is [12.28333333333333, 88.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 195017.1006400833, 195017.1006400833, 66138.10373938698], 
processed observation next is [1.0, 0.21739130434782608, 0.19469696969696954, 0.885, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.07222855579262345, 0.07222855579262345, 0.1613124481448463], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.32753932], dtype=float32), 0.17437899]. 
=============================================
[2019-03-23 00:35:18,147] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[64.52851]
 [64.5113 ]
 [64.47844]
 [64.44052]
 [64.41348]], R is [[63.90598297]
 [63.266922  ]
 [62.63425446]
 [62.00791168]
 [61.38783264]].
[2019-03-23 00:35:18,521] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:35:18,524] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9059
[2019-03-23 00:35:18,530] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.31666666666667, 49.5, 1.0, 2.0, 0.4920453291824238, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 534403.1503990886, 534403.150399089, 108476.9895435054], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6527400.0000, 
sim time next is 6528000.0000, 
raw observation next is [20.13333333333333, 50.0, 1.0, 2.0, 0.4818270908354702, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 523299.299347006, 523299.2993470057, 107301.1403076944], 
processed observation next is [1.0, 0.5652173913043478, 0.5515151515151513, 0.5, 1.0, 1.0, 0.3522838635443377, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19381455531370592, 0.1938145553137058, 0.26171009831144976], 
reward next is 0.7383, 
noisyNet noise sample is [array([-0.28787854], dtype=float32), 0.3939804]. 
=============================================
[2019-03-23 00:35:18,563] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[71.59434]
 [72.09068]
 [72.42808]
 [72.42432]
 [72.3589 ]], R is [[71.58643341]
 [71.60598755]
 [71.64241028]
 [71.69282532]
 [71.7461319 ]].
[2019-03-23 00:35:19,136] A3C_AGENT_WORKER-Thread-9 INFO:Local step 77500, global step 1236654: loss 0.0241
[2019-03-23 00:35:19,139] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 77500, global step 1236655: learning rate 0.0010
[2019-03-23 00:35:19,822] A3C_AGENT_WORKER-Thread-14 INFO:Local step 77500, global step 1236985: loss 0.0587
[2019-03-23 00:35:19,825] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 77500, global step 1236985: learning rate 0.0010
[2019-03-23 00:35:20,983] A3C_AGENT_WORKER-Thread-3 INFO:Local step 78000, global step 1237534: loss -32.3101
[2019-03-23 00:35:20,985] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 78000, global step 1237534: learning rate 0.0010
[2019-03-23 00:35:23,433] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 4.8652903e-38 9.3128810e-32 1.5443299e-36], sum to 1.0000
[2019-03-23 00:35:23,438] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4825
[2019-03-23 00:35:23,444] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.63333333333334, 58.66666666666667, 1.0, 2.0, 0.7460901777030438, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 839474.5116986614, 839474.5116986614, 163215.1405664546], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6614400.0000, 
sim time next is 6615000.0000, 
raw observation next is [23.55, 59.0, 1.0, 2.0, 0.8068520962853696, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 908131.7740013017, 908131.7740013017, 171759.5170940874], 
processed observation next is [1.0, 0.5652173913043478, 0.7068181818181819, 0.59, 1.0, 1.0, 0.758565120356712, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3363451014819636, 0.3363451014819636, 0.4189256514489937], 
reward next is 0.5811, 
noisyNet noise sample is [array([0.22510843], dtype=float32), -0.6877914]. 
=============================================
[2019-03-23 00:35:23,463] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[62.854084]
 [63.28621 ]
 [63.41345 ]
 [63.594604]
 [63.474636]], R is [[62.70996475]
 [62.68478012]
 [62.70070267]
 [62.73369217]
 [62.78447342]].
[2019-03-23 00:35:23,874] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.2662948e-38 1.4679447e-34 2.1919137e-37], sum to 1.0000
[2019-03-23 00:35:23,884] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6449
[2019-03-23 00:35:23,891] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.43333333333333, 58.33333333333333, 1.0, 2.0, 0.4935862470575583, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 552934.613273065, 552934.6132730646, 132306.8447620911], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6612000.0000, 
sim time next is 6612600.0000, 
raw observation next is [23.61666666666667, 58.16666666666666, 1.0, 2.0, 0.4866265483230388, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 545933.020474746, 545933.020474746, 131972.1254014885], 
processed observation next is [1.0, 0.5217391304347826, 0.7098484848484851, 0.5816666666666666, 1.0, 1.0, 0.3582831854037985, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20219741499064667, 0.20219741499064667, 0.32188323268655733], 
reward next is 0.6781, 
noisyNet noise sample is [array([0.48250246], dtype=float32), 0.79787433]. 
=============================================
[2019-03-23 00:35:24,010] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.4382354e-38 0.0000000e+00], sum to 1.0000
[2019-03-23 00:35:24,017] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3213
[2019-03-23 00:35:24,020] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.68333333333333, 62.33333333333333, 1.0, 2.0, 0.4664964862048044, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 506640.4699528163, 506640.4699528163, 115663.1891734445], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6603000.0000, 
sim time next is 6603600.0000, 
raw observation next is [19.96666666666667, 61.66666666666667, 1.0, 2.0, 0.4940909913579444, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 536626.1401851707, 536626.1401851707, 120845.4174934113], 
processed observation next is [1.0, 0.43478260869565216, 0.5439393939393941, 0.6166666666666667, 1.0, 1.0, 0.36761373919743046, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19875042229080395, 0.19875042229080395, 0.2947449207156373], 
reward next is 0.7053, 
noisyNet noise sample is [array([-0.00492152], dtype=float32), -1.1618781]. 
=============================================
[2019-03-23 00:35:29,179] A3C_AGENT_WORKER-Thread-2 INFO:Local step 77500, global step 1241401: loss 0.0207
[2019-03-23 00:35:29,182] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 77500, global step 1241401: learning rate 0.0010
[2019-03-23 00:35:30,398] A3C_AGENT_WORKER-Thread-15 INFO:Local step 77500, global step 1242005: loss 0.0055
[2019-03-23 00:35:30,399] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 77500, global step 1242005: learning rate 0.0010
[2019-03-23 00:35:31,039] A3C_AGENT_WORKER-Thread-20 INFO:Local step 77500, global step 1242286: loss 0.0168
[2019-03-23 00:35:31,040] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 77500, global step 1242286: learning rate 0.0010
[2019-03-23 00:35:31,147] A3C_AGENT_WORKER-Thread-18 INFO:Local step 77500, global step 1242335: loss 0.0214
[2019-03-23 00:35:31,149] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 77500, global step 1242335: learning rate 0.0010
[2019-03-23 00:35:31,183] A3C_AGENT_WORKER-Thread-11 INFO:Local step 77500, global step 1242353: loss 0.0056
[2019-03-23 00:35:31,184] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 77500, global step 1242353: learning rate 0.0010
[2019-03-23 00:35:31,359] A3C_AGENT_WORKER-Thread-12 INFO:Local step 77500, global step 1242438: loss 0.0051
[2019-03-23 00:35:31,361] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 77500, global step 1242438: learning rate 0.0010
[2019-03-23 00:35:31,416] A3C_AGENT_WORKER-Thread-19 INFO:Local step 77500, global step 1242466: loss 0.0060
[2019-03-23 00:35:31,419] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 77500, global step 1242466: learning rate 0.0010
[2019-03-23 00:35:32,000] A3C_AGENT_WORKER-Thread-17 INFO:Local step 77500, global step 1242751: loss 0.0192
[2019-03-23 00:35:32,003] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 77500, global step 1242751: learning rate 0.0010
[2019-03-23 00:35:32,020] A3C_AGENT_WORKER-Thread-22 INFO:Local step 77500, global step 1242758: loss 0.0113
[2019-03-23 00:35:32,022] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 77500, global step 1242758: learning rate 0.0010
[2019-03-23 00:35:32,207] A3C_AGENT_WORKER-Thread-16 INFO:Local step 77500, global step 1242850: loss 0.0085
[2019-03-23 00:35:32,211] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 77500, global step 1242851: learning rate 0.0010
[2019-03-23 00:35:32,246] A3C_AGENT_WORKER-Thread-13 INFO:Local step 77500, global step 1242871: loss 0.0056
[2019-03-23 00:35:32,249] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 77500, global step 1242871: learning rate 0.0010
[2019-03-23 00:35:32,366] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:35:32,376] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2214
[2019-03-23 00:35:32,381] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.9, 85.0, 1.0, 2.0, 0.2577390920835942, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 279853.379227705, 279853.3792277047, 86506.02304641611], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7260000.0000, 
sim time next is 7260600.0000, 
raw observation next is [15.45, 87.5, 1.0, 2.0, 0.2526924119798361, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 274372.142952981, 274372.142952981, 84778.48586601549], 
processed observation next is [1.0, 0.0, 0.3386363636363636, 0.875, 1.0, 1.0, 0.06586551497479512, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10161931220480777, 0.10161931220480777, 0.20677679479515973], 
reward next is 0.7932, 
noisyNet noise sample is [array([-0.91141725], dtype=float32), 1.5259119]. 
=============================================
[2019-03-23 00:35:32,476] A3C_AGENT_WORKER-Thread-21 INFO:Local step 78500, global step 1242974: loss 0.0231
[2019-03-23 00:35:32,480] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 78500, global step 1242978: learning rate 0.0010
[2019-03-23 00:35:32,587] A3C_AGENT_WORKER-Thread-10 INFO:Local step 77500, global step 1243030: loss 0.0041
[2019-03-23 00:35:32,589] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 77500, global step 1243031: learning rate 0.0010
[2019-03-23 00:35:35,953] A3C_AGENT_WORKER-Thread-9 INFO:Local step 78000, global step 1244673: loss -6.1354
[2019-03-23 00:35:35,956] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 78000, global step 1244673: learning rate 0.0010
[2019-03-23 00:35:36,467] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:35:36,473] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5597
[2019-03-23 00:35:36,476] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.53333333333333, 50.66666666666667, 1.0, 2.0, 0.4390606965433383, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 500302.7274022779, 500302.7274022776, 132473.6095330245], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6888000.0000, 
sim time next is 6888600.0000, 
raw observation next is [27.45, 51.5, 1.0, 2.0, 0.4414883443326786, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 503197.8019844111, 503197.8019844108, 132901.1039938683], 
processed observation next is [0.0, 0.7391304347826086, 0.884090909090909, 0.515, 1.0, 1.0, 0.3018604304158482, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18636955629052263, 0.18636955629052251, 0.3241490341313861], 
reward next is 0.6759, 
noisyNet noise sample is [array([-0.8794361], dtype=float32), -0.5873261]. 
=============================================
[2019-03-23 00:35:36,671] A3C_AGENT_WORKER-Thread-14 INFO:Local step 78000, global step 1245020: loss 31.0715
[2019-03-23 00:35:36,673] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 78000, global step 1245020: learning rate 0.0010
[2019-03-23 00:35:37,559] A3C_AGENT_WORKER-Thread-3 INFO:Local step 78500, global step 1245452: loss 0.3739
[2019-03-23 00:35:37,565] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 78500, global step 1245452: learning rate 0.0010
[2019-03-23 00:35:38,570] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:35:38,578] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0087
[2019-03-23 00:35:38,585] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 97.0, 1.0, 2.0, 0.3531672523704874, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 393180.9882105388, 393180.9882105388, 118479.5319194915], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7089600.0000, 
sim time next is 7090200.0000, 
raw observation next is [17.7, 97.0, 1.0, 2.0, 0.3529386959973586, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 392929.1302116007, 392929.1302116007, 118462.4390451685], 
processed observation next is [1.0, 0.043478260869565216, 0.44090909090909086, 0.97, 1.0, 1.0, 0.19117336999669823, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14552930748577803, 0.14552930748577803, 0.2889327781589476], 
reward next is 0.7111, 
noisyNet noise sample is [array([-0.68423694], dtype=float32), 0.95818454]. 
=============================================
[2019-03-23 00:35:40,494] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:35:40,504] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5559
[2019-03-23 00:35:40,512] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.5, 56.0, 1.0, 2.0, 0.4224150730026896, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 479670.406073212, 479670.4060732117, 129172.3354683749], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7498800.0000, 
sim time next is 7499400.0000, 
raw observation next is [25.41666666666666, 57.0, 1.0, 2.0, 0.4199726392696792, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 476902.0534982459, 476902.0534982459, 128940.4194842941], 
processed observation next is [0.0, 0.8260869565217391, 0.7916666666666664, 0.57, 1.0, 1.0, 0.27496579908709895, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17663039018453552, 0.17663039018453552, 0.31448882801047345], 
reward next is 0.6855, 
noisyNet noise sample is [array([-0.88554955], dtype=float32), 0.5551764]. 
=============================================
[2019-03-23 00:35:41,729] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:35:41,738] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7137
[2019-03-23 00:35:41,742] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.38333333333333, 63.0, 1.0, 2.0, 0.2558842947702094, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 277838.8630821632, 277838.8630821629, 84318.55438317468], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7159800.0000, 
sim time next is 7160400.0000, 
raw observation next is [18.3, 63.0, 1.0, 2.0, 0.2547388989450258, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 276594.8400094663, 276594.840009466, 83755.6886854631], 
processed observation next is [1.0, 0.9130434782608695, 0.4681818181818182, 0.63, 1.0, 1.0, 0.06842362368128227, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10244253333683936, 0.10244253333683925, 0.20428216752551975], 
reward next is 0.7957, 
noisyNet noise sample is [array([-0.8625414], dtype=float32), -0.30974934]. 
=============================================
[2019-03-23 00:35:45,590] A3C_AGENT_WORKER-Thread-2 INFO:Local step 78000, global step 1249379: loss -47.6061
[2019-03-23 00:35:45,594] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 78000, global step 1249380: learning rate 0.0010
[2019-03-23 00:35:46,847] A3C_AGENT_WORKER-Thread-15 INFO:Local step 78000, global step 1249977: loss -73.7673
[2019-03-23 00:35:46,848] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 78000, global step 1249977: learning rate 0.0010
[2019-03-23 00:35:46,897] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-23 00:35:46,898] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 00:35:46,900] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:35:46,900] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 00:35:46,901] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 00:35:46,902] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:35:46,903] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:35:46,903] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 00:35:46,905] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 00:35:46,907] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:35:46,907] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:35:46,931] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run51
[2019-03-23 00:35:46,953] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run51
[2019-03-23 00:35:46,953] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run51
[2019-03-23 00:35:47,000] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run51
[2019-03-23 00:35:47,020] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run51
[2019-03-23 00:36:28,137] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.09967104], dtype=float32), 0.071537316]
[2019-03-23 00:36:28,138] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.66666666666667, 74.66666666666667, 1.0, 2.0, 0.4388145640254517, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 498918.9856887037, 498918.9856887039, 131292.9581720381]
[2019-03-23 00:36:28,141] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 00:36:28,145] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.2663248124958213
[2019-03-23 00:36:46,838] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.09967104], dtype=float32), 0.071537316]
[2019-03-23 00:36:46,840] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [26.0, 79.0, 1.0, 2.0, 0.6038310850746758, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 680711.9261662188, 680711.9261662184, 163245.0608585825]
[2019-03-23 00:36:46,841] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 00:36:46,843] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 1.3867537e-37 8.8365298e-37 0.0000000e+00], sampled 0.8009293362341383
[2019-03-23 00:36:52,214] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.09967104], dtype=float32), 0.071537316]
[2019-03-23 00:36:52,216] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.86666666666667, 69.16666666666667, 1.0, 2.0, 0.3039970932944301, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 330890.8426545996, 330890.8426545993, 116053.3236541134]
[2019-03-23 00:36:52,217] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 00:36:52,220] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.760696848175859
[2019-03-23 00:36:54,417] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.09967104], dtype=float32), 0.071537316]
[2019-03-23 00:36:54,418] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.68333333333333, 90.0, 1.0, 2.0, 0.4616058553875764, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 524978.7242973301, 524978.7242973298, 138095.050696883]
[2019-03-23 00:36:54,421] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 00:36:54,423] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.00000000e+00 1.00000000e+00 0.00000000e+00 1.15772296e-35
 0.00000000e+00], sampled 0.0706281845749922
[2019-03-23 00:37:08,925] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.09967104], dtype=float32), 0.071537316]
[2019-03-23 00:37:08,926] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [15.955246605, 85.18335378500001, 1.0, 2.0, 0.48959611611544, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 531686.1815156221, 531686.1815156221, 115812.7199858363]
[2019-03-23 00:37:08,926] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 00:37:08,929] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 8.314236e-38 0.000000e+00], sampled 0.13114449219559132
[2019-03-23 00:37:33,378] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3486 1683344882.4587 214.0000
[2019-03-23 00:37:33,520] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1148 1656229146.4555 80.0000
[2019-03-23 00:37:33,643] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9309 1705967916.6745 465.0000
[2019-03-23 00:37:33,701] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5599 1663815647.6096 105.0000
[2019-03-23 00:37:33,794] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2492 1773187030.7201 173.0000
[2019-03-23 00:37:34,810] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1250000, evaluation results [1250000.0, 8512.249193409023, 1773187030.7201214, 173.0, 9061.114827412715, 1656229146.4555063, 80.0, 8856.559925897878, 1663815647.6095803, 105.0, 8596.930884973775, 1705967916.6744611, 465.0, 8574.348638023737, 1683344882.4586744, 214.0]
[2019-03-23 00:37:35,267] A3C_AGENT_WORKER-Thread-20 INFO:Local step 78000, global step 1250273: loss 15.0588
[2019-03-23 00:37:35,269] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 78000, global step 1250273: learning rate 0.0010
[2019-03-23 00:37:35,361] A3C_AGENT_WORKER-Thread-18 INFO:Local step 78000, global step 1250326: loss -36.4648
[2019-03-23 00:37:35,363] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 78000, global step 1250326: learning rate 0.0010
[2019-03-23 00:37:35,404] A3C_AGENT_WORKER-Thread-11 INFO:Local step 78000, global step 1250355: loss 4.1665
[2019-03-23 00:37:35,406] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 78000, global step 1250356: learning rate 0.0010
[2019-03-23 00:37:35,623] A3C_AGENT_WORKER-Thread-12 INFO:Local step 78000, global step 1250481: loss 20.3533
[2019-03-23 00:37:35,624] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 78000, global step 1250481: learning rate 0.0010
[2019-03-23 00:37:35,668] A3C_AGENT_WORKER-Thread-19 INFO:Local step 78000, global step 1250512: loss -70.8244
[2019-03-23 00:37:35,671] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 78000, global step 1250513: learning rate 0.0010
[2019-03-23 00:37:35,998] A3C_AGENT_WORKER-Thread-17 INFO:Local step 78000, global step 1250703: loss 3.4895
[2019-03-23 00:37:36,002] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 78000, global step 1250707: learning rate 0.0010
[2019-03-23 00:37:36,135] A3C_AGENT_WORKER-Thread-22 INFO:Local step 78000, global step 1250788: loss 62.2243
[2019-03-23 00:37:36,141] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 78000, global step 1250789: learning rate 0.0010
[2019-03-23 00:37:36,151] A3C_AGENT_WORKER-Thread-13 INFO:Local step 78000, global step 1250796: loss 122.9509
[2019-03-23 00:37:36,155] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 78000, global step 1250796: learning rate 0.0010
[2019-03-23 00:37:36,230] A3C_AGENT_WORKER-Thread-16 INFO:Local step 78000, global step 1250845: loss 28.0872
[2019-03-23 00:37:36,233] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 78000, global step 1250846: learning rate 0.0010
[2019-03-23 00:37:36,496] A3C_AGENT_WORKER-Thread-10 INFO:Local step 78000, global step 1251004: loss -31.2659
[2019-03-23 00:37:36,498] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 78000, global step 1251006: learning rate 0.0010
[2019-03-23 00:37:36,796] A3C_AGENT_WORKER-Thread-21 INFO:Local step 79000, global step 1251182: loss 220.9790
[2019-03-23 00:37:36,800] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 79000, global step 1251185: learning rate 0.0010
[2019-03-23 00:37:37,194] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 9.3982287e-36 9.6886035e-30 0.0000000e+00], sum to 1.0000
[2019-03-23 00:37:37,204] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6408
[2019-03-23 00:37:37,208] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.38333333333333, 54.16666666666667, 1.0, 2.0, 0.5300495975566677, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 588506.6028793635, 588506.6028793635, 133896.876083063], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7132200.0000, 
sim time next is 7132800.0000, 
raw observation next is [23.46666666666667, 53.33333333333334, 1.0, 2.0, 0.6761893375467791, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 751056.3184612992, 751056.3184612992, 150014.5761779485], 
processed observation next is [1.0, 0.5652173913043478, 0.7030303030303031, 0.5333333333333334, 1.0, 1.0, 0.5952366719334738, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2781690068375182, 0.2781690068375182, 0.3658892101901183], 
reward next is 0.6341, 
noisyNet noise sample is [array([-0.16289577], dtype=float32), -1.0818788]. 
=============================================
[2019-03-23 00:37:39,354] A3C_AGENT_WORKER-Thread-9 INFO:Local step 78500, global step 1252723: loss 0.0345
[2019-03-23 00:37:39,356] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 78500, global step 1252724: learning rate 0.0010
[2019-03-23 00:37:39,368] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 7.3535305e-33 1.3108702e-22 1.3897540e-33], sum to 1.0000
[2019-03-23 00:37:39,375] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4718
[2019-03-23 00:37:39,379] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 84.0, 1.0, 2.0, 0.6034091341217739, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 679130.6170095204, 679130.6170095206, 145463.2075697392], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7120800.0000, 
sim time next is 7121400.0000, 
raw observation next is [20.36666666666667, 81.33333333333333, 1.0, 2.0, 0.6499501514843573, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 732079.0936361727, 732079.0936361727, 151280.52825281], 
processed observation next is [1.0, 0.43478260869565216, 0.5621212121212124, 0.8133333333333332, 1.0, 1.0, 0.5624376893554466, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.27114040505043435, 0.27114040505043435, 0.3689768981775854], 
reward next is 0.6310, 
noisyNet noise sample is [array([-1.3333981], dtype=float32), -1.8494188]. 
=============================================
[2019-03-23 00:37:39,935] A3C_AGENT_WORKER-Thread-14 INFO:Local step 78500, global step 1253068: loss 0.0380
[2019-03-23 00:37:39,938] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 78500, global step 1253070: learning rate 0.0010
[2019-03-23 00:37:40,759] A3C_AGENT_WORKER-Thread-3 INFO:Local step 79000, global step 1253559: loss 111.7079
[2019-03-23 00:37:40,761] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 79000, global step 1253560: learning rate 0.0010
[2019-03-23 00:37:48,362] A3C_AGENT_WORKER-Thread-2 INFO:Local step 78500, global step 1257365: loss 0.0667
[2019-03-23 00:37:48,365] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 78500, global step 1257366: learning rate 0.0010
[2019-03-23 00:37:49,618] A3C_AGENT_WORKER-Thread-15 INFO:Local step 78500, global step 1257967: loss 0.1440
[2019-03-23 00:37:49,621] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 78500, global step 1257967: learning rate 0.0010
[2019-03-23 00:37:50,128] A3C_AGENT_WORKER-Thread-20 INFO:Local step 78500, global step 1258207: loss 0.0039
[2019-03-23 00:37:50,132] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 78500, global step 1258207: learning rate 0.0010
[2019-03-23 00:37:50,335] A3C_AGENT_WORKER-Thread-18 INFO:Local step 78500, global step 1258299: loss 0.0851
[2019-03-23 00:37:50,337] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 78500, global step 1258300: learning rate 0.0010
[2019-03-23 00:37:50,362] A3C_AGENT_WORKER-Thread-11 INFO:Local step 78500, global step 1258311: loss 0.0243
[2019-03-23 00:37:50,363] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 78500, global step 1258312: learning rate 0.0010
[2019-03-23 00:37:50,680] A3C_AGENT_WORKER-Thread-12 INFO:Local step 78500, global step 1258467: loss 0.0494
[2019-03-23 00:37:50,681] A3C_AGENT_WORKER-Thread-19 INFO:Local step 78500, global step 1258467: loss 0.0059
[2019-03-23 00:37:50,686] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 78500, global step 1258468: learning rate 0.0010
[2019-03-23 00:37:50,687] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 78500, global step 1258468: learning rate 0.0010
[2019-03-23 00:37:51,151] A3C_AGENT_WORKER-Thread-13 INFO:Local step 78500, global step 1258687: loss 0.0058
[2019-03-23 00:37:51,153] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 78500, global step 1258688: learning rate 0.0010
[2019-03-23 00:37:51,175] A3C_AGENT_WORKER-Thread-17 INFO:Local step 78500, global step 1258700: loss 0.0090
[2019-03-23 00:37:51,178] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 78500, global step 1258701: learning rate 0.0010
[2019-03-23 00:37:51,342] A3C_AGENT_WORKER-Thread-22 INFO:Local step 78500, global step 1258777: loss 0.0148
[2019-03-23 00:37:51,348] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 78500, global step 1258777: learning rate 0.0010
[2019-03-23 00:37:51,418] A3C_AGENT_WORKER-Thread-16 INFO:Local step 78500, global step 1258807: loss 0.0753
[2019-03-23 00:37:51,419] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 78500, global step 1258807: learning rate 0.0010
[2019-03-23 00:37:51,730] A3C_AGENT_WORKER-Thread-10 INFO:Local step 78500, global step 1258958: loss 0.1428
[2019-03-23 00:37:51,734] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 78500, global step 1258960: learning rate 0.0010
[2019-03-23 00:37:52,892] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:37:52,893] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:37:52,962] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run7
[2019-03-23 00:37:55,172] A3C_AGENT_WORKER-Thread-9 INFO:Local step 79000, global step 1260717: loss -36.4837
[2019-03-23 00:37:55,175] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 79000, global step 1260717: learning rate 0.0010
[2019-03-23 00:37:55,824] A3C_AGENT_WORKER-Thread-14 INFO:Local step 79000, global step 1261022: loss -133.9975
[2019-03-23 00:37:55,826] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 79000, global step 1261022: learning rate 0.0010
[2019-03-23 00:37:57,427] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:37:57,428] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:37:57,490] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run7
[2019-03-23 00:38:01,947] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:38:01,956] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8174
[2019-03-23 00:38:01,965] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 43.0, 1.0, 2.0, 0.3005551214770076, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 326358.6682822201, 326358.6682822198, 90397.81942994034], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 151200.0000, 
sim time next is 151800.0000, 
raw observation next is [21.66666666666667, 43.5, 1.0, 2.0, 0.2990887997919872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 324765.9268788145, 324765.9268788142, 89043.69175854737], 
processed observation next is [1.0, 0.782608695652174, 0.6212121212121214, 0.435, 1.0, 1.0, 0.123860999739984, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12028367662178316, 0.12028367662178303, 0.217179735996457], 
reward next is 0.7828, 
noisyNet noise sample is [array([0.5781849], dtype=float32), -0.94546276]. 
=============================================
[2019-03-23 00:38:04,616] A3C_AGENT_WORKER-Thread-2 INFO:Local step 79000, global step 1265328: loss -75.3403
[2019-03-23 00:38:04,620] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 79000, global step 1265330: learning rate 0.0010
[2019-03-23 00:38:05,771] A3C_AGENT_WORKER-Thread-15 INFO:Local step 79000, global step 1265867: loss 59.0873
[2019-03-23 00:38:05,773] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 79000, global step 1265867: learning rate 0.0010
[2019-03-23 00:38:06,205] A3C_AGENT_WORKER-Thread-20 INFO:Local step 79000, global step 1266071: loss 30.8222
[2019-03-23 00:38:06,207] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 79000, global step 1266071: learning rate 0.0010
[2019-03-23 00:38:06,438] A3C_AGENT_WORKER-Thread-11 INFO:Local step 79000, global step 1266181: loss -123.5193
[2019-03-23 00:38:06,441] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 79000, global step 1266181: learning rate 0.0010
[2019-03-23 00:38:06,469] A3C_AGENT_WORKER-Thread-18 INFO:Local step 79000, global step 1266198: loss -90.6348
[2019-03-23 00:38:06,473] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 79000, global step 1266198: learning rate 0.0010
[2019-03-23 00:38:06,840] A3C_AGENT_WORKER-Thread-12 INFO:Local step 79000, global step 1266371: loss 61.3162
[2019-03-23 00:38:06,842] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 79000, global step 1266371: learning rate 0.0010
[2019-03-23 00:38:06,870] A3C_AGENT_WORKER-Thread-19 INFO:Local step 79000, global step 1266379: loss -109.4787
[2019-03-23 00:38:06,872] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 79000, global step 1266379: learning rate 0.0010
[2019-03-23 00:38:07,204] A3C_AGENT_WORKER-Thread-17 INFO:Local step 79000, global step 1266544: loss 12.8157
[2019-03-23 00:38:07,207] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 79000, global step 1266544: learning rate 0.0010
[2019-03-23 00:38:07,329] A3C_AGENT_WORKER-Thread-16 INFO:Local step 79000, global step 1266603: loss -62.4156
[2019-03-23 00:38:07,334] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 79000, global step 1266605: learning rate 0.0010
[2019-03-23 00:38:07,373] A3C_AGENT_WORKER-Thread-13 INFO:Local step 79000, global step 1266628: loss 75.4652
[2019-03-23 00:38:07,374] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 79000, global step 1266628: learning rate 0.0010
[2019-03-23 00:38:07,538] A3C_AGENT_WORKER-Thread-22 INFO:Local step 79000, global step 1266705: loss -153.6132
[2019-03-23 00:38:07,539] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 79000, global step 1266705: learning rate 0.0010
[2019-03-23 00:38:07,820] A3C_AGENT_WORKER-Thread-10 INFO:Local step 79000, global step 1266810: loss 82.2644
[2019-03-23 00:38:07,821] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 79000, global step 1266810: learning rate 0.0010
[2019-03-23 00:38:12,173] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:38:12,174] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:38:12,238] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run7
[2019-03-23 00:38:12,735] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:38:12,736] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:38:12,784] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run7
[2019-03-23 00:38:18,476] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 9.425834e-37], sum to 1.0000
[2019-03-23 00:38:18,487] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3388
[2019-03-23 00:38:18,494] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.5, 85.0, 1.0, 2.0, 0.2026878342127567, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 220065.1423394215, 220065.1423394212, 71529.42150467083], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 99000.0000, 
sim time next is 99600.0000, 
raw observation next is [13.33333333333333, 86.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 216589.5979799582, 216589.5979799579, 71056.06002399609], 
processed observation next is [1.0, 0.13043478260869565, 0.2424242424242423, 0.86, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08021836962220674, 0.08021836962220663, 0.1733074634731612], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.53077686], dtype=float32), 1.5182321]. 
=============================================
[2019-03-23 00:38:20,576] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:38:20,584] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2719
[2019-03-23 00:38:20,589] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.33333333333333, 70.66666666666667, 1.0, 2.0, 0.221455076066828, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 240446.4177449626, 240446.4177449626, 76439.789555175], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 412800.0000, 
sim time next is 413400.0000, 
raw observation next is [16.16666666666667, 71.33333333333333, 1.0, 2.0, 0.218525003962588, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 237264.2952555351, 237264.2952555351, 75874.8063919215], 
processed observation next is [1.0, 0.782608695652174, 0.37121212121212144, 0.7133333333333333, 1.0, 1.0, 0.023156254953234992, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08787566490945745, 0.08787566490945745, 0.1850605033949305], 
reward next is 0.8149, 
noisyNet noise sample is [array([0.7023099], dtype=float32), -0.36614305]. 
=============================================
[2019-03-23 00:38:21,047] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:38:21,047] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:38:21,098] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run7
[2019-03-23 00:38:22,057] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:38:22,057] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:38:22,113] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run7
[2019-03-23 00:38:22,396] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:38:22,396] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:38:22,449] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run7
[2019-03-23 00:38:22,577] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:38:22,579] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9135
[2019-03-23 00:38:22,585] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.53333333333333, 97.33333333333334, 1.0, 2.0, 0.5414121387533938, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 609717.4238127038, 609717.4238127038, 138700.5742237109], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 30000.0000, 
sim time next is 30600.0000, 
raw observation next is [18.8, 96.0, 1.0, 2.0, 0.625169407215428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 705288.0485440495, 705288.0485440495, 148855.828055557], 
processed observation next is [1.0, 0.34782608695652173, 0.49090909090909096, 0.96, 1.0, 1.0, 0.5314617590192849, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2612177957570554, 0.2612177957570554, 0.3630629952574561], 
reward next is 0.6369, 
noisyNet noise sample is [array([1.0411983], dtype=float32), -0.23291749]. 
=============================================
[2019-03-23 00:38:22,618] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:38:22,618] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:38:22,636] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:38:22,637] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:38:22,673] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run7
[2019-03-23 00:38:22,704] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run7
[2019-03-23 00:38:22,788] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:38:22,788] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:38:22,821] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run7
[2019-03-23 00:38:22,931] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:38:22,932] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:38:22,953] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run7
[2019-03-23 00:38:23,036] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:38:23,037] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:38:23,048] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run7
[2019-03-23 00:38:23,069] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:38:23,069] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:38:23,083] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run7
[2019-03-23 00:38:23,106] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:38:23,107] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:38:23,116] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run7
[2019-03-23 00:38:23,154] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:38:23,155] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:38:23,158] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run7
[2019-03-23 00:38:23,257] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:38:23,257] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:38:23,261] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run7
[2019-03-23 00:38:24,146] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-23 00:38:24,146] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 00:38:24,147] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:38:24,148] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 00:38:24,148] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:38:24,149] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 00:38:24,150] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:38:24,151] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 00:38:24,151] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:38:24,151] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 00:38:24,152] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:38:24,160] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run52
[2019-03-23 00:38:24,188] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run52
[2019-03-23 00:38:24,215] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run52
[2019-03-23 00:38:24,215] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run52
[2019-03-23 00:38:24,260] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run52
[2019-03-23 00:38:33,871] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.29556075], dtype=float32), 0.096671864]
[2019-03-23 00:38:33,872] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.20368296, 64.75849627, 1.0, 2.0, 0.4034317306320993, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 445356.8415055753, 445356.8415055749, 125498.262748803]
[2019-03-23 00:38:33,873] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 00:38:33,876] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.950233038921665
[2019-03-23 00:38:34,573] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.29556075], dtype=float32), 0.096671864]
[2019-03-23 00:38:34,575] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.02979785, 62.47725513, 1.0, 2.0, 0.3039611230207511, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 330036.9796316281, 330036.9796316277, 108519.68639992]
[2019-03-23 00:38:34,576] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 00:38:34,578] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.9787533414366745
[2019-03-23 00:39:04,228] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.29556075], dtype=float32), 0.096671864]
[2019-03-23 00:39:04,229] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.5, 91.5, 1.0, 2.0, 0.5514712014379658, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 628659.4517007879, 628659.4517007879, 148711.536472957]
[2019-03-23 00:39:04,231] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 00:39:04,234] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 7.6207776e-33 0.0000000e+00 2.0781368e-38], sampled 0.6981509346235764
[2019-03-23 00:39:22,738] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.29556075], dtype=float32), 0.096671864]
[2019-03-23 00:39:22,739] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [24.0, 61.0, 1.0, 2.0, 0.3985633227055745, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 450602.4383630506, 450602.4383630506, 125549.9838992747]
[2019-03-23 00:39:22,743] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 00:39:22,745] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.9475271913620249
[2019-03-23 00:39:45,704] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.29556075], dtype=float32), 0.096671864]
[2019-03-23 00:39:45,705] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [25.06525432, 63.31497809, 1.0, 2.0, 0.4485017185669425, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 510926.2834821877, 510926.2834821877, 137642.9524703872]
[2019-03-23 00:39:45,708] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 00:39:45,710] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.12537382531786356
[2019-03-23 00:40:01,328] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.29556075], dtype=float32), 0.096671864]
[2019-03-23 00:40:01,329] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [14.93904315666667, 91.41552865833333, 1.0, 2.0, 0.2805614520167765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 95.55338769695034, 304623.4864461191, 304623.4864461184, 91785.26691781153]
[2019-03-23 00:40:01,330] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 00:40:01,333] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.8009395827624256
[2019-03-23 00:40:11,652] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.29556075], dtype=float32), 0.096671864]
[2019-03-23 00:40:11,654] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.26959785666667, 44.36314692333333, 1.0, 2.0, 0.3516420235559674, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 381824.7194022915, 381824.7194022915, 114293.8760804292]
[2019-03-23 00:40:11,657] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 00:40:11,659] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.5378200694228682
[2019-03-23 00:40:12,368] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9060.3047 1656272944.4788 80.0000
[2019-03-23 00:40:12,424] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3486 1683344882.4587 214.0000
[2019-03-23 00:40:12,621] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9309 1705967916.6745 465.0000
[2019-03-23 00:40:12,736] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8511.4596 1773255043.8485 173.0000
[2019-03-23 00:40:12,786] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5599 1663815647.6096 105.0000
[2019-03-23 00:40:13,803] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 1275000, evaluation results [1275000.0, 8511.459593596486, 1773255043.8485475, 173.0, 9060.304679780347, 1656272944.478839, 80.0, 8856.559925897878, 1663815647.6095803, 105.0, 8596.930884973775, 1705967916.6744611, 465.0, 8574.348638023737, 1683344882.4586744, 214.0]
[2019-03-23 00:40:21,062] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:40:21,075] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7265
[2019-03-23 00:40:21,080] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.16666666666667, 80.33333333333334, 1.0, 2.0, 0.2040957623223118, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 221594.1264428289, 221594.1264428286, 74565.33452523137], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 420600.0000, 
sim time next is 421200.0000, 
raw observation next is [15.0, 82.0, 1.0, 2.0, 0.2042833842525386, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 221797.8807807004, 221797.8807807001, 74639.81815367729], 
processed observation next is [1.0, 0.9130434782608695, 0.3181818181818182, 0.82, 1.0, 1.0, 0.005354230315673253, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08214736325211125, 0.08214736325211115, 0.18204833696018852], 
reward next is 0.8180, 
noisyNet noise sample is [array([-1.5795033], dtype=float32), -1.7507672]. 
=============================================
[2019-03-23 00:40:22,187] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:40:22,196] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8201
[2019-03-23 00:40:22,203] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.33333333333334, 50.0, 1.0, 2.0, 0.2722234263346349, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 295585.2639794846, 295585.2639794843, 81750.37448414614], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 157200.0000, 
sim time next is 157800.0000, 
raw observation next is [19.16666666666667, 51.0, 1.0, 2.0, 0.2693677480918865, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 292483.5829781683, 292483.5829781686, 81447.06140720235], 
processed observation next is [1.0, 0.8260869565217391, 0.5075757575757578, 0.51, 1.0, 1.0, 0.08670968511485813, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10832725295487716, 0.10832725295487726, 0.19865136928585939], 
reward next is 0.8013, 
noisyNet noise sample is [array([0.7512818], dtype=float32), 0.1461655]. 
=============================================
[2019-03-23 00:40:23,914] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:40:23,925] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0615
[2019-03-23 00:40:23,929] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.83333333333333, 89.00000000000001, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 214108.1917454251, 214108.1917454248, 72418.21090997373], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 187800.0000, 
sim time next is 188400.0000, 
raw observation next is [13.66666666666667, 90.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 212259.4433789966, 212259.4433789966, 71937.62038282063], 
processed observation next is [0.0, 0.17391304347826086, 0.25757575757575774, 0.9, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.07861460865888763, 0.07861460865888763, 0.17545761068980642], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.09198475], dtype=float32), -0.671912]. 
=============================================
[2019-03-23 00:40:27,644] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:40:27,654] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9775
[2019-03-23 00:40:27,662] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.0, 94.0, 1.0, 2.0, 0.2404797114982231, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 261108.0950046463, 261108.095004646, 85038.08316579404], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 254400.0000, 
sim time next is 255000.0000, 
raw observation next is [15.0, 94.0, 1.0, 2.0, 0.2403371577703096, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 260953.2714747554, 260953.2714747551, 85016.06762931695], 
processed observation next is [0.0, 0.9565217391304348, 0.3181818181818182, 0.94, 1.0, 1.0, 0.05042144721288697, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09664935980546496, 0.09664935980546485, 0.20735626251052916], 
reward next is 0.7926, 
noisyNet noise sample is [array([0.45218307], dtype=float32), 0.15125994]. 
=============================================
[2019-03-23 00:40:27,679] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[79.33689 ]
 [79.26273 ]
 [79.176636]
 [79.083084]
 [78.99581 ]], R is [[79.38792419]
 [79.38663483]
 [79.38515472]
 [79.38339996]
 [79.38121796]].
[2019-03-23 00:40:29,470] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 5.055783e-38 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 00:40:29,478] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9816
[2019-03-23 00:40:29,488] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 100.0, 1.0, 2.0, 0.2190587880924935, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 237843.994962491, 237843.9949624913, 79943.45810216169], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 283800.0000, 
sim time next is 284400.0000, 
raw observation next is [14.0, 100.0, 1.0, 2.0, 0.2189057539484602, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 237677.7969037815, 237677.7969037818, 79930.363493674], 
processed observation next is [0.0, 0.30434782608695654, 0.2727272727272727, 1.0, 1.0, 1.0, 0.023632192435575246, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08802881366806722, 0.08802881366806733, 0.1949521060821317], 
reward next is 0.8050, 
noisyNet noise sample is [array([-0.29207128], dtype=float32), -0.34558028]. 
=============================================
[2019-03-23 00:40:32,304] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:40:32,313] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1169
[2019-03-23 00:40:32,320] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.16666666666667, 59.0, 1.0, 2.0, 0.2012389383713709, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 218491.6730487008, 218491.6730487006, 70651.42617781575], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 337800.0000, 
sim time next is 338400.0000, 
raw observation next is [16.0, 59.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 216489.7353234682, 216489.7353234679, 70181.11067569164], 
processed observation next is [0.0, 0.9565217391304348, 0.36363636363636365, 0.59, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08018138345313637, 0.08018138345313626, 0.17117344067241863], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.33023074], dtype=float32), -0.009555814]. 
=============================================
[2019-03-23 00:40:34,375] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 5.5806180e-37 6.2776164e-30 3.7270351e-37], sum to 1.0000
[2019-03-23 00:40:34,385] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9749
[2019-03-23 00:40:34,393] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 72.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 211999.4727957428, 211999.4727957431, 69328.1728474252], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 374400.0000, 
sim time next is 375000.0000, 
raw observation next is [14.16666666666667, 72.83333333333333, 1.0, 2.0, 0.3175395078123741, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 344807.7528548797, 344807.7528548797, 80841.84064128608], 
processed observation next is [1.0, 0.34782608695652173, 0.28030303030303044, 0.7283333333333333, 1.0, 1.0, 0.14692438476546762, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12770657513143693, 0.12770657513143693, 0.1971752210763075], 
reward next is 0.8028, 
noisyNet noise sample is [array([-1.0661721], dtype=float32), -0.6060868]. 
=============================================
[2019-03-23 00:40:34,409] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[74.41826 ]
 [74.10992 ]
 [73.810745]
 [73.73331 ]
 [73.26468 ]], R is [[74.03161621]
 [73.29129791]
 [73.37583923]
 [73.44743347]
 [73.51892853]].
[2019-03-23 00:40:35,483] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:40:35,491] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5670
[2019-03-23 00:40:35,497] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 99.16666666666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 209156.2872562572, 209156.2872562575, 72014.19564137195], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 435000.0000, 
sim time next is 435600.0000, 
raw observation next is [13.0, 99.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 207130.9254912133, 207130.925491213, 71616.61434200588], 
processed observation next is [1.0, 0.043478260869565216, 0.22727272727272727, 0.99, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07671515758933826, 0.07671515758933815, 0.1746746691268436], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.7951194], dtype=float32), -0.5255635]. 
=============================================
[2019-03-23 00:40:37,974] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:40:37,981] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1303
[2019-03-23 00:40:37,988] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 99.66666666666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 205966.6035280477, 205966.6035280477, 71577.5747352613], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 438000.0000, 
sim time next is 438600.0000, 
raw observation next is [13.0, 99.83333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 205956.7054512913, 205956.705451291, 71621.30584390638], 
processed observation next is [1.0, 0.043478260869565216, 0.22727272727272727, 0.9983333333333334, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07628026127825603, 0.07628026127825592, 0.1746861118144058], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.1473731], dtype=float32), -0.82002276]. 
=============================================
[2019-03-23 00:40:46,832] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:40:46,839] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4316
[2019-03-23 00:40:46,848] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 94.0, 1.0, 2.0, 0.3965827266451328, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 446975.1518208913, 446975.1518208913, 124582.2125055591], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 874800.0000, 
sim time next is 875400.0000, 
raw observation next is [19.0, 94.00000000000001, 1.0, 2.0, 0.3967758486684854, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 447133.3248828492, 447133.3248828489, 124567.8161159722], 
processed observation next is [0.0, 0.13043478260869565, 0.5, 0.9400000000000002, 1.0, 1.0, 0.24596981083560676, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.165604935141796, 0.1656049351417959, 0.30382394174627364], 
reward next is 0.6962, 
noisyNet noise sample is [array([1.3560622], dtype=float32), 2.3715909]. 
=============================================
[2019-03-23 00:40:48,668] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 2.3908645e-29 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 00:40:48,676] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1752
[2019-03-23 00:40:48,686] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1366232.009295796 W.
[2019-03-23 00:40:48,691] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.33333333333334, 60.66666666666666, 1.0, 2.0, 0.6041457941988261, 1.0, 2.0, 0.6041457941988261, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1366232.009295796, 1366232.009295796, 261333.792438641], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1269600.0000, 
sim time next is 1270200.0000, 
raw observation next is [27.16666666666666, 61.33333333333334, 1.0, 2.0, 0.5962560156739971, 1.0, 2.0, 0.5962560156739971, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1349519.518999275, 1349519.518999275, 258790.8571936111], 
processed observation next is [1.0, 0.6956521739130435, 0.871212121212121, 0.6133333333333334, 1.0, 1.0, 0.49532001959249633, 1.0, 1.0, 0.49532001959249633, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.4998220440738056, 0.4998220440738056, 0.6311972126673442], 
reward next is 0.3688, 
noisyNet noise sample is [array([-1.0609258], dtype=float32), -0.7307]. 
=============================================
[2019-03-23 00:40:48,851] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.4446143e-36 0.0000000e+00], sum to 1.0000
[2019-03-23 00:40:48,857] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2184
[2019-03-23 00:40:48,862] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.5, 94.0, 1.0, 2.0, 0.2708770643544401, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 294122.9170138562, 294122.9170138559, 93136.68457836729], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 628200.0000, 
sim time next is 628800.0000, 
raw observation next is [15.66666666666667, 94.0, 1.0, 2.0, 0.2734251764158167, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 296890.5448853461, 296890.5448853464, 95360.93956748018], 
processed observation next is [1.0, 0.2608695652173913, 0.3484848484848486, 0.94, 1.0, 1.0, 0.09178147051977087, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1099594610686467, 0.1099594610686468, 0.23258765748165897], 
reward next is 0.7674, 
noisyNet noise sample is [array([0.7817105], dtype=float32), 0.5171191]. 
=============================================
[2019-03-23 00:40:52,886] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.21624375e-36 1.00000000e+00 2.95287986e-26 0.00000000e+00
 1.82703450e-10], sum to 1.0000
[2019-03-23 00:40:52,898] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4542
[2019-03-23 00:40:52,907] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1378834.602535121 W.
[2019-03-23 00:40:52,911] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.66666666666666, 56.0, 1.0, 2.0, 0.6065785458509239, 1.0, 1.0, 0.6065785458509239, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1378834.602535121, 1378834.602535121, 259394.4083519636], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 744000.0000, 
sim time next is 744600.0000, 
raw observation next is [27.83333333333334, 55.5, 1.0, 2.0, 0.6242431414360922, 1.0, 2.0, 0.6242431414360922, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1417049.911690934, 1417049.911690934, 265214.4255745609], 
processed observation next is [1.0, 0.6086956521739131, 0.9015151515151518, 0.555, 1.0, 1.0, 0.5303039267951152, 1.0, 1.0, 0.5303039267951152, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.5248333006262719, 0.5248333006262719, 0.6468644526208802], 
reward next is 0.3531, 
noisyNet noise sample is [array([0.3357419], dtype=float32), -1.1321212]. 
=============================================
[2019-03-23 00:40:58,418] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:40:58,425] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8181
[2019-03-23 00:40:58,432] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.83333333333334, 58.66666666666667, 1.0, 2.0, 0.5191368056715381, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 591411.4342774831, 591411.4342774831, 145111.4108255627], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 843000.0000, 
sim time next is 843600.0000, 
raw observation next is [27.66666666666667, 59.33333333333334, 1.0, 2.0, 0.5170547677018729, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 589107.6303274902, 589107.6303274904, 144794.8981014856], 
processed observation next is [0.0, 0.782608695652174, 0.8939393939393941, 0.5933333333333334, 1.0, 1.0, 0.396318459627341, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21818801123240375, 0.21818801123240386, 0.3531582880524039], 
reward next is 0.6468, 
noisyNet noise sample is [array([-1.8735812], dtype=float32), 0.60085875]. 
=============================================
[2019-03-23 00:40:59,455] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.9579582e-29 2.0716144e-31 4.1360756e-28], sum to 1.0000
[2019-03-23 00:40:59,463] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7941
[2019-03-23 00:40:59,472] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 69.0, 1.0, 2.0, 0.6460721984653301, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 727128.3220301018, 727128.3220301018, 150520.3196978889], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1089600.0000, 
sim time next is 1090200.0000, 
raw observation next is [22.0, 69.0, 1.0, 2.0, 0.660760062269142, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 743741.3770951452, 743741.3770951452, 152359.2465689574], 
processed observation next is [1.0, 0.6086956521739131, 0.6363636363636364, 0.69, 1.0, 1.0, 0.5759500778364274, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2754597692944982, 0.2754597692944982, 0.3716079184608717], 
reward next is 0.6284, 
noisyNet noise sample is [array([-0.40187743], dtype=float32), 1.7047757]. 
=============================================
[2019-03-23 00:40:59,848] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:40:59,860] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1549
[2019-03-23 00:40:59,865] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 88.0, 1.0, 2.0, 0.4709675683088432, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 537355.9250059064, 537355.9250059064, 137173.4566889047], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1364400.0000, 
sim time next is 1365000.0000, 
raw observation next is [22.0, 89.00000000000001, 1.0, 2.0, 0.4752712901669668, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 542309.4544722777, 542309.4544722777, 137882.7657932547], 
processed observation next is [1.0, 0.8260869565217391, 0.6363636363636364, 0.8900000000000001, 1.0, 1.0, 0.34408911270870846, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20085535350825098, 0.20085535350825098, 0.33629942876403585], 
reward next is 0.6637, 
noisyNet noise sample is [array([-0.74059194], dtype=float32), 0.30793977]. 
=============================================
[2019-03-23 00:40:59,875] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[68.86872 ]
 [68.90665 ]
 [69.23683 ]
 [69.66239 ]
 [69.679474]], R is [[68.33765411]
 [68.31970978]
 [68.30303955]
 [68.28742218]
 [68.27217865]].
[2019-03-23 00:41:06,010] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-23 00:41:06,012] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 00:41:06,013] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:41:06,014] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 00:41:06,015] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:41:06,016] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 00:41:06,017] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 00:41:06,018] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:41:06,019] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:41:06,018] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 00:41:06,020] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:41:06,043] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run53
[2019-03-23 00:41:06,067] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run53
[2019-03-23 00:41:06,067] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run53
[2019-03-23 00:41:06,118] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run53
[2019-03-23 00:41:06,118] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run53
[2019-03-23 00:41:58,444] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.3140125], dtype=float32), 0.02321171]
[2019-03-23 00:41:58,445] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [26.86666666666667, 59.66666666666667, 1.0, 2.0, 0.4879393574417153, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 556669.7542731961, 556669.7542731958, 144342.3771202043]
[2019-03-23 00:41:58,447] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 00:41:58,451] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.49834620003983987
[2019-03-23 00:42:41,891] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.3140125], dtype=float32), 0.02321171]
[2019-03-23 00:42:41,891] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.64836091, 70.23982743666667, 1.0, 2.0, 0.295092198267722, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 320404.6511279424, 320404.651127942, 115173.1562346801]
[2019-03-23 00:42:41,892] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 00:42:41,898] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.40744286774188543
[2019-03-23 00:42:49,544] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.3140125], dtype=float32), 0.02321171]
[2019-03-23 00:42:49,547] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.11666666666667, 100.0, 1.0, 2.0, 0.4248721028093236, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 477973.833707755, 477973.833707755, 126717.8076506734]
[2019-03-23 00:42:49,548] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 00:42:49,551] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.4806387e-33 2.6501291e-32], sampled 0.43989467676550575
[2019-03-23 00:42:51,607] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8855.7542 1663858414.4981 105.0000
[2019-03-23 00:42:52,131] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8573.5427 1683387571.2268 214.0000
[2019-03-23 00:42:52,167] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9309 1705967916.6745 465.0000
[2019-03-23 00:42:52,253] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9060.3047 1656272944.4788 80.0000
[2019-03-23 00:42:52,315] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8510.6820 1773306048.0551 173.0000
[2019-03-23 00:42:53,335] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 1300000, evaluation results [1300000.0, 8510.682019562386, 1773306048.0550985, 173.0, 9060.304679780347, 1656272944.478839, 80.0, 8855.754186439062, 1663858414.498091, 105.0, 8596.930884973775, 1705967916.6744611, 465.0, 8573.54267693097, 1683387571.2267911, 214.0]
[2019-03-23 00:42:54,984] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 4.2668346e-34 7.1774486e-29 8.6820895e-23], sum to 1.0000
[2019-03-23 00:42:54,991] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7497
[2019-03-23 00:42:54,995] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 94.0, 1.0, 2.0, 0.3956832124512948, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 445923.6621173274, 445923.6621173274, 124481.4992849754], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 973200.0000, 
sim time next is 973800.0000, 
raw observation next is [19.0, 94.0, 1.0, 2.0, 0.3926388994130712, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 442464.6152598023, 442464.6152598023, 124194.4575239584], 
processed observation next is [1.0, 0.2608695652173913, 0.5, 0.94, 1.0, 1.0, 0.24079862426633894, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16387578342955642, 0.16387578342955642, 0.30291331103404484], 
reward next is 0.6971, 
noisyNet noise sample is [array([0.18326223], dtype=float32), -0.3729769]. 
=============================================
[2019-03-23 00:43:05,728] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.9613331e-33 2.0540219e-36 1.9126338e-34], sum to 1.0000
[2019-03-23 00:43:05,738] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0233
[2019-03-23 00:43:05,743] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.66666666666667, 71.33333333333333, 1.0, 2.0, 0.5525698692352616, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 625958.6804504768, 625958.6804504768, 151148.3730338269], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1431600.0000, 
sim time next is 1432200.0000, 
raw observation next is [26.83333333333333, 70.66666666666667, 1.0, 2.0, 0.554393193316128, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 627771.7281847723, 627771.7281847723, 151472.9324099374], 
processed observation next is [0.0, 0.5652173913043478, 0.8560606060606059, 0.7066666666666667, 1.0, 1.0, 0.44299149164516, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23250804747584158, 0.23250804747584158, 0.36944617660960344], 
reward next is 0.6306, 
noisyNet noise sample is [array([0.02868806], dtype=float32), 0.5540874]. 
=============================================
[2019-03-23 00:43:06,266] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 3.129679e-37], sum to 1.0000
[2019-03-23 00:43:06,274] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1841
[2019-03-23 00:43:06,283] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.16666666666667, 69.33333333333334, 1.0, 2.0, 0.7245016076671473, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 824669.5586981112, 824669.5586981116, 173884.9173854415], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1170600.0000, 
sim time next is 1171200.0000, 
raw observation next is [26.33333333333334, 68.66666666666667, 1.0, 2.0, 0.9878084037453624, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1124143.453808521, 1124143.453808521, 219908.2975498558], 
processed observation next is [1.0, 0.5652173913043478, 0.8333333333333336, 0.6866666666666668, 1.0, 1.0, 0.9847605046817028, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.4163494273364892, 0.4163494273364892, 0.5363617013411117], 
reward next is 0.4636, 
noisyNet noise sample is [array([0.20384158], dtype=float32), -0.24116811]. 
=============================================
[2019-03-23 00:43:16,189] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.7034915e-31], sum to 1.0000
[2019-03-23 00:43:16,198] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3453
[2019-03-23 00:43:16,205] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666667, 81.33333333333334, 1.0, 2.0, 0.466573067796163, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 532178.6772826441, 532178.6772826441, 136205.767507462], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1362000.0000, 
sim time next is 1362600.0000, 
raw observation next is [22.5, 83.0, 1.0, 2.0, 0.4659448678627971, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 531515.6041937559, 531515.6041937559, 136270.6626481814], 
processed observation next is [1.0, 0.782608695652174, 0.6590909090909091, 0.83, 1.0, 1.0, 0.3324310848284963, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19685763118287256, 0.19685763118287256, 0.33236746987361315], 
reward next is 0.6676, 
noisyNet noise sample is [array([0.57728726], dtype=float32), -1.3359008]. 
=============================================
[2019-03-23 00:43:19,499] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.6452877e-27 1.0000000e+00 8.7679400e-20 1.4842912e-19 3.7246597e-08], sum to 1.0000
[2019-03-23 00:43:19,506] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3810
[2019-03-23 00:43:19,517] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1146479.687517617 W.
[2019-03-23 00:43:19,525] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.0, 61.0, 1.0, 2.0, 0.5028529356335488, 1.0, 2.0, 0.5028529356335488, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1146479.687517617, 1146479.687517616, 229979.2955493807], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1950600.0000, 
sim time next is 1951200.0000, 
raw observation next is [26.0, 61.0, 1.0, 2.0, 0.5118366295006535, 1.0, 2.0, 0.5118366295006535, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1166905.431195643, 1166905.431195643, 232213.6494306044], 
processed observation next is [1.0, 0.6086956521739131, 0.8181818181818182, 0.61, 1.0, 1.0, 0.3897957868758168, 1.0, 1.0, 0.3897957868758168, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.43218719673912703, 0.43218719673912703, 0.5663747547087912], 
reward next is 0.4336, 
noisyNet noise sample is [array([1.5905268], dtype=float32), -0.14571504]. 
=============================================
[2019-03-23 00:43:26,560] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 8.9650089e-37 1.0200892e-37], sum to 1.0000
[2019-03-23 00:43:26,571] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8939
[2019-03-23 00:43:26,575] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.33333333333334, 81.66666666666667, 1.0, 2.0, 0.5647431971658424, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 638303.950529538, 638303.9505295383, 153201.3250282658], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1531200.0000, 
sim time next is 1531800.0000, 
raw observation next is [25.5, 81.0, 1.0, 2.0, 0.5680529924532234, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 641662.7606774697, 641662.7606774697, 153748.5043768199], 
processed observation next is [0.0, 0.7391304347826086, 0.7954545454545454, 0.81, 1.0, 1.0, 0.46006624056652917, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23765287432498877, 0.23765287432498877, 0.3749963521385851], 
reward next is 0.6250, 
noisyNet noise sample is [array([-0.53004235], dtype=float32), 0.21239305]. 
=============================================
[2019-03-23 00:43:26,771] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:43:26,777] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1577
[2019-03-23 00:43:26,780] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.66666666666667, 81.66666666666666, 1.0, 2.0, 0.5486318106611606, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 622792.6811689954, 622792.6811689954, 150123.8438584058], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1536000.0000, 
sim time next is 1536600.0000, 
raw observation next is [24.33333333333333, 82.33333333333334, 1.0, 2.0, 0.5381323357092795, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 611718.4280815541, 611718.4280815541, 148368.3345876704], 
processed observation next is [0.0, 0.782608695652174, 0.7424242424242422, 0.8233333333333335, 1.0, 1.0, 0.42266541963659937, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22656238077094598, 0.22656238077094598, 0.3618739867991961], 
reward next is 0.6381, 
noisyNet noise sample is [array([0.23022233], dtype=float32), 0.2585604]. 
=============================================
[2019-03-23 00:43:31,027] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 2.0790493e-30 2.1306947e-35 6.8071503e-28], sum to 1.0000
[2019-03-23 00:43:31,035] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2058
[2019-03-23 00:43:31,041] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1130433.727616787 W.
[2019-03-23 00:43:31,045] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.93333333333333, 62.16666666666667, 1.0, 2.0, 0.4978607005107309, 1.0, 1.0, 0.4978607005107309, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1130433.727616787, 1130433.727616787, 231709.4112708612], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1605000.0000, 
sim time next is 1605600.0000, 
raw observation next is [27.0, 62.0, 1.0, 2.0, 0.5277138287001215, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9626410576911106, 6.933863352349046, 6.9112, 77.32840769832487, 1148646.269355981, 1141285.681364898, 264080.3651227436], 
processed observation next is [1.0, 0.6086956521739131, 0.8636363636363636, 0.62, 1.0, 1.0, 0.40964228587515183, 0.0, 0.5, -0.25, 1.0, 0.5, 0.9466300824158723, 0.0022663352349045597, 0.0, 0.5084284464000636, 0.42542454420591885, 0.4226984005055178, 0.6440984515188868], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8304828], dtype=float32), 1.3757268]. 
=============================================
[2019-03-23 00:43:36,446] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 8.6184432e-29 1.1069182e-26], sum to 1.0000
[2019-03-23 00:43:36,459] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8389
[2019-03-23 00:43:36,463] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 87.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 202963.3777872944, 202963.3777872947, 68304.93206299277], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2353800.0000, 
sim time next is 2354400.0000, 
raw observation next is [13.0, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 202594.7467028977, 202594.746702898, 68417.81049881934], 
processed observation next is [1.0, 0.2608695652173913, 0.22727272727272727, 0.88, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0750350913714436, 0.07503509137144371, 0.1668727085337057], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.1096617], dtype=float32), 2.5777454]. 
=============================================
[2019-03-23 00:43:42,385] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 3.2628886e-31], sum to 1.0000
[2019-03-23 00:43:42,394] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4215
[2019-03-23 00:43:42,399] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 70.5, 1.0, 2.0, 0.2818586710612455, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 306050.684040926, 306050.6840409263, 104436.9582432379], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1906200.0000, 
sim time next is 1906800.0000, 
raw observation next is [19.0, 71.33333333333333, 1.0, 2.0, 0.2852572488578103, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 309742.1379636796, 309742.1379636799, 107085.9293260492], 
processed observation next is [1.0, 0.043478260869565216, 0.5, 0.7133333333333333, 1.0, 1.0, 0.10657156107226284, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11471931035691837, 0.11471931035691849, 0.26118519347816876], 
reward next is 0.7388, 
noisyNet noise sample is [array([-0.6921203], dtype=float32), 0.7951797]. 
=============================================
[2019-03-23 00:43:46,041] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 00:43:46,044] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 00:43:46,045] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 00:43:46,046] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:43:46,046] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:43:46,046] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 00:43:46,047] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 00:43:46,047] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 00:43:46,050] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:43:46,052] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:43:46,053] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:43:46,074] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run54
[2019-03-23 00:43:46,100] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run54
[2019-03-23 00:43:46,101] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run54
[2019-03-23 00:43:46,160] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run54
[2019-03-23 00:43:46,162] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run54
[2019-03-23 00:43:59,124] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.41791707], dtype=float32), 0.036707103]
[2019-03-23 00:43:59,126] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [29.3, 40.0, 1.0, 2.0, 0.4083388032833693, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 463937.2341959204, 463937.2341959204, 132362.6209152328]
[2019-03-23 00:43:59,129] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 00:43:59,132] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.298350394885988
[2019-03-23 00:44:26,421] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.41791707], dtype=float32), 0.036707103]
[2019-03-23 00:44:26,422] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.52118225, 91.47174204999999, 1.0, 2.0, 0.5333967731498085, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 605343.8095534067, 605343.8095534063, 152531.5020724605]
[2019-03-23 00:44:26,425] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 00:44:26,426] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 2.0585852e-38], sampled 0.8843389796211419
[2019-03-23 00:44:36,185] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.41791707], dtype=float32), 0.036707103]
[2019-03-23 00:44:36,188] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.24256718333334, 90.08350439166668, 1.0, 2.0, 0.5487766089050513, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 617949.0983109587, 617949.0983109587, 143813.1052178105]
[2019-03-23 00:44:36,190] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 00:44:36,194] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.0770016e-37], sampled 0.27067980562901295
[2019-03-23 00:44:36,775] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.41791707], dtype=float32), 0.036707103]
[2019-03-23 00:44:36,776] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [15.58123307666667, 85.69582154333334, 1.0, 2.0, 0.249505600974443, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 270896.5665795159, 270896.5665795156, 88351.81897795672]
[2019-03-23 00:44:36,778] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 00:44:36,781] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.7837548274197471
[2019-03-23 00:44:53,272] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.41791707], dtype=float32), 0.036707103]
[2019-03-23 00:44:53,274] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [26.270147265, 41.861377705, 1.0, 2.0, 0.3567992521760606, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 397704.1154607981, 397704.1154607978, 123293.8693206212]
[2019-03-23 00:44:53,276] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 00:44:53,281] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.9711442124266954
[2019-03-23 00:45:04,399] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.41791707], dtype=float32), 0.036707103]
[2019-03-23 00:45:04,400] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.56666666666667, 46.66666666666667, 1.0, 2.0, 0.2803465713064521, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 304390.1176542563, 304390.1176542563, 89341.16266074705]
[2019-03-23 00:45:04,402] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 00:45:04,404] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.3239790685486058
[2019-03-23 00:45:07,931] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.41791707], dtype=float32), 0.036707103]
[2019-03-23 00:45:07,932] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.859725775, 65.94426073833334, 1.0, 2.0, 0.2788708413299332, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 302787.4200683779, 302787.4200683775, 97720.28510657653]
[2019-03-23 00:45:07,934] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 00:45:07,937] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.6072284091873349
[2019-03-23 00:45:30,110] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.41791707], dtype=float32), 0.036707103]
[2019-03-23 00:45:30,112] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.33333333333334, 71.0, 1.0, 2.0, 0.3413384900152466, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 370633.3465204866, 370633.3465204862, 118363.1410273868]
[2019-03-23 00:45:30,113] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 00:45:30,118] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.35515510094044145
[2019-03-23 00:45:31,964] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8509.1813 1773413472.9632 173.0000
[2019-03-23 00:45:32,062] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8595.3099 1706074232.0561 465.0000
[2019-03-23 00:45:32,250] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8571.9617 1683477666.0862 214.0000
[2019-03-23 00:45:32,330] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9058.6831 1656359050.7176 80.0000
[2019-03-23 00:45:32,414] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8854.1746 1663949029.5070 105.0000
[2019-03-23 00:45:33,430] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 1325000, evaluation results [1325000.0, 8509.181281245757, 1773413472.9631987, 173.0, 9058.683074210225, 1656359050.7176125, 80.0, 8854.174594824059, 1663949029.507014, 105.0, 8595.309948762033, 1706074232.0561063, 465.0, 8571.9617444755, 1683477666.0861843, 214.0]
[2019-03-23 00:45:37,421] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.4634574e-37 2.5610926e-29], sum to 1.0000
[2019-03-23 00:45:37,428] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0193
[2019-03-23 00:45:37,434] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 66.0, 1.0, 2.0, 0.311930846753211, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 338715.3350989922, 338715.3350989919, 111998.6333007394], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1985400.0000, 
sim time next is 1986000.0000, 
raw observation next is [19.66666666666667, 66.66666666666666, 1.0, 2.0, 0.3050513298042205, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 331242.552168073, 331242.5521680727, 109356.4876598977], 
processed observation next is [1.0, 1.0, 0.5303030303030305, 0.6666666666666665, 1.0, 1.0, 0.13131416225527562, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12268242672891594, 0.12268242672891583, 0.26672314063389685], 
reward next is 0.7333, 
noisyNet noise sample is [array([-0.6339826], dtype=float32), 2.7183735]. 
=============================================
[2019-03-23 00:45:37,449] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[70.08398 ]
 [69.99423 ]
 [69.914955]
 [69.88608 ]
 [69.860825]], R is [[70.22631836]
 [70.25088501]
 [70.27346039]
 [70.29394531]
 [70.31329346]].
[2019-03-23 00:45:49,514] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.4001472e-32 5.9270496e-21 4.4308571e-17], sum to 1.0000
[2019-03-23 00:45:49,523] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5007
[2019-03-23 00:45:49,526] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 73.83333333333334, 1.0, 2.0, 0.6202306380451613, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 675438.5494022153, 675438.5494022156, 139023.7863401109], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2203800.0000, 
sim time next is 2204400.0000, 
raw observation next is [19.0, 74.66666666666667, 1.0, 2.0, 0.4796982005853075, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 522950.1072890987, 522950.1072890987, 125677.6288764808], 
processed observation next is [1.0, 0.5217391304347826, 0.5, 0.7466666666666667, 1.0, 1.0, 0.34962275073163435, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19368522492188842, 0.19368522492188842, 0.306530802137758], 
reward next is 0.6935, 
noisyNet noise sample is [array([-0.7212978], dtype=float32), -0.08131001]. 
=============================================
[2019-03-23 00:45:54,232] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.5224702e-37 9.4583811e-25 2.4993130e-22], sum to 1.0000
[2019-03-23 00:45:54,241] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7089
[2019-03-23 00:45:54,245] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 94.0, 1.0, 2.0, 0.3053026141496606, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 331515.5043943026, 331515.5043943029, 103667.9263241262], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2242800.0000, 
sim time next is 2243400.0000, 
raw observation next is [16.0, 93.00000000000001, 1.0, 2.0, 0.3000529241080731, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 325813.1731077211, 325813.1731077211, 101435.4430266073], 
processed observation next is [1.0, 1.0, 0.36363636363636365, 0.9300000000000002, 1.0, 1.0, 0.12506615513509137, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12067154559545225, 0.12067154559545225, 0.24740351957709097], 
reward next is 0.7526, 
noisyNet noise sample is [array([1.3702557], dtype=float32), 0.7274975]. 
=============================================
[2019-03-23 00:45:57,442] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.4244664e-32 7.3603278e-24], sum to 1.0000
[2019-03-23 00:45:57,443] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6115
[2019-03-23 00:45:57,450] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.33333333333333, 88.0, 1.0, 2.0, 0.2168690635178737, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 235465.9168661261, 235465.9168661258, 71497.26714209853], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2344800.0000, 
sim time next is 2345400.0000, 
raw observation next is [12.5, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 208400.0013964919, 208400.0013964917, 68787.08101460492], 
processed observation next is [1.0, 0.13043478260869565, 0.20454545454545456, 0.88, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0771851857024044, 0.07718518570240433, 0.16777336832830467], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.2135295], dtype=float32), -0.103311434]. 
=============================================
[2019-03-23 00:45:57,759] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 7.3884132e-36 3.2940465e-28 3.0197308e-22], sum to 1.0000
[2019-03-23 00:45:57,767] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7520
[2019-03-23 00:45:57,771] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 83.0, 1.0, 2.0, 0.6245040402885625, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 711881.2296090325, 711881.2296090325, 154141.7399091174], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2859600.0000, 
sim time next is 2860200.0000, 
raw observation next is [22.0, 83.0, 1.0, 2.0, 0.5274555247608854, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 601116.0068250684, 601116.0068250686, 142153.9653079841], 
processed observation next is [1.0, 0.08695652173913043, 0.6363636363636364, 0.83, 1.0, 1.0, 0.4093194059511067, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22263555808335866, 0.22263555808335875, 0.34671698855605876], 
reward next is 0.6533, 
noisyNet noise sample is [array([-1.1829525], dtype=float32), 0.6558153]. 
=============================================
[2019-03-23 00:46:05,762] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.8445695e-28 4.6690354e-19], sum to 1.0000
[2019-03-23 00:46:05,772] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6651
[2019-03-23 00:46:05,781] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.16666666666667, 83.00000000000001, 1.0, 2.0, 0.5225422583464165, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 567544.7507091012, 567544.7507091012, 115418.0299145466], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2455800.0000, 
sim time next is 2456400.0000, 
raw observation next is [16.33333333333334, 84.0, 1.0, 2.0, 0.5063763630426966, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 549976.679484333, 549976.6794843328, 115989.9841904259], 
processed observation next is [1.0, 0.43478260869565216, 0.37878787878787906, 0.84, 1.0, 1.0, 0.38297045380337075, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2036950664756789, 0.2036950664756788, 0.2829024004644534], 
reward next is 0.7171, 
noisyNet noise sample is [array([0.03728426], dtype=float32), 0.5061155]. 
=============================================
[2019-03-23 00:46:07,856] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.2508029e-37], sum to 1.0000
[2019-03-23 00:46:07,865] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7911
[2019-03-23 00:46:07,869] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 94.0, 1.0, 2.0, 0.2331830071736839, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 253183.4162675543, 253183.4162675546, 78648.41507879407], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2490600.0000, 
sim time next is 2491200.0000, 
raw observation next is [14.0, 94.0, 1.0, 2.0, 0.2325021487793105, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 252443.9679161886, 252443.9679161884, 78576.09603761355], 
processed observation next is [1.0, 0.8695652173913043, 0.2727272727272727, 0.94, 1.0, 1.0, 0.04062768597413811, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09349776589488466, 0.0934977658948846, 0.1916490147258867], 
reward next is 0.8084, 
noisyNet noise sample is [array([-0.26579705], dtype=float32), 1.6757696]. 
=============================================
[2019-03-23 00:46:13,229] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:46:13,237] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0792
[2019-03-23 00:46:13,243] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.43333333333334, 67.0, 1.0, 2.0, 0.2582193695727457, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 280375.0153503875, 280375.0153503872, 88648.38994952949], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2586000.0000, 
sim time next is 2586600.0000, 
raw observation next is [18.35, 68.5, 1.0, 2.0, 0.2608340950569788, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 283214.9152164622, 283214.9152164625, 89975.03620160664], 
processed observation next is [1.0, 0.9565217391304348, 0.4704545454545455, 0.685, 1.0, 1.0, 0.07604261882122348, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10489441304313415, 0.10489441304313427, 0.21945130780879668], 
reward next is 0.7805, 
noisyNet noise sample is [array([0.4399748], dtype=float32), -0.011391874]. 
=============================================
[2019-03-23 00:46:15,543] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:46:15,549] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6259
[2019-03-23 00:46:15,554] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.16666666666667, 46.16666666666667, 1.0, 2.0, 0.340944529215303, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 379064.6791579946, 379064.6791579946, 117298.880895074], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2632200.0000, 
sim time next is 2632800.0000, 
raw observation next is [25.33333333333334, 45.33333333333334, 1.0, 2.0, 0.3382224910392259, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 375943.5498696246, 375943.5498696246, 117047.9062609873], 
processed observation next is [0.0, 0.4782608695652174, 0.7878787878787882, 0.4533333333333334, 1.0, 1.0, 0.17277811379903238, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13923835180356467, 0.13923835180356467, 0.28548269819753], 
reward next is 0.7145, 
noisyNet noise sample is [array([-0.29521945], dtype=float32), 0.1912691]. 
=============================================
[2019-03-23 00:46:20,331] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:46:20,337] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3741
[2019-03-23 00:46:20,344] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.33333333333334, 64.0, 1.0, 2.0, 0.481628235056627, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 549378.0742460991, 549378.0742460993, 139734.9555216949], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2722800.0000, 
sim time next is 2723400.0000, 
raw observation next is [26.5, 63.5, 1.0, 2.0, 0.4852768460885409, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 553469.1946217836, 553469.1946217836, 140293.2589855134], 
processed observation next is [0.0, 0.5217391304347826, 0.8409090909090909, 0.635, 1.0, 1.0, 0.3565960576106761, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20498859060066058, 0.20498859060066058, 0.34217868045247174], 
reward next is 0.6578, 
noisyNet noise sample is [array([0.200428], dtype=float32), 0.34599644]. 
=============================================
[2019-03-23 00:46:21,009] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:46:21,020] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5003
[2019-03-23 00:46:21,025] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 61.0, 1.0, 2.0, 0.4561877238488979, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 520407.1876095074, 520407.1876095074, 135296.675395883], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2736000.0000, 
sim time next is 2736600.0000, 
raw observation next is [26.16666666666667, 59.33333333333334, 1.0, 2.0, 0.4545317030103911, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 518448.5057915826, 518448.5057915829, 134939.1857611062], 
processed observation next is [0.0, 0.6956521739130435, 0.825757575757576, 0.5933333333333334, 1.0, 1.0, 0.31816462876298884, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19201796510799354, 0.19201796510799368, 0.32911996527099074], 
reward next is 0.6709, 
noisyNet noise sample is [array([-0.85668963], dtype=float32), 0.45731574]. 
=============================================
[2019-03-23 00:46:21,431] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:46:21,438] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0641
[2019-03-23 00:46:21,448] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.83333333333333, 77.83333333333334, 1.0, 2.0, 0.2955121626778227, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 320880.949938644, 320880.949938644, 102228.2998800401], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3280200.0000, 
sim time next is 3280800.0000, 
raw observation next is [17.66666666666667, 78.66666666666667, 1.0, 2.0, 0.2939199185978877, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 319151.449397184, 319151.4493971842, 101093.5448862984], 
processed observation next is [0.0, 1.0, 0.4393939393939396, 0.7866666666666667, 1.0, 1.0, 0.1173998982473596, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11820424051747556, 0.11820424051747562, 0.24656962167389854], 
reward next is 0.7534, 
noisyNet noise sample is [array([-1.340504], dtype=float32), -0.61222595]. 
=============================================
[2019-03-23 00:46:25,846] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-23 00:46:25,850] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 00:46:25,850] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:46:25,852] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 00:46:25,853] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:46:25,853] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 00:46:25,854] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 00:46:25,855] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:46:25,855] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:46:25,856] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 00:46:25,857] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:46:25,887] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run55
[2019-03-23 00:46:25,910] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run55
[2019-03-23 00:46:25,910] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run55
[2019-03-23 00:46:25,954] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run55
[2019-03-23 00:46:25,954] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run55
[2019-03-23 00:46:53,271] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.41636443], dtype=float32), 0.12072098]
[2019-03-23 00:46:53,273] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.98333333333333, 89.16666666666667, 1.0, 2.0, 0.3652759094833238, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 408811.9674592049, 408811.9674592049, 124719.6422420942]
[2019-03-23 00:46:53,274] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 00:46:53,276] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0.0000000e+00 1.0000000e+00 2.7841796e-36 3.5100632e-38 3.0846607e-23], sampled 0.7043357465647274
[2019-03-23 00:46:54,886] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.41636443], dtype=float32), 0.12072098]
[2019-03-23 00:46:54,888] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [24.997066595, 55.343882765, 1.0, 2.0, 0.4002804134438252, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 452371.8576163778, 452371.8576163778, 129934.8489484765]
[2019-03-23 00:46:54,889] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 00:46:54,892] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 3.0861784e-31], sampled 0.7731604518531864
[2019-03-23 00:47:09,427] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.41636443], dtype=float32), 0.12072098]
[2019-03-23 00:47:09,430] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.40223924, 73.33271136, 1.0, 2.0, 0.3607600755383155, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 400834.9271994568, 400834.9271994564, 123073.817866246]
[2019-03-23 00:47:09,433] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 00:47:09,436] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0.0000000e+00 1.0000000e+00 4.1041983e-37 1.7553421e-38 1.8961392e-23], sampled 0.1656871509012865
[2019-03-23 00:47:29,807] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.41636443], dtype=float32), 0.12072098]
[2019-03-23 00:47:29,808] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.70267103, 64.46913219000001, 1.0, 2.0, 0.3013133004215698, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 327161.2262373087, 327161.2262373084, 107989.2363986787]
[2019-03-23 00:47:29,812] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 00:47:29,817] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.9062007e-28], sampled 0.8378512735151545
[2019-03-23 00:47:37,552] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.41636443], dtype=float32), 0.12072098]
[2019-03-23 00:47:37,553] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.29720222333333, 79.54332298666668, 1.0, 2.0, 0.3981429252754518, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 446988.4481535516, 446988.4481535512, 128162.3613319334]
[2019-03-23 00:47:37,554] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 00:47:37,556] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0.0000000e+00 1.0000000e+00 3.0544624e-38 0.0000000e+00 6.4991492e-27], sampled 0.6995065385014931
[2019-03-23 00:47:40,526] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.41636443], dtype=float32), 0.12072098]
[2019-03-23 00:47:40,526] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [15.51666666666667, 90.0, 1.0, 2.0, 0.2528826301608961, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 274563.957451741, 274563.9574517407, 91702.69138623243]
[2019-03-23 00:47:40,528] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 00:47:40,531] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.9974547e-26], sampled 0.15890686163838796
[2019-03-23 00:48:09,914] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8500.5239 1779929993.7673 141.0000
[2019-03-23 00:48:10,186] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8577.8611 1685865942.2154 167.0000
[2019-03-23 00:48:10,480] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8858.6689 1665590029.2493 70.0000
[2019-03-23 00:48:10,493] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9063.6238 1657744949.3618 49.0000
[2019-03-23 00:48:10,513] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8600.1620 1706658977.3564 437.0000
[2019-03-23 00:48:11,528] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1350000, evaluation results [1350000.0, 8500.523860384492, 1779929993.7673275, 141.0, 9063.623792514667, 1657744949.3618186, 49.0, 8858.66893062997, 1665590029.2493, 70.0, 8600.16196917127, 1706658977.3563964, 437.0, 8577.86107048613, 1685865942.215367, 167.0]
[2019-03-23 00:48:12,876] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.6730376e-37 1.0000000e+00 4.5164017e-33 1.0551924e-36 1.1585394e-14], sum to 1.0000
[2019-03-23 00:48:12,887] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9820
[2019-03-23 00:48:12,900] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 89.0, 1.0, 2.0, 0.5609945408525094, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 635732.4083037318, 635732.4083037318, 152164.6208402303], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3099600.0000, 
sim time next is 3100200.0000, 
raw observation next is [23.83333333333333, 89.0, 1.0, 2.0, 0.5606068560693143, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 635721.4004185386, 635721.4004185386, 151950.2901601857], 
processed observation next is [1.0, 0.9130434782608695, 0.7196969696969695, 0.89, 1.0, 1.0, 0.4507585700866428, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23545237052538467, 0.23545237052538467, 0.37061046380533097], 
reward next is 0.6294, 
noisyNet noise sample is [array([-0.33491907], dtype=float32), -0.112096824]. 
=============================================
[2019-03-23 00:48:27,070] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.9711954e-34 0.0000000e+00 3.6485899e-25], sum to 1.0000
[2019-03-23 00:48:27,075] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3609
[2019-03-23 00:48:27,080] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 83.0, 1.0, 2.0, 0.5352127074340255, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 609229.1270729641, 609229.1270729643, 147485.5649380339], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3096000.0000, 
sim time next is 3096600.0000, 
raw observation next is [24.0, 84.0, 1.0, 2.0, 0.5368420724235549, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 610872.8878029202, 610872.8878029202, 147834.7268278633], 
processed observation next is [1.0, 0.8695652173913043, 0.7272727272727273, 0.84, 1.0, 1.0, 0.42105259052944355, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22624921770478526, 0.22624921770478526, 0.3605725044582032], 
reward next is 0.6394, 
noisyNet noise sample is [array([-1.5416336], dtype=float32), 0.46465638]. 
=============================================
[2019-03-23 00:48:27,261] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 2.5714833e-26], sum to 1.0000
[2019-03-23 00:48:27,270] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0732
[2019-03-23 00:48:27,276] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 74.0, 1.0, 2.0, 0.5628906973714987, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 638552.0046038725, 638552.0046038725, 152152.5969968502], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3092400.0000, 
sim time next is 3093000.0000, 
raw observation next is [25.66666666666667, 75.5, 1.0, 2.0, 0.5614800172877871, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 637300.1421179833, 637300.142117983, 151820.2705355696], 
processed observation next is [1.0, 0.8260869565217391, 0.8030303030303032, 0.755, 1.0, 1.0, 0.4518500216097338, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.23603708967332715, 0.236037089673327, 0.37029334276968195], 
reward next is 0.6297, 
noisyNet noise sample is [array([0.24647354], dtype=float32), 0.36690322]. 
=============================================
[2019-03-23 00:48:27,294] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[60.605415]
 [60.4451  ]
 [60.25524 ]
 [60.03517 ]
 [59.58675 ]], R is [[60.55239105]
 [60.5757637 ]
 [60.59888077]
 [60.62117386]
 [60.64149094]].
[2019-03-23 00:48:34,650] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:48:34,663] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8541
[2019-03-23 00:48:34,669] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 68.16666666666667, 1.0, 2.0, 0.3715100087356061, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 416889.7411415201, 416889.7411415201, 121436.1547574995], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3229800.0000, 
sim time next is 3230400.0000, 
raw observation next is [22.0, 67.33333333333334, 1.0, 2.0, 0.368468427421434, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 412913.094394092, 412913.094394092, 120909.2017762512], 
processed observation next is [0.0, 0.391304347826087, 0.6363636363636364, 0.6733333333333335, 1.0, 1.0, 0.21058553427679247, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15293077570151556, 0.15293077570151556, 0.29490049213719804], 
reward next is 0.7051, 
noisyNet noise sample is [array([0.21392605], dtype=float32), -1.3455594]. 
=============================================
[2019-03-23 00:48:36,667] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:48:36,677] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4745
[2019-03-23 00:48:36,682] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.5, 74.83333333333334, 1.0, 2.0, 0.3047943133434248, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 330963.3737130687, 330963.3737130687, 108374.6623884519], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3279000.0000, 
sim time next is 3279600.0000, 
raw observation next is [18.0, 77.0, 1.0, 2.0, 0.2987161480275498, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 324361.1475719704, 324361.1475719707, 103585.9110325968], 
processed observation next is [0.0, 1.0, 0.45454545454545453, 0.77, 1.0, 1.0, 0.12339518503443725, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12013375835998905, 0.12013375835998916, 0.25264856349413856], 
reward next is 0.7474, 
noisyNet noise sample is [array([2.2742507], dtype=float32), 0.5695751]. 
=============================================
[2019-03-23 00:48:38,491] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 6.8183686e-38 3.8252417e-37 2.7471371e-37], sum to 1.0000
[2019-03-23 00:48:38,502] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6042
[2019-03-23 00:48:38,508] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.5478815523100939, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 625134.2199678716, 625134.2199678718, 147258.6511137408], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3565800.0000, 
sim time next is 3566400.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.5391552983308544, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 615173.1280166812, 615173.1280166808, 146183.8445448622], 
processed observation next is [1.0, 0.2608695652173913, 0.5909090909090909, 1.0, 1.0, 1.0, 0.423944122913568, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22784189926543746, 0.22784189926543735, 0.35654596230454194], 
reward next is 0.6435, 
noisyNet noise sample is [array([-0.69317], dtype=float32), 0.95336646]. 
=============================================
[2019-03-23 00:48:38,814] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 2.3258811e-34 3.8477082e-36 2.0697549e-34], sum to 1.0000
[2019-03-23 00:48:38,831] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3413
[2019-03-23 00:48:38,836] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.5888373240380265, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 671588.8333488803, 671588.8333488803, 153090.4632288702], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3571200.0000, 
sim time next is 3571800.0000, 
raw observation next is [22.0, 94.00000000000001, 1.0, 2.0, 0.6337993601147939, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 722861.9095967278, 722861.909596728, 159170.2720467303], 
processed observation next is [1.0, 0.34782608695652173, 0.6363636363636364, 0.9400000000000002, 1.0, 1.0, 0.5422492001434923, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2677266331839733, 0.26772663318397333, 0.38822017572373246], 
reward next is 0.6118, 
noisyNet noise sample is [array([-0.2249179], dtype=float32), 0.032198984]. 
=============================================
[2019-03-23 00:48:54,904] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 2.3416183e-36 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 00:48:54,910] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3301
[2019-03-23 00:48:54,918] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1478311.374991815 W.
[2019-03-23 00:48:54,926] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.0, 58.0, 1.0, 2.0, 0.4368189573911604, 1.0, 1.0, 0.4368189573911604, 1.0, 2.0, 0.8833119328067655, 6.911199999999999, 6.9112, 77.3421103, 1478311.374991815, 1478311.374991815, 323666.9126529184], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3679200.0000, 
sim time next is 3679800.0000, 
raw observation next is [28.16666666666667, 57.5, 1.0, 2.0, 0.6647236005612868, 1.0, 2.0, 0.6647236005612868, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1500040.091381614, 1500040.091381614, 279794.4928135904], 
processed observation next is [1.0, 0.6086956521739131, 0.9166666666666669, 0.575, 1.0, 1.0, 0.5809045007016084, 1.0, 1.0, 0.5809045007016084, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.5555704042154126, 0.5555704042154126, 0.6824255922282693], 
reward next is 0.3176, 
noisyNet noise sample is [array([-0.92227167], dtype=float32), -0.77289873]. 
=============================================
[2019-03-23 00:48:58,944] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:48:58,956] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9956
[2019-03-23 00:48:58,959] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333334, 52.00000000000001, 1.0, 2.0, 0.3208090372892299, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 353047.3084053565, 353047.3084053562, 114292.0327639807], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3928200.0000, 
sim time next is 3928800.0000, 
raw observation next is [23.66666666666667, 51.0, 1.0, 2.0, 0.321504929173512, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 354521.8972500759, 354521.8972500759, 114615.1687457561], 
processed observation next is [0.0, 0.4782608695652174, 0.7121212121212124, 0.51, 1.0, 1.0, 0.15188116146688996, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.131304406388917, 0.131304406388917, 0.27954919206281975], 
reward next is 0.7205, 
noisyNet noise sample is [array([-0.06934939], dtype=float32), -0.40456238]. 
=============================================
[2019-03-23 00:49:04,107] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-23 00:49:04,111] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 00:49:04,111] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 00:49:04,112] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 00:49:04,112] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:49:04,113] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 00:49:04,113] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:49:04,114] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 00:49:04,115] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:49:04,116] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:49:04,112] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:49:04,133] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run56
[2019-03-23 00:49:04,154] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run56
[2019-03-23 00:49:04,173] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run56
[2019-03-23 00:49:04,200] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run56
[2019-03-23 00:49:04,220] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run56
[2019-03-23 00:49:05,305] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.41538456], dtype=float32), 0.04573904]
[2019-03-23 00:49:05,306] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.9009817, 77.27532235333334, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 95.55338769695034, 251309.0291525384, 251309.0291525381, 134757.5883885576]
[2019-03-23 00:49:05,307] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 00:49:05,309] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.7711649e-24 3.7023760e-04 7.9729643e-24 5.4090481e-20 9.9962974e-01], sampled 0.7674675720341482
[2019-03-23 00:49:05,934] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.41538456], dtype=float32), 0.04573904]
[2019-03-23 00:49:05,938] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.55, 34.33333333333334, 1.0, 2.0, 0.4903120556854812, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 532464.0141975675, 532464.0141975675, 109413.0546057232]
[2019-03-23 00:49:05,939] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 00:49:05,942] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.35417163346054137
[2019-03-23 00:49:24,232] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.41538456], dtype=float32), 0.04573904]
[2019-03-23 00:49:24,233] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [24.887899785, 93.01767760833333, 1.0, 2.0, 0.6031916931920914, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 677736.1512031642, 677736.1512031639, 163651.0217453269]
[2019-03-23 00:49:24,234] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 00:49:24,236] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.08176929913858966
[2019-03-23 00:49:41,404] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.41538456], dtype=float32), 0.04573904]
[2019-03-23 00:49:41,408] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [27.906167525, 65.09519287, 1.0, 2.0, 0.5741282550367361, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 648808.3238709609, 648808.3238709605, 158761.4935167828]
[2019-03-23 00:49:41,409] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 00:49:41,414] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 3.982129e-38], sampled 0.6307618561251664
[2019-03-23 00:49:50,590] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.41538456], dtype=float32), 0.04573904]
[2019-03-23 00:49:50,592] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [18.38333333333333, 90.0, 1.0, 2.0, 0.353265429008612, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 392656.1949469932, 392656.1949469929, 122539.8954458812]
[2019-03-23 00:49:50,594] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 00:49:50,597] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.07882661661416146
[2019-03-23 00:50:41,570] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.41538456], dtype=float32), 0.04573904]
[2019-03-23 00:50:41,571] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [25.58449861, 42.63544404, 1.0, 2.0, 0.5822814194543611, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 647615.9423718, 647615.9423717996, 144075.9693499248]
[2019-03-23 00:50:41,571] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 00:50:41,574] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 3.231994e-38], sampled 0.4644989035636379
[2019-03-23 00:50:51,249] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9057.0586 1656443078.0244 80.0000
[2019-03-23 00:50:51,324] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8508.4528 1773463374.2284 173.0000
[2019-03-23 00:50:51,373] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8570.4787 1683579848.9606 214.0000
[2019-03-23 00:50:51,519] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8852.6925 1664051680.8275 105.0000
[2019-03-23 00:50:51,568] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8593.6867 1706159149.9219 465.0000
[2019-03-23 00:50:52,584] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 1375000, evaluation results [1375000.0, 8508.45277065677, 1773463374.2284098, 173.0, 9057.05855481395, 1656443078.0244372, 80.0, 8852.692524936243, 1664051680.8275282, 105.0, 8593.686660790749, 1706159149.921858, 465.0, 8570.478727897242, 1683579848.9606183, 214.0]
[2019-03-23 00:50:56,366] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:50:56,370] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7029
[2019-03-23 00:50:56,379] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 90.0, 1.0, 2.0, 0.311503041341496, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 338250.633865177, 338250.6338651773, 111970.0208367677], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3814800.0000, 
sim time next is 3815400.0000, 
raw observation next is [17.0, 89.0, 1.0, 2.0, 0.3071450498556685, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 333516.8153104829, 333516.8153104829, 111672.5656615414], 
processed observation next is [0.0, 0.13043478260869565, 0.4090909090909091, 0.89, 1.0, 1.0, 0.13393131231958558, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12352474641128998, 0.12352474641128998, 0.2723721113696132], 
reward next is 0.7276, 
noisyNet noise sample is [array([-1.6073322], dtype=float32), 1.0019174]. 
=============================================
[2019-03-23 00:51:11,714] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 7.5855266e-36 1.7660536e-32 7.0604459e-33], sum to 1.0000
[2019-03-23 00:51:11,723] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7194
[2019-03-23 00:51:11,728] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 83.0, 1.0, 2.0, 0.5768255530492876, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 648317.0357394965, 648317.0357394968, 141999.6037529846], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4185000.0000, 
sim time next is 4185600.0000, 
raw observation next is [20.33333333333334, 81.33333333333334, 1.0, 2.0, 0.6059659085274011, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 681987.862138409, 681987.862138409, 145750.2662391772], 
processed observation next is [1.0, 0.43478260869565216, 0.5606060606060609, 0.8133333333333335, 1.0, 1.0, 0.5074573856592512, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.25258809708829966, 0.25258809708829966, 0.3554884542418956], 
reward next is 0.6445, 
noisyNet noise sample is [array([0.5100327], dtype=float32), -1.5366718]. 
=============================================
[2019-03-23 00:51:12,420] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.6708611e-38 1.0000000e+00 1.1556477e-30 1.4915929e-31 3.1653315e-34], sum to 1.0000
[2019-03-23 00:51:12,429] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1547
[2019-03-23 00:51:12,434] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.83333333333334, 78.0, 1.0, 2.0, 0.7001595827247264, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 794987.9887246102, 794987.9887246102, 161330.7894974586], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4099800.0000, 
sim time next is 4100400.0000, 
raw observation next is [22.0, 78.0, 1.0, 2.0, 0.7174861325740939, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 815504.7419662599, 815504.7419662599, 164328.8255619029], 
processed observation next is [1.0, 0.4782608695652174, 0.6363636363636364, 0.78, 1.0, 1.0, 0.6468576657176173, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.302038793320837, 0.302038793320837, 0.4008020135656168], 
reward next is 0.5992, 
noisyNet noise sample is [array([-1.4558815], dtype=float32), -1.6914707]. 
=============================================
[2019-03-23 00:51:14,655] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.7654680e-34 1.0000000e+00 2.2492502e-29 1.9937655e-23 6.7254376e-34], sum to 1.0000
[2019-03-23 00:51:14,666] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2083
[2019-03-23 00:51:14,674] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.83333333333333, 94.0, 1.0, 2.0, 0.8767906157847195, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1000428.939203226, 1000428.939203226, 192478.4076886982], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4794600.0000, 
sim time next is 4795200.0000, 
raw observation next is [21.0, 94.0, 1.0, 2.0, 0.8794588539612582, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1003766.285679627, 1003766.285679627, 193641.5198910057], 
processed observation next is [1.0, 0.5217391304347826, 0.5909090909090909, 0.94, 1.0, 1.0, 0.8493235674515728, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3717652909924544, 0.3717652909924544, 0.4722963899780627], 
reward next is 0.5277, 
noisyNet noise sample is [array([-0.7518649], dtype=float32), -0.2705492]. 
=============================================
[2019-03-23 00:51:21,542] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 3.4093712e-38 2.1492696e-32 4.9117761e-32], sum to 1.0000
[2019-03-23 00:51:21,552] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0111
[2019-03-23 00:51:21,556] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.06666666666667, 99.33333333333334, 1.0, 2.0, 0.4915709455537982, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 560865.4797255356, 560865.4797255356, 140494.8442033341], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4821600.0000, 
sim time next is 4822200.0000, 
raw observation next is [21.05, 99.5, 1.0, 2.0, 0.4919122644723248, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 561253.7516029003, 561253.7516029003, 140539.1896962316], 
processed observation next is [1.0, 0.8260869565217391, 0.5931818181818183, 0.995, 1.0, 1.0, 0.36489033059040593, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20787175985292605, 0.20787175985292605, 0.3427785114542234], 
reward next is 0.6572, 
noisyNet noise sample is [array([-0.840177], dtype=float32), 0.6550256]. 
=============================================
[2019-03-23 00:51:21,705] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.7813331e-34 1.0000000e+00 2.5872213e-30 1.7058117e-25 1.2272373e-22], sum to 1.0000
[2019-03-23 00:51:21,711] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0874
[2019-03-23 00:51:21,717] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.33333333333334, 87.0, 1.0, 2.0, 0.6101100186438724, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 684015.6169695109, 684015.6169695113, 145016.9211424236], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4263600.0000, 
sim time next is 4264200.0000, 
raw observation next is [20.0, 83.5, 1.0, 2.0, 0.7130147431139663, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 802161.7650400208, 802161.7650400208, 158796.5534477073], 
processed observation next is [1.0, 0.34782608695652173, 0.5454545454545454, 0.835, 1.0, 1.0, 0.6412684288924577, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2970969500148225, 0.2970969500148225, 0.38730866694562754], 
reward next is 0.6127, 
noisyNet noise sample is [array([-1.8245603], dtype=float32), 1.1435672]. 
=============================================
[2019-03-23 00:51:26,065] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:51:26,067] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.6466123e-31 1.0000000e+00 1.8017063e-29 4.0128960e-26 9.2625450e-15], sum to 1.0000
[2019-03-23 00:51:26,076] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2411
[2019-03-23 00:51:26,081] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.5, 77.5, 1.0, 2.0, 0.2806725808253456, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 304762.3877889157, 304762.3877889159, 95609.21051519265], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4998600.0000, 
sim time next is 4999200.0000, 
raw observation next is [17.33333333333333, 79.0, 1.0, 2.0, 0.2814307607021613, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 305585.9000288247, 305585.9000288244, 95915.65884235923], 
processed observation next is [1.0, 0.8695652173913043, 0.42424242424242403, 0.79, 1.0, 1.0, 0.10178845087770158, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11317996297363878, 0.11317996297363866, 0.23394063132282739], 
reward next is 0.7661, 
noisyNet noise sample is [array([-0.19790766], dtype=float32), -0.61223775]. 
=============================================
[2019-03-23 00:51:26,083] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5404
[2019-03-23 00:51:26,091] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1102133.917602483 W.
[2019-03-23 00:51:26,095] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.0, 69.33333333333333, 1.0, 2.0, 0.9653897398377772, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1102133.917602483, 1102133.917602483, 211131.0553836363], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4354800.0000, 
sim time next is 4355400.0000, 
raw observation next is [25.5, 67.16666666666667, 1.0, 2.0, 0.5527805302271624, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9679406601877079, 6.917490450284019, 6.9112, 77.32844776882897, 1178901.667987926, 1176858.65881176, 265153.4625418028], 
processed observation next is [1.0, 0.391304347826087, 0.7954545454545454, 0.6716666666666667, 1.0, 1.0, 0.440975662783953, 0.0, 1.0, -0.25, 1.0, 0.5, 0.9542009431252969, 0.0006290450284018867, 0.0, 0.5084287098606048, 0.43663024740293555, 0.43587357733768883, 0.6467157622970799], 
reward next is 0.3218, 
noisyNet noise sample is [array([0.04556105], dtype=float32), 0.20137879]. 
=============================================
[2019-03-23 00:51:30,201] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.4340943e-36 1.8629455e-36], sum to 1.0000
[2019-03-23 00:51:30,207] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5950
[2019-03-23 00:51:30,211] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.83333333333333, 77.83333333333334, 1.0, 2.0, 0.2047672280771654, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 222323.3276295763, 222323.327629576, 72914.0135158068], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4690200.0000, 
sim time next is 4690800.0000, 
raw observation next is [15.0, 77.0, 1.0, 2.0, 0.2060795848660417, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 223748.5294962382, 223748.5294962385, 73221.49850784577], 
processed observation next is [1.0, 0.30434782608695654, 0.3181818181818182, 0.77, 1.0, 1.0, 0.007599481082552102, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08286982573934748, 0.08286982573934759, 0.17858902075084335], 
reward next is 0.8214, 
noisyNet noise sample is [array([-0.1697916], dtype=float32), -0.9365232]. 
=============================================
[2019-03-23 00:51:31,428] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.5968870e-35 1.5632578e-33], sum to 1.0000
[2019-03-23 00:51:31,441] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4438
[2019-03-23 00:51:31,446] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 74.0, 1.0, 2.0, 0.4675748699994808, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 533499.3223800963, 533499.3223800963, 136881.439179363], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4443600.0000, 
sim time next is 4444200.0000, 
raw observation next is [24.0, 74.0, 1.0, 2.0, 0.468714417457864, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 534800.426693026, 534800.426693026, 137007.194379862], 
processed observation next is [0.0, 0.43478260869565216, 0.7272727272727273, 0.74, 1.0, 1.0, 0.33589302182233, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19807423210852815, 0.19807423210852815, 0.3341638887313707], 
reward next is 0.6658, 
noisyNet noise sample is [array([-0.6240636], dtype=float32), 0.54219276]. 
=============================================
[2019-03-23 00:51:32,324] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 4.4446956e-36 1.5311398e-33 1.1474107e-31], sum to 1.0000
[2019-03-23 00:51:32,336] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4222
[2019-03-23 00:51:32,342] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.66666666666667, 71.33333333333334, 1.0, 2.0, 0.5234923997765956, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 596190.3507727259, 596190.3507727257, 145801.2488793267], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4454400.0000, 
sim time next is 4455000.0000, 
raw observation next is [25.5, 72.0, 1.0, 2.0, 0.5219589473609744, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 594566.9754447793, 594566.9754447793, 145508.8024479717], 
processed observation next is [0.0, 0.5652173913043478, 0.7954545454545454, 0.72, 1.0, 1.0, 0.40244868420121793, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2202099909054738, 0.2202099909054738, 0.3548995181657847], 
reward next is 0.6451, 
noisyNet noise sample is [array([-0.33163926], dtype=float32), 0.483543]. 
=============================================
[2019-03-23 00:51:32,353] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[66.4179  ]
 [66.376595]
 [66.377716]
 [66.374916]
 [66.41159 ]], R is [[66.45324707]
 [66.43309784]
 [66.41298676]
 [66.39316559]
 [66.3743515 ]].
[2019-03-23 00:51:33,343] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 5.4969736e-36 1.5125693e-32 1.6568546e-30], sum to 1.0000
[2019-03-23 00:51:33,352] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9196
[2019-03-23 00:51:33,358] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 78.83333333333333, 1.0, 2.0, 0.4704535848964257, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 536631.928861673, 536631.928861673, 136685.0097551586], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4477800.0000, 
sim time next is 4478400.0000, 
raw observation next is [23.0, 78.0, 1.0, 2.0, 0.4647633300447079, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 530020.5831621346, 530020.5831621346, 135813.1826593141], 
processed observation next is [0.0, 0.8695652173913043, 0.6818181818181818, 0.78, 1.0, 1.0, 0.33095416255588483, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1963039196896795, 0.1963039196896795, 0.3312516650227173], 
reward next is 0.6687, 
noisyNet noise sample is [array([0.28553095], dtype=float32), 0.40000057]. 
=============================================
[2019-03-23 00:51:41,465] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 2.9099794e-37 1.9150786e-35 1.4331302e-27], sum to 1.0000
[2019-03-23 00:51:41,478] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5022
[2019-03-23 00:51:41,482] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.66666666666667, 61.33333333333334, 1.0, 2.0, 0.5083422190692158, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 552113.0134034031, 552113.0134034035, 119334.3343754683], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4616400.0000, 
sim time next is 4617000.0000, 
raw observation next is [20.0, 60.0, 1.0, 2.0, 0.5191831732900903, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 563894.2575395795, 563894.2575395795, 121656.3393104291], 
processed observation next is [1.0, 0.43478260869565216, 0.5454545454545454, 0.6, 1.0, 1.0, 0.3989789666126129, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2088497250146591, 0.2088497250146591, 0.2967227788059246], 
reward next is 0.7033, 
noisyNet noise sample is [array([-0.45450103], dtype=float32), 1.4059972]. 
=============================================
[2019-03-23 00:51:41,502] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[65.43218 ]
 [65.430664]
 [65.8383  ]
 [65.60409 ]
 [65.59047 ]], R is [[65.38452148]
 [65.43961334]
 [65.49671173]
 [65.56899261]
 [65.63537598]].
[2019-03-23 00:51:45,385] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-23 00:51:45,387] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 00:51:45,388] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:51:45,388] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 00:51:45,389] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:51:45,390] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 00:51:45,390] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 00:51:45,391] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:51:45,392] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 00:51:45,393] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:51:45,394] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:51:45,419] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run57
[2019-03-23 00:51:45,447] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run57
[2019-03-23 00:51:45,447] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run57
[2019-03-23 00:51:45,496] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run57
[2019-03-23 00:51:45,497] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run57
[2019-03-23 00:51:47,318] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.3373713], dtype=float32), -0.016909277]
[2019-03-23 00:51:47,319] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.16338309833333, 70.07259278000001, 1.0, 2.0, 0.2623918364743989, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 284890.8988276575, 284890.8988276571, 88432.11344456412]
[2019-03-23 00:51:47,321] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 00:51:47,325] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.0072996e-33], sampled 0.48109585708716296
[2019-03-23 00:52:08,495] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.3373713], dtype=float32), -0.016909277]
[2019-03-23 00:52:08,496] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.03333333333333, 73.0, 1.0, 2.0, 0.3265288290375627, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 354547.9253212854, 354547.9253212854, 117314.1822084289]
[2019-03-23 00:52:08,497] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 00:52:08,501] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 4.696648e-36], sampled 0.6785357170683455
[2019-03-23 00:52:47,787] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.3373713], dtype=float32), -0.016909277]
[2019-03-23 00:52:47,789] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [14.62325909, 83.76940394, 1.0, 2.0, 0.2408693727725675, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 261517.8852010351, 261517.8852010347, 82632.99293862989]
[2019-03-23 00:52:47,790] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 00:52:47,794] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 3.3069652e-35], sampled 0.41203952723887405
[2019-03-23 00:52:57,453] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.3373713], dtype=float32), -0.016909277]
[2019-03-23 00:52:57,454] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [26.83333333333334, 51.33333333333334, 1.0, 2.0, 0.4236568932866967, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 481867.7479191275, 481867.7479191275, 129954.61301341]
[2019-03-23 00:52:57,455] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 00:52:57,458] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 3.098247e-30], sampled 0.16539352130603158
[2019-03-23 00:53:33,177] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8580.5834 1685402702.7162 163.0000
[2019-03-23 00:53:33,252] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8487.4675 1783281440.0672 142.0000
[2019-03-23 00:53:33,342] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9063.0955 1657380667.6095 52.0000
[2019-03-23 00:53:33,454] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8855.5280 1665031518.9440 82.0000
[2019-03-23 00:53:33,528] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8603.7926 1707454904.2584 410.0000
[2019-03-23 00:53:34,546] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 1400000, evaluation results [1400000.0, 8487.467518938169, 1783281440.0671797, 142.0, 9063.095524767545, 1657380667.6094952, 52.0, 8855.52804265329, 1665031518.9439998, 82.0, 8603.79256652319, 1707454904.2583575, 410.0, 8580.583379647513, 1685402702.7162447, 163.0]
[2019-03-23 00:53:35,074] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 6.0070980e-38 2.5363974e-29], sum to 1.0000
[2019-03-23 00:53:35,085] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6789
[2019-03-23 00:53:35,091] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 68.33333333333333, 1.0, 2.0, 0.4314467564522649, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 491231.1317576753, 491231.1317576756, 131225.800490626], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4733400.0000, 
sim time next is 4734000.0000, 
raw observation next is [24.0, 69.0, 1.0, 2.0, 0.4340096181207134, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 494344.3649972999, 494344.3649972999, 131704.7901134207], 
processed observation next is [1.0, 0.8260869565217391, 0.7272727272727273, 0.69, 1.0, 1.0, 0.29251202265089177, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18309050555455553, 0.18309050555455553, 0.3212311953985871], 
reward next is 0.6788, 
noisyNet noise sample is [array([1.1650983], dtype=float32), 1.0749747]. 
=============================================
[2019-03-23 00:53:35,108] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[76.45416 ]
 [76.305824]
 [75.95727 ]
 [75.79774 ]
 [75.711235]], R is [[76.45348358]
 [76.36888885]
 [76.28652191]
 [76.20657349]
 [76.1287384 ]].
[2019-03-23 00:53:36,766] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.3032117e-37 1.0000000e+00 1.6554395e-30 8.9220104e-32 8.0650401e-17], sum to 1.0000
[2019-03-23 00:53:36,775] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1141
[2019-03-23 00:53:36,778] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.26666666666667, 92.0, 1.0, 2.0, 0.4500318668848615, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 511264.9929042268, 511264.9929042268, 132088.1486056201], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5382600.0000, 
sim time next is 5383200.0000, 
raw observation next is [20.53333333333333, 91.0, 1.0, 2.0, 0.4392374642830219, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 499397.329855609, 499397.329855609, 131333.5953887615], 
processed observation next is [1.0, 0.30434782608695654, 0.5696969696969696, 0.91, 1.0, 1.0, 0.2990468303537773, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18496197402059592, 0.18496197402059592, 0.3203258424116134], 
reward next is 0.6797, 
noisyNet noise sample is [array([0.82113546], dtype=float32), 1.8086262]. 
=============================================
[2019-03-23 00:53:40,772] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.000000e+00 1.326747e-30 9.236895e-37 0.000000e+00 1.000000e+00], sum to 1.0000
[2019-03-23 00:53:40,781] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5323
[2019-03-23 00:53:40,790] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [21.16666666666667, 99.00000000000001, 1.0, 2.0, 0.247397984694377, 1.0, 2.0, 0.247397984694377, 1.0, 2.0, 0.5010950860682977, 6.911199999999999, 6.9112, 77.3421103, 844397.9929153918, 844397.9929153922, 241405.0450217538], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4799400.0000, 
sim time next is 4800000.0000, 
raw observation next is [21.33333333333334, 98.0, 1.0, 2.0, 0.2959666913333309, 1.0, 2.0, 0.2959666913333309, 1.0, 2.0, 0.5995344555403335, 6.911199999999999, 6.9112, 77.3421103, 1009365.217166728, 1009365.217166729, 258090.3619522064], 
processed observation next is [1.0, 0.5652173913043478, 0.6060606060606063, 0.98, 1.0, 1.0, 0.11995836416666364, 1.0, 1.0, 0.11995836416666364, 1.0, 1.0, 0.42790636505761925, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.37383896932101035, 0.37383896932101074, 0.6294886876883083], 
reward next is 0.3705, 
noisyNet noise sample is [array([0.6794581], dtype=float32), -0.10754696]. 
=============================================
[2019-03-23 00:53:40,807] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[67.0955 ]
 [66.48149]
 [65.67988]
 [64.43373]
 [62.90563]], R is [[66.4019165 ]
 [66.14910889]
 [65.91053009]
 [65.68470764]
 [65.46237183]].
[2019-03-23 00:53:43,823] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 6.883801e-33 3.713366e-31 9.964454e-27], sum to 1.0000
[2019-03-23 00:53:43,833] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8821
[2019-03-23 00:53:43,838] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.16666666666667, 99.0, 1.0, 2.0, 0.4087508347992019, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 463591.7428906097, 463591.7428906097, 127441.2571386724], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4855800.0000, 
sim time next is 4856400.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4063285830700405, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 460656.1243476302, 460656.1243476305, 127080.6610765992], 
processed observation next is [1.0, 0.21739130434782608, 0.5, 1.0, 1.0, 1.0, 0.25791072883755056, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1706133793880112, 0.1706133793880113, 0.30995283189414435], 
reward next is 0.6900, 
noisyNet noise sample is [array([0.89180267], dtype=float32), 1.8594924]. 
=============================================
[2019-03-23 00:53:45,970] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.2071806e-33 1.0000000e+00 4.3569645e-29 1.2271699e-25 5.8002885e-23], sum to 1.0000
[2019-03-23 00:53:45,977] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3753
[2019-03-23 00:53:45,985] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 78.0, 1.0, 2.0, 0.7669294911477149, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 872210.3215580628, 872210.3215580632, 171741.129825453], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4899600.0000, 
sim time next is 4900200.0000, 
raw observation next is [22.16666666666667, 77.16666666666667, 1.0, 2.0, 0.5211087563940965, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 592324.9008306755, 592324.9008306755, 139869.4234426359], 
processed observation next is [1.0, 0.7391304347826086, 0.6439393939393941, 0.7716666666666667, 1.0, 1.0, 0.4013859454926206, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2193795929002502, 0.2193795929002502, 0.3411449352259412], 
reward next is 0.6589, 
noisyNet noise sample is [array([-0.3547182], dtype=float32), -0.20612842]. 
=============================================
[2019-03-23 00:53:46,257] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:53:46,269] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6912
[2019-03-23 00:53:46,275] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 60.66666666666666, 1.0, 2.0, 0.2837466399189732, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 308101.3472024469, 308101.3472024472, 97916.76415726473], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4989000.0000, 
sim time next is 4989600.0000, 
raw observation next is [20.0, 60.0, 1.0, 2.0, 0.2836856710722366, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 308035.124275846, 308035.124275846, 96680.81225661082], 
processed observation next is [1.0, 0.782608695652174, 0.5454545454545454, 0.6, 1.0, 1.0, 0.10460708884029571, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11408708306512814, 0.11408708306512814, 0.2358068591624654], 
reward next is 0.7642, 
noisyNet noise sample is [array([-2.9298968], dtype=float32), -2.1647801]. 
=============================================
[2019-03-23 00:53:56,056] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:53:56,065] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7363
[2019-03-23 00:53:56,071] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.3, 46.0, 1.0, 2.0, 0.438267658883004, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 499171.5162843823, 499171.5162843823, 132107.9648685025], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5338800.0000, 
sim time next is 5339400.0000, 
raw observation next is [27.93333333333334, 47.33333333333334, 1.0, 2.0, 0.4324641424020196, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 492333.4743460142, 492333.4743460142, 131267.3257015572], 
processed observation next is [1.0, 0.8260869565217391, 0.9060606060606063, 0.47333333333333344, 1.0, 1.0, 0.29058017800252445, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1823457312392645, 0.1823457312392645, 0.32016420902818826], 
reward next is 0.6798, 
noisyNet noise sample is [array([-1.7793978], dtype=float32), -1.5691097]. 
=============================================
[2019-03-23 00:53:56,866] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:53:56,876] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5768
[2019-03-23 00:53:56,882] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.66666666666666, 70.33333333333334, 1.0, 2.0, 0.4307777053872642, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 490513.4912942767, 490513.4912942767, 131206.8318174518], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5088000.0000, 
sim time next is 5088600.0000, 
raw observation next is [23.5, 71.0, 1.0, 2.0, 0.4298905737969773, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 489385.7386165621, 489385.7386165624, 130990.6779060541], 
processed observation next is [0.0, 0.9130434782608695, 0.7045454545454546, 0.71, 1.0, 1.0, 0.2873632172462216, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18125397726539336, 0.18125397726539347, 0.319489458307449], 
reward next is 0.6805, 
noisyNet noise sample is [array([-1.7870718], dtype=float32), -0.51946545]. 
=============================================
[2019-03-23 00:54:01,144] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:54:01,154] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4721
[2019-03-23 00:54:01,160] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [9.9, 86.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 146734.0108160893, 146734.0108160891, 57422.32817367178], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5713800.0000, 
sim time next is 5714400.0000, 
raw observation next is [9.8, 86.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 145341.8156034347, 145341.8156034347, 57243.81285751551], 
processed observation next is [0.0, 0.13043478260869565, 0.08181818181818185, 0.86, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.053830302075346184, 0.053830302075346184, 0.13961905575003783], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.8670352], dtype=float32), -0.49137616]. 
=============================================
[2019-03-23 00:54:05,689] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.8728369e-38 1.0000000e+00 1.4791499e-31 2.4487819e-32 0.0000000e+00], sum to 1.0000
[2019-03-23 00:54:05,700] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6092
[2019-03-23 00:54:05,706] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.8661566307627081, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 987919.0507866258, 987919.0507866258, 195386.9540236899], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5239200.0000, 
sim time next is 5239800.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.8414574572897098, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 959748.6044519333, 959748.6044519333, 191137.9240700306], 
processed observation next is [1.0, 0.6521739130434783, 0.6363636363636364, 0.94, 1.0, 1.0, 0.8018218216121372, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3554624460933086, 0.3554624460933086, 0.4661900587073917], 
reward next is 0.5338, 
noisyNet noise sample is [array([-0.7944962], dtype=float32), 0.24399789]. 
=============================================
[2019-03-23 00:54:11,630] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:54:11,641] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4909
[2019-03-23 00:54:11,646] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.8, 73.16666666666667, 1.0, 2.0, 0.4542541373852049, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 518036.5411738124, 518036.5411738124, 134704.3665189638], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5356200.0000, 
sim time next is 5356800.0000, 
raw observation next is [23.8, 74.0, 1.0, 2.0, 0.4584147193921645, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 522902.7746323407, 522902.7746323407, 135410.8662569273], 
processed observation next is [1.0, 0.0, 0.7181818181818183, 0.74, 1.0, 1.0, 0.3230183992402056, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19366769430827432, 0.19366769430827432, 0.3302704055047007], 
reward next is 0.6697, 
noisyNet noise sample is [array([0.09670395], dtype=float32), -0.58023375]. 
=============================================
[2019-03-23 00:54:15,660] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 6.554445e-35 0.000000e+00], sum to 1.0000
[2019-03-23 00:54:15,666] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7815
[2019-03-23 00:54:15,670] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.36666666666667, 99.0, 1.0, 2.0, 0.3683238647294709, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 409461.6779581204, 409461.6779581201, 119454.2633971171], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5456400.0000, 
sim time next is 5457000.0000, 
raw observation next is [17.28333333333333, 99.5, 1.0, 2.0, 0.3641017246293272, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 404576.3059040025, 404576.3059040028, 119034.4910518757], 
processed observation next is [1.0, 0.13043478260869565, 0.4219696969696969, 0.995, 1.0, 1.0, 0.205127155786659, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14984307626074167, 0.14984307626074178, 0.2903280269557944], 
reward next is 0.7097, 
noisyNet noise sample is [array([-1.9710473], dtype=float32), 1.0410963]. 
=============================================
[2019-03-23 00:54:15,691] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[69.18536 ]
 [69.1265  ]
 [68.99479 ]
 [68.82137 ]
 [69.677635]], R is [[69.34250641]
 [69.35772705]
 [69.37306213]
 [69.38770294]
 [69.39048004]].
[2019-03-23 00:54:15,944] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 5.1771387e-38 0.0000000e+00], sum to 1.0000
[2019-03-23 00:54:15,950] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3329
[2019-03-23 00:54:15,955] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.66666666666667, 85.16666666666667, 1.0, 2.0, 0.3910645253475382, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 432630.9102721353, 432630.9102721353, 120505.2810183304], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5987400.0000, 
sim time next is 5988000.0000, 
raw observation next is [19.03333333333333, 83.33333333333334, 1.0, 2.0, 0.3768398576090046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 417830.7047177925, 417830.7047177928, 119709.6123729295], 
processed observation next is [1.0, 0.30434782608695654, 0.5015151515151515, 0.8333333333333335, 1.0, 1.0, 0.22104982201125575, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15475211285844168, 0.1547521128584418, 0.2919746643242183], 
reward next is 0.7080, 
noisyNet noise sample is [array([-0.66542596], dtype=float32), 1.1366946]. 
=============================================
[2019-03-23 00:54:15,975] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[69.38558 ]
 [70.04274 ]
 [70.121506]
 [70.07101 ]
 [70.062805]], R is [[69.32675934]
 [69.33957672]
 [69.36194611]
 [69.38625336]
 [69.40991974]].
[2019-03-23 00:54:20,839] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.8786333e-34 1.1413442e-36], sum to 1.0000
[2019-03-23 00:54:20,849] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7556
[2019-03-23 00:54:20,856] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.78333333333333, 61.0, 1.0, 2.0, 0.213809530154092, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 232143.2311165889, 232143.2311165886, 73442.35144947366], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5781000.0000, 
sim time next is 5781600.0000, 
raw observation next is [16.6, 62.0, 1.0, 2.0, 0.2115781006698395, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 229719.8892953692, 229719.889295369, 73124.65390377633], 
processed observation next is [0.0, 0.9565217391304348, 0.390909090909091, 0.62, 1.0, 1.0, 0.014472625837299372, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08508144047976637, 0.0850814404797663, 0.17835281439945447], 
reward next is 0.8216, 
noisyNet noise sample is [array([1.2991796], dtype=float32), -0.46514067]. 
=============================================
[2019-03-23 00:54:23,430] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 5.0420916e-37 8.4856486e-26], sum to 1.0000
[2019-03-23 00:54:23,439] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4141
[2019-03-23 00:54:23,450] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1291219.373400571 W.
[2019-03-23 00:54:23,460] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.33333333333333, 70.0, 1.0, 2.0, 0.379636606507268, 1.0, 2.0, 0.379636606507268, 1.0, 1.0, 0.7688316310045489, 6.911200000000001, 6.9112, 77.3421103, 1291219.373400571, 1291219.373400571, 293552.3667144546], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5564400.0000, 
sim time next is 5565000.0000, 
raw observation next is [25.71666666666667, 68.5, 1.0, 2.0, 0.6734200213321474, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9754845011563645, 6.911200000000001, 6.9112, 77.32846344354104, 1314809.584683689, 1314809.584683688, 286425.8735785584], 
processed observation next is [1.0, 0.391304347826087, 0.8053030303030304, 0.685, 1.0, 1.0, 0.5917750266651842, 0.0, 0.5, -0.25, 1.0, 1.0, 0.9649778587948067, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.4869665128458108, 0.48696651284581033, 0.6985996916550204], 
reward next is 0.3014, 
noisyNet noise sample is [array([0.49638098], dtype=float32), -0.44504115]. 
=============================================
[2019-03-23 00:54:23,475] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[51.255116]
 [51.262836]
 [51.694656]
 [51.982918]
 [51.9081  ]], R is [[51.53318405]
 [51.01785278]
 [50.91078568]
 [50.719841  ]
 [50.55957413]].
[2019-03-23 00:54:27,276] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-23 00:54:27,277] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 00:54:27,278] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 00:54:27,279] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:54:27,280] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 00:54:27,280] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:54:27,282] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 00:54:27,282] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:54:27,282] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:54:27,283] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 00:54:27,286] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:54:27,312] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run58
[2019-03-23 00:54:27,338] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run58
[2019-03-23 00:54:27,360] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run58
[2019-03-23 00:54:27,362] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run58
[2019-03-23 00:54:27,384] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run58
[2019-03-23 00:54:46,999] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.38813433], dtype=float32), 0.019956771]
[2019-03-23 00:54:47,001] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.03333333333333, 81.0, 1.0, 2.0, 0.4012249407473574, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 453571.0589825254, 453571.0589825251, 130100.4637447362]
[2019-03-23 00:54:47,002] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 00:54:47,006] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 2.932604e-35 0.000000e+00], sampled 0.8284030122946012
[2019-03-23 00:55:04,717] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.38813433], dtype=float32), 0.019956771]
[2019-03-23 00:55:04,718] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [16.7, 99.66666666666666, 1.0, 2.0, 0.329066468494219, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 361942.5240247414, 361942.5240247414, 114821.4729871996]
[2019-03-23 00:55:04,718] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 00:55:04,722] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 5.031606e-35 0.000000e+00], sampled 0.22933897715883989
[2019-03-23 00:55:51,082] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.38813433], dtype=float32), 0.019956771]
[2019-03-23 00:55:51,084] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.45, 68.5, 1.0, 2.0, 0.6931875519677987, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 782860.1027157068, 782860.1027157065, 157781.0427956097]
[2019-03-23 00:55:51,086] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 00:55:51,090] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.6557497e-29 0.0000000e+00], sampled 0.48831434686567965
[2019-03-23 00:56:14,622] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9057.0586 1656443078.0244 80.0000
[2019-03-23 00:56:15,129] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8592.8737 1706200825.6989 465.0000
[2019-03-23 00:56:15,287] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8852.6925 1664051680.8275 105.0000
[2019-03-23 00:56:15,287] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8507.7271 1773514361.6667 173.0000
[2019-03-23 00:56:15,288] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8571.2008 1683531899.0519 214.0000
[2019-03-23 00:56:16,309] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 1425000, evaluation results [1425000.0, 8507.727149272585, 1773514361.6667252, 173.0, 9057.05855481395, 1656443078.0244372, 80.0, 8852.692524936243, 1664051680.8275282, 105.0, 8592.873732714792, 1706200825.698916, 465.0, 8571.200785595147, 1683531899.0518706, 214.0]
[2019-03-23 00:56:17,448] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 7.592996e-36 0.000000e+00], sum to 1.0000
[2019-03-23 00:56:17,457] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4958
[2019-03-23 00:56:17,465] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 99.0, 1.0, 2.0, 0.3444215965631068, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 380823.3200114635, 380823.3200114632, 116715.8507654641], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5642400.0000, 
sim time next is 5643000.0000, 
raw observation next is [16.9, 98.5, 1.0, 2.0, 0.3393341678572305, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 374222.0297068986, 374222.0297068986, 115950.2085303772], 
processed observation next is [0.0, 0.30434782608695654, 0.4045454545454545, 0.985, 1.0, 1.0, 0.17416770982153806, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13860075174329578, 0.13860075174329578, 0.2828053866594566], 
reward next is 0.7172, 
noisyNet noise sample is [array([-0.36934698], dtype=float32), 1.4177384]. 
=============================================
[2019-03-23 00:56:17,478] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[74.229645]
 [74.18083 ]
 [74.16983 ]
 [74.12279 ]
 [74.117836]], R is [[74.26617432]
 [74.2388382 ]
 [74.21017456]
 [74.18045807]
 [74.15021515]].
[2019-03-23 00:56:17,642] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 8.596483e-35 0.000000e+00], sum to 1.0000
[2019-03-23 00:56:17,651] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0495
[2019-03-23 00:56:17,656] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.5, 87.0, 1.0, 2.0, 0.2442024177183899, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 265151.2372891362, 265151.2372891362, 83776.42692844664], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5666400.0000, 
sim time next is 5667000.0000, 
raw observation next is [15.5, 86.0, 1.0, 2.0, 0.2410237734496106, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 261698.9855944676, 261698.9855944673, 82758.16179115641], 
processed observation next is [0.0, 0.6086956521739131, 0.3409090909090909, 0.86, 1.0, 1.0, 0.05127971681201323, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09692555022017318, 0.09692555022017307, 0.2018491751003815], 
reward next is 0.7982, 
noisyNet noise sample is [array([1.1262375], dtype=float32), -0.18216419]. 
=============================================
[2019-03-23 00:56:17,667] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[80.9988  ]
 [80.867874]
 [80.76161 ]
 [80.65557 ]
 [80.55487 ]], R is [[81.07105255]
 [81.05601501]
 [81.0390625 ]
 [81.02017975]
 [80.99931335]].
[2019-03-23 00:56:18,693] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 8.553754e-37 0.000000e+00], sum to 1.0000
[2019-03-23 00:56:18,704] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5139
[2019-03-23 00:56:18,709] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.1, 86.0, 1.0, 2.0, 0.2593052626894195, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 281554.4211697633, 281554.4211697636, 89102.36004966627], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5662800.0000, 
sim time next is 5663400.0000, 
raw observation next is [16.0, 86.16666666666667, 1.0, 2.0, 0.2580225987444885, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 280161.2997240655, 280161.2997240658, 88279.91058368003], 
processed observation next is [0.0, 0.5652173913043478, 0.36363636363636365, 0.8616666666666667, 1.0, 1.0, 0.07252824843061063, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10376344434224649, 0.1037634443422466, 0.2153168550821464], 
reward next is 0.7847, 
noisyNet noise sample is [array([-0.6629125], dtype=float32), -0.3254081]. 
=============================================
[2019-03-23 00:56:24,294] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.3117062e-36 1.0000000e+00 2.2090378e-37 6.2322778e-16 9.4768409e-24], sum to 1.0000
[2019-03-23 00:56:24,300] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9478
[2019-03-23 00:56:24,304] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.28333333333333, 82.5, 1.0, 2.0, 0.3840965503795006, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 417111.2833867737, 417111.283386774, 86730.03445008938], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5802600.0000, 
sim time next is 5803200.0000, 
raw observation next is [12.2, 83.0, 1.0, 2.0, 0.3812226539453882, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 413989.0346568893, 413989.0346568896, 86404.76461195367], 
processed observation next is [1.0, 0.17391304347826086, 0.1909090909090909, 0.83, 1.0, 1.0, 0.2265283174317352, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1533292720951442, 0.1533292720951443, 0.2107433283218382], 
reward next is 0.7893, 
noisyNet noise sample is [array([0.2389879], dtype=float32), 0.16066515]. 
=============================================
[2019-03-23 00:56:25,347] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.00000000e+00 1.00000000e+00 8.38921333e-35 3.37050099e-22
 1.16735514e-35], sum to 1.0000
[2019-03-23 00:56:25,355] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9943
[2019-03-23 00:56:25,358] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.8, 79.0, 1.0, 2.0, 0.2380766579582266, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 258498.2138179602, 258498.2138179599, 80062.18840564314], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6057000.0000, 
sim time next is 6057600.0000, 
raw observation next is [15.7, 78.66666666666667, 1.0, 2.0, 0.2298197421826508, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 249530.7429284993, 249530.7429284996, 78544.80288705972], 
processed observation next is [1.0, 0.08695652173913043, 0.35, 0.7866666666666667, 1.0, 1.0, 0.03727467772831349, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09241879367722196, 0.09241879367722207, 0.19157268996843835], 
reward next is 0.8084, 
noisyNet noise sample is [array([1.2791317], dtype=float32), -0.53950334]. 
=============================================
[2019-03-23 00:56:28,527] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 2.051283e-27 0.000000e+00], sum to 1.0000
[2019-03-23 00:56:28,540] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0243
[2019-03-23 00:56:28,543] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.1, 40.0, 1.0, 2.0, 0.6536154876647402, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 724592.7691808047, 724592.7691808047, 146849.2125700663], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5847000.0000, 
sim time next is 5847600.0000, 
raw observation next is [26.1, 40.0, 1.0, 2.0, 0.6389061119094334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 708270.3975684975, 708270.3975684978, 145164.0292695678], 
processed observation next is [1.0, 0.6956521739130435, 0.8227272727272728, 0.4, 1.0, 1.0, 0.5486326398867917, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.26232236946981385, 0.262322369469814, 0.35405860797455563], 
reward next is 0.6459, 
noisyNet noise sample is [array([0.7834496], dtype=float32), 0.86917156]. 
=============================================
[2019-03-23 00:56:33,006] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.7746402e-33 1.0000000e+00 9.5662355e-30 8.8425729e-13 6.4013936e-19], sum to 1.0000
[2019-03-23 00:56:33,016] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0857
[2019-03-23 00:56:33,023] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.7, 46.0, 1.0, 2.0, 0.4565105867396351, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9148540629539316, 6.911200000000001, 6.9112, 77.32846344354104, 1040883.782981357, 1040883.782981357, 238676.4036956957], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5926200.0000, 
sim time next is 5926800.0000, 
raw observation next is [27.7, 46.0, 1.0, 2.0, 0.8590348407315404, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 977581.6110205272, 977581.6110205272, 186269.5735984789], 
processed observation next is [1.0, 0.6086956521739131, 0.8954545454545454, 0.46, 1.0, 1.0, 0.8237935509144253, 0.0, 1.0, -0.25, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.362067263340936, 0.362067263340936, 0.4543160331670217], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.3257732], dtype=float32), 0.5801205]. 
=============================================
[2019-03-23 00:56:37,455] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.3355774e-36 1.0000000e+00 4.3887172e-25 2.6252888e-15 5.5174105e-30], sum to 1.0000
[2019-03-23 00:56:37,467] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9652
[2019-03-23 00:56:37,471] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.7, 61.0, 1.0, 2.0, 0.840471720331793, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 955803.2024265308, 955803.2024265308, 182764.583365479], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5999400.0000, 
sim time next is 6000000.0000, 
raw observation next is [25.16666666666666, 59.33333333333333, 1.0, 2.0, 0.904327851241048, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1029384.888686238, 1029384.888686238, 193851.409877443], 
processed observation next is [1.0, 0.43478260869565216, 0.78030303030303, 0.5933333333333333, 1.0, 1.0, 0.88040981405131, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3812536624763844, 0.3812536624763844, 0.47280831677425117], 
reward next is 0.5272, 
noisyNet noise sample is [array([0.4703627], dtype=float32), -0.7399843]. 
=============================================
[2019-03-23 00:56:37,482] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[53.234943]
 [53.655437]
 [53.82021 ]
 [54.026237]
 [54.761295]], R is [[52.45664597]
 [52.48631287]
 [52.53188324]
 [52.58145142]
 [52.63450623]].
[2019-03-23 00:56:43,342] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 4.9125258e-32 6.0150289e-24 0.0000000e+00], sum to 1.0000
[2019-03-23 00:56:43,351] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2444
[2019-03-23 00:56:43,358] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 47.0, 1.0, 2.0, 0.7887595336647338, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 869341.4077063374, 869341.4077063374, 161671.9660799584], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6108600.0000, 
sim time next is 6109200.0000, 
raw observation next is [23.8, 48.0, 1.0, 2.0, 0.7694260557865182, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 848043.0778443447, 848043.0778443447, 159207.9247897657], 
processed observation next is [1.0, 0.7391304347826086, 0.7181818181818183, 0.48, 1.0, 1.0, 0.7117825697331478, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.31409002883123877, 0.31409002883123877, 0.38831201168235535], 
reward next is 0.6117, 
noisyNet noise sample is [array([-1.5553689], dtype=float32), 1.5834843]. 
=============================================
[2019-03-23 00:56:43,664] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:56:43,675] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2448
[2019-03-23 00:56:43,681] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 53.0, 1.0, 2.0, 0.304383310837286, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 330516.931649766, 330516.9316497657, 111485.23280354], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6114000.0000, 
sim time next is 6114600.0000, 
raw observation next is [21.9, 53.0, 1.0, 2.0, 0.3010754556572415, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 326923.864609684, 326923.8646096843, 109156.0267469962], 
processed observation next is [1.0, 0.782608695652174, 0.6318181818181817, 0.53, 1.0, 1.0, 0.12634431957155182, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12108291281840147, 0.12108291281840158, 0.2662342115780395], 
reward next is 0.7338, 
noisyNet noise sample is [array([0.97611684], dtype=float32), -1.0594127]. 
=============================================
[2019-03-23 00:56:46,457] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0537625e-32 1.0000000e+00 4.2581410e-24 1.9750096e-21 7.3867279e-27], sum to 1.0000
[2019-03-23 00:56:46,465] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0117
[2019-03-23 00:56:46,474] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 93.0, 1.0, 2.0, 0.8244619928848733, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 939449.1948725126, 939449.1948725128, 182123.8049433008], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6436800.0000, 
sim time next is 6437400.0000, 
raw observation next is [20.21666666666667, 94.16666666666666, 1.0, 2.0, 0.88554086304133, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1008823.176343749, 1008823.176343749, 191625.5917649738], 
processed observation next is [1.0, 0.5217391304347826, 0.5553030303030304, 0.9416666666666665, 1.0, 1.0, 0.8569260788016625, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3736382134606478, 0.3736382134606478, 0.4673794921096922], 
reward next is 0.5326, 
noisyNet noise sample is [array([0.5239243], dtype=float32), 0.6240287]. 
=============================================
[2019-03-23 00:56:46,714] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 2.2477510e-35 1.6087305e-29 3.6376035e-29], sum to 1.0000
[2019-03-23 00:56:46,722] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4301
[2019-03-23 00:56:46,728] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 71.0, 1.0, 2.0, 0.5157822072426558, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 581420.6369544042, 581420.6369544044, 136255.254994485], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6180000.0000, 
sim time next is 6180600.0000, 
raw observation next is [22.1, 71.0, 1.0, 2.0, 0.544931383303631, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 614933.6931533808, 614933.6931533808, 139722.9767576271], 
processed observation next is [1.0, 0.5217391304347826, 0.640909090909091, 0.71, 1.0, 1.0, 0.4311642291295387, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22775321968643733, 0.22775321968643733, 0.3407877481893344], 
reward next is 0.6592, 
noisyNet noise sample is [array([-0.18086872], dtype=float32), 0.8898042]. 
=============================================
[2019-03-23 00:56:47,343] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.6306502e-31 2.5129751e-29], sum to 1.0000
[2019-03-23 00:56:47,354] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6889
[2019-03-23 00:56:47,361] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.25, 78.5, 1.0, 2.0, 0.3622187220468097, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 404976.669272196, 404976.669272196, 119956.0473436402], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6211800.0000, 
sim time next is 6212400.0000, 
raw observation next is [20.16666666666666, 79.33333333333334, 1.0, 2.0, 0.3634318651821046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 406476.7195270731, 406476.7195270734, 120121.081355492], 
processed observation next is [1.0, 0.9130434782608695, 0.5530303030303028, 0.7933333333333334, 1.0, 1.0, 0.2042898314776307, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15054693315817522, 0.15054693315817533, 0.29297824720851706], 
reward next is 0.7070, 
noisyNet noise sample is [array([1.2421303], dtype=float32), -0.075816356]. 
=============================================
[2019-03-23 00:56:56,776] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 5.7000341e-35 7.1098073e-38 2.1975589e-35], sum to 1.0000
[2019-03-23 00:56:56,785] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4589
[2019-03-23 00:56:56,790] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.1, 71.0, 1.0, 2.0, 0.5294534198319703, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 602065.8190468749, 602065.8190468745, 147160.6283897794], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6346800.0000, 
sim time next is 6347400.0000, 
raw observation next is [26.28333333333334, 70.33333333333334, 1.0, 2.0, 0.5312980386938576, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 603963.1632341399, 603963.1632341399, 147503.8558848934], 
processed observation next is [0.0, 0.4782608695652174, 0.8310606060606063, 0.7033333333333335, 1.0, 1.0, 0.414122548367322, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22369006045708886, 0.22369006045708886, 0.3597655021582766], 
reward next is 0.6402, 
noisyNet noise sample is [array([1.0236105], dtype=float32), -0.12258584]. 
=============================================
[2019-03-23 00:57:04,197] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.0907116e-37 0.0000000e+00], sum to 1.0000
[2019-03-23 00:57:04,203] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8316
[2019-03-23 00:57:04,210] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.5, 75.0, 1.0, 2.0, 0.22006587242528, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 238937.7095639153, 238937.7095639156, 75342.88319929664], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6472800.0000, 
sim time next is 6473400.0000, 
raw observation next is [15.5, 75.0, 1.0, 2.0, 0.2192101063668565, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 238008.3296091833, 238008.329609183, 75249.50223918281], 
processed observation next is [1.0, 0.9565217391304348, 0.3409090909090909, 0.75, 1.0, 1.0, 0.024012632958570618, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0881512331885864, 0.0881512331885863, 0.18353537131508002], 
reward next is 0.8165, 
noisyNet noise sample is [array([-2.1724432], dtype=float32), 0.8159551]. 
=============================================
[2019-03-23 00:57:08,238] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 5.3022623e-36 2.1791574e-30], sum to 1.0000
[2019-03-23 00:57:08,247] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5887
[2019-03-23 00:57:08,255] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.65, 51.0, 1.0, 2.0, 0.5238294256168187, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 568943.5898739728, 568943.589873973, 123222.6516170113], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7209000.0000, 
sim time next is 7209600.0000, 
raw observation next is [21.83333333333334, 50.33333333333333, 1.0, 2.0, 0.5571605711352562, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 605167.8766406353, 605167.8766406353, 127380.2709033616], 
processed observation next is [1.0, 0.43478260869565216, 0.628787878787879, 0.5033333333333333, 1.0, 1.0, 0.4464507139190702, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2241362506076427, 0.2241362506076427, 0.31068358756917464], 
reward next is 0.6893, 
noisyNet noise sample is [array([-0.9951869], dtype=float32), -0.87722486]. 
=============================================
[2019-03-23 00:57:09,054] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-23 00:57:09,056] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 00:57:09,056] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 00:57:09,057] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 00:57:09,059] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:57:09,060] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 00:57:09,061] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:57:09,062] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 00:57:09,061] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:57:09,062] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:57:09,065] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:57:09,082] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run59
[2019-03-23 00:57:09,103] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run59
[2019-03-23 00:57:09,127] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run59
[2019-03-23 00:57:09,128] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run59
[2019-03-23 00:57:09,128] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run59
[2019-03-23 00:57:11,392] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.47045857], dtype=float32), 0.011315507]
[2019-03-23 00:57:11,394] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [16.75, 49.0, 1.0, 2.0, 0.2418536667274399, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 262586.7911349991, 262586.7911349988, 77892.12522787979]
[2019-03-23 00:57:11,395] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 00:57:11,401] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.7844478433427248
[2019-03-23 00:57:17,826] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.47045857], dtype=float32), 0.011315507]
[2019-03-23 00:57:17,828] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [17.43333333333333, 61.33333333333333, 1.0, 2.0, 0.367363048372543, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 398900.8019134466, 398900.8019134469, 95061.77753118028]
[2019-03-23 00:57:17,829] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 00:57:17,832] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.5142277231112663
[2019-03-23 00:57:28,361] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.47045857], dtype=float32), 0.011315507]
[2019-03-23 00:57:28,363] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.10553444666667, 87.331278845, 1.0, 2.0, 0.3718652540785208, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 419547.1964680283, 419547.1964680283, 126972.069610268]
[2019-03-23 00:57:28,368] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 00:57:28,371] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.9104099736138196
[2019-03-23 00:58:09,042] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.47045857], dtype=float32), 0.011315507]
[2019-03-23 00:58:09,043] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [26.1759674, 63.436106715, 1.0, 2.0, 0.8246981857930591, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 941218.7575318847, 941218.7575318844, 190847.6378708182]
[2019-03-23 00:58:09,044] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 00:58:09,048] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.6321509e-35 2.3359666e-32], sampled 0.915465047870577
[2019-03-23 00:58:42,209] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.47045857], dtype=float32), 0.011315507]
[2019-03-23 00:58:42,213] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.33424795333333, 72.11718196666666, 1.0, 2.0, 0.4625304546356941, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 527696.7760278054, 527696.7760278054, 140700.1254571148]
[2019-03-23 00:58:42,214] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 00:58:42,217] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.48653797690377987
[2019-03-23 00:58:55,653] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.47045857], dtype=float32), 0.011315507]
[2019-03-23 00:58:55,654] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.0, 69.33333333333334, 1.0, 2.0, 0.3045362048739703, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 330683.0092490705, 330683.0092490703, 103926.8283724616]
[2019-03-23 00:58:55,658] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 00:58:55,661] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.3356306530977068
[2019-03-23 00:58:56,769] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8507.7271 1773514361.6667 173.0000
[2019-03-23 00:58:56,991] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8592.8737 1706200825.6989 465.0000
[2019-03-23 00:58:57,034] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8851.9735 1664101423.8647 105.0000
[2019-03-23 00:58:57,074] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8569.7595 1683629455.5724 214.0000
[2019-03-23 00:58:57,147] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9057.0586 1656443078.0244 80.0000
[2019-03-23 00:58:58,162] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 1450000, evaluation results [1450000.0, 8507.727149272585, 1773514361.6667252, 173.0, 9057.05855481395, 1656443078.0244372, 80.0, 8851.973532677643, 1664101423.8646872, 105.0, 8592.873732714792, 1706200825.698916, 465.0, 8569.759499047412, 1683629455.5724304, 214.0]
[2019-03-23 00:59:00,049] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:59:00,059] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8632
[2019-03-23 00:59:00,066] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.41666666666667, 72.16666666666667, 1.0, 2.0, 0.3747594821348117, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 420463.5844136307, 420463.5844136307, 121677.0877256456], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6631800.0000, 
sim time next is 6632400.0000, 
raw observation next is [21.23333333333333, 73.33333333333334, 1.0, 2.0, 0.3756131561614237, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 421365.3922439634, 421365.3922439631, 121722.7603426614], 
processed observation next is [1.0, 0.782608695652174, 0.6015151515151514, 0.7333333333333334, 1.0, 1.0, 0.21951644520177963, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1560612563866531, 0.156061256386653, 0.2968847813235644], 
reward next is 0.7031, 
noisyNet noise sample is [array([0.8412743], dtype=float32), -0.75499964]. 
=============================================
[2019-03-23 00:59:01,118] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0.00000000e+00 1.00000000e+00 0.00000000e+00 1.13817645e-33
 1.21379092e-30], sum to 1.0000
[2019-03-23 00:59:01,125] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6413
[2019-03-23 00:59:01,130] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.06666666666667, 58.66666666666667, 1.0, 2.0, 0.5888705095500675, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 658131.8823766798, 658131.8823766798, 141720.9014785327], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6610800.0000, 
sim time next is 6611400.0000, 
raw observation next is [23.25, 58.5, 1.0, 2.0, 0.5267001369859715, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 589270.3343040985, 589270.3343040985, 135347.6553104443], 
processed observation next is [1.0, 0.5217391304347826, 0.6931818181818182, 0.585, 1.0, 1.0, 0.40837517123246436, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21824827196448093, 0.21824827196448093, 0.3301162324644983], 
reward next is 0.6699, 
noisyNet noise sample is [array([0.01686542], dtype=float32), 2.1232405]. 
=============================================
[2019-03-23 00:59:03,691] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:59:03,700] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9435
[2019-03-23 00:59:03,710] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.16666666666666, 46.33333333333333, 1.0, 2.0, 0.3402418897782522, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 378399.2277415961, 378399.2277415964, 117293.1405297197], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7321200.0000, 
sim time next is 7321800.0000, 
raw observation next is [25.08333333333334, 46.16666666666666, 1.0, 2.0, 0.3404725264168417, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 378107.7282218347, 378107.7282218344, 117081.119254832], 
processed observation next is [1.0, 0.7391304347826086, 0.7765151515151518, 0.46166666666666656, 1.0, 1.0, 0.17559065802105214, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14003989934142025, 0.14003989934142014, 0.28556370549959026], 
reward next is 0.7144, 
noisyNet noise sample is [array([-1.8055066], dtype=float32), -0.43957734]. 
=============================================
[2019-03-23 00:59:05,680] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:59:05,691] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6563
[2019-03-23 00:59:05,697] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.7, 60.5, 1.0, 2.0, 0.5171023002028219, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 588747.2699205629, 588747.2699205632, 145151.957914374], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6972600.0000, 
sim time next is 6973200.0000, 
raw observation next is [27.7, 61.0, 1.0, 2.0, 0.5205867200565468, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 592491.0589875246, 592491.0589875246, 145739.9440986082], 
processed observation next is [0.0, 0.7391304347826086, 0.8954545454545454, 0.61, 1.0, 1.0, 0.4007334000706835, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21944113295834244, 0.21944113295834244, 0.35546327828928825], 
reward next is 0.6445, 
noisyNet noise sample is [array([0.47988832], dtype=float32), -0.052931465]. 
=============================================
[2019-03-23 00:59:21,522] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.1699265e-29 1.0000000e+00 2.9275535e-19 9.5425203e-20 8.8736145e-12], sum to 1.0000
[2019-03-23 00:59:21,534] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2581
[2019-03-23 00:59:21,543] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1138902.427648762 W.
[2019-03-23 00:59:21,551] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.15, 78.0, 1.0, 2.0, 0.5014082830786596, 1.0, 2.0, 0.5014082830786596, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1138902.427648762, 1138902.427648762, 232385.541869874], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7637400.0000, 
sim time next is 7638000.0000, 
raw observation next is [24.43333333333333, 76.66666666666666, 1.0, 2.0, 0.5040176869331621, 1.0, 2.0, 0.5040176869331621, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1144089.816515024, 1144089.816515024, 233351.4209311911], 
processed observation next is [1.0, 0.391304347826087, 0.7469696969696968, 0.7666666666666666, 1.0, 1.0, 0.38002210866645253, 1.0, 1.0, 0.38002210866645253, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.42373696907963854, 0.42373696907963854, 0.5691498071492466], 
reward next is 0.4309, 
noisyNet noise sample is [array([-0.24667338], dtype=float32), 0.12877677]. 
=============================================
[2019-03-23 00:59:21,570] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[63.921604]
 [64.24344 ]
 [64.319214]
 [65.7164  ]
 [66.03367 ]], R is [[63.81829071]
 [63.61331177]
 [63.41983414]
 [63.26332855]
 [63.17435837]].
[2019-03-23 00:59:22,863] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:59:22,872] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7627
[2019-03-23 00:59:22,880] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.2, 84.0, 1.0, 2.0, 0.4567019411022332, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 520820.4802582015, 520820.4802582018, 134946.52727272], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6999600.0000, 
sim time next is 7000200.0000, 
raw observation next is [22.2, 84.0, 1.0, 2.0, 0.4564316416925075, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 520511.7707943704, 520511.7707943704, 134917.1669478577], 
processed observation next is [1.0, 0.0, 0.6454545454545454, 0.84, 1.0, 1.0, 0.32053955211563434, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1927821373312483, 0.1927821373312483, 0.32906626084843343], 
reward next is 0.6709, 
noisyNet noise sample is [array([-0.6290288], dtype=float32), 0.96937263]. 
=============================================
[2019-03-23 00:59:26,550] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.9947098e-37], sum to 1.0000
[2019-03-23 00:59:26,559] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6224
[2019-03-23 00:59:26,566] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.1, 81.5, 1.0, 2.0, 0.4095851066909197, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 464086.9890995732, 464086.9890995729, 127209.4146899197], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7061400.0000, 
sim time next is 7062000.0000, 
raw observation next is [20.73333333333333, 82.33333333333334, 1.0, 2.0, 0.4047395508863549, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 457658.8134761247, 457658.8134761247, 126160.6690533245], 
processed observation next is [1.0, 0.7391304347826086, 0.5787878787878786, 0.8233333333333335, 1.0, 1.0, 0.25592443860794356, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16950326425041656, 0.16950326425041656, 0.30770894891054756], 
reward next is 0.6923, 
noisyNet noise sample is [array([-1.9094021], dtype=float32), -1.1165394]. 
=============================================
[2019-03-23 00:59:26,576] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[70.288704]
 [69.33724 ]
 [67.94101 ]
 [65.86744 ]
 [66.60456 ]], R is [[70.6288147 ]
 [70.61225891]
 [70.58921051]
 [70.52993774]
 [70.38882446]].
[2019-03-23 00:59:32,797] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:59:32,804] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8112
[2019-03-23 00:59:32,813] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.0, 77.0, 1.0, 2.0, 0.2144517566349832, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 232840.6940181495, 232840.6940181492, 74049.81757067563], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7174800.0000, 
sim time next is 7175400.0000, 
raw observation next is [14.85, 77.83333333333334, 1.0, 2.0, 0.2130390704667121, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 231306.5072853492, 231306.5072853495, 73786.64776627309], 
processed observation next is [1.0, 0.043478260869565216, 0.31136363636363634, 0.7783333333333334, 1.0, 1.0, 0.016298838083390124, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08566907677235155, 0.08566907677235167, 0.17996743357627584], 
reward next is 0.8200, 
noisyNet noise sample is [array([2.035003], dtype=float32), -0.4745902]. 
=============================================
[2019-03-23 00:59:35,316] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:59:35,326] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6002
[2019-03-23 00:59:35,330] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.6, 88.66666666666667, 1.0, 2.0, 0.2329711596066834, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 252953.3384459658, 252953.3384459655, 78865.88260087534], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7263600.0000, 
sim time next is 7264200.0000, 
raw observation next is [14.5, 88.33333333333334, 1.0, 2.0, 0.2292832913418378, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 248948.1331258844, 248948.1331258847, 77945.64685470016], 
processed observation next is [1.0, 0.043478260869565216, 0.29545454545454547, 0.8833333333333334, 1.0, 1.0, 0.036604114177297246, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09220301226884607, 0.09220301226884618, 0.1901113337919516], 
reward next is 0.8099, 
noisyNet noise sample is [array([0.792552], dtype=float32), 1.2116408]. 
=============================================
[2019-03-23 00:59:40,304] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:59:40,305] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:59:40,389] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run8
[2019-03-23 00:59:45,060] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:59:45,060] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:59:45,133] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run8
[2019-03-23 00:59:50,313] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-23 00:59:50,318] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 00:59:50,320] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:59:50,321] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 00:59:50,323] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:59:50,324] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 00:59:50,325] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:59:50,326] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 00:59:50,328] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:59:50,327] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 00:59:50,330] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:59:50,351] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run60
[2019-03-23 00:59:50,376] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run60
[2019-03-23 00:59:50,407] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run60
[2019-03-23 00:59:50,408] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run60
[2019-03-23 00:59:50,445] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run60
[2019-03-23 01:00:33,739] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.43700066], dtype=float32), 0.037074074]
[2019-03-23 01:00:33,740] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.96155385666667, 88.88722408000001, 1.0, 2.0, 0.434142032146588, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 493302.1900270308, 493302.1900270308, 134917.9025829014]
[2019-03-23 01:00:33,741] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 01:00:33,744] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.19268354105588648
[2019-03-23 01:00:38,621] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.43700066], dtype=float32), 0.037074074]
[2019-03-23 01:00:38,623] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.53199586833333, 85.93853501166667, 1.0, 2.0, 0.6533006634577371, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 101.2265246204184, 722896.5339187885, 722896.5339187889, 151183.6463737521]
[2019-03-23 01:00:38,625] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 01:00:38,629] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.9619476398266142
[2019-03-23 01:00:48,897] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.43700066], dtype=float32), 0.037074074]
[2019-03-23 01:00:48,899] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.052389205, 94.30014324999999, 1.0, 2.0, 0.4448837465223007, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 506012.7598821117, 506012.7598821117, 136426.5369509349]
[2019-03-23 01:00:48,900] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 01:00:48,904] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.5087863675904462
[2019-03-23 01:01:02,720] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.43700066], dtype=float32), 0.037074074]
[2019-03-23 01:01:02,721] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.50524793, 69.24205011, 1.0, 2.0, 0.3556536157757965, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 393110.2540289524, 393110.254028952, 121848.6256133421]
[2019-03-23 01:01:02,723] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 01:01:02,725] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.7912925609586934
[2019-03-23 01:01:03,143] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.43700066], dtype=float32), 0.037074074]
[2019-03-23 01:01:03,144] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [25.45, 49.5, 1.0, 2.0, 0.381730253598526, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 428989.2084875513, 428989.2084875513, 126941.5989877483]
[2019-03-23 01:01:03,144] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 01:01:03,152] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.8003809490754038
[2019-03-23 01:01:11,662] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.43700066], dtype=float32), 0.037074074]
[2019-03-23 01:01:11,663] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.86807049666667, 55.13271404666666, 1.0, 2.0, 0.624444604322087, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769683804, 706852.612850431, 706852.612850431, 154459.6413011662]
[2019-03-23 01:01:11,666] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 01:01:11,668] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.5744904845606164
[2019-03-23 01:01:13,184] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.43700066], dtype=float32), 0.037074074]
[2019-03-23 01:01:13,185] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.2, 51.5, 1.0, 2.0, 0.381180710687936, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 413943.4669550958, 413943.4669550958, 116881.3222362332]
[2019-03-23 01:01:13,185] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 01:01:13,188] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.9837642455074584
[2019-03-23 01:01:28,452] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.43700066], dtype=float32), 0.037074074]
[2019-03-23 01:01:28,453] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.4, 40.0, 1.0, 2.0, 0.3593064338332786, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 390149.695086695, 390149.695086695, 106135.5172231623]
[2019-03-23 01:01:28,454] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 01:01:28,458] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.4887371839645578
[2019-03-23 01:01:32,549] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.43700066], dtype=float32), 0.037074074]
[2019-03-23 01:01:32,550] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.91567563, 63.7540017, 1.0, 2.0, 0.4060161181419997, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 457446.2387378037, 457446.2387378037, 129675.3099813071]
[2019-03-23 01:01:32,551] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 01:01:32,555] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.4670448526373411
[2019-03-23 01:01:37,993] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8593.6867 1706159149.9219 465.0000
[2019-03-23 01:01:38,122] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8508.4528 1773463374.2284 173.0000
[2019-03-23 01:01:38,365] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9057.8713 1656401324.5381 80.0000
[2019-03-23 01:01:38,412] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8853.4143 1664003580.0750 105.0000
[2019-03-23 01:01:38,476] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8570.4787 1683579848.9606 214.0000
[2019-03-23 01:01:39,493] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 1475000, evaluation results [1475000.0, 8508.45277065677, 1773463374.2284098, 173.0, 9057.871276350008, 1656401324.538099, 80.0, 8853.414337702749, 1664003580.0749555, 105.0, 8593.686660790749, 1706159149.921858, 465.0, 8570.478727897242, 1683579848.9606183, 214.0]
[2019-03-23 01:01:42,608] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:01:42,618] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0843
[2019-03-23 01:01:42,623] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.3, 56.0, 1.0, 2.0, 0.5071986909159997, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 578004.9305567789, 578004.9305567786, 143479.6288561249], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7567200.0000, 
sim time next is 7567800.0000, 
raw observation next is [28.2, 56.16666666666667, 1.0, 2.0, 0.5061700043625438, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 576893.0009884045, 576893.0009884045, 143291.9260216209], 
processed observation next is [0.0, 0.6086956521739131, 0.9181818181818181, 0.5616666666666668, 1.0, 1.0, 0.3827125054531797, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21366407444014981, 0.21366407444014981, 0.3494925024917583], 
reward next is 0.6505, 
noisyNet noise sample is [array([-0.73204815], dtype=float32), -1.5316998]. 
=============================================
[2019-03-23 01:01:44,889] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:01:44,902] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7993
[2019-03-23 01:01:44,905] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 210520.1837055792, 210520.1837055792, 72488.35250405507], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 265200.0000, 
sim time next is 265800.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 210537.4440875833, 210537.4440875836, 72475.79490971036], 
processed observation next is [0.0, 0.043478260869565216, 0.22727272727272727, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07797683114354938, 0.07797683114354949, 0.17677023148709842], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.27434382], dtype=float32), 1.6753691]. 
=============================================
[2019-03-23 01:01:45,897] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 3.5430410e-35 1.7058364e-34 6.3091349e-31], sum to 1.0000
[2019-03-23 01:01:45,909] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1267
[2019-03-23 01:01:45,912] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 96.0, 1.0, 2.0, 0.4942522916645378, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 562303.283348729, 562303.2833487287, 137369.4274253843], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7618200.0000, 
sim time next is 7618800.0000, 
raw observation next is [20.0, 96.0, 1.0, 2.0, 0.4492539438612752, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 511081.6595593743, 511081.6595593743, 132609.6928125504], 
processed observation next is [1.0, 0.17391304347826086, 0.5454545454545454, 0.96, 1.0, 1.0, 0.31156742982659397, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.189289503540509, 0.189289503540509, 0.32343827515256196], 
reward next is 0.6766, 
noisyNet noise sample is [array([-0.30158958], dtype=float32), 0.87589663]. 
=============================================
[2019-03-23 01:01:46,053] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:01:46,064] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4312
[2019-03-23 01:01:46,070] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.95, 85.5, 1.0, 2.0, 0.6400528667938046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 721403.306539613, 721403.306539613, 150311.7303872512], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7893000.0000, 
sim time next is 7893600.0000, 
raw observation next is [19.76666666666667, 88.0, 1.0, 2.0, 0.6984632112236426, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 788532.7260191301, 788532.7260191299, 158313.364123766], 
processed observation next is [1.0, 0.34782608695652173, 0.534848484848485, 0.88, 1.0, 1.0, 0.6230790140295532, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.292049157784863, 0.2920491577848629, 0.38613015639942927], 
reward next is 0.6139, 
noisyNet noise sample is [array([-0.38051498], dtype=float32), -0.076144725]. 
=============================================
[2019-03-23 01:01:49,893] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:01:49,893] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:01:49,968] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run8
[2019-03-23 01:01:50,027] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:01:50,028] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:01:50,042] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run8
[2019-03-23 01:01:50,363] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 8.037084e-34 0.000000e+00], sum to 1.0000
[2019-03-23 01:01:50,370] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9826
[2019-03-23 01:01:50,374] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.5, 97.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 209300.9499201967, 209300.9499201964, 72940.59717180948], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 275400.0000, 
sim time next is 276000.0000, 
raw observation next is [13.66666666666667, 96.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 211689.9595452026, 211689.9595452026, 73606.38904235009], 
processed observation next is [0.0, 0.17391304347826086, 0.25757575757575774, 0.96, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.07840368872044541, 0.07840368872044541, 0.17952777815207338], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.91729], dtype=float32), 1.4244848]. 
=============================================
[2019-03-23 01:01:50,391] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[74.00086 ]
 [73.98537 ]
 [73.96082 ]
 [73.94703 ]
 [73.880226]], R is [[73.26994324]
 [72.5372467 ]
 [71.81187439]
 [71.09375763]
 [70.38282013]].
[2019-03-23 01:01:50,849] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 4.4008827e-35 2.4321333e-27 4.7436021e-38], sum to 1.0000
[2019-03-23 01:01:50,852] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8824
[2019-03-23 01:01:50,858] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.11666666666667, 72.33333333333333, 1.0, 2.0, 0.5643087907028782, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 613429.1033689589, 613429.1033689589, 133033.6351499319], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7721400.0000, 
sim time next is 7722000.0000, 
raw observation next is [19.4, 70.0, 1.0, 2.0, 0.5941304244439362, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 645676.1668786333, 645676.1668786333, 135933.5250445987], 
processed observation next is [1.0, 0.391304347826087, 0.5181818181818181, 0.7, 1.0, 1.0, 0.49266303055492017, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23913932106616048, 0.23913932106616048, 0.3315451830356066], 
reward next is 0.6685, 
noisyNet noise sample is [array([-0.52794397], dtype=float32), 1.2352728]. 
=============================================
[2019-03-23 01:01:50,872] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[73.1113  ]
 [73.68588 ]
 [74.52403 ]
 [75.206215]
 [75.837036]], R is [[72.48976135]
 [72.44039154]
 [72.3970108 ]
 [72.36762238]
 [72.35033417]].
[2019-03-23 01:01:55,255] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:01:55,266] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3114
[2019-03-23 01:01:55,272] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.9, 75.16666666666666, 1.0, 2.0, 0.3286547206120062, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 363217.3465753085, 363217.3465753088, 115456.8630611512], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7887000.0000, 
sim time next is 7887600.0000, 
raw observation next is [20.0, 75.0, 1.0, 2.0, 0.3436344146293116, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 380259.2222732464, 380259.2222732467, 116776.6780924329], 
processed observation next is [1.0, 0.30434782608695654, 0.5454545454545454, 0.75, 1.0, 1.0, 0.1795430182866395, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14083674899009124, 0.14083674899009135, 0.2848211660791046], 
reward next is 0.7152, 
noisyNet noise sample is [array([-0.51883084], dtype=float32), -0.19230029]. 
=============================================
[2019-03-23 01:01:58,003] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:01:58,013] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9851
[2019-03-23 01:01:58,016] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.11666666666667, 48.5, 1.0, 2.0, 0.4345285797629343, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 473478.8372703365, 473478.8372703365, 121727.3996962192], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7837800.0000, 
sim time next is 7838400.0000, 
raw observation next is [22.93333333333333, 49.0, 1.0, 2.0, 0.3245851080652145, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 352461.156459369, 352461.156459369, 112872.7097842232], 
processed observation next is [1.0, 0.7391304347826086, 0.6787878787878786, 0.49, 1.0, 1.0, 0.15573138508151813, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13054116905902555, 0.13054116905902555, 0.27529929215664195], 
reward next is 0.7247, 
noisyNet noise sample is [array([-1.3012764], dtype=float32), 1.5198503]. 
=============================================
[2019-03-23 01:01:59,105] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:01:59,114] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0338
[2019-03-23 01:01:59,118] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.9, 69.66666666666667, 1.0, 2.0, 0.3398368486354471, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 369029.0327528053, 369029.0327528053, 105991.501743097], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7870200.0000, 
sim time next is 7870800.0000, 
raw observation next is [19.0, 69.33333333333334, 1.0, 2.0, 0.3045362048739703, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 330683.0092490705, 330683.0092490703, 103926.8283724616], 
processed observation next is [1.0, 0.08695652173913043, 0.5, 0.6933333333333335, 1.0, 1.0, 0.13067025609246288, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12247518861076685, 0.12247518861076678, 0.25348006920112587], 
reward next is 0.7465, 
noisyNet noise sample is [array([0.5406013], dtype=float32), -2.1464922]. 
=============================================
[2019-03-23 01:01:59,808] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:01:59,808] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:01:59,880] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run8
[2019-03-23 01:02:01,355] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 9.9723563e-36 3.4825493e-30 2.4372204e-29], sum to 1.0000
[2019-03-23 01:02:01,367] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2355
[2019-03-23 01:02:01,371] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 88.0, 1.0, 2.0, 0.7980281095254543, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 908880.588905085, 908880.588905085, 177560.578849469], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7906200.0000, 
sim time next is 7906800.0000, 
raw observation next is [20.9, 89.0, 1.0, 2.0, 0.6899126735169094, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 785665.4198230907, 785665.4198230907, 161925.0481418428], 
processed observation next is [1.0, 0.5217391304347826, 0.5863636363636363, 0.89, 1.0, 1.0, 0.6123908418961368, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2909871925270706, 0.2909871925270706, 0.3949391418093727], 
reward next is 0.6051, 
noisyNet noise sample is [array([-0.04121554], dtype=float32), 1.5125917]. 
=============================================
[2019-03-23 01:02:01,883] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.7513727e-34 1.0000000e+00 3.7495163e-26 3.7315135e-31 1.1435890e-28], sum to 1.0000
[2019-03-23 01:02:01,890] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4632
[2019-03-23 01:02:01,894] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.51666666666667, 87.5, 1.0, 2.0, 0.8826518136386472, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1006955.876458984, 1006955.876458984, 193130.7588167286], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7920600.0000, 
sim time next is 7921200.0000, 
raw observation next is [21.43333333333334, 88.0, 1.0, 2.0, 0.8733974489555554, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 996346.8347847409, 996346.8347847413, 191512.4740958116], 
processed observation next is [1.0, 0.6956521739130435, 0.6106060606060609, 0.88, 1.0, 1.0, 0.8417468111944443, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.36901734621657073, 0.36901734621657084, 0.46710359535563806], 
reward next is 0.5329, 
noisyNet noise sample is [array([-1.4607222], dtype=float32), -0.3710304]. 
=============================================
[2019-03-23 01:02:02,099] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:02:02,099] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:02:02,198] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run8
[2019-03-23 01:02:03,133] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:02:03,134] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4717
[2019-03-23 01:02:03,137] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 94.0, 1.0, 2.0, 0.32550765302878, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 353463.2956007504, 353463.2956007504, 89284.05676329561], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 541800.0000, 
sim time next is 542400.0000, 
raw observation next is [14.0, 94.0, 1.0, 2.0, 0.2229732166457651, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 242095.1598568237, 242095.1598568234, 78530.87562635085], 
processed observation next is [1.0, 0.2608695652173913, 0.2727272727272727, 0.94, 1.0, 1.0, 0.028716520807206374, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08966487402104582, 0.0896648740210457, 0.19153872103988012], 
reward next is 0.8085, 
noisyNet noise sample is [array([-1.1057427], dtype=float32), -0.137439]. 
=============================================
[2019-03-23 01:02:03,431] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:02:03,433] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:02:03,515] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run8
[2019-03-23 01:02:03,615] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:02:03,616] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:02:03,666] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run8
[2019-03-23 01:02:03,740] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:02:03,741] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:02:03,767] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:02:03,768] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:02:03,773] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:02:03,774] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:02:03,812] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run8
[2019-03-23 01:02:03,841] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:02:03,841] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:02:03,847] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run8
[2019-03-23 01:02:03,886] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run8
[2019-03-23 01:02:03,937] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run8
[2019-03-23 01:02:03,966] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:02:03,969] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:02:03,973] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:02:03,974] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:02:03,983] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run8
[2019-03-23 01:02:04,001] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:02:04,002] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:02:04,012] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run8
[2019-03-23 01:02:04,052] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run8
[2019-03-23 01:02:04,078] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:02:04,079] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:02:04,094] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run8
[2019-03-23 01:02:05,405] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.6626039e-37 1.0000000e+00 1.2793766e-36 7.0130877e-35 5.1733348e-28], sum to 1.0000
[2019-03-23 01:02:05,411] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2828
[2019-03-23 01:02:05,414] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.16666666666667, 69.0, 1.0, 2.0, 0.8270650613616789, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 939665.4323246466, 939665.4323246466, 179967.0103671594], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 724200.0000, 
sim time next is 724800.0000, 
raw observation next is [23.33333333333334, 69.0, 1.0, 2.0, 0.7576516386901531, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 861406.9707307076, 861406.9707307076, 170187.0684992617], 
processed observation next is [1.0, 0.391304347826087, 0.6969696969696972, 0.69, 1.0, 1.0, 0.6970645483626914, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.319039618789151, 0.319039618789151, 0.415090410973809], 
reward next is 0.5849, 
noisyNet noise sample is [array([0.03686585], dtype=float32), 0.5250915]. 
=============================================
[2019-03-23 01:02:05,653] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:02:05,662] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0607
[2019-03-23 01:02:05,667] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 94.0, 1.0, 2.0, 0.371638644630967, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 413551.1173340308, 413551.1173340308, 119890.5615206194], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 18000.0000, 
sim time next is 18600.0000, 
raw observation next is [17.83333333333333, 95.0, 1.0, 2.0, 0.3657822884346739, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 406866.275000817, 406866.2750008167, 119343.6929902457], 
processed observation next is [1.0, 0.21739130434782608, 0.44696969696969674, 0.95, 1.0, 1.0, 0.20722786054334238, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15069121296326557, 0.15069121296326543, 0.29108217802498954], 
reward next is 0.7089, 
noisyNet noise sample is [array([-0.32016414], dtype=float32), -2.232027]. 
=============================================
[2019-03-23 01:02:07,792] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:02:07,799] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5631
[2019-03-23 01:02:07,804] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 45.33333333333334, 1.0, 2.0, 0.5034682804334641, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 546816.4268587272, 546816.4268587272, 117563.5642722662], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 134400.0000, 
sim time next is 135000.0000, 
raw observation next is [22.5, 45.0, 1.0, 2.0, 0.549294069083331, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 596618.3193232376, 596618.3193232379, 123414.1199568784], 
processed observation next is [1.0, 0.5652173913043478, 0.6590909090909091, 0.45, 1.0, 1.0, 0.4366175863541637, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22096974789749543, 0.22096974789749552, 0.30101004867531317], 
reward next is 0.6990, 
noisyNet noise sample is [array([1.0965731], dtype=float32), 0.3104982]. 
=============================================
[2019-03-23 01:02:07,818] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[68.253   ]
 [68.36148 ]
 [68.6185  ]
 [68.501495]
 [68.48013 ]], R is [[68.01805115]
 [68.05112457]
 [68.09212494]
 [68.14559174]
 [68.19985199]].
[2019-03-23 01:02:10,294] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:02:10,302] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1875
[2019-03-23 01:02:10,309] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 77.0, 1.0, 2.0, 0.2350819196284341, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 255245.7419141014, 255245.7419141016, 79457.74693399553], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 82800.0000, 
sim time next is 83400.0000, 
raw observation next is [16.0, 77.0, 1.0, 2.0, 0.2353293778570567, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 255514.4961018144, 255514.4961018144, 79486.75388256456], 
processed observation next is [1.0, 1.0, 0.36363636363636365, 0.77, 1.0, 1.0, 0.04416172232132087, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09463499855622756, 0.09463499855622756, 0.19387013142088919], 
reward next is 0.8061, 
noisyNet noise sample is [array([0.56316864], dtype=float32), 0.9323386]. 
=============================================
[2019-03-23 01:02:20,042] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.9630142e-36 0.0000000e+00], sum to 1.0000
[2019-03-23 01:02:20,047] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9638
[2019-03-23 01:02:20,054] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.83333333333333, 95.0, 1.0, 2.0, 0.2393043972322428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 259831.6212411788, 259831.6212411788, 84429.44356082953], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 256200.0000, 
sim time next is 256800.0000, 
raw observation next is [14.66666666666667, 96.0, 1.0, 2.0, 0.2370705946762965, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 257405.5641561009, 257405.5641561006, 83719.4827845899], 
processed observation next is [0.0, 1.0, 0.30303030303030315, 0.96, 1.0, 1.0, 0.046338243345370594, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09533539413188923, 0.0953353941318891, 0.20419386045021926], 
reward next is 0.7958, 
noisyNet noise sample is [array([1.0597582], dtype=float32), 0.9629509]. 
=============================================
[2019-03-23 01:02:24,012] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:02:24,021] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3577
[2019-03-23 01:02:24,022] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:02:24,026] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.16666666666666, 53.33333333333333, 1.0, 2.0, 0.3605377086983681, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 402877.183753643, 402877.1837536432, 119718.6053329778], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 672600.0000, 
sim time next is 673200.0000, 
raw observation next is [24.0, 54.0, 1.0, 2.0, 0.3584930911669091, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 400406.3172751041, 400406.3172751044, 119468.2654586021], 
processed observation next is [1.0, 0.8260869565217391, 0.7272727272727273, 0.54, 1.0, 1.0, 0.19811636395863633, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14829863602781634, 0.14829863602781646, 0.29138601331366365], 
reward next is 0.7086, 
noisyNet noise sample is [array([0.2824912], dtype=float32), -0.15627657]. 
=============================================
[2019-03-23 01:02:24,034] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1835
[2019-03-23 01:02:24,038] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 43.0, 1.0, 2.0, 0.2521818090964079, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 273817.576857555, 273817.576857555, 79426.41671779373], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 325800.0000, 
sim time next is 326400.0000, 
raw observation next is [20.33333333333333, 43.0, 1.0, 2.0, 0.2498521541107879, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 271287.3452161358, 271287.3452161358, 78729.04317558673], 
processed observation next is [0.0, 0.782608695652174, 0.5606060606060604, 0.43, 1.0, 1.0, 0.06231519263848486, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10047679452449473, 0.10047679452449473, 0.1920220565258213], 
reward next is 0.8080, 
noisyNet noise sample is [array([0.31271413], dtype=float32), -0.49585745]. 
=============================================
[2019-03-23 01:02:31,217] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-23 01:02:31,219] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 01:02:31,221] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 01:02:31,222] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:02:31,223] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:02:31,224] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 01:02:31,223] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 01:02:31,228] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 01:02:31,229] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:02:31,235] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:02:31,246] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:02:32,167] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run61
[2019-03-23 01:02:32,189] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run61
[2019-03-23 01:02:32,217] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run61
[2019-03-23 01:02:32,218] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run61
[2019-03-23 01:02:32,236] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run61
[2019-03-23 01:03:24,404] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.49730492], dtype=float32), -0.059253044]
[2019-03-23 01:03:24,407] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [26.86657179, 63.1798775, 1.0, 2.0, 0.9313398200016303, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 1061681.948412745, 1061681.948412745, 211791.5517296159]
[2019-03-23 01:03:24,409] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 01:03:24,413] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 6.9247157e-37 0.0000000e+00], sampled 0.04541190585602495
[2019-03-23 01:03:34,789] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.49730492], dtype=float32), -0.059253044]
[2019-03-23 01:03:34,790] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.5, 89.0, 1.0, 2.0, 0.5063155304437593, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 577503.9434774881, 577503.9434774878, 146865.6482343916]
[2019-03-23 01:03:34,793] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 01:03:34,795] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.9119704602749231
[2019-03-23 01:03:37,001] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.49730492], dtype=float32), -0.059253044]
[2019-03-23 01:03:37,002] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.38333333333333, 66.33333333333334, 1.0, 2.0, 0.3001377591639672, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 325884.4960349535, 325884.4960349535, 107025.5720072627]
[2019-03-23 01:03:37,002] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 01:03:37,007] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.5873533528035522
[2019-03-23 01:03:44,653] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.49730492], dtype=float32), -0.059253044]
[2019-03-23 01:03:44,655] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.2, 76.0, 1.0, 2.0, 0.3443417998845427, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 383142.8577879017, 383142.8577879013, 122009.3874072263]
[2019-03-23 01:03:44,656] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 01:03:44,661] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.558183102486877
[2019-03-23 01:03:51,064] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.49730492], dtype=float32), -0.059253044]
[2019-03-23 01:03:51,067] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.5, 58.0, 1.0, 2.0, 0.3212911187762155, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 348882.9893437253, 348882.9893437253, 102485.1999682397]
[2019-03-23 01:03:51,068] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 01:03:51,069] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.5116279350580071
[2019-03-23 01:04:19,283] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8509.1813 1773413472.9632 173.0000
[2019-03-23 01:04:19,562] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8853.4143 1664003580.0750 105.0000
[2019-03-23 01:04:19,610] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8571.2008 1683531899.0519 214.0000
[2019-03-23 01:04:19,679] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8594.4987 1706116953.1019 465.0000
[2019-03-23 01:04:19,897] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9058.6831 1656359050.7176 80.0000
[2019-03-23 01:04:20,912] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 1500000, evaluation results [1500000.0, 8509.181281245757, 1773413472.9631987, 173.0, 9058.683074210225, 1656359050.7176125, 80.0, 8853.414337702749, 1664003580.0749555, 105.0, 8594.49866461476, 1706116953.1019058, 465.0, 8571.200785595147, 1683531899.0518706, 214.0]
[2019-03-23 01:04:28,933] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.0331794e-33 0.0000000e+00], sum to 1.0000
[2019-03-23 01:04:28,938] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8860
[2019-03-23 01:04:28,942] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.4133194404573908, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 468548.0268771983, 468548.0268771986, 127717.3358423202], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 940200.0000, 
sim time next is 940800.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4132675399931738, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 468489.21223634, 468489.21223634, 127712.4302620824], 
processed observation next is [0.0, 0.9130434782608695, 0.5, 1.0, 1.0, 1.0, 0.2665844249914672, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17351452305049628, 0.17351452305049628, 0.31149373234654243], 
reward next is 0.6885, 
noisyNet noise sample is [array([0.16412067], dtype=float32), 0.5003068]. 
=============================================
[2019-03-23 01:04:32,317] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:04:32,326] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3380
[2019-03-23 01:04:32,334] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 50.00000000000001, 1.0, 2.0, 0.8835634624684533, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1000944.402995963, 1000944.402995963, 186737.1754996939], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 663600.0000, 
sim time next is 664200.0000, 
raw observation next is [26.0, 49.5, 1.0, 2.0, 0.9459900806428863, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1071170.309981753, 1071170.309981753, 196509.8545691975], 
processed observation next is [1.0, 0.6956521739130435, 0.8181818181818182, 0.495, 1.0, 1.0, 0.9324876008036078, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.39672974443768627, 0.39672974443768627, 0.47929232821755485], 
reward next is 0.5207, 
noisyNet noise sample is [array([0.72994024], dtype=float32), 1.4966809]. 
=============================================
[2019-03-23 01:04:34,926] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:04:34,934] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3948
[2019-03-23 01:04:34,937] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.33333333333334, 93.00000000000001, 1.0, 2.0, 0.3327805207760797, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 361363.7150331566, 361363.7150331566, 110362.3519148727], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 713400.0000, 
sim time next is 714000.0000, 
raw observation next is [16.66666666666667, 92.0, 1.0, 2.0, 0.3170688750756723, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 344296.5242986059, 344296.5242986061, 112350.4870266764], 
processed observation next is [1.0, 0.2608695652173913, 0.39393939393939414, 0.92, 1.0, 1.0, 0.14633609384459031, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12751723122170588, 0.12751723122170597, 0.27402557811384487], 
reward next is 0.7260, 
noisyNet noise sample is [array([0.5566709], dtype=float32), -0.13133486]. 
=============================================
[2019-03-23 01:04:34,950] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[69.99702]
 [70.35961]
 [70.46505]
 [70.50815]
 [70.55031]], R is [[69.99638367]
 [70.02723694]
 [70.07495117]
 [70.12960815]
 [70.18786621]].
[2019-03-23 01:04:37,062] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:04:37,071] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7557
[2019-03-23 01:04:37,075] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.33333333333334, 60.0, 1.0, 2.0, 0.465702578612423, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 531362.204993338, 531362.204993338, 136678.2583837447], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 762000.0000, 
sim time next is 762600.0000, 
raw observation next is [26.16666666666667, 60.5, 1.0, 2.0, 0.4639747001695171, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 529359.0094150781, 529359.0094150781, 136349.8160107475], 
processed observation next is [1.0, 0.8260869565217391, 0.825757575757576, 0.605, 1.0, 1.0, 0.3299683752118963, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19605889237595486, 0.19605889237595486, 0.33256052685548176], 
reward next is 0.6674, 
noisyNet noise sample is [array([-1.9602644], dtype=float32), -1.2425185]. 
=============================================
[2019-03-23 01:04:44,044] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:04:44,045] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7412
[2019-03-23 01:04:44,049] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 88.5, 1.0, 2.0, 0.4082270318469771, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 461663.2579130239, 461663.2579130237, 126520.4756696958], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 865800.0000, 
sim time next is 866400.0000, 
raw observation next is [19.66666666666667, 90.33333333333334, 1.0, 2.0, 0.4046431637875781, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 457171.7438285849, 457171.7438285852, 125928.0887092646], 
processed observation next is [0.0, 0.0, 0.5303030303030305, 0.9033333333333334, 1.0, 1.0, 0.2558039547344726, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16932286808466107, 0.16932286808466118, 0.30714167977869417], 
reward next is 0.6929, 
noisyNet noise sample is [array([-0.40345728], dtype=float32), 0.74141675]. 
=============================================
[2019-03-23 01:04:48,535] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.2680834e-38 1.2837205e-32], sum to 1.0000
[2019-03-23 01:04:48,546] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4117
[2019-03-23 01:04:48,553] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.2258507517259405, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 245220.256842913, 245220.2568429127, 76689.73850449799], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1048800.0000, 
sim time next is 1049400.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.2103041611653223, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 228336.3910402417, 228336.3910402417, 74853.6741052901], 
processed observation next is [1.0, 0.13043478260869565, 0.22727272727272727, 1.0, 1.0, 1.0, 0.012880201456652862, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08456903371860804, 0.08456903371860804, 0.182569936842171], 
reward next is 0.8174, 
noisyNet noise sample is [array([1.2032942], dtype=float32), -0.21402769]. 
=============================================
[2019-03-23 01:04:53,957] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.1748706e-33 5.8022223e-35 3.7924408e-26], sum to 1.0000
[2019-03-23 01:04:53,966] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7948
[2019-03-23 01:04:53,970] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 94.0, 1.0, 2.0, 0.4434257249818271, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 481571.9622289063, 481571.9622289063, 97156.85531210208], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1058400.0000, 
sim time next is 1059000.0000, 
raw observation next is [13.16666666666667, 93.00000000000001, 1.0, 2.0, 0.2791726896310476, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 303133.2550723224, 303133.2550723224, 81621.86293580369], 
processed observation next is [1.0, 0.2608695652173913, 0.23484848484848497, 0.9300000000000002, 1.0, 1.0, 0.09896586203880946, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11227157595271199, 0.11227157595271199, 0.19907771447756997], 
reward next is 0.8009, 
noisyNet noise sample is [array([1.4983785], dtype=float32), 2.161346]. 
=============================================
[2019-03-23 01:04:53,979] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[64.42722 ]
 [64.48631 ]
 [64.484856]
 [64.47456 ]
 [64.9585  ]], R is [[66.06626892]
 [66.16864014]
 [66.27267456]
 [66.37352753]
 [66.46586609]].
[2019-03-23 01:05:00,671] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.6854394e-37 1.0000000e+00 9.1978827e-26 0.0000000e+00 1.4531532e-18], sum to 1.0000
[2019-03-23 01:05:00,678] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9190
[2019-03-23 01:05:00,686] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1396651.961630429 W.
[2019-03-23 01:05:00,692] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.0, 65.33333333333333, 1.0, 2.0, 0.7476143845079637, 0.0, 2.0, 0.0, 1.0, 2.0, 0.978621223428177, 6.911200000000001, 6.9112, 77.32846344354104, 1396651.961630429, 1396651.961630429, 300777.6099823965], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1174200.0000, 
sim time next is 1174800.0000, 
raw observation next is [27.0, 64.66666666666667, 1.0, 2.0, 0.6135523569230942, 1.0, 1.0, 0.6135523569230942, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1385244.736713717, 1385244.736713717, 264605.9002697784], 
processed observation next is [1.0, 0.6086956521739131, 0.8636363636363636, 0.6466666666666667, 1.0, 1.0, 0.5169404461538677, 1.0, 0.5, 0.5169404461538677, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.5130536061902655, 0.5130536061902655, 0.6453802445604351], 
reward next is 0.3546, 
noisyNet noise sample is [array([-2.236757], dtype=float32), 0.043443028]. 
=============================================
[2019-03-23 01:05:02,465] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:05:02,475] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1064
[2019-03-23 01:05:02,483] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.4360682108899899, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 494360.4383644059, 494360.4383644059, 129925.0117971821], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1221000.0000, 
sim time next is 1221600.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4125276860313772, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 467658.9076647232, 467658.9076647229, 127648.0980897031], 
processed observation next is [1.0, 0.13043478260869565, 0.5, 1.0, 1.0, 1.0, 0.26565960753922147, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17320700283878637, 0.17320700283878626, 0.31133682460903195], 
reward next is 0.6887, 
noisyNet noise sample is [array([-1.0329756], dtype=float32), 0.7813665]. 
=============================================
[2019-03-23 01:05:08,216] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:05:08,225] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2247
[2019-03-23 01:05:08,232] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 100.0, 1.0, 2.0, 0.4697419158298555, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 535964.7867280857, 535964.7867280861, 137075.5998519372], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1467000.0000, 
sim time next is 1467600.0000, 
raw observation next is [20.33333333333333, 100.0, 1.0, 2.0, 0.4630429209930692, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 528211.103992179, 528211.1039921793, 135976.3333151418], 
processed observation next is [0.0, 1.0, 0.5606060606060604, 1.0, 1.0, 1.0, 0.3288036512413365, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19563374221932556, 0.19563374221932567, 0.33164959345156536], 
reward next is 0.6684, 
noisyNet noise sample is [array([-1.1521401], dtype=float32), -1.3214576]. 
=============================================
[2019-03-23 01:05:12,077] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:05:12,085] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5505
[2019-03-23 01:05:12,093] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.488066759296128, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 556859.4975658968, 556859.4975658968, 140114.5075039051], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1404000.0000, 
sim time next is 1404600.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.4883470567773606, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 557179.3461798659, 557179.3461798656, 140147.019480595], 
processed observation next is [0.0, 0.2608695652173913, 0.5909090909090909, 1.0, 1.0, 1.0, 0.36043382097170074, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20636272080735774, 0.20636272080735765, 0.3418219987331585], 
reward next is 0.6582, 
noisyNet noise sample is [array([0.48643267], dtype=float32), 0.8178132]. 
=============================================
[2019-03-23 01:05:13,555] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-23 01:05:13,556] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 01:05:13,557] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 01:05:13,557] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:05:13,558] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:05:13,560] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 01:05:13,559] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 01:05:13,561] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 01:05:13,561] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:05:13,563] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:05:13,563] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:05:13,585] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run62
[2019-03-23 01:05:13,613] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run62
[2019-03-23 01:05:13,638] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run62
[2019-03-23 01:05:13,661] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run62
[2019-03-23 01:05:13,683] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run62
[2019-03-23 01:05:23,802] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.47677037], dtype=float32), -0.047081012]
[2019-03-23 01:05:23,802] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.2, 52.33333333333334, 1.0, 2.0, 0.2573690764344969, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 279436.1892539894, 279436.1892539894, 82668.83519059849]
[2019-03-23 01:05:23,805] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 01:05:23,808] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.899119659241352
[2019-03-23 01:05:45,667] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.47677037], dtype=float32), -0.047081012]
[2019-03-23 01:05:45,668] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [13.15, 81.33333333333333, 1.0, 2.0, 0.3732844137707291, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 405332.6791669534, 405332.6791669531, 91089.84032434439]
[2019-03-23 01:05:45,670] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 01:05:45,671] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.5514237433695011
[2019-03-23 01:05:51,278] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.47677037], dtype=float32), -0.047081012]
[2019-03-23 01:05:51,278] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [26.76116752, 39.89987562, 1.0, 2.0, 0.3576397450210108, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 398578.5230213551, 398578.5230213551, 123334.9375610491]
[2019-03-23 01:05:51,281] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 01:05:51,284] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.15642456358392876
[2019-03-23 01:05:55,301] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.47677037], dtype=float32), -0.047081012]
[2019-03-23 01:05:55,303] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.75470773, 100.0, 1.0, 2.0, 0.4821996809318195, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 550174.0869032447, 550174.0869032447, 143282.7704361415]
[2019-03-23 01:05:55,307] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 01:05:55,310] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.4662457470433482
[2019-03-23 01:06:03,006] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.47677037], dtype=float32), -0.047081012]
[2019-03-23 01:06:03,007] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.03333333333333, 87.33333333333334, 1.0, 2.0, 0.4409182087372441, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 501457.2719147778, 501457.2719147778, 135984.9825773122]
[2019-03-23 01:06:03,009] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 01:06:03,014] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.2796613748101656
[2019-03-23 01:06:13,528] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.47677037], dtype=float32), -0.047081012]
[2019-03-23 01:06:13,530] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.93333333333334, 82.33333333333334, 1.0, 2.0, 0.5326235213920025, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 606657.8796966865, 606657.8796966862, 151115.2928182528]
[2019-03-23 01:06:13,531] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 01:06:13,534] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.07111754776192047
[2019-03-23 01:06:29,589] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.47677037], dtype=float32), -0.047081012]
[2019-03-23 01:06:29,590] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.05, 78.0, 1.0, 2.0, 0.3504441374884148, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 390446.3826035295, 390446.3826035295, 122709.8792266579]
[2019-03-23 01:06:29,591] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 01:06:29,594] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.6332127475997312
[2019-03-23 01:06:34,165] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.47677037], dtype=float32), -0.047081012]
[2019-03-23 01:06:34,170] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [16.1, 90.0, 1.0, 2.0, 0.2709739426983835, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 294211.1673670094, 294211.1673670094, 99587.35944997365]
[2019-03-23 01:06:34,171] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 01:06:34,177] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.9154438360615783
[2019-03-23 01:06:35,952] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.47677037], dtype=float32), -0.047081012]
[2019-03-23 01:06:35,952] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.75, 43.66666666666667, 1.0, 2.0, 0.3341789813856114, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 366809.8454121352, 366809.8454121352, 119233.9872623877]
[2019-03-23 01:06:35,953] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 01:06:35,957] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.9574199881750561
[2019-03-23 01:06:47,286] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.47677037], dtype=float32), -0.047081012]
[2019-03-23 01:06:47,288] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.93333333333333, 81.66666666666667, 1.0, 2.0, 0.3790012967916477, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 424317.4486151439, 424317.4486151436, 125936.4288925481]
[2019-03-23 01:06:47,289] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 01:06:47,292] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.36511831580000076
[2019-03-23 01:06:47,722] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.47677037], dtype=float32), -0.047081012]
[2019-03-23 01:06:47,725] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.45, 73.0, 1.0, 2.0, 0.4134665287067218, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 468802.7765014977, 468802.7765014977, 127791.8315022377]
[2019-03-23 01:06:47,726] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 01:06:47,728] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.3806372537671642
[2019-03-23 01:07:01,269] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8594.4987 1706116953.1019 465.0000
[2019-03-23 01:07:01,372] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8509.1813 1773413472.9632 173.0000
[2019-03-23 01:07:01,733] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8571.2008 1683531899.0519 214.0000
[2019-03-23 01:07:01,745] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9058.6831 1656359050.7176 80.0000
[2019-03-23 01:07:01,785] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8854.1746 1663949029.5070 105.0000
[2019-03-23 01:07:02,802] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 1525000, evaluation results [1525000.0, 8509.181281245757, 1773413472.9631987, 173.0, 9058.683074210225, 1656359050.7176125, 80.0, 8854.174594824059, 1663949029.507014, 105.0, 8594.49866461476, 1706116953.1019058, 465.0, 8571.200785595147, 1683531899.0518706, 214.0]
[2019-03-23 01:07:04,917] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:07:04,925] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8089
[2019-03-23 01:07:04,930] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333333, 97.16666666666667, 1.0, 2.0, 0.4862526160406053, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 554788.4063558157, 554788.4063558157, 139907.8994017528], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1443000.0000, 
sim time next is 1443600.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.4860244246430601, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 554527.6198770255, 554527.6198770255, 139882.9128070861], 
processed observation next is [0.0, 0.7391304347826086, 0.5909090909090909, 1.0, 1.0, 1.0, 0.35753053080382513, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20538059995445387, 0.20538059995445387, 0.34117783611484415], 
reward next is 0.6588, 
noisyNet noise sample is [array([-0.407982], dtype=float32), 0.75377905]. 
=============================================
[2019-03-23 01:07:05,623] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:07:05,633] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5886
[2019-03-23 01:07:05,641] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.5, 77.0, 1.0, 2.0, 0.5132841018888615, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 585010.7456465345, 585010.7456465345, 144135.041894122], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1438200.0000, 
sim time next is 1438800.0000, 
raw observation next is [24.0, 79.0, 1.0, 2.0, 0.505905728355887, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 576900.2419845196, 576900.2419845196, 142869.4502428776], 
processed observation next is [0.0, 0.6521739130434783, 0.7272727272727273, 0.79, 1.0, 1.0, 0.3823821604448587, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21366675629056284, 0.21366675629056284, 0.34846207376311605], 
reward next is 0.6515, 
noisyNet noise sample is [array([1.3216056], dtype=float32), -0.4720736]. 
=============================================
[2019-03-23 01:07:11,016] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:07:11,031] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5816
[2019-03-23 01:07:11,037] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 91.0, 1.0, 2.0, 0.4437380918904292, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 505684.920297163, 505684.920297163, 133022.6249976031], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1549800.0000, 
sim time next is 1550400.0000, 
raw observation next is [21.0, 90.0, 1.0, 2.0, 0.4398464854502591, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 501036.3261188029, 501036.3261188032, 132348.0788687089], 
processed observation next is [0.0, 0.9565217391304348, 0.5909090909090909, 0.9, 1.0, 1.0, 0.2998081068128239, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18556900967363069, 0.1855690096736308, 0.32280019236270463], 
reward next is 0.6772, 
noisyNet noise sample is [array([0.7345186], dtype=float32), 0.4547875]. 
=============================================
[2019-03-23 01:07:11,772] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 3.732172e-29], sum to 1.0000
[2019-03-23 01:07:11,780] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2552
[2019-03-23 01:07:11,787] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1104401.119919539 W.
[2019-03-23 01:07:11,793] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [22.83333333333334, 89.83333333333333, 1.0, 2.0, 0.4886426331512525, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9482681678987092, 6.957806955116434, 6.9112, 77.32834802500349, 1104401.119919539, 1089264.156767896, 256354.8823633235], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1590600.0000, 
sim time next is 1591200.0000, 
raw observation next is [23.0, 89.0, 1.0, 2.0, 0.310242627834439, 1.0, 1.0, 0.310242627834439, 1.0, 2.0, 0.6281998341538997, 6.9112, 6.9112, 77.3421103, 1054186.346754081, 1054186.346754081, 265381.2071581112], 
processed observation next is [1.0, 0.43478260869565216, 0.6818181818181818, 0.89, 1.0, 1.0, 0.13780328479304874, 1.0, 0.5, 0.13780328479304874, 1.0, 1.0, 0.4688569059341425, 0.0, 0.0, 0.5085185399722538, 0.39043938768669667, 0.39043938768669667, 0.647271236971003], 
reward next is 0.3527, 
noisyNet noise sample is [array([-1.9907649], dtype=float32), -0.3771489]. 
=============================================
[2019-03-23 01:07:15,922] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.3145382e-36 9.9999762e-01 3.0672951e-33 1.6790262e-20 2.4015862e-06], sum to 1.0000
[2019-03-23 01:07:15,931] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8528
[2019-03-23 01:07:15,936] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 89.00000000000001, 1.0, 2.0, 0.3620095117370709, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 405034.3978764792, 405034.3978764792, 120072.1951573112], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1663800.0000, 
sim time next is 1664400.0000, 
raw observation next is [19.0, 90.0, 1.0, 2.0, 0.3581371708973217, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 401275.7230454521, 401275.7230454521, 120022.7326692831], 
processed observation next is [1.0, 0.2608695652173913, 0.5, 0.9, 1.0, 1.0, 0.19767146362165214, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14862063816498225, 0.14862063816498225, 0.2927383723641051], 
reward next is 0.7073, 
noisyNet noise sample is [array([0.6560059], dtype=float32), -1.378638]. 
=============================================
[2019-03-23 01:07:28,016] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 6.7903114e-30], sum to 1.0000
[2019-03-23 01:07:28,026] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4564
[2019-03-23 01:07:28,036] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.26666666666667, 94.33333333333334, 1.0, 2.0, 0.2408926046591485, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 261556.5267448908, 261556.5267448908, 80824.3140137826], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2180400.0000, 
sim time next is 2181000.0000, 
raw observation next is [14.23333333333333, 94.16666666666667, 1.0, 2.0, 0.239237007038341, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 259758.4308634509, 259758.4308634512, 80413.30029121763], 
processed observation next is [1.0, 0.21739130434782608, 0.2833333333333332, 0.9416666666666668, 1.0, 1.0, 0.049046258797926234, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09620682624572255, 0.09620682624572267, 0.1961300007102869], 
reward next is 0.8039, 
noisyNet noise sample is [array([-0.1172493], dtype=float32), 1.3529819]. 
=============================================
[2019-03-23 01:07:28,053] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[75.93056 ]
 [75.87247 ]
 [75.810234]
 [75.67664 ]
 [75.814964]], R is [[76.03107452]
 [76.07363129]
 [76.11486816]
 [76.15314484]
 [76.1859436 ]].
[2019-03-23 01:07:34,397] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 3.4173437e-36], sum to 1.0000
[2019-03-23 01:07:34,406] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1252
[2019-03-23 01:07:34,414] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 49.0, 1.0, 2.0, 0.4948099645601208, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 537407.439777597, 537407.4397775967, 107234.946901141], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2295000.0000, 
sim time next is 2295600.0000, 
raw observation next is [20.0, 49.0, 1.0, 2.0, 0.5001314945042153, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 543190.3218613229, 543190.3218613229, 107978.4670898305], 
processed observation next is [1.0, 0.5652173913043478, 0.5454545454545454, 0.49, 1.0, 1.0, 0.37516436813026915, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20118160068937885, 0.20118160068937885, 0.2633621148532451], 
reward next is 0.7366, 
noisyNet noise sample is [array([1.226976], dtype=float32), 0.21998021]. 
=============================================
[2019-03-23 01:07:35,676] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 4.8938766e-25], sum to 1.0000
[2019-03-23 01:07:35,686] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5287
[2019-03-23 01:07:35,692] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 60.0, 1.0, 2.0, 0.3151583562743213, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 342221.2135630365, 342221.2135630362, 112220.2752537371], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1980000.0000, 
sim time next is 1980600.0000, 
raw observation next is [21.0, 60.66666666666666, 1.0, 2.0, 0.3152274113490412, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 342328.436152829, 342328.4361528287, 112236.7747084488], 
processed observation next is [1.0, 0.9565217391304348, 0.5909090909090909, 0.6066666666666666, 1.0, 1.0, 0.14403426418630147, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12678830968623295, 0.12678830968623284, 0.2737482309962166], 
reward next is 0.7263, 
noisyNet noise sample is [array([1.2660913], dtype=float32), -1.1864115]. 
=============================================
[2019-03-23 01:07:37,980] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:07:37,988] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2228
[2019-03-23 01:07:37,997] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 47.0, 1.0, 2.0, 0.3056479197529464, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 331890.5854435464, 331890.5854435467, 109269.7856118552], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2034000.0000, 
sim time next is 2034600.0000, 
raw observation next is [23.0, 48.0, 1.0, 2.0, 0.3062422742506828, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 332536.1913661498, 332536.1913661498, 111611.3391822857], 
processed observation next is [0.0, 0.5652173913043478, 0.6818181818181818, 0.48, 1.0, 1.0, 0.13280284281335347, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12316155235783326, 0.12316155235783326, 0.2722227784933797], 
reward next is 0.7278, 
noisyNet noise sample is [array([-1.6153343], dtype=float32), -0.5549954]. 
=============================================
[2019-03-23 01:07:41,906] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:07:41,916] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1146
[2019-03-23 01:07:41,923] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.66666666666667, 47.0, 1.0, 2.0, 0.3850393719345966, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 435102.3425396871, 435102.3425396874, 124199.7408550445], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2126400.0000, 
sim time next is 2127000.0000, 
raw observation next is [26.83333333333333, 46.0, 1.0, 2.0, 0.3838007529955643, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 433528.267460776, 433528.267460776, 123986.1576735197], 
processed observation next is [0.0, 0.6086956521739131, 0.8560606060606059, 0.46, 1.0, 1.0, 0.2297509412444554, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1605660249854726, 0.1605660249854726, 0.3024052626183407], 
reward next is 0.6976, 
noisyNet noise sample is [array([-0.6011436], dtype=float32), 0.9494877]. 
=============================================
[2019-03-23 01:07:41,941] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[73.817024]
 [73.76575 ]
 [73.7246  ]
 [73.68567 ]
 [73.678406]], R is [[73.83463287]
 [73.79336548]
 [73.75205994]
 [73.71086884]
 [73.66997528]].
[2019-03-23 01:07:50,849] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 7.6169916e-35], sum to 1.0000
[2019-03-23 01:07:50,859] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4111
[2019-03-23 01:07:50,863] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.43333333333334, 67.0, 1.0, 2.0, 0.2582193695727457, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 280375.0153503875, 280375.0153503872, 88648.38994952949], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2586000.0000, 
sim time next is 2586600.0000, 
raw observation next is [18.35, 68.5, 1.0, 2.0, 0.2608340950569788, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 283214.9152164622, 283214.9152164625, 89975.03620160664], 
processed observation next is [1.0, 0.9565217391304348, 0.4704545454545455, 0.685, 1.0, 1.0, 0.07604261882122348, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10489441304313415, 0.10489441304313427, 0.21945130780879668], 
reward next is 0.7805, 
noisyNet noise sample is [array([-0.4965476], dtype=float32), -1.289235]. 
=============================================
[2019-03-23 01:07:53,771] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 7.765936e-31], sum to 1.0000
[2019-03-23 01:07:53,779] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9358
[2019-03-23 01:07:53,786] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 49.0, 1.0, 2.0, 0.4134712509379764, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 449025.594929533, 449025.5949295327, 98349.02047922277], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2293800.0000, 
sim time next is 2294400.0000, 
raw observation next is [20.0, 49.0, 1.0, 2.0, 0.4650070331718907, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 505022.002964083, 505022.002964083, 103737.6719687098], 
processed observation next is [1.0, 0.5652173913043478, 0.5454545454545454, 0.49, 1.0, 1.0, 0.3312587914648633, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1870451862829937, 0.1870451862829937, 0.2530187121188044], 
reward next is 0.7470, 
noisyNet noise sample is [array([0.08845977], dtype=float32), 1.2497427]. 
=============================================
[2019-03-23 01:07:55,783] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-23 01:07:55,786] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 01:07:55,787] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:07:55,787] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 01:07:55,791] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 01:07:55,791] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:07:55,792] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 01:07:55,793] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 01:07:55,793] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:07:55,795] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:07:55,795] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:07:55,820] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run63
[2019-03-23 01:07:55,848] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run63
[2019-03-23 01:07:55,848] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run63
[2019-03-23 01:07:55,890] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run63
[2019-03-23 01:07:55,913] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run63
[2019-03-23 01:08:10,543] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.58009845], dtype=float32), -0.07461728]
[2019-03-23 01:08:10,544] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [29.66666666666667, 42.66666666666667, 1.0, 2.0, 0.7520018020537238, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 857883.382759832, 857883.382759832, 177295.2627471827]
[2019-03-23 01:08:10,546] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 01:08:10,550] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.037288241370376785
[2019-03-23 01:08:25,090] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.58009845], dtype=float32), -0.07461728]
[2019-03-23 01:08:25,091] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.7, 47.0, 1.0, 2.0, 0.3099276604503928, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 336517.1810729805, 336517.1810729805, 109063.0170436493]
[2019-03-23 01:08:25,092] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 01:08:25,096] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.9611187741912646
[2019-03-23 01:08:46,045] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.58009845], dtype=float32), -0.07461728]
[2019-03-23 01:08:46,046] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.65176413333334, 85.82356962, 1.0, 2.0, 0.5845408639325265, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 666856.2440288366, 666856.2440288363, 156317.2899509516]
[2019-03-23 01:08:46,046] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 01:08:46,051] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.12910780100099373
[2019-03-23 01:09:07,843] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.58009845], dtype=float32), -0.07461728]
[2019-03-23 01:09:07,845] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [23.13487867, 85.05693364999999, 1.0, 2.0, 0.4762038385226242, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 543167.9329179652, 543167.9329179652, 143340.7269174829]
[2019-03-23 01:09:07,846] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 01:09:07,849] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.8732975067594437
[2019-03-23 01:09:11,760] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.58009845], dtype=float32), -0.07461728]
[2019-03-23 01:09:11,762] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [24.61666666666667, 75.33333333333334, 1.0, 2.0, 0.6108732821148265, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9738142995479249, 6.911199999999999, 6.9112, 77.3284087418987, 1244415.099856319, 1244415.099856319, 276026.3812166415]
[2019-03-23 01:09:11,764] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 01:09:11,769] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.6577708e-38 1.0000000e+00 2.4325607e-34 0.0000000e+00 4.5915750e-23], sampled 0.26178816309665176
[2019-03-23 01:09:11,770] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1244415.099856319 W.
[2019-03-23 01:09:39,355] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.58009845], dtype=float32), -0.07461728]
[2019-03-23 01:09:39,356] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.05, 96.0, 1.0, 2.0, 0.4364758971397096, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 496616.6179523598, 496616.6179523601, 131385.0327189366]
[2019-03-23 01:09:39,360] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 01:09:39,363] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.26072548129474515
[2019-03-23 01:09:44,047] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8570.4787 1683579848.9606 214.0000
[2019-03-23 01:09:44,114] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8592.8737 1706200825.6989 465.0000
[2019-03-23 01:09:44,153] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9057.0586 1656443078.0244 80.0000
[2019-03-23 01:09:44,155] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8508.4528 1773463374.2284 173.0000
[2019-03-23 01:09:44,228] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8852.6925 1664051680.8275 105.0000
[2019-03-23 01:09:45,247] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 1550000, evaluation results [1550000.0, 8508.45277065677, 1773463374.2284098, 173.0, 9057.05855481395, 1656443078.0244372, 80.0, 8852.692524936243, 1664051680.8275282, 105.0, 8592.873732714792, 1706200825.698916, 465.0, 8570.478727897242, 1683579848.9606183, 214.0]
[2019-03-23 01:09:47,554] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.0895817e-35 0.0000000e+00 1.0933430e-17], sum to 1.0000
[2019-03-23 01:09:47,556] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6501
[2019-03-23 01:09:47,567] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 49.0, 1.0, 2.0, 0.4600270761299203, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 499610.7294136912, 499610.7294136915, 103469.0741318445], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2371200.0000, 
sim time next is 2371800.0000, 
raw observation next is [20.0, 49.0, 1.0, 2.0, 0.4570293561638016, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 496353.4045015313, 496353.4045015316, 103112.0627637181], 
processed observation next is [1.0, 0.43478260869565216, 0.5454545454545454, 0.49, 1.0, 1.0, 0.32128669520475195, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1838345942598264, 0.18383459425982654, 0.2514928360090685], 
reward next is 0.7485, 
noisyNet noise sample is [array([0.46132794], dtype=float32), -1.7551247]. 
=============================================
[2019-03-23 01:09:53,501] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 8.777842e-36 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 01:09:53,511] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1555
[2019-03-23 01:09:53,517] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 89.0, 1.0, 2.0, 0.5226026560933636, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 595377.4989722532, 595377.4989722532, 145518.4978041883], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3109800.0000, 
sim time next is 3110400.0000, 
raw observation next is [23.0, 89.0, 1.0, 2.0, 0.5211429732521016, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 593714.8035230673, 593714.8035230673, 145339.8717623487], 
processed observation next is [1.0, 0.0, 0.6818181818181818, 0.89, 1.0, 1.0, 0.4014287165651269, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2198943716752101, 0.2198943716752101, 0.3544874921032895], 
reward next is 0.6455, 
noisyNet noise sample is [array([0.83304936], dtype=float32), 0.16142143]. 
=============================================
[2019-03-23 01:10:05,346] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:10:05,354] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1440
[2019-03-23 01:10:05,364] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.7, 99.66666666666666, 1.0, 2.0, 0.329066468494219, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 361942.5240247414, 361942.5240247414, 114821.4729871996], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2698800.0000, 
sim time next is 2699400.0000, 
raw observation next is [16.75, 99.83333333333334, 1.0, 2.0, 0.3300053771294053, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 363412.8142403244, 363412.8142403247, 115055.3755422898], 
processed observation next is [0.0, 0.21739130434782608, 0.3977272727272727, 0.9983333333333334, 1.0, 1.0, 0.16250672141175662, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13459733860752757, 0.13459733860752768, 0.28062286717631657], 
reward next is 0.7194, 
noisyNet noise sample is [array([0.4099763], dtype=float32), 0.53103346]. 
=============================================
[2019-03-23 01:10:07,344] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:10:07,353] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2176
[2019-03-23 01:10:07,364] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.66666666666666, 62.33333333333333, 1.0, 2.0, 0.4540938501541351, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 517949.8454295654, 517949.8454295654, 134895.4790329382], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2734800.0000, 
sim time next is 2735400.0000, 
raw observation next is [25.83333333333334, 61.66666666666666, 1.0, 2.0, 0.4550895150030776, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 519122.2280392279, 519122.2280392279, 135092.0012372903], 
processed observation next is [0.0, 0.6521739130434783, 0.8106060606060609, 0.6166666666666666, 1.0, 1.0, 0.31886189375384694, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1922674918663807, 0.1922674918663807, 0.3294926859446105], 
reward next is 0.6705, 
noisyNet noise sample is [array([0.65849656], dtype=float32), -1.1609759]. 
=============================================
[2019-03-23 01:10:24,437] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 5.9455155e-25], sum to 1.0000
[2019-03-23 01:10:24,445] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3910
[2019-03-23 01:10:24,454] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.5, 91.0, 1.0, 2.0, 0.3940419402645693, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 433069.2221214545, 433069.2221214548, 119710.9644436762], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3033000.0000, 
sim time next is 3033600.0000, 
raw observation next is [17.33333333333333, 92.0, 1.0, 2.0, 0.3740748820799013, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 410596.1727665297, 410596.17276653, 117935.0126010674], 
processed observation next is [1.0, 0.08695652173913043, 0.42424242424242403, 0.92, 1.0, 1.0, 0.21759360259987662, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1520726565801962, 0.1520726565801963, 0.2876463721977254], 
reward next is 0.7124, 
noisyNet noise sample is [array([-0.2331509], dtype=float32), -1.1299311]. 
=============================================
[2019-03-23 01:10:37,396] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.4763238e-26], sum to 1.0000
[2019-03-23 01:10:37,408] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4126
[2019-03-23 01:10:37,413] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 57.5, 1.0, 2.0, 0.324491268663386, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 355298.9740986379, 355298.9740986376, 113892.8544116849], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3269400.0000, 
sim time next is 3270000.0000, 
raw observation next is [22.0, 58.00000000000001, 1.0, 2.0, 0.3253366320230748, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 356713.1134390372, 356713.1134390375, 114130.8689905241], 
processed observation next is [0.0, 0.8695652173913043, 0.6363636363636364, 0.5800000000000001, 1.0, 1.0, 0.15667079002884346, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13211596794038413, 0.13211596794038427, 0.27836797314761974], 
reward next is 0.7216, 
noisyNet noise sample is [array([0.86242914], dtype=float32), -2.5053325]. 
=============================================
[2019-03-23 01:10:37,428] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[72.5448 ]
 [72.66342]
 [72.73688]
 [72.79696]
 [72.83943]], R is [[72.46077728]
 [72.45838165]
 [72.45661163]
 [72.45541382]
 [72.45468903]].
[2019-03-23 01:10:37,730] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-23 01:10:37,732] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 01:10:37,732] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:10:37,733] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 01:10:37,734] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:10:37,736] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 01:10:37,736] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:10:37,737] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 01:10:37,738] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 01:10:37,739] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:10:37,743] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:10:37,771] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run64
[2019-03-23 01:10:37,797] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run64
[2019-03-23 01:10:37,835] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run64
[2019-03-23 01:10:37,857] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run64
[2019-03-23 01:10:37,857] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run64
[2019-03-23 01:10:56,177] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.64307606], dtype=float32), -0.094911225]
[2019-03-23 01:10:56,177] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [26.40974341666667, 89.44113584666667, 1.0, 2.0, 0.6961386531933998, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 782237.8192929794, 782237.8192929791, 177337.4567158492]
[2019-03-23 01:10:56,178] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 01:10:56,183] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.3540343e-36 1.0000000e+00 7.7073741e-33 4.7479977e-32 3.2838739e-19], sampled 0.39419770810418897
[2019-03-23 01:11:02,380] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.64307606], dtype=float32), -0.094911225]
[2019-03-23 01:11:02,380] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.82143923, 59.74898818, 1.0, 2.0, 0.3277029578065621, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 355823.1822701754, 355823.182270175, 103579.2545181293]
[2019-03-23 01:11:02,382] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 01:11:02,385] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 7.018906e-32], sampled 0.8827141266691528
[2019-03-23 01:12:00,668] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.64307606], dtype=float32), -0.094911225]
[2019-03-23 01:12:00,668] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [25.72650007, 36.26687418, 1.0, 2.0, 0.4359435392115134, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 473537.1445226054, 473537.1445226051, 125699.4752154643]
[2019-03-23 01:12:00,668] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 01:12:00,673] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.6089059e-32], sampled 0.29864462144898185
[2019-03-23 01:12:10,938] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.64307606], dtype=float32), -0.094911225]
[2019-03-23 01:12:10,939] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.8, 89.0, 1.0, 2.0, 0.3658745487491611, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 408551.7078697689, 408551.7078697692, 120028.16015193]
[2019-03-23 01:12:10,940] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 01:12:10,944] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 1.946414e-38 5.177143e-29], sampled 0.8136688294894842
[2019-03-23 01:12:23,872] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8591.2438 1706283482.2077 465.0000
[2019-03-23 01:12:24,114] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8497.6984 1777358340.9718 169.0000
[2019-03-23 01:12:24,169] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9058.0329 1656802266.9555 68.0000
[2019-03-23 01:12:24,292] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8849.8276 1664255106.4627 105.0000
[2019-03-23 01:12:24,327] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8571.6879 1684259277.4785 200.0000
[2019-03-23 01:12:25,343] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 1575000, evaluation results [1575000.0, 8497.69838168822, 1777358340.9717941, 169.0, 9058.032890005059, 1656802266.9554727, 68.0, 8849.827576800239, 1664255106.4627442, 105.0, 8591.243823297678, 1706283482.2076914, 465.0, 8571.687933860563, 1684259277.4785318, 200.0]
[2019-03-23 01:12:30,667] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.3734792e-33 6.2023044e-37], sum to 1.0000
[2019-03-23 01:12:30,675] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8957
[2019-03-23 01:12:30,682] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.83333333333334, 89.83333333333334, 1.0, 2.0, 0.5201249252244049, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 592635.5579594212, 592635.557959421, 145139.7216257142], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3453000.0000, 
sim time next is 3453600.0000, 
raw observation next is [22.66666666666667, 90.66666666666667, 1.0, 2.0, 0.5196851183335248, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 592248.3834367241, 592248.3834367241, 144971.9816011903], 
processed observation next is [1.0, 1.0, 0.6666666666666669, 0.9066666666666667, 1.0, 1.0, 0.399606397916906, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21935125312471263, 0.21935125312471263, 0.3535901990272934], 
reward next is 0.6464, 
noisyNet noise sample is [array([0.6064038], dtype=float32), 1.2392079]. 
=============================================
[2019-03-23 01:12:32,547] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 2.0880831e-33], sum to 1.0000
[2019-03-23 01:12:32,555] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8751
[2019-03-23 01:12:32,559] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.33333333333334, 70.0, 1.0, 2.0, 0.5077072170012702, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 577207.8195411842, 577207.8195411842, 144563.5845519713], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3433200.0000, 
sim time next is 3433800.0000, 
raw observation next is [26.16666666666667, 72.0, 1.0, 2.0, 0.5235781863549209, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 594721.86500716, 594721.86500716, 146785.1070341194], 
processed observation next is [1.0, 0.7391304347826086, 0.825757575757576, 0.72, 1.0, 1.0, 0.4044727329436511, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22026735741005926, 0.22026735741005926, 0.35801245618077904], 
reward next is 0.6420, 
noisyNet noise sample is [array([1.4985815], dtype=float32), 1.1156723]. 
=============================================
[2019-03-23 01:12:35,336] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.2076707e-31 6.3302548e-38], sum to 1.0000
[2019-03-23 01:12:35,347] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9852
[2019-03-23 01:12:35,354] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.556835374992577, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 635353.892598803, 635353.892598803, 148377.6943113258], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3471600.0000, 
sim time next is 3472200.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.5437153171201032, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 620376.8847661666, 620376.8847661668, 146749.1050586399], 
processed observation next is [1.0, 0.17391304347826086, 0.5909090909090909, 1.0, 1.0, 1.0, 0.429644146400129, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2297692165800617, 0.22976921658006177, 0.3579246464844875], 
reward next is 0.6421, 
noisyNet noise sample is [array([-0.12453784], dtype=float32), 1.0279728]. 
=============================================
[2019-03-23 01:12:46,670] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.7857828e-30 2.3323185e-30], sum to 1.0000
[2019-03-23 01:12:46,678] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6654
[2019-03-23 01:12:46,682] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.5057432360145309, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 577034.9952708326, 577034.9952708326, 142171.4054513477], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3656400.0000, 
sim time next is 3657000.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.4990947952282072, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 569446.677657862, 569446.677657862, 141391.8853399311], 
processed observation next is [1.0, 0.30434782608695654, 0.5909090909090909, 1.0, 1.0, 1.0, 0.37386849403525896, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21090617691031924, 0.21090617691031924, 0.3448582569266612], 
reward next is 0.6551, 
noisyNet noise sample is [array([-0.47173443], dtype=float32), -2.534798]. 
=============================================
[2019-03-23 01:12:46,692] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[65.95312]
 [65.74747]
 [65.63653]
 [65.25065]
 [65.16674]], R is [[66.13052368]
 [66.12245941]
 [66.11103058]
 [66.10037994]
 [66.08004761]].
[2019-03-23 01:12:46,815] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:12:46,822] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0882
[2019-03-23 01:12:46,826] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 88.0, 1.0, 2.0, 0.298893741974346, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 324554.0524388847, 324554.0524388844, 109792.938469774], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3817200.0000, 
sim time next is 3817800.0000, 
raw observation next is [17.0, 88.0, 1.0, 2.0, 0.2989248799603768, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 324587.8749343009, 324587.8749343006, 109788.4890923011], 
processed observation next is [0.0, 0.17391304347826086, 0.4090909090909091, 0.88, 1.0, 1.0, 0.123656099950471, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12021773145714848, 0.12021773145714837, 0.267776802664149], 
reward next is 0.7322, 
noisyNet noise sample is [array([-0.28823486], dtype=float32), 1.175277]. 
=============================================
[2019-03-23 01:12:58,099] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:12:58,109] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0750
[2019-03-23 01:12:58,112] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 73.0, 1.0, 2.0, 0.2965236362068765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 321979.6188707367, 321979.6188707367, 110959.5906936831], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3847800.0000, 
sim time next is 3848400.0000, 
raw observation next is [19.0, 73.0, 1.0, 2.0, 0.2970737408782811, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 322577.1470793688, 322577.1470793688, 110996.2061466117], 
processed observation next is [0.0, 0.5652173913043478, 0.5, 0.73, 1.0, 1.0, 0.12134217609785135, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11947301743680326, 0.11947301743680326, 0.2707224540161261], 
reward next is 0.7293, 
noisyNet noise sample is [array([-0.5741741], dtype=float32), 0.5846808]. 
=============================================
[2019-03-23 01:13:02,408] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:13:02,419] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3952
[2019-03-23 01:13:02,424] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 45.0, 1.0, 2.0, 0.3491444711848279, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 390517.5544572884, 390517.5544572884, 118965.7808200755], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3939000.0000, 
sim time next is 3939600.0000, 
raw observation next is [26.0, 45.0, 1.0, 2.0, 0.349463991999397, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 390875.1062838271, 390875.1062838274, 118991.6286238038], 
processed observation next is [0.0, 0.6086956521739131, 0.8181818181818182, 0.45, 1.0, 1.0, 0.18682998999924622, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14476855788289894, 0.14476855788289902, 0.2902234844483019], 
reward next is 0.7098, 
noisyNet noise sample is [array([-1.5756719], dtype=float32), -1.522868]. 
=============================================
[2019-03-23 01:13:11,344] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.2673109e-36 1.0000000e+00 1.0869234e-30 2.9378228e-27 1.0366332e-19], sum to 1.0000
[2019-03-23 01:13:11,351] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5740
[2019-03-23 01:13:11,359] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 94.0, 1.0, 2.0, 0.6279035806095017, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 708244.1286991709, 708244.1286991709, 149118.0512338658], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4093200.0000, 
sim time next is 4093800.0000, 
raw observation next is [19.33333333333334, 91.33333333333334, 1.0, 2.0, 0.6303469408173203, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 711415.3413033172, 711415.341303317, 149629.9820141653], 
processed observation next is [1.0, 0.391304347826087, 0.5151515151515155, 0.9133333333333334, 1.0, 1.0, 0.5379336760216504, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.263487163445673, 0.26348716344567297, 0.36495117564430557], 
reward next is 0.6350, 
noisyNet noise sample is [array([1.196965], dtype=float32), 1.2946781]. 
=============================================
[2019-03-23 01:13:16,029] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 7.0485604e-38 3.2839099e-35 1.6763671e-36], sum to 1.0000
[2019-03-23 01:13:16,037] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9701
[2019-03-23 01:13:16,043] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 83.0, 1.0, 2.0, 0.596867339172074, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 677117.1103437749, 677117.1103437749, 147719.4138666485], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4882800.0000, 
sim time next is 4883400.0000, 
raw observation next is [21.0, 83.0, 1.0, 2.0, 0.5456204096366291, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 618777.3097087234, 618777.3097087234, 141605.753382579], 
processed observation next is [1.0, 0.5217391304347826, 0.5909090909090909, 0.83, 1.0, 1.0, 0.43202551204578626, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22917678137360128, 0.22917678137360128, 0.34537988629897315], 
reward next is 0.6546, 
noisyNet noise sample is [array([-0.18320549], dtype=float32), 0.4871816]. 
=============================================
[2019-03-23 01:13:18,234] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-23 01:13:18,236] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 01:13:18,237] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 01:13:18,238] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:13:18,238] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 01:13:18,239] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:13:18,241] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 01:13:18,241] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:13:18,243] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:13:18,244] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 01:13:18,246] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:13:18,274] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run65
[2019-03-23 01:13:18,301] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run65
[2019-03-23 01:13:18,301] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run65
[2019-03-23 01:13:18,323] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run65
[2019-03-23 01:13:18,349] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run65
[2019-03-23 01:13:33,065] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.6979656], dtype=float32), -0.11134596]
[2019-03-23 01:13:33,066] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [14.396890605, 99.47485179833333, 1.0, 2.0, 0.2745845765308296, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 298132.4014724711, 298132.4014724708, 92869.46582743831]
[2019-03-23 01:13:33,067] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 01:13:33,070] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.36223687733040544
[2019-03-23 01:13:45,771] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.6979656], dtype=float32), -0.11134596]
[2019-03-23 01:13:45,772] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.03333333333333, 89.66666666666667, 1.0, 2.0, 0.423177006122048, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 479084.6163385482, 479084.6163385478, 132574.7389084116]
[2019-03-23 01:13:45,773] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 01:13:45,775] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.512805868314024
[2019-03-23 01:13:50,166] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.6979656], dtype=float32), -0.11134596]
[2019-03-23 01:13:50,169] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [14.83333333333333, 89.00000000000001, 1.0, 2.0, 0.2363924363373098, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 256669.041812319, 256669.0418123187, 80442.39484369896]
[2019-03-23 01:13:50,171] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 01:13:50,174] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.2540350974103023
[2019-03-23 01:14:09,994] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.6979656], dtype=float32), -0.11134596]
[2019-03-23 01:14:09,996] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.86666666666667, 89.5, 1.0, 2.0, 0.4826238009468531, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 550635.0999505303, 550635.0999505303, 142939.0137247679]
[2019-03-23 01:14:09,997] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 01:14:10,002] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.7345097629120676
[2019-03-23 01:14:41,691] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.6979656], dtype=float32), -0.11134596]
[2019-03-23 01:14:41,693] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.978494035, 69.83543800666666, 1.0, 2.0, 0.3273828807489648, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 355475.5365794459, 355475.5365794455, 111339.1224243176]
[2019-03-23 01:14:41,694] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 01:14:41,697] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.12324962362315117
[2019-03-23 01:14:43,722] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.6979656], dtype=float32), -0.11134596]
[2019-03-23 01:14:43,726] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.3, 76.5, 1.0, 2.0, 0.5816832752466051, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 640557.0406077611, 640557.0406077608, 137375.8803880771]
[2019-03-23 01:14:43,728] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 01:14:43,729] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.7670098745440627
[2019-03-23 01:14:46,700] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.6979656], dtype=float32), -0.11134596]
[2019-03-23 01:14:46,702] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [25.0, 76.0, 1.0, 2.0, 0.5306374092415602, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 604106.6554694513, 604106.6554694513, 146853.6684796929]
[2019-03-23 01:14:46,702] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 01:14:46,705] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.49088443450179486
[2019-03-23 01:14:50,594] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.6979656], dtype=float32), -0.11134596]
[2019-03-23 01:14:50,595] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.16666666666667, 81.16666666666667, 1.0, 2.0, 0.3615132800097612, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 405189.7624325512, 405189.7624325512, 124685.9141523104]
[2019-03-23 01:14:50,597] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 01:14:50,600] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.15792631091078413
[2019-03-23 01:15:02,412] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.6979656], dtype=float32), -0.11134596]
[2019-03-23 01:15:02,413] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.8, 57.66666666666667, 1.0, 2.0, 0.3549646853597179, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 398390.3461689812, 398390.3461689809, 124408.2768169429]
[2019-03-23 01:15:02,416] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 01:15:02,418] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.31364582693131227
[2019-03-23 01:15:06,708] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9057.0586 1656443078.0244 80.0000
[2019-03-23 01:15:07,112] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8851.9735 1664101423.8647 105.0000
[2019-03-23 01:15:07,282] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8592.8737 1706200825.6989 465.0000
[2019-03-23 01:15:07,323] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8507.7271 1773514361.6667 173.0000
[2019-03-23 01:15:07,488] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8569.7595 1683629455.5724 214.0000
[2019-03-23 01:15:08,504] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 1600000, evaluation results [1600000.0, 8507.727149272585, 1773514361.6667252, 173.0, 9057.05855481395, 1656443078.0244372, 80.0, 8851.973532677643, 1664101423.8646872, 105.0, 8592.873732714792, 1706200825.698916, 465.0, 8569.759499047412, 1683629455.5724304, 214.0]
[2019-03-23 01:15:10,442] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:15:10,449] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8973
[2019-03-23 01:15:10,456] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.16666666666667, 82.33333333333333, 1.0, 2.0, 0.4519359174699271, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 515058.2956889392, 515058.2956889389, 133913.3874377168], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4408800.0000, 
sim time next is 4409400.0000, 
raw observation next is [22.08333333333334, 82.66666666666667, 1.0, 2.0, 0.4501315958248431, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 512940.0684763797, 512940.0684763797, 133641.2210744674], 
processed observation next is [0.0, 0.0, 0.6401515151515155, 0.8266666666666667, 1.0, 1.0, 0.3126644947810538, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18997780313939988, 0.18997780313939988, 0.3259541977426034], 
reward next is 0.6740, 
noisyNet noise sample is [array([2.9747593], dtype=float32), 0.21530153]. 
=============================================
[2019-03-23 01:15:12,064] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 7.4956334e-37 0.0000000e+00], sum to 1.0000
[2019-03-23 01:15:12,070] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3680
[2019-03-23 01:15:12,074] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.66666666666666, 45.83333333333333, 1.0, 2.0, 0.6519432135514522, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 736162.4219682771, 736162.4219682773, 152475.9477386379], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4279800.0000, 
sim time next is 4280400.0000, 
raw observation next is [27.0, 45.0, 1.0, 2.0, 0.6565183932917281, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 742142.4779288395, 742142.4779288395, 153494.7013088579], 
processed observation next is [1.0, 0.5652173913043478, 0.8636363636363636, 0.45, 1.0, 1.0, 0.5706479916146601, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.27486758441808873, 0.27486758441808873, 0.3743773202655071], 
reward next is 0.6256, 
noisyNet noise sample is [array([0.22362012], dtype=float32), 1.095224]. 
=============================================
[2019-03-23 01:15:12,763] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 7.1592691e-35 3.3388066e-35], sum to 1.0000
[2019-03-23 01:15:12,766] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4280
[2019-03-23 01:15:12,773] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.83333333333333, 47.5, 1.0, 2.0, 0.7477705406904742, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 823767.4823943279, 823767.4823943279, 156355.1618308878], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4637400.0000, 
sim time next is 4638000.0000, 
raw observation next is [23.66666666666666, 48.0, 1.0, 2.0, 0.6959591994142409, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 765805.3973189397, 765805.3973189397, 149804.7821161551], 
processed observation next is [1.0, 0.6956521739130435, 0.7121212121212118, 0.48, 1.0, 1.0, 0.6199489992678011, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2836316286366443, 0.2836316286366443, 0.3653775173564759], 
reward next is 0.6346, 
noisyNet noise sample is [array([-0.20723349], dtype=float32), -0.05835817]. 
=============================================
[2019-03-23 01:15:12,781] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[62.55705 ]
 [62.740017]
 [62.974747]
 [63.27859 ]
 [63.598003]], R is [[63.13343811]
 [63.12075043]
 [63.1115036 ]
 [63.10870743]
 [63.11563492]].
[2019-03-23 01:15:15,101] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 2.334178e-08], sum to 1.0000
[2019-03-23 01:15:15,112] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0583
[2019-03-23 01:15:15,123] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1175169.823618361 W.
[2019-03-23 01:15:15,127] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.0, 58.0, 1.0, 2.0, 0.3445425188983509, 1.0, 2.0, 0.3445425188983509, 1.0, 1.0, 0.6979344793976853, 6.911199999999999, 6.9112, 77.3421103, 1175169.823618361, 1175169.823618361, 276614.4957516463], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4359600.0000, 
sim time next is 4360200.0000, 
raw observation next is [27.0, 58.0, 1.0, 2.0, 0.5828839217606572, 1.0, 2.0, 0.5828839217606572, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1325989.910741649, 1325989.910741649, 252369.2349025144], 
processed observation next is [1.0, 0.4782608695652174, 0.8636363636363636, 0.58, 1.0, 1.0, 0.4786049022008214, 1.0, 1.0, 0.4786049022008214, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.49110737434875895, 0.49110737434875895, 0.6155347192744254], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2863256], dtype=float32), -0.55031854]. 
=============================================
[2019-03-23 01:15:19,833] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.8853275e-35 6.5748059e-27 5.3028272e-29 0.0000000e+00 1.0000000e+00], sum to 1.0000
[2019-03-23 01:15:19,839] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0317
[2019-03-23 01:15:19,847] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [21.33333333333334, 83.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.3421103, 470879.8330287726, 470879.8330287726, 192077.6577994337], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4432800.0000, 
sim time next is 4433400.0000, 
raw observation next is [21.5, 83.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.3421103, 476409.7929586985, 476409.7929586988, 193479.9582529026], 
processed observation next is [0.0, 0.30434782608695654, 0.6136363636363636, 0.83, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.17644807146618463, 0.17644807146618474, 0.4719023372022015], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.6471907], dtype=float32), 1.3202152]. 
=============================================
[2019-03-23 01:15:19,977] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.4552066e-33 1.0000000e+00 6.4237407e-30 2.5849983e-25 1.9778691e-19], sum to 1.0000
[2019-03-23 01:15:19,989] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1986
[2019-03-23 01:15:19,993] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.83333333333333, 74.66666666666667, 1.0, 2.0, 0.4626067143954578, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 527789.3961995936, 527789.3961995936, 136170.5452206318], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4441800.0000, 
sim time next is 4442400.0000, 
raw observation next is [24.0, 74.0, 1.0, 2.0, 0.4656966369495772, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 531347.9162433195, 531347.9162433193, 136639.6898242805], 
processed observation next is [0.0, 0.43478260869565216, 0.7272727272727273, 0.74, 1.0, 1.0, 0.33212079618697143, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19679552453456278, 0.1967955245345627, 0.33326753615678173], 
reward next is 0.6667, 
noisyNet noise sample is [array([-0.07047144], dtype=float32), 0.61822337]. 
=============================================
[2019-03-23 01:15:39,326] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.8028257e-29 5.8795132e-02 7.7306386e-14 0.0000000e+00 9.4120491e-01], sum to 1.0000
[2019-03-23 01:15:39,332] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3727
[2019-03-23 01:15:39,340] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.7, 65.66666666666667, 1.0, 2.0, 0.4583090175274642, 1.0, 2.0, 0.4583090175274642, 1.0, 2.0, 0.9273330402776039, 6.9112, 6.9112, 77.3421103, 1546307.703785803, 1546307.703785803, 337171.0242536192], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5397600.0000, 
sim time next is 5398200.0000, 
raw observation next is [27.7, 65.0, 1.0, 2.0, 0.4560257722694167, 1.0, 2.0, 0.4560257722694167, 1.0, 2.0, 0.9227131687807099, 6.9112, 6.9112, 77.3421103, 1538593.701701974, 1538593.701701974, 335934.6958385436], 
processed observation next is [1.0, 0.4782608695652174, 0.8954545454545454, 0.65, 1.0, 1.0, 0.32003221533677084, 1.0, 1.0, 0.32003221533677084, 1.0, 1.0, 0.8895902411152999, 0.0, 0.0, 0.5085185399722538, 0.5698495191488793, 0.5698495191488793, 0.8193529166793746], 
reward next is 0.1806, 
noisyNet noise sample is [array([2.240231], dtype=float32), 0.74635214]. 
=============================================
[2019-03-23 01:15:40,857] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 4.8608737e-31 0.0000000e+00 1.1217062e-34], sum to 1.0000
[2019-03-23 01:15:40,866] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9090
[2019-03-23 01:15:40,876] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1098912.510464999 W.
[2019-03-23 01:15:40,882] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.5, 97.0, 1.0, 2.0, 0.9630557484055919, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1098912.510464999, 1098912.510464999, 212217.5575427314], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4800600.0000, 
sim time next is 4801200.0000, 
raw observation next is [21.66666666666667, 96.0, 1.0, 2.0, 0.4884939646981883, 1.0, 1.0, 0.4884939646981883, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1111023.290672842, 1111023.290672842, 228521.4426735726], 
processed observation next is [1.0, 0.5652173913043478, 0.6212121212121214, 0.96, 1.0, 1.0, 0.3606174558727353, 1.0, 0.5, 0.3606174558727353, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.41149010765660815, 0.41149010765660815, 0.5573693723745673], 
reward next is 0.4426, 
noisyNet noise sample is [array([-0.21918896], dtype=float32), -0.034630787]. 
=============================================
[2019-03-23 01:15:40,924] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 8.940038e-31 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 01:15:40,932] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2149
[2019-03-23 01:15:40,935] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 83.0, 1.0, 2.0, 0.5534328258519775, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 604564.1593963451, 604564.1593963455, 132896.4017300949], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4960800.0000, 
sim time next is 4961400.0000, 
raw observation next is [18.16666666666667, 81.33333333333334, 1.0, 2.0, 0.6041659857010574, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 659819.243135082, 659819.243135082, 137945.4733724558], 
processed observation next is [1.0, 0.43478260869565216, 0.4621212121212123, 0.8133333333333335, 1.0, 1.0, 0.5052074821263217, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.24437749745743775, 0.24437749745743775, 0.3364523740791605], 
reward next is 0.6635, 
noisyNet noise sample is [array([-0.4978345], dtype=float32), -0.48727426]. 
=============================================
[2019-03-23 01:15:45,221] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 7.4817154e-31 4.3078755e-31 0.0000000e+00], sum to 1.0000
[2019-03-23 01:15:45,235] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6775
[2019-03-23 01:15:45,239] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 75.5, 1.0, 2.0, 0.8045318602866399, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 915671.1048856424, 915671.1048856424, 177931.2587871032], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4897800.0000, 
sim time next is 4898400.0000, 
raw observation next is [22.33333333333334, 76.33333333333334, 1.0, 2.0, 0.8282519989132043, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 942502.5012604315, 942502.5012604318, 181405.3786250471], 
processed observation next is [1.0, 0.6956521739130435, 0.6515151515151518, 0.7633333333333334, 1.0, 1.0, 0.7853149986415053, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3490750004668265, 0.3490750004668266, 0.44245214298791974], 
reward next is 0.5575, 
noisyNet noise sample is [array([-0.02855638], dtype=float32), -0.08239655]. 
=============================================
[2019-03-23 01:15:51,037] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:15:51,045] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5732
[2019-03-23 01:15:51,055] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.16666666666667, 81.16666666666667, 1.0, 2.0, 0.2849549493128204, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 309413.7862923166, 309413.7862923169, 97527.44104880404], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5007000.0000, 
sim time next is 5007600.0000, 
raw observation next is [17.0, 82.0, 1.0, 2.0, 0.2806492166611334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 304737.0103567261, 304737.0103567261, 96215.29007976975], 
processed observation next is [1.0, 1.0, 0.4090909090909091, 0.82, 1.0, 1.0, 0.10081152082641674, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11286555939138004, 0.11286555939138004, 0.23467143921895062], 
reward next is 0.7653, 
noisyNet noise sample is [array([-1.1633967], dtype=float32), -0.32793355]. 
=============================================
[2019-03-23 01:15:51,813] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:15:51,823] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3299
[2019-03-23 01:15:51,830] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.46666666666667, 75.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 188092.5681780491, 188092.5681780493, 63807.2267195419], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5694600.0000, 
sim time next is 5695200.0000, 
raw observation next is [12.2, 77.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 184565.4786423804, 184565.4786423801, 63129.63764594678], 
processed observation next is [0.0, 0.9565217391304348, 0.1909090909090909, 0.77, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.06835758468236311, 0.068357584682363, 0.15397472596572384], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.6005291], dtype=float32), -0.051292095]. 
=============================================
[2019-03-23 01:15:56,076] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:15:56,085] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2480
[2019-03-23 01:15:56,089] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 54.0, 1.0, 2.0, 0.401212212761002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 455655.1357297687, 455655.1357297684, 127194.2207238257], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5058600.0000, 
sim time next is 5059200.0000, 
raw observation next is [26.0, 54.00000000000001, 1.0, 2.0, 0.4022176591782177, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 456810.4835380655, 456810.4835380655, 127299.7283272064], 
processed observation next is [0.0, 0.5652173913043478, 0.8181818181818182, 0.54, 1.0, 1.0, 0.2527720739727721, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1691890679770613, 0.1691890679770613, 0.310487142261479], 
reward next is 0.6895, 
noisyNet noise sample is [array([0.15899397], dtype=float32), -1.001629]. 
=============================================
[2019-03-23 01:15:58,143] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:15:58,151] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5553
[2019-03-23 01:15:58,157] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.16666666666667, 87.16666666666667, 1.0, 2.0, 0.3944512875533671, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 445882.5616214953, 445882.561621495, 125132.8079156119], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5105400.0000, 
sim time next is 5106000.0000, 
raw observation next is [20.33333333333334, 86.33333333333334, 1.0, 2.0, 0.3943896596013369, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 446032.0009268151, 446032.0009268151, 125259.8898420177], 
processed observation next is [0.0, 0.08695652173913043, 0.5606060606060609, 0.8633333333333334, 1.0, 1.0, 0.24298707450167106, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1651970373803019, 0.1651970373803019, 0.3055119264439456], 
reward next is 0.6945, 
noisyNet noise sample is [array([-0.4745267], dtype=float32), -0.37586382]. 
=============================================
[2019-03-23 01:15:58,182] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[68.142365]
 [67.632835]
 [67.64681 ]
 [67.69833 ]
 [67.7606  ]], R is [[67.98170471]
 [67.99668884]
 [68.01117706]
 [68.02346802]
 [68.03388977]].
[2019-03-23 01:16:01,021] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-23 01:16:01,023] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 01:16:01,024] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 01:16:01,024] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:16:01,025] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:16:01,025] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 01:16:01,027] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 01:16:01,026] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 01:16:01,029] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:16:01,030] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:16:01,031] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:16:01,050] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run66
[2019-03-23 01:16:01,078] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run66
[2019-03-23 01:16:01,105] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run66
[2019-03-23 01:16:01,127] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run66
[2019-03-23 01:16:01,151] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run66
[2019-03-23 01:16:07,501] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.74125534], dtype=float32), -0.07780408]
[2019-03-23 01:16:07,502] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [17.62341317, 49.93182982666667, 1.0, 2.0, 0.2851569823247944, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 309614.4324250314, 309614.432425031, 84139.4779991204]
[2019-03-23 01:16:07,502] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 01:16:07,504] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.5777073416984967
[2019-03-23 01:16:33,487] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.74125534], dtype=float32), -0.07780408]
[2019-03-23 01:16:33,489] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [13.1, 81.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 204790.9927798323, 204790.9927798323, 72405.87683667474]
[2019-03-23 01:16:33,491] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 01:16:33,494] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.9589649209711244
[2019-03-23 01:16:42,714] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.74125534], dtype=float32), -0.07780408]
[2019-03-23 01:16:42,715] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.43973839, 89.08038733, 1.0, 2.0, 0.5877232066713056, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 663060.083104617, 663060.0831046166, 160897.4818761109]
[2019-03-23 01:16:42,717] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 01:16:42,719] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.23460187805626043
[2019-03-23 01:16:48,222] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.74125534], dtype=float32), -0.07780408]
[2019-03-23 01:16:48,223] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [24.33333333333334, 54.66666666666667, 1.0, 2.0, 0.3675222316295679, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 412449.1096275202, 412449.1096275199, 121116.6582295992]
[2019-03-23 01:16:48,224] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 01:16:48,230] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.7878720393407628
[2019-03-23 01:17:36,017] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.74125534], dtype=float32), -0.07780408]
[2019-03-23 01:17:36,018] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [16.01666666666667, 91.33333333333334, 1.0, 2.0, 0.2854047139853054, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 309883.4809705843, 309883.4809705843, 101881.5399556889]
[2019-03-23 01:17:36,019] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 01:17:36,020] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.7404624796371426
[2019-03-23 01:17:49,676] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9056.2452 1656484552.8426 80.0000
[2019-03-23 01:17:50,174] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8506.2823 1773618593.6159 173.0000
[2019-03-23 01:17:50,192] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8569.0423 1683679931.9503 214.0000
[2019-03-23 01:17:50,324] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8851.2566 1664152039.1676 105.0000
[2019-03-23 01:17:50,326] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8592.0601 1706242222.4174 465.0000
[2019-03-23 01:17:51,343] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 1625000, evaluation results [1625000.0, 8506.282311108684, 1773618593.6158986, 173.0, 9056.245151782041, 1656484552.8426478, 80.0, 8851.256611154593, 1664152039.1676362, 105.0, 8592.06009615295, 1706242222.4174447, 465.0, 8569.042332002715, 1683679931.9503295, 214.0]
[2019-03-23 01:18:02,811] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:18:02,815] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0703
[2019-03-23 01:18:02,819] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.88333333333334, 70.16666666666667, 1.0, 2.0, 0.8066620956301606, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 908669.5095606619, 908669.5095606619, 172111.9295485898], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5994600.0000, 
sim time next is 5995200.0000, 
raw observation next is [22.16666666666667, 69.33333333333334, 1.0, 2.0, 0.8210308949896408, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 926386.3388723459, 926386.3388723456, 174983.2539286408], 
processed observation next is [1.0, 0.391304347826087, 0.6439393939393941, 0.6933333333333335, 1.0, 1.0, 0.776288618737051, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3431060514342022, 0.3431060514342021, 0.42678842421619706], 
reward next is 0.5732, 
noisyNet noise sample is [array([-0.06282759], dtype=float32), -1.0412804]. 
=============================================
[2019-03-23 01:18:08,647] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 2.2722599e-36 0.0000000e+00 2.3298410e-27], sum to 1.0000
[2019-03-23 01:18:08,659] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6171
[2019-03-23 01:18:08,670] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1195721.218740252 W.
[2019-03-23 01:18:08,675] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.9, 70.0, 1.0, 2.0, 0.3532176167382428, 1.0, 2.0, 0.3532176167382428, 1.0, 2.0, 0.7143961766390545, 6.9112, 6.9112, 77.3421103, 1195721.218740252, 1195721.218740252, 284205.978634123], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5487600.0000, 
sim time next is 5488200.0000, 
raw observation next is [25.8, 70.5, 1.0, 2.0, 0.5306395127214767, 1.0, 2.0, 0.5306395127214767, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1200131.323926495, 1200131.323926494, 241550.6156525289], 
processed observation next is [1.0, 0.5217391304347826, 0.8090909090909091, 0.705, 1.0, 1.0, 0.4132993909018458, 1.0, 1.0, 0.4132993909018458, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.44449308293573886, 0.4444930829357385, 0.5891478430549486], 
reward next is 0.4109, 
noisyNet noise sample is [array([-0.98057646], dtype=float32), 0.53213906]. 
=============================================
[2019-03-23 01:18:08,895] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:18:08,906] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8952
[2019-03-23 01:18:08,916] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.46666666666667, 79.33333333333334, 1.0, 2.0, 0.4552608996532315, 0.0, 2.0, 0.0, 1.0, 1.0, 0.920007950956801, 6.911199999999999, 6.9112, 77.32846344354104, 1039159.359415819, 1039159.35941582, 244763.1082503941], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5480400.0000, 
sim time next is 5481000.0000, 
raw observation next is [23.85, 78.0, 1.0, 2.0, 0.8873131743379532, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1012669.931356388, 1012669.931356388, 198021.0783453604], 
processed observation next is [1.0, 0.43478260869565216, 0.7204545454545456, 0.78, 1.0, 1.0, 0.8591414679224415, 0.0, 1.0, -0.25, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.37506293753940295, 0.37506293753940295, 0.4829782398667327], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0158751], dtype=float32), -0.6345057]. 
=============================================
[2019-03-23 01:18:08,923] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[49.715744]
 [48.306602]
 [49.65145 ]
 [51.030506]
 [51.379063]], R is [[48.62889481]
 [48.54561996]
 [48.54306412]
 [48.57167053]
 [48.63989258]].
[2019-03-23 01:18:14,372] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:18:14,382] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5458
[2019-03-23 01:18:14,388] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.1, 93.5, 1.0, 2.0, 0.2905097709923071, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 315447.3570058552, 315447.3570058552, 102991.2571151747], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5651400.0000, 
sim time next is 5652000.0000, 
raw observation next is [16.1, 93.0, 1.0, 2.0, 0.2891877545098726, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 314011.3941439678, 314011.3941439681, 101921.0433489284], 
processed observation next is [0.0, 0.43478260869565216, 0.3681818181818182, 0.93, 1.0, 1.0, 0.11148469313734075, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11630051634961769, 0.11630051634961783, 0.24858791060714244], 
reward next is 0.7514, 
noisyNet noise sample is [array([0.17167048], dtype=float32), 2.2558243]. 
=============================================
[2019-03-23 01:18:14,402] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[58.429035]
 [58.420784]
 [58.41072 ]
 [58.39634 ]
 [58.37548 ]], R is [[58.62617493]
 [58.78871536]
 [58.94688416]
 [59.10052872]
 [59.24949646]].
[2019-03-23 01:18:14,422] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:18:14,431] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1264
[2019-03-23 01:18:14,436] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.5, 62.0, 1.0, 2.0, 0.4885156539385488, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 557333.4282363129, 557333.4282363129, 140289.754960544], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5595000.0000, 
sim time next is 5595600.0000, 
raw observation next is [25.3, 67.0, 1.0, 2.0, 0.4812998725769602, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 549204.4476909228, 549204.4476909228, 138913.413464598], 
processed observation next is [1.0, 0.782608695652174, 0.7863636363636364, 0.67, 1.0, 1.0, 0.35162484072120026, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20340905470034176, 0.20340905470034176, 0.33881320357219025], 
reward next is 0.6612, 
noisyNet noise sample is [array([0.18042034], dtype=float32), -1.4487121]. 
=============================================
[2019-03-23 01:18:19,009] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.0638346e-37 0.0000000e+00], sum to 1.0000
[2019-03-23 01:18:19,017] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5642
[2019-03-23 01:18:19,025] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 63.0, 1.0, 2.0, 0.5527106775631407, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 626749.3851181747, 626749.3851181747, 150931.166326169], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6370200.0000, 
sim time next is 6370800.0000, 
raw observation next is [27.9, 63.66666666666666, 1.0, 2.0, 0.5537471184868261, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 627822.228094971, 627822.228094971, 151105.2846165162], 
processed observation next is [0.0, 0.7391304347826086, 0.9045454545454544, 0.6366666666666666, 1.0, 1.0, 0.4421838981085326, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23252675114628557, 0.23252675114628557, 0.3685494746744298], 
reward next is 0.6315, 
noisyNet noise sample is [array([-2.5894928], dtype=float32), 1.3564535]. 
=============================================
[2019-03-23 01:18:20,964] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:18:20,973] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2544
[2019-03-23 01:18:20,979] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.86666666666667, 47.33333333333333, 1.0, 2.0, 0.2632333966446782, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 285820.8539459512, 285820.8539459509, 84821.97210481728], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5769600.0000, 
sim time next is 5770200.0000, 
raw observation next is [20.68333333333334, 48.16666666666667, 1.0, 2.0, 0.2613452722473595, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 283770.1157949906, 283770.1157949909, 84459.03156170135], 
processed observation next is [0.0, 0.782608695652174, 0.5765151515151519, 0.4816666666666667, 1.0, 1.0, 0.07668159030919934, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10510004288703356, 0.10510004288703367, 0.20599763795536916], 
reward next is 0.7940, 
noisyNet noise sample is [array([0.4300348], dtype=float32), 0.23127078]. 
=============================================
[2019-03-23 01:18:27,067] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:18:27,077] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9078
[2019-03-23 01:18:27,082] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.35, 62.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 213331.6425302906, 213331.6425302903, 69394.49172224625], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5787000.0000, 
sim time next is 5787600.0000, 
raw observation next is [15.1, 62.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 210168.5346503376, 210168.5346503373, 68472.50805329828], 
processed observation next is [0.0, 1.0, 0.3227272727272727, 0.62, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07784019801864356, 0.07784019801864345, 0.16700611720316655], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.6209818], dtype=float32), 1.3448769]. 
=============================================
[2019-03-23 01:18:29,699] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:18:29,707] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0820
[2019-03-23 01:18:29,713] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.4, 51.33333333333334, 1.0, 2.0, 0.437913741876712, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 488936.2198250554, 488936.2198250554, 126251.1385874881], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5833200.0000, 
sim time next is 5833800.0000, 
raw observation next is [24.4, 51.0, 1.0, 2.0, 0.4091087235795671, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 456269.9100519198, 456269.9100519198, 123462.2581659978], 
processed observation next is [1.0, 0.5217391304347826, 0.7454545454545454, 0.51, 1.0, 1.0, 0.26138590447445886, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1689888555747851, 0.1689888555747851, 0.30112745894145804], 
reward next is 0.6989, 
noisyNet noise sample is [array([0.38520387], dtype=float32), 1.0185459]. 
=============================================
[2019-03-23 01:18:30,212] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 7.6693155e-38], sum to 1.0000
[2019-03-23 01:18:30,220] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7882
[2019-03-23 01:18:30,228] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1175810.368504056 W.
[2019-03-23 01:18:30,236] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.61666666666667, 46.16666666666667, 1.0, 2.0, 0.3432628024133594, 1.0, 2.0, 0.3432628024133594, 1.0, 2.0, 0.6922114756653319, 6.9112, 6.9112, 77.3421103, 1175810.368504056, 1175810.368504056, 268682.7657135235], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5933400.0000, 
sim time next is 5934000.0000, 
raw observation next is [27.53333333333333, 46.33333333333334, 1.0, 2.0, 0.5533552598177249, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9602040643928562, 6.9173374202289, 6.9112, 77.32844838748076, 1179184.455416454, 1177191.147246163, 257257.6021873725], 
processed observation next is [1.0, 0.6956521739130435, 0.8878787878787878, 0.46333333333333343, 1.0, 1.0, 0.4416940747721561, 0.0, 0.5, -0.25, 1.0, 1.0, 0.943148663418366, 0.0006137420228900404, 0.0, 0.5084287139281937, 0.43673498348757556, 0.4359967212022826, 0.6274575663106646], 
reward next is 0.3419, 
noisyNet noise sample is [array([-0.27728775], dtype=float32), 1.2984803]. 
=============================================
[2019-03-23 01:18:30,251] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[63.99807 ]
 [64.658394]
 [65.039604]
 [65.404755]
 [65.58489 ]], R is [[63.84706879]
 [63.55327606]
 [63.28739929]
 [63.01637268]
 [62.74831772]].
[2019-03-23 01:18:30,460] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:18:30,476] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8292
[2019-03-23 01:18:30,484] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.36666666666667, 70.66666666666667, 1.0, 2.0, 0.3274554047841684, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 361133.5251837183, 361133.5251837183, 115070.6619871107], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5870400.0000, 
sim time next is 5871000.0000, 
raw observation next is [20.18333333333333, 71.83333333333333, 1.0, 2.0, 0.3289821150084135, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 362727.666904875, 362727.6669048753, 115148.839053438], 
processed observation next is [1.0, 0.9565217391304348, 0.5537878787878786, 0.7183333333333333, 1.0, 1.0, 0.16122764376051688, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1343435803351389, 0.134343580335139, 0.2808508269596049], 
reward next is 0.7191, 
noisyNet noise sample is [array([-0.01697824], dtype=float32), -0.5695329]. 
=============================================
[2019-03-23 01:18:30,492] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[70.49459 ]
 [70.60233 ]
 [70.701996]
 [70.79335 ]
 [70.91539 ]], R is [[70.38169098]
 [70.39720917]
 [70.41247559]
 [70.42740631]
 [70.44192505]].
[2019-03-23 01:18:36,304] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:18:36,308] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3524
[2019-03-23 01:18:36,314] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.68333333333334, 76.33333333333333, 1.0, 2.0, 0.3634879502381314, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 407050.6037130427, 407050.6037130427, 120361.6338385402], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5964600.0000, 
sim time next is 5965200.0000, 
raw observation next is [20.5, 78.0, 1.0, 2.0, 0.3649405978178499, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 408897.4884942665, 408897.4884942662, 120585.4622029092], 
processed observation next is [1.0, 0.043478260869565216, 0.5681818181818182, 0.78, 1.0, 1.0, 0.20617574727231233, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15144351425713576, 0.15144351425713562, 0.29411088342172975], 
reward next is 0.7059, 
noisyNet noise sample is [array([-0.91675025], dtype=float32), 0.5223367]. 
=============================================
[2019-03-23 01:18:43,629] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-23 01:18:43,633] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 01:18:43,634] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 01:18:43,634] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:18:43,636] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 01:18:43,636] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 01:18:43,634] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 01:18:43,639] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:18:43,637] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:18:43,641] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:18:43,639] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:18:43,670] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run67
[2019-03-23 01:18:43,692] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run67
[2019-03-23 01:18:43,717] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run67
[2019-03-23 01:18:43,737] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run67
[2019-03-23 01:18:43,768] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run67
[2019-03-23 01:19:35,318] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.72824305], dtype=float32), -0.09955639]
[2019-03-23 01:19:35,321] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.65, 75.0, 1.0, 2.0, 0.6078533932057948, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 693042.238254978, 693042.238254978, 160128.1847749166]
[2019-03-23 01:19:35,322] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 01:19:35,323] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.43069608623096334
[2019-03-23 01:20:32,703] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9058.6831 1656359050.7176 80.0000
[2019-03-23 01:20:32,931] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8509.1813 1773413472.9632 173.0000
[2019-03-23 01:20:33,085] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8595.3099 1706074232.0561 465.0000
[2019-03-23 01:20:33,115] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8854.1746 1663949029.5070 105.0000
[2019-03-23 01:20:33,183] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8571.9617 1683477666.0862 214.0000
[2019-03-23 01:20:34,200] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 1650000, evaluation results [1650000.0, 8509.181281245757, 1773413472.9631987, 173.0, 9058.683074210225, 1656359050.7176125, 80.0, 8854.174594824059, 1663949029.507014, 105.0, 8595.309948762033, 1706074232.0561063, 465.0, 8571.9617444755, 1683477666.0861843, 214.0]
[2019-03-23 01:20:34,837] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:20:34,844] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3948
[2019-03-23 01:20:34,852] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 58.0, 1.0, 2.0, 0.5560746390255966, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 603987.6431468566, 603987.6431468562, 122819.358387111], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6087600.0000, 
sim time next is 6088200.0000, 
raw observation next is [20.18333333333333, 57.5, 1.0, 2.0, 0.5665900822907719, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 615416.3587018935, 615416.3587018935, 124895.4581992903], 
processed observation next is [1.0, 0.4782608695652174, 0.5537878787878786, 0.575, 1.0, 1.0, 0.4582376028634648, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22793198470440498, 0.22793198470440498, 0.30462306877875683], 
reward next is 0.6954, 
noisyNet noise sample is [array([1.3728971], dtype=float32), 0.41459844]. 
=============================================
[2019-03-23 01:20:43,948] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:20:43,958] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0975
[2019-03-23 01:20:43,963] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.2, 74.33333333333334, 1.0, 2.0, 0.6050518091810083, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 679918.0273925448, 679918.0273925448, 159599.2866349025], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6272400.0000, 
sim time next is 6273000.0000, 
raw observation next is [27.75, 70.5, 1.0, 2.0, 0.6037318026957819, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 678433.6541686939, 678433.6541686939, 159413.323836291], 
processed observation next is [0.0, 0.6086956521739131, 0.8977272727272727, 0.705, 1.0, 1.0, 0.5046647533697273, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.25127172376618295, 0.25127172376618295, 0.3888129849665634], 
reward next is 0.6112, 
noisyNet noise sample is [array([-0.38930765], dtype=float32), 0.32328638]. 
=============================================
[2019-03-23 01:20:43,973] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[62.847263]
 [62.91415 ]
 [63.04086 ]
 [63.134476]
 [63.243824]], R is [[62.82242966]
 [62.80493927]
 [62.78821182]
 [62.77362442]
 [62.76311493]].
[2019-03-23 01:20:50,456] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:20:50,463] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1489
[2019-03-23 01:20:50,469] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.16666666666666, 80.33333333333334, 1.0, 2.0, 0.5621777641194718, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 637151.5862435669, 637151.5862435669, 152290.2793742855], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6381600.0000, 
sim time next is 6382200.0000, 
raw observation next is [25.08333333333334, 80.66666666666666, 1.0, 2.0, 0.5606326395388319, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 635552.8002981106, 635552.8002981103, 152030.6116685191], 
processed observation next is [0.0, 0.8695652173913043, 0.7765151515151518, 0.8066666666666665, 1.0, 1.0, 0.45079079942353983, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.23538992603633727, 0.23538992603633715, 0.3708063699232173], 
reward next is 0.6292, 
noisyNet noise sample is [array([-0.5776675], dtype=float32), -0.5873692]. 
=============================================
[2019-03-23 01:21:01,120] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:21:01,131] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3554
[2019-03-23 01:21:01,137] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.25, 93.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 212931.5424045164, 212931.5424045164, 69719.75198297734], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6579000.0000, 
sim time next is 6579600.0000, 
raw observation next is [12.03333333333333, 94.33333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 206665.1488330305, 206665.1488330302, 68565.50120786008], 
processed observation next is [1.0, 0.13043478260869565, 0.18333333333333315, 0.9433333333333332, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07654264771593722, 0.0765426477159371, 0.1672329297752685], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.46979547], dtype=float32), 0.10681568]. 
=============================================
[2019-03-23 01:21:16,077] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:21:16,086] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6588
[2019-03-23 01:21:16,094] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 58.0, 1.0, 2.0, 0.5165483996500125, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 588403.3335700224, 588403.3335700224, 144849.5180385669], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7482600.0000, 
sim time next is 7483200.0000, 
raw observation next is [28.1, 57.0, 1.0, 2.0, 0.5123545786812249, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 583808.5151811973, 583808.5151811976, 144171.4904223103], 
processed observation next is [0.0, 0.6086956521739131, 0.9136363636363637, 0.57, 1.0, 1.0, 0.3904432233515311, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21622537599303604, 0.21622537599303612, 0.35163778151783004], 
reward next is 0.6484, 
noisyNet noise sample is [array([-0.82088596], dtype=float32), 1.6033231]. 
=============================================
[2019-03-23 01:21:20,775] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:21:20,785] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4411
[2019-03-23 01:21:20,791] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 97.0, 1.0, 2.0, 0.3487361066442998, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 388234.856754711, 388234.856754711, 118122.4499008419], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7095600.0000, 
sim time next is 7096200.0000, 
raw observation next is [17.7, 97.0, 1.0, 2.0, 0.3521097095291766, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 391998.0071792626, 391998.0071792629, 118393.0162434722], 
processed observation next is [1.0, 0.13043478260869565, 0.44090909090909086, 0.97, 1.0, 1.0, 0.19013713691147072, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1451844471034306, 0.1451844471034307, 0.2887634542523712], 
reward next is 0.7112, 
noisyNet noise sample is [array([-0.56919754], dtype=float32), -1.6780931]. 
=============================================
[2019-03-23 01:21:21,351] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:21:21,360] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3184
[2019-03-23 01:21:21,364] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 88.5, 1.0, 2.0, 0.3630990770552519, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 405124.4574515114, 405124.4574515111, 119656.3370494657], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6928200.0000, 
sim time next is 6928800.0000, 
raw observation next is [18.8, 88.0, 1.0, 2.0, 0.3603749863647621, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 401752.8538482962, 401752.8538482962, 119290.2267775082], 
processed observation next is [0.0, 0.17391304347826086, 0.49090909090909096, 0.88, 1.0, 1.0, 0.20046873295595263, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14879735327714674, 0.14879735327714674, 0.29095177262806876], 
reward next is 0.7090, 
noisyNet noise sample is [array([-1.3609778], dtype=float32), -0.2774438]. 
=============================================
[2019-03-23 01:21:23,287] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:21:23,294] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9760
[2019-03-23 01:21:23,297] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.2, 60.0, 1.0, 2.0, 0.5015247720981404, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 571908.414673172, 571908.414673172, 142343.7308883737], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6976800.0000, 
sim time next is 6977400.0000, 
raw observation next is [27.01666666666667, 61.16666666666666, 1.0, 2.0, 0.5000136770299685, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 570185.32694846, 570185.3269484596, 142165.3131115005], 
processed observation next is [0.0, 0.782608695652174, 0.8643939393939395, 0.6116666666666666, 1.0, 1.0, 0.37501709628746055, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21117975072165185, 0.2111797507216517, 0.34674466612561095], 
reward next is 0.6533, 
noisyNet noise sample is [array([0.804487], dtype=float32), -1.6247251]. 
=============================================
[2019-03-23 01:21:26,141] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-23 01:21:26,142] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 01:21:26,144] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 01:21:26,144] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:21:26,146] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:21:26,148] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 01:21:26,149] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 01:21:26,150] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:21:26,150] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:21:26,152] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 01:21:26,155] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:21:26,186] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run68
[2019-03-23 01:21:26,187] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run68
[2019-03-23 01:21:26,231] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run68
[2019-03-23 01:21:26,256] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run68
[2019-03-23 01:21:26,276] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run68
[2019-03-23 01:21:50,386] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.70378494], dtype=float32), -0.08432484]
[2019-03-23 01:21:50,387] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.014680855, 83.65190204833334, 1.0, 2.0, 0.2652586054421102, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 288004.2276487898, 288004.2276487898, 91723.47433185381]
[2019-03-23 01:21:50,389] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 01:21:50,391] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.6551289803731837
[2019-03-23 01:22:13,553] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.70378494], dtype=float32), -0.08432484]
[2019-03-23 01:22:13,554] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.0, 46.5, 1.0, 2.0, 0.3086966081296216, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 335180.1407455028, 335180.1407455031, 112243.1812093115]
[2019-03-23 01:22:13,555] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 01:22:13,558] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.5352187521977376
[2019-03-23 01:22:27,581] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.70378494], dtype=float32), -0.08432484]
[2019-03-23 01:22:27,584] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [25.763708675, 53.966878375, 1.0, 2.0, 0.4281053413265827, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 485529.7542412729, 485529.7542412729, 133624.506488047]
[2019-03-23 01:22:27,586] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 01:22:27,588] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.5488977848947149
[2019-03-23 01:22:54,392] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.70378494], dtype=float32), -0.08432484]
[2019-03-23 01:22:54,394] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.33333333333333, 59.33333333333334, 1.0, 2.0, 0.3354755101523329, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 371026.4388396872, 371026.4388396875, 120391.3899869608]
[2019-03-23 01:22:54,395] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 01:22:54,400] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.4359291229952249
[2019-03-23 01:23:02,712] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.70378494], dtype=float32), -0.08432484]
[2019-03-23 01:23:02,712] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.1, 45.0, 1.0, 2.0, 0.3930484000603705, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 444181.5695112993, 444181.5695112993, 129266.0309302474]
[2019-03-23 01:23:02,713] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 01:23:02,716] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.8887547584183749
[2019-03-23 01:23:06,352] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.70378494], dtype=float32), -0.08432484]
[2019-03-23 01:23:06,354] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [25.96810175666666, 43.397039515, 1.0, 2.0, 0.3818262957520228, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 95.55338769695034, 425293.8982047712, 425293.8982047705, 125219.7521508682]
[2019-03-23 01:23:06,354] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 01:23:06,356] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.20808710430039423
[2019-03-23 01:23:11,071] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.70378494], dtype=float32), -0.08432484]
[2019-03-23 01:23:11,073] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.23333333333333, 60.5, 1.0, 2.0, 0.3063550819489213, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 334135.7632133741, 334135.7632133737, 116453.8475573152]
[2019-03-23 01:23:11,076] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 01:23:11,079] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.7442699959666719
[2019-03-23 01:23:15,901] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9057.8713 1656401324.5381 80.0000
[2019-03-23 01:23:15,937] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8594.4987 1706116953.1019 465.0000
[2019-03-23 01:23:16,049] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8853.4143 1664003580.0750 105.0000
[2019-03-23 01:23:16,057] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8571.9617 1683477666.0862 214.0000
[2019-03-23 01:23:16,077] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8509.1813 1773413472.9632 173.0000
[2019-03-23 01:23:17,093] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 1675000, evaluation results [1675000.0, 8509.181281245757, 1773413472.9631987, 173.0, 9057.871276350008, 1656401324.538099, 80.0, 8853.414337702749, 1664003580.0749555, 105.0, 8594.49866461476, 1706116953.1019058, 465.0, 8571.9617444755, 1683477666.0861843, 214.0]
[2019-03-23 01:23:26,056] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:23:26,063] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5312
[2019-03-23 01:23:26,069] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.95, 85.5, 1.0, 2.0, 0.3558291905014667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 389470.6843523189, 389470.6843523186, 116143.1643495326], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7353000.0000, 
sim time next is 7353600.0000, 
raw observation next is [17.86666666666667, 86.0, 1.0, 2.0, 0.3425396989748898, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 374667.2714395601, 374667.2714395604, 115064.3277925841], 
processed observation next is [1.0, 0.08695652173913043, 0.44848484848484865, 0.86, 1.0, 1.0, 0.1781746237186122, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13876565608872596, 0.13876565608872607, 0.28064470193313196], 
reward next is 0.7194, 
noisyNet noise sample is [array([-0.84558904], dtype=float32), -1.4016379]. 
=============================================
[2019-03-23 01:23:28,540] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:23:28,547] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1135
[2019-03-23 01:23:28,553] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 43.0, 1.0, 2.0, 0.7652897201850404, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 833481.2581030322, 833481.2581030326, 155378.3806152623], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7224000.0000, 
sim time next is 7224600.0000, 
raw observation next is [23.9, 43.0, 1.0, 2.0, 0.7554823563212993, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 821398.3811933488, 821398.3811933491, 153761.6717799763], 
processed observation next is [1.0, 0.6086956521739131, 0.7227272727272727, 0.43, 1.0, 1.0, 0.6943529454016242, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3042216226642033, 0.3042216226642034, 0.37502846775603976], 
reward next is 0.6250, 
noisyNet noise sample is [array([0.8702278], dtype=float32), -1.4552938]. 
=============================================
[2019-03-23 01:23:29,464] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:23:29,465] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:23:29,521] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run9
[2019-03-23 01:23:33,513] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:23:33,513] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:23:33,596] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run9
[2019-03-23 01:23:34,275] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:23:34,285] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4222
[2019-03-23 01:23:34,290] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 81.0, 1.0, 2.0, 0.332298975996039, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 365416.4720644839, 365416.4720644839, 115028.2150316541], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7347600.0000, 
sim time next is 7348200.0000, 
raw observation next is [18.7, 81.5, 1.0, 2.0, 0.3321124144006275, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 365041.9175410689, 365041.9175410686, 114951.3371379863], 
processed observation next is [1.0, 0.043478260869565216, 0.48636363636363633, 0.815, 1.0, 1.0, 0.16514051800078436, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1352007102003959, 0.13520071020039576, 0.2803691149706983], 
reward next is 0.7196, 
noisyNet noise sample is [array([0.27979305], dtype=float32), -1.2774916]. 
=============================================
[2019-03-23 01:23:45,446] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:23:45,453] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1506
[2019-03-23 01:23:45,462] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.5, 97.0, 1.0, 2.0, 0.2227963339674434, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 241903.0601518611, 241903.0601518611, 81622.41109854283], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 286200.0000, 
sim time next is 286800.0000, 
raw observation next is [14.66666666666667, 96.0, 1.0, 2.0, 0.2250548944428258, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 244355.9278572436, 244355.9278572439, 82324.26422016414], 
processed observation next is [0.0, 0.30434782608695654, 0.30303030303030315, 0.96, 1.0, 1.0, 0.03131861805353225, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09050219550268282, 0.09050219550268292, 0.20079088834186376], 
reward next is 0.7992, 
noisyNet noise sample is [array([-0.233649], dtype=float32), -0.37955755]. 
=============================================
[2019-03-23 01:23:47,904] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:23:47,914] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9521
[2019-03-23 01:23:47,917] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 95.0, 1.0, 2.0, 0.4328460480988126, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 492027.051693929, 492027.051693929, 130606.3891941198], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7594800.0000, 
sim time next is 7595400.0000, 
raw observation next is [20.0, 95.5, 1.0, 2.0, 0.4347207577195493, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 494317.936026263, 494317.9360262627, 130931.2372638307], 
processed observation next is [0.0, 0.9130434782608695, 0.5454545454545454, 0.955, 1.0, 1.0, 0.2934009471494366, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18308071704676407, 0.18308071704676396, 0.3193444811312944], 
reward next is 0.6807, 
noisyNet noise sample is [array([-0.82951516], dtype=float32), 1.2515403]. 
=============================================
[2019-03-23 01:23:49,364] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:23:49,365] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:23:49,416] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:23:49,416] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:23:49,436] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run9
[2019-03-23 01:23:49,520] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run9
[2019-03-23 01:23:58,217] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:23:58,218] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:23:58,294] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run9
[2019-03-23 01:24:02,727] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:24:02,728] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:24:02,831] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run9
[2019-03-23 01:24:04,885] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:24:04,886] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:24:04,946] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run9
[2019-03-23 01:24:05,023] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.7992716e-34 2.4945587e-38], sum to 1.0000
[2019-03-23 01:24:05,029] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4159
[2019-03-23 01:24:05,033] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 95.0, 1.0, 2.0, 0.2023668662408822, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 219716.5776817496, 219716.5776817496, 75712.69082888965], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 277800.0000, 
sim time next is 278400.0000, 
raw observation next is [14.0, 96.0, 1.0, 2.0, 0.2075811262983201, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 225379.1884699638, 225379.1884699636, 76682.11615345071], 
processed observation next is [0.0, 0.21739130434782608, 0.2727272727272727, 0.96, 1.0, 1.0, 0.009476407872900106, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08347377350739399, 0.08347377350739393, 0.18702955159378223], 
reward next is 0.8130, 
noisyNet noise sample is [array([0.18588562], dtype=float32), 0.5066958]. 
=============================================
[2019-03-23 01:24:05,770] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:24:05,771] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:24:05,832] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run9
[2019-03-23 01:24:06,018] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:24:06,019] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:24:06,071] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run9
[2019-03-23 01:24:06,256] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:24:06,259] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:24:06,279] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:24:06,280] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:24:06,298] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run9
[2019-03-23 01:24:06,320] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:24:06,322] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:24:06,346] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run9
[2019-03-23 01:24:06,386] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:24:06,387] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:24:06,396] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run9
[2019-03-23 01:24:06,447] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run9
[2019-03-23 01:24:06,544] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:24:06,544] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:24:06,549] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run9
[2019-03-23 01:24:06,635] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:24:06,635] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:24:06,648] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run9
[2019-03-23 01:24:06,689] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:24:06,690] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:24:06,696] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run9
[2019-03-23 01:24:07,226] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-23 01:24:07,233] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 01:24:07,233] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 01:24:07,233] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:24:07,234] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:24:07,234] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 01:24:07,234] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 01:24:07,235] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:24:07,235] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:24:07,235] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 01:24:07,236] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:24:07,244] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run69
[2019-03-23 01:24:07,264] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run69
[2019-03-23 01:24:07,284] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run69
[2019-03-23 01:24:07,287] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run69
[2019-03-23 01:24:07,339] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run69
[2019-03-23 01:24:21,266] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.66478306], dtype=float32), -0.09267932]
[2019-03-23 01:24:21,268] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [28.85, 40.0, 1.0, 2.0, 0.4110078878835716, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 466152.1292679419, 466152.1292679415, 131991.6796638505]
[2019-03-23 01:24:21,270] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 01:24:21,273] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.7321006129466212
[2019-03-23 01:25:20,979] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.66478306], dtype=float32), -0.09267932]
[2019-03-23 01:25:20,981] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.65225704333333, 87.56332448166667, 1.0, 2.0, 0.4118057155922016, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 464077.477521511, 464077.477521511, 130261.4533849022]
[2019-03-23 01:25:20,983] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 01:25:20,986] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 1.643325e-33 0.000000e+00], sampled 0.5679326440227017
[2019-03-23 01:25:27,484] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.66478306], dtype=float32), -0.09267932]
[2019-03-23 01:25:27,485] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [7.992846661333334, 92.20244300833335, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 122519.8724931875, 122519.8724931879, 58648.00832745485]
[2019-03-23 01:25:27,487] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 01:25:27,491] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.3116905e-37 0.0000000e+00], sampled 0.029301068943660358
[2019-03-23 01:25:43,535] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.66478306], dtype=float32), -0.09267932]
[2019-03-23 01:25:43,536] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [18.5, 84.0, 1.0, 2.0, 0.3502526307730295, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 385790.5954321949, 385790.5954321946, 120918.3577689069]
[2019-03-23 01:25:43,537] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 01:25:43,540] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.4627288e-35 0.0000000e+00], sampled 0.8131067298389543
[2019-03-23 01:25:57,145] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8569.7595 1683629455.5724 214.0000
[2019-03-23 01:25:57,242] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8507.0038 1773566163.6992 173.0000
[2019-03-23 01:25:57,267] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8851.2566 1664152039.1676 105.0000
[2019-03-23 01:25:57,317] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8592.0601 1706242222.4174 465.0000
[2019-03-23 01:25:57,348] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9056.2452 1656484552.8426 80.0000
[2019-03-23 01:25:58,364] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 1700000, evaluation results [1700000.0, 8507.003781615034, 1773566163.6991806, 173.0, 9056.245151782041, 1656484552.8426478, 80.0, 8851.256611154593, 1664152039.1676362, 105.0, 8592.06009615295, 1706242222.4174447, 465.0, 8569.759499047412, 1683629455.5724304, 214.0]
[2019-03-23 01:26:03,802] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:26:03,810] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8345
[2019-03-23 01:26:03,815] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.16666666666667, 87.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 213760.6401196665, 213760.6401196665, 70451.756727712], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 100200.0000, 
sim time next is 100800.0000, 
raw observation next is [13.0, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 211433.679677329, 211433.6796773287, 69934.0541956312], 
processed observation next is [1.0, 0.17391304347826086, 0.22727272727272727, 0.88, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0783087702508626, 0.07830877025086248, 0.1705708638917834], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.4617413], dtype=float32), -0.49761033]. 
=============================================
[2019-03-23 01:26:04,988] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:26:04,997] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9952
[2019-03-23 01:26:05,002] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333334, 46.0, 1.0, 2.0, 0.4554798549947074, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 494669.723848662, 494669.7238486617, 107157.8581672836], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 130800.0000, 
sim time next is 131400.0000, 
raw observation next is [21.5, 46.0, 1.0, 2.0, 0.4241087463489039, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 460583.2794035059, 460583.2794035062, 104369.7944611095], 
processed observation next is [1.0, 0.5217391304347826, 0.6136363636363636, 0.46, 1.0, 1.0, 0.2801359329361298, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17058639977907625, 0.17058639977907636, 0.254560474295389], 
reward next is 0.7454, 
noisyNet noise sample is [array([0.8154825], dtype=float32), -0.2125268]. 
=============================================
[2019-03-23 01:26:11,224] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:26:11,232] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8677
[2019-03-23 01:26:11,237] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.33333333333334, 84.0, 1.0, 2.0, 0.2819531862355079, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 306153.3437840101, 306153.3437840104, 105532.5860127969], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 236400.0000, 
sim time next is 237000.0000, 
raw observation next is [16.66666666666667, 89.0, 1.0, 2.0, 0.2798613104960188, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 303881.2118363641, 303881.2118363638, 103421.5031327324], 
processed observation next is [0.0, 0.7391304347826086, 0.39393939393939414, 0.89, 1.0, 1.0, 0.0998266381200235, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11254859697643116, 0.11254859697643102, 0.2522475686164205], 
reward next is 0.7478, 
noisyNet noise sample is [array([-1.0103613], dtype=float32), -1.3763742]. 
=============================================
[2019-03-23 01:26:11,252] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[74.671165]
 [74.67524 ]
 [74.65712 ]
 [74.61923 ]
 [74.59386 ]], R is [[74.64557648]
 [74.64173126]
 [74.63442993]
 [74.62596893]
 [74.61894989]].
[2019-03-23 01:26:25,692] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:26:25,703] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9254
[2019-03-23 01:26:25,710] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.0, 94.0, 1.0, 2.0, 0.2560496582979461, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 278018.4659237721, 278018.4659237718, 86799.68272656604], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 504000.0000, 
sim time next is 504600.0000, 
raw observation next is [15.0, 93.00000000000001, 1.0, 2.0, 0.2533916292199213, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 275131.5642392403, 275131.5642392406, 85762.61161092528], 
processed observation next is [1.0, 0.8695652173913043, 0.3181818181818182, 0.9300000000000002, 1.0, 1.0, 0.06673953652490162, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10190057934786678, 0.1019005793478669, 0.20917710149006166], 
reward next is 0.7908, 
noisyNet noise sample is [array([-1.4914516], dtype=float32), -0.5181411]. 
=============================================
[2019-03-23 01:26:34,960] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:26:34,969] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2619
[2019-03-23 01:26:34,974] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 60.5, 1.0, 2.0, 0.352157305959374, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 391542.7507208275, 391542.7507208278, 118182.6677609515], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 682200.0000, 
sim time next is 682800.0000, 
raw observation next is [22.33333333333334, 61.66666666666667, 1.0, 2.0, 0.3555461950108999, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 395466.7260295094, 395466.7260295097, 118516.4888148242], 
processed observation next is [1.0, 0.9130434782608695, 0.6515151515151518, 0.6166666666666667, 1.0, 1.0, 0.19443274376362485, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14646915778870717, 0.14646915778870728, 0.2890646068654249], 
reward next is 0.7109, 
noisyNet noise sample is [array([-0.54911005], dtype=float32), 0.05837361]. 
=============================================
[2019-03-23 01:26:43,348] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.8623673e-34 0.0000000e+00], sum to 1.0000
[2019-03-23 01:26:43,356] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7049
[2019-03-23 01:26:43,362] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 94.0, 1.0, 2.0, 0.395185964415756, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 445334.6024915735, 445334.6024915735, 124421.6813234262], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 877200.0000, 
sim time next is 877800.0000, 
raw observation next is [19.0, 94.0, 1.0, 2.0, 0.3962599196184106, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 446545.9022144021, 446545.9022144021, 124518.376017512], 
processed observation next is [0.0, 0.13043478260869565, 0.5, 0.94, 1.0, 1.0, 0.24532489952301326, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1653873711905193, 0.1653873711905193, 0.30370335614027316], 
reward next is 0.6963, 
noisyNet noise sample is [array([1.5630157], dtype=float32), -0.9572]. 
=============================================
[2019-03-23 01:26:43,618] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:26:43,629] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2020
[2019-03-23 01:26:43,636] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 56.0, 1.0, 2.0, 0.5430466468020894, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 616969.992596114, 616969.9925961138, 149165.0873069344], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 826800.0000, 
sim time next is 827400.0000, 
raw observation next is [29.0, 55.5, 1.0, 2.0, 0.5385107742475823, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 612136.8321640952, 612136.8321640952, 148422.9067834368], 
processed observation next is [0.0, 0.5652173913043478, 0.9545454545454546, 0.555, 1.0, 1.0, 0.42313846780947784, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2267173452459612, 0.2267173452459612, 0.3620070897156995], 
reward next is 0.6380, 
noisyNet noise sample is [array([-0.21626988], dtype=float32), -0.043728985]. 
=============================================
[2019-03-23 01:26:50,039] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-23 01:26:50,041] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 01:26:50,041] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 01:26:50,042] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:26:50,042] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:26:50,043] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 01:26:50,042] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 01:26:50,044] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 01:26:50,046] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:26:50,048] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:26:50,046] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:26:50,077] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run70
[2019-03-23 01:26:50,079] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run70
[2019-03-23 01:26:50,121] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run70
[2019-03-23 01:26:50,123] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run70
[2019-03-23 01:26:50,146] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run70
[2019-03-23 01:26:59,673] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.71401215], dtype=float32), -0.19445735]
[2019-03-23 01:26:59,674] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [10.75, 86.0, 1.0, 2.0, 0.3988320094426472, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 433083.6558742748, 433083.6558742748, 90788.54684257908]
[2019-03-23 01:26:59,674] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 01:26:59,681] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.5575221688807463
[2019-03-23 01:27:02,912] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.71401215], dtype=float32), -0.19445735]
[2019-03-23 01:27:02,913] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.61131131833333, 83.36652926166667, 1.0, 2.0, 0.4825654474416218, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 550568.46603329, 550568.4660332897, 142931.640945294]
[2019-03-23 01:27:02,914] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 01:27:02,916] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.9673562327324746
[2019-03-23 01:27:34,554] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.71401215], dtype=float32), -0.19445735]
[2019-03-23 01:27:34,555] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.0, 74.66666666666667, 1.0, 2.0, 0.444416043758446, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 505932.4886812943, 505932.4886812943, 132468.6804805459]
[2019-03-23 01:27:34,558] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 01:27:34,560] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.7619277e-33 0.0000000e+00], sampled 0.7709725426309598
[2019-03-23 01:27:37,387] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.71401215], dtype=float32), -0.19445735]
[2019-03-23 01:27:37,390] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.66666666666667, 90.0, 1.0, 2.0, 0.3440944744035619, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 378241.440399098, 378241.4403990983, 115850.3339335704]
[2019-03-23 01:27:37,391] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 01:27:37,393] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.9547474191613594
[2019-03-23 01:27:46,889] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.71401215], dtype=float32), -0.19445735]
[2019-03-23 01:27:46,890] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.157279255, 97.68683706, 1.0, 2.0, 0.3025433623553617, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 328497.1730831618, 328497.1730831618, 115669.2035855839]
[2019-03-23 01:27:46,891] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 01:27:46,895] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.48043427924239435
[2019-03-23 01:27:58,959] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.71401215], dtype=float32), -0.19445735]
[2019-03-23 01:27:58,960] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.44594884333333, 75.82385069, 1.0, 2.0, 0.3565741435144929, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 397611.5329833171, 397611.5329833171, 123345.4116648373]
[2019-03-23 01:27:58,960] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 01:27:58,965] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.16245336893487283
[2019-03-23 01:28:13,104] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.71401215], dtype=float32), -0.19445735]
[2019-03-23 01:28:13,105] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [25.94492503833333, 53.43975744666666, 1.0, 2.0, 0.6762251210763842, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 767292.6827017011, 767292.6827017011, 162163.8874491887]
[2019-03-23 01:28:13,107] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 01:28:13,110] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.3471454720899497
[2019-03-23 01:28:39,395] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8507.7271 1773514361.6667 173.0000
[2019-03-23 01:28:39,931] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9056.2452 1656484552.8426 80.0000
[2019-03-23 01:28:39,956] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8569.7595 1683629455.5724 214.0000
[2019-03-23 01:28:39,976] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8851.9735 1664101423.8647 105.0000
[2019-03-23 01:28:39,996] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8592.0601 1706242222.4174 465.0000
[2019-03-23 01:28:41,013] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 1725000, evaluation results [1725000.0, 8507.727149272585, 1773514361.6667252, 173.0, 9056.245151782041, 1656484552.8426478, 80.0, 8851.973532677643, 1664101423.8646872, 105.0, 8592.06009615295, 1706242222.4174447, 465.0, 8569.759499047412, 1683629455.5724304, 214.0]
[2019-03-23 01:28:45,243] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:28:45,254] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8741
[2019-03-23 01:28:45,260] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 100.0, 1.0, 2.0, 0.2695241782047881, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 292653.4882705437, 292653.4882705435, 86160.11003200566], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1012800.0000, 
sim time next is 1013400.0000, 
raw observation next is [14.0, 100.0, 1.0, 2.0, 0.259269368958273, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 281515.4363706367, 281515.436370637, 84518.53193451435], 
processed observation next is [1.0, 0.7391304347826086, 0.2727272727272727, 1.0, 1.0, 1.0, 0.07408671119784126, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10426497643356915, 0.10426497643356925, 0.20614276081588867], 
reward next is 0.7939, 
noisyNet noise sample is [array([-3.2126787], dtype=float32), -0.3182012]. 
=============================================
[2019-03-23 01:28:51,333] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:28:51,344] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6442
[2019-03-23 01:28:51,350] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 88.0, 1.0, 2.0, 0.3187681011604869, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 350472.040807142, 350472.040807142, 114019.5130803875], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1130400.0000, 
sim time next is 1131000.0000, 
raw observation next is [18.0, 88.00000000000001, 1.0, 2.0, 0.3542486664005419, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 389891.347963838, 389891.3479638383, 116795.3823514859], 
processed observation next is [1.0, 0.08695652173913043, 0.45454545454545453, 0.8800000000000001, 1.0, 1.0, 0.1928108330006774, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14440420294956963, 0.14440420294956974, 0.2848667862231363], 
reward next is 0.7151, 
noisyNet noise sample is [array([2.7181664], dtype=float32), -1.5992532]. 
=============================================
[2019-03-23 01:28:51,359] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[69.36148 ]
 [69.354324]
 [69.35343 ]
 [69.35338 ]
 [69.34436 ]], R is [[69.570961  ]
 [69.59715271]
 [69.62472534]
 [69.65370941]
 [69.68413544]].
[2019-03-23 01:28:52,796] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:28:52,802] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6652
[2019-03-23 01:28:52,808] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.83333333333333, 79.0, 1.0, 2.0, 0.611667877116473, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 687357.9940738509, 687357.9940738509, 160534.4777953226], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1507800.0000, 
sim time next is 1508400.0000, 
raw observation next is [27.0, 79.0, 1.0, 2.0, 0.6192178407159986, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 695848.2935839825, 695848.2935839829, 161606.4816202385], 
processed observation next is [0.0, 0.4782608695652174, 0.8636363636363636, 0.79, 1.0, 1.0, 0.5240223008949982, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2577215902162898, 0.25772159021628993, 0.3941621502932647], 
reward next is 0.6058, 
noisyNet noise sample is [array([0.4440759], dtype=float32), 0.9085138]. 
=============================================
[2019-03-23 01:29:04,527] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:29:04,540] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2387
[2019-03-23 01:29:04,544] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [9.666666666666668, 69.33333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 161964.2595963718, 161964.2595963721, 59411.61603604272], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1730400.0000, 
sim time next is 1731000.0000, 
raw observation next is [9.333333333333332, 70.16666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 157323.8519062379, 157323.8519062382, 58803.31590595789], 
processed observation next is [1.0, 0.0, 0.06060606060606055, 0.7016666666666667, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.058268093298606626, 0.05826809329860674, 0.1434227217218485], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.43951988], dtype=float32), 1.2906377]. 
=============================================
[2019-03-23 01:29:04,563] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[70.04767]
 [70.06567]
 [70.09737]
 [70.13316]
 [70.48473]], R is [[69.3120575 ]
 [68.61893463]
 [67.93274689]
 [67.25341797]
 [66.58088684]].
[2019-03-23 01:29:07,383] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.00000e+00 1.00000e+00 0.00000e+00 3.57389e-38 0.00000e+00], sum to 1.0000
[2019-03-23 01:29:07,392] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3056
[2019-03-23 01:29:07,398] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 89.0, 1.0, 2.0, 0.5122954819248656, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 583628.9639156511, 583628.9639156507, 144271.3551299325], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1418400.0000, 
sim time next is 1419000.0000, 
raw observation next is [23.16666666666667, 88.0, 1.0, 2.0, 0.5139781372510092, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 585490.6243785275, 585490.6243785275, 144524.7727518952], 
processed observation next is [0.0, 0.43478260869565216, 0.6893939393939396, 0.88, 1.0, 1.0, 0.3924726715637614, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21684837939945464, 0.21684837939945464, 0.35249944573632974], 
reward next is 0.6475, 
noisyNet noise sample is [array([-1.4190482], dtype=float32), -0.39919952]. 
=============================================
[2019-03-23 01:29:07,407] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[64.01925 ]
 [63.96305 ]
 [63.916016]
 [63.864693]
 [63.819004]], R is [[64.02709961]
 [64.03495026]
 [64.04294586]
 [64.0508728 ]
 [64.05853271]].
[2019-03-23 01:29:11,425] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:29:11,431] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5084
[2019-03-23 01:29:11,436] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.33333333333334, 79.0, 1.0, 2.0, 0.5976807159365962, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 671790.7436087817, 671790.7436087817, 158538.3306208879], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1506000.0000, 
sim time next is 1506600.0000, 
raw observation next is [26.5, 79.0, 1.0, 2.0, 0.6012150682071208, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 675603.5493590591, 675603.5493590593, 159063.7991044083], 
processed observation next is [0.0, 0.43478260869565216, 0.8409090909090909, 0.79, 1.0, 1.0, 0.501518835258901, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.25022353679965154, 0.2502235367996516, 0.38796048562050806], 
reward next is 0.6120, 
noisyNet noise sample is [array([0.2405791], dtype=float32), 1.747336]. 
=============================================
[2019-03-23 01:29:11,468] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:29:11,474] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5326
[2019-03-23 01:29:11,481] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333333, 99.00000000000001, 1.0, 2.0, 0.4812210541061932, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 548921.260228501, 548921.260228501, 139672.1434805081], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1494600.0000, 
sim time next is 1495200.0000, 
raw observation next is [21.66666666666667, 98.0, 1.0, 2.0, 0.4888425109474595, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 557361.9166576172, 557361.9166576172, 140978.1940865699], 
processed observation next is [0.0, 0.30434782608695654, 0.6212121212121214, 0.98, 1.0, 1.0, 0.36105313868432437, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2064303395028212, 0.2064303395028212, 0.34384925386968274], 
reward next is 0.6562, 
noisyNet noise sample is [array([-1.3325257], dtype=float32), 0.88501316]. 
=============================================
[2019-03-23 01:29:20,350] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.5554045e-35 0.0000000e+00 1.1181847e-36], sum to 1.0000
[2019-03-23 01:29:20,362] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3458
[2019-03-23 01:29:20,367] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.66666666666667, 84.33333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 205670.4382124768, 205670.4382124771, 67897.94025475917], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2342400.0000, 
sim time next is 2343000.0000, 
raw observation next is [12.33333333333333, 86.16666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 201993.8108926229, 201993.8108926232, 67081.39557611739], 
processed observation next is [1.0, 0.08695652173913043, 0.19696969696969682, 0.8616666666666667, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0748125225528233, 0.0748125225528234, 0.16361315994174971], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.1418502], dtype=float32), -0.02411145]. 
=============================================
[2019-03-23 01:29:20,378] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[74.52608 ]
 [74.59613 ]
 [74.689026]
 [74.723434]
 [74.57387 ]], R is [[73.71459198]
 [72.97744751]
 [72.24767303]
 [72.35243988]
 [72.4515152 ]].
[2019-03-23 01:29:22,191] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:29:22,199] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6554
[2019-03-23 01:29:22,207] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [8.0, 81.0, 1.0, 2.0, 0.3281546996286083, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 356338.7322330874, 356338.7322330874, 77130.67492289764], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1741800.0000, 
sim time next is 1742400.0000, 
raw observation next is [8.0, 81.0, 1.0, 2.0, 0.327643404959841, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 355783.3211844948, 355783.3211844945, 77085.15477209113], 
processed observation next is [1.0, 0.17391304347826086, 0.0, 0.81, 1.0, 1.0, 0.15955425619980124, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13177160043870179, 0.13177160043870165, 0.18801257261485643], 
reward next is 0.8120, 
noisyNet noise sample is [array([-0.3686931], dtype=float32), 0.97466594]. 
=============================================
[2019-03-23 01:29:24,514] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:29:24,533] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8497
[2019-03-23 01:29:24,539] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [10.33333333333333, 67.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 170944.2480844536, 170944.2480844534, 60590.38157149297], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1729200.0000, 
sim time next is 1729800.0000, 
raw observation next is [10.0, 68.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 166700.2814281439, 166700.2814281442, 60032.95857254748], 
processed observation next is [1.0, 0.0, 0.09090909090909091, 0.685, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.06174084497338663, 0.06174084497338674, 0.1464218501769451], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.47209892], dtype=float32), 0.94597864]. 
=============================================
[2019-03-23 01:29:27,241] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:29:27,250] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5597
[2019-03-23 01:29:27,255] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.66666666666667, 51.5, 1.0, 2.0, 0.2826903797318662, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 306954.063518391, 306954.0635183907, 90250.8299772917], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1890600.0000, 
sim time next is 1891200.0000, 
raw observation next is [20.33333333333334, 54.0, 1.0, 2.0, 0.2781479531227432, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 302020.2229595098, 302020.2229595101, 90400.10133980802], 
processed observation next is [1.0, 0.9130434782608695, 0.5606060606060609, 0.54, 1.0, 1.0, 0.097684941403429, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11185934183685549, 0.1118593418368556, 0.22048805204831226], 
reward next is 0.7795, 
noisyNet noise sample is [array([0.2505201], dtype=float32), -0.33409828]. 
=============================================
[2019-03-23 01:29:32,557] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 01:29:32,561] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 01:29:32,562] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:29:32,563] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 01:29:32,563] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 01:29:32,564] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:29:32,565] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:29:32,564] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 01:29:32,566] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 01:29:32,568] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:29:32,569] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:29:32,590] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run71
[2019-03-23 01:29:32,616] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run71
[2019-03-23 01:29:32,639] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run71
[2019-03-23 01:29:32,664] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run71
[2019-03-23 01:29:32,665] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run71
[2019-03-23 01:29:36,798] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.78999954], dtype=float32), -0.19612072]
[2019-03-23 01:29:36,800] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.35168489, 83.91932977, 1.0, 2.0, 0.2522965269723615, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 273927.4586876693, 273927.4586876689, 107150.3352204389]
[2019-03-23 01:29:36,801] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 01:29:36,804] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.43336452288515814
[2019-03-23 01:29:46,659] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.78999954], dtype=float32), -0.19612072]
[2019-03-23 01:29:46,661] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [17.0545589, 96.27307454, 1.0, 2.0, 0.3533177903315709, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 388926.4943160067, 388926.4943160064, 121063.543559166]
[2019-03-23 01:29:46,663] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 01:29:46,665] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.9542668953057458
[2019-03-23 01:29:49,551] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.78999954], dtype=float32), -0.19612072]
[2019-03-23 01:29:49,553] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [25.46666666666667, 70.66666666666667, 1.0, 2.0, 0.6294021518031757, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 717455.3563389287, 717455.3563389287, 163253.1667262286]
[2019-03-23 01:29:49,555] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 01:29:49,557] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.05463755121092839
[2019-03-23 01:29:53,174] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.78999954], dtype=float32), -0.19612072]
[2019-03-23 01:29:53,177] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.56499581666667, 99.67903651833333, 1.0, 2.0, 0.4639250642627243, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 529159.0573837844, 529159.0573837844, 140369.7588404011]
[2019-03-23 01:29:53,179] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 01:29:53,182] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.5926753778267652
[2019-03-23 01:30:01,553] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.78999954], dtype=float32), -0.19612072]
[2019-03-23 01:30:01,556] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.63333333333333, 56.0, 1.0, 2.0, 0.3335005973146891, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 367565.5774899734, 367565.5774899734, 119745.0463162772]
[2019-03-23 01:30:01,559] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 01:30:01,560] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.22734350864009234
[2019-03-23 01:30:20,209] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.78999954], dtype=float32), -0.19612072]
[2019-03-23 01:30:20,210] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.8, 63.5, 1.0, 2.0, 0.2538401567600275, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 275603.8175971236, 275603.8175971236, 91736.37277401572]
[2019-03-23 01:30:20,211] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 01:30:20,214] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.2333931994955304
[2019-03-23 01:30:30,637] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.78999954], dtype=float32), -0.19612072]
[2019-03-23 01:30:30,639] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.637706095, 95.758808395, 1.0, 2.0, 0.3894381256323004, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 438483.8708267275, 438483.8708267272, 128037.3164353457]
[2019-03-23 01:30:30,640] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 01:30:30,643] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.21745873816315486
[2019-03-23 01:30:54,363] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.78999954], dtype=float32), -0.19612072]
[2019-03-23 01:30:54,365] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.26666666666667, 84.0, 1.0, 2.0, 0.3660256129832926, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 407886.8249624261, 407886.8249624257, 123999.1475722018]
[2019-03-23 01:30:54,367] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 01:30:54,370] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.6759442651763934
[2019-03-23 01:31:03,688] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.78999954], dtype=float32), -0.19612072]
[2019-03-23 01:31:03,691] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.3, 50.0, 1.0, 2.0, 0.5592314095843944, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 636726.5248930318, 636726.5248930318, 149563.2318896854]
[2019-03-23 01:31:03,693] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 01:31:03,696] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.4358085480102082
[2019-03-23 01:31:17,553] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.78999954], dtype=float32), -0.19612072]
[2019-03-23 01:31:17,554] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.55, 64.0, 1.0, 2.0, 0.3249321149671942, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 359268.7009746965, 359268.7009746961, 119562.8620330334]
[2019-03-23 01:31:17,556] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 01:31:17,559] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.7050100846697968
[2019-03-23 01:31:22,482] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8853.4143 1664003580.0750 105.0000
[2019-03-23 01:31:22,696] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9058.6831 1656359050.7176 80.0000
[2019-03-23 01:31:22,724] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8509.1813 1773413472.9632 173.0000
[2019-03-23 01:31:22,744] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8594.4987 1706116953.1019 465.0000
[2019-03-23 01:31:22,992] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8571.9617 1683477666.0862 214.0000
[2019-03-23 01:31:24,012] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 1750000, evaluation results [1750000.0, 8509.181281245757, 1773413472.9631987, 173.0, 9058.683074210225, 1656359050.7176125, 80.0, 8853.414337702749, 1664003580.0749555, 105.0, 8594.49866461476, 1706116953.1019058, 465.0, 8571.9617444755, 1683477666.0861843, 214.0]
[2019-03-23 01:31:43,953] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.1482327e-33], sum to 1.0000
[2019-03-23 01:31:43,966] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0698
[2019-03-23 01:31:43,969] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.0, 92.0, 1.0, 2.0, 0.445290200557074, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 483597.8387142053, 483597.8387142053, 105516.6091603872], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2450400.0000, 
sim time next is 2451000.0000, 
raw observation next is [15.0, 93.0, 1.0, 2.0, 0.4629303199986459, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 502765.4173279546, 502765.4173279549, 108280.337156999], 
processed observation next is [1.0, 0.34782608695652173, 0.3181818181818182, 0.93, 1.0, 1.0, 0.3286628999983074, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18620941382516837, 0.18620941382516848, 0.26409838330975366], 
reward next is 0.7359, 
noisyNet noise sample is [array([-0.6145], dtype=float32), 0.5716903]. 
=============================================
[2019-03-23 01:31:43,977] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[71.75696]
 [72.13134]
 [72.58961]
 [73.1345 ]
 [73.74075]], R is [[71.55092621]
 [71.57806396]
 [71.61513519]
 [71.66464996]
 [71.73029327]].
[2019-03-23 01:31:49,361] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:31:49,368] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8316
[2019-03-23 01:31:49,374] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.66666666666667, 70.33333333333334, 1.0, 2.0, 0.2041992476823832, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 221706.5098354034, 221706.5098354037, 70846.80567024712], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2337600.0000, 
sim time next is 2338200.0000, 
raw observation next is [14.5, 72.0, 1.0, 2.0, 0.20204256598461, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 219364.3944850136, 219364.3944850139, 70690.11721081386], 
processed observation next is [1.0, 0.043478260869565216, 0.29545454545454547, 0.72, 1.0, 1.0, 0.002553207480762501, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08124607203148651, 0.08124607203148664, 0.17241492002637526], 
reward next is 0.8276, 
noisyNet noise sample is [array([-2.643204], dtype=float32), 0.47534138]. 
=============================================
[2019-03-23 01:31:49,624] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:31:49,634] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4596
[2019-03-23 01:31:49,639] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.0, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 197734.3300852345, 197734.3300852343, 66191.9127047771], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2343600.0000, 
sim time next is 2344200.0000, 
raw observation next is [12.16666666666667, 88.00000000000001, 1.0, 2.0, 0.2305069317262396, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 250277.0627789807, 250277.062778981, 72120.9584640484], 
processed observation next is [1.0, 0.13043478260869565, 0.18939393939393953, 0.8800000000000001, 1.0, 1.0, 0.03813366465779948, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09269520843665952, 0.09269520843665963, 0.17590477674158145], 
reward next is 0.8241, 
noisyNet noise sample is [array([0.87476516], dtype=float32), 1.2620438]. 
=============================================
[2019-03-23 01:31:59,748] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 1.125257e-30 0.000000e+00 5.911110e-28], sum to 1.0000
[2019-03-23 01:31:59,755] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3567
[2019-03-23 01:31:59,762] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1694998.29650958 W.
[2019-03-23 01:31:59,768] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.5, 72.0, 1.0, 2.0, 0.5170500045547144, 1.0, 1.0, 0.5023134392189645, 1.0, 2.0, 0.9865530188920543, 6.911199999999999, 6.9112, 77.3421103, 1694998.29650958, 1694998.29650958, 358772.7821673196], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2892600.0000, 
sim time next is 2893200.0000, 
raw observation next is [27.66666666666666, 71.33333333333333, 1.0, 2.0, 0.4788602209422857, 1.0, 2.0, 0.4788602209422857, 1.0, 2.0, 0.968915922601947, 6.911199999999999, 6.9112, 77.3421103, 1615745.19718517, 1615745.197185171, 348549.6432988947], 
processed observation next is [1.0, 0.4782608695652174, 0.8939393939393937, 0.7133333333333333, 1.0, 1.0, 0.3485752761778571, 1.0, 1.0, 0.3485752761778571, 1.0, 1.0, 0.9555941751456386, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.5984241471056185, 0.5984241471056189, 0.8501210812168163], 
reward next is 0.1499, 
noisyNet noise sample is [array([-0.94305617], dtype=float32), -0.09053638]. 
=============================================
[2019-03-23 01:31:59,973] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:31:59,981] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5520
[2019-03-23 01:31:59,984] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 88.00000000000001, 1.0, 2.0, 0.4383201935949627, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 498679.3366191677, 498679.3366191677, 131536.3306815886], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3193800.0000, 
sim time next is 3194400.0000, 
raw observation next is [21.0, 88.0, 1.0, 2.0, 0.4392997817700109, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 499795.5080413604, 499795.5080413604, 131636.5424806404], 
processed observation next is [1.0, 1.0, 0.5909090909090909, 0.88, 1.0, 1.0, 0.2991247272125136, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1851094474227261, 0.1851094474227261, 0.32106473775765954], 
reward next is 0.6789, 
noisyNet noise sample is [array([-0.9339147], dtype=float32), -0.600056]. 
=============================================
[2019-03-23 01:32:03,893] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:32:03,900] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8749
[2019-03-23 01:32:03,908] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.2, 75.0, 1.0, 2.0, 0.440766081145765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 502300.5753403582, 502300.5753403582, 132721.552186803], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2715600.0000, 
sim time next is 2716200.0000, 
raw observation next is [23.4, 73.5, 1.0, 2.0, 0.4399547490022283, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 501339.731847281, 501339.731847281, 132589.0312501123], 
processed observation next is [0.0, 0.43478260869565216, 0.7, 0.735, 1.0, 1.0, 0.29994343625278536, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18568138216565963, 0.18568138216565963, 0.3233878810978349], 
reward next is 0.6766, 
noisyNet noise sample is [array([0.9712983], dtype=float32), -1.244248]. 
=============================================
[2019-03-23 01:32:15,491] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-23 01:32:15,492] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 01:32:15,493] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 01:32:15,493] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:32:15,495] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 01:32:15,495] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:32:15,493] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 01:32:15,497] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:32:15,496] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 01:32:15,500] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:32:15,500] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:32:15,529] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run72
[2019-03-23 01:32:15,556] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run72
[2019-03-23 01:32:15,557] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run72
[2019-03-23 01:32:15,558] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run72
[2019-03-23 01:32:15,580] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run72
[2019-03-23 01:32:53,989] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.910553], dtype=float32), -0.17166165]
[2019-03-23 01:32:53,992] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [23.23578522333333, 74.58977922, 1.0, 2.0, 0.4201128425843287, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 478406.6056359515, 478406.6056359512, 134546.8487986298]
[2019-03-23 01:32:53,994] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 01:32:53,995] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.9209134611906854
[2019-03-23 01:33:03,906] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.910553], dtype=float32), -0.17166165]
[2019-03-23 01:33:03,907] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [28.18488308, 44.25010387666667, 1.0, 2.0, 0.5596907174051095, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 635452.2740728765, 635452.2740728762, 148073.9536266482]
[2019-03-23 01:33:03,910] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 01:33:03,912] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.19372828824620503
[2019-03-23 01:33:54,641] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.910553], dtype=float32), -0.17166165]
[2019-03-23 01:33:54,642] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.8, 84.33333333333334, 1.0, 2.0, 0.4986283293335566, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 568918.7942909641, 568918.7942909641, 145282.656270906]
[2019-03-23 01:33:54,644] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 01:33:54,650] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.27520602894768154
[2019-03-23 01:34:05,198] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8594.4987 1706116953.1019 465.0000
[2019-03-23 01:34:05,648] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8854.1746 1663949029.5070 105.0000
[2019-03-23 01:34:05,931] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8571.9617 1683477666.0862 214.0000
[2019-03-23 01:34:05,932] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9058.6831 1656359050.7176 80.0000
[2019-03-23 01:34:05,963] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8509.1813 1773413472.9632 173.0000
[2019-03-23 01:34:06,977] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 1775000, evaluation results [1775000.0, 8509.181281245757, 1773413472.9631987, 173.0, 9058.683074210225, 1656359050.7176125, 80.0, 8854.174594824059, 1663949029.507014, 105.0, 8594.49866461476, 1706116953.1019058, 465.0, 8571.9617444755, 1683477666.0861843, 214.0]
[2019-03-23 01:34:08,110] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:34:08,120] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3192
[2019-03-23 01:34:08,127] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 61.0, 1.0, 2.0, 0.4582423144301236, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 522747.8418451841, 522747.8418451841, 135504.3716125188], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2840400.0000, 
sim time next is 2841000.0000, 
raw observation next is [25.66666666666667, 63.83333333333334, 1.0, 2.0, 0.4617208446161577, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 526798.1428257277, 526798.1428257277, 136156.1590223736], 
processed observation next is [1.0, 0.9130434782608695, 0.8030303030303032, 0.6383333333333334, 1.0, 1.0, 0.3271510557701971, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19511042326878802, 0.19511042326878802, 0.3320881927374966], 
reward next is 0.6679, 
noisyNet noise sample is [array([0.59149975], dtype=float32), -1.2961755]. 
=============================================
[2019-03-23 01:34:08,141] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[58.278645]
 [58.276352]
 [58.33424 ]
 [58.448605]
 [58.454624]], R is [[58.29227829]
 [58.37885666]
 [58.46497345]
 [58.55086136]
 [58.63686752]].
[2019-03-23 01:34:15,115] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:34:15,123] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6395
[2019-03-23 01:34:15,128] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 73.5, 1.0, 2.0, 0.4382143200220447, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 499554.1619126612, 499554.1619126615, 132699.0140067585], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3173400.0000, 
sim time next is 3174000.0000, 
raw observation next is [23.33333333333333, 73.33333333333333, 1.0, 2.0, 0.4369001509820121, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 497764.5962155668, 497764.5962155668, 132153.3128209852], 
processed observation next is [1.0, 0.7391304347826086, 0.6969696969696968, 0.7333333333333333, 1.0, 1.0, 0.29612518872751514, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18435725785761733, 0.18435725785761733, 0.3223251532219151], 
reward next is 0.6777, 
noisyNet noise sample is [array([-2.2076774], dtype=float32), -0.93738526]. 
=============================================
[2019-03-23 01:34:15,142] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[61.543224]
 [60.522312]
 [58.557247]
 [54.10576 ]
 [52.740215]], R is [[61.75828171]
 [61.8170433 ]
 [61.8680687 ]
 [61.77316284]
 [61.50706482]].
[2019-03-23 01:34:24,529] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 7.7951852e-35 0.0000000e+00 3.8881947e-29], sum to 1.0000
[2019-03-23 01:34:24,535] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6140
[2019-03-23 01:34:24,543] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1359345.526165495 W.
[2019-03-23 01:34:24,550] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.16666666666666, 68.66666666666667, 1.0, 2.0, 0.604442664586716, 1.0, 2.0, 0.604442664586716, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1359345.526165495, 1359345.526165495, 263235.627299692], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3503400.0000, 
sim time next is 3504000.0000, 
raw observation next is [27.33333333333334, 67.33333333333334, 1.0, 2.0, 0.7017418853086745, 1.0, 2.0, 0.7017418853086745, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1578469.090251733, 1578469.090251733, 292337.3576002484], 
processed observation next is [1.0, 0.5652173913043478, 0.878787878787879, 0.6733333333333335, 1.0, 1.0, 0.6271773566358432, 1.0, 1.0, 0.6271773566358432, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.584618181574716, 0.584618181574716, 0.7130179453664596], 
reward next is 0.2870, 
noisyNet noise sample is [array([0.53753716], dtype=float32), 1.553369]. 
=============================================
[2019-03-23 01:34:24,566] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[55.41374 ]
 [56.289894]
 [55.82552 ]
 [54.601654]
 [52.86182 ]], R is [[53.84514236]
 [53.66465378]
 [53.41996384]
 [53.20707321]
 [52.99777603]].
[2019-03-23 01:34:39,160] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.77303528e-35 1.00000000e+00 3.05687995e-35 3.25102164e-17
 1.04451524e-29], sum to 1.0000
[2019-03-23 01:34:39,169] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3339
[2019-03-23 01:34:39,175] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 60.0, 1.0, 2.0, 0.7108049257699472, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 787430.4775476579, 787430.4775476579, 153422.0100568898], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3776400.0000, 
sim time next is 3777000.0000, 
raw observation next is [21.83333333333334, 60.66666666666666, 1.0, 2.0, 0.4586160643336278, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 506625.5243620845, 506625.5243620842, 126075.8192592645], 
processed observation next is [1.0, 0.7391304347826086, 0.628787878787879, 0.6066666666666666, 1.0, 1.0, 0.3232700804170347, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18763908309706834, 0.18763908309706823, 0.3075019981933281], 
reward next is 0.6925, 
noisyNet noise sample is [array([-1.7090468], dtype=float32), -0.4271192]. 
=============================================
[2019-03-23 01:34:39,190] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[54.505653]
 [54.43765 ]
 [54.78529 ]
 [55.451405]
 [54.7681  ]], R is [[57.69882965]
 [57.74764252]
 [57.79478073]
 [57.84970856]
 [57.92427063]].
[2019-03-23 01:34:39,704] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.6954324e-32 0.0000000e+00], sum to 1.0000
[2019-03-23 01:34:39,706] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4831
[2019-03-23 01:34:39,717] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.5, 78.5, 1.0, 2.0, 0.3455236885753852, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 382415.7800694666, 382415.7800694666, 116947.3444140045], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3785400.0000, 
sim time next is 3786000.0000, 
raw observation next is [19.0, 81.66666666666667, 1.0, 2.0, 0.344606122875932, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 380887.5384437909, 380887.5384437906, 116675.5842280878], 
processed observation next is [1.0, 0.8260869565217391, 0.5, 0.8166666666666668, 1.0, 1.0, 0.180757653594915, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14106945868288553, 0.1410694586828854, 0.28457459567826293], 
reward next is 0.7154, 
noisyNet noise sample is [array([-1.1064494], dtype=float32), -0.56500095]. 
=============================================
[2019-03-23 01:34:39,744] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[68.51744 ]
 [68.59617 ]
 [68.75184 ]
 [68.945045]
 [69.05622 ]], R is [[68.51925659]
 [68.54882812]
 [68.57750702]
 [68.60546112]
 [68.63342285]].
[2019-03-23 01:34:48,072] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.7997656e-33 3.0738697e-28 3.1013578e-22], sum to 1.0000
[2019-03-23 01:34:48,082] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3206
[2019-03-23 01:34:48,089] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.5079421296610465, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 579279.8913738882, 579279.8913738879, 143023.2531962882], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3619800.0000, 
sim time next is 3620400.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.5111773876469405, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 582970.4143683066, 582970.4143683069, 143408.537875614], 
processed observation next is [1.0, 0.9130434782608695, 0.6363636363636364, 0.94, 1.0, 1.0, 0.3889717345586756, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.215914968284558, 0.2159149682845581, 0.3497769216478391], 
reward next is 0.6502, 
noisyNet noise sample is [array([-2.7984912], dtype=float32), 0.5709344]. 
=============================================
[2019-03-23 01:34:48,835] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.4390217e-35 1.0000000e+00 2.8795058e-27 1.5193202e-29 2.9396209e-24], sum to 1.0000
[2019-03-23 01:34:48,844] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0228
[2019-03-23 01:34:48,851] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.491369333766301, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 560629.6346433408, 560629.6346433408, 140492.7289641036], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3633000.0000, 
sim time next is 3633600.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.4910758108554579, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 560294.6409624402, 560294.6409624405, 140458.7367836387], 
processed observation next is [1.0, 0.043478260869565216, 0.5909090909090909, 1.0, 1.0, 1.0, 0.3638447635693223, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20751653368979264, 0.20751653368979278, 0.3425822848381432], 
reward next is 0.6574, 
noisyNet noise sample is [array([-0.3266311], dtype=float32), 0.48734072]. 
=============================================
[2019-03-23 01:34:49,997] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.4105490e-34 1.0000000e+00 8.8574902e-29 5.9549023e-21 6.1862733e-14], sum to 1.0000
[2019-03-23 01:34:50,005] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3126
[2019-03-23 01:34:50,010] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.505547914995118, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 576813.041227276, 576813.041227276, 142144.9656535948], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3646200.0000, 
sim time next is 3646800.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.5040677725826117, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 575123.6903119136, 575123.6903119136, 141970.7343893655], 
processed observation next is [1.0, 0.21739130434782608, 0.5909090909090909, 1.0, 1.0, 1.0, 0.3800847157282646, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21300877418959763, 0.21300877418959763, 0.3462700838765012], 
reward next is 0.6537, 
noisyNet noise sample is [array([0.86769176], dtype=float32), -1.2256246]. 
=============================================
[2019-03-23 01:34:50,508] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:34:50,517] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0652
[2019-03-23 01:34:50,522] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666667, 57.00000000000001, 1.0, 2.0, 0.3348332417087067, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 370247.5744750371, 370247.5744750371, 115998.2465963177], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3864000.0000, 
sim time next is 3864600.0000, 
raw observation next is [22.5, 57.0, 1.0, 2.0, 0.3306451448063228, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 364728.5102100467, 364728.510210047, 115335.9579086701], 
processed observation next is [0.0, 0.7391304347826086, 0.6590909090909091, 0.57, 1.0, 1.0, 0.16330643100790346, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13508463341112842, 0.13508463341112853, 0.2813072144113905], 
reward next is 0.7187, 
noisyNet noise sample is [array([-1.1318799], dtype=float32), 1.1610947]. 
=============================================
[2019-03-23 01:34:52,325] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.6981540e-22 9.9999905e-01 5.7176436e-21 2.7237105e-13 9.3394328e-07], sum to 1.0000
[2019-03-23 01:34:52,337] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9044
[2019-03-23 01:34:52,342] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 94.0, 1.0, 2.0, 0.3275885088858099, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 358442.2080257083, 358442.2080257086, 114025.8127584549], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4054800.0000, 
sim time next is 4055400.0000, 
raw observation next is [17.0, 94.0, 1.0, 2.0, 0.3240118310928842, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 354511.8315758604, 354511.8315758601, 113763.892294335], 
processed observation next is [1.0, 0.9565217391304348, 0.4090909090909091, 0.94, 1.0, 1.0, 0.1550147888661052, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13130067836142978, 0.13130067836142967, 0.27747290803496344], 
reward next is 0.7225, 
noisyNet noise sample is [array([0.4181426], dtype=float32), 0.2592738]. 
=============================================
[2019-03-23 01:34:52,875] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.2270833e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 01:34:52,886] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5269
[2019-03-23 01:34:52,894] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.5, 60.0, 1.0, 2.0, 0.511509628802325, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 582895.5660518701, 582895.5660518698, 144019.7848438061], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3695400.0000, 
sim time next is 3696000.0000, 
raw observation next is [27.33333333333334, 60.66666666666666, 1.0, 2.0, 0.5097356727363153, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 580938.6104948006, 580938.6104948006, 143738.7894563729], 
processed observation next is [1.0, 0.782608695652174, 0.878787878787879, 0.6066666666666666, 1.0, 1.0, 0.38716959092039405, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21516244833140763, 0.21516244833140763, 0.3505824133082266], 
reward next is 0.6494, 
noisyNet noise sample is [array([-0.9542912], dtype=float32), 0.64995694]. 
=============================================
[2019-03-23 01:34:52,901] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[64.45427 ]
 [64.168884]
 [64.4135  ]
 [64.37218 ]
 [64.51725 ]], R is [[64.48439026]
 [64.48828125]
 [64.49189758]
 [64.49564362]
 [64.49990845]].
[2019-03-23 01:34:55,693] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-23 01:34:55,695] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 01:34:55,695] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 01:34:55,696] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 01:34:55,698] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:34:55,698] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 01:34:55,696] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:34:55,701] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:34:55,703] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:34:55,700] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 01:34:55,707] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:34:55,734] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run73
[2019-03-23 01:34:55,760] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run73
[2019-03-23 01:34:55,761] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run73
[2019-03-23 01:34:55,785] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run73
[2019-03-23 01:34:55,786] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run73
[2019-03-23 01:35:12,364] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.87101966], dtype=float32), -0.21001886]
[2019-03-23 01:35:12,366] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [26.53333333333333, 65.33333333333333, 1.0, 2.0, 0.5081781359936705, 0.0, 2.0, 0.0, 1.0, 1.0, 0.8879488684415897, 7.033335707093761, 6.9112, 95.55299586971242, 1126448.480329546, 1077432.662924553, 254756.2663873932]
[2019-03-23 01:35:12,368] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 01:35:12,370] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 4.7069574e-30], sampled 0.41139059545041634
[2019-03-23 01:35:12,372] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1126448.480329546 W.
[2019-03-23 01:35:39,008] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.87101966], dtype=float32), -0.21001886]
[2019-03-23 01:35:39,010] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.0, 88.5, 1.0, 2.0, 0.5971463425209921, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 659216.9347269076, 659216.9347269076, 139555.353085059]
[2019-03-23 01:35:39,013] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 01:35:39,017] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 1.8142652e-37 1.3593136e-38 3.3976041e-33], sampled 0.3815064112452754
[2019-03-23 01:35:40,872] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.87101966], dtype=float32), -0.21001886]
[2019-03-23 01:35:40,874] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.11471757333333, 75.09414147333334, 1.0, 2.0, 0.3971397698312109, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 446626.4974464144, 446626.4974464144, 128450.9662096471]
[2019-03-23 01:35:40,880] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 01:35:40,882] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.06552301124893489
[2019-03-23 01:35:47,894] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.87101966], dtype=float32), -0.21001886]
[2019-03-23 01:35:47,894] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [28.13554333333333, 58.35704882666668, 1.0, 2.0, 0.5426987521091993, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 617048.435292803, 617048.435292803, 153129.8755174614]
[2019-03-23 01:35:47,895] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 01:35:47,900] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.9027628146729295
[2019-03-23 01:35:57,493] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.87101966], dtype=float32), -0.21001886]
[2019-03-23 01:35:57,495] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [27.16666666666666, 57.5, 1.0, 2.0, 0.4769958480662473, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 544277.285079412, 544277.2850794124, 138578.4471776102]
[2019-03-23 01:35:57,496] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 01:35:57,501] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.4169153e-35 0.0000000e+00], sampled 0.24065630548441264
[2019-03-23 01:36:09,818] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.87101966], dtype=float32), -0.21001886]
[2019-03-23 01:36:09,819] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [18.06666666666667, 85.83333333333334, 1.0, 2.0, 0.4078094922914315, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 447906.7449630222, 447906.7449630219, 125052.0275907764]
[2019-03-23 01:36:09,821] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 01:36:09,825] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.8567537920091646
[2019-03-23 01:36:11,791] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.87101966], dtype=float32), -0.21001886]
[2019-03-23 01:36:11,792] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.57064076666667, 98.58674351666667, 1.0, 2.0, 0.4761614729787816, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 543164.945276607, 543164.945276607, 141824.0444298247]
[2019-03-23 01:36:11,795] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 01:36:11,798] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.3536732e-38], sampled 0.5302880391783659
[2019-03-23 01:36:46,001] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8592.0601 1706242222.4174 465.0000
[2019-03-23 01:36:46,268] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9055.4314 1656525891.1207 80.0000
[2019-03-23 01:36:46,327] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8569.0423 1683679931.9503 214.0000
[2019-03-23 01:36:46,466] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8851.2566 1664152039.1676 105.0000
[2019-03-23 01:36:46,476] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8507.0038 1773566163.6992 173.0000
[2019-03-23 01:36:47,492] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 1800000, evaluation results [1800000.0, 8507.003781615034, 1773566163.6991806, 173.0, 9055.431439997737, 1656525891.120677, 80.0, 8851.256611154593, 1664152039.1676362, 105.0, 8592.06009615295, 1706242222.4174447, 465.0, 8569.042332002715, 1683679931.9503295, 214.0]
[2019-03-23 01:36:52,018] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:36:52,025] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9226
[2019-03-23 01:36:52,030] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.83333333333334, 73.83333333333333, 1.0, 2.0, 0.3219795317201821, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 354418.4489759358, 354418.4489759358, 114408.335579667], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3837000.0000, 
sim time next is 3837600.0000, 
raw observation next is [20.0, 73.0, 1.0, 2.0, 0.3230282817147332, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 355871.9209462374, 355871.9209462377, 114598.9586793705], 
processed observation next is [0.0, 0.43478260869565216, 0.5454545454545454, 0.73, 1.0, 1.0, 0.15378535214341646, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1318044151652731, 0.13180441516527322, 0.2795096553155378], 
reward next is 0.7205, 
noisyNet noise sample is [array([1.7034613], dtype=float32), 2.0398984]. 
=============================================
[2019-03-23 01:37:00,104] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 9.856087e-31 0.000000e+00], sum to 1.0000
[2019-03-23 01:37:00,114] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6001
[2019-03-23 01:37:00,118] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 94.0, 1.0, 2.0, 0.5530507929478597, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 616866.6354456866, 616866.6354456866, 137335.2318505767], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4032000.0000, 
sim time next is 4032600.0000, 
raw observation next is [18.0, 94.00000000000001, 1.0, 2.0, 0.6243931698091039, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 696419.3434587806, 696419.3434587806, 145154.6080312092], 
processed observation next is [1.0, 0.6956521739130435, 0.45454545454545453, 0.9400000000000002, 1.0, 1.0, 0.5304914622613798, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2579330901699187, 0.2579330901699187, 0.3540356293444127], 
reward next is 0.6460, 
noisyNet noise sample is [array([1.7414211], dtype=float32), -0.42422262]. 
=============================================
[2019-03-23 01:37:00,964] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.00000000e+00 1.00000000e+00 1.09225695e-36 1.01702072e-35
 5.54410388e-36], sum to 1.0000
[2019-03-23 01:37:00,973] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9559
[2019-03-23 01:37:00,978] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 85.5, 1.0, 2.0, 0.4299217161751986, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 470850.6928636465, 470850.6928636468, 122125.9380656523], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4005000.0000, 
sim time next is 4005600.0000, 
raw observation next is [18.0, 86.33333333333334, 1.0, 2.0, 0.4559565431650219, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 500538.7923520895, 500538.7923520898, 124743.1747130915], 
processed observation next is [1.0, 0.34782608695652173, 0.45454545454545453, 0.8633333333333334, 1.0, 1.0, 0.3199456789562773, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1853847379081813, 0.18538473790818139, 0.3042516456416866], 
reward next is 0.6957, 
noisyNet noise sample is [array([-0.2638067], dtype=float32), -0.26768538]. 
=============================================
[2019-03-23 01:37:02,627] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 4.865804e-33 1.976132e-29 0.000000e+00], sum to 1.0000
[2019-03-23 01:37:02,636] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8924
[2019-03-23 01:37:02,645] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 94.0, 1.0, 2.0, 0.5533988678690038, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 617032.8670627321, 617032.8670627321, 137283.2905638127], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4035600.0000, 
sim time next is 4036200.0000, 
raw observation next is [17.83333333333333, 94.00000000000001, 1.0, 2.0, 0.4221563282272324, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 469512.5470728858, 469512.5470728858, 124077.5085622668], 
processed observation next is [1.0, 0.7391304347826086, 0.44696969696969674, 0.9400000000000002, 1.0, 1.0, 0.2776954102840405, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17389353595292067, 0.17389353595292067, 0.30262806966406536], 
reward next is 0.6974, 
noisyNet noise sample is [array([-0.5253124], dtype=float32), -0.63536656]. 
=============================================
[2019-03-23 01:37:02,824] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 6.9421419e-38 1.1538229e-32 0.0000000e+00], sum to 1.0000
[2019-03-23 01:37:02,833] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2696
[2019-03-23 01:37:02,838] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 94.0, 1.0, 2.0, 0.3345622444334198, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 366451.8598301183, 366451.8598301183, 114663.8665722539], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4039200.0000, 
sim time next is 4039800.0000, 
raw observation next is [17.0, 95.0, 1.0, 2.0, 0.3366214463914776, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 368936.3511369004, 368936.3511369004, 114896.8123517901], 
processed observation next is [1.0, 0.782608695652174, 0.4090909090909091, 0.95, 1.0, 1.0, 0.170776807989347, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1366430930136668, 0.1366430930136668, 0.28023612768729295], 
reward next is 0.7198, 
noisyNet noise sample is [array([0.07831093], dtype=float32), -0.5738513]. 
=============================================
[2019-03-23 01:37:05,828] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 9.7173388e-35 5.4281673e-36 3.3894159e-37], sum to 1.0000
[2019-03-23 01:37:05,839] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6295
[2019-03-23 01:37:05,847] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.33333333333334, 98.0, 1.0, 2.0, 0.3403055623643219, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 377261.516177143, 377261.5161771433, 116797.3221164114], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4087200.0000, 
sim time next is 4087800.0000, 
raw observation next is [17.5, 97.0, 1.0, 2.0, 0.3381893105450595, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 375243.2619507451, 375243.2619507451, 116769.260976171], 
processed observation next is [1.0, 0.30434782608695654, 0.4318181818181818, 0.97, 1.0, 1.0, 0.17273663818132437, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13897898590768337, 0.13897898590768337, 0.2848030755516366], 
reward next is 0.7152, 
noisyNet noise sample is [array([0.52397585], dtype=float32), -0.6782561]. 
=============================================
[2019-03-23 01:37:11,749] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.4366150e-37 1.0000000e+00 0.0000000e+00 4.3206534e-28 1.3038874e-23], sum to 1.0000
[2019-03-23 01:37:11,755] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5087
[2019-03-23 01:37:11,765] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 65.0, 1.0, 2.0, 0.7973976540788824, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 901112.9020266846, 901112.9020266846, 172338.3461385176], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4190400.0000, 
sim time next is 4191000.0000, 
raw observation next is [23.16666666666667, 64.33333333333334, 1.0, 2.0, 0.7510857763044918, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 848927.3917071573, 848927.3917071573, 165896.4426727243], 
processed observation next is [1.0, 0.5217391304347826, 0.6893939393939396, 0.6433333333333334, 1.0, 1.0, 0.6888572203806148, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.31441755248413233, 0.31441755248413233, 0.4046254699334739], 
reward next is 0.5954, 
noisyNet noise sample is [array([0.5747173], dtype=float32), 0.7819217]. 
=============================================
[2019-03-23 01:37:11,778] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[63.328354]
 [63.73706 ]
 [64.23567 ]
 [64.88122 ]
 [65.22764 ]], R is [[63.39893723]
 [63.34461212]
 [63.29432297]
 [63.25226974]
 [63.22879028]].
[2019-03-23 01:37:16,413] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.4316487e-28 0.0000000e+00], sum to 1.0000
[2019-03-23 01:37:16,420] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8285
[2019-03-23 01:37:16,425] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.46666666666667, 57.0, 1.0, 2.0, 0.844278715310144, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 955134.1832122474, 955134.1832122478, 179845.312387277], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4272000.0000, 
sim time next is 4272600.0000, 
raw observation next is [24.58333333333333, 56.0, 1.0, 2.0, 0.8449939784619057, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 955480.3809805921, 955480.3809805921, 179678.1381841691], 
processed observation next is [1.0, 0.43478260869565216, 0.7537878787878786, 0.56, 1.0, 1.0, 0.8062424730773821, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3538816225854045, 0.3538816225854045, 0.4382393614248027], 
reward next is 0.5618, 
noisyNet noise sample is [array([-1.7357913], dtype=float32), 0.64872533]. 
=============================================
[2019-03-23 01:37:23,019] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 2.1352595e-20], sum to 1.0000
[2019-03-23 01:37:23,025] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8441
[2019-03-23 01:37:23,030] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.58333333333333, 80.5, 1.0, 2.0, 0.4569030265639091, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 520945.4239691026, 520945.4239691026, 134777.9213276618], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4405800.0000, 
sim time next is 4406400.0000, 
raw observation next is [22.5, 81.0, 1.0, 2.0, 0.4567682410844019, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 520774.3644148069, 520774.3644148067, 134734.4428809145], 
processed observation next is [0.0, 0.0, 0.6590909090909091, 0.81, 1.0, 1.0, 0.32096030135550235, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19287939422770625, 0.1928793942277062, 0.3286205923924744], 
reward next is 0.6714, 
noisyNet noise sample is [array([0.19471274], dtype=float32), 1.0313711]. 
=============================================
[2019-03-23 01:37:23,981] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.42270204e-38 1.00000000e+00 1.05885014e-35 8.58197002e-27
 1.33524483e-25], sum to 1.0000
[2019-03-23 01:37:23,994] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5971
[2019-03-23 01:37:23,999] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.7, 83.5, 1.0, 2.0, 0.4716636932523403, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 538196.125392908, 538196.1253929083, 137534.0615975614], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5178600.0000, 
sim time next is 5179200.0000, 
raw observation next is [22.6, 83.66666666666667, 1.0, 2.0, 0.4684669235245347, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 534525.2261612947, 534525.2261612947, 137021.0079179645], 
processed observation next is [0.0, 0.9565217391304348, 0.6636363636363637, 0.8366666666666667, 1.0, 1.0, 0.3355836544056683, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1979723059856647, 0.1979723059856647, 0.33419758028771834], 
reward next is 0.6658, 
noisyNet noise sample is [array([-0.00012821], dtype=float32), 1.2451401]. 
=============================================
[2019-03-23 01:37:26,036] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 4.0671363e-37 1.6378123e-32 6.7931253e-33], sum to 1.0000
[2019-03-23 01:37:26,045] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6849
[2019-03-23 01:37:26,051] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 65.0, 1.0, 2.0, 0.4947889728699278, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 564489.5195635838, 564489.5195635838, 141025.7406459966], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4460400.0000, 
sim time next is 4461000.0000, 
raw observation next is [26.0, 65.83333333333334, 1.0, 2.0, 0.4954669834184399, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 565199.5073410688, 565199.5073410688, 141266.1817792084], 
processed observation next is [0.0, 0.6521739130434783, 0.8181818181818182, 0.6583333333333334, 1.0, 1.0, 0.36933372927304986, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20933315086706253, 0.20933315086706253, 0.34455166287611805], 
reward next is 0.6554, 
noisyNet noise sample is [array([0.01343675], dtype=float32), -2.017536]. 
=============================================
[2019-03-23 01:37:26,060] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[67.13334 ]
 [67.05741 ]
 [66.9997  ]
 [66.951775]
 [66.916176]], R is [[67.10935974]
 [67.09430695]
 [67.07805634]
 [67.06064606]
 [67.04206848]].
[2019-03-23 01:37:36,305] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:37:36,309] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1965
[2019-03-23 01:37:36,313] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 64.0, 1.0, 2.0, 0.2648015234051812, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 287524.0413995275, 287524.0413995275, 90723.2262650764], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4655400.0000, 
sim time next is 4656000.0000, 
raw observation next is [19.0, 64.0, 1.0, 2.0, 0.2635957275987933, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 286214.391458178, 286214.3914581777, 90589.07919787308], 
processed observation next is [1.0, 0.9130434782608695, 0.5, 0.64, 1.0, 1.0, 0.0794946594984916, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10600533016969556, 0.10600533016969545, 0.22094897365334898], 
reward next is 0.7791, 
noisyNet noise sample is [array([-0.47771642], dtype=float32), 0.0038391436]. 
=============================================
[2019-03-23 01:37:36,326] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[75.13145]
 [75.13127]
 [75.08374]
 [75.06221]
 [75.01621]], R is [[75.18460083]
 [75.21147919]
 [75.23783875]
 [75.264328  ]
 [75.2908783 ]].
[2019-03-23 01:37:38,665] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-23 01:37:38,666] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 01:37:38,667] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 01:37:38,668] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:37:38,669] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:37:38,670] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 01:37:38,672] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 01:37:38,673] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:37:38,670] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 01:37:38,674] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:37:38,676] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:37:38,696] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run74
[2019-03-23 01:37:38,719] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run74
[2019-03-23 01:37:38,722] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run74
[2019-03-23 01:37:38,722] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run74
[2019-03-23 01:37:38,795] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run74
[2019-03-23 01:38:07,376] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.87290365], dtype=float32), -0.29518762]
[2019-03-23 01:38:07,378] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [17.69853345, 63.64149444, 1.0, 2.0, 0.2506721165949916, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 272163.3783124261, 272163.3783124264, 85555.85249015165]
[2019-03-23 01:38:07,379] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 01:38:07,380] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.0713111906352677
[2019-03-23 01:38:08,747] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.87290365], dtype=float32), -0.29518762]
[2019-03-23 01:38:08,748] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.5, 68.0, 1.0, 2.0, 0.2622728426697568, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 284761.671168795, 284761.671168795, 95392.29763457777]
[2019-03-23 01:38:08,749] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 01:38:08,754] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.5377605892305783
[2019-03-23 01:38:14,228] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.87290365], dtype=float32), -0.29518762]
[2019-03-23 01:38:14,231] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [12.274025768, 95.58918170666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 206660.7191502186, 206660.7191502182, 73743.24622303271]
[2019-03-23 01:38:14,235] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 01:38:14,238] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 4.8671674e-37], sampled 0.590196165829328
[2019-03-23 01:38:15,442] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.87290365], dtype=float32), -0.29518762]
[2019-03-23 01:38:15,444] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.983463805, 82.04134741666667, 1.0, 2.0, 0.3476939381636998, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 384822.9178748754, 384822.917874875, 121433.9484254733]
[2019-03-23 01:38:15,446] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 01:38:15,449] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.8310548667132395
[2019-03-23 01:38:27,079] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.87290365], dtype=float32), -0.29518762]
[2019-03-23 01:38:27,082] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.926745835, 91.40913552833334, 1.0, 2.0, 0.6538499034255418, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 734689.686031311, 734689.686031311, 170931.9046445641]
[2019-03-23 01:38:27,085] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 01:38:27,088] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 2.3747197e-38], sampled 0.6739616918738789
[2019-03-23 01:39:05,169] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.87290365], dtype=float32), -0.29518762]
[2019-03-23 01:39:05,170] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.82374552, 72.38628790499999, 1.0, 2.0, 0.3687490020395878, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 403877.6554682999, 403877.6554682995, 121534.1188097547]
[2019-03-23 01:39:05,172] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 01:39:05,177] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.1575410824847454
[2019-03-23 01:39:29,349] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9057.0586 1656443078.0244 80.0000
[2019-03-23 01:39:29,381] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8569.7595 1683629455.5724 214.0000
[2019-03-23 01:39:29,543] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8851.9735 1664101423.8647 105.0000
[2019-03-23 01:39:29,687] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8507.7271 1773514361.6667 173.0000
[2019-03-23 01:39:29,688] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8592.0601 1706242222.4174 465.0000
[2019-03-23 01:39:30,707] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 1825000, evaluation results [1825000.0, 8507.727149272585, 1773514361.6667252, 173.0, 9057.05855481395, 1656443078.0244372, 80.0, 8851.973532677643, 1664101423.8646872, 105.0, 8592.06009615295, 1706242222.4174447, 465.0, 8569.759499047412, 1683629455.5724304, 214.0]
[2019-03-23 01:39:33,404] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:39:33,414] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9709
[2019-03-23 01:39:33,420] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 65.0, 1.0, 2.0, 0.4157987638924668, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 472301.2863818037, 472301.2863818037, 128646.9939662459], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4730400.0000, 
sim time next is 4731000.0000, 
raw observation next is [24.0, 65.66666666666667, 1.0, 2.0, 0.4183247665922651, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 475346.4635955883, 475346.4635955883, 129033.922597548], 
processed observation next is [1.0, 0.782608695652174, 0.7272727272727273, 0.6566666666666667, 1.0, 1.0, 0.2729059582403313, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17605424577614381, 0.17605424577614381, 0.3147168843842634], 
reward next is 0.6853, 
noisyNet noise sample is [array([1.149277], dtype=float32), 0.9501133]. 
=============================================
[2019-03-23 01:39:33,442] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[68.79472 ]
 [68.14307 ]
 [67.9849  ]
 [67.276276]
 [65.78702 ]], R is [[68.90552521]
 [68.9026947 ]
 [68.89995575]
 [68.89743805]
 [68.89524841]].
[2019-03-23 01:39:36,991] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 6.7407097e-37 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 01:39:36,999] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9767
[2019-03-23 01:39:37,004] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.83333333333334, 83.00000000000001, 1.0, 2.0, 0.2740152009870689, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 297531.4013827565, 297531.4013827562, 94851.73891866134], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5011800.0000, 
sim time next is 5012400.0000, 
raw observation next is [16.66666666666667, 84.0, 1.0, 2.0, 0.2721268677951454, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 295480.3870694334, 295480.3870694334, 94052.1013895089], 
processed observation next is [0.0, 0.0, 0.39393939393939414, 0.84, 1.0, 1.0, 0.09015858474393172, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10943718039608645, 0.10943718039608645, 0.22939536924270462], 
reward next is 0.7706, 
noisyNet noise sample is [array([0.02963753], dtype=float32), 0.022402445]. 
=============================================
[2019-03-23 01:39:42,708] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:39:42,723] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2448
[2019-03-23 01:39:42,726] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333333, 81.33333333333334, 1.0, 2.0, 0.4129963383742565, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 468488.4172182077, 468488.4172182077, 127901.5043626965], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4909800.0000, 
sim time next is 4910400.0000, 
raw observation next is [21.0, 83.0, 1.0, 2.0, 0.4103175476516262, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 465095.0130534381, 465095.0130534384, 127398.8747727577], 
processed observation next is [1.0, 0.8695652173913043, 0.5909090909090909, 0.83, 1.0, 1.0, 0.2628969345645327, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1722574122420141, 0.1722574122420142, 0.31072896286038465], 
reward next is 0.6893, 
noisyNet noise sample is [array([-1.1829515], dtype=float32), 0.11229996]. 
=============================================
[2019-03-23 01:39:45,252] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:39:45,260] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7792
[2019-03-23 01:39:45,264] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.66666666666667, 74.66666666666667, 1.0, 2.0, 0.5399894132409541, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 613283.2233973027, 613283.223397303, 148881.3628326687], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5163000.0000, 
sim time next is 5163600.0000, 
raw observation next is [25.33333333333334, 75.33333333333334, 1.0, 2.0, 0.5372619580692399, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 610920.4091981691, 610920.4091981694, 148151.3734331164], 
processed observation next is [0.0, 0.782608695652174, 0.7878787878787882, 0.7533333333333334, 1.0, 1.0, 0.42157744758654986, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22626681822154412, 0.2262668182215442, 0.36134481325150336], 
reward next is 0.6387, 
noisyNet noise sample is [array([1.0065356], dtype=float32), 0.9449368]. 
=============================================
[2019-03-23 01:39:46,463] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.00000000e+00 1.00000000e+00 0.00000000e+00 1.29849684e-23
 0.00000000e+00], sum to 1.0000
[2019-03-23 01:39:46,472] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3192
[2019-03-23 01:39:46,475] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.93333333333334, 47.33333333333334, 1.0, 2.0, 0.4324641424021139, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 492333.4743460142, 492333.4743460142, 131267.3257014529], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5339400.0000, 
sim time next is 5340000.0000, 
raw observation next is [27.56666666666667, 48.66666666666667, 1.0, 2.0, 0.4296844407961185, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 489037.9845738495, 489037.9845738495, 130853.069698134], 
processed observation next is [1.0, 0.8260869565217391, 0.8893939393939395, 0.4866666666666667, 1.0, 1.0, 0.2871055509951481, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1811251794717961, 0.1811251794717961, 0.31915382853203417], 
reward next is 0.6808, 
noisyNet noise sample is [array([-1.5430137], dtype=float32), 0.7945015]. 
=============================================
[2019-03-23 01:39:46,484] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[62.681652]
 [63.001774]
 [63.04125 ]
 [63.074547]
 [63.154884]], R is [[62.9587822 ]
 [63.00902939]
 [63.05672455]
 [63.09965515]
 [63.13805771]].
[2019-03-23 01:39:55,771] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:39:55,778] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3231
[2019-03-23 01:39:55,786] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 83.0, 1.0, 2.0, 0.4329355927031092, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 493245.955639325, 493245.9556393247, 131749.8619988137], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5200200.0000, 
sim time next is 5200800.0000, 
raw observation next is [22.0, 83.0, 1.0, 2.0, 0.4313792521388989, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 491469.3500802136, 491469.3500802136, 131588.3561296366], 
processed observation next is [1.0, 0.17391304347826086, 0.6363636363636364, 0.83, 1.0, 1.0, 0.2892240651736236, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18202568521489393, 0.18202568521489393, 0.32094721007228444], 
reward next is 0.6791, 
noisyNet noise sample is [array([-0.31261203], dtype=float32), 2.1113284]. 
=============================================
[2019-03-23 01:40:03,573] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 2.4353995e-36 2.1883519e-32 3.1004028e-35], sum to 1.0000
[2019-03-23 01:40:03,579] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0602
[2019-03-23 01:40:03,585] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.11666666666666, 63.83333333333334, 1.0, 2.0, 0.7457167073858199, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 847625.8211689317, 847625.8211689317, 168307.4133635228], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5302200.0000, 
sim time next is 5302800.0000, 
raw observation next is [24.4, 62.0, 1.0, 2.0, 0.7370390405670733, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 837624.1039565594, 837624.1039565594, 166970.6288390398], 
processed observation next is [1.0, 0.391304347826087, 0.7454545454545454, 0.62, 1.0, 1.0, 0.6712988007088416, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.31023114961354054, 0.31023114961354054, 0.40724543619278], 
reward next is 0.5928, 
noisyNet noise sample is [array([0.7541038], dtype=float32), 0.28020322]. 
=============================================
[2019-03-23 01:40:04,379] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.3247245e-37 1.0000000e+00 7.2802831e-35 0.0000000e+00 2.3934013e-29], sum to 1.0000
[2019-03-23 01:40:04,386] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8567
[2019-03-23 01:40:04,394] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1283647.900805067 W.
[2019-03-23 01:40:04,398] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.21666666666667, 53.33333333333334, 1.0, 2.0, 0.6477885834253527, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9781482684332763, 6.911199999999999, 6.9112, 77.32846344354078, 1283647.900805067, 1283647.900805067, 285221.9938586509], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5316600.0000, 
sim time next is 5317200.0000, 
raw observation next is [29.4, 53.0, 1.0, 2.0, 0.4768456240546556, 1.0, 1.0, 0.4768456240546556, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1077957.227358871, 1077957.227358871, 228386.5741914028], 
processed observation next is [1.0, 0.5652173913043478, 0.9727272727272727, 0.53, 1.0, 1.0, 0.34605703006831945, 1.0, 0.5, 0.34605703006831945, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.39924341754032255, 0.39924341754032255, 0.5570404248570799], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.3668128], dtype=float32), -0.7051466]. 
=============================================
[2019-03-23 01:40:06,311] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:40:06,317] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7533
[2019-03-23 01:40:06,322] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.1, 54.0, 1.0, 2.0, 0.4233788319841739, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 481082.5325723207, 481082.5325723207, 129519.7489093122], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5344800.0000, 
sim time next is 5345400.0000, 
raw observation next is [26.1, 54.0, 1.0, 2.0, 0.4210021116400395, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 478378.1768656651, 478378.1768656651, 129285.0406540036], 
processed observation next is [1.0, 0.8695652173913043, 0.8227272727272728, 0.54, 1.0, 1.0, 0.2762526395500493, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17717710254283894, 0.17717710254283894, 0.31532936744878926], 
reward next is 0.6847, 
noisyNet noise sample is [array([0.8971584], dtype=float32), -0.69172466]. 
=============================================
[2019-03-23 01:40:11,263] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.7797849e-37 1.0000000e+00 1.8450101e-36 3.3183831e-16 2.1807634e-14], sum to 1.0000
[2019-03-23 01:40:11,272] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2576
[2019-03-23 01:40:11,274] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.4, 74.0, 1.0, 2.0, 0.4891154148558473, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 558086.8110545768, 558086.811054577, 140110.039574587], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5518800.0000, 
sim time next is 5519400.0000, 
raw observation next is [24.21666666666667, 74.33333333333334, 1.0, 2.0, 0.4850607495818039, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 553490.3327124427, 553490.3327124425, 139440.2683443007], 
processed observation next is [1.0, 0.9130434782608695, 0.7371212121212122, 0.7433333333333334, 1.0, 1.0, 0.35632593697725484, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20499641952312694, 0.20499641952312686, 0.3400982154739042], 
reward next is 0.6599, 
noisyNet noise sample is [array([-3.1317163], dtype=float32), -0.63226634]. 
=============================================
[2019-03-23 01:40:12,028] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 5.1092098e-33 6.5353688e-28], sum to 1.0000
[2019-03-23 01:40:12,042] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8302
[2019-03-23 01:40:12,046] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.45, 81.5, 1.0, 2.0, 0.3833827008602873, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 416335.7435632223, 416335.7435632223, 86765.35600211655], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5801400.0000, 
sim time next is 5802000.0000, 
raw observation next is [12.36666666666667, 82.0, 1.0, 2.0, 0.3838700670894554, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 416865.227458022, 416865.227458022, 86758.90298655523], 
processed observation next is [1.0, 0.13043478260869565, 0.19848484848484868, 0.82, 1.0, 1.0, 0.22983758386181927, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1543945286881563, 0.1543945286881563, 0.21160708045501275], 
reward next is 0.7884, 
noisyNet noise sample is [array([1.0749856], dtype=float32), -0.2321116]. 
=============================================
[2019-03-23 01:40:12,056] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[69.52887]
 [69.52748]
 [70.03941]
 [70.13954]
 [70.25412]], R is [[69.59227753]
 [69.68473053]
 [69.77620697]
 [69.86849976]
 [69.96421814]].
[2019-03-23 01:40:13,213] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.3461474e-34 1.0000000e+00 4.1183268e-38 2.9100889e-23 7.5652711e-13], sum to 1.0000
[2019-03-23 01:40:13,218] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8228
[2019-03-23 01:40:13,223] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.2, 95.0, 1.0, 2.0, 0.3269762733194131, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 359575.7567413406, 359575.7567413409, 114643.2848225369], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5467800.0000, 
sim time next is 5468400.0000, 
raw observation next is [17.2, 96.0, 1.0, 2.0, 0.3286617055359304, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 362117.8286965055, 362117.8286965055, 115027.0222153749], 
processed observation next is [1.0, 0.30434782608695654, 0.41818181818181815, 0.96, 1.0, 1.0, 0.16082713191991296, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1341177143320391, 0.1341177143320391, 0.2805537127204266], 
reward next is 0.7194, 
noisyNet noise sample is [array([-1.9663093], dtype=float32), -0.52273905]. 
=============================================
[2019-03-23 01:40:17,407] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.9941550e-29 1.8731313e-33], sum to 1.0000
[2019-03-23 01:40:17,419] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3323
[2019-03-23 01:40:17,424] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 76.0, 1.0, 2.0, 0.358389248163288, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 400282.8401446967, 400282.8401446967, 119456.5590217559], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6208800.0000, 
sim time next is 6209400.0000, 
raw observation next is [20.5, 76.0, 1.0, 2.0, 0.3583916294822779, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 400286.116823387, 400286.1168233868, 119457.027613119], 
processed observation next is [1.0, 0.8695652173913043, 0.5681818181818182, 0.76, 1.0, 1.0, 0.19798953685284731, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14825411734199517, 0.14825411734199512, 0.2913586039344366], 
reward next is 0.7086, 
noisyNet noise sample is [array([-0.51697534], dtype=float32), 0.99151045]. 
=============================================
[2019-03-23 01:40:17,882] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:40:17,890] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8083
[2019-03-23 01:40:17,897] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.61666666666667, 97.5, 1.0, 2.0, 0.3552354329223684, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 395406.4689061129, 395406.4689061129, 118611.7071059617], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5638200.0000, 
sim time next is 5638800.0000, 
raw observation next is [17.53333333333333, 98.0, 1.0, 2.0, 0.3536283835388647, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 393421.1389755509, 393421.1389755509, 118400.6471934941], 
processed observation next is [0.0, 0.2608695652173913, 0.43333333333333324, 0.98, 1.0, 1.0, 0.19203547942358087, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14571153295390774, 0.14571153295390774, 0.28878206632559533], 
reward next is 0.7112, 
noisyNet noise sample is [array([0.01059627], dtype=float32), -0.8478364]. 
=============================================
[2019-03-23 01:40:18,784] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.1078296e-27 8.7690100e-02 6.6430090e-29 3.5158696e-18 9.1230989e-01], sum to 1.0000
[2019-03-23 01:40:18,790] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2484
[2019-03-23 01:40:18,794] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.65, 64.5, 1.0, 2.0, 0.5776623581652452, 1.0, 2.0, 0.5776623581652452, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354101, 1307887.582828945, 1307887.582828945, 253542.3102670072], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5571000.0000, 
sim time next is 5571600.0000, 
raw observation next is [26.83333333333334, 63.66666666666666, 1.0, 2.0, 0.3557465966733334, 1.0, 2.0, 0.3557465966733334, 1.0, 1.0, 0.7199254200628452, 6.9112, 6.9112, 77.3421103, 1206377.132538214, 1206377.132538214, 284578.8404579583], 
processed observation next is [1.0, 0.4782608695652174, 0.8560606060606063, 0.6366666666666666, 1.0, 1.0, 0.19468324584166674, 1.0, 1.0, 0.19468324584166674, 1.0, 0.5, 0.5998934572326361, 0.0, 0.0, 0.5085185399722538, 0.44680634538452374, 0.44680634538452374, 0.6940947328242885], 
reward next is 0.3059, 
noisyNet noise sample is [array([0.2640898], dtype=float32), -0.7689708]. 
=============================================
[2019-03-23 01:40:18,969] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.0000000e+00 3.5175096e-19 0.0000000e+00 0.0000000e+00 1.0000000e+00], sum to 1.0000
[2019-03-23 01:40:18,979] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0902
[2019-03-23 01:40:18,982] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.61666666666667, 56.0, 1.0, 2.0, 0.4233292661643569, 1.0, 2.0, 0.4233292661643569, 1.0, 2.0, 0.8550904773876333, 6.9112, 6.9112, 77.3421103, 1428654.579502075, 1428654.579502075, 317911.5188543968], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5579400.0000, 
sim time next is 5580000.0000, 
raw observation next is [28.8, 55.0, 1.0, 2.0, 0.4319861124702667, 1.0, 2.0, 0.4319861124702667, 1.0, 2.0, 0.8725919203569914, 6.911199999999999, 6.9112, 77.3421103, 1457967.411483143, 1457967.411483143, 322281.6720525189], 
processed observation next is [1.0, 0.6086956521739131, 0.9454545454545454, 0.55, 1.0, 1.0, 0.28998264058783335, 1.0, 1.0, 0.28998264058783335, 1.0, 1.0, 0.8179884576528449, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.5399879301789419, 0.5399879301789419, 0.7860528586646802], 
reward next is 0.2139, 
noisyNet noise sample is [array([-1.003708], dtype=float32), -1.1512359]. 
=============================================
[2019-03-23 01:40:18,994] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[47.685932]
 [46.98163 ]
 [46.498814]
 [46.81636 ]
 [48.70759 ]], R is [[48.45995331]
 [48.1999588 ]
 [47.93951797]
 [47.68029785]
 [47.46720123]].
[2019-03-23 01:40:22,133] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-23 01:40:22,135] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 01:40:22,136] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:40:22,136] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 01:40:22,137] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:40:22,138] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 01:40:22,139] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 01:40:22,139] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:40:22,140] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:40:22,141] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 01:40:22,143] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:40:22,165] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run75
[2019-03-23 01:40:22,165] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run75
[2019-03-23 01:40:22,188] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run75
[2019-03-23 01:40:22,236] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run75
[2019-03-23 01:40:22,258] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run75
[2019-03-23 01:40:33,217] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.9079384], dtype=float32), -0.27259964]
[2019-03-23 01:40:33,219] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.0, 94.0, 1.0, 2.0, 0.3852390532974909, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 434092.5405698278, 434092.5405698278, 123520.8714049788]
[2019-03-23 01:40:33,220] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 01:40:33,224] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.4598091283642156
[2019-03-23 01:40:57,692] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.9079384], dtype=float32), -0.27259964]
[2019-03-23 01:40:57,694] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [28.6, 56.5, 1.0, 2.0, 0.4788506941764538, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8802194041068988, 7.03662358566929, 6.9112, 95.55295093059904, 1087646.157920541, 1037310.864267152, 251589.5084583917]
[2019-03-23 01:40:57,695] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 01:40:57,697] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.5360739315513912
[2019-03-23 01:40:57,698] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1087646.157920541 W.
[2019-03-23 01:41:00,110] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.9079384], dtype=float32), -0.27259964]
[2019-03-23 01:41:00,111] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.11666666666667, 59.66666666666666, 1.0, 2.0, 0.3483078782063054, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 384614.2848677663, 384614.284867766, 121136.1405493585]
[2019-03-23 01:41:00,114] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 01:41:00,117] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.9192738796003678
[2019-03-23 01:41:56,571] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.9079384], dtype=float32), -0.27259964]
[2019-03-23 01:41:56,572] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.14608908166667, 86.07939680166668, 1.0, 2.0, 0.3824808852467248, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 427754.9007350638, 427754.9007350634, 126023.3602206273]
[2019-03-23 01:41:56,574] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 01:41:56,577] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.33052414605066105
[2019-03-23 01:42:11,569] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8593.6867 1706159149.9219 465.0000
[2019-03-23 01:42:11,586] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8508.4528 1773463374.2284 173.0000
[2019-03-23 01:42:11,793] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8571.9617 1683477666.0862 214.0000
[2019-03-23 01:42:11,847] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8853.4143 1664003580.0750 105.0000
[2019-03-23 01:42:11,910] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9057.8713 1656401324.5381 80.0000
[2019-03-23 01:42:12,927] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1850000, evaluation results [1850000.0, 8508.45277065677, 1773463374.2284098, 173.0, 9057.871276350008, 1656401324.538099, 80.0, 8853.414337702749, 1664003580.0749555, 105.0, 8593.686660790749, 1706159149.921858, 465.0, 8571.9617444755, 1683477666.0861843, 214.0]
[2019-03-23 01:42:16,504] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:42:16,511] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4422
[2019-03-23 01:42:16,518] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.2, 69.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 214281.2746398477, 214281.2746398475, 69099.13272316182], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5690400.0000, 
sim time next is 5691000.0000, 
raw observation next is [14.0, 69.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 211070.2085857615, 211070.2085857618, 68350.01646678202], 
processed observation next is [0.0, 0.8695652173913043, 0.2727272727272727, 0.69, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07817415132805981, 0.07817415132805992, 0.1667073572360537], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.7541041], dtype=float32), 0.6793962]. 
=============================================
[2019-03-23 01:42:16,542] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[87.351746]
 [87.233444]
 [87.1019  ]
 [86.941414]
 [86.79363 ]], R is [[86.60092163]
 [85.73491669]
 [84.87757111]
 [84.02879333]
 [84.01660156]].
[2019-03-23 01:42:22,477] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 2.8761393e-32], sum to 1.0000
[2019-03-23 01:42:22,484] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5007
[2019-03-23 01:42:22,487] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.8, 80.5, 1.0, 2.0, 0.3565283455223726, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 387161.554862041, 387161.5548620412, 84505.67652542445], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5799000.0000, 
sim time next is 5799600.0000, 
raw observation next is [12.7, 80.0, 1.0, 2.0, 0.3570884209413552, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 387769.9949377187, 387769.994937719, 84296.14593049078], 
processed observation next is [1.0, 0.13043478260869565, 0.2136363636363636, 0.8, 1.0, 1.0, 0.19636052617669394, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1436185166435995, 0.14361851664359965, 0.20560035592802628], 
reward next is 0.7944, 
noisyNet noise sample is [array([-0.7019585], dtype=float32), -1.2538683]. 
=============================================
[2019-03-23 01:42:38,604] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 2.2300813e-34 3.5858637e-32 1.5173377e-31], sum to 1.0000
[2019-03-23 01:42:38,613] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4489
[2019-03-23 01:42:38,619] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.91666666666667, 55.5, 1.0, 2.0, 0.5271158934589044, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 572515.2029371652, 572515.2029371648, 124113.1219107649], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6090600.0000, 
sim time next is 6091200.0000, 
raw observation next is [21.1, 55.0, 1.0, 2.0, 0.4977544149131917, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 540607.1519146184, 540607.1519146188, 122045.1718060002], 
processed observation next is [1.0, 0.5217391304347826, 0.5954545454545456, 0.55, 1.0, 1.0, 0.3721930186414896, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2002248710794883, 0.20022487107948844, 0.297671150746342], 
reward next is 0.7023, 
noisyNet noise sample is [array([1.2915782], dtype=float32), -0.20837069]. 
=============================================
[2019-03-23 01:42:39,615] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 1.734733e-38 5.448700e-38], sum to 1.0000
[2019-03-23 01:42:39,623] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9881
[2019-03-23 01:42:39,626] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 42.0, 1.0, 2.0, 0.7255476671429281, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 798654.3920036092, 798654.3920036092, 153418.9039106448], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6105600.0000, 
sim time next is 6106200.0000, 
raw observation next is [24.8, 43.0, 1.0, 2.0, 0.7377882165793105, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 812219.7566382261, 812219.7566382261, 154936.6612159501], 
processed observation next is [1.0, 0.6956521739130435, 0.7636363636363637, 0.43, 1.0, 1.0, 0.672235270724138, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3008221320882319, 0.3008221320882319, 0.3778942956486588], 
reward next is 0.6221, 
noisyNet noise sample is [array([1.4545872], dtype=float32), 0.7285927]. 
=============================================
[2019-03-23 01:42:42,369] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 8.842937e-37], sum to 1.0000
[2019-03-23 01:42:42,371] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8465
[2019-03-23 01:42:42,375] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 81.0, 1.0, 2.0, 0.3659489593088031, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 409677.4458205416, 409677.4458205413, 120505.7317709861], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6829200.0000, 
sim time next is 6829800.0000, 
raw observation next is [19.8, 82.5, 1.0, 2.0, 0.3655262747136807, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 409110.9687901165, 409110.9687901165, 120427.5880206846], 
processed observation next is [0.0, 0.043478260869565216, 0.5363636363636364, 0.825, 1.0, 1.0, 0.20690784339210086, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15152258103337649, 0.15152258103337649, 0.29372582444069417], 
reward next is 0.7063, 
noisyNet noise sample is [array([0.6164742], dtype=float32), 1.3880827]. 
=============================================
[2019-03-23 01:42:43,357] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 3.2738861e-38 1.1303387e-36 2.4135936e-34], sum to 1.0000
[2019-03-23 01:42:43,364] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7286
[2019-03-23 01:42:43,370] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 51.0, 1.0, 2.0, 0.4532876499776428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 492287.6941906651, 492287.6941906651, 106779.5530718124], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6534600.0000, 
sim time next is 6535200.0000, 
raw observation next is [20.5, 51.00000000000001, 1.0, 2.0, 0.4515697544751163, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 490421.0530130503, 490421.0530130503, 106648.6816045663], 
processed observation next is [1.0, 0.6521739130434783, 0.5681818181818182, 0.5100000000000001, 1.0, 1.0, 0.3144621930938954, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18163742704187047, 0.18163742704187047, 0.26011873562089344], 
reward next is 0.7399, 
noisyNet noise sample is [array([-1.804837], dtype=float32), -1.6821135]. 
=============================================
[2019-03-23 01:42:44,489] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:42:44,496] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2292
[2019-03-23 01:42:44,503] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.3, 58.0, 1.0, 2.0, 0.2542798050356484, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 276096.2155339411, 276096.2155339408, 80590.49321959478], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6555000.0000, 
sim time next is 6555600.0000, 
raw observation next is [18.3, 58.0, 1.0, 2.0, 0.253202570639431, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 274926.22720816, 274926.22720816, 80480.89356205791], 
processed observation next is [1.0, 0.9130434782608695, 0.4681818181818182, 0.58, 1.0, 1.0, 0.06650321329928877, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1018245285956148, 0.1018245285956148, 0.19629486234648272], 
reward next is 0.8037, 
noisyNet noise sample is [array([-0.22937194], dtype=float32), 2.330618]. 
=============================================
[2019-03-23 01:42:52,751] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:42:52,761] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5944
[2019-03-23 01:42:52,766] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.7, 65.0, 1.0, 2.0, 0.5576137208325436, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 631984.5756895146, 631984.575689515, 151691.5546650293], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6360000.0000, 
sim time next is 6360600.0000, 
raw observation next is [27.7, 65.0, 1.0, 2.0, 0.5580371698854613, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 632464.107441291, 632464.107441291, 151746.9250371252], 
processed observation next is [0.0, 0.6086956521739131, 0.8954545454545454, 0.65, 1.0, 1.0, 0.44754646235682655, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23424596571899667, 0.23424596571899667, 0.3701144513100615], 
reward next is 0.6299, 
noisyNet noise sample is [array([0.6527725], dtype=float32), -1.3010181]. 
=============================================
[2019-03-23 01:43:01,528] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:43:01,537] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4737
[2019-03-23 01:43:01,543] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.88333333333333, 65.33333333333334, 1.0, 2.0, 0.4407092743422917, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 478620.3733882359, 478620.3733882356, 103106.5497614531], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6513000.0000, 
sim time next is 6513600.0000, 
raw observation next is [18.06666666666667, 63.66666666666667, 1.0, 2.0, 0.4235712725158867, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 459999.305183741, 459999.3051837413, 101268.4010697097], 
processed observation next is [1.0, 0.391304347826087, 0.45757575757575775, 0.6366666666666667, 1.0, 1.0, 0.2794640906448584, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17037011303101518, 0.1703701130310153, 0.24699610017002366], 
reward next is 0.7530, 
noisyNet noise sample is [array([1.499191], dtype=float32), -0.82582706]. 
=============================================
[2019-03-23 01:43:04,662] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-23 01:43:04,665] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 01:43:04,666] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 01:43:04,667] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 01:43:04,668] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:43:04,669] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:43:04,670] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 01:43:04,668] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:43:04,671] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 01:43:04,673] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:43:04,674] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:43:04,699] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run76
[2019-03-23 01:43:04,726] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run76
[2019-03-23 01:43:04,727] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run76
[2019-03-23 01:43:04,749] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run76
[2019-03-23 01:43:04,771] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run76
[2019-03-23 01:43:19,664] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.76125693], dtype=float32), -0.25181785]
[2019-03-23 01:43:19,666] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [29.2, 59.0, 1.0, 2.0, 0.7492687779407197, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 846732.6162389818, 846732.6162389818, 184605.2293487349]
[2019-03-23 01:43:19,669] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 01:43:19,672] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.8253489830374351
[2019-03-23 01:43:25,639] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.76125693], dtype=float32), -0.25181785]
[2019-03-23 01:43:25,639] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [26.704884295, 88.85914761, 1.0, 2.0, 0.6676628741601348, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 750220.1396327509, 750220.1396327505, 173007.5222590234]
[2019-03-23 01:43:25,639] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 01:43:25,642] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.13020283528731358
[2019-03-23 01:43:26,026] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.76125693], dtype=float32), -0.25181785]
[2019-03-23 01:43:26,029] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [27.18508471, 88.27926278, 1.0, 2.0, 0.6798588515031067, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 763932.8793006348, 763932.8793006345, 174854.0168637019]
[2019-03-23 01:43:26,030] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 01:43:26,033] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.40491195881225006
[2019-03-23 01:43:44,634] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.76125693], dtype=float32), -0.25181785]
[2019-03-23 01:43:44,635] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [24.24190319, 79.66266831, 1.0, 2.0, 0.7419175926279193, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 844903.6717244764, 844903.6717244759, 180489.1448048577]
[2019-03-23 01:43:44,637] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 01:43:44,640] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.9279660564583699
[2019-03-23 01:43:48,513] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.76125693], dtype=float32), -0.25181785]
[2019-03-23 01:43:48,516] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [23.32918314333333, 85.82872511000001, 1.0, 2.0, 0.4960037842345129, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 565330.7462432696, 565330.7462432693, 146292.9357519961]
[2019-03-23 01:43:48,517] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 01:43:48,519] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.6157784384046027
[2019-03-23 01:43:56,674] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.76125693], dtype=float32), -0.25181785]
[2019-03-23 01:43:56,675] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.1, 88.5, 1.0, 2.0, 0.5040842497114423, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 574139.980369188, 574139.980369188, 147654.3087939616]
[2019-03-23 01:43:56,677] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 01:43:56,683] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.44668703616143424
[2019-03-23 01:44:29,470] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.76125693], dtype=float32), -0.25181785]
[2019-03-23 01:44:29,472] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [15.156292965, 78.38608765000001, 1.0, 2.0, 0.2165652788701163, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 235125.1631864316, 235125.1631864316, 79775.64224948097]
[2019-03-23 01:44:29,473] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 01:44:29,476] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.7438624219861425
[2019-03-23 01:44:36,755] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.76125693], dtype=float32), -0.25181785]
[2019-03-23 01:44:36,757] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [7.945588939000001, 100.0, 1.0, 2.0, 0.3432183831583536, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 372675.2115661869, 372675.2115661865, 84306.21469382862]
[2019-03-23 01:44:36,758] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 01:44:36,762] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.30840221465984297
[2019-03-23 01:44:54,045] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9057.0586 1656443078.0244 80.0000
[2019-03-23 01:44:54,512] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8851.9735 1664101423.8647 105.0000
[2019-03-23 01:44:54,648] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8592.8737 1706200825.6989 465.0000
[2019-03-23 01:44:54,697] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8507.7271 1773514361.6667 173.0000
[2019-03-23 01:44:54,853] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8569.7595 1683629455.5724 214.0000
[2019-03-23 01:44:55,870] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 1875000, evaluation results [1875000.0, 8507.727149272585, 1773514361.6667252, 173.0, 9057.05855481395, 1656443078.0244372, 80.0, 8851.973532677643, 1664101423.8646872, 105.0, 8592.873732714792, 1706200825.698916, 465.0, 8569.759499047412, 1683629455.5724304, 214.0]
[2019-03-23 01:44:59,684] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:44:59,693] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9490
[2019-03-23 01:44:59,701] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 67.66666666666667, 1.0, 2.0, 0.376558851767239, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 422216.9661034971, 422216.9661034971, 121703.2413392932], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6628800.0000, 
sim time next is 6629400.0000, 
raw observation next is [21.9, 68.5, 1.0, 2.0, 0.3672095462834377, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 411677.7833312263, 411677.7833312263, 120887.420879184], 
processed observation next is [1.0, 0.7391304347826086, 0.6318181818181817, 0.685, 1.0, 1.0, 0.20901193285429712, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1524732530856394, 0.1524732530856394, 0.29484736799800976], 
reward next is 0.7052, 
noisyNet noise sample is [array([-0.36071253], dtype=float32), 1.079765]. 
=============================================
[2019-03-23 01:44:59,860] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:44:59,869] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6174
[2019-03-23 01:44:59,873] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.55, 77.5, 1.0, 2.0, 0.4724695954014746, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 539111.6443574842, 539111.6443574845, 137579.5744897374], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6993000.0000, 
sim time next is 6993600.0000, 
raw observation next is [23.46666666666667, 78.0, 1.0, 2.0, 0.4719152480968442, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 538476.2759714761, 538476.2759714763, 137497.6232402388], 
processed observation next is [0.0, 0.9565217391304348, 0.7030303030303031, 0.78, 1.0, 1.0, 0.3398940601210552, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19943565776721336, 0.19943565776721345, 0.3353600566835093], 
reward next is 0.6646, 
noisyNet noise sample is [array([1.0414188], dtype=float32), -0.9843083]. 
=============================================
[2019-03-23 01:45:07,370] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:45:07,377] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6849
[2019-03-23 01:45:07,385] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.13333333333334, 80.5, 1.0, 2.0, 0.3906567917194714, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 441856.3276353395, 441856.3276353395, 124949.6191654665], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6857400.0000, 
sim time next is 6858000.0000, 
raw observation next is [21.6, 78.0, 1.0, 2.0, 0.3949773399344806, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 447196.9103738483, 447196.9103738486, 125627.972482302], 
processed observation next is [0.0, 0.391304347826087, 0.6181818181818183, 0.78, 1.0, 1.0, 0.2437216749181007, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16562848532364752, 0.16562848532364763, 0.3064096889812244], 
reward next is 0.6936, 
noisyNet noise sample is [array([-0.08769375], dtype=float32), 2.1505208]. 
=============================================
[2019-03-23 01:45:07,419] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[70.382065]
 [70.4142  ]
 [70.44881 ]
 [70.4742  ]
 [70.498634]], R is [[70.39916229]
 [70.39041138]
 [70.38353729]
 [70.3786087 ]
 [70.3757019 ]].
[2019-03-23 01:45:07,938] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:45:07,945] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1488
[2019-03-23 01:45:07,952] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.36666666666667, 60.33333333333334, 1.0, 2.0, 0.5101054739094485, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 581370.5151265902, 581370.5151265905, 143771.7486015012], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6975600.0000, 
sim time next is 6976200.0000, 
raw observation next is [27.28333333333333, 60.16666666666666, 1.0, 2.0, 0.5058371336576881, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 576678.1402709187, 576678.1402709191, 143059.1254912481], 
processed observation next is [0.0, 0.7391304347826086, 0.8765151515151515, 0.6016666666666666, 1.0, 1.0, 0.3822964170721101, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21358449639663657, 0.21358449639663668, 0.3489246963201173], 
reward next is 0.6511, 
noisyNet noise sample is [array([0.7770739], dtype=float32), -1.3168339]. 
=============================================
[2019-03-23 01:45:08,019] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:45:08,028] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9688
[2019-03-23 01:45:08,035] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.83333333333334, 59.33333333333334, 1.0, 2.0, 0.4738451890068294, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 540688.0024880238, 540688.0024880238, 138154.8452315489], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6868200.0000, 
sim time next is 6868800.0000, 
raw observation next is [27.2, 58.0, 1.0, 2.0, 0.4755893843142612, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 542650.38715759, 542650.3871575904, 138553.1559898105], 
processed observation next is [0.0, 0.5217391304347826, 0.8727272727272727, 0.58, 1.0, 1.0, 0.34448673039282646, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2009816248731815, 0.2009816248731816, 0.3379345268044159], 
reward next is 0.6621, 
noisyNet noise sample is [array([-1.067992], dtype=float32), 0.56038284]. 
=============================================
[2019-03-23 01:45:09,768] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:45:09,778] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1258
[2019-03-23 01:45:09,782] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.4, 61.0, 1.0, 2.0, 0.4144439314733401, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 469992.1372704514, 469992.1372704517, 127941.1951487709], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6805800.0000, 
sim time next is 6806400.0000, 
raw observation next is [24.2, 61.33333333333333, 1.0, 2.0, 0.4082898574103926, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 462580.6076699615, 462580.6076699618, 127062.2391919738], 
processed observation next is [1.0, 0.782608695652174, 0.7363636363636363, 0.6133333333333333, 1.0, 1.0, 0.2603623217629907, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17132615098887463, 0.17132615098887474, 0.3099079004682288], 
reward next is 0.6901, 
noisyNet noise sample is [array([0.19893934], dtype=float32), 0.8593025]. 
=============================================
[2019-03-23 01:45:10,724] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:45:10,736] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3695
[2019-03-23 01:45:10,741] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.8, 87.83333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 203631.2468604697, 203631.2468604697, 68240.48998492611], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7185000.0000, 
sim time next is 7185600.0000, 
raw observation next is [12.7, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 202188.7994121763, 202188.799412176, 67867.66789529011], 
processed observation next is [1.0, 0.17391304347826086, 0.2136363636363636, 0.88, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07488474052302826, 0.07488474052302815, 0.16553089730558565], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.90232015], dtype=float32), 0.3749648]. 
=============================================
[2019-03-23 01:45:11,746] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:45:11,754] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7026
[2019-03-23 01:45:11,759] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.18333333333333, 61.33333333333333, 1.0, 2.0, 0.493176023529643, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 535631.8573891624, 535631.8573891624, 113078.9298624251], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7204200.0000, 
sim time next is 7204800.0000, 
raw observation next is [19.56666666666667, 59.66666666666667, 1.0, 2.0, 0.5111637878817245, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 555179.2834337, 555179.2834337003, 116417.7965653], 
processed observation next is [1.0, 0.391304347826087, 0.5257575757575759, 0.5966666666666667, 1.0, 1.0, 0.38895473485215554, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20562195682729628, 0.20562195682729642, 0.2839458452812195], 
reward next is 0.7161, 
noisyNet noise sample is [array([0.3753047], dtype=float32), -1.1239702]. 
=============================================
[2019-03-23 01:45:14,745] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:45:14,753] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8007
[2019-03-23 01:45:14,756] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.06666666666667, 71.66666666666667, 1.0, 2.0, 0.4250298339783294, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 483111.3716024688, 483111.3716024688, 129808.6591117855], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6903600.0000, 
sim time next is 6904200.0000, 
raw observation next is [22.88333333333333, 72.33333333333333, 1.0, 2.0, 0.4229462001689734, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 480531.8328744086, 480531.8328744086, 129429.0082625609], 
processed observation next is [0.0, 0.9130434782608695, 0.6765151515151513, 0.7233333333333333, 1.0, 1.0, 0.2786827502112167, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17797475291644763, 0.17797475291644763, 0.3156805079574656], 
reward next is 0.6843, 
noisyNet noise sample is [array([0.47446832], dtype=float32), 1.0250338]. 
=============================================
[2019-03-23 01:45:17,068] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:45:17,074] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2986
[2019-03-23 01:45:17,080] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.4, 48.0, 1.0, 2.0, 0.7420593572872756, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 824017.6693760494, 824017.6693760497, 158021.8973814161], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7142400.0000, 
sim time next is 7143000.0000, 
raw observation next is [24.3, 48.66666666666666, 1.0, 2.0, 0.8559125839771726, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 951322.6748233712, 951322.6748233712, 173582.7539441503], 
processed observation next is [1.0, 0.6956521739130435, 0.740909090909091, 0.4866666666666666, 1.0, 1.0, 0.8198907299714658, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3523417314160634, 0.3523417314160634, 0.4233725705954885], 
reward next is 0.5766, 
noisyNet noise sample is [array([0.7976782], dtype=float32), 0.0059937625]. 
=============================================
[2019-03-23 01:45:17,097] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[61.43496 ]
 [61.778976]
 [61.495445]
 [61.050644]
 [61.104218]], R is [[60.52232361]
 [60.53168488]
 [60.55888367]
 [60.57835388]
 [60.58171463]].
[2019-03-23 01:45:21,890] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.7329038e-35 1.0000000e+00 5.7884466e-36 6.8901904e-24 9.8074477e-30], sum to 1.0000
[2019-03-23 01:45:21,901] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4368
[2019-03-23 01:45:21,909] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.3, 93.66666666666666, 1.0, 2.0, 0.6740011012748051, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 762500.2236949436, 762500.2236949436, 156051.7094431528], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7037400.0000, 
sim time next is 7038000.0000, 
raw observation next is [19.4, 93.0, 1.0, 2.0, 0.7011995612951168, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 793484.1813148882, 793484.1813148882, 159720.2983597403], 
processed observation next is [1.0, 0.4782608695652174, 0.5181818181818181, 0.93, 1.0, 1.0, 0.626499451618896, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.29388303011662525, 0.29388303011662525, 0.38956170331643974], 
reward next is 0.6104, 
noisyNet noise sample is [array([-0.9343643], dtype=float32), 0.2866829]. 
=============================================
[2019-03-23 01:45:21,920] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[58.013268]
 [57.9392  ]
 [57.890682]
 [57.795425]
 [57.61192 ]], R is [[57.82239914]
 [57.86355972]
 [57.90384293]
 [57.94163132]
 [57.97492218]].
[2019-03-23 01:45:28,973] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:45:28,986] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1813
[2019-03-23 01:45:28,994] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.5, 78.0, 1.0, 2.0, 0.220767808806341, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 239700.0285763683, 239700.0285763683, 76508.2122914095], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7171200.0000, 
sim time next is 7171800.0000, 
raw observation next is [15.41666666666667, 77.83333333333333, 1.0, 2.0, 0.2191348962369152, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 237926.6499096643, 237926.649909664, 75998.97051359413], 
processed observation next is [1.0, 0.0, 0.33712121212121227, 0.7783333333333333, 1.0, 1.0, 0.023918620296143993, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08812098144802381, 0.0881209814480237, 0.18536334271608326], 
reward next is 0.8146, 
noisyNet noise sample is [array([-0.8942988], dtype=float32), 2.1432812]. 
=============================================
[2019-03-23 01:45:32,325] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:45:32,326] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:45:32,368] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run10
[2019-03-23 01:45:33,770] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:45:33,779] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2144
[2019-03-23 01:45:33,782] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.9, 87.16666666666666, 1.0, 2.0, 0.21340017600327, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 231698.6698798368, 231698.6698798371, 74040.53089377288], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7267800.0000, 
sim time next is 7268400.0000, 
raw observation next is [13.8, 87.0, 1.0, 2.0, 0.2106262290411179, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 228686.1563698546, 228686.1563698546, 73426.83876367976], 
processed observation next is [1.0, 0.13043478260869565, 0.26363636363636367, 0.87, 1.0, 1.0, 0.013282786301397377, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08469857643327948, 0.08469857643327948, 0.17908985064312136], 
reward next is 0.8209, 
noisyNet noise sample is [array([-1.0843192], dtype=float32), -1.209181]. 
=============================================
[2019-03-23 01:45:36,776] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:45:36,776] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:45:36,847] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run10
[2019-03-23 01:45:37,324] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 1.773543e-22], sum to 1.0000
[2019-03-23 01:45:37,330] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3719
[2019-03-23 01:45:37,334] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.8, 44.5, 1.0, 2.0, 0.8491390792704707, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 950599.2190826865, 950599.2190826862, 175476.2597488913], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7317000.0000, 
sim time next is 7317600.0000, 
raw observation next is [25.7, 45.33333333333334, 1.0, 2.0, 0.8400825641929104, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 941055.3926719261, 941055.3926719261, 174439.4697827475], 
processed observation next is [1.0, 0.6956521739130435, 0.8045454545454546, 0.4533333333333334, 1.0, 1.0, 0.800103205241138, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3485390343229356, 0.3485390343229356, 0.4254621214213354], 
reward next is 0.5745, 
noisyNet noise sample is [array([0.37197652], dtype=float32), 1.0014775]. 
=============================================
[2019-03-23 01:45:38,001] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:45:38,007] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8911
[2019-03-23 01:45:38,011] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.41666666666667, 94.16666666666666, 1.0, 2.0, 0.4387033684454565, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 499532.2880911021, 499532.2880911021, 131999.2314554327], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7537800.0000, 
sim time next is 7538400.0000, 
raw observation next is [20.5, 93.0, 1.0, 2.0, 0.4361862569653774, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 496546.618543735, 496546.618543735, 131616.0956428344], 
processed observation next is [0.0, 0.2608695652173913, 0.5681818181818182, 0.93, 1.0, 1.0, 0.2952328212067217, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18390615501619814, 0.18390615501619814, 0.32101486742154733], 
reward next is 0.6790, 
noisyNet noise sample is [array([0.20366815], dtype=float32), -0.81895626]. 
=============================================
[2019-03-23 01:45:42,454] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.8670515e-38 9.9953246e-01 4.5011724e-32 0.0000000e+00 4.6750312e-04], sum to 1.0000
[2019-03-23 01:45:42,461] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2749
[2019-03-23 01:45:42,467] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.43333333333333, 92.33333333333334, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.3421103, 411830.1172460445, 411830.1172460447, 177986.3544583318], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7428000.0000, 
sim time next is 7428600.0000, 
raw observation next is [18.25, 93.5, 1.0, 2.0, 0.3673970736532393, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 410822.1060077676, 410822.1060077673, 120406.8214873687], 
processed observation next is [1.0, 1.0, 0.4659090909090909, 0.935, 1.0, 1.0, 0.20924634206654913, 0.0, 0.5, -0.25, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15215633555843244, 0.15215633555843233, 0.29367517435943585], 
reward next is 0.7063, 
noisyNet noise sample is [array([0.9173222], dtype=float32), 0.9675289]. 
=============================================
[2019-03-23 01:45:42,967] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.1804679e-34 1.0000000e+00 1.4805924e-27 1.5319643e-32 5.8755806e-16], sum to 1.0000
[2019-03-23 01:45:42,976] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6457
[2019-03-23 01:45:42,984] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.5, 72.0, 1.0, 2.0, 0.2179856979892436, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 236678.5994233573, 236678.599423357, 74197.07264871435], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7783200.0000, 
sim time next is 7783800.0000, 
raw observation next is [15.4, 72.66666666666667, 1.0, 2.0, 0.2517900547548409, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 273392.0926628388, 273392.092662839, 77335.49345909686], 
processed observation next is [1.0, 0.08695652173913043, 0.33636363636363636, 0.7266666666666667, 1.0, 1.0, 0.06473756844355111, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10125633061586622, 0.1012563306158663, 0.18862315477828503], 
reward next is 0.8114, 
noisyNet noise sample is [array([-0.57946944], dtype=float32), 0.24454556]. 
=============================================
[2019-03-23 01:45:47,422] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 01:45:47,424] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 01:45:47,424] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:45:47,425] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 01:45:47,426] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:45:47,427] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 01:45:47,428] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:45:47,428] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 01:45:47,429] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 01:45:47,430] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:45:47,430] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:45:47,458] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run77
[2019-03-23 01:45:47,484] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run77
[2019-03-23 01:45:47,505] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run77
[2019-03-23 01:45:47,529] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run77
[2019-03-23 01:45:47,529] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run77
[2019-03-23 01:45:58,878] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.64470994], dtype=float32), -0.25366488]
[2019-03-23 01:45:58,879] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.48993626166667, 87.08544872, 1.0, 2.0, 0.3293134971857548, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 363851.4800515652, 363851.4800515648, 119786.4002561527]
[2019-03-23 01:45:58,879] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 01:45:58,882] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 2.6806145e-37], sampled 0.40547948234713627
[2019-03-23 01:46:11,193] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.64470994], dtype=float32), -0.25366488]
[2019-03-23 01:46:11,195] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.06666666666667, 39.0, 1.0, 2.0, 0.5563884769790235, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 604257.0907448445, 604257.0907448442, 131227.484278487]
[2019-03-23 01:46:11,196] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 01:46:11,200] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 3.099065e-36], sampled 0.9448602600686379
[2019-03-23 01:46:26,087] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.64470994], dtype=float32), -0.25366488]
[2019-03-23 01:46:26,088] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.58333333333334, 66.83333333333334, 1.0, 2.0, 0.5080759818319082, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 98.65048047196778, 558095.0412780205, 558095.0412780205, 134224.0575114229]
[2019-03-23 01:46:26,089] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 01:46:26,092] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 2.2257084e-38], sampled 0.506603407073398
[2019-03-23 01:46:38,761] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.64470994], dtype=float32), -0.25366488]
[2019-03-23 01:46:38,763] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.05, 90.5, 1.0, 2.0, 0.4913650573788396, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 560618.2016874014, 560618.201687401, 144531.9603269228]
[2019-03-23 01:46:38,766] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 01:46:38,771] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 7.2813386e-35], sampled 0.08789199118016255
[2019-03-23 01:46:53,261] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.64470994], dtype=float32), -0.25366488]
[2019-03-23 01:46:53,264] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.40245676, 100.0, 1.0, 2.0, 0.5319318272362576, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 604065.0928294199, 604065.0928294195, 152171.3206225241]
[2019-03-23 01:46:53,265] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 01:46:53,269] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 6.529931e-37], sampled 0.6114680861249752
[2019-03-23 01:47:00,630] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.64470994], dtype=float32), -0.25366488]
[2019-03-23 01:47:00,631] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.9, 62.0, 1.0, 2.0, 0.4803919168632456, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 546631.4327546298, 546631.4327546294, 140335.1227590646]
[2019-03-23 01:47:00,632] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 01:47:00,637] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.7288906e-33], sampled 0.20292545154336938
[2019-03-23 01:47:34,251] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.64470994], dtype=float32), -0.25366488]
[2019-03-23 01:47:34,252] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [23.88430861, 42.21829729666666, 1.0, 2.0, 0.4717819156784205, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 512332.2643314048, 512332.2643314044, 127612.5847475371]
[2019-03-23 01:47:34,253] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 01:47:34,255] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 5.7353187e-37], sampled 0.12353823617452131
[2019-03-23 01:47:37,039] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8573.6635 1685608274.8586 181.0000
[2019-03-23 01:47:37,379] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9054.6152 1656608297.4237 80.0000
[2019-03-23 01:47:37,407] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8849.1151 1664307374.6356 105.0000
[2019-03-23 01:47:37,421] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8455.4990 1786577148.7226 145.0000
[2019-03-23 01:47:37,453] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8593.8481 1707264005.6456 447.0000
[2019-03-23 01:47:38,469] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 1900000, evaluation results [1900000.0, 8455.498954400573, 1786577148.7225728, 145.0, 9054.615151893038, 1656608297.4236796, 80.0, 8849.11513522178, 1664307374.6356287, 105.0, 8593.848090992606, 1707264005.6455712, 447.0, 8573.663520999706, 1685608274.858636, 181.0]
[2019-03-23 01:47:44,221] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:47:44,221] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:47:44,292] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run10
[2019-03-23 01:47:44,325] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:47:44,326] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:47:44,387] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run10
[2019-03-23 01:47:47,098] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:47:47,107] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9660
[2019-03-23 01:47:47,113] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.6, 91.66666666666667, 1.0, 2.0, 0.4764742788039106, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 543677.3124383519, 543677.3124383519, 137972.2079304192], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7681200.0000, 
sim time next is 7681800.0000, 
raw observation next is [21.6, 91.33333333333334, 1.0, 2.0, 0.4743993151211328, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 541294.0004503168, 541294.0004503168, 137651.8310153081], 
processed observation next is [1.0, 0.9130434782608695, 0.6181818181818183, 0.9133333333333334, 1.0, 1.0, 0.342999143901416, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20047925942604328, 0.20047925942604328, 0.33573617320806853], 
reward next is 0.6643, 
noisyNet noise sample is [array([-0.47390178], dtype=float32), 0.6693814]. 
=============================================
[2019-03-23 01:47:52,071] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:47:52,073] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:47:52,158] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run10
[2019-03-23 01:47:58,299] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:47:58,307] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5829
[2019-03-23 01:47:58,310] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.8, 75.33333333333334, 1.0, 2.0, 0.3266938682912871, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 360609.7577478804, 360609.7577478804, 115137.7009189735], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7886400.0000, 
sim time next is 7887000.0000, 
raw observation next is [19.9, 75.16666666666666, 1.0, 2.0, 0.3286547206120062, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 363217.3465753085, 363217.3465753088, 115456.8630611512], 
processed observation next is [1.0, 0.2608695652173913, 0.5409090909090909, 0.7516666666666666, 1.0, 1.0, 0.1608184007650077, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13452494317604016, 0.1345249431760403, 0.28160210502719807], 
reward next is 0.7184, 
noisyNet noise sample is [array([-0.9486373], dtype=float32), -0.97968096]. 
=============================================
[2019-03-23 01:47:58,316] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:47:58,316] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:47:58,326] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[67.0672  ]
 [67.11118 ]
 [67.150185]
 [67.16877 ]
 [67.333435]], R is [[67.07941437]
 [67.12779999]
 [67.17642975]
 [67.22503662]
 [67.27246857]].
[2019-03-23 01:47:58,398] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run10
[2019-03-23 01:47:59,671] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:47:59,681] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8730
[2019-03-23 01:47:59,688] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 94.0, 1.0, 2.0, 0.6934552301900127, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 785390.1518468313, 785390.1518468313, 159105.1875426223], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7896000.0000, 
sim time next is 7896600.0000, 
raw observation next is [19.4, 94.5, 1.0, 2.0, 0.7088310976735687, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 803200.9579654383, 803200.9579654383, 161396.8082439661], 
processed observation next is [1.0, 0.391304347826087, 0.5181818181818181, 0.945, 1.0, 1.0, 0.6360388720919607, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.29748183628349567, 0.29748183628349567, 0.3936507518145515], 
reward next is 0.6063, 
noisyNet noise sample is [array([0.8061597], dtype=float32), 1.7789599]. 
=============================================
[2019-03-23 01:47:59,825] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:47:59,831] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3472
[2019-03-23 01:47:59,838] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 54.0, 1.0, 2.0, 0.3620721724627655, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 404351.3307281333, 404351.3307281333, 119736.911477436], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 676200.0000, 
sim time next is 676800.0000, 
raw observation next is [24.0, 54.0, 1.0, 2.0, 0.3589652520363313, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 400871.6492736979, 400871.6492736976, 119479.1153641958], 
processed observation next is [1.0, 0.8695652173913043, 0.7272727272727273, 0.54, 1.0, 1.0, 0.1987065650454141, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1484709812124807, 0.1484709812124806, 0.29141247649803853], 
reward next is 0.7086, 
noisyNet noise sample is [array([-0.15946995], dtype=float32), -0.18709496]. 
=============================================
[2019-03-23 01:48:00,288] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:48:00,289] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:48:00,351] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run10
[2019-03-23 01:48:01,795] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:48:01,795] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:48:01,874] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run10
[2019-03-23 01:48:01,899] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:48:01,905] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:48:01,948] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run10
[2019-03-23 01:48:02,005] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:48:02,006] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:48:02,025] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:48:02,025] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:48:02,053] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:48:02,054] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:48:02,057] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run10
[2019-03-23 01:48:02,102] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run10
[2019-03-23 01:48:02,135] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:48:02,137] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:48:02,157] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run10
[2019-03-23 01:48:02,214] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run10
[2019-03-23 01:48:02,357] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:48:02,357] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:48:02,360] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run10
[2019-03-23 01:48:02,388] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:48:02,390] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:48:02,408] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run10
[2019-03-23 01:48:02,628] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:48:02,629] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:48:02,637] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run10
[2019-03-23 01:48:15,354] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:48:15,363] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4687
[2019-03-23 01:48:15,368] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.2, 72.0, 1.0, 2.0, 0.2593647274942527, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 281619.0069245542, 281619.0069245545, 93108.41702909392], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 228600.0000, 
sim time next is 229200.0000, 
raw observation next is [18.43333333333333, 71.0, 1.0, 2.0, 0.26238416854229, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 284898.4854350614, 284898.4854350617, 94619.91058068842], 
processed observation next is [0.0, 0.6521739130434783, 0.4742424242424241, 0.71, 1.0, 1.0, 0.07798021067786251, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10551795756854125, 0.10551795756854136, 0.23078026970899615], 
reward next is 0.7692, 
noisyNet noise sample is [array([1.6142777], dtype=float32), -0.48932144]. 
=============================================
[2019-03-23 01:48:24,370] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:48:24,378] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1319
[2019-03-23 01:48:24,383] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.66666666666667, 55.33333333333334, 1.0, 2.0, 0.35742728525857, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 388138.1218557518, 388138.1218557521, 95915.0467588574], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 388200.0000, 
sim time next is 388800.0000, 
raw observation next is [20.0, 56.0, 1.0, 2.0, 0.3489444344358132, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 378922.8189702291, 378922.8189702288, 97974.78039620654], 
processed observation next is [1.0, 0.5217391304347826, 0.5454545454545454, 0.56, 1.0, 1.0, 0.18618054304476647, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14034178480378856, 0.14034178480378845, 0.2389628790151379], 
reward next is 0.7610, 
noisyNet noise sample is [array([0.12174758], dtype=float32), -0.7620725]. 
=============================================
[2019-03-23 01:48:29,264] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-23 01:48:29,266] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 01:48:29,267] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:48:29,268] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 01:48:29,268] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 01:48:29,270] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 01:48:29,272] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 01:48:29,274] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:48:29,269] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:48:29,275] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:48:29,276] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:48:29,307] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run78
[2019-03-23 01:48:29,330] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run78
[2019-03-23 01:48:29,353] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run78
[2019-03-23 01:48:29,386] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run78
[2019-03-23 01:48:29,414] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run78
[2019-03-23 01:48:41,247] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.46650714], dtype=float32), -0.20179604]
[2019-03-23 01:48:41,250] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.21666666666667, 42.0, 1.0, 2.0, 0.3741409178321074, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 420643.6509664436, 420643.6509664433, 126381.0455187946]
[2019-03-23 01:48:41,251] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 01:48:41,254] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.5608624204105948
[2019-03-23 01:48:49,298] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.46650714], dtype=float32), -0.20179604]
[2019-03-23 01:48:49,301] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.10148361, 95.7102003, 1.0, 2.0, 0.4318002326342319, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 491224.8019547947, 491224.8019547943, 135200.1169162939]
[2019-03-23 01:48:49,304] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 01:48:49,307] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.9124699790336339
[2019-03-23 01:49:00,794] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.46650714], dtype=float32), -0.20179604]
[2019-03-23 01:49:00,797] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [13.58333333333333, 81.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 207975.6266152383, 207975.6266152379, 73640.80524066361]
[2019-03-23 01:49:00,800] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 01:49:00,805] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.6599819129371848
[2019-03-23 01:50:18,797] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9057.8713 1656401324.5381 80.0000
[2019-03-23 01:50:19,056] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8570.4787 1683579848.9606 214.0000
[2019-03-23 01:50:19,152] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8592.8737 1706200825.6989 465.0000
[2019-03-23 01:50:19,169] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8509.1813 1773413472.9632 173.0000
[2019-03-23 01:50:19,216] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8852.6925 1664051680.8275 105.0000
[2019-03-23 01:50:20,230] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 1925000, evaluation results [1925000.0, 8509.181281245757, 1773413472.9631987, 173.0, 9057.871276350008, 1656401324.538099, 80.0, 8852.692524936243, 1664051680.8275282, 105.0, 8592.873732714792, 1706200825.698916, 465.0, 8570.478727897242, 1683579848.9606183, 214.0]
[2019-03-23 01:50:21,478] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 5.1472392e-33], sum to 1.0000
[2019-03-23 01:50:21,487] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1426
[2019-03-23 01:50:21,493] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.0, 88.0, 1.0, 2.0, 0.2373392226925135, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 257697.3112804529, 257697.3112804526, 80848.1566113988], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 507600.0000, 
sim time next is 508200.0000, 
raw observation next is [14.83333333333333, 89.00000000000001, 1.0, 2.0, 0.2345604325951616, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 254679.376816901, 254679.3768169013, 80254.30294790174], 
processed observation next is [1.0, 0.9130434782608695, 0.3106060606060605, 0.8900000000000001, 1.0, 1.0, 0.043200540743951986, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09432569511737074, 0.09432569511737085, 0.19574220231195547], 
reward next is 0.8043, 
noisyNet noise sample is [array([-1.1988997], dtype=float32), 1.1840737]. 
=============================================
[2019-03-23 01:50:27,183] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.4779771e-38], sum to 1.0000
[2019-03-23 01:50:27,193] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8777
[2019-03-23 01:50:27,197] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 83.0, 1.0, 2.0, 0.3104233999645609, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 337882.0502495598, 337882.0502495595, 112175.7955175915], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 598800.0000, 
sim time next is 599400.0000, 
raw observation next is [18.0, 83.0, 1.0, 2.0, 0.3090515487600479, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 336381.7657014254, 336381.7657014257, 112079.4184215995], 
processed observation next is [1.0, 0.9565217391304348, 0.45454545454545453, 0.83, 1.0, 1.0, 0.13631443595005988, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12458583914867606, 0.1245858391486762, 0.27336443517463294], 
reward next is 0.7266, 
noisyNet noise sample is [array([-0.8397361], dtype=float32), -0.014525582]. 
=============================================
[2019-03-23 01:50:38,442] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:50:38,452] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3998
[2019-03-23 01:50:38,459] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 88.0, 1.0, 2.0, 0.4232138994983671, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 481346.8756731279, 481346.8756731282, 129896.0416569622], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 802800.0000, 
sim time next is 803400.0000, 
raw observation next is [21.16666666666667, 87.16666666666667, 1.0, 2.0, 0.4290252524480803, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 488196.3866127747, 488196.3866127747, 130696.4904549169], 
processed observation next is [0.0, 0.30434782608695654, 0.5984848484848487, 0.8716666666666667, 1.0, 1.0, 0.28628156556010037, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1808134765232499, 0.1808134765232499, 0.3187719279388217], 
reward next is 0.6812, 
noisyNet noise sample is [array([-0.8034789], dtype=float32), 0.33015984]. 
=============================================
[2019-03-23 01:50:46,005] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.0990694e-28 1.0000000e+00 3.1547058e-30 7.8945995e-27 1.8878594e-17], sum to 1.0000
[2019-03-23 01:50:46,012] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6651
[2019-03-23 01:50:46,017] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.4102488036455231, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 465060.4075355385, 465060.4075355382, 127422.3036534508], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 945000.0000, 
sim time next is 945600.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4108488816724606, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 465741.6073026133, 465741.607302613, 127479.6097442258], 
processed observation next is [0.0, 0.9565217391304348, 0.5, 1.0, 1.0, 1.0, 0.2635611020905757, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1724968915935605, 0.17249689159356035, 0.310925877424941], 
reward next is 0.6891, 
noisyNet noise sample is [array([0.2028758], dtype=float32), -0.38515097]. 
=============================================
[2019-03-23 01:50:48,463] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.8010352e-34], sum to 1.0000
[2019-03-23 01:50:48,478] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9462
[2019-03-23 01:50:48,488] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 95.0, 1.0, 2.0, 0.3842218363539589, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 433571.9657439627, 433571.9657439627, 123775.303331653], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 967800.0000, 
sim time next is 968400.0000, 
raw observation next is [19.0, 94.0, 1.0, 2.0, 0.3793907719985717, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 427633.7613246174, 427633.7613246174, 123078.6811247752], 
processed observation next is [1.0, 0.21739130434782608, 0.5, 0.94, 1.0, 1.0, 0.2242384649982146, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1583828745646731, 0.1583828745646731, 0.30019190518237854], 
reward next is 0.6998, 
noisyNet noise sample is [array([2.9797971], dtype=float32), -0.15351222]. 
=============================================
[2019-03-23 01:51:03,926] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.0121181e-35 9.3931034e-05 0.0000000e+00 1.0032487e-31 9.9990606e-01], sum to 1.0000
[2019-03-23 01:51:03,938] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6690
[2019-03-23 01:51:03,945] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.0, 62.0, 1.0, 2.0, 0.24590536167906, 1.0, 2.0, 0.24590536167906, 1.0, 2.0, 0.4978801374322948, 6.9112, 6.9112, 77.3421103, 835063.0738353045, 835063.0738353045, 243527.0872713054], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1271400.0000, 
sim time next is 1272000.0000, 
raw observation next is [27.0, 62.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3431022358450733, 6.9112, 6.9112, 77.3421103, 576880.5861417967, 576880.5861417967, 214909.1987104445], 
processed observation next is [1.0, 0.7391304347826086, 0.8636363636363636, 0.62, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.06157462263581905, 0.0, 0.0, 0.5085185399722538, 0.21365947634881358, 0.21365947634881358, 0.5241687773425475], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.80181557], dtype=float32), -0.60041314]. 
=============================================
[2019-03-23 01:51:03,957] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[77.01341 ]
 [74.068436]
 [74.5474  ]
 [74.80082 ]
 [74.96011 ]], R is [[77.05947113]
 [76.69490814]
 [76.1735611 ]
 [75.66985321]
 [75.16455078]].
[2019-03-23 01:51:05,474] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 2.2516599e-24], sum to 1.0000
[2019-03-23 01:51:05,486] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9748
[2019-03-23 01:51:05,489] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.66666666666667, 96.0, 1.0, 2.0, 0.3562506697715428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 395919.5867535276, 395919.5867535279, 118434.9442397721], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1300800.0000, 
sim time next is 1301400.0000, 
raw observation next is [17.5, 97.0, 1.0, 2.0, 0.3534197516592281, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 392423.1792989468, 392423.1792989465, 118066.3259230504], 
processed observation next is [1.0, 0.043478260869565216, 0.4318181818181818, 0.97, 1.0, 1.0, 0.19177468957403512, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1453419182588692, 0.14534191825886908, 0.28796664859280585], 
reward next is 0.7120, 
noisyNet noise sample is [array([0.90511996], dtype=float32), 0.3479542]. 
=============================================
[2019-03-23 01:51:12,503] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-23 01:51:12,506] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 01:51:12,510] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 01:51:12,511] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:51:12,512] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:51:12,513] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 01:51:12,514] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 01:51:12,516] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:51:12,516] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:51:12,518] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 01:51:12,519] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:51:12,543] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run79
[2019-03-23 01:51:12,570] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run79
[2019-03-23 01:51:12,592] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run79
[2019-03-23 01:51:12,593] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run79
[2019-03-23 01:51:12,616] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run79
[2019-03-23 01:51:18,464] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.45914862], dtype=float32), -0.20518795]
[2019-03-23 01:51:18,465] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [17.6, 84.5, 1.0, 2.0, 0.2971338557169435, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 322622.0331075568, 322622.0331075564, 115307.0889336006]
[2019-03-23 01:51:18,465] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 01:51:18,469] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.8336533484655198
[2019-03-23 01:51:40,733] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.45914862], dtype=float32), -0.20518795]
[2019-03-23 01:51:40,736] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.1, 48.0, 1.0, 2.0, 0.3068147722344113, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 95.55338769695034, 333136.2930861713, 333136.2930861706, 103719.9758844424]
[2019-03-23 01:51:40,736] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 01:51:40,739] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.6321216322958136
[2019-03-23 01:52:11,154] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.45914862], dtype=float32), -0.20518795]
[2019-03-23 01:52:11,155] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [26.5, 48.0, 1.0, 2.0, 0.3667117178670583, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344284481, 414487.5899493721, 414487.5899493718, 122642.7419607914]
[2019-03-23 01:52:11,157] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 01:52:11,161] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.9307134101466993
[2019-03-23 01:52:15,255] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.45914862], dtype=float32), -0.20518795]
[2019-03-23 01:52:15,256] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [14.5, 97.0, 1.0, 2.0, 0.2439686337805176, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 264897.3291505821, 264897.3291505821, 84034.62631616542]
[2019-03-23 01:52:15,257] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 01:52:15,261] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.3010855073846742
[2019-03-23 01:52:15,892] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.45914862], dtype=float32), -0.20518795]
[2019-03-23 01:52:15,893] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.39320345833334, 91.52288930333333, 1.0, 2.0, 0.2822153101856772, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 306419.6436436145, 306419.6436436145, 108044.3440845641]
[2019-03-23 01:52:15,894] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 01:52:15,897] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.15558893609155577
[2019-03-23 01:52:20,384] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.45914862], dtype=float32), -0.20518795]
[2019-03-23 01:52:20,385] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.67064052666667, 89.01583806000001, 1.0, 2.0, 0.2961454499086377, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 321548.5546381483, 321548.5546381483, 109383.3270541454]
[2019-03-23 01:52:20,390] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 01:52:20,394] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.2519413831961713
[2019-03-23 01:52:26,910] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.45914862], dtype=float32), -0.20518795]
[2019-03-23 01:52:26,911] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.58667313166666, 86.20696916833333, 1.0, 2.0, 0.4485530145850956, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 508727.654379767, 508727.654379767, 135644.6118117394]
[2019-03-23 01:52:26,912] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 01:52:26,917] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.6887349317270748
[2019-03-23 01:52:44,948] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.45914862], dtype=float32), -0.20518795]
[2019-03-23 01:52:44,949] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.08333333333334, 80.66666666666666, 1.0, 2.0, 0.3725288227299736, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 417213.8785610728, 417213.8785610728, 125456.1538770089]
[2019-03-23 01:52:44,950] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 01:52:44,953] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.8848893579611342
[2019-03-23 01:52:57,977] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8508.4528 1773463374.2284 173.0000
[2019-03-23 01:52:58,349] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8570.4787 1683579848.9606 214.0000
[2019-03-23 01:52:58,362] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8852.6925 1664051680.8275 105.0000
[2019-03-23 01:52:58,461] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9057.0586 1656443078.0244 80.0000
[2019-03-23 01:52:58,469] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8593.6867 1706159149.9219 465.0000
[2019-03-23 01:52:59,486] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 1950000, evaluation results [1950000.0, 8508.45277065677, 1773463374.2284098, 173.0, 9057.05855481395, 1656443078.0244372, 80.0, 8852.692524936243, 1664051680.8275282, 105.0, 8593.686660790749, 1706159149.921858, 465.0, 8570.478727897242, 1683579848.9606183, 214.0]
[2019-03-23 01:53:07,203] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 6.3894295e-37 0.0000000e+00 2.9181707e-38], sum to 1.0000
[2019-03-23 01:53:07,209] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1595
[2019-03-23 01:53:07,216] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.3976391974216755, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 450795.6747357529, 450795.6747357529, 126263.4612949874], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1566000.0000, 
sim time next is 1566600.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4568280846696164, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 517935.0064024731, 517935.0064024728, 132013.1476819555], 
processed observation next is [1.0, 0.13043478260869565, 0.5, 1.0, 1.0, 1.0, 0.32103510583702044, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1918277801490641, 0.191827780149064, 0.3219832870291598], 
reward next is 0.6780, 
noisyNet noise sample is [array([-1.0157324], dtype=float32), -2.3569748]. 
=============================================
[2019-03-23 01:53:09,570] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:53:09,582] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5716
[2019-03-23 01:53:09,587] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.66666666666667, 90.33333333333334, 1.0, 2.0, 0.5613529638372038, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 628282.2577421727, 628282.2577421725, 139104.2321385372], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1672800.0000, 
sim time next is 1673400.0000, 
raw observation next is [18.33333333333333, 92.16666666666667, 1.0, 2.0, 0.5455823156434253, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 609632.4962034429, 609632.4962034429, 136999.5422430364], 
processed observation next is [1.0, 0.34782608695652173, 0.4696969696969695, 0.9216666666666667, 1.0, 1.0, 0.4319778945542816, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22578981340868257, 0.22578981340868257, 0.33414522498301563], 
reward next is 0.6659, 
noisyNet noise sample is [array([0.17452154], dtype=float32), 0.12587509]. 
=============================================
[2019-03-23 01:53:19,616] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 7.7668343e-36 2.3753973e-32 3.0868825e-25], sum to 1.0000
[2019-03-23 01:53:19,628] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2937
[2019-03-23 01:53:19,633] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 71.66666666666667, 1.0, 2.0, 0.6012748913082814, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 653115.4686723606, 653115.4686723606, 136555.6803652932], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2470800.0000, 
sim time next is 2471400.0000, 
raw observation next is [19.5, 71.0, 1.0, 2.0, 0.6021385610996837, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 655885.2004674148, 655885.2004674146, 137202.4951344393], 
processed observation next is [1.0, 0.6086956521739131, 0.5227272727272727, 0.71, 1.0, 1.0, 0.5026732013746046, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.24292044461756104, 0.24292044461756096, 0.33464023203521776], 
reward next is 0.6654, 
noisyNet noise sample is [array([-1.1471626], dtype=float32), -1.4545616]. 
=============================================
[2019-03-23 01:53:21,760] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 8.3477323e-38 4.2576493e-26], sum to 1.0000
[2019-03-23 01:53:21,773] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3498
[2019-03-23 01:53:21,778] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.66666666666667, 74.33333333333333, 1.0, 2.0, 0.5147574206068838, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 559084.6028071117, 559084.6028071117, 128207.0298199707], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2198400.0000, 
sim time next is 2199000.0000, 
raw observation next is [18.83333333333333, 73.66666666666667, 1.0, 2.0, 0.4845192019639642, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 526224.7106072792, 526224.7106072792, 125491.9519682358], 
processed observation next is [1.0, 0.43478260869565216, 0.4924242424242422, 0.7366666666666667, 1.0, 1.0, 0.35564900245495523, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19489804096565896, 0.19489804096565896, 0.3060779316298434], 
reward next is 0.6939, 
noisyNet noise sample is [array([0.64134544], dtype=float32), 0.65697485]. 
=============================================
[2019-03-23 01:53:21,789] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[78.12077 ]
 [77.73923 ]
 [77.94043 ]
 [78.02974 ]
 [78.223145]], R is [[78.0044632 ]
 [77.91172028]
 [77.80456543]
 [77.7062149 ]
 [77.6159668 ]].
[2019-03-23 01:53:30,893] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 6.5901534e-33], sum to 1.0000
[2019-03-23 01:53:30,902] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8066
[2019-03-23 01:53:30,910] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 65.0, 1.0, 2.0, 0.3794056649859224, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 427701.4487386462, 427701.4487386459, 123108.1403530639], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2671200.0000, 
sim time next is 2671800.0000, 
raw observation next is [22.83333333333334, 65.66666666666667, 1.0, 2.0, 0.3795177038984429, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 427713.289061685, 427713.289061685, 123055.4262681655], 
processed observation next is [0.0, 0.9565217391304348, 0.6742424242424245, 0.6566666666666667, 1.0, 1.0, 0.22439712987305363, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15841232928210555, 0.15841232928210555, 0.30013518601991585], 
reward next is 0.6999, 
noisyNet noise sample is [array([-2.6707811], dtype=float32), 1.0792072]. 
=============================================
[2019-03-23 01:53:33,192] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.5819867e-33 5.5337854e-31 2.9871679e-23], sum to 1.0000
[2019-03-23 01:53:33,201] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6197
[2019-03-23 01:53:33,207] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.66666666666666, 58.0, 1.0, 2.0, 0.2857929739411474, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 310324.0322934703, 310324.0322934706, 101327.6904690026], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2022600.0000, 
sim time next is 2023200.0000, 
raw observation next is [21.0, 56.0, 1.0, 2.0, 0.2850558452971071, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 309523.3774517219, 309523.3774517216, 101299.1847112216], 
processed observation next is [0.0, 0.43478260869565216, 0.5909090909090909, 0.56, 1.0, 1.0, 0.10631980662138385, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1146382879450822, 0.11463828794508206, 0.24707118222249172], 
reward next is 0.7529, 
noisyNet noise sample is [array([-0.6579311], dtype=float32), 1.9025872]. 
=============================================
[2019-03-23 01:53:36,782] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.9643047e-38 1.0000000e+00 2.8690320e-29 2.5108509e-34 2.5023536e-24], sum to 1.0000
[2019-03-23 01:53:36,790] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4471
[2019-03-23 01:53:36,799] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 88.0, 1.0, 2.0, 0.4290373977863206, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 488108.1295351337, 488108.1295351337, 130598.8121108446], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2869200.0000, 
sim time next is 2869800.0000, 
raw observation next is [21.0, 88.00000000000001, 1.0, 2.0, 0.4361145070986443, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 496166.9921515666, 496166.9921515666, 131312.0095320698], 
processed observation next is [1.0, 0.21739130434782608, 0.5909090909090909, 0.8800000000000001, 1.0, 1.0, 0.2951431338733053, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18376555264872838, 0.18376555264872838, 0.320273193980658], 
reward next is 0.6797, 
noisyNet noise sample is [array([-0.6139583], dtype=float32), -0.8983528]. 
=============================================
[2019-03-23 01:53:39,130] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 8.5415217e-38 0.0000000e+00 3.5563183e-31], sum to 1.0000
[2019-03-23 01:53:39,138] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2980
[2019-03-23 01:53:39,143] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.83333333333333, 77.0, 1.0, 2.0, 0.5289027207276912, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 574457.0724814228, 574457.0724814228, 124775.5323340388], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2195400.0000, 
sim time next is 2196000.0000, 
raw observation next is [18.0, 77.0, 1.0, 2.0, 0.5066235267125375, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 550245.2765279927, 550245.276527993, 124520.1670928881], 
processed observation next is [1.0, 0.43478260869565216, 0.45454545454545453, 0.77, 1.0, 1.0, 0.38327940839067187, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2037945468622195, 0.20379454686221965, 0.30370772461680023], 
reward next is 0.6963, 
noisyNet noise sample is [array([-1.5675569], dtype=float32), -1.1704807]. 
=============================================
[2019-03-23 01:53:39,159] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[65.1925  ]
 [65.36466 ]
 [65.56742 ]
 [65.645065]
 [65.78777 ]], R is [[65.49187469]
 [65.53263092]
 [65.58201599]
 [65.63980103]
 [65.7008667 ]].
[2019-03-23 01:53:46,335] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 7.6332636e-32], sum to 1.0000
[2019-03-23 01:53:46,340] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9894
[2019-03-23 01:53:46,347] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.83333333333333, 89.00000000000001, 1.0, 2.0, 0.2363924363373098, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 256669.041812319, 256669.0418123187, 80442.39484369896], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2250600.0000, 
sim time next is 2251200.0000, 
raw observation next is [14.66666666666667, 90.0, 1.0, 2.0, 0.2339011760703237, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 253963.3870228584, 253963.3870228581, 79869.27929537518], 
processed observation next is [1.0, 0.043478260869565216, 0.30303030303030315, 0.9, 1.0, 1.0, 0.04237647008790462, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09406051371216978, 0.09406051371216967, 0.1948031202326224], 
reward next is 0.8052, 
noisyNet noise sample is [array([0.17254563], dtype=float32), 1.3379678]. 
=============================================
[2019-03-23 01:53:49,864] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:53:49,875] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7697
[2019-03-23 01:53:49,880] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.2, 75.0, 1.0, 2.0, 0.440766081145765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 502300.5753403582, 502300.5753403582, 132721.552186803], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2715600.0000, 
sim time next is 2716200.0000, 
raw observation next is [23.4, 73.5, 1.0, 2.0, 0.4399547490022283, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 501339.731847281, 501339.731847281, 132589.0312501123], 
processed observation next is [0.0, 0.43478260869565216, 0.7, 0.735, 1.0, 1.0, 0.29994343625278536, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18568138216565963, 0.18568138216565963, 0.3233878810978349], 
reward next is 0.6766, 
noisyNet noise sample is [array([-1.34749], dtype=float32), 0.4556495]. 
=============================================
[2019-03-23 01:53:50,513] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:53:50,519] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9244
[2019-03-23 01:53:50,524] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.33333333333333, 54.0, 1.0, 2.0, 0.2410048894787761, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 261678.4762256738, 261678.4762256741, 75241.40098119726], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2320800.0000, 
sim time next is 2321400.0000, 
raw observation next is [17.16666666666667, 54.5, 1.0, 2.0, 0.2390795640288277, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 259587.4369876808, 259587.4369876811, 74887.60653666548], 
processed observation next is [1.0, 0.8695652173913043, 0.4166666666666669, 0.545, 1.0, 1.0, 0.04884945503603463, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09614349518062251, 0.09614349518062264, 0.1826526988699158], 
reward next is 0.8173, 
noisyNet noise sample is [array([0.25592518], dtype=float32), 1.3397443]. 
=============================================
[2019-03-23 01:53:50,611] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 5.8140226e-38], sum to 1.0000
[2019-03-23 01:53:50,620] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6191
[2019-03-23 01:53:50,624] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 52.5, 1.0, 2.0, 0.2325126323480113, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 252455.3536196685, 252455.3536196688, 73463.35230804238], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2328600.0000, 
sim time next is 2329200.0000, 
raw observation next is [17.0, 52.0, 1.0, 2.0, 0.2331190627628311, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 253113.9691958246, 253113.9691958246, 73407.4204108092], 
processed observation next is [1.0, 1.0, 0.4090909090909091, 0.52, 1.0, 1.0, 0.04139882845353885, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09374591451697208, 0.09374591451697208, 0.1790424888068517], 
reward next is 0.8210, 
noisyNet noise sample is [array([-0.7957313], dtype=float32), 1.8030727]. 
=============================================
[2019-03-23 01:53:51,187] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00
 1.01939546e-32], sum to 1.0000
[2019-03-23 01:53:51,200] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9312
[2019-03-23 01:53:51,205] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 83.00000000000001, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 204534.3136242876, 204534.3136242873, 67903.88851291197], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2351400.0000, 
sim time next is 2352000.0000, 
raw observation next is [13.0, 84.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 202557.304798537, 202557.3047985367, 67774.05594633825], 
processed observation next is [1.0, 0.21739130434782608, 0.22727272727272727, 0.84, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07502122399945814, 0.07502122399945804, 0.16530257547887378], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.33480683], dtype=float32), -0.08273795]. 
=============================================
[2019-03-23 01:53:51,230] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[72.50423 ]
 [72.448044]
 [72.363205]
 [72.336494]
 [72.30272 ]], R is [[71.79137421]
 [71.07346344]
 [70.36273193]
 [69.65910339]
 [68.96251678]].
[2019-03-23 01:53:51,249] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.7520449e-37 0.0000000e+00 1.0512952e-36], sum to 1.0000
[2019-03-23 01:53:51,254] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3249
[2019-03-23 01:53:51,257] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.66666666666667, 78.83333333333334, 1.0, 2.0, 0.2266486949265369, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 246086.8527503014, 246086.8527503014, 72733.94145985864], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2340600.0000, 
sim time next is 2341200.0000, 
raw observation next is [13.33333333333333, 80.66666666666667, 1.0, 2.0, 0.2052252459041196, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 222820.7283706747, 222820.7283706744, 70831.09492922926], 
processed observation next is [1.0, 0.08695652173913043, 0.2424242424242423, 0.8066666666666668, 1.0, 1.0, 0.0065315573801495025, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08252619569284249, 0.08252619569284236, 0.17275876812007138], 
reward next is 0.8272, 
noisyNet noise sample is [array([-0.29268017], dtype=float32), 0.17907429]. 
=============================================
[2019-03-23 01:53:51,929] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-23 01:53:51,934] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 01:53:51,934] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:53:51,936] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 01:53:51,937] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 01:53:51,938] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:53:51,939] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 01:53:51,939] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:53:51,941] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:53:51,940] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 01:53:51,945] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:53:51,968] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run80
[2019-03-23 01:53:51,969] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run80
[2019-03-23 01:53:52,016] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run80
[2019-03-23 01:53:52,017] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run80
[2019-03-23 01:53:52,018] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run80
[2019-03-23 01:54:42,907] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.32677254], dtype=float32), -0.22800386]
[2019-03-23 01:54:42,908] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.03670633, 91.84949101666668, 1.0, 2.0, 0.5404748747621163, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 614829.9636510488, 614829.9636510488, 152664.3315956922]
[2019-03-23 01:54:42,909] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 01:54:42,913] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.18671998991093686
[2019-03-23 01:55:03,074] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.32677254], dtype=float32), -0.22800386]
[2019-03-23 01:55:03,077] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [26.20189040333334, 68.22312159, 1.0, 2.0, 0.522480317374487, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 594918.3808627838, 594918.3808627834, 150024.038495399]
[2019-03-23 01:55:03,078] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 01:55:03,081] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.7000426795827623
[2019-03-23 01:55:11,549] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.32677254], dtype=float32), -0.22800386]
[2019-03-23 01:55:11,552] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [18.63333333333333, 77.66666666666667, 1.0, 2.0, 0.3054034165664807, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 332129.7967098343, 332129.796709834, 116046.0613505702]
[2019-03-23 01:55:11,553] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 01:55:11,556] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.2878390437352625
[2019-03-23 01:55:12,086] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.32677254], dtype=float32), -0.22800386]
[2019-03-23 01:55:12,088] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [12.50316743, 92.65920453, 1.0, 2.0, 0.4984636615478924, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 541320.3989469247, 541320.3989469247, 106051.2521310221]
[2019-03-23 01:55:12,090] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 01:55:12,093] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 6.461196e-37], sampled 0.5506186428056876
[2019-03-23 01:55:13,799] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.32677254], dtype=float32), -0.22800386]
[2019-03-23 01:55:13,800] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [27.70597822333333, 54.28571018666666, 1.0, 2.0, 0.6300355129157919, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 718941.1890044218, 718941.1890044218, 161176.4292014887]
[2019-03-23 01:55:13,802] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 01:55:13,806] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.11341871665191872
[2019-03-23 01:55:40,190] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8504.2537 1774693701.5591 173.0000
[2019-03-23 01:55:40,598] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8591.2438 1706283482.2077 465.0000
[2019-03-23 01:55:40,648] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9056.2452 1656484552.8426 80.0000
[2019-03-23 01:55:40,682] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8851.2566 1664152039.1676 105.0000
[2019-03-23 01:55:40,707] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8569.0423 1683679931.9503 214.0000
[2019-03-23 01:55:41,721] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 1975000, evaluation results [1975000.0, 8504.25368927381, 1774693701.559082, 173.0, 9056.245151782041, 1656484552.8426478, 80.0, 8851.256611154593, 1664152039.1676362, 105.0, 8591.243823297678, 1706283482.2076914, 465.0, 8569.042332002715, 1683679931.9503295, 214.0]
[2019-03-23 01:55:55,354] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:55:55,366] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9985
[2019-03-23 01:55:55,370] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 82.0, 1.0, 2.0, 0.2477624210796585, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 269017.7033254652, 269017.7033254652, 83806.20401703191], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3291600.0000, 
sim time next is 3292200.0000, 
raw observation next is [16.0, 82.0, 1.0, 2.0, 0.2466951385025525, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 267858.5405657373, 267858.540565737, 83682.22103907312], 
processed observation next is [0.0, 0.08695652173913043, 0.36363636363636365, 0.82, 1.0, 1.0, 0.05836892312819062, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09920686687619899, 0.09920686687619888, 0.2041029781440808], 
reward next is 0.7959, 
noisyNet noise sample is [array([-0.04815274], dtype=float32), -0.76636636]. 
=============================================
[2019-03-23 01:55:57,136] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:55:57,144] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3932
[2019-03-23 01:55:57,149] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 65.0, 1.0, 2.0, 0.4917001243482953, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 560971.8633177746, 560971.8633177746, 140645.9113188187], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3006000.0000, 
sim time next is 3006600.0000, 
raw observation next is [25.66666666666667, 65.66666666666667, 1.0, 2.0, 0.4881381749289685, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 556987.386039529, 556987.3860395286, 139911.5981202586], 
processed observation next is [1.0, 0.8260869565217391, 0.8030303030303032, 0.6566666666666667, 1.0, 1.0, 0.3601727186612106, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2062916244590848, 0.2062916244590847, 0.34124780029331364], 
reward next is 0.6588, 
noisyNet noise sample is [array([0.31366885], dtype=float32), -0.33672875]. 
=============================================
[2019-03-23 01:56:06,102] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:56:06,112] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8472
[2019-03-23 01:56:06,119] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 78.0, 1.0, 2.0, 0.4204687016382813, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 476645.2773611488, 476645.2773611488, 128393.1454628142], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3018000.0000, 
sim time next is 3018600.0000, 
raw observation next is [21.5, 78.0, 1.0, 2.0, 0.4157195898546904, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 470691.363906912, 470691.363906912, 127563.3650832239], 
processed observation next is [1.0, 0.9565217391304348, 0.6136363636363636, 0.78, 1.0, 1.0, 0.2696494873183629, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17433013478033776, 0.17433013478033776, 0.31113015873957045], 
reward next is 0.6889, 
noisyNet noise sample is [array([0.6438247], dtype=float32), -0.12778123]. 
=============================================
[2019-03-23 01:56:14,834] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 2.9679849e-37 0.0000000e+00 1.4958029e-32], sum to 1.0000
[2019-03-23 01:56:14,851] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5368
[2019-03-23 01:56:14,858] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 100.0, 1.0, 2.0, 0.5368896564870119, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 610658.2539682906, 610658.2539682906, 148010.0756522485], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2938800.0000, 
sim time next is 2939400.0000, 
raw observation next is [22.0, 100.0, 1.0, 2.0, 0.5368245901335799, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 610584.4720048042, 610584.4720048045, 148001.7708976557], 
processed observation next is [1.0, 0.0, 0.6363636363636364, 1.0, 1.0, 1.0, 0.4210307376669748, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22614239703881636, 0.2261423970388165, 0.36097992901867243], 
reward next is 0.6390, 
noisyNet noise sample is [array([0.01335296], dtype=float32), 1.564302]. 
=============================================
[2019-03-23 01:56:15,310] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:56:15,312] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5865
[2019-03-23 01:56:15,318] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.83333333333334, 50.66666666666667, 1.0, 2.0, 0.35516308773364, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 397442.5333027554, 397442.5333027554, 119542.649569941], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3333000.0000, 
sim time next is 3333600.0000, 
raw observation next is [25.0, 50.0, 1.0, 2.0, 0.35580770895976, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 398304.5154536546, 398304.5154536549, 119660.7020961405], 
processed observation next is [0.0, 0.6086956521739131, 0.7727272727272727, 0.5, 1.0, 1.0, 0.19475963619969996, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14752019090876095, 0.1475201909087611, 0.29185537096619635], 
reward next is 0.7081, 
noisyNet noise sample is [array([-0.5233727], dtype=float32), 0.36201388]. 
=============================================
[2019-03-23 01:56:16,245] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:56:16,252] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3396
[2019-03-23 01:56:16,258] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333333, 59.66666666666667, 1.0, 2.0, 0.3688583281783017, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 413661.9052316115, 413661.9052316117, 121090.4243641656], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3350400.0000, 
sim time next is 3351000.0000, 
raw observation next is [23.16666666666667, 60.33333333333334, 1.0, 2.0, 0.3682270623755156, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 412727.0036836132, 412727.0036836132, 120929.0861894918], 
processed observation next is [0.0, 0.782608695652174, 0.6893939393939396, 0.6033333333333334, 1.0, 1.0, 0.2102838279693945, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15286185321615303, 0.15286185321615303, 0.29494899070607755], 
reward next is 0.7051, 
noisyNet noise sample is [array([1.2031612], dtype=float32), -0.90271306]. 
=============================================
[2019-03-23 01:56:16,273] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[69.443184]
 [69.47358 ]
 [69.50722 ]
 [69.52794 ]
 [69.59582 ]], R is [[69.43013   ]
 [69.44049072]
 [69.45041656]
 [69.45985413]
 [69.46878052]].
[2019-03-23 01:56:28,781] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.0000000e+00 2.4175783e-01 4.2751845e-38 0.0000000e+00 7.5824219e-01], sum to 1.0000
[2019-03-23 01:56:28,791] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0688
[2019-03-23 01:56:28,798] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1328496.354164462 W.
[2019-03-23 01:56:28,801] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.66666666666667, 57.33333333333334, 1.0, 2.0, 0.3911861967134315, 1.0, 2.0, 0.3911861967134315, 1.0, 2.0, 0.7919483359083658, 6.911199999999999, 6.9112, 77.3421103, 1328496.354164462, 1328496.354164463, 299659.9392921981], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3428400.0000, 
sim time next is 3429000.0000, 
raw observation next is [27.5, 58.5, 1.0, 2.0, 0.5923151104801005, 1.0, 2.0, 0.5923151104801005, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1342428.236631393, 1342428.236631393, 257096.5618222546], 
processed observation next is [1.0, 0.6956521739130435, 0.8863636363636364, 0.585, 1.0, 1.0, 0.49039388810012563, 1.0, 1.0, 0.49039388810012563, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.4971956431968122, 0.4971956431968122, 0.6270647849323283], 
reward next is 0.3729, 
noisyNet noise sample is [array([1.0105615], dtype=float32), 0.3636813]. 
=============================================
[2019-03-23 01:56:28,816] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[54.811718]
 [54.281918]
 [53.95179 ]
 [53.280205]
 [53.954285]], R is [[54.58971786]
 [54.3129425 ]
 [54.04227829]
 [53.77375031]
 [53.50854492]].
[2019-03-23 01:56:29,058] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:56:29,065] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2689
[2019-03-23 01:56:29,070] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 88.0, 1.0, 2.0, 0.3333147366678002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 366848.4370799233, 366848.4370799233, 115220.9111718394], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3217200.0000, 
sim time next is 3217800.0000, 
raw observation next is [18.0, 88.0, 1.0, 2.0, 0.3325503606706393, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 366003.6382282531, 366003.6382282531, 115163.1286270642], 
processed observation next is [0.0, 0.21739130434782608, 0.45454545454545453, 0.88, 1.0, 1.0, 0.16568795083829913, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13555690304750115, 0.13555690304750115, 0.28088567957820537], 
reward next is 0.7191, 
noisyNet noise sample is [array([-1.0001956], dtype=float32), -0.28233212]. 
=============================================
[2019-03-23 01:56:29,147] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:56:29,159] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4561
[2019-03-23 01:56:29,165] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 94.0, 1.0, 2.0, 0.3928430795389779, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 442665.9437215276, 442665.9437215279, 124197.2859482176], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3202200.0000, 
sim time next is 3202800.0000, 
raw observation next is [19.0, 94.0, 1.0, 2.0, 0.3931194976597872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 442977.7030103136, 442977.7030103139, 124222.0725049065], 
processed observation next is [0.0, 0.043478260869565216, 0.5, 0.94, 1.0, 1.0, 0.241399372074734, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16406581592974578, 0.1640658159297459, 0.3029806646461134], 
reward next is 0.6970, 
noisyNet noise sample is [array([-1.1498709], dtype=float32), 0.42971507]. 
=============================================
[2019-03-23 01:56:34,133] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-23 01:56:34,133] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 01:56:34,134] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 01:56:34,135] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:56:34,137] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:56:34,137] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 01:56:34,139] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:56:34,139] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 01:56:34,140] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 01:56:34,141] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:56:34,141] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:56:35,180] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run81
[2019-03-23 01:56:35,205] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run81
[2019-03-23 01:56:35,227] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run81
[2019-03-23 01:56:35,228] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run81
[2019-03-23 01:56:35,266] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run81
[2019-03-23 01:56:42,267] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.20997056], dtype=float32), -0.20376176]
[2019-03-23 01:56:42,268] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [15.2, 64.0, 1.0, 2.0, 0.2120189069042163, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 230188.2169721683, 230188.216972168, 75697.33804317568]
[2019-03-23 01:56:42,268] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 01:56:42,272] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.5123727314136377
[2019-03-23 01:56:46,501] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.20997056], dtype=float32), -0.20376176]
[2019-03-23 01:56:46,503] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.99183606333333, 83.46534174, 1.0, 2.0, 0.2978299282230562, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 323378.0181285595, 323378.0181285595, 104507.4010262373]
[2019-03-23 01:56:46,507] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 01:56:46,512] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.8447052778955724
[2019-03-23 01:57:15,581] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.20997056], dtype=float32), -0.20376176]
[2019-03-23 01:57:15,583] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.5, 78.0, 1.0, 2.0, 0.4157195898546904, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 470691.363906912, 470691.363906912, 127563.3650832239]
[2019-03-23 01:57:15,584] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 01:57:15,586] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.6105575687422419
[2019-03-23 01:57:16,589] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.20997056], dtype=float32), -0.20376176]
[2019-03-23 01:57:16,592] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [26.3, 65.0, 1.0, 2.0, 0.7739722949285329, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 882544.5873430419, 882544.5873430416, 184422.9108990275]
[2019-03-23 01:57:16,593] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 01:57:16,596] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.22241461311455513
[2019-03-23 01:57:22,833] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.20997056], dtype=float32), -0.20376176]
[2019-03-23 01:57:22,834] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.51197743833333, 90.34242198166667, 1.0, 2.0, 0.5640574992798856, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 640245.7827244822, 640245.7827244822, 156418.7648806947]
[2019-03-23 01:57:22,835] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 01:57:22,836] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.4069691279358032
[2019-03-23 01:57:26,507] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.20997056], dtype=float32), -0.20376176]
[2019-03-23 01:57:26,509] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [13.16881612, 91.35869978, 1.0, 2.0, 0.2060253158755466, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 223679.7845236392, 223679.7845236392, 77162.84771849838]
[2019-03-23 01:57:26,511] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 01:57:26,516] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.29476634177161265
[2019-03-23 01:57:54,300] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.20997056], dtype=float32), -0.20376176]
[2019-03-23 01:57:54,300] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [25.308193815, 48.821406575, 1.0, 2.0, 0.4967582946702043, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 556855.519414949, 556855.5194149486, 137119.1487361233]
[2019-03-23 01:57:54,305] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 01:57:54,307] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.7143764310561637
[2019-03-23 01:58:02,519] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.20997056], dtype=float32), -0.20376176]
[2019-03-23 01:58:02,519] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.12138766666667, 78.42929757666667, 1.0, 2.0, 0.4001206609287343, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 448620.4373657005, 448620.4373657002, 128056.7507464597]
[2019-03-23 01:58:02,521] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 01:58:02,525] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.12501501282387506
[2019-03-23 01:58:07,068] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.20997056], dtype=float32), -0.20376176]
[2019-03-23 01:58:07,069] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [26.56445127, 59.32801603, 1.0, 2.0, 0.7527386697012857, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 859015.4070746042, 859015.4070746042, 178345.9404588258]
[2019-03-23 01:58:07,071] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 01:58:07,074] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.7947619492941442
[2019-03-23 01:58:08,918] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.20997056], dtype=float32), -0.20376176]
[2019-03-23 01:58:08,920] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [28.46666666666667, 49.33333333333334, 1.0, 2.0, 0.4553663516262134, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 519512.7571477731, 519512.7571477731, 135346.6176063167]
[2019-03-23 01:58:08,921] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 01:58:08,924] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.9306425223963639
[2019-03-23 01:58:23,102] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8570.4787 1683579848.9606 214.0000
[2019-03-23 01:58:23,249] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8852.6925 1664051680.8275 105.0000
[2019-03-23 01:58:23,318] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9057.8713 1656401324.5381 80.0000
[2019-03-23 01:58:23,431] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8508.4528 1773463374.2284 173.0000
[2019-03-23 01:58:23,457] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8593.6867 1706159149.9219 465.0000
[2019-03-23 01:58:24,471] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 2000000, evaluation results [2000000.0, 8508.45277065677, 1773463374.2284098, 173.0, 9057.871276350008, 1656401324.538099, 80.0, 8852.692524936243, 1664051680.8275282, 105.0, 8593.686660790749, 1706159149.921858, 465.0, 8570.478727897242, 1683579848.9606183, 214.0]
[2019-03-23 01:58:24,965] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.2814053e-26 1.0000000e+00 3.1259752e-25 2.1789312e-24 1.0032100e-14], sum to 1.0000
[2019-03-23 01:58:24,973] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0122
[2019-03-23 01:58:24,983] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1424023.192080044 W.
[2019-03-23 01:58:24,987] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.33333333333334, 63.33333333333334, 1.0, 2.0, 0.421544183034358, 1.0, 1.0, 0.421544183034358, 1.0, 2.0, 0.8518347978963846, 6.911199999999999, 6.9112, 77.3421103, 1424023.192080044, 1424023.192080044, 316655.0836710978], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3676800.0000, 
sim time next is 3677400.0000, 
raw observation next is [27.5, 62.0, 1.0, 2.0, 0.6735296998464405, 1.0, 2.0, 0.6735296998464405, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846344352107, 1517262.801116511, 1517262.801116511, 283079.0708587344], 
processed observation next is [1.0, 0.5652173913043478, 0.8863636363636364, 0.62, 1.0, 1.0, 0.5919121248080506, 1.0, 1.0, 0.5919121248080506, 0.0, 0.5, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129205228, 0.5619491855987078, 0.5619491855987078, 0.6904367581920352], 
reward next is 0.3096, 
noisyNet noise sample is [array([-0.60172266], dtype=float32), -1.0490186]. 
=============================================
[2019-03-23 01:58:25,437] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:58:25,451] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8830
[2019-03-23 01:58:25,456] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.33333333333333, 71.0, 1.0, 2.0, 0.2692507705373398, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 292356.5287993409, 292356.5287993409, 94212.56018082658], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3310800.0000, 
sim time next is 3311400.0000, 
raw observation next is [18.66666666666667, 69.5, 1.0, 2.0, 0.2721299658511076, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 295483.7520178293, 295483.7520178293, 96087.65841329355], 
processed observation next is [0.0, 0.30434782608695654, 0.4848484848484851, 0.695, 1.0, 1.0, 0.09016245731388449, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1094384266732701, 0.1094384266732701, 0.23436014247144768], 
reward next is 0.7656, 
noisyNet noise sample is [array([-0.5553807], dtype=float32), -0.054689508]. 
=============================================
[2019-03-23 01:58:27,753] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:58:27,760] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4999
[2019-03-23 01:58:27,768] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 61.0, 1.0, 2.0, 0.3671877261213584, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 411324.5723782057, 411324.5723782057, 120730.0184434245], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3351600.0000, 
sim time next is 3352200.0000, 
raw observation next is [22.83333333333334, 61.5, 1.0, 2.0, 0.365477275152487, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 409066.844530224, 409066.844530224, 120428.3228285924], 
processed observation next is [0.0, 0.8260869565217391, 0.6742424242424245, 0.615, 1.0, 1.0, 0.20684659394060875, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15150623871489777, 0.15150623871489777, 0.2937276166551034], 
reward next is 0.7063, 
noisyNet noise sample is [array([-0.92210084], dtype=float32), -1.0871083]. 
=============================================
[2019-03-23 01:58:29,572] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 9.1537227e-38], sum to 1.0000
[2019-03-23 01:58:29,580] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3021
[2019-03-23 01:58:29,588] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 100.0, 1.0, 2.0, 0.3392182603621814, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 375416.2332627076, 375416.2332627076, 116456.6809923748], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4165200.0000, 
sim time next is 4165800.0000, 
raw observation next is [17.0, 100.0, 1.0, 2.0, 0.3338830136494165, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 369494.3693194262, 369494.3693194262, 116045.3552836621], 
processed observation next is [1.0, 0.21739130434782608, 0.4090909090909091, 1.0, 1.0, 1.0, 0.16735376706177063, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13684976641460228, 0.13684976641460228, 0.283037451911371], 
reward next is 0.7170, 
noisyNet noise sample is [array([0.6155062], dtype=float32), -1.2890075]. 
=============================================
[2019-03-23 01:58:32,927] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.1926339e-29 3.4821039e-07 7.7854481e-24 5.2604814e-34 9.9999964e-01], sum to 1.0000
[2019-03-23 01:58:32,935] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5243
[2019-03-23 01:58:32,940] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.5, 72.0, 1.0, 2.0, 0.2798720051970019, 1.0, 2.0, 0.2798720051970019, 1.0, 2.0, 0.5666398563459007, 6.9112, 6.9112, 77.3421103, 950439.89353794, 950439.89353794, 254651.95712268], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3673800.0000, 
sim time next is 3674400.0000, 
raw observation next is [26.0, 70.0, 1.0, 2.0, 0.3165584609102665, 1.0, 2.0, 0.3165584609102665, 1.0, 2.0, 0.640654910370436, 6.9112, 6.9112, 77.3421103, 1073550.838684191, 1073550.838684191, 268629.2259360825], 
processed observation next is [1.0, 0.5217391304347826, 0.8181818181818182, 0.7, 1.0, 1.0, 0.14569807613783312, 1.0, 1.0, 0.14569807613783312, 1.0, 1.0, 0.4866498719577657, 0.0, 0.0, 0.5085185399722538, 0.39761142173488556, 0.39761142173488556, 0.655193233990445], 
reward next is 0.3448, 
noisyNet noise sample is [array([0.03321903], dtype=float32), 0.16101204]. 
=============================================
[2019-03-23 01:58:36,337] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.8538607e-20 8.1297964e-02 3.0215334e-18 5.4415105e-31 9.1870207e-01], sum to 1.0000
[2019-03-23 01:58:36,345] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8699
[2019-03-23 01:58:36,353] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.83333333333334, 63.33333333333334, 1.0, 2.0, 0.4176132662441565, 1.0, 2.0, 0.4176132662441565, 1.0, 2.0, 0.844990094097913, 6.911199999999999, 6.9112, 77.3421103, 1408831.82789288, 1408831.82789288, 315970.6905909466], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3505800.0000, 
sim time next is 3506400.0000, 
raw observation next is [28.0, 62.0, 1.0, 2.0, 0.4377228476083392, 1.0, 2.0, 0.4377228476083392, 1.0, 2.0, 0.8856794074475897, 6.9112, 6.9112, 77.3421103, 1476760.603443161, 1476760.603443161, 326225.3822088055], 
processed observation next is [1.0, 0.6086956521739131, 0.9090909090909091, 0.62, 1.0, 1.0, 0.29715355951042394, 1.0, 1.0, 0.29715355951042394, 1.0, 1.0, 0.8366848677822711, 0.0, 0.0, 0.5085185399722538, 0.5469483716456152, 0.5469483716456152, 0.7956716639239158], 
reward next is 0.2043, 
noisyNet noise sample is [array([0.02683498], dtype=float32), -0.8296597]. 
=============================================
[2019-03-23 01:58:38,787] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.4409395e-38 1.0000000e+00 2.6847019e-34 0.0000000e+00 1.1639298e-30], sum to 1.0000
[2019-03-23 01:58:38,798] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7396
[2019-03-23 01:58:38,806] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.5123457963219865, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 584302.5576395615, 584302.5576395612, 143549.1798098755], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3621600.0000, 
sim time next is 3622200.0000, 
raw observation next is [21.83333333333334, 95.0, 1.0, 2.0, 0.5102092250132598, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 581905.7689154734, 581905.7689154734, 143226.3036591802], 
processed observation next is [1.0, 0.9565217391304348, 0.628787878787879, 0.95, 1.0, 1.0, 0.38776153126657475, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21552065515387903, 0.21552065515387903, 0.34933244794922], 
reward next is 0.6507, 
noisyNet noise sample is [array([2.3817809], dtype=float32), 0.54709655]. 
=============================================
[2019-03-23 01:58:39,702] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:58:39,714] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8501
[2019-03-23 01:58:39,722] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.5607156289406031, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 639472.1684570676, 639472.1684570676, 149519.5131171882], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3555000.0000, 
sim time next is 3555600.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.5558705054222167, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 633948.4382147196, 633948.4382147196, 148901.4920265753], 
processed observation next is [1.0, 0.13043478260869565, 0.6363636363636364, 0.94, 1.0, 1.0, 0.4448381317777709, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23479571785730358, 0.23479571785730358, 0.3631743707965251], 
reward next is 0.6368, 
noisyNet noise sample is [array([0.49983877], dtype=float32), -0.556226]. 
=============================================
[2019-03-23 01:58:41,435] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.18973544e-26 1.00000000e+00 1.49322643e-24 6.09360623e-29
 2.47445049e-13], sum to 1.0000
[2019-03-23 01:58:41,443] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6715
[2019-03-23 01:58:41,447] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.83333333333334, 78.0, 1.0, 2.0, 0.3187745635543696, 1.0, 2.0, 0.3187745635543696, 1.0, 1.0, 0.6446189062597554, 6.9112, 6.9112, 77.3421103, 1078482.956301568, 1078482.956301568, 270371.4512741021], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3669000.0000, 
sim time next is 3669600.0000, 
raw observation next is [24.66666666666667, 78.0, 1.0, 2.0, 0.9992612148879246, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.269258562674994, 6.9112, 77.32775299230923, 1252553.164654536, 1136264.135471021, 222773.499817355], 
processed observation next is [1.0, 0.4782608695652174, 0.7575757575757578, 0.78, 1.0, 1.0, 0.9990765186099057, 0.0, 0.5, -0.25, 0.0, 0.5, -0.4285714285714286, 0.035805856267499436, 0.0, 0.5084241417574066, 0.46390857950167996, 0.42083856869297076, 0.5433499995545245], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1737484], dtype=float32), 0.14507692]. 
=============================================
[2019-03-23 01:58:45,224] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.09181535e-36 1.00000000e+00 2.36536812e-33 0.00000000e+00
 3.37063222e-13], sum to 1.0000
[2019-03-23 01:58:45,232] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6234
[2019-03-23 01:58:45,236] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.33333333333334, 55.66666666666667, 1.0, 2.0, 0.4564829702721279, 1.0, 2.0, 0.4564829702721279, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1039154.606367215, 1039154.606367215, 220452.5535699327], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4364400.0000, 
sim time next is 4365000.0000, 
raw observation next is [27.5, 54.5, 1.0, 2.0, 0.7993460943181501, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 912354.6707382173, 912354.6707382173, 182783.6767792583], 
processed observation next is [1.0, 0.5217391304347826, 0.8863636363636364, 0.545, 1.0, 1.0, 0.7491826178976876, 0.0, 0.5, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.33790913731045086, 0.33790913731045086, 0.44581384580306904], 
reward next is 0.5542, 
noisyNet noise sample is [array([-0.77880013], dtype=float32), 0.1321376]. 
=============================================
[2019-03-23 01:58:45,245] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[54.883972]
 [52.766968]
 [53.02468 ]
 [52.660923]
 [52.895874]], R is [[55.14421844]
 [54.59277725]
 [54.33116913]
 [54.16657257]
 [53.62490845]].
[2019-03-23 01:58:45,967] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:58:45,976] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2010
[2019-03-23 01:58:45,980] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.66666666666666, 68.0, 1.0, 2.0, 0.5012395359926995, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 571698.1387120147, 571698.1387120147, 142119.2702450809], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4459200.0000, 
sim time next is 4459800.0000, 
raw observation next is [25.83333333333334, 66.5, 1.0, 2.0, 0.4980098383897413, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 568095.2707739645, 568095.2707739645, 141575.4539429868], 
processed observation next is [0.0, 0.6086956521739131, 0.8106060606060609, 0.665, 1.0, 1.0, 0.37251229798717655, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21040565584220905, 0.21040565584220905, 0.34530598522679706], 
reward next is 0.6547, 
noisyNet noise sample is [array([-0.6298], dtype=float32), -1.0233599]. 
=============================================
[2019-03-23 01:58:48,741] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 2.5363839e-32 3.2512308e-33 1.8482420e-30], sum to 1.0000
[2019-03-23 01:58:48,749] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8016
[2019-03-23 01:58:48,755] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.5089935710144614, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 580482.6410448605, 580482.6410448605, 143142.8333144495], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3722400.0000, 
sim time next is 3723000.0000, 
raw observation next is [22.0, 94.00000000000001, 1.0, 2.0, 0.8863941770010234, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 85.22654624974355, 1011078.557698673, 1011078.557698673, 201220.1634675362], 
processed observation next is [1.0, 0.08695652173913043, 0.6363636363636364, 0.9400000000000002, 1.0, 1.0, 0.8579927212512791, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5603581114827346, 0.3744735398883974, 0.3744735398883974, 0.49078088650618584], 
reward next is 0.5092, 
noisyNet noise sample is [array([-1.466805], dtype=float32), 0.80620944]. 
=============================================
[2019-03-23 01:58:48,764] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[62.226284]
 [62.17144 ]
 [62.237617]
 [62.341824]
 [62.42499 ]], R is [[58.41989136]
 [58.48656464]
 [58.55221176]
 [58.61721802]
 [58.68200302]].
[2019-03-23 01:58:53,925] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:58:53,937] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7399
[2019-03-23 01:58:53,944] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 88.0, 1.0, 2.0, 0.3027770488037801, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 328772.1702185383, 328772.1702185383, 110306.6089348219], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3816000.0000, 
sim time next is 3816600.0000, 
raw observation next is [17.0, 88.00000000000001, 1.0, 2.0, 0.3002865741871277, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 326066.9676520651, 326066.9676520648, 109939.1674121107], 
processed observation next is [0.0, 0.17391304347826086, 0.4090909090909091, 0.8800000000000001, 1.0, 1.0, 0.12535821773390957, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12076554357483893, 0.12076554357483882, 0.2681443107612456], 
reward next is 0.7319, 
noisyNet noise sample is [array([0.81685835], dtype=float32), -0.29814577]. 
=============================================
[2019-03-23 01:59:03,534] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:59:03,543] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7364
[2019-03-23 01:59:03,551] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.66666666666667, 79.0, 1.0, 2.0, 0.281773515300733, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 305958.1902502673, 305958.1902502673, 100419.2868493307], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3980400.0000, 
sim time next is 3981000.0000, 
raw observation next is [17.58333333333333, 79.5, 1.0, 2.0, 0.2807729314283414, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 304871.385523712, 304871.3855237123, 99969.01930769808], 
processed observation next is [1.0, 0.043478260869565216, 0.4356060606060604, 0.795, 1.0, 1.0, 0.10096616428542676, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11291532797174518, 0.1129153279717453, 0.24382687636023923], 
reward next is 0.7562, 
noisyNet noise sample is [array([-0.5683228], dtype=float32), 0.74549836]. 
=============================================
[2019-03-23 01:59:03,561] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[69.550545]
 [69.48631 ]
 [69.44309 ]
 [69.34831 ]
 [69.45485 ]], R is [[69.64627075]
 [69.70487976]
 [69.76167297]
 [69.81687927]
 [69.87075806]].
[2019-03-23 01:59:11,818] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:59:11,826] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5779
[2019-03-23 01:59:11,829] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.3785904934738962, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 425023.8071018842, 425023.8071018842, 122130.5443220131], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4137600.0000, 
sim time next is 4138200.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.3788883960242388, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 425356.581787493, 425356.581787493, 122155.2811868296], 
processed observation next is [1.0, 0.9130434782608695, 0.45454545454545453, 1.0, 1.0, 1.0, 0.22361049503029848, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15753947473610852, 0.15753947473610852, 0.2979397102117795], 
reward next is 0.7021, 
noisyNet noise sample is [array([1.587445], dtype=float32), -0.1578348]. 
=============================================
[2019-03-23 01:59:15,074] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:59:15,081] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3013
[2019-03-23 01:59:15,088] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 73.0, 1.0, 2.0, 0.4250963604771499, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 483440.7220294932, 483440.7220294935, 130037.9011466709], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4903200.0000, 
sim time next is 4903800.0000, 
raw observation next is [23.0, 73.0, 1.0, 2.0, 0.4277093871034928, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 486440.8749313, 486440.8749312997, 130321.4303653947], 
processed observation next is [1.0, 0.782608695652174, 0.6818181818181818, 0.73, 1.0, 1.0, 0.284636733879366, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1801632870115926, 0.18016328701159248, 0.31785714723267], 
reward next is 0.6821, 
noisyNet noise sample is [array([-0.74651587], dtype=float32), 0.10442448]. 
=============================================
[2019-03-23 01:59:16,333] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 01:59:16,334] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 01:59:16,335] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:59:16,335] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 01:59:16,336] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:59:16,337] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 01:59:16,338] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 01:59:16,339] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:59:16,340] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:59:16,340] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 01:59:16,343] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:59:16,357] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run82
[2019-03-23 01:59:16,380] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run82
[2019-03-23 01:59:16,381] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run82
[2019-03-23 01:59:16,401] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run82
[2019-03-23 01:59:16,403] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run82
[2019-03-23 01:59:18,288] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.1368503], dtype=float32), -0.18480068]
[2019-03-23 01:59:18,292] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.28815203, 75.37407059333334, 1.0, 2.0, 0.417458723640163, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 471545.2793124222, 471545.2793124219, 131384.5446832101]
[2019-03-23 01:59:18,293] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 01:59:18,294] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.9078519523007214
[2019-03-23 01:59:23,239] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.1368503], dtype=float32), -0.18480068]
[2019-03-23 01:59:23,241] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [15.02030687, 99.10866714, 1.0, 2.0, 0.4555258338201613, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 494671.6810392446, 494671.6810392442, 117128.1288714369]
[2019-03-23 01:59:23,241] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 01:59:23,243] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.2840441673394669
[2019-03-23 01:59:27,542] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.1368503], dtype=float32), -0.18480068]
[2019-03-23 01:59:27,544] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [27.8, 41.66666666666667, 1.0, 2.0, 0.3925624715799377, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 443346.5129287785, 443346.5129287781, 129054.0504651018]
[2019-03-23 01:59:27,547] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 01:59:27,551] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.6506320681024751
[2019-03-23 01:59:29,140] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.1368503], dtype=float32), -0.18480068]
[2019-03-23 01:59:29,141] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [14.54134741333333, 94.62078706666668, 1.0, 2.0, 0.2479002241745857, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 269153.165087695, 269153.1650876947, 87733.65859087747]
[2019-03-23 01:59:29,142] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 01:59:29,145] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.9733262363766364
[2019-03-23 01:59:30,027] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.1368503], dtype=float32), -0.18480068]
[2019-03-23 01:59:30,028] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.7, 84.0, 1.0, 2.0, 0.4421324947676629, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 503381.5918891375, 503381.5918891375, 136647.9120097199]
[2019-03-23 01:59:30,030] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 01:59:30,032] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.9817980502893431
[2019-03-23 01:59:34,253] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.1368503], dtype=float32), -0.18480068]
[2019-03-23 01:59:34,254] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [23.493814205, 85.76991121500001, 1.0, 2.0, 0.5283933187168908, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 601601.8514689724, 601601.851468972, 150789.4363884159]
[2019-03-23 01:59:34,255] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 01:59:34,258] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.01360850356358101
[2019-03-23 01:59:36,319] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.1368503], dtype=float32), -0.18480068]
[2019-03-23 01:59:36,321] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.0, 94.0, 1.0, 2.0, 0.7351832207388498, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 838501.248192538, 838501.248192538, 173973.5148080566]
[2019-03-23 01:59:36,323] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 01:59:36,327] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.9295057155317856
[2019-03-23 01:59:47,778] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.1368503], dtype=float32), -0.18480068]
[2019-03-23 01:59:47,779] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [15.94637046, 90.97874919333333, 1.0, 2.0, 0.3047451768348857, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 330888.5292822615, 330888.5292822615, 102368.5923156586]
[2019-03-23 01:59:47,780] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 01:59:47,782] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.6038630318138842
[2019-03-23 02:00:17,199] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.1368503], dtype=float32), -0.18480068]
[2019-03-23 02:00:17,201] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.47102069333333, 45.54023905666666, 1.0, 2.0, 0.2919949026895439, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 317040.7883440927, 317040.7883440927, 89414.80224414072]
[2019-03-23 02:00:17,203] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 02:00:17,206] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.8766731819620641
[2019-03-23 02:00:25,698] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.1368503], dtype=float32), -0.18480068]
[2019-03-23 02:00:25,699] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.57620840333333, 85.36575109500001, 1.0, 2.0, 0.3909479010073759, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 438332.0178131471, 438332.0178131471, 127255.0301412265]
[2019-03-23 02:00:25,701] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 02:00:25,705] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.9451752043748921
[2019-03-23 02:00:39,846] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.1368503], dtype=float32), -0.18480068]
[2019-03-23 02:00:39,847] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [32.93302810833333, 56.75450570333333, 1.0, 2.0, 0.6420963741986377, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 721475.0578712324, 721475.0578712319, 169232.8455369735]
[2019-03-23 02:00:39,849] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 02:00:39,853] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.2971414125301248
[2019-03-23 02:00:40,235] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.1368503], dtype=float32), -0.18480068]
[2019-03-23 02:00:40,236] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [26.19726602666667, 74.91786789333334, 1.0, 2.0, 0.5806534733523568, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 656697.0955443882, 656697.0955443882, 159485.6150055809]
[2019-03-23 02:00:40,237] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 02:00:40,241] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.7012909394205702
[2019-03-23 02:01:01,814] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8594.4987 1706116953.1019 465.0000
[2019-03-23 02:01:01,897] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9058.6831 1656359050.7176 80.0000
[2019-03-23 02:01:02,322] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8509.9204 1773362326.3127 173.0000
[2019-03-23 02:01:02,353] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8571.9617 1683477666.0862 214.0000
[2019-03-23 02:01:02,387] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8853.4143 1664003580.0750 105.0000
[2019-03-23 02:01:03,402] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 2025000, evaluation results [2025000.0, 8509.920393844055, 1773362326.3127284, 173.0, 9058.683074210225, 1656359050.7176125, 80.0, 8853.414337702749, 1664003580.0749555, 105.0, 8594.49866461476, 1706116953.1019058, 465.0, 8571.9617444755, 1683477666.0861843, 214.0]
[2019-03-23 02:01:10,331] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:01:10,338] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4515
[2019-03-23 02:01:10,342] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 66.0, 1.0, 2.0, 0.5705860777866308, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 644271.5165632213, 644271.516563221, 154154.7116479899], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5148600.0000, 
sim time next is 5149200.0000, 
raw observation next is [28.0, 66.0, 1.0, 2.0, 0.5709688231521802, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 644702.3421008107, 644702.3421008107, 154206.2220673624], 
processed observation next is [0.0, 0.6086956521739131, 0.9090909090909091, 0.66, 1.0, 1.0, 0.46371102894022526, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23877864522252248, 0.23877864522252248, 0.3761127367496644], 
reward next is 0.6239, 
noisyNet noise sample is [array([-0.757408], dtype=float32), -0.23656875]. 
=============================================
[2019-03-23 02:01:14,982] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:01:14,996] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2963
[2019-03-23 02:01:15,002] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 74.0, 1.0, 2.0, 0.468714417457864, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 534800.426693026, 534800.426693026, 137007.194379862], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4444200.0000, 
sim time next is 4444800.0000, 
raw observation next is [24.0, 74.0, 1.0, 2.0, 0.470540942097966, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 536885.8649978008, 536885.8649978008, 137208.9191908331], 
processed observation next is [0.0, 0.43478260869565216, 0.7272727272727273, 0.74, 1.0, 1.0, 0.33817617762245744, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19884661666585216, 0.19884661666585216, 0.33465590046544663], 
reward next is 0.6653, 
noisyNet noise sample is [array([0.2626416], dtype=float32), 0.94053084]. 
=============================================
[2019-03-23 02:01:16,736] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.5976492e-36 0.0000000e+00 3.3865613e-36], sum to 1.0000
[2019-03-23 02:01:16,744] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0082
[2019-03-23 02:01:16,750] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.43333333333333, 100.0, 1.0, 2.0, 0.5077729129636704, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 578833.6500893852, 578833.6500893852, 143353.6001958245], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5263800.0000, 
sim time next is 5264400.0000, 
raw observation next is [21.36666666666667, 100.0, 1.0, 2.0, 0.5056371536191817, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 576503.3192247654, 576503.3192247654, 142966.1886546529], 
processed observation next is [1.0, 0.9565217391304348, 0.6075757575757578, 1.0, 1.0, 1.0, 0.3820464420239771, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21351974786102423, 0.21351974786102423, 0.3486980211089095], 
reward next is 0.6513, 
noisyNet noise sample is [array([0.87528116], dtype=float32), 1.9158992]. 
=============================================
[2019-03-23 02:01:18,654] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:01:18,662] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3789
[2019-03-23 02:01:18,667] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 94.0, 1.0, 2.0, 0.4616921921069952, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 526592.998960892, 526592.998960892, 135643.5213956959], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4495200.0000, 
sim time next is 4495800.0000, 
raw observation next is [21.0, 94.0, 1.0, 2.0, 0.4622335744862021, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 527210.8604073273, 527210.8604073273, 135701.8450041212], 
processed observation next is [0.0, 0.0, 0.5909090909090909, 0.94, 1.0, 1.0, 0.32779196810775263, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19526328163234344, 0.19526328163234344, 0.3309801097661492], 
reward next is 0.6690, 
noisyNet noise sample is [array([2.1902769], dtype=float32), -1.7077775]. 
=============================================
[2019-03-23 02:01:20,689] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.9467827e-33], sum to 1.0000
[2019-03-23 02:01:20,699] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9094
[2019-03-23 02:01:20,706] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.16666666666666, 89.0, 1.0, 2.0, 0.4530210675113022, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 516204.9339574765, 516204.9339574765, 133903.6831965887], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4531800.0000, 
sim time next is 4532400.0000, 
raw observation next is [21.0, 88.0, 1.0, 2.0, 0.4412092239127522, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 502165.6470338663, 502165.6470338663, 132021.7929360781], 
processed observation next is [0.0, 0.4782608695652174, 0.5909090909090909, 0.88, 1.0, 1.0, 0.3015115298909402, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18598727667920975, 0.18598727667920975, 0.32200437301482465], 
reward next is 0.6780, 
noisyNet noise sample is [array([0.8774721], dtype=float32), 0.42386878]. 
=============================================
[2019-03-23 02:01:30,250] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:01:30,259] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3571
[2019-03-23 02:01:30,264] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 67.66666666666667, 1.0, 2.0, 0.4241659979180609, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 482708.1458490968, 482708.1458490971, 130255.8048657175], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5085600.0000, 
sim time next is 5086200.0000, 
raw observation next is [24.0, 68.33333333333333, 1.0, 2.0, 0.4278296938774243, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 487093.8014950059, 487093.8014950059, 130843.3475600804], 
processed observation next is [0.0, 0.8695652173913043, 0.7272727272727273, 0.6833333333333332, 1.0, 1.0, 0.28478711734678036, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18040511166481701, 0.18040511166481701, 0.3191301160001961], 
reward next is 0.6809, 
noisyNet noise sample is [array([1.1420428], dtype=float32), 0.42284212]. 
=============================================
[2019-03-23 02:01:32,657] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.4833120e-34 1.0000000e+00 2.6328928e-36 1.2115335e-30 0.0000000e+00], sum to 1.0000
[2019-03-23 02:01:32,668] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0599
[2019-03-23 02:01:32,673] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.6742554105791162, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 765186.632901401, 765186.632901401, 157608.0158005439], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4870200.0000, 
sim time next is 4870800.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.6818973687629488, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 773904.9422276375, 773904.9422276375, 158643.7888870819], 
processed observation next is [1.0, 0.391304347826087, 0.5, 1.0, 1.0, 1.0, 0.602371710953686, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2866314600843102, 0.2866314600843102, 0.3869360704562973], 
reward next is 0.6131, 
noisyNet noise sample is [array([0.3670025], dtype=float32), -0.023068925]. 
=============================================
[2019-03-23 02:01:33,417] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.1970211e-38 0.0000000e+00], sum to 1.0000
[2019-03-23 02:01:33,425] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5130
[2019-03-23 02:01:33,434] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 88.0, 1.0, 2.0, 0.3733073735179695, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 417253.5642220335, 417253.5642220338, 120820.615024676], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4762200.0000, 
sim time next is 4762800.0000, 
raw observation next is [19.0, 88.0, 1.0, 2.0, 0.3725841335426084, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 416434.4870345797, 416434.4870345797, 120755.520941281], 
processed observation next is [1.0, 0.13043478260869565, 0.5, 0.88, 1.0, 1.0, 0.21573016692826047, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15423499519799247, 0.15423499519799247, 0.2945256608323927], 
reward next is 0.7055, 
noisyNet noise sample is [array([1.0694118], dtype=float32), 0.27918553]. 
=============================================
[2019-03-23 02:01:34,273] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:01:34,285] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5977
[2019-03-23 02:01:34,291] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.33333333333333, 98.0, 1.0, 2.0, 0.24917330349454, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 270550.0499729706, 270550.0499729709, 84190.3079421733], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5017800.0000, 
sim time next is 5018400.0000, 
raw observation next is [14.0, 100.0, 1.0, 2.0, 0.2461571851197103, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 267274.2769193627, 267274.276919363, 82980.71681990974], 
processed observation next is [0.0, 0.08695652173913043, 0.2727272727272727, 1.0, 1.0, 1.0, 0.05769648139963786, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0989904729330973, 0.09899047293309741, 0.2023919922436823], 
reward next is 0.7976, 
noisyNet noise sample is [array([1.2604173], dtype=float32), 0.6696217]. 
=============================================
[2019-03-23 02:01:40,324] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.3513493e-35 1.3209324e-33], sum to 1.0000
[2019-03-23 02:01:40,331] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7100
[2019-03-23 02:01:40,338] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.56666666666667, 74.66666666666667, 1.0, 2.0, 0.3511863345112454, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 385869.638345396, 385869.6383453963, 116323.5313904748], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5278800.0000, 
sim time next is 5279400.0000, 
raw observation next is [19.5, 75.5, 1.0, 2.0, 0.3290955144071448, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 361754.8270166305, 361754.8270166308, 114741.3072704639], 
processed observation next is [1.0, 0.08695652173913043, 0.5227272727272727, 0.755, 1.0, 1.0, 0.16136939300893097, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1339832692654187, 0.13398326926541881, 0.2798568470011315], 
reward next is 0.7201, 
noisyNet noise sample is [array([-0.10879899], dtype=float32), -0.25579333]. 
=============================================
[2019-03-23 02:01:40,596] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:01:40,604] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9703
[2019-03-23 02:01:40,608] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.66666666666667, 75.33333333333333, 1.0, 2.0, 0.4527042183877473, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 516448.8755057686, 516448.8755057689, 134977.7902678884], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5132400.0000, 
sim time next is 5133000.0000, 
raw observation next is [23.83333333333333, 74.66666666666667, 1.0, 2.0, 0.4548495096989603, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 518936.3414274746, 518936.3414274749, 135341.0234782863], 
processed observation next is [0.0, 0.391304347826087, 0.7196969696969695, 0.7466666666666667, 1.0, 1.0, 0.31856188712370037, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19219864497313874, 0.19219864497313885, 0.33010005726411296], 
reward next is 0.6699, 
noisyNet noise sample is [array([0.81751573], dtype=float32), -0.35032254]. 
=============================================
[2019-03-23 02:01:40,620] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[69.57807 ]
 [69.58972 ]
 [69.602165]
 [69.60672 ]
 [69.63694 ]], R is [[69.53614807]
 [69.51157379]
 [69.48804474]
 [69.46559906]
 [69.44428253]].
[2019-03-23 02:01:40,933] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:01:40,944] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8980
[2019-03-23 02:01:40,949] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.66666666666667, 77.0, 1.0, 2.0, 0.5006073544442183, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 570390.3987810084, 570390.3987810081, 142797.5310649717], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5138400.0000, 
sim time next is 5139000.0000, 
raw observation next is [24.5, 78.5, 1.0, 2.0, 0.5036350978861786, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 573724.5070343501, 573724.5070343501, 143266.2989881079], 
processed observation next is [0.0, 0.4782608695652174, 0.75, 0.785, 1.0, 1.0, 0.37954387235772313, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2124905581608704, 0.2124905581608704, 0.3494299975319705], 
reward next is 0.6506, 
noisyNet noise sample is [array([-0.15029164], dtype=float32), -1.7240192]. 
=============================================
[2019-03-23 02:01:40,959] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[65.09585]
 [65.11559]
 [65.18577]
 [65.25497]
 [65.3407 ]], R is [[65.07624054]
 [65.07718658]
 [65.07942963]
 [65.08344269]
 [65.0901413 ]].
[2019-03-23 02:01:50,000] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:01:50,010] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4488
[2019-03-23 02:01:50,015] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.83333333333333, 57.66666666666666, 1.0, 2.0, 0.3578244616911648, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 401744.1689370301, 401744.1689370298, 120394.6555823595], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5053800.0000, 
sim time next is 5054400.0000, 
raw observation next is [24.0, 57.0, 1.0, 2.0, 0.358925786688955, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 403172.2497921279, 403172.2497921276, 120581.977078482], 
processed observation next is [0.0, 0.5217391304347826, 0.7272727272727273, 0.57, 1.0, 1.0, 0.1986572333611937, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1493230554785659, 0.14932305547856578, 0.29410238311824877], 
reward next is 0.7059, 
noisyNet noise sample is [array([1.287404], dtype=float32), -0.6599647]. 
=============================================
[2019-03-23 02:01:56,050] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-23 02:01:56,050] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 02:01:56,051] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:01:56,054] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 02:01:56,056] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 02:01:56,056] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 02:01:56,056] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:01:56,057] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:01:56,057] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 02:01:56,057] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:01:56,059] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:01:56,093] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run83
[2019-03-23 02:01:56,093] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run83
[2019-03-23 02:01:56,150] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run83
[2019-03-23 02:01:56,179] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run83
[2019-03-23 02:01:56,200] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run83
[2019-03-23 02:02:08,276] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05752117], dtype=float32), -0.19090998]
[2019-03-23 02:02:08,279] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [28.33333333333333, 57.0, 1.0, 2.0, 0.5252185537093352, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 597977.3431802014, 597977.3431802011, 146154.1260022804]
[2019-03-23 02:02:08,279] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 02:02:08,282] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.4049563926840579
[2019-03-23 02:02:21,637] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05752117], dtype=float32), -0.19090998]
[2019-03-23 02:02:21,637] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [26.85, 60.0, 1.0, 2.0, 0.5072951522368141, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 578741.4199259569, 578741.4199259569, 146657.7115077605]
[2019-03-23 02:02:21,638] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 02:02:21,640] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 5.2095894e-38 0.0000000e+00], sampled 0.7322290318686677
[2019-03-23 02:02:59,768] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05752117], dtype=float32), -0.19090998]
[2019-03-23 02:02:59,770] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.66666666666666, 70.33333333333334, 1.0, 2.0, 0.4345773770653056, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 494856.399180078, 494856.399180078, 131606.8745002668]
[2019-03-23 02:02:59,772] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 02:02:59,774] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.8581852407627821
[2019-03-23 02:03:09,466] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05752117], dtype=float32), -0.19090998]
[2019-03-23 02:03:09,467] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.38333333333333, 75.16666666666667, 1.0, 2.0, 0.4117391895495548, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 467328.80439462, 467328.8043946197, 132316.5458993627]
[2019-03-23 02:03:09,471] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 02:03:09,474] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.20885468132083707
[2019-03-23 02:03:33,948] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05752117], dtype=float32), -0.19090998]
[2019-03-23 02:03:33,949] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.26666666666667, 80.66666666666666, 1.0, 2.0, 0.8631355976196748, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 985122.9688275835, 985122.9688275835, 197234.3229499987]
[2019-03-23 02:03:33,950] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 02:03:33,953] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.9924226e-25 9.9830235e-34], sampled 0.6792576961773936
[2019-03-23 02:03:35,530] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05752117], dtype=float32), -0.19090998]
[2019-03-23 02:03:35,532] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.869530135, 58.71771381000001, 1.0, 2.0, 0.4413433327110684, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 492143.6254812284, 492143.6254812281, 130631.7116294746]
[2019-03-23 02:03:35,532] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 02:03:35,534] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.44156845627301344
[2019-03-23 02:03:43,333] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9057.0586 1656443078.0244 80.0000
[2019-03-23 02:03:44,115] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8505.7943 1774306819.5124 173.0000
[2019-03-23 02:03:44,155] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8570.6642 1683795416.3693 214.0000
[2019-03-23 02:03:44,201] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8851.9735 1664101423.8647 105.0000
[2019-03-23 02:03:44,323] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8592.8737 1706200825.6989 465.0000
[2019-03-23 02:03:45,343] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 2050000, evaluation results [2050000.0, 8505.794325258668, 1774306819.5124316, 173.0, 9057.05855481395, 1656443078.0244372, 80.0, 8851.973532677643, 1664101423.8646872, 105.0, 8592.873732714792, 1706200825.698916, 465.0, 8570.664192729193, 1683795416.3692544, 214.0]
[2019-03-23 02:03:49,079] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.8101173e-36 1.0000000e+00 1.4729467e-36 3.0032654e-24 3.1689624e-30], sum to 1.0000
[2019-03-23 02:03:49,086] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6280
[2019-03-23 02:03:49,091] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.3810454491204145, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7712378442642568, 6.9112, 6.9112, 77.32845337660108, 868592.0169836043, 868592.0169836043, 217980.1056144846], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5228400.0000, 
sim time next is 5229000.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.6246239313976977, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846338122582, 712243.5440908142, 712243.5440908142, 158121.6466499747], 
processed observation next is [1.0, 0.5217391304347826, 0.6363636363636364, 0.94, 1.0, 1.0, 0.530779914247122, 0.0, 1.0, -0.25, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288125109362, 0.26379390521882007, 0.26379390521882007, 0.3856625528048163], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5641448], dtype=float32), -1.1450603]. 
=============================================
[2019-03-23 02:03:49,101] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[43.870777]
 [40.73999 ]
 [41.91627 ]
 [42.231106]
 [42.44585 ]], R is [[43.5515213 ]
 [43.58434677]
 [43.53032303]
 [43.60005569]
 [43.67559814]].
[2019-03-23 02:03:51,486] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:03:51,497] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7599
[2019-03-23 02:03:51,501] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.5, 92.0, 1.0, 2.0, 0.2628416733309882, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 285395.3929501424, 285395.3929501427, 90030.11328771764], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5656800.0000, 
sim time next is 5657400.0000, 
raw observation next is [15.5, 91.5, 1.0, 2.0, 0.2608668527406704, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 283250.4940246784, 283250.4940246787, 89314.66765273188], 
processed observation next is [0.0, 0.4782608695652174, 0.3409090909090909, 0.915, 1.0, 1.0, 0.07608356592583798, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10490759037951053, 0.10490759037951064, 0.21784065281154116], 
reward next is 0.7822, 
noisyNet noise sample is [array([-0.46432105], dtype=float32), -0.84328216]. 
=============================================
[2019-03-23 02:03:52,083] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:03:52,095] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7019
[2019-03-23 02:03:52,099] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.55, 67.5, 1.0, 2.0, 0.7220951068539286, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 820715.8729440436, 820715.8729440436, 164944.4124537868], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5301000.0000, 
sim time next is 5301600.0000, 
raw observation next is [23.83333333333333, 65.66666666666666, 1.0, 2.0, 0.7434285544159923, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 845077.1383972933, 845077.1383972936, 168025.0993045166], 
processed observation next is [1.0, 0.34782608695652173, 0.7196969696969695, 0.6566666666666666, 1.0, 1.0, 0.6792856930199903, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.31299153273973823, 0.3129915327397384, 0.4098173153768698], 
reward next is 0.5902, 
noisyNet noise sample is [array([0.1743647], dtype=float32), -0.25980157]. 
=============================================
[2019-03-23 02:04:00,206] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 5.060073e-28 7.820776e-26], sum to 1.0000
[2019-03-23 02:04:00,214] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0920
[2019-03-23 02:04:00,219] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [11.6, 86.0, 1.0, 2.0, 0.3852732637807905, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 418389.690119029, 418389.6901190293, 86332.38850884326], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5806800.0000, 
sim time next is 5807400.0000, 
raw observation next is [11.6, 86.0, 1.0, 2.0, 0.3878979225794706, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 421241.1879645906, 421241.1879645909, 86571.13473144796], 
processed observation next is [1.0, 0.21739130434782608, 0.1636363636363636, 0.86, 1.0, 1.0, 0.23487240322433822, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15601525480170023, 0.15601525480170034, 0.2111491091010926], 
reward next is 0.7889, 
noisyNet noise sample is [array([-0.7910472], dtype=float32), -1.978427]. 
=============================================
[2019-03-23 02:04:11,494] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.2095829e-31 2.8861944e-33], sum to 1.0000
[2019-03-23 02:04:11,503] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8139
[2019-03-23 02:04:11,507] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.2, 84.5, 1.0, 2.0, 0.4936498257474727, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 563028.7131662647, 563028.7131662644, 141250.3010830012], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6335400.0000, 
sim time next is 6336000.0000, 
raw observation next is [23.3, 84.0, 1.0, 2.0, 0.4950482300356894, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 564588.9049119042, 564588.9049119042, 141474.8090881083], 
processed observation next is [0.0, 0.34782608695652173, 0.6954545454545454, 0.84, 1.0, 1.0, 0.3688102875446117, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2091070018192238, 0.2091070018192238, 0.34506050997099585], 
reward next is 0.6549, 
noisyNet noise sample is [array([0.08126752], dtype=float32), -0.84776443]. 
=============================================
[2019-03-23 02:04:11,520] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[70.948204]
 [70.972046]
 [70.999146]
 [71.032   ]
 [71.063416]], R is [[70.90254211]
 [70.84900665]
 [70.79654694]
 [70.74514008]
 [70.69483185]].
[2019-03-23 02:04:20,196] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.8277218e-28 0.0000000e+00], sum to 1.0000
[2019-03-23 02:04:20,205] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3149
[2019-03-23 02:04:20,212] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.83333333333334, 56.0, 1.0, 2.0, 0.2450528602968915, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 266074.8873714529, 266074.8873714526, 80480.8286805382], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5772000.0000, 
sim time next is 5772600.0000, 
raw observation next is [18.0, 59.5, 1.0, 2.0, 0.2371524130926898, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 257494.4241456849, 257494.4241456849, 78563.50410578282], 
processed observation next is [0.0, 0.8260869565217391, 0.45454545454545453, 0.595, 1.0, 1.0, 0.046440516365862244, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09536830523914255, 0.09536830523914255, 0.19161830269703126], 
reward next is 0.8084, 
noisyNet noise sample is [array([2.1145475], dtype=float32), -0.2670509]. 
=============================================
[2019-03-23 02:04:20,243] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 4.827438e-34 0.000000e+00], sum to 1.0000
[2019-03-23 02:04:20,253] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4178
[2019-03-23 02:04:20,261] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.3, 78.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 185213.7737274802, 185213.7737274805, 64514.15798460694], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5795400.0000, 
sim time next is 5796000.0000, 
raw observation next is [13.3, 83.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 184432.9837621411, 184432.9837621408, 65013.88415111153], 
processed observation next is [1.0, 0.08695652173913043, 0.24090909090909093, 0.83, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.06830851250449671, 0.06830851250449659, 0.15857044914905252], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.223734], dtype=float32), -0.47173008]. 
=============================================
[2019-03-23 02:04:20,278] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[68.43511 ]
 [68.3468  ]
 [68.19922 ]
 [68.066765]
 [67.88145 ]], R is [[67.86457825]
 [67.18593597]
 [66.51407623]
 [65.84893799]
 [65.19045258]].
[2019-03-23 02:04:25,476] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.3154614e-33], sum to 1.0000
[2019-03-23 02:04:25,491] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5579
[2019-03-23 02:04:25,498] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.26666666666667, 59.66666666666667, 1.0, 2.0, 0.2828057705748392, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 307079.3980656464, 307079.3980656466, 99051.42963345133], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6119400.0000, 
sim time next is 6120000.0000, 
raw observation next is [20.0, 61.0, 1.0, 2.0, 0.2836669297831858, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 308014.7679305127, 308014.7679305124, 98374.88421792857], 
processed observation next is [1.0, 0.8695652173913043, 0.5454545454545454, 0.61, 1.0, 1.0, 0.10458366222898224, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11407954367796767, 0.11407954367796755, 0.23993874199494775], 
reward next is 0.7601, 
noisyNet noise sample is [array([0.41316062], dtype=float32), -0.094389595]. 
=============================================
[2019-03-23 02:04:25,507] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[71.77869 ]
 [71.71316 ]
 [71.614944]
 [71.50137 ]
 [71.459496]], R is [[71.95793152]
 [71.99675751]
 [72.03304291]
 [72.06684875]
 [72.09820557]].
[2019-03-23 02:04:25,782] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 7.1838985e-33 4.6751714e-32 7.0700945e-33], sum to 1.0000
[2019-03-23 02:04:25,791] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9774
[2019-03-23 02:04:25,797] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.58333333333334, 80.5, 1.0, 2.0, 0.3547950071885356, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 394796.4605603834, 394796.4605603834, 118525.8086998529], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5968200.0000, 
sim time next is 5968800.0000, 
raw observation next is [19.4, 81.0, 1.0, 2.0, 0.352933497422476, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 392063.3976198098, 392063.3976198095, 118101.8463815468], 
processed observation next is [1.0, 0.08695652173913043, 0.5181818181818181, 0.81, 1.0, 1.0, 0.19116687177809497, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14520866578511474, 0.14520866578511463, 0.28805328385743123], 
reward next is 0.7119, 
noisyNet noise sample is [array([1.2970548], dtype=float32), -1.3028501]. 
=============================================
[2019-03-23 02:04:26,166] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.3261564e-38 0.0000000e+00], sum to 1.0000
[2019-03-23 02:04:26,174] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5186
[2019-03-23 02:04:26,178] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.2, 78.33333333333333, 1.0, 2.0, 0.2528572661735423, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 274551.1913258678, 274551.1913258681, 90238.10431588006], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5899200.0000, 
sim time next is 5899800.0000, 
raw observation next is [17.2, 79.16666666666667, 1.0, 2.0, 0.2560245266796244, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 277991.1702387239, 277991.1702387236, 91650.90898412724], 
processed observation next is [1.0, 0.2608695652173913, 0.41818181818181815, 0.7916666666666667, 1.0, 1.0, 0.07003065834953047, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10295969268100887, 0.10295969268100873, 0.22353880240031032], 
reward next is 0.7765, 
noisyNet noise sample is [array([0.57743853], dtype=float32), -0.52647084]. 
=============================================
[2019-03-23 02:04:30,181] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.3532616e-36 5.1313477e-30 3.0775695e-33], sum to 1.0000
[2019-03-23 02:04:30,190] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3471
[2019-03-23 02:04:30,197] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.1, 68.0, 1.0, 2.0, 0.3751035554026867, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 421227.1094723956, 421227.1094723956, 121890.0317155419], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5958600.0000, 
sim time next is 5959200.0000, 
raw observation next is [22.0, 68.0, 1.0, 2.0, 0.3715076312899734, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 416745.0249109081, 416745.0249109078, 121367.3092074317], 
processed observation next is [1.0, 1.0, 0.6363636363636364, 0.68, 1.0, 1.0, 0.21438453911246672, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15435000922626224, 0.15435000922626213, 0.29601782733519927], 
reward next is 0.7040, 
noisyNet noise sample is [array([1.0631742], dtype=float32), -0.43023628]. 
=============================================
[2019-03-23 02:04:30,409] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 5.4419809e-34 2.2465492e-14 3.1835991e-30], sum to 1.0000
[2019-03-23 02:04:30,416] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8882
[2019-03-23 02:04:30,424] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.46666666666667, 53.83333333333334, 1.0, 2.0, 0.4337723101085561, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 471083.0211377472, 471083.0211377474, 117504.0605475453], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6091800.0000, 
sim time next is 6092400.0000, 
raw observation next is [21.83333333333334, 52.66666666666667, 1.0, 2.0, 0.3863723290621073, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 419583.7413007013, 419583.7413007013, 115026.8059685847], 
processed observation next is [1.0, 0.5217391304347826, 0.628787878787879, 0.5266666666666667, 1.0, 1.0, 0.23296541132763407, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1554013856669264, 0.1554013856669264, 0.28055318528923096], 
reward next is 0.7194, 
noisyNet noise sample is [array([1.2435496], dtype=float32), -0.36330658]. 
=============================================
[2019-03-23 02:04:30,560] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.5954824e-38 1.0000000e+00 2.6372788e-26 6.4850894e-25 1.2378832e-28], sum to 1.0000
[2019-03-23 02:04:30,569] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0944
[2019-03-23 02:04:30,576] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.9, 86.0, 1.0, 2.0, 0.3596648097439566, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 400047.4688087259, 400047.4688087259, 118845.3233514278], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5971800.0000, 
sim time next is 5972400.0000, 
raw observation next is [18.8, 87.0, 1.0, 2.0, 0.3623252315029062, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 403125.8987719535, 403125.8987719535, 119108.6854888294], 
processed observation next is [1.0, 0.13043478260869565, 0.49090909090909096, 0.87, 1.0, 1.0, 0.2029065393786327, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14930588843405684, 0.14930588843405684, 0.2905089889971449], 
reward next is 0.7095, 
noisyNet noise sample is [array([-0.85502064], dtype=float32), 0.9521238]. 
=============================================
[2019-03-23 02:04:32,633] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.0000000e+00 8.9694094e-03 3.5026847e-36 9.9860058e-25 9.9103057e-01], sum to 1.0000
[2019-03-23 02:04:32,639] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6124
[2019-03-23 02:04:32,644] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [19.9, 58.16666666666666, 1.0, 2.0, 0.5324297777200446, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 578290.1935460706, 578290.1935460706, 119568.9694382348], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6087000.0000, 
sim time next is 6087600.0000, 
raw observation next is [20.0, 58.0, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 1.0, 0.3462545618590704, 6.9112, 6.9112, 77.3421103, 604013.0577991852, 604013.0577991852, 195735.2724925957], 
processed observation next is [1.0, 0.4782608695652174, 0.5454545454545454, 0.58, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 0.5, 0.06607794551295772, 0.0, 0.0, 0.5085185399722538, 0.22370853992562414, 0.22370853992562414, 0.4774031036404773], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.0021989], dtype=float32), -0.50051004]. 
=============================================
[2019-03-23 02:04:38,102] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-23 02:04:38,105] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 02:04:38,106] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:04:38,106] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 02:04:38,106] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:04:38,107] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 02:04:38,108] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 02:04:38,109] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:04:38,110] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:04:38,111] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 02:04:38,113] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:04:38,131] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run84
[2019-03-23 02:04:38,157] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run84
[2019-03-23 02:04:38,184] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run84
[2019-03-23 02:04:38,184] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run84
[2019-03-23 02:04:38,229] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run84
[2019-03-23 02:05:35,516] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.0110049], dtype=float32), -0.18507957]
[2019-03-23 02:05:35,519] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.0, 100.0, 1.0, 2.0, 0.3801155654502506, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 426827.45278115, 426827.45278115, 122306.0024549569]
[2019-03-23 02:05:35,523] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 02:05:35,525] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 9.624772e-36 0.000000e+00], sampled 0.39256753592169624
[2019-03-23 02:06:03,026] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.0110049], dtype=float32), -0.18507957]
[2019-03-23 02:06:03,028] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.6, 87.0, 1.0, 2.0, 0.4078417811608065, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 462317.3976525136, 462317.3976525136, 131521.3366106261]
[2019-03-23 02:06:03,032] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 02:06:03,034] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.3666624e-35 0.0000000e+00], sampled 0.37733219195468226
[2019-03-23 02:06:25,126] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8504.9281 1774921464.2614 169.0000
[2019-03-23 02:06:25,931] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8570.4871 1683868018.2663 214.0000
[2019-03-23 02:06:25,948] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8852.6925 1664051680.8275 105.0000
[2019-03-23 02:06:25,985] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8592.8737 1706200825.6989 465.0000
[2019-03-23 02:06:26,021] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9057.0586 1656443078.0244 80.0000
[2019-03-23 02:06:27,040] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 2075000, evaluation results [2075000.0, 8504.928136538345, 1774921464.261403, 169.0, 9057.05855481395, 1656443078.0244372, 80.0, 8852.692524936243, 1664051680.8275282, 105.0, 8592.873732714792, 1706200825.698916, 465.0, 8570.487114931439, 1683868018.266335, 214.0]
[2019-03-23 02:06:30,944] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:06:30,949] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0632
[2019-03-23 02:06:30,954] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.71666666666667, 49.66666666666667, 1.0, 2.0, 0.4706604612713234, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 537057.7487299328, 537057.7487299332, 137716.7907356203], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6880200.0000, 
sim time next is 6880800.0000, 
raw observation next is [28.63333333333334, 49.33333333333334, 1.0, 2.0, 0.467656869017568, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 533623.5570606516, 533623.5570606516, 137114.6923767912], 
processed observation next is [0.0, 0.6521739130434783, 0.9378787878787882, 0.4933333333333334, 1.0, 1.0, 0.3345710862719599, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.197638354466908, 0.197638354466908, 0.3344260789677834], 
reward next is 0.6656, 
noisyNet noise sample is [array([-0.12789577], dtype=float32), 0.28946728]. 
=============================================
[2019-03-23 02:06:41,727] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.2953127e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 02:06:41,734] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6832
[2019-03-23 02:06:41,743] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.3, 61.0, 1.0, 2.0, 0.550748862446027, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 624818.803120832, 624818.803120832, 150558.7741364893], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6366000.0000, 
sim time next is 6366600.0000, 
raw observation next is [28.3, 61.0, 1.0, 2.0, 0.5507339376808824, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 624802.3237914469, 624802.3237914469, 150556.6629894989], 
processed observation next is [0.0, 0.6956521739130435, 0.9227272727272727, 0.61, 1.0, 1.0, 0.43841742210110296, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23140826807090625, 0.23140826807090625, 0.36721137314511926], 
reward next is 0.6328, 
noisyNet noise sample is [array([0.29412255], dtype=float32), 0.07641204]. 
=============================================
[2019-03-23 02:06:42,239] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:06:42,247] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5826
[2019-03-23 02:06:42,253] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.7, 65.0, 1.0, 2.0, 0.5576137208325436, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 631984.5756895146, 631984.575689515, 151691.5546650293], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6360000.0000, 
sim time next is 6360600.0000, 
raw observation next is [27.7, 65.0, 1.0, 2.0, 0.5580371698854613, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 632464.107441291, 632464.107441291, 151746.9250371252], 
processed observation next is [0.0, 0.6086956521739131, 0.8954545454545454, 0.65, 1.0, 1.0, 0.44754646235682655, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23424596571899667, 0.23424596571899667, 0.3701144513100615], 
reward next is 0.6299, 
noisyNet noise sample is [array([0.04816652], dtype=float32), -1.2739582]. 
=============================================
[2019-03-23 02:06:46,104] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:06:46,116] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9035
[2019-03-23 02:06:46,121] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.55, 73.5, 1.0, 2.0, 0.2212477579699014, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 240221.2650659254, 240221.2650659257, 75091.99090866101], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6564600.0000, 
sim time next is 6565200.0000, 
raw observation next is [15.73333333333333, 71.33333333333334, 1.0, 2.0, 0.2209148259834172, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 239859.6927546169, 239859.6927546166, 74854.59716863553], 
processed observation next is [1.0, 1.0, 0.3515151515151514, 0.7133333333333334, 1.0, 1.0, 0.026143532479271474, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08883692324245071, 0.0888369232424506, 0.18257218821618423], 
reward next is 0.8174, 
noisyNet noise sample is [array([1.3284545], dtype=float32), 0.5032075]. 
=============================================
[2019-03-23 02:06:49,981] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:06:49,988] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4942
[2019-03-23 02:06:49,994] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.6, 72.5, 1.0, 2.0, 0.3603728374510388, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 391338.0487111797, 391338.04871118, 92570.44622069082], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6510600.0000, 
sim time next is 6511200.0000, 
raw observation next is [16.96666666666667, 70.66666666666667, 1.0, 2.0, 0.3916366111871885, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 425303.0257581176, 425303.0257581176, 96731.35195920947], 
processed observation next is [1.0, 0.34782608695652173, 0.40757575757575765, 0.7066666666666667, 1.0, 1.0, 0.2395457639839856, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15751963916967318, 0.15751963916967318, 0.2359301267297792], 
reward next is 0.7641, 
noisyNet noise sample is [array([0.526561], dtype=float32), 0.31873772]. 
=============================================
[2019-03-23 02:06:54,094] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 3.847046e-37 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 02:06:54,104] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4041
[2019-03-23 02:06:54,107] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [11.1, 98.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 192624.6223040046, 192624.6223040048, 65488.42458668137], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6585600.0000, 
sim time next is 6586200.0000, 
raw observation next is [11.1, 98.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 188701.7871798289, 188701.7871798292, 64729.31080405162], 
processed observation next is [1.0, 0.21739130434782608, 0.1409090909090909, 0.98, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.06988955080734405, 0.06988955080734414, 0.15787636781476005], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.5472747], dtype=float32), 1.7927377]. 
=============================================
[2019-03-23 02:06:58,587] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:06:58,597] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2119
[2019-03-23 02:06:58,603] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.63333333333334, 99.83333333333334, 1.0, 2.0, 0.3300317147366758, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 362843.9129182367, 362843.912918237, 114832.0500990251], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7451400.0000, 
sim time next is 7452000.0000, 
raw observation next is [16.6, 100.0, 1.0, 2.0, 0.329319345447383, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 361952.8589658532, 361952.8589658529, 114739.6747467332], 
processed observation next is [0.0, 0.2608695652173913, 0.390909090909091, 1.0, 1.0, 1.0, 0.16164918180922874, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13405661443179748, 0.13405661443179737, 0.27985286523593467], 
reward next is 0.7201, 
noisyNet noise sample is [array([0.45933107], dtype=float32), 1.2770275]. 
=============================================
[2019-03-23 02:06:58,615] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[68.54206 ]
 [68.550026]
 [68.562546]
 [68.56222 ]
 [68.55801 ]], R is [[68.61654663]
 [68.6503067 ]
 [68.68351746]
 [68.71620941]
 [68.74838257]].
[2019-03-23 02:07:00,218] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.2087545e-36 2.1914456e-37], sum to 1.0000
[2019-03-23 02:07:00,223] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5685
[2019-03-23 02:07:00,228] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.55, 90.0, 1.0, 2.0, 0.5428086919597414, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 605815.7290868693, 605815.7290868693, 136414.6589517729], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6690600.0000, 
sim time next is 6691200.0000, 
raw observation next is [18.46666666666667, 91.0, 1.0, 2.0, 0.5379200566376311, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 600585.8079747509, 600585.8079747509, 135998.7360822183], 
processed observation next is [1.0, 0.43478260869565216, 0.4757575757575758, 0.91, 1.0, 1.0, 0.42240007079703884, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22243918813879662, 0.22243918813879662, 0.3317042343468739], 
reward next is 0.6683, 
noisyNet noise sample is [array([0.18028569], dtype=float32), 0.39439824]. 
=============================================
[2019-03-23 02:07:03,712] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 2.1242698e-25], sum to 1.0000
[2019-03-23 02:07:03,718] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9597
[2019-03-23 02:07:03,727] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.3, 50.0, 1.0, 2.0, 0.7656234536120866, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 853108.3092672937, 853108.3092672937, 162186.951144431], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7138200.0000, 
sim time next is 7138800.0000, 
raw observation next is [24.4, 50.0, 1.0, 2.0, 0.7737794143754546, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 863219.1372101465, 863219.1372101465, 163677.8057800448], 
processed observation next is [1.0, 0.6521739130434783, 0.7454545454545454, 0.5, 1.0, 1.0, 0.7172242679693183, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.31971079155931353, 0.31971079155931353, 0.3992141604391336], 
reward next is 0.6008, 
noisyNet noise sample is [array([-1.2217171], dtype=float32), -0.4134526]. 
=============================================
[2019-03-23 02:07:03,882] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:07:03,891] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3657
[2019-03-23 02:07:03,895] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.1, 90.0, 1.0, 2.0, 0.4412814556317425, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 502743.9426457905, 502743.9426457905, 132585.0219383198], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7545600.0000, 
sim time next is 7546200.0000, 
raw observation next is [21.28333333333333, 89.0, 1.0, 2.0, 0.4445732648540986, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 506596.9856327844, 506596.9856327844, 133055.2688972402], 
processed observation next is [0.0, 0.34782608695652173, 0.6037878787878787, 0.89, 1.0, 1.0, 0.3057165810676232, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18762851319732754, 0.18762851319732754, 0.32452504609082977], 
reward next is 0.6755, 
noisyNet noise sample is [array([2.2269406], dtype=float32), -2.1366022]. 
=============================================
[2019-03-23 02:07:07,597] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 6.6918106e-34 8.1533082e-36 1.8556576e-10], sum to 1.0000
[2019-03-23 02:07:07,609] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9747
[2019-03-23 02:07:07,615] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 93.5, 1.0, 2.0, 0.4369211946231585, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 496259.2049109844, 496259.2049109844, 130685.3644722929], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7613400.0000, 
sim time next is 7614000.0000, 
raw observation next is [20.0, 93.0, 1.0, 2.0, 0.4314909224533996, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 489901.6078623427, 489901.6078623427, 130002.1359837301], 
processed observation next is [1.0, 0.13043478260869565, 0.5454545454545454, 0.93, 1.0, 1.0, 0.28936365306674944, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1814450399490158, 0.1814450399490158, 0.3170783804481222], 
reward next is 0.6829, 
noisyNet noise sample is [array([1.004084], dtype=float32), 1.1627903]. 
=============================================
[2019-03-23 02:07:07,624] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[64.892395]
 [64.881454]
 [64.9747  ]
 [64.99159 ]
 [64.785355]], R is [[64.97265625]
 [65.00418091]
 [65.03384399]
 [65.06071472]
 [65.07366943]].
[2019-03-23 02:07:09,137] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:07:09,146] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3793
[2019-03-23 02:07:09,151] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.56666666666666, 75.0, 1.0, 2.0, 0.4909018683057132, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 559904.7248373723, 559904.7248373723, 140910.5050935908], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7553400.0000, 
sim time next is 7554000.0000, 
raw observation next is [24.73333333333333, 74.0, 1.0, 2.0, 0.4924682440582578, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 561676.6034162235, 561676.6034162235, 141120.0696702226], 
processed observation next is [0.0, 0.43478260869565216, 0.7606060606060605, 0.74, 1.0, 1.0, 0.3655853050728222, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20802837163563834, 0.20802837163563834, 0.3441952918785917], 
reward next is 0.6558, 
noisyNet noise sample is [array([0.6429347], dtype=float32), 0.1262532]. 
=============================================
[2019-03-23 02:07:09,171] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[66.711006]
 [66.73475 ]
 [66.75095 ]
 [66.81465 ]
 [66.881096]], R is [[66.7170639 ]
 [66.7062149 ]
 [66.69664001]
 [66.68973541]
 [66.68554688]].
[2019-03-23 02:07:17,814] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:07:17,823] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2408
[2019-03-23 02:07:17,828] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 75.33333333333333, 1.0, 2.0, 0.4806731770994638, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 548491.4040324783, 548491.4040324786, 138775.5500872448], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6990000.0000, 
sim time next is 6990600.0000, 
raw observation next is [23.9, 75.66666666666667, 1.0, 2.0, 0.4776421267146755, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 545030.2689421668, 545030.2689421668, 138335.1892263741], 
processed observation next is [0.0, 0.9130434782608695, 0.7227272727272727, 0.7566666666666667, 1.0, 1.0, 0.3470526583933443, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2018630625711729, 0.2018630625711729, 0.3374029005521319], 
reward next is 0.6626, 
noisyNet noise sample is [array([0.7350514], dtype=float32), 1.5228324]. 
=============================================
[2019-03-23 02:07:19,779] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-23 02:07:19,784] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 02:07:19,785] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 02:07:19,785] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:07:19,786] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:07:19,786] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 02:07:19,788] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 02:07:19,788] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:07:19,790] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:07:19,789] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 02:07:19,795] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:07:19,819] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run85
[2019-03-23 02:07:19,845] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run85
[2019-03-23 02:07:19,882] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run85
[2019-03-23 02:07:19,905] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run85
[2019-03-23 02:07:19,905] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run85
[2019-03-23 02:07:38,946] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06496572], dtype=float32), -0.17767759]
[2019-03-23 02:07:38,949] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.88333333333333, 77.83333333333333, 1.0, 2.0, 0.6226303454722086, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 702828.4099945517, 702828.4099945517, 153120.6446984835]
[2019-03-23 02:07:38,949] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 02:07:38,953] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 9.5805411e-32 1.7176388e-38], sampled 0.10678904164359349
[2019-03-23 02:07:42,729] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06496572], dtype=float32), -0.17767759]
[2019-03-23 02:07:42,731] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.33333333333334, 86.33333333333334, 1.0, 2.0, 0.3335076661959157, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 368084.0743721686, 368084.0743721683, 115625.4424848632]
[2019-03-23 02:07:42,733] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 02:07:42,737] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.6929896449062272
[2019-03-23 02:08:07,808] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06496572], dtype=float32), -0.17767759]
[2019-03-23 02:08:07,810] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.93333333333334, 81.83333333333334, 1.0, 2.0, 0.7096675408008085, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769669352, 809868.6666562272, 809868.6666562272, 172860.6145236564]
[2019-03-23 02:08:07,811] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 02:08:07,815] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.3681097e-31 1.0318087e-33], sampled 0.009024494549480178
[2019-03-23 02:08:08,778] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06496572], dtype=float32), -0.17767759]
[2019-03-23 02:08:08,780] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [27.404235095, 84.129313525, 1.0, 2.0, 0.8271141894030414, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9865530188920543, 6.9112, 6.9112, 95.55301014370616, 1478107.372448004, 1478107.372448004, 325052.7211859424]
[2019-03-23 02:08:08,783] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 02:08:08,786] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.6867331e-32 1.0000000e+00 4.1077287e-34 3.8014596e-21 8.9402473e-15], sampled 0.9697420762662371
[2019-03-23 02:08:08,787] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1478107.372448004 W.
[2019-03-23 02:08:37,165] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06496572], dtype=float32), -0.17767759]
[2019-03-23 02:08:37,167] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.5, 44.0, 1.0, 2.0, 0.2481008994947948, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 269385.3212347721, 269385.3212347718, 79404.5279016167]
[2019-03-23 02:08:37,167] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 02:08:37,170] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.5566668879313252
[2019-03-23 02:08:51,501] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06496572], dtype=float32), -0.17767759]
[2019-03-23 02:08:51,502] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [25.08333333333334, 61.66666666666667, 1.0, 2.0, 0.462046892575826, 0.0, 2.0, 0.0, 1.0, 2.0, 0.923084316754405, 6.920493919807314, 6.9112, 77.32844112272508, 1054422.590344173, 1051404.116155572, 241894.5029169875]
[2019-03-23 02:08:51,504] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 02:08:51,508] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.3733068e-36 1.0000000e+00 2.0818275e-37 4.4997060e-32 5.0047472e-13], sampled 0.2687783312295876
[2019-03-23 02:09:02,091] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06496572], dtype=float32), -0.17767759]
[2019-03-23 02:09:02,093] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [26.83333333333334, 61.33333333333334, 1.0, 2.0, 0.4914560569397285, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 560587.5949878696, 560587.5949878696, 140876.0201892967]
[2019-03-23 02:09:02,094] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 02:09:02,097] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.17410763097408277
[2019-03-23 02:09:05,074] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06496572], dtype=float32), -0.17767759]
[2019-03-23 02:09:05,078] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.60430244166667, 58.83426463333333, 1.0, 2.0, 0.2982642872431706, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 324708.9048454143, 324708.9048454143, 115687.8692220874]
[2019-03-23 02:09:05,079] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 02:09:05,083] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.4245750043865193
[2019-03-23 02:09:07,385] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8492.7742 1779211600.8441 164.0000
[2019-03-23 02:09:07,569] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.8424 1684365443.3071 193.0000
[2019-03-23 02:09:07,731] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8592.1364 1706815809.2630 457.0000
[2019-03-23 02:09:07,746] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8851.9735 1664101423.8647 105.0000
[2019-03-23 02:09:07,764] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9056.2452 1656484552.8426 80.0000
[2019-03-23 02:09:08,779] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 2100000, evaluation results [2100000.0, 8492.774212199252, 1779211600.8441067, 164.0, 9056.245151782041, 1656484552.8426478, 80.0, 8851.973532677643, 1664101423.8646872, 105.0, 8592.13637385026, 1706815809.2630136, 457.0, 8574.842443485108, 1684365443.3071172, 193.0]
[2019-03-23 02:09:12,273] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:09:12,279] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6628
[2019-03-23 02:09:12,284] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 87.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 206080.083326981, 206080.083326981, 68938.28872840705], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7183800.0000, 
sim time next is 7184400.0000, 
raw observation next is [12.9, 87.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 204911.6564267337, 204911.6564267337, 68591.52985302525], 
processed observation next is [1.0, 0.13043478260869565, 0.22272727272727275, 0.8766666666666667, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.07589320608397544, 0.07589320608397544, 0.16729641427567132], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.92835414], dtype=float32), -0.3767058]. 
=============================================
[2019-03-23 02:09:16,451] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 02:09:16,452] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:09:16,530] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run11
[2019-03-23 02:09:18,205] A3C_AGENT_WORKER-Thread-21 INFO:Local step 132500, global step 2104610: loss 46.1835
[2019-03-23 02:09:18,207] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 132500, global step 2104611: learning rate 0.0010
[2019-03-23 02:09:18,896] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.0011618e-27], sum to 1.0000
[2019-03-23 02:09:18,903] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6510
[2019-03-23 02:09:18,907] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.9, 43.33333333333334, 1.0, 2.0, 0.7850076798930545, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 853624.2656079446, 853624.2656079449, 157368.6043812418], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7225800.0000, 
sim time next is 7226400.0000, 
raw observation next is [24.0, 43.66666666666667, 1.0, 2.0, 0.7900278830005295, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 861457.7595928891, 861457.7595928891, 158733.883059541], 
processed observation next is [1.0, 0.6521739130434783, 0.7272727272727273, 0.4366666666666667, 1.0, 1.0, 0.7375348537506617, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3190584294788478, 0.3190584294788478, 0.3871558123403439], 
reward next is 0.6128, 
noisyNet noise sample is [array([-1.5482846], dtype=float32), 1.889732]. 
=============================================
[2019-03-23 02:09:21,128] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 02:09:21,130] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:09:21,194] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run11
[2019-03-23 02:09:22,849] A3C_AGENT_WORKER-Thread-3 INFO:Local step 132500, global step 2106909: loss 15.0365
[2019-03-23 02:09:22,855] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 132500, global step 2106910: learning rate 0.0010
[2019-03-23 02:09:25,061] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:09:25,072] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8476
[2019-03-23 02:09:25,079] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.81666666666667, 84.5, 1.0, 2.0, 0.3939581267136576, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 446243.9436637323, 446243.943663732, 125666.459660997], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7462200.0000, 
sim time next is 7462800.0000, 
raw observation next is [21.1, 84.0, 1.0, 2.0, 0.4012274178863636, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 455189.7414357798, 455189.7414357798, 126829.4440743815], 
processed observation next is [0.0, 0.391304347826087, 0.5954545454545456, 0.84, 1.0, 1.0, 0.2515342723579545, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1685887931243629, 0.1685887931243629, 0.3093401074984915], 
reward next is 0.6907, 
noisyNet noise sample is [array([1.2331184], dtype=float32), 0.120604575]. 
=============================================
[2019-03-23 02:09:25,859] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:09:25,862] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3060
[2019-03-23 02:09:25,866] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.1, 85.0, 1.0, 2.0, 0.3196814323099778, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 350125.8632674406, 350125.8632674408, 113583.9485151955], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7368000.0000, 
sim time next is 7368600.0000, 
raw observation next is [18.2, 84.5, 1.0, 2.0, 0.3196888317189689, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 350388.1625966338, 350388.1625966335, 113677.3965012828], 
processed observation next is [1.0, 0.2608695652173913, 0.4636363636363636, 0.845, 1.0, 1.0, 0.14961103964871109, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1297733935543088, 0.1297733935543087, 0.2772619426860556], 
reward next is 0.7227, 
noisyNet noise sample is [array([-1.0144212], dtype=float32), 1.0295115]. 
=============================================
[2019-03-23 02:09:29,311] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:09:29,322] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3594
[2019-03-23 02:09:29,326] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.96666666666667, 71.33333333333334, 1.0, 2.0, 0.5826681180546882, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 639732.2160846526, 639732.2160846523, 136840.8706747672], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7809600.0000, 
sim time next is 7810200.0000, 
raw observation next is [20.25, 73.0, 1.0, 2.0, 0.610413784958852, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 675833.0888972767, 675833.0888972764, 141677.9960632497], 
processed observation next is [1.0, 0.391304347826087, 0.5568181818181818, 0.73, 1.0, 1.0, 0.513017231198565, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2503085514434358, 0.2503085514434357, 0.3455560879591456], 
reward next is 0.6544, 
noisyNet noise sample is [array([-1.1224539], dtype=float32), -0.20106307]. 
=============================================
[2019-03-23 02:09:34,571] A3C_AGENT_WORKER-Thread-21 INFO:Local step 133000, global step 2112461: loss 0.3613
[2019-03-23 02:09:34,573] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 133000, global step 2112462: learning rate 0.0010
[2019-03-23 02:09:38,050] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 02:09:38,051] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:09:38,130] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run11
[2019-03-23 02:09:38,368] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 02:09:38,369] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:09:38,431] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run11
[2019-03-23 02:09:39,069] A3C_AGENT_WORKER-Thread-3 INFO:Local step 133000, global step 2114692: loss 0.2002
[2019-03-23 02:09:39,074] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 133000, global step 2114692: learning rate 0.0010
[2019-03-23 02:09:39,703] A3C_AGENT_WORKER-Thread-14 INFO:Local step 132500, global step 2115076: loss 1.8389
[2019-03-23 02:09:39,707] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 132500, global step 2115078: learning rate 0.0010
[2019-03-23 02:09:40,119] A3C_AGENT_WORKER-Thread-9 INFO:Local step 132500, global step 2115279: loss 5.4086
[2019-03-23 02:09:40,122] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 132500, global step 2115280: learning rate 0.0010
[2019-03-23 02:09:45,584] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 02:09:45,584] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:09:45,662] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run11
[2019-03-23 02:09:45,926] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.7972823e-30 0.0000000e+00], sum to 1.0000
[2019-03-23 02:09:45,932] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7974
[2019-03-23 02:09:45,938] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.95, 66.5, 1.0, 2.0, 0.5475161670008617, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 595099.3198206959, 595099.3198206959, 131393.5426241035], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7723800.0000, 
sim time next is 7724400.0000, 
raw observation next is [20.13333333333333, 65.33333333333334, 1.0, 2.0, 0.5594240135116971, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 608214.76476617, 608214.7647661702, 132588.9090986034], 
processed observation next is [1.0, 0.391304347826087, 0.5515151515151513, 0.6533333333333334, 1.0, 1.0, 0.4492800168896214, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22526472769117406, 0.22526472769117414, 0.3233875831673254], 
reward next is 0.6766, 
noisyNet noise sample is [array([-0.65829253], dtype=float32), 0.45566127]. 
=============================================
[2019-03-23 02:09:47,360] A3C_AGENT_WORKER-Thread-2 INFO:Local step 132500, global step 2118845: loss 20.1399
[2019-03-23 02:09:47,366] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 132500, global step 2118845: learning rate 0.0010
[2019-03-23 02:09:48,098] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:09:48,108] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6261
[2019-03-23 02:09:48,112] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.33333333333333, 69.0, 1.0, 2.0, 0.2373309832978029, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 257688.3627707408, 257688.3627707406, 77420.80611241696], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 164400.0000, 
sim time next is 165000.0000, 
raw observation next is [16.16666666666667, 70.5, 1.0, 2.0, 0.2346356853069102, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 254761.1055761044, 254761.1055761044, 77207.12887866379], 
processed observation next is [1.0, 0.9130434782608695, 0.37121212121212144, 0.705, 1.0, 1.0, 0.04329460663363774, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09435596502818681, 0.09435596502818681, 0.18831007043576534], 
reward next is 0.8117, 
noisyNet noise sample is [array([0.6992246], dtype=float32), 0.398914]. 
=============================================
[2019-03-23 02:09:48,118] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[78.54469]
 [78.61824]
 [78.67288]
 [78.72336]
 [78.79745]], R is [[78.48996735]
 [78.51624298]
 [78.54161835]
 [78.56590271]
 [78.58930206]].
[2019-03-23 02:09:50,127] A3C_AGENT_WORKER-Thread-21 INFO:Local step 133500, global step 2120157: loss 0.0062
[2019-03-23 02:09:50,129] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 133500, global step 2120157: learning rate 0.0010
[2019-03-23 02:09:52,205] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 02:09:52,206] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:09:52,284] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run11
[2019-03-23 02:09:52,597] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:09:52,603] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7837
[2019-03-23 02:09:52,606] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.6, 92.5, 1.0, 2.0, 0.4387588522428555, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 499552.8038654413, 499552.8038654413, 131958.4043786648], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7937400.0000, 
sim time next is 7938000.0000, 
raw observation next is [20.5, 93.0, 1.0, 2.0, 0.4368189391882642, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 497258.0398148531, 497258.0398148534, 131670.6961988264], 
processed observation next is [1.0, 0.9130434782608695, 0.5681818181818182, 0.93, 1.0, 1.0, 0.2960236739853302, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18416964437587152, 0.18416964437587163, 0.3211480395093327], 
reward next is 0.6789, 
noisyNet noise sample is [array([0.33211425], dtype=float32), 0.061981432]. 
=============================================
[2019-03-23 02:09:52,614] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[65.80068]
 [65.7752 ]
 [65.75386]
 [65.73407]
 [65.74463]], R is [[65.88593292]
 [65.90522766]
 [65.92360687]
 [65.94107819]
 [65.95764923]].
[2019-03-23 02:09:53,941] A3C_AGENT_WORKER-Thread-15 INFO:Local step 132500, global step 2122100: loss 9.9612
[2019-03-23 02:09:53,944] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 132500, global step 2122100: learning rate 0.0010
[2019-03-23 02:09:54,097] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 02:09:54,099] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:09:54,190] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run11
[2019-03-23 02:09:54,588] A3C_AGENT_WORKER-Thread-3 INFO:Local step 133500, global step 2122428: loss 0.0062
[2019-03-23 02:09:54,591] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 133500, global step 2122430: learning rate 0.0010
[2019-03-23 02:09:55,207] A3C_AGENT_WORKER-Thread-14 INFO:Local step 133000, global step 2122804: loss 0.2790
[2019-03-23 02:09:55,209] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 133000, global step 2122807: learning rate 0.0010
[2019-03-23 02:09:55,392] A3C_AGENT_WORKER-Thread-9 INFO:Local step 133000, global step 2122908: loss 0.2605
[2019-03-23 02:09:55,394] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 133000, global step 2122909: learning rate 0.0010
[2019-03-23 02:09:55,832] A3C_AGENT_WORKER-Thread-20 INFO:Local step 132500, global step 2123130: loss 2.4536
[2019-03-23 02:09:55,837] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 132500, global step 2123131: learning rate 0.0010
[2019-03-23 02:09:57,504] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 02:09:57,505] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:09:57,534] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 02:09:57,534] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:09:57,581] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run11
[2019-03-23 02:09:57,607] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 02:09:57,608] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:09:57,646] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run11
[2019-03-23 02:09:57,696] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run11
[2019-03-23 02:09:57,767] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 02:09:57,768] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:09:57,769] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 02:09:57,769] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:09:57,800] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run11
[2019-03-23 02:09:57,844] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run11
[2019-03-23 02:09:57,946] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 02:09:57,947] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:09:57,976] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run11
[2019-03-23 02:09:58,013] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 02:09:58,014] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:09:58,033] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run11
[2019-03-23 02:09:58,091] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 02:09:58,092] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:09:58,110] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run11
[2019-03-23 02:09:58,277] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 02:09:58,277] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:09:58,286] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run11
[2019-03-23 02:09:59,224] A3C_AGENT_WORKER-Thread-19 INFO:Local step 132500, global step 2124735: loss 4.8943
[2019-03-23 02:09:59,225] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 132500, global step 2124735: learning rate 0.0010
[2019-03-23 02:09:59,291] A3C_AGENT_WORKER-Thread-17 INFO:Local step 132500, global step 2124782: loss 14.2327
[2019-03-23 02:09:59,294] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 132500, global step 2124783: learning rate 0.0010
[2019-03-23 02:09:59,310] A3C_AGENT_WORKER-Thread-18 INFO:Local step 132500, global step 2124792: loss 3.4325
[2019-03-23 02:09:59,311] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 132500, global step 2124792: learning rate 0.0010
[2019-03-23 02:09:59,451] A3C_AGENT_WORKER-Thread-10 INFO:Local step 132500, global step 2124895: loss 0.6594
[2019-03-23 02:09:59,454] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 132500, global step 2124896: learning rate 0.0010
[2019-03-23 02:09:59,559] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.05586055e-29 1.00000000e+00 9.91191993e-25 6.20286446e-32
 1.56245898e-18], sum to 1.0000
[2019-03-23 02:09:59,567] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6950
[2019-03-23 02:09:59,570] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.33333333333334, 81.0, 1.0, 2.0, 0.2743107583733875, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 297852.4220112503, 297852.4220112506, 96839.78976986863], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2400.0000, 
sim time next is 3000.0000, 
raw observation next is [17.66666666666666, 82.0, 1.0, 2.0, 0.2877340875963967, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 312432.4386176548, 312432.4386176551, 107996.681573716], 
processed observation next is [1.0, 0.0, 0.4393939393939391, 0.82, 1.0, 1.0, 0.10966760949549584, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1157157180065388, 0.11571571800653892, 0.2634065404236976], 
reward next is 0.7366, 
noisyNet noise sample is [array([-0.96843135], dtype=float32), -0.3009714]. 
=============================================
[2019-03-23 02:09:59,582] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[36.82966 ]
 [30.808146]
 [23.645054]
 [16.36347 ]
 [ 8.469821]], R is [[42.15628433]
 [42.49852753]
 [42.07354355]
 [41.65280914]
 [41.23628235]].
[2019-03-23 02:09:59,613] A3C_AGENT_WORKER-Thread-16 INFO:Local step 132500, global step 2124993: loss 5.8573
[2019-03-23 02:09:59,614] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 132500, global step 2124993: learning rate 0.0010
[2019-03-23 02:09:59,628] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-23 02:09:59,631] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 02:09:59,632] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:09:59,632] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 02:09:59,634] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 02:09:59,635] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:09:59,635] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 02:09:59,635] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 02:09:59,635] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:09:59,637] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:09:59,639] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:09:59,663] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run86
[2019-03-23 02:09:59,686] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run86
[2019-03-23 02:09:59,715] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run86
[2019-03-23 02:09:59,734] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run86
[2019-03-23 02:09:59,734] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run86
[2019-03-23 02:10:03,676] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.0151728], dtype=float32), -0.11531788]
[2019-03-23 02:10:03,677] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.3, 43.33333333333334, 1.0, 2.0, 0.2807025630259856, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 304776.7385285412, 304776.7385285412, 89719.91091834466]
[2019-03-23 02:10:03,678] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 02:10:03,682] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.5332944096902643
[2019-03-23 02:10:20,732] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.0151728], dtype=float32), -0.11531788]
[2019-03-23 02:10:20,734] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [25.36666666666667, 66.0, 1.0, 2.0, 0.4763506819774996, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 543482.9083955163, 543482.908395516, 142300.7219154045]
[2019-03-23 02:10:20,736] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 02:10:20,738] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.002424742723775797
[2019-03-23 02:10:21,912] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.0151728], dtype=float32), -0.11531788]
[2019-03-23 02:10:21,913] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.26666666666667, 86.66666666666667, 1.0, 2.0, 0.4454503078829746, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 506958.4909804422, 506958.4909804419, 136776.1955189237]
[2019-03-23 02:10:21,914] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 02:10:21,918] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.24589383877461668
[2019-03-23 02:10:29,748] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.0151728], dtype=float32), -0.11531788]
[2019-03-23 02:10:29,748] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [16.36666666666667, 49.66666666666667, 1.0, 2.0, 0.2310245482847058, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 250826.8834761727, 250826.8834761727, 76533.78623895941]
[2019-03-23 02:10:29,749] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 02:10:29,753] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.8374065017520846
[2019-03-23 02:10:53,586] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.0151728], dtype=float32), -0.11531788]
[2019-03-23 02:10:53,587] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.0, 100.0, 1.0, 2.0, 0.3411544369863719, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 377563.3064602307, 377563.3064602307, 116606.0070143053]
[2019-03-23 02:10:53,588] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 02:10:53,592] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.2598503341076337
[2019-03-23 02:10:55,739] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.0151728], dtype=float32), -0.11531788]
[2019-03-23 02:10:55,740] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [26.8, 58.5, 1.0, 2.0, 0.4864857691213879, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 555067.5368704668, 555067.5368704663, 143659.9108491064]
[2019-03-23 02:10:55,742] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 02:10:55,745] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.3067470368093621
[2019-03-23 02:11:16,814] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.0151728], dtype=float32), -0.11531788]
[2019-03-23 02:11:16,816] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [13.3, 70.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 184714.16417701, 184714.16417701, 63417.49873933737]
[2019-03-23 02:11:16,818] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 02:11:16,821] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.28087962806401023
[2019-03-23 02:11:35,285] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.0151728], dtype=float32), -0.11531788]
[2019-03-23 02:11:35,286] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.9, 57.66666666666667, 1.0, 2.0, 0.540244404927799, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 601511.5726108464, 601511.5726108464, 135573.3144516412]
[2019-03-23 02:11:35,286] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 02:11:35,288] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.8300006e-30 9.8394954e-36], sampled 0.009988311030612707
[2019-03-23 02:11:46,467] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8483.7939 1782688715.4277 151.0000
[2019-03-23 02:11:46,887] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8576.7294 1685427029.8934 172.0000
[2019-03-23 02:11:47,064] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8851.9735 1664101423.8647 105.0000
[2019-03-23 02:11:47,160] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9057.7483 1656667702.0598 74.0000
[2019-03-23 02:11:47,210] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8600.7181 1707556560.4291 427.0000
[2019-03-23 02:11:48,227] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 2125000, evaluation results [2125000.0, 8483.793858748902, 1782688715.4276757, 151.0, 9057.74831003496, 1656667702.059805, 74.0, 8851.973532677643, 1664101423.8646872, 105.0, 8600.71813598386, 1707556560.429122, 427.0, 8576.72938932831, 1685427029.893405, 172.0]
[2019-03-23 02:11:48,362] A3C_AGENT_WORKER-Thread-12 INFO:Local step 132500, global step 2125072: loss 0.4160
[2019-03-23 02:11:48,367] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 132500, global step 2125072: learning rate 0.0010
[2019-03-23 02:11:48,539] A3C_AGENT_WORKER-Thread-11 INFO:Local step 132500, global step 2125152: loss 0.9367
[2019-03-23 02:11:48,547] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 132500, global step 2125156: learning rate 0.0010
[2019-03-23 02:11:48,681] A3C_AGENT_WORKER-Thread-22 INFO:Local step 132500, global step 2125221: loss 1.0703
[2019-03-23 02:11:48,684] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 132500, global step 2125222: learning rate 0.0010
[2019-03-23 02:11:48,807] A3C_AGENT_WORKER-Thread-2 INFO:Local step 133000, global step 2125278: loss 0.3927
[2019-03-23 02:11:48,810] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 133000, global step 2125278: learning rate 0.0010
[2019-03-23 02:11:48,842] A3C_AGENT_WORKER-Thread-13 INFO:Local step 132500, global step 2125295: loss 25.0241
[2019-03-23 02:11:48,845] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 132500, global step 2125296: learning rate 0.0010
[2019-03-23 02:11:49,251] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.9499277e-36 1.0000000e+00 4.8827512e-37 1.8286438e-19 3.6391876e-28], sum to 1.0000
[2019-03-23 02:11:49,262] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9186
[2019-03-23 02:11:49,268] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.2143097684890022, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 232686.4937125957, 232686.4937125957, 75860.98057792547], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 459600.0000, 
sim time next is 460200.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 209539.9304423279, 209539.9304423276, 72517.68386178861], 
processed observation next is [1.0, 0.30434782608695654, 0.22727272727272727, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07760738164530663, 0.07760738164530652, 0.17687239966289905], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.03538033], dtype=float32), -0.450913]. 
=============================================
[2019-03-23 02:11:51,592] A3C_AGENT_WORKER-Thread-21 INFO:Local step 134000, global step 2126594: loss 0.0619
[2019-03-23 02:11:51,595] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 134000, global step 2126595: learning rate 0.0010
[2019-03-23 02:11:56,158] A3C_AGENT_WORKER-Thread-15 INFO:Local step 133000, global step 2128759: loss 0.2049
[2019-03-23 02:11:56,162] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 133000, global step 2128760: learning rate 0.0010
[2019-03-23 02:11:57,163] A3C_AGENT_WORKER-Thread-3 INFO:Local step 134000, global step 2129227: loss 0.0062
[2019-03-23 02:11:57,167] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 134000, global step 2129228: learning rate 0.0010
[2019-03-23 02:11:57,747] A3C_AGENT_WORKER-Thread-14 INFO:Local step 133500, global step 2129505: loss 0.0464
[2019-03-23 02:11:57,750] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 133500, global step 2129507: learning rate 0.0010
[2019-03-23 02:11:57,876] A3C_AGENT_WORKER-Thread-9 INFO:Local step 133500, global step 2129567: loss 0.2978
[2019-03-23 02:11:57,879] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 133500, global step 2129567: learning rate 0.0010
[2019-03-23 02:11:58,731] A3C_AGENT_WORKER-Thread-20 INFO:Local step 133000, global step 2129947: loss 0.2614
[2019-03-23 02:11:58,735] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 133000, global step 2129949: learning rate 0.0010
[2019-03-23 02:11:59,306] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:11:59,317] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0521
[2019-03-23 02:11:59,323] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.66666666666666, 65.5, 1.0, 2.0, 0.304467220011951, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 332999.0288161758, 332999.0288161758, 112345.3880050918], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 211800.0000, 
sim time next is 212400.0000, 
raw observation next is [21.0, 64.0, 1.0, 2.0, 0.3072951977384176, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 336705.4183648739, 336705.4183648736, 112766.894083757], 
processed observation next is [0.0, 0.4782608695652174, 0.5909090909090909, 0.64, 1.0, 1.0, 0.134118997173022, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12470571050550885, 0.12470571050550874, 0.27504120508233415], 
reward next is 0.7250, 
noisyNet noise sample is [array([1.1369607], dtype=float32), -0.51536924]. 
=============================================
[2019-03-23 02:12:00,154] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.2555028e-38 1.0000000e+00 0.0000000e+00 6.5587605e-31 6.7507301e-19], sum to 1.0000
[2019-03-23 02:12:00,164] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2047
[2019-03-23 02:12:00,173] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 54.5, 1.0, 2.0, 0.4207321994038681, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 470742.1919842254, 470742.1919842256, 125130.4178360193], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 651000.0000, 
sim time next is 651600.0000, 
raw observation next is [24.0, 54.0, 1.0, 2.0, 0.4696473163292594, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 525076.7476214888, 525076.7476214888, 129507.3613147756], 
processed observation next is [1.0, 0.5652173913043478, 0.7272727272727273, 0.54, 1.0, 1.0, 0.33705914541157417, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1944728694894403, 0.1944728694894403, 0.3158716129628673], 
reward next is 0.6841, 
noisyNet noise sample is [array([-0.68674403], dtype=float32), 2.0959988]. 
=============================================
[2019-03-23 02:12:00,590] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:12:00,596] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6511
[2019-03-23 02:12:00,601] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 55.33333333333334, 1.0, 2.0, 0.2744387963179728, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 297991.4909122052, 297991.4909122052, 98688.31999837127], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 220200.0000, 
sim time next is 220800.0000, 
raw observation next is [20.0, 60.66666666666667, 1.0, 2.0, 0.2657118581522279, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 288512.7848160527, 288512.7848160524, 95996.81132590733], 
processed observation next is [0.0, 0.5652173913043478, 0.5454545454545454, 0.6066666666666667, 1.0, 1.0, 0.08213982269028489, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10685658696890842, 0.1068565869689083, 0.23413856420953008], 
reward next is 0.7659, 
noisyNet noise sample is [array([0.8221362], dtype=float32), 0.3816065]. 
=============================================
[2019-03-23 02:12:04,319] A3C_AGENT_WORKER-Thread-19 INFO:Local step 133000, global step 2132596: loss 0.0424
[2019-03-23 02:12:04,323] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 133000, global step 2132597: learning rate 0.0010
[2019-03-23 02:12:04,595] A3C_AGENT_WORKER-Thread-17 INFO:Local step 133000, global step 2132724: loss 0.0084
[2019-03-23 02:12:04,600] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 133000, global step 2132725: learning rate 0.0010
[2019-03-23 02:12:04,734] A3C_AGENT_WORKER-Thread-18 INFO:Local step 133000, global step 2132792: loss 0.0238
[2019-03-23 02:12:04,736] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 133000, global step 2132792: learning rate 0.0010
[2019-03-23 02:12:04,961] A3C_AGENT_WORKER-Thread-10 INFO:Local step 133000, global step 2132898: loss 0.0072
[2019-03-23 02:12:04,965] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 133000, global step 2132899: learning rate 0.0010
[2019-03-23 02:12:05,052] A3C_AGENT_WORKER-Thread-16 INFO:Local step 133000, global step 2132939: loss 0.0033
[2019-03-23 02:12:05,054] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 133000, global step 2132939: learning rate 0.0010
[2019-03-23 02:12:05,328] A3C_AGENT_WORKER-Thread-12 INFO:Local step 133000, global step 2133068: loss 0.0204
[2019-03-23 02:12:05,333] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 133000, global step 2133068: learning rate 0.0010
[2019-03-23 02:12:05,641] A3C_AGENT_WORKER-Thread-11 INFO:Local step 133000, global step 2133218: loss 0.0638
[2019-03-23 02:12:05,646] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 133000, global step 2133219: learning rate 0.0010
[2019-03-23 02:12:05,686] A3C_AGENT_WORKER-Thread-22 INFO:Local step 133000, global step 2133238: loss 0.0721
[2019-03-23 02:12:05,690] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 133000, global step 2133239: learning rate 0.0010
[2019-03-23 02:12:05,711] A3C_AGENT_WORKER-Thread-13 INFO:Local step 133000, global step 2133248: loss 0.0241
[2019-03-23 02:12:05,715] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 133000, global step 2133248: learning rate 0.0010
[2019-03-23 02:12:05,770] A3C_AGENT_WORKER-Thread-2 INFO:Local step 133500, global step 2133276: loss 0.4650
[2019-03-23 02:12:05,771] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 133500, global step 2133276: learning rate 0.0010
[2019-03-23 02:12:08,711] A3C_AGENT_WORKER-Thread-21 INFO:Local step 134500, global step 2134661: loss 1.7637
[2019-03-23 02:12:08,713] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 134500, global step 2134661: learning rate 0.0010
[2019-03-23 02:12:13,116] A3C_AGENT_WORKER-Thread-15 INFO:Local step 133500, global step 2136738: loss 4.6521
[2019-03-23 02:12:13,118] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 133500, global step 2136739: learning rate 0.0010
[2019-03-23 02:12:14,193] A3C_AGENT_WORKER-Thread-3 INFO:Local step 134500, global step 2137245: loss 2.5532
[2019-03-23 02:12:14,195] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 134500, global step 2137246: learning rate 0.0010
[2019-03-23 02:12:14,916] A3C_AGENT_WORKER-Thread-14 INFO:Local step 134000, global step 2137585: loss 0.0809
[2019-03-23 02:12:14,920] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 134000, global step 2137586: learning rate 0.0010
[2019-03-23 02:12:14,978] A3C_AGENT_WORKER-Thread-9 INFO:Local step 134000, global step 2137615: loss 0.0889
[2019-03-23 02:12:14,980] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 134000, global step 2137615: learning rate 0.0010
[2019-03-23 02:12:15,210] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.4979797e-38 1.8822998e-33], sum to 1.0000
[2019-03-23 02:12:15,216] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7871
[2019-03-23 02:12:15,222] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 100.0, 1.0, 2.0, 0.3176316365306361, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 344907.8284712989, 344907.8284712986, 90525.33659108935], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 478800.0000, 
sim time next is 479400.0000, 
raw observation next is [14.0, 100.0, 1.0, 2.0, 0.3928897524680638, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 426664.4884360067, 426664.4884360064, 98209.49341972473], 
processed observation next is [1.0, 0.5652173913043478, 0.2727272727272727, 1.0, 1.0, 1.0, 0.2411121905850797, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15802388460592842, 0.1580238846059283, 0.23953534980420668], 
reward next is 0.7605, 
noisyNet noise sample is [array([-1.9160246], dtype=float32), -0.4911972]. 
=============================================
[2019-03-23 02:12:15,578] A3C_AGENT_WORKER-Thread-20 INFO:Local step 133500, global step 2137898: loss 2.5445
[2019-03-23 02:12:15,580] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 133500, global step 2137900: learning rate 0.0010
[2019-03-23 02:12:21,273] A3C_AGENT_WORKER-Thread-19 INFO:Local step 133500, global step 2140576: loss 0.2643
[2019-03-23 02:12:21,275] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 133500, global step 2140576: learning rate 0.0010
[2019-03-23 02:12:21,633] A3C_AGENT_WORKER-Thread-18 INFO:Local step 133500, global step 2140748: loss 0.1174
[2019-03-23 02:12:21,636] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 133500, global step 2140748: learning rate 0.0010
[2019-03-23 02:12:21,650] A3C_AGENT_WORKER-Thread-17 INFO:Local step 133500, global step 2140757: loss 0.7789
[2019-03-23 02:12:21,656] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 133500, global step 2140759: learning rate 0.0010
[2019-03-23 02:12:21,836] A3C_AGENT_WORKER-Thread-10 INFO:Local step 133500, global step 2140841: loss 0.4219
[2019-03-23 02:12:21,839] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 133500, global step 2140843: learning rate 0.0010
[2019-03-23 02:12:22,048] A3C_AGENT_WORKER-Thread-16 INFO:Local step 133500, global step 2140944: loss 0.0034
[2019-03-23 02:12:22,050] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 133500, global step 2140944: learning rate 0.0010
[2019-03-23 02:12:22,278] A3C_AGENT_WORKER-Thread-12 INFO:Local step 133500, global step 2141047: loss 0.0185
[2019-03-23 02:12:22,281] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 133500, global step 2141048: learning rate 0.0010
[2019-03-23 02:12:22,586] A3C_AGENT_WORKER-Thread-11 INFO:Local step 133500, global step 2141192: loss 0.4025
[2019-03-23 02:12:22,590] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 133500, global step 2141192: learning rate 0.0010
[2019-03-23 02:12:22,725] A3C_AGENT_WORKER-Thread-13 INFO:Local step 133500, global step 2141259: loss 0.4647
[2019-03-23 02:12:22,728] A3C_AGENT_WORKER-Thread-22 INFO:Local step 133500, global step 2141260: loss 0.1223
[2019-03-23 02:12:22,728] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 133500, global step 2141260: learning rate 0.0010
[2019-03-23 02:12:22,729] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 133500, global step 2141261: learning rate 0.0010
[2019-03-23 02:12:22,821] A3C_AGENT_WORKER-Thread-2 INFO:Local step 134000, global step 2141303: loss 0.0106
[2019-03-23 02:12:22,822] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 134000, global step 2141303: learning rate 0.0010
[2019-03-23 02:12:25,826] A3C_AGENT_WORKER-Thread-21 INFO:Local step 135000, global step 2142724: loss 0.0431
[2019-03-23 02:12:25,830] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 135000, global step 2142725: learning rate 0.0010
[2019-03-23 02:12:29,956] A3C_AGENT_WORKER-Thread-15 INFO:Local step 134000, global step 2144666: loss 0.2118
[2019-03-23 02:12:29,958] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 134000, global step 2144666: learning rate 0.0010
[2019-03-23 02:12:31,341] A3C_AGENT_WORKER-Thread-3 INFO:Local step 135000, global step 2145328: loss 0.1821
[2019-03-23 02:12:31,342] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 135000, global step 2145329: learning rate 0.0010
[2019-03-23 02:12:31,872] A3C_AGENT_WORKER-Thread-9 INFO:Local step 134500, global step 2145577: loss 0.0895
[2019-03-23 02:12:31,876] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 134500, global step 2145580: learning rate 0.0010
[2019-03-23 02:12:31,922] A3C_AGENT_WORKER-Thread-14 INFO:Local step 134500, global step 2145604: loss 2.0137
[2019-03-23 02:12:31,925] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 134500, global step 2145605: learning rate 0.0010
[2019-03-23 02:12:32,587] A3C_AGENT_WORKER-Thread-20 INFO:Local step 134000, global step 2145916: loss 0.1337
[2019-03-23 02:12:32,590] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 134000, global step 2145916: learning rate 0.0010
[2019-03-23 02:12:32,965] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 8.958082e-34 2.088047e-37], sum to 1.0000
[2019-03-23 02:12:32,978] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6223
[2019-03-23 02:12:32,985] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666666, 66.33333333333333, 1.0, 2.0, 0.7613524343180025, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 859288.528905357, 859288.528905357, 166633.5796993516], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1093200.0000, 
sim time next is 1093800.0000, 
raw observation next is [22.83333333333334, 65.66666666666667, 1.0, 2.0, 0.7826781492953276, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 883919.1456624361, 883919.1456624361, 169920.2923560732], 
processed observation next is [1.0, 0.6521739130434783, 0.6742424242424245, 0.6566666666666667, 1.0, 1.0, 0.7283476866191596, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.32737746135645784, 0.32737746135645784, 0.41443973745383705], 
reward next is 0.5856, 
noisyNet noise sample is [array([-1.532341], dtype=float32), 0.3706743]. 
=============================================
[2019-03-23 02:12:33,707] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:12:33,715] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0151
[2019-03-23 02:12:33,720] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 60.66666666666667, 1.0, 2.0, 0.5883776255746244, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 663993.3428710415, 663993.3428710415, 156652.3847923617], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 823200.0000, 
sim time next is 823800.0000, 
raw observation next is [29.0, 59.33333333333334, 1.0, 2.0, 0.5773065214767891, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 652881.3656993136, 652881.3656993136, 154764.5450449057], 
processed observation next is [0.0, 0.5217391304347826, 0.9545454545454546, 0.5933333333333334, 1.0, 1.0, 0.4716331518459863, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.24180791322196798, 0.24180791322196798, 0.3774745001095261], 
reward next is 0.6225, 
noisyNet noise sample is [array([-1.3003557], dtype=float32), -0.95629126]. 
=============================================
[2019-03-23 02:12:36,483] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:12:36,491] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1063
[2019-03-23 02:12:36,496] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.83333333333334, 89.00000000000001, 1.0, 2.0, 0.4008932687359194, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 452862.7279485968, 452862.7279485968, 125542.6044829032], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 871800.0000, 
sim time next is 872400.0000, 
raw observation next is [19.66666666666667, 90.0, 1.0, 2.0, 0.4011189879335418, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 452940.8354143014, 452940.8354143017, 125461.4131345115], 
processed observation next is [0.0, 0.08695652173913043, 0.5303030303030305, 0.9, 1.0, 1.0, 0.2513987349169272, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16775586496825975, 0.1677558649682599, 0.30600344666954027], 
reward next is 0.6940, 
noisyNet noise sample is [array([0.18284565], dtype=float32), -1.4593074]. 
=============================================
[2019-03-23 02:12:38,276] A3C_AGENT_WORKER-Thread-19 INFO:Local step 134000, global step 2148584: loss 0.0107
[2019-03-23 02:12:38,278] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 134000, global step 2148584: learning rate 0.0010
[2019-03-23 02:12:38,715] A3C_AGENT_WORKER-Thread-17 INFO:Local step 134000, global step 2148796: loss 0.0333
[2019-03-23 02:12:38,721] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 134000, global step 2148796: learning rate 0.0010
[2019-03-23 02:12:38,723] A3C_AGENT_WORKER-Thread-10 INFO:Local step 134000, global step 2148799: loss 0.0508
[2019-03-23 02:12:38,726] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 134000, global step 2148800: learning rate 0.0010
[2019-03-23 02:12:38,730] A3C_AGENT_WORKER-Thread-18 INFO:Local step 134000, global step 2148801: loss 0.0375
[2019-03-23 02:12:38,733] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 134000, global step 2148801: learning rate 0.0010
[2019-03-23 02:12:38,998] A3C_AGENT_WORKER-Thread-16 INFO:Local step 134000, global step 2148927: loss 0.0431
[2019-03-23 02:12:38,999] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 134000, global step 2148927: learning rate 0.0010
[2019-03-23 02:12:39,157] A3C_AGENT_WORKER-Thread-12 INFO:Local step 134000, global step 2149000: loss 0.0103
[2019-03-23 02:12:39,161] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 134000, global step 2149000: learning rate 0.0010
[2019-03-23 02:12:39,626] A3C_AGENT_WORKER-Thread-11 INFO:Local step 134000, global step 2149220: loss 0.0995
[2019-03-23 02:12:39,629] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 134000, global step 2149220: learning rate 0.0010
[2019-03-23 02:12:39,696] A3C_AGENT_WORKER-Thread-22 INFO:Local step 134000, global step 2149254: loss 0.0947
[2019-03-23 02:12:39,700] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 134000, global step 2149255: learning rate 0.0010
[2019-03-23 02:12:39,731] A3C_AGENT_WORKER-Thread-2 INFO:Local step 134500, global step 2149269: loss 0.2838
[2019-03-23 02:12:39,732] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 134500, global step 2149269: learning rate 0.0010
[2019-03-23 02:12:39,837] A3C_AGENT_WORKER-Thread-13 INFO:Local step 134000, global step 2149322: loss 0.0814
[2019-03-23 02:12:39,839] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 134000, global step 2149322: learning rate 0.0010
[2019-03-23 02:12:41,270] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-23 02:12:41,271] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 02:12:41,272] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 02:12:41,272] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:12:41,273] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:12:41,273] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 02:12:41,275] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 02:12:41,274] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 02:12:41,279] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:12:41,278] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:12:41,280] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:12:41,310] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run87
[2019-03-23 02:12:41,335] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run87
[2019-03-23 02:12:41,336] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run87
[2019-03-23 02:12:41,384] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run87
[2019-03-23 02:12:41,384] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run87
[2019-03-23 02:12:59,422] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00279958], dtype=float32), -0.09722481]
[2019-03-23 02:12:59,424] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [25.7, 69.0, 1.0, 2.0, 0.6549055552418518, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 746608.4786136339, 746608.4786136339, 166721.8353643738]
[2019-03-23 02:12:59,426] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 02:12:59,430] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.49177846301497197
[2019-03-23 02:13:09,892] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00279958], dtype=float32), -0.09722481]
[2019-03-23 02:13:09,894] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [17.32032802333333, 64.61641210833334, 1.0, 2.0, 0.2469359581796491, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 268105.997300241, 268105.997300241, 84247.95221587164]
[2019-03-23 02:13:09,895] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 02:13:09,898] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.8016915885729379
[2019-03-23 02:13:13,589] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00279958], dtype=float32), -0.09722481]
[2019-03-23 02:13:13,591] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.0, 52.66666666666667, 1.0, 2.0, 0.3983094147485205, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 432552.6696375455, 432552.6696375458, 92281.79013975486]
[2019-03-23 02:13:13,592] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 02:13:13,594] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.7006789625950716
[2019-03-23 02:13:53,932] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00279958], dtype=float32), -0.09722481]
[2019-03-23 02:13:53,933] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.5, 45.5, 1.0, 2.0, 0.5965179791486763, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 676831.5029582514, 676831.5029582514, 152122.1052104212]
[2019-03-23 02:13:53,935] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 02:13:53,938] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.3262050643868779
[2019-03-23 02:13:56,457] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00279958], dtype=float32), -0.09722481]
[2019-03-23 02:13:56,457] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.125017, 80.50807460333334, 1.0, 2.0, 0.4148691561381203, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 469609.0573528615, 469609.0573528612, 131740.894599839]
[2019-03-23 02:13:56,461] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 02:13:56,464] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.7655441019376874
[2019-03-23 02:14:10,378] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00279958], dtype=float32), -0.09722481]
[2019-03-23 02:14:10,381] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [26.13333333333333, 54.33333333333333, 1.0, 2.0, 0.4248004770359267, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 482897.4944965501, 482897.4944965501, 134172.2441361755]
[2019-03-23 02:14:10,381] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 02:14:10,382] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.1366857930825045
[2019-03-23 02:14:19,261] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00279958], dtype=float32), -0.09722481]
[2019-03-23 02:14:19,261] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [14.81911043, 74.98822262, 1.0, 2.0, 0.213752546709382, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 232070.7872483098, 232070.7872483095, 77563.97352254487]
[2019-03-23 02:14:19,263] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 02:14:19,267] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.3879363304722321
[2019-03-23 02:14:29,610] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8594.4987 1706116953.1019 465.0000
[2019-03-23 02:14:29,860] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9058.6831 1656359050.7176 80.0000
[2019-03-23 02:14:29,949] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8854.1746 1663949029.5070 105.0000
[2019-03-23 02:14:29,979] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8571.9617 1683477666.0862 214.0000
[2019-03-23 02:14:30,020] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8508.9568 1773757395.0600 173.0000
[2019-03-23 02:14:31,037] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 2150000, evaluation results [2150000.0, 8508.956811533557, 1773757395.0600324, 173.0, 9058.683074210225, 1656359050.7176125, 80.0, 8854.174594824059, 1663949029.507014, 105.0, 8594.49866461476, 1706116953.1019058, 465.0, 8571.9617444755, 1683477666.0861843, 214.0]
[2019-03-23 02:14:32,305] A3C_AGENT_WORKER-Thread-21 INFO:Local step 135500, global step 2150615: loss 0.1532
[2019-03-23 02:14:32,307] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 135500, global step 2150615: learning rate 0.0010
[2019-03-23 02:14:36,723] A3C_AGENT_WORKER-Thread-15 INFO:Local step 134500, global step 2152705: loss 0.5934
[2019-03-23 02:14:36,725] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 134500, global step 2152705: learning rate 0.0010
[2019-03-23 02:14:37,940] A3C_AGENT_WORKER-Thread-3 INFO:Local step 135500, global step 2153271: loss 0.2648
[2019-03-23 02:14:37,943] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 135500, global step 2153271: learning rate 0.0010
[2019-03-23 02:14:38,814] A3C_AGENT_WORKER-Thread-9 INFO:Local step 135000, global step 2153683: loss 0.0308
[2019-03-23 02:14:38,817] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 135000, global step 2153684: learning rate 0.0010
[2019-03-23 02:14:38,902] A3C_AGENT_WORKER-Thread-14 INFO:Local step 135000, global step 2153727: loss 0.0882
[2019-03-23 02:14:38,903] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 135000, global step 2153727: learning rate 0.0010
[2019-03-23 02:14:39,295] A3C_AGENT_WORKER-Thread-20 INFO:Local step 134500, global step 2153908: loss 0.2758
[2019-03-23 02:14:39,297] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 134500, global step 2153909: learning rate 0.0010
[2019-03-23 02:14:42,683] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 7.3099168e-36 6.5360189e-35 2.9735537e-34], sum to 1.0000
[2019-03-23 02:14:42,692] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7536
[2019-03-23 02:14:42,699] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.66666666666666, 70.66666666666667, 1.0, 2.0, 0.711101243783071, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 811649.7561770075, 811649.7561770077, 168537.3776626913], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1165200.0000, 
sim time next is 1165800.0000, 
raw observation next is [24.83333333333334, 69.83333333333333, 1.0, 2.0, 0.7348103687561904, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 838729.3471525018, 838729.3471525015, 172159.640395507], 
processed observation next is [1.0, 0.4782608695652174, 0.7651515151515155, 0.6983333333333333, 1.0, 1.0, 0.668512960945238, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.31064049894537105, 0.31064049894537094, 0.419901561940261], 
reward next is 0.5801, 
noisyNet noise sample is [array([-0.65606457], dtype=float32), 1.1771703]. 
=============================================
[2019-03-23 02:14:44,933] A3C_AGENT_WORKER-Thread-19 INFO:Local step 134500, global step 2156574: loss 0.6666
[2019-03-23 02:14:44,935] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 134500, global step 2156574: learning rate 0.0010
[2019-03-23 02:14:45,249] A3C_AGENT_WORKER-Thread-10 INFO:Local step 134500, global step 2156724: loss 0.2680
[2019-03-23 02:14:45,252] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 134500, global step 2156726: learning rate 0.0010
[2019-03-23 02:14:45,259] A3C_AGENT_WORKER-Thread-18 INFO:Local step 134500, global step 2156729: loss 1.2210
[2019-03-23 02:14:45,263] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 134500, global step 2156729: learning rate 0.0010
[2019-03-23 02:14:45,370] A3C_AGENT_WORKER-Thread-17 INFO:Local step 134500, global step 2156779: loss 0.9741
[2019-03-23 02:14:45,373] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 134500, global step 2156779: learning rate 0.0010
[2019-03-23 02:14:45,662] A3C_AGENT_WORKER-Thread-16 INFO:Local step 134500, global step 2156921: loss 0.2091
[2019-03-23 02:14:45,664] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 134500, global step 2156922: learning rate 0.0010
[2019-03-23 02:14:45,715] A3C_AGENT_WORKER-Thread-12 INFO:Local step 134500, global step 2156945: loss 1.9000
[2019-03-23 02:14:45,723] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 134500, global step 2156945: learning rate 0.0010
[2019-03-23 02:14:46,214] A3C_AGENT_WORKER-Thread-22 INFO:Local step 134500, global step 2157178: loss 1.2360
[2019-03-23 02:14:46,219] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 134500, global step 2157179: learning rate 0.0010
[2019-03-23 02:14:46,239] A3C_AGENT_WORKER-Thread-11 INFO:Local step 134500, global step 2157189: loss 4.3163
[2019-03-23 02:14:46,240] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 134500, global step 2157189: learning rate 0.0010
[2019-03-23 02:14:46,562] A3C_AGENT_WORKER-Thread-13 INFO:Local step 134500, global step 2157340: loss 0.4174
[2019-03-23 02:14:46,565] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 134500, global step 2157342: learning rate 0.0010
[2019-03-23 02:14:46,654] A3C_AGENT_WORKER-Thread-2 INFO:Local step 135000, global step 2157385: loss 0.1123
[2019-03-23 02:14:46,656] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 135000, global step 2157385: learning rate 0.0010
[2019-03-23 02:14:49,076] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.66998993e-37 1.00000000e+00 1.44532165e-30 5.34288043e-32
 3.01627607e-15], sum to 1.0000
[2019-03-23 02:14:49,087] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2506
[2019-03-23 02:14:49,096] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333334, 96.0, 1.0, 2.0, 0.4825788112335291, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 550657.1097465534, 550657.1097465534, 139156.1086258985], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1381200.0000, 
sim time next is 1381800.0000, 
raw observation next is [21.16666666666666, 98.0, 1.0, 2.0, 0.4856943416163791, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 554192.3855675332, 554192.3855675332, 139663.0198598871], 
processed observation next is [1.0, 1.0, 0.5984848484848482, 0.98, 1.0, 1.0, 0.35711792702047385, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20525643909908636, 0.20525643909908636, 0.3406415118533832], 
reward next is 0.6594, 
noisyNet noise sample is [array([-0.39120272], dtype=float32), -2.1553729]. 
=============================================
[2019-03-23 02:14:49,208] A3C_AGENT_WORKER-Thread-21 INFO:Local step 136000, global step 2158584: loss 0.0163
[2019-03-23 02:14:49,209] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 136000, global step 2158584: learning rate 0.0010
[2019-03-23 02:14:50,452] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:14:50,464] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8834
[2019-03-23 02:14:50,471] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333334, 78.0, 1.0, 2.0, 0.4887367356031614, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 557695.0702418404, 557695.0702418402, 139524.2168990177], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1279200.0000, 
sim time next is 1279800.0000, 
raw observation next is [22.0, 82.0, 1.0, 2.0, 0.4633151125319826, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 528028.5294902978, 528028.5294902978, 135106.2285631811], 
processed observation next is [1.0, 0.8260869565217391, 0.6363636363636364, 0.82, 1.0, 1.0, 0.32914389066497823, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19556612203344362, 0.19556612203344362, 0.3295273867394661], 
reward next is 0.6705, 
noisyNet noise sample is [array([-0.4824194], dtype=float32), -0.0044848314]. 
=============================================
[2019-03-23 02:14:52,517] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:14:52,524] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9209
[2019-03-23 02:14:52,528] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [11.66666666666667, 68.33333333333333, 1.0, 2.0, 0.3394583826670357, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 368617.9005617644, 368617.9005617644, 79845.46229313976], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1755600.0000, 
sim time next is 1756200.0000, 
raw observation next is [11.83333333333333, 67.66666666666667, 1.0, 2.0, 0.3498293371033401, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 379884.1204316977, 379884.1204316977, 80894.25596262216], 
processed observation next is [1.0, 0.30434782608695654, 0.17424242424242412, 0.6766666666666667, 1.0, 1.0, 0.18728667137917507, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14069782238211026, 0.14069782238211026, 0.1973030633234687], 
reward next is 0.8027, 
noisyNet noise sample is [array([0.72424275], dtype=float32), 0.38526592]. 
=============================================
[2019-03-23 02:14:53,776] A3C_AGENT_WORKER-Thread-15 INFO:Local step 135000, global step 2160720: loss 0.0835
[2019-03-23 02:14:53,779] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 135000, global step 2160721: learning rate 0.0010
[2019-03-23 02:14:54,711] A3C_AGENT_WORKER-Thread-3 INFO:Local step 136000, global step 2161157: loss 0.0488
[2019-03-23 02:14:54,712] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 136000, global step 2161157: learning rate 0.0010
[2019-03-23 02:14:55,543] A3C_AGENT_WORKER-Thread-9 INFO:Local step 135500, global step 2161553: loss 0.1004
[2019-03-23 02:14:55,553] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 135500, global step 2161557: learning rate 0.0010
[2019-03-23 02:14:55,686] A3C_AGENT_WORKER-Thread-14 INFO:Local step 135500, global step 2161622: loss 0.1001
[2019-03-23 02:14:55,687] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 135500, global step 2161622: learning rate 0.0010
[2019-03-23 02:14:56,293] A3C_AGENT_WORKER-Thread-20 INFO:Local step 135000, global step 2161911: loss 0.0447
[2019-03-23 02:14:56,295] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 135000, global step 2161911: learning rate 0.0010
[2019-03-23 02:15:01,912] A3C_AGENT_WORKER-Thread-19 INFO:Local step 135000, global step 2164581: loss 0.1981
[2019-03-23 02:15:01,916] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 135000, global step 2164581: learning rate 0.0010
[2019-03-23 02:15:02,084] A3C_AGENT_WORKER-Thread-10 INFO:Local step 135000, global step 2164662: loss 0.1022
[2019-03-23 02:15:02,087] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 135000, global step 2164662: learning rate 0.0010
[2019-03-23 02:15:02,263] A3C_AGENT_WORKER-Thread-18 INFO:Local step 135000, global step 2164744: loss 0.0542
[2019-03-23 02:15:02,269] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 135000, global step 2164745: learning rate 0.0010
[2019-03-23 02:15:02,534] A3C_AGENT_WORKER-Thread-17 INFO:Local step 135000, global step 2164863: loss 0.0408
[2019-03-23 02:15:02,537] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 135000, global step 2164863: learning rate 0.0010
[2019-03-23 02:15:02,862] A3C_AGENT_WORKER-Thread-16 INFO:Local step 135000, global step 2165022: loss 0.0392
[2019-03-23 02:15:02,865] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 135000, global step 2165022: learning rate 0.0010
[2019-03-23 02:15:02,915] A3C_AGENT_WORKER-Thread-12 INFO:Local step 135000, global step 2165048: loss 0.1399
[2019-03-23 02:15:02,919] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 135000, global step 2165050: learning rate 0.0010
[2019-03-23 02:15:03,365] A3C_AGENT_WORKER-Thread-2 INFO:Local step 135500, global step 2165258: loss 0.1488
[2019-03-23 02:15:03,370] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 135500, global step 2165259: learning rate 0.0010
[2019-03-23 02:15:03,486] A3C_AGENT_WORKER-Thread-22 INFO:Local step 135000, global step 2165317: loss 0.1765
[2019-03-23 02:15:03,488] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 135000, global step 2165318: learning rate 0.0010
[2019-03-23 02:15:03,546] A3C_AGENT_WORKER-Thread-11 INFO:Local step 135000, global step 2165341: loss 0.0968
[2019-03-23 02:15:03,548] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 135000, global step 2165341: learning rate 0.0010
[2019-03-23 02:15:03,824] A3C_AGENT_WORKER-Thread-13 INFO:Local step 135000, global step 2165474: loss 0.2069
[2019-03-23 02:15:03,829] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 135000, global step 2165474: learning rate 0.0010
[2019-03-23 02:15:05,904] A3C_AGENT_WORKER-Thread-21 INFO:Local step 136500, global step 2166463: loss 0.0156
[2019-03-23 02:15:05,906] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 136500, global step 2166464: learning rate 0.0010
[2019-03-23 02:15:10,643] A3C_AGENT_WORKER-Thread-15 INFO:Local step 135500, global step 2168695: loss 0.0809
[2019-03-23 02:15:10,647] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 135500, global step 2168695: learning rate 0.0010
[2019-03-23 02:15:11,511] A3C_AGENT_WORKER-Thread-3 INFO:Local step 136500, global step 2169102: loss 0.0098
[2019-03-23 02:15:11,513] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 136500, global step 2169102: learning rate 0.0010
[2019-03-23 02:15:12,444] A3C_AGENT_WORKER-Thread-9 INFO:Local step 136000, global step 2169538: loss 0.0756
[2019-03-23 02:15:12,447] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 136000, global step 2169539: learning rate 0.0010
[2019-03-23 02:15:12,659] A3C_AGENT_WORKER-Thread-14 INFO:Local step 136000, global step 2169642: loss 0.1535
[2019-03-23 02:15:12,661] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 136000, global step 2169642: learning rate 0.0010
[2019-03-23 02:15:13,244] A3C_AGENT_WORKER-Thread-20 INFO:Local step 135500, global step 2169911: loss 0.0030
[2019-03-23 02:15:13,248] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 135500, global step 2169911: learning rate 0.0010
[2019-03-23 02:15:15,777] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:15:15,784] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4179
[2019-03-23 02:15:15,789] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.35, 68.5, 1.0, 2.0, 0.2608340950569788, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 283214.9152164622, 283214.9152164625, 89975.03620160664], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2586600.0000, 
sim time next is 2587200.0000, 
raw observation next is [18.26666666666667, 70.0, 1.0, 2.0, 0.2636876296146968, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 286314.2087899313, 286314.2087899316, 91415.85391766849], 
processed observation next is [1.0, 0.9565217391304348, 0.4666666666666668, 0.7, 1.0, 1.0, 0.07960953701837095, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10604229955182641, 0.10604229955182652, 0.22296549736016705], 
reward next is 0.7770, 
noisyNet noise sample is [array([0.12149701], dtype=float32), 0.84450877]. 
=============================================
[2019-03-23 02:15:18,752] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:15:18,760] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9422
[2019-03-23 02:15:18,769] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.83333333333334, 41.0, 1.0, 2.0, 0.4898208125427576, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 531985.8137416075, 531985.8137416075, 101847.8688554584], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1781400.0000, 
sim time next is 1782000.0000, 
raw observation next is [20.0, 40.0, 1.0, 2.0, 0.4838806423513903, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 525530.8114034265, 525530.8114034268, 101184.7788317587], 
processed observation next is [1.0, 0.6521739130434783, 0.5454545454545454, 0.4, 1.0, 1.0, 0.3548508029392378, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1946410412605283, 0.19464104126052845, 0.24679214349209438], 
reward next is 0.7532, 
noisyNet noise sample is [array([0.23475212], dtype=float32), -0.3777582]. 
=============================================
[2019-03-23 02:15:18,785] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[77.28292 ]
 [77.16516 ]
 [77.092995]
 [77.012596]
 [77.05308 ]], R is [[77.47608185]
 [77.45291138]
 [77.43138885]
 [77.41246033]
 [77.39339447]].
[2019-03-23 02:15:18,825] A3C_AGENT_WORKER-Thread-19 INFO:Local step 135500, global step 2172539: loss 0.0102
[2019-03-23 02:15:18,828] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 135500, global step 2172540: learning rate 0.0010
[2019-03-23 02:15:19,126] A3C_AGENT_WORKER-Thread-10 INFO:Local step 135500, global step 2172682: loss 0.0147
[2019-03-23 02:15:19,128] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 135500, global step 2172683: learning rate 0.0010
[2019-03-23 02:15:19,308] A3C_AGENT_WORKER-Thread-18 INFO:Local step 135500, global step 2172770: loss 0.0265
[2019-03-23 02:15:19,311] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 135500, global step 2172770: learning rate 0.0010
[2019-03-23 02:15:19,489] A3C_AGENT_WORKER-Thread-17 INFO:Local step 135500, global step 2172855: loss 0.0693
[2019-03-23 02:15:19,492] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 135500, global step 2172855: learning rate 0.0010
[2019-03-23 02:15:19,812] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:15:19,821] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0996
[2019-03-23 02:15:19,826] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.0, 86.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 184359.2246924184, 184359.2246924187, 63858.58081102247], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1820400.0000, 
sim time next is 1821000.0000, 
raw observation next is [11.5, 90.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 178083.7739671096, 178083.7739671099, 62667.1966258046], 
processed observation next is [1.0, 0.043478260869565216, 0.1590909090909091, 0.9033333333333334, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0659569533211517, 0.06595695332115181, 0.1528468210385478], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.801842], dtype=float32), -0.07430042]. 
=============================================
[2019-03-23 02:15:19,839] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[75.11604 ]
 [74.846275]
 [74.56648 ]
 [74.2116  ]
 [74.007225]], R is [[74.55776978]
 [73.81219482]
 [73.07407379]
 [72.34333038]
 [71.61989594]].
[2019-03-23 02:15:19,875] A3C_AGENT_WORKER-Thread-12 INFO:Local step 135500, global step 2173034: loss 0.0124
[2019-03-23 02:15:19,879] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 135500, global step 2173035: learning rate 0.0010
[2019-03-23 02:15:20,092] A3C_AGENT_WORKER-Thread-16 INFO:Local step 135500, global step 2173135: loss 0.0458
[2019-03-23 02:15:20,094] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 135500, global step 2173136: learning rate 0.0010
[2019-03-23 02:15:20,385] A3C_AGENT_WORKER-Thread-2 INFO:Local step 136000, global step 2173277: loss 0.2734
[2019-03-23 02:15:20,387] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 136000, global step 2173277: learning rate 0.0010
[2019-03-23 02:15:20,477] A3C_AGENT_WORKER-Thread-22 INFO:Local step 135500, global step 2173320: loss 0.0062
[2019-03-23 02:15:20,478] A3C_AGENT_WORKER-Thread-11 INFO:Local step 135500, global step 2173320: loss 0.0010
[2019-03-23 02:15:20,479] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 135500, global step 2173320: learning rate 0.0010
[2019-03-23 02:15:20,481] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 135500, global step 2173320: learning rate 0.0010
[2019-03-23 02:15:20,850] A3C_AGENT_WORKER-Thread-13 INFO:Local step 135500, global step 2173494: loss 0.0735
[2019-03-23 02:15:20,851] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 135500, global step 2173494: learning rate 0.0010
[2019-03-23 02:15:21,348] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:15:21,358] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1815
[2019-03-23 02:15:21,363] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 47.0, 1.0, 2.0, 0.3889351460329371, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 440291.0786250086, 440291.0786250086, 125034.9360639475], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2128800.0000, 
sim time next is 2129400.0000, 
raw observation next is [27.0, 48.0, 1.0, 2.0, 0.394204882053245, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 446883.246091154, 446883.246091154, 125933.2057965111], 
processed observation next is [0.0, 0.6521739130434783, 0.8636363636363636, 0.48, 1.0, 1.0, 0.24275610256655622, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16551231336709407, 0.16551231336709407, 0.3071541604792954], 
reward next is 0.6928, 
noisyNet noise sample is [array([1.91497], dtype=float32), -0.8459622]. 
=============================================
[2019-03-23 02:15:22,741] A3C_AGENT_WORKER-Thread-21 INFO:Local step 137000, global step 2174398: loss 0.0003
[2019-03-23 02:15:22,742] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 137000, global step 2174398: learning rate 0.0010
[2019-03-23 02:15:24,016] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-23 02:15:24,018] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 02:15:24,018] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:15:24,019] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 02:15:24,020] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:15:24,020] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 02:15:24,021] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:15:24,021] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 02:15:24,022] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 02:15:24,024] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:15:24,025] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:15:24,045] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run88
[2019-03-23 02:15:24,071] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run88
[2019-03-23 02:15:24,098] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run88
[2019-03-23 02:15:24,098] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run88
[2019-03-23 02:15:24,149] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run88
[2019-03-23 02:15:39,992] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.06015964], dtype=float32), -0.08208379]
[2019-03-23 02:15:39,993] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [31.7, 46.0, 1.0, 2.0, 0.6817735784164475, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 772754.9473772643, 772754.9473772639, 173322.5917089926]
[2019-03-23 02:15:39,994] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 02:15:39,998] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.49957060940007003
[2019-03-23 02:15:43,193] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.06015964], dtype=float32), -0.08208379]
[2019-03-23 02:15:43,195] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.7, 92.0, 1.0, 2.0, 0.4098160773411623, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 463677.0392973978, 463677.0392973975, 131133.4938605954]
[2019-03-23 02:15:43,195] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 02:15:43,200] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.33302787701440406
[2019-03-23 02:15:47,710] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.06015964], dtype=float32), -0.08208379]
[2019-03-23 02:15:47,713] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [28.05427703666667, 50.99922475666666, 1.0, 2.0, 0.8262421813208202, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 943025.4582921584, 943025.4582921584, 190503.7473928989]
[2019-03-23 02:15:47,713] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 02:15:47,717] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.599217610282442
[2019-03-23 02:15:55,984] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.06015964], dtype=float32), -0.08208379]
[2019-03-23 02:15:55,985] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.307061755, 88.10907661, 1.0, 2.0, 0.3836819423541613, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 430809.9551887451, 430809.9551887446, 126926.495087832]
[2019-03-23 02:15:55,986] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 02:15:55,990] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.35715926941984844
[2019-03-23 02:15:58,228] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.06015964], dtype=float32), -0.08208379]
[2019-03-23 02:15:58,230] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.16666666666667, 63.33333333333334, 1.0, 2.0, 0.8209982658027105, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 906318.842456075, 906318.8424560752, 166402.2273282422]
[2019-03-23 02:15:58,231] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 02:15:58,238] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.528798912864535
[2019-03-23 02:16:10,369] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.06015964], dtype=float32), -0.08208379]
[2019-03-23 02:16:10,370] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.5, 41.16666666666667, 1.0, 2.0, 0.3083648346660949, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 95.55338769695034, 334819.8036043394, 334819.8036043387, 104242.9038275523]
[2019-03-23 02:16:10,371] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 02:16:10,375] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.9125932061188681
[2019-03-23 02:16:21,527] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.06015964], dtype=float32), -0.08208379]
[2019-03-23 02:16:21,530] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [26.2, 65.0, 1.0, 2.0, 0.4963904231378973, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 566114.7103628834, 566114.710362883, 145835.6231251092]
[2019-03-23 02:16:21,532] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 02:16:21,534] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.1836761263609964
[2019-03-23 02:16:27,880] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.06015964], dtype=float32), -0.08208379]
[2019-03-23 02:16:27,882] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.60722311666667, 69.04622737833333, 1.0, 2.0, 0.3069506004572579, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 333283.8148536415, 333283.8148536411, 102744.9430494402]
[2019-03-23 02:16:27,883] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 02:16:27,886] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.7758399482114124
[2019-03-23 02:16:28,590] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.06015964], dtype=float32), -0.08208379]
[2019-03-23 02:16:28,591] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.10281362666667, 77.35314128, 1.0, 2.0, 0.3072200944700756, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 333576.5098975804, 333576.5098975807, 112925.8332381246]
[2019-03-23 02:16:28,592] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 02:16:28,595] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.12079717595493378
[2019-03-23 02:16:33,633] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.06015964], dtype=float32), -0.08208379]
[2019-03-23 02:16:33,635] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.8, 44.0, 1.0, 2.0, 0.3173596559617428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 344589.1007885188, 344589.1007885188, 116676.7099235228]
[2019-03-23 02:16:33,636] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 02:16:33,638] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.7244395097799013
[2019-03-23 02:17:01,015] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.06015964], dtype=float32), -0.08208379]
[2019-03-23 02:17:01,017] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [15.5, 78.0, 1.0, 2.0, 0.220767808806341, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 239700.0285763683, 239700.0285763683, 76508.2122914095]
[2019-03-23 02:17:01,018] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 02:17:01,021] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.1183287547495332
[2019-03-23 02:17:11,792] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8509.7184 1773701116.8024 173.0000
[2019-03-23 02:17:12,225] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8595.3099 1706074232.0561 465.0000
[2019-03-23 02:17:12,362] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9059.4942 1656316253.3799 80.0000
[2019-03-23 02:17:12,490] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8572.7457 1683431468.5083 214.0000
[2019-03-23 02:17:12,521] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8854.9574 1663902404.7778 105.0000
[2019-03-23 02:17:13,541] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 2175000, evaluation results [2175000.0, 8509.718437251891, 1773701116.8024025, 173.0, 9059.494152790281, 1656316253.3798783, 80.0, 8854.957448082614, 1663902404.7778378, 105.0, 8595.309948762033, 1706074232.0561063, 465.0, 8572.74574444999, 1683431468.5082529, 214.0]
[2019-03-23 02:17:14,134] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:17:14,145] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5626
[2019-03-23 02:17:14,152] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.16666666666667, 68.0, 1.0, 2.0, 0.248021745359481, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 269299.3527213861, 269299.3527213861, 86581.7700521077], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1901400.0000, 
sim time next is 1902000.0000, 
raw observation next is [18.33333333333334, 68.0, 1.0, 2.0, 0.2521278623497449, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 273758.9853008479, 273758.9853008479, 88308.30742989256], 
processed observation next is [1.0, 0.0, 0.46969696969696995, 0.68, 1.0, 1.0, 0.06515982793718109, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10139221677809182, 0.10139221677809182, 0.2153861156826648], 
reward next is 0.7846, 
noisyNet noise sample is [array([0.2467486], dtype=float32), -0.057576016]. 
=============================================
[2019-03-23 02:17:14,173] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[80.61473]
 [81.27802]
 [82.57767]
 [82.57633]
 [82.56727]], R is [[80.32620239]
 [80.31176758]
 [80.30027771]
 [80.28720856]
 [80.27249146]].
[2019-03-23 02:17:16,973] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.7481318e-22 1.0072157e-13 1.7836560e-18 0.0000000e+00 1.0000000e+00], sum to 1.0000
[2019-03-23 02:17:16,979] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0196
[2019-03-23 02:17:16,983] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.33333333333333, 65.33333333333333, 1.0, 2.0, 0.2529240597416321, 1.0, 2.0, 0.2529240597416321, 1.0, 2.0, 0.5119916829175899, 6.9112, 6.9112, 77.3421103, 864625.5127497637, 864625.5127497637, 241757.4905603274], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1946400.0000, 
sim time next is 1947000.0000, 
raw observation next is [25.66666666666667, 63.16666666666666, 1.0, 2.0, 0.2452430258722806, 1.0, 2.0, 0.2452430258722806, 1.0, 2.0, 0.4963092514050509, 6.911199999999999, 6.9112, 77.3421103, 838658.5785822029, 838658.5785822032, 239026.6423861895], 
processed observation next is [1.0, 0.5217391304347826, 0.8030303030303032, 0.6316666666666666, 1.0, 1.0, 0.05655378234035075, 1.0, 1.0, 0.05655378234035075, 1.0, 1.0, 0.2804417877215013, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.31061428836377886, 0.31061428836377897, 0.5829918106980232], 
reward next is 0.4170, 
noisyNet noise sample is [array([-1.3318605], dtype=float32), -1.6983013]. 
=============================================
[2019-03-23 02:17:16,996] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[53.75574 ]
 [52.390594]
 [50.809483]
 [48.81826 ]
 [48.11943 ]], R is [[54.47422791]
 [54.33983231]
 [54.18566513]
 [54.00417709]
 [53.75525284]].
[2019-03-23 02:17:17,290] A3C_AGENT_WORKER-Thread-15 INFO:Local step 136000, global step 2176776: loss 0.0871
[2019-03-23 02:17:17,296] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 136000, global step 2176777: learning rate 0.0010
[2019-03-23 02:17:17,855] A3C_AGENT_WORKER-Thread-3 INFO:Local step 137000, global step 2177037: loss 0.0136
[2019-03-23 02:17:17,857] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 137000, global step 2177037: learning rate 0.0010
[2019-03-23 02:17:18,808] A3C_AGENT_WORKER-Thread-9 INFO:Local step 136500, global step 2177490: loss 0.1309
[2019-03-23 02:17:18,812] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 136500, global step 2177490: learning rate 0.0010
[2019-03-23 02:17:18,975] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00
 1.04618446e-32], sum to 1.0000
[2019-03-23 02:17:18,988] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1646
[2019-03-23 02:17:18,992] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 60.0, 1.0, 2.0, 0.3379402139418386, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 372696.9819903087, 372696.981990309, 115850.5923385222], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1975800.0000, 
sim time next is 1976400.0000, 
raw observation next is [22.0, 60.0, 1.0, 2.0, 0.3369303425928311, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 371578.5029490732, 371578.5029490732, 115773.0945511864], 
processed observation next is [1.0, 0.9130434782608695, 0.6363636363636364, 0.6, 1.0, 1.0, 0.17116292824103888, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13762166775891602, 0.13762166775891602, 0.28237340134435707], 
reward next is 0.7176, 
noisyNet noise sample is [array([-1.0270118], dtype=float32), -0.44341025]. 
=============================================
[2019-03-23 02:17:18,998] A3C_AGENT_WORKER-Thread-14 INFO:Local step 136500, global step 2177581: loss 0.1228
[2019-03-23 02:17:19,000] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 136500, global step 2177581: learning rate 0.0010
[2019-03-23 02:17:19,820] A3C_AGENT_WORKER-Thread-20 INFO:Local step 136000, global step 2177962: loss 0.0690
[2019-03-23 02:17:19,826] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 136000, global step 2177964: learning rate 0.0010
[2019-03-23 02:17:25,246] A3C_AGENT_WORKER-Thread-19 INFO:Local step 136000, global step 2180539: loss 0.0039
[2019-03-23 02:17:25,251] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 136000, global step 2180540: learning rate 0.0010
[2019-03-23 02:17:25,760] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:17:25,769] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7756
[2019-03-23 02:17:25,778] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 91.0, 1.0, 2.0, 0.2075792287084974, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 225377.1277029504, 225377.1277029501, 74795.78442021983], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2093400.0000, 
sim time next is 2094000.0000, 
raw observation next is [14.0, 92.0, 1.0, 2.0, 0.2106513761663518, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 228713.4661285006, 228713.4661285003, 75462.56329061836], 
processed observation next is [0.0, 0.21739130434782608, 0.2727272727272727, 0.92, 1.0, 1.0, 0.01331422020793973, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08470869115870393, 0.08470869115870382, 0.18405503241614235], 
reward next is 0.8159, 
noisyNet noise sample is [array([-0.562103], dtype=float32), 0.16958445]. 
=============================================
[2019-03-23 02:17:25,790] A3C_AGENT_WORKER-Thread-10 INFO:Local step 136000, global step 2180795: loss 0.0002
[2019-03-23 02:17:25,795] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 136000, global step 2180797: learning rate 0.0010
[2019-03-23 02:17:25,802] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[74.57456]
 [74.6813 ]
 [74.74088]
 [74.79739]
 [74.75962]], R is [[74.52154541]
 [74.59390259]
 [74.66711426]
 [74.7408905 ]
 [73.9934845 ]].
[2019-03-23 02:17:25,816] A3C_AGENT_WORKER-Thread-18 INFO:Local step 136000, global step 2180808: loss 0.0004
[2019-03-23 02:17:25,817] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 136000, global step 2180808: learning rate 0.0010
[2019-03-23 02:17:25,995] A3C_AGENT_WORKER-Thread-17 INFO:Local step 136000, global step 2180893: loss 0.0014
[2019-03-23 02:17:26,001] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 136000, global step 2180895: learning rate 0.0010
[2019-03-23 02:17:26,217] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.5750879e-38 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 02:17:26,227] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8328
[2019-03-23 02:17:26,234] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 92.33333333333334, 1.0, 2.0, 0.5493116277500281, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 626303.7593775381, 626303.7593775381, 148308.400253889], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2960400.0000, 
sim time next is 2961000.0000, 
raw observation next is [22.5, 91.5, 1.0, 2.0, 0.5514712014379658, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 628659.4517007879, 628659.4517007879, 148711.536472957], 
processed observation next is [1.0, 0.2608695652173913, 0.6590909090909091, 0.915, 1.0, 1.0, 0.4393390017974572, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23283683396325477, 0.23283683396325477, 0.3627110645681878], 
reward next is 0.6373, 
noisyNet noise sample is [array([-0.8018676], dtype=float32), -0.12291565]. 
=============================================
[2019-03-23 02:17:26,256] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[61.94778 ]
 [61.940826]
 [62.447525]
 [62.321487]
 [62.120586]], R is [[61.91747284]
 [61.93656921]
 [61.95458603]
 [61.98995209]
 [62.02425766]].
[2019-03-23 02:17:26,375] A3C_AGENT_WORKER-Thread-12 INFO:Local step 136000, global step 2181071: loss 0.0184
[2019-03-23 02:17:26,379] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 136000, global step 2181071: learning rate 0.0010
[2019-03-23 02:17:26,573] A3C_AGENT_WORKER-Thread-16 INFO:Local step 136000, global step 2181162: loss 0.0018
[2019-03-23 02:17:26,577] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 136000, global step 2181163: learning rate 0.0010
[2019-03-23 02:17:26,598] A3C_AGENT_WORKER-Thread-2 INFO:Local step 136500, global step 2181173: loss 0.1884
[2019-03-23 02:17:26,601] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 136500, global step 2181174: learning rate 0.0010
[2019-03-23 02:17:26,838] A3C_AGENT_WORKER-Thread-11 INFO:Local step 136000, global step 2181288: loss 0.0052
[2019-03-23 02:17:26,842] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 136000, global step 2181290: learning rate 0.0010
[2019-03-23 02:17:26,926] A3C_AGENT_WORKER-Thread-22 INFO:Local step 136000, global step 2181330: loss 0.0073
[2019-03-23 02:17:26,928] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 136000, global step 2181330: learning rate 0.0010
[2019-03-23 02:17:27,354] A3C_AGENT_WORKER-Thread-13 INFO:Local step 136000, global step 2181530: loss 0.0022
[2019-03-23 02:17:27,355] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 136000, global step 2181530: learning rate 0.0010
[2019-03-23 02:17:27,531] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:17:27,538] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8798
[2019-03-23 02:17:27,545] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.66666666666667, 55.16666666666666, 1.0, 2.0, 0.4128086259231634, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 468625.4113804636, 468625.4113804639, 128141.7443008568], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2139000.0000, 
sim time next is 2139600.0000, 
raw observation next is [25.33333333333334, 56.33333333333334, 1.0, 2.0, 0.4097488300159914, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 464867.4573486973, 464867.4573486973, 127638.7069875927], 
processed observation next is [0.0, 0.782608695652174, 0.7878787878787882, 0.5633333333333335, 1.0, 1.0, 0.2621860375199892, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17217313235136936, 0.17217313235136936, 0.31131391948193343], 
reward next is 0.6887, 
noisyNet noise sample is [array([1.5263369], dtype=float32), 0.64811176]. 
=============================================
[2019-03-23 02:17:29,226] A3C_AGENT_WORKER-Thread-21 INFO:Local step 137500, global step 2182414: loss 0.3011
[2019-03-23 02:17:29,228] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 137500, global step 2182414: learning rate 0.0010
[2019-03-23 02:17:30,504] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:17:30,520] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9250
[2019-03-23 02:17:30,525] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.7, 94.5, 1.0, 2.0, 0.2453953701568885, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 266446.8815422074, 266446.8815422074, 83864.94092023533], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2176200.0000, 
sim time next is 2176800.0000, 
raw observation next is [14.6, 94.66666666666666, 1.0, 2.0, 0.2433297415176441, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 264203.4415010862, 264203.4415010859, 83101.83278522779], 
processed observation next is [1.0, 0.17391304347826086, 0.3, 0.9466666666666665, 1.0, 1.0, 0.054162176897055124, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09785312648188378, 0.09785312648188366, 0.20268739703714095], 
reward next is 0.7973, 
noisyNet noise sample is [array([-0.11629152], dtype=float32), -1.1886113]. 
=============================================
[2019-03-23 02:17:34,072] A3C_AGENT_WORKER-Thread-15 INFO:Local step 136500, global step 2184699: loss 0.0233
[2019-03-23 02:17:34,081] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 136500, global step 2184700: learning rate 0.0010
[2019-03-23 02:17:35,130] A3C_AGENT_WORKER-Thread-3 INFO:Local step 137500, global step 2185201: loss 0.1130
[2019-03-23 02:17:35,133] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 137500, global step 2185202: learning rate 0.0010
[2019-03-23 02:17:35,733] A3C_AGENT_WORKER-Thread-9 INFO:Local step 137000, global step 2185487: loss 0.0084
[2019-03-23 02:17:35,736] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 137000, global step 2185487: learning rate 0.0010
[2019-03-23 02:17:35,876] A3C_AGENT_WORKER-Thread-14 INFO:Local step 137000, global step 2185553: loss 0.0118
[2019-03-23 02:17:35,880] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 137000, global step 2185556: learning rate 0.0010
[2019-03-23 02:17:36,027] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:17:36,036] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7411
[2019-03-23 02:17:36,043] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 49.0, 1.0, 2.0, 0.5001314945042153, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 543190.3218613229, 543190.3218613229, 107978.4670898305], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2295600.0000, 
sim time next is 2296200.0000, 
raw observation next is [20.0, 49.0, 1.0, 2.0, 0.5024452479352619, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 545704.6885190962, 545704.6885190962, 108260.9432683935], 
processed observation next is [1.0, 0.5652173913043478, 0.5454545454545454, 0.49, 1.0, 1.0, 0.37805655991907733, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20211284759966527, 0.20211284759966527, 0.26405108114242315], 
reward next is 0.7359, 
noisyNet noise sample is [array([0.14614494], dtype=float32), 1.7205665]. 
=============================================
[2019-03-23 02:17:36,642] A3C_AGENT_WORKER-Thread-20 INFO:Local step 136500, global step 2185919: loss 0.0264
[2019-03-23 02:17:36,644] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 136500, global step 2185919: learning rate 0.0010
[2019-03-23 02:17:37,305] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:17:37,311] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4069
[2019-03-23 02:17:37,319] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 51.66666666666667, 1.0, 2.0, 0.5086547818659425, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 552452.682329391, 552452.682329391, 111165.9043593869], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2301600.0000, 
sim time next is 2302200.0000, 
raw observation next is [20.0, 51.0, 1.0, 2.0, 0.5130285871090096, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 557205.8184282902, 557205.8184282904, 110966.5127910866], 
processed observation next is [1.0, 0.6521739130434783, 0.5454545454545454, 0.51, 1.0, 1.0, 0.3912857338862619, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20637252534381118, 0.20637252534381126, 0.2706500311977722], 
reward next is 0.7293, 
noisyNet noise sample is [array([2.3398361], dtype=float32), 0.31224263]. 
=============================================
[2019-03-23 02:17:42,183] A3C_AGENT_WORKER-Thread-19 INFO:Local step 136500, global step 2188515: loss 0.0034
[2019-03-23 02:17:42,186] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 136500, global step 2188515: learning rate 0.0010
[2019-03-23 02:17:42,558] A3C_AGENT_WORKER-Thread-10 INFO:Local step 136500, global step 2188690: loss 0.0154
[2019-03-23 02:17:42,562] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 136500, global step 2188690: learning rate 0.0010
[2019-03-23 02:17:42,757] A3C_AGENT_WORKER-Thread-17 INFO:Local step 136500, global step 2188788: loss 0.0059
[2019-03-23 02:17:42,759] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 136500, global step 2188788: learning rate 0.0010
[2019-03-23 02:17:42,883] A3C_AGENT_WORKER-Thread-18 INFO:Local step 136500, global step 2188846: loss 0.0075
[2019-03-23 02:17:42,884] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 136500, global step 2188846: learning rate 0.0010
[2019-03-23 02:17:43,342] A3C_AGENT_WORKER-Thread-12 INFO:Local step 136500, global step 2189062: loss 0.0123
[2019-03-23 02:17:43,345] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 136500, global step 2189063: learning rate 0.0010
[2019-03-23 02:17:43,487] A3C_AGENT_WORKER-Thread-2 INFO:Local step 137000, global step 2189131: loss 0.0748
[2019-03-23 02:17:43,491] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 137000, global step 2189133: learning rate 0.0010
[2019-03-23 02:17:43,547] A3C_AGENT_WORKER-Thread-16 INFO:Local step 136500, global step 2189161: loss 0.0601
[2019-03-23 02:17:43,550] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 136500, global step 2189163: learning rate 0.0010
[2019-03-23 02:17:43,723] A3C_AGENT_WORKER-Thread-22 INFO:Local step 136500, global step 2189250: loss 0.0124
[2019-03-23 02:17:43,728] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 136500, global step 2189251: learning rate 0.0010
[2019-03-23 02:17:43,805] A3C_AGENT_WORKER-Thread-11 INFO:Local step 136500, global step 2189288: loss 0.0224
[2019-03-23 02:17:43,807] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 136500, global step 2189288: learning rate 0.0010
[2019-03-23 02:17:44,107] A3C_AGENT_WORKER-Thread-13 INFO:Local step 136500, global step 2189429: loss 0.0091
[2019-03-23 02:17:44,108] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 136500, global step 2189429: learning rate 0.0010
[2019-03-23 02:17:46,530] A3C_AGENT_WORKER-Thread-21 INFO:Local step 138000, global step 2190578: loss 0.0682
[2019-03-23 02:17:46,532] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 138000, global step 2190579: learning rate 0.0010
[2019-03-23 02:17:47,938] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:17:47,945] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7504
[2019-03-23 02:17:47,951] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.2143298987349975, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 232708.355323927, 232708.3553239267, 75127.54057129007], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2504400.0000, 
sim time next is 2505000.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.2136661935365249, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 231987.5665831442, 231987.5665831439, 75060.324892402], 
processed observation next is [1.0, 1.0, 0.22727272727272727, 1.0, 1.0, 1.0, 0.017082741920656126, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08592132095672007, 0.08592132095671996, 0.1830739631522], 
reward next is 0.8169, 
noisyNet noise sample is [array([-1.0228881], dtype=float32), -0.1740287]. 
=============================================
[2019-03-23 02:17:47,965] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[81.52106 ]
 [81.51512 ]
 [81.51853 ]
 [81.522285]
 [81.55552 ]], R is [[81.54199219]
 [81.54333496]
 [81.54455566]
 [81.54576874]
 [81.54740143]].
[2019-03-23 02:17:50,909] A3C_AGENT_WORKER-Thread-15 INFO:Local step 137000, global step 2192650: loss 0.1102
[2019-03-23 02:17:50,914] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 137000, global step 2192652: learning rate 0.0010
[2019-03-23 02:17:52,045] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:17:52,053] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2385
[2019-03-23 02:17:52,057] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 84.0, 1.0, 2.0, 0.3426487211170299, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 379378.8442141851, 379378.8442141854, 116784.2464309554], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2685600.0000, 
sim time next is 2686200.0000, 
raw observation next is [18.66666666666667, 84.5, 1.0, 2.0, 0.3398974301352336, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 375828.3432836352, 375828.3432836352, 116374.084847034], 
processed observation next is [0.0, 0.08695652173913043, 0.4848484848484851, 0.845, 1.0, 1.0, 0.174871787669042, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13919568269764268, 0.13919568269764268, 0.2838392313342293], 
reward next is 0.7162, 
noisyNet noise sample is [array([0.10261633], dtype=float32), -0.58984405]. 
=============================================
[2019-03-23 02:17:52,534] A3C_AGENT_WORKER-Thread-3 INFO:Local step 138000, global step 2193403: loss 0.0471
[2019-03-23 02:17:52,537] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 138000, global step 2193404: learning rate 0.0010
[2019-03-23 02:17:53,053] A3C_AGENT_WORKER-Thread-9 INFO:Local step 137500, global step 2193648: loss 0.2306
[2019-03-23 02:17:53,056] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 137500, global step 2193648: learning rate 0.0010
[2019-03-23 02:17:53,098] A3C_AGENT_WORKER-Thread-14 INFO:Local step 137500, global step 2193666: loss 0.0737
[2019-03-23 02:17:53,101] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 137500, global step 2193666: learning rate 0.0010
[2019-03-23 02:17:53,482] A3C_AGENT_WORKER-Thread-20 INFO:Local step 137000, global step 2193844: loss 0.0092
[2019-03-23 02:17:53,486] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 137000, global step 2193846: learning rate 0.0010
[2019-03-23 02:17:54,671] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:17:54,679] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9811
[2019-03-23 02:17:54,689] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 73.0, 1.0, 2.0, 0.3822483048432085, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 431749.2831178434, 431749.2831178437, 123833.5876164804], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2624400.0000, 
sim time next is 2625000.0000, 
raw observation next is [22.33333333333334, 71.0, 1.0, 2.0, 0.3842191887820897, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 434165.8187564478, 434165.8187564478, 124120.9165182527], 
processed observation next is [0.0, 0.391304347826087, 0.6515151515151518, 0.71, 1.0, 1.0, 0.23027398597761212, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16080215509498066, 0.16080215509498066, 0.30273394272744564], 
reward next is 0.6973, 
noisyNet noise sample is [array([-0.04905702], dtype=float32), 1.8672435]. 
=============================================
[2019-03-23 02:17:54,706] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[64.38815]
 [64.34795]
 [64.38438]
 [64.43298]
 [64.50122]], R is [[64.45427704]
 [64.50769806]
 [64.56180573]
 [64.61660004]
 [64.67208099]].
[2019-03-23 02:17:58,902] A3C_AGENT_WORKER-Thread-19 INFO:Local step 137000, global step 2196415: loss 0.0826
[2019-03-23 02:17:58,906] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 137000, global step 2196415: learning rate 0.0010
[2019-03-23 02:17:59,403] A3C_AGENT_WORKER-Thread-10 INFO:Local step 137000, global step 2196648: loss 0.0025
[2019-03-23 02:17:59,408] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 137000, global step 2196648: learning rate 0.0010
[2019-03-23 02:17:59,515] A3C_AGENT_WORKER-Thread-17 INFO:Local step 137000, global step 2196701: loss 0.0325
[2019-03-23 02:17:59,519] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 137000, global step 2196702: learning rate 0.0010
[2019-03-23 02:17:59,629] A3C_AGENT_WORKER-Thread-18 INFO:Local step 137000, global step 2196756: loss 0.0271
[2019-03-23 02:17:59,633] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 137000, global step 2196758: learning rate 0.0010
[2019-03-23 02:18:00,010] A3C_AGENT_WORKER-Thread-12 INFO:Local step 137000, global step 2196938: loss 0.0445
[2019-03-23 02:18:00,013] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 137000, global step 2196938: learning rate 0.0010
[2019-03-23 02:18:00,455] A3C_AGENT_WORKER-Thread-16 INFO:Local step 137000, global step 2197144: loss 0.0619
[2019-03-23 02:18:00,456] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 137000, global step 2197144: learning rate 0.0010
[2019-03-23 02:18:00,503] A3C_AGENT_WORKER-Thread-11 INFO:Local step 137000, global step 2197167: loss 0.0176
[2019-03-23 02:18:00,510] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 137000, global step 2197169: learning rate 0.0010
[2019-03-23 02:18:00,511] A3C_AGENT_WORKER-Thread-22 INFO:Local step 137000, global step 2197171: loss 0.0475
[2019-03-23 02:18:00,517] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 137000, global step 2197171: learning rate 0.0010
[2019-03-23 02:18:00,900] A3C_AGENT_WORKER-Thread-13 INFO:Local step 137000, global step 2197351: loss 0.0041
[2019-03-23 02:18:00,901] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 137000, global step 2197351: learning rate 0.0010
[2019-03-23 02:18:00,994] A3C_AGENT_WORKER-Thread-2 INFO:Local step 137500, global step 2197397: loss 0.0435
[2019-03-23 02:18:00,995] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 137500, global step 2197397: learning rate 0.0010
[2019-03-23 02:18:03,920] A3C_AGENT_WORKER-Thread-21 INFO:Local step 138500, global step 2198771: loss 10.7322
[2019-03-23 02:18:03,923] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 138500, global step 2198772: learning rate 0.0010
[2019-03-23 02:18:06,529] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 02:18:06,531] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 02:18:06,532] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:18:06,533] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 02:18:06,535] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 02:18:06,536] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 02:18:06,536] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:18:06,537] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 02:18:06,537] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:18:06,537] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:18:06,540] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:18:06,566] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run89
[2019-03-23 02:18:06,592] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run89
[2019-03-23 02:18:06,592] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run89
[2019-03-23 02:18:06,641] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run89
[2019-03-23 02:18:06,661] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run89
[2019-03-23 02:18:30,206] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.08536667], dtype=float32), -0.10353793]
[2019-03-23 02:18:30,208] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [24.33169054, 66.74433057, 1.0, 2.0, 0.4555843052854038, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 518862.1228273414, 518862.1228273411, 138217.9265022919]
[2019-03-23 02:18:30,209] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 02:18:30,213] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.8656947771015356
[2019-03-23 02:18:34,692] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.08536667], dtype=float32), -0.10353793]
[2019-03-23 02:18:34,695] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [25.0, 57.0, 1.0, 2.0, 0.5181788327590124, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9453047431478392, 6.939592965041038, 6.9112, 77.3283878341948, 1138058.482391898, 1128837.037099582, 248494.0566767475]
[2019-03-23 02:18:34,698] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 02:18:34,701] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.8211177e-35 1.0000000e+00 7.2346652e-33 0.0000000e+00 2.3018011e-20], sampled 0.4595753497818995
[2019-03-23 02:18:34,701] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1138058.482391898 W.
[2019-03-23 02:18:38,384] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.08536667], dtype=float32), -0.10353793]
[2019-03-23 02:18:38,386] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.85, 50.0, 1.0, 2.0, 0.2588696561786596, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 281065.8113313877, 281065.8113313877, 83490.61546835907]
[2019-03-23 02:18:38,387] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 02:18:38,390] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.6696783555801348
[2019-03-23 02:18:40,958] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08536667], dtype=float32), -0.10353793]
[2019-03-23 02:18:40,958] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [17.21666666666667, 67.33333333333333, 1.0, 2.0, 0.2553200844459992, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 277211.0013650384, 277211.0013650384, 86150.71348175291]
[2019-03-23 02:18:40,960] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 02:18:40,963] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.42581479272067535
[2019-03-23 02:18:49,828] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.08536667], dtype=float32), -0.10353793]
[2019-03-23 02:18:49,829] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.01666666666667, 90.0, 1.0, 2.0, 0.4545638259667507, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 517677.6477270091, 517677.6477270087, 138085.8623833248]
[2019-03-23 02:18:49,831] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 02:18:49,833] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.5335067710779295
[2019-03-23 02:19:19,759] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.08536667], dtype=float32), -0.10353793]
[2019-03-23 02:19:19,760] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [30.32017794666666, 46.74479110666667, 1.0, 2.0, 0.4921786299920025, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 561110.6322070962, 561110.6322070959, 145666.0206082968]
[2019-03-23 02:19:19,761] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 02:19:19,764] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.0044099093738118045
[2019-03-23 02:19:54,600] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9059.4942 1656316253.3799 80.0000
[2019-03-23 02:19:54,909] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8572.7541 1683719637.8140 214.0000
[2019-03-23 02:19:55,000] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8595.3099 1706074232.0561 465.0000
[2019-03-23 02:19:55,070] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8505.3716 1775367457.9896 168.0000
[2019-03-23 02:19:55,131] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8854.9574 1663902404.7778 105.0000
[2019-03-23 02:19:56,149] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 2200000, evaluation results [2200000.0, 8505.37155686623, 1775367457.9896488, 168.0, 9059.494152790281, 1656316253.3798783, 80.0, 8854.957448082614, 1663902404.7778378, 105.0, 8595.309948762033, 1706074232.0561063, 465.0, 8572.754131484187, 1683719637.8139696, 214.0]
[2019-03-23 02:19:57,105] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 2.4309572e-33], sum to 1.0000
[2019-03-23 02:19:57,115] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9728
[2019-03-23 02:19:57,123] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.83333333333334, 83.83333333333334, 1.0, 2.0, 0.5669750009836448, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 646056.8948542551, 646056.8948542554, 146666.2647171816], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2862600.0000, 
sim time next is 2863200.0000, 
raw observation next is [21.66666666666667, 84.66666666666667, 1.0, 2.0, 0.5296156720497727, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 603354.7997337166, 603354.7997337166, 142124.1513018849], 
processed observation next is [1.0, 0.13043478260869565, 0.6212121212121214, 0.8466666666666667, 1.0, 1.0, 0.4120195900622158, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22346474064211727, 0.22346474064211727, 0.34664427146801197], 
reward next is 0.6534, 
noisyNet noise sample is [array([1.5926017], dtype=float32), 1.6351846]. 
=============================================
[2019-03-23 02:19:57,724] A3C_AGENT_WORKER-Thread-15 INFO:Local step 137500, global step 2200754: loss 0.4093
[2019-03-23 02:19:57,730] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 137500, global step 2200756: learning rate 0.0010
[2019-03-23 02:19:59,314] A3C_AGENT_WORKER-Thread-3 INFO:Local step 138500, global step 2201503: loss 3.9986
[2019-03-23 02:19:59,318] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 138500, global step 2201503: learning rate 0.0010
[2019-03-23 02:19:59,480] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 5.2851429e-34 0.0000000e+00 1.9367558e-38], sum to 1.0000
[2019-03-23 02:19:59,488] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6470
[2019-03-23 02:19:59,492] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.83333333333334, 83.83333333333334, 1.0, 2.0, 0.4969385891601844, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 567059.6942647174, 567059.6942647174, 140695.1418669269], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2879400.0000, 
sim time next is 2880000.0000, 
raw observation next is [23.0, 83.0, 1.0, 2.0, 0.5069065155643865, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 578431.4464531984, 578431.4464531984, 141959.8472037588], 
processed observation next is [1.0, 0.34782608695652173, 0.6818181818181818, 0.83, 1.0, 1.0, 0.3836331444554831, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21423386905674016, 0.21423386905674016, 0.3462435297652654], 
reward next is 0.6538, 
noisyNet noise sample is [array([-0.7671336], dtype=float32), 0.8866606]. 
=============================================
[2019-03-23 02:19:59,507] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[55.18874 ]
 [55.071648]
 [54.947643]
 [55.07601 ]
 [55.16518 ]], R is [[55.26164246]
 [55.36586761]
 [55.46781921]
 [55.56539536]
 [55.66369247]].
[2019-03-23 02:19:59,607] A3C_AGENT_WORKER-Thread-9 INFO:Local step 138000, global step 2201640: loss 0.0392
[2019-03-23 02:19:59,608] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 138000, global step 2201640: learning rate 0.0010
[2019-03-23 02:19:59,624] A3C_AGENT_WORKER-Thread-14 INFO:Local step 138000, global step 2201648: loss 0.0055
[2019-03-23 02:19:59,628] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 138000, global step 2201648: learning rate 0.0010
[2019-03-23 02:20:00,331] A3C_AGENT_WORKER-Thread-20 INFO:Local step 137500, global step 2201980: loss 0.0322
[2019-03-23 02:20:00,335] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 137500, global step 2201980: learning rate 0.0010
[2019-03-23 02:20:03,005] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:20:03,017] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4222
[2019-03-23 02:20:03,024] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 88.0, 1.0, 2.0, 0.3340228342795715, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 367659.3139318851, 367659.3139318848, 115285.1314058683], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3372000.0000, 
sim time next is 3372600.0000, 
raw observation next is [18.0, 88.0, 1.0, 2.0, 0.3333412929145349, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 366907.0275929371, 366907.0275929371, 115233.9195509946], 
processed observation next is [1.0, 0.0, 0.45454545454545453, 0.88, 1.0, 1.0, 0.16667661614316862, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13589149170108783, 0.13589149170108783, 0.28105834036827954], 
reward next is 0.7189, 
noisyNet noise sample is [array([0.6828444], dtype=float32), -0.19775376]. 
=============================================
[2019-03-23 02:20:05,567] A3C_AGENT_WORKER-Thread-19 INFO:Local step 137500, global step 2204442: loss 0.0532
[2019-03-23 02:20:05,569] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 137500, global step 2204442: learning rate 0.0010
[2019-03-23 02:20:05,969] A3C_AGENT_WORKER-Thread-10 INFO:Local step 137500, global step 2204635: loss 0.1826
[2019-03-23 02:20:05,972] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 137500, global step 2204635: learning rate 0.0010
[2019-03-23 02:20:06,097] A3C_AGENT_WORKER-Thread-17 INFO:Local step 137500, global step 2204689: loss 0.1774
[2019-03-23 02:20:06,099] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 137500, global step 2204690: learning rate 0.0010
[2019-03-23 02:20:06,220] A3C_AGENT_WORKER-Thread-18 INFO:Local step 137500, global step 2204748: loss 1.0162
[2019-03-23 02:20:06,223] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 137500, global step 2204749: learning rate 0.0010
[2019-03-23 02:20:06,709] A3C_AGENT_WORKER-Thread-12 INFO:Local step 137500, global step 2204980: loss 0.7255
[2019-03-23 02:20:06,710] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 137500, global step 2204980: learning rate 0.0010
[2019-03-23 02:20:07,146] A3C_AGENT_WORKER-Thread-16 INFO:Local step 137500, global step 2205184: loss 0.2631
[2019-03-23 02:20:07,148] A3C_AGENT_WORKER-Thread-22 INFO:Local step 137500, global step 2205184: loss 0.0245
[2019-03-23 02:20:07,151] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 137500, global step 2205185: learning rate 0.0010
[2019-03-23 02:20:07,151] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 137500, global step 2205184: learning rate 0.0010
[2019-03-23 02:20:07,191] A3C_AGENT_WORKER-Thread-11 INFO:Local step 137500, global step 2205206: loss 0.0437
[2019-03-23 02:20:07,194] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 137500, global step 2205208: learning rate 0.0010
[2019-03-23 02:20:07,349] A3C_AGENT_WORKER-Thread-2 INFO:Local step 138000, global step 2205280: loss 0.0034
[2019-03-23 02:20:07,354] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 138000, global step 2205280: learning rate 0.0010
[2019-03-23 02:20:07,467] A3C_AGENT_WORKER-Thread-13 INFO:Local step 137500, global step 2205335: loss 0.1319
[2019-03-23 02:20:07,470] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 137500, global step 2205335: learning rate 0.0010
[2019-03-23 02:20:10,439] A3C_AGENT_WORKER-Thread-21 INFO:Local step 139000, global step 2206731: loss 0.1358
[2019-03-23 02:20:10,441] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 139000, global step 2206731: learning rate 0.0010
[2019-03-23 02:20:14,595] A3C_AGENT_WORKER-Thread-15 INFO:Local step 138000, global step 2208688: loss 0.0033
[2019-03-23 02:20:14,601] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 138000, global step 2208688: learning rate 0.0010
[2019-03-23 02:20:16,028] A3C_AGENT_WORKER-Thread-3 INFO:Local step 139000, global step 2209364: loss 0.0004
[2019-03-23 02:20:16,031] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 139000, global step 2209366: learning rate 0.0010
[2019-03-23 02:20:16,625] A3C_AGENT_WORKER-Thread-9 INFO:Local step 138500, global step 2209645: loss 7.6025
[2019-03-23 02:20:16,628] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 138500, global step 2209646: learning rate 0.0010
[2019-03-23 02:20:16,705] A3C_AGENT_WORKER-Thread-14 INFO:Local step 138500, global step 2209687: loss 0.1023
[2019-03-23 02:20:16,708] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 138500, global step 2209687: learning rate 0.0010
[2019-03-23 02:20:16,925] A3C_AGENT_WORKER-Thread-20 INFO:Local step 138000, global step 2209789: loss 0.0250
[2019-03-23 02:20:16,927] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 138000, global step 2209790: learning rate 0.0010
[2019-03-23 02:20:19,636] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:20:19,646] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3065
[2019-03-23 02:20:19,651] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333334, 76.33333333333334, 1.0, 2.0, 0.3533930402507439, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 393915.8460559675, 393915.8460559675, 118705.3046134815], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3224400.0000, 
sim time next is 3225000.0000, 
raw observation next is [20.66666666666666, 74.66666666666667, 1.0, 2.0, 0.3556773879603636, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 397007.5033661535, 397007.5033661535, 119127.0486331016], 
processed observation next is [0.0, 0.30434782608695654, 0.5757575757575755, 0.7466666666666667, 1.0, 1.0, 0.19459673495045446, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14703981606153835, 0.14703981606153835, 0.29055377715390635], 
reward next is 0.7094, 
noisyNet noise sample is [array([0.39651576], dtype=float32), 0.77024215]. 
=============================================
[2019-03-23 02:20:19,667] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[69.96037 ]
 [69.984764]
 [70.01712 ]
 [70.04516 ]
 [70.10765 ]], R is [[69.96186829]
 [69.97272491]
 [69.98478699]
 [69.99809265]
 [70.01261139]].
[2019-03-23 02:20:22,723] A3C_AGENT_WORKER-Thread-19 INFO:Local step 138000, global step 2212517: loss 0.0043
[2019-03-23 02:20:22,726] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 138000, global step 2212519: learning rate 0.0010
[2019-03-23 02:20:22,928] A3C_AGENT_WORKER-Thread-10 INFO:Local step 138000, global step 2212613: loss 0.0005
[2019-03-23 02:20:22,931] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 138000, global step 2212613: learning rate 0.0010
[2019-03-23 02:20:23,083] A3C_AGENT_WORKER-Thread-17 INFO:Local step 138000, global step 2212686: loss 0.0037
[2019-03-23 02:20:23,085] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 138000, global step 2212686: learning rate 0.0010
[2019-03-23 02:20:23,290] A3C_AGENT_WORKER-Thread-18 INFO:Local step 138000, global step 2212779: loss 0.0089
[2019-03-23 02:20:23,294] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 138000, global step 2212779: learning rate 0.0010
[2019-03-23 02:20:23,727] A3C_AGENT_WORKER-Thread-12 INFO:Local step 138000, global step 2212985: loss 0.0002
[2019-03-23 02:20:23,731] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 138000, global step 2212987: learning rate 0.0010
[2019-03-23 02:20:23,888] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:20:23,899] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3850
[2019-03-23 02:20:23,903] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 59.0, 1.0, 2.0, 0.3225367695721487, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 354646.4579193803, 354646.4579193803, 114302.7784930912], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3321600.0000, 
sim time next is 3322200.0000, 
raw observation next is [22.0, 59.5, 1.0, 2.0, 0.3249437920874471, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 357764.4028082985, 357764.4028082988, 114655.6928182868], 
processed observation next is [0.0, 0.43478260869565216, 0.6363636363636364, 0.595, 1.0, 1.0, 0.15617974010930888, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1325053343734439, 0.132505334373444, 0.27964803126411414], 
reward next is 0.7204, 
noisyNet noise sample is [array([-1.8540524], dtype=float32), -0.14400312]. 
=============================================
[2019-03-23 02:20:24,046] A3C_AGENT_WORKER-Thread-22 INFO:Local step 138000, global step 2213139: loss 0.0037
[2019-03-23 02:20:24,047] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 138000, global step 2213139: learning rate 0.0010
[2019-03-23 02:20:24,077] A3C_AGENT_WORKER-Thread-16 INFO:Local step 138000, global step 2213149: loss 0.0001
[2019-03-23 02:20:24,080] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 138000, global step 2213149: learning rate 0.0010
[2019-03-23 02:20:24,202] A3C_AGENT_WORKER-Thread-11 INFO:Local step 138000, global step 2213211: loss 0.0017
[2019-03-23 02:20:24,204] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 138000, global step 2213211: learning rate 0.0010
[2019-03-23 02:20:24,507] A3C_AGENT_WORKER-Thread-13 INFO:Local step 138000, global step 2213350: loss 0.0094
[2019-03-23 02:20:24,513] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 138000, global step 2213351: learning rate 0.0010
[2019-03-23 02:20:24,633] A3C_AGENT_WORKER-Thread-2 INFO:Local step 138500, global step 2213404: loss 1.2271
[2019-03-23 02:20:24,637] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 138500, global step 2213406: learning rate 0.0010
[2019-03-23 02:20:26,056] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:20:26,064] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8571
[2019-03-23 02:20:26,070] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 94.0, 1.0, 2.0, 0.3572020362967074, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 397403.6892100045, 397403.6892100045, 118688.4342339064], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4089600.0000, 
sim time next is 4090200.0000, 
raw observation next is [18.16666666666667, 94.00000000000001, 1.0, 2.0, 0.4282818102065404, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 477613.9502228837, 477613.9502228837, 125141.4406050031], 
processed observation next is [1.0, 0.34782608695652173, 0.4621212121212123, 0.9400000000000002, 1.0, 1.0, 0.28535226275817543, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1768940556381051, 0.1768940556381051, 0.3052230258658612], 
reward next is 0.6948, 
noisyNet noise sample is [array([0.7723445], dtype=float32), -2.3866482]. 
=============================================
[2019-03-23 02:20:27,191] A3C_AGENT_WORKER-Thread-21 INFO:Local step 139500, global step 2214617: loss 4.1527
[2019-03-23 02:20:27,192] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 139500, global step 2214618: learning rate 0.0010
[2019-03-23 02:20:31,901] A3C_AGENT_WORKER-Thread-15 INFO:Local step 138500, global step 2216832: loss 2.7893
[2019-03-23 02:20:31,904] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 138500, global step 2216832: learning rate 0.0010
[2019-03-23 02:20:32,640] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.6558480e-30 8.5361254e-13 7.3257499e-27 0.0000000e+00 1.0000000e+00], sum to 1.0000
[2019-03-23 02:20:32,643] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9485
[2019-03-23 02:20:32,647] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.0, 69.0, 1.0, 2.0, 0.3047406999788484, 1.0, 2.0, 0.3047406999788484, 1.0, 2.0, 0.6127851359949308, 6.911199999999999, 6.9112, 77.3421103, 1043345.984922688, 1043345.984922689, 252367.5927172682], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4208400.0000, 
sim time next is 4209000.0000, 
raw observation next is [23.0, 69.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3803925010652922, 6.9112, 6.9112, 77.3421103, 648244.1680051454, 648244.1680051454, 216468.1545438432], 
processed observation next is [1.0, 0.7391304347826086, 0.6818181818181818, 0.69, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.11484643009327461, 0.0, 0.0, 0.5085185399722538, 0.2400904325944983, 0.2400904325944983, 0.52797110864352], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.1532142], dtype=float32), 0.11105047]. 
=============================================
[2019-03-23 02:20:32,675] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[58.190983]
 [57.37658 ]
 [55.838852]
 [55.150974]
 [54.401287]], R is [[60.26591492]
 [60.04772568]
 [59.8384285 ]
 [59.62150574]
 [59.48662949]].
[2019-03-23 02:20:32,818] A3C_AGENT_WORKER-Thread-3 INFO:Local step 139500, global step 2217264: loss 1.5000
[2019-03-23 02:20:32,820] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 139500, global step 2217264: learning rate 0.0010
[2019-03-23 02:20:32,977] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:20:32,990] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1583
[2019-03-23 02:20:32,994] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 77.0, 1.0, 2.0, 0.2807665859427075, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 304864.4932518947, 304864.4932518947, 101571.9620143177], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3897600.0000, 
sim time next is 3898200.0000, 
raw observation next is [18.0, 77.0, 1.0, 2.0, 0.2807091101047064, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 304802.0647644539, 304802.0647644539, 101571.1596409499], 
processed observation next is [0.0, 0.08695652173913043, 0.45454545454545453, 0.77, 1.0, 1.0, 0.10088638763088298, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11288965361646441, 0.11288965361646441, 0.2477345357096339], 
reward next is 0.7523, 
noisyNet noise sample is [array([-1.1628104], dtype=float32), 0.43378952]. 
=============================================
[2019-03-23 02:20:33,692] A3C_AGENT_WORKER-Thread-9 INFO:Local step 139000, global step 2217675: loss 0.0009
[2019-03-23 02:20:33,696] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 139000, global step 2217678: learning rate 0.0010
[2019-03-23 02:20:33,742] A3C_AGENT_WORKER-Thread-14 INFO:Local step 139000, global step 2217697: loss 0.0022
[2019-03-23 02:20:33,746] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 139000, global step 2217698: learning rate 0.0010
[2019-03-23 02:20:34,231] A3C_AGENT_WORKER-Thread-20 INFO:Local step 138500, global step 2217929: loss 1.7588
[2019-03-23 02:20:34,232] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 138500, global step 2217929: learning rate 0.0010
[2019-03-23 02:20:34,634] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:20:34,643] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3796
[2019-03-23 02:20:34,649] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333334, 52.00000000000001, 1.0, 2.0, 0.3208090372892299, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 353047.3084053565, 353047.3084053562, 114292.0327639807], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3928200.0000, 
sim time next is 3928800.0000, 
raw observation next is [23.66666666666667, 51.0, 1.0, 2.0, 0.321504929173512, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 354521.8972500759, 354521.8972500759, 114615.1687457561], 
processed observation next is [0.0, 0.4782608695652174, 0.7121212121212124, 0.51, 1.0, 1.0, 0.15188116146688996, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.131304406388917, 0.131304406388917, 0.27954919206281975], 
reward next is 0.7205, 
noisyNet noise sample is [array([-1.1741498], dtype=float32), 0.33777523]. 
=============================================
[2019-03-23 02:20:35,045] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.0000000e+00 9.5723165e-33 0.0000000e+00 0.0000000e+00 1.0000000e+00], sum to 1.0000
[2019-03-23 02:20:35,056] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2194
[2019-03-23 02:20:35,062] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.5, 72.0, 1.0, 2.0, 0.3978126745498556, 1.0, 2.0, 0.3978126745498556, 1.0, 2.0, 0.8049259840914562, 6.911199999999999, 6.9112, 77.3421103, 1341954.757944128, 1341954.757944128, 306296.481384136], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3497400.0000, 
sim time next is 3498000.0000, 
raw observation next is [26.66666666666667, 71.33333333333333, 1.0, 2.0, 0.3952441123329791, 1.0, 2.0, 0.3952441123329791, 1.0, 2.0, 0.7997288081280234, 6.9112, 6.9112, 77.3421103, 1333279.943513694, 1333279.943513694, 305072.2983738228], 
processed observation next is [1.0, 0.4782608695652174, 0.8484848484848487, 0.7133333333333333, 1.0, 1.0, 0.2440551404162239, 1.0, 1.0, 0.2440551404162239, 1.0, 1.0, 0.7138982973257477, 0.0, 0.0, 0.5085185399722538, 0.4938073864865533, 0.4938073864865533, 0.7440787765215191], 
reward next is 0.2559, 
noisyNet noise sample is [array([2.9592335], dtype=float32), 1.7276537]. 
=============================================
[2019-03-23 02:20:35,074] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[53.482056]
 [53.36912 ]
 [53.01488 ]
 [51.978516]
 [51.465523]], R is [[53.95969009]
 [53.67302704]
 [53.40304184]
 [53.13352966]
 [52.83773041]].
[2019-03-23 02:20:39,692] A3C_AGENT_WORKER-Thread-19 INFO:Local step 138500, global step 2220508: loss 1.7148
[2019-03-23 02:20:39,695] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 138500, global step 2220509: learning rate 0.0010
[2019-03-23 02:20:39,751] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.7646219e-29 1.0000000e+00 5.4512172e-30 8.1579913e-32 1.5480990e-21], sum to 1.0000
[2019-03-23 02:20:39,763] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8361
[2019-03-23 02:20:39,774] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1434789.489198138 W.
[2019-03-23 02:20:39,785] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.0, 94.0, 1.0, 2.0, 0.784198079124183, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9815134028748278, 6.9112, 6.9112, 77.32846344354104, 1434789.489198138, 1434789.489198138, 309471.2569378552], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3585600.0000, 
sim time next is 3586200.0000, 
raw observation next is [23.5, 92.33333333333334, 1.0, 2.0, 0.4077544921505213, 1.0, 1.0, 0.4077544921505213, 1.0, 2.0, 0.8250420533567925, 6.9112, 6.9112, 77.3421103, 1375532.546754154, 1375532.546754154, 311101.3935061213], 
processed observation next is [1.0, 0.5217391304347826, 0.7045454545454546, 0.9233333333333335, 1.0, 1.0, 0.2596931151881516, 1.0, 0.5, 0.2596931151881516, 1.0, 1.0, 0.7500600762239894, 0.0, 0.0, 0.5085185399722538, 0.5094564987978348, 0.5094564987978348, 0.7587838866002958], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.1405244], dtype=float32), -0.68205065]. 
=============================================
[2019-03-23 02:20:39,953] A3C_AGENT_WORKER-Thread-10 INFO:Local step 138500, global step 2220630: loss 0.7697
[2019-03-23 02:20:39,956] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 138500, global step 2220631: learning rate 0.0010
[2019-03-23 02:20:40,146] A3C_AGENT_WORKER-Thread-17 INFO:Local step 138500, global step 2220721: loss 1.8303
[2019-03-23 02:20:40,151] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 138500, global step 2220722: learning rate 0.0010
[2019-03-23 02:20:40,402] A3C_AGENT_WORKER-Thread-18 INFO:Local step 138500, global step 2220839: loss 0.2407
[2019-03-23 02:20:40,403] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 138500, global step 2220841: learning rate 0.0010
[2019-03-23 02:20:40,749] A3C_AGENT_WORKER-Thread-12 INFO:Local step 138500, global step 2221000: loss -2.1534
[2019-03-23 02:20:40,753] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 138500, global step 2221001: learning rate 0.0010
[2019-03-23 02:20:40,877] A3C_AGENT_WORKER-Thread-22 INFO:Local step 138500, global step 2221061: loss 4.2886
[2019-03-23 02:20:40,885] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 138500, global step 2221061: learning rate 0.0010
[2019-03-23 02:20:40,937] A3C_AGENT_WORKER-Thread-16 INFO:Local step 138500, global step 2221090: loss 1.1804
[2019-03-23 02:20:40,938] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 138500, global step 2221090: learning rate 0.0010
[2019-03-23 02:20:41,292] A3C_AGENT_WORKER-Thread-11 INFO:Local step 138500, global step 2221256: loss 1.1594
[2019-03-23 02:20:41,297] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 138500, global step 2221256: learning rate 0.0010
[2019-03-23 02:20:41,444] A3C_AGENT_WORKER-Thread-13 INFO:Local step 138500, global step 2221329: loss 1.4676
[2019-03-23 02:20:41,448] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 138500, global step 2221330: learning rate 0.0010
[2019-03-23 02:20:41,654] A3C_AGENT_WORKER-Thread-2 INFO:Local step 139000, global step 2221430: loss 0.0072
[2019-03-23 02:20:41,656] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 139000, global step 2221430: learning rate 0.0010
[2019-03-23 02:20:43,962] A3C_AGENT_WORKER-Thread-21 INFO:Local step 140000, global step 2222517: loss 0.0002
[2019-03-23 02:20:43,969] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 140000, global step 2222520: learning rate 0.0010
[2019-03-23 02:20:44,758] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.00000e+00 1.00000e+00 5.19901e-37 0.00000e+00 0.00000e+00], sum to 1.0000
[2019-03-23 02:20:44,766] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1666
[2019-03-23 02:20:44,774] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.16666666666667, 68.66666666666667, 1.0, 2.0, 0.5220791722057588, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 594533.9234486866, 594533.9234486866, 145666.5067474474], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3700200.0000, 
sim time next is 3700800.0000, 
raw observation next is [26.0, 70.0, 1.0, 2.0, 0.5258029303338891, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 598638.7378771971, 598638.7378771971, 146229.4423128414], 
processed observation next is [1.0, 0.8695652173913043, 0.8181818181818182, 0.7, 1.0, 1.0, 0.40725366291736137, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22171805106562856, 0.22171805106562856, 0.3566571763727839], 
reward next is 0.6433, 
noisyNet noise sample is [array([-2.6006155], dtype=float32), -0.96036065]. 
=============================================
[2019-03-23 02:20:48,923] A3C_AGENT_WORKER-Thread-15 INFO:Local step 139000, global step 2224868: loss 0.0002
[2019-03-23 02:20:48,928] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 139000, global step 2224868: learning rate 0.0010
[2019-03-23 02:20:49,208] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-23 02:20:49,209] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 02:20:49,210] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 02:20:49,210] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:20:49,211] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 02:20:49,211] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:20:49,212] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:20:49,214] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 02:20:49,215] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:20:49,216] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 02:20:49,216] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:20:49,242] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run90
[2019-03-23 02:20:49,265] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run90
[2019-03-23 02:20:49,293] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run90
[2019-03-23 02:20:49,316] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run90
[2019-03-23 02:20:49,339] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run90
[2019-03-23 02:20:58,585] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.24508397], dtype=float32), -0.07149562]
[2019-03-23 02:20:58,586] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.44877502, 65.68655261666667, 1.0, 2.0, 0.2716896372595325, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 294988.4266273707, 294988.4266273707, 93489.76693076559]
[2019-03-23 02:20:58,587] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 02:20:58,592] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.5531934504184992
[2019-03-23 02:21:12,594] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.24508397], dtype=float32), -0.07149562]
[2019-03-23 02:21:12,594] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.0, 81.33333333333334, 1.0, 2.0, 0.4065921121212294, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 460146.5506299282, 460146.5506299285, 126573.6444686746]
[2019-03-23 02:21:12,595] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 02:21:12,596] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.6240503957261911
[2019-03-23 02:22:33,236] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8471.5010 1790078345.8984 103.0000
[2019-03-23 02:22:33,493] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9065.4520 1656820368.2691 62.0000
[2019-03-23 02:22:33,598] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8618.8240 1710193041.7420 349.0000
[2019-03-23 02:22:33,761] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8581.3502 1687391348.3369 147.0000
[2019-03-23 02:22:33,812] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8861.7646 1665008371.8975 76.0000
[2019-03-23 02:22:34,829] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 2225000, evaluation results [2225000.0, 8471.50101965292, 1790078345.8983989, 103.0, 9065.451984940664, 1656820368.2690945, 62.0, 8861.764630675998, 1665008371.8974876, 76.0, 8618.823995994213, 1710193041.7419534, 349.0, 8581.35018303139, 1687391348.3369377, 147.0]
[2019-03-23 02:22:35,378] A3C_AGENT_WORKER-Thread-3 INFO:Local step 140000, global step 2225259: loss 0.0010
[2019-03-23 02:22:35,381] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 140000, global step 2225262: learning rate 0.0010
[2019-03-23 02:22:35,779] A3C_AGENT_WORKER-Thread-14 INFO:Local step 139500, global step 2225449: loss 5.9858
[2019-03-23 02:22:35,782] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 139500, global step 2225449: learning rate 0.0010
[2019-03-23 02:22:35,911] A3C_AGENT_WORKER-Thread-9 INFO:Local step 139500, global step 2225510: loss 5.4176
[2019-03-23 02:22:35,916] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 139500, global step 2225512: learning rate 0.0010
[2019-03-23 02:22:37,021] A3C_AGENT_WORKER-Thread-20 INFO:Local step 139000, global step 2226037: loss 0.0001
[2019-03-23 02:22:37,024] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 139000, global step 2226038: learning rate 0.0010
[2019-03-23 02:22:42,168] A3C_AGENT_WORKER-Thread-19 INFO:Local step 139000, global step 2228467: loss 0.0088
[2019-03-23 02:22:42,175] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 139000, global step 2228467: learning rate 0.0010
[2019-03-23 02:22:42,549] A3C_AGENT_WORKER-Thread-10 INFO:Local step 139000, global step 2228644: loss 0.0408
[2019-03-23 02:22:42,550] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 139000, global step 2228644: learning rate 0.0010
[2019-03-23 02:22:42,925] A3C_AGENT_WORKER-Thread-17 INFO:Local step 139000, global step 2228822: loss 0.0005
[2019-03-23 02:22:42,931] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 139000, global step 2228823: learning rate 0.0010
[2019-03-23 02:22:42,987] A3C_AGENT_WORKER-Thread-18 INFO:Local step 139000, global step 2228851: loss 0.0037
[2019-03-23 02:22:42,989] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 139000, global step 2228851: learning rate 0.0010
[2019-03-23 02:22:43,400] A3C_AGENT_WORKER-Thread-16 INFO:Local step 139000, global step 2229046: loss 0.0001
[2019-03-23 02:22:43,403] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 139000, global step 2229047: learning rate 0.0010
[2019-03-23 02:22:43,504] A3C_AGENT_WORKER-Thread-12 INFO:Local step 139000, global step 2229093: loss 0.0140
[2019-03-23 02:22:43,507] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 139000, global step 2229093: learning rate 0.0010
[2019-03-23 02:22:43,770] A3C_AGENT_WORKER-Thread-22 INFO:Local step 139000, global step 2229219: loss 0.0313
[2019-03-23 02:22:43,772] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 139000, global step 2229219: learning rate 0.0010
[2019-03-23 02:22:43,956] A3C_AGENT_WORKER-Thread-13 INFO:Local step 139000, global step 2229303: loss 0.0019
[2019-03-23 02:22:43,960] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 139000, global step 2229303: learning rate 0.0010
[2019-03-23 02:22:44,028] A3C_AGENT_WORKER-Thread-11 INFO:Local step 139000, global step 2229341: loss 0.0010
[2019-03-23 02:22:44,031] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 139000, global step 2229341: learning rate 0.0010
[2019-03-23 02:22:44,145] A3C_AGENT_WORKER-Thread-2 INFO:Local step 139500, global step 2229391: loss 5.5534
[2019-03-23 02:22:44,147] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 139500, global step 2229391: learning rate 0.0010
[2019-03-23 02:22:46,456] A3C_AGENT_WORKER-Thread-21 INFO:Local step 140500, global step 2230482: loss 22.3142
[2019-03-23 02:22:46,458] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 140500, global step 2230483: learning rate 0.0010
[2019-03-23 02:22:47,580] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:22:47,587] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5507
[2019-03-23 02:22:47,592] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 94.00000000000001, 1.0, 2.0, 0.4614734026214813, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 526347.2341572782, 526347.2341572782, 135628.7829817845], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4831800.0000, 
sim time next is 4832400.0000, 
raw observation next is [21.0, 94.0, 1.0, 2.0, 0.4616754692772964, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 526575.7806500107, 526575.7806500107, 135645.9061201781], 
processed observation next is [1.0, 0.9565217391304348, 0.5909090909090909, 0.94, 1.0, 1.0, 0.32709433659662046, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19502806690741137, 0.19502806690741137, 0.33084367346384896], 
reward next is 0.6692, 
noisyNet noise sample is [array([-1.431543], dtype=float32), -0.062298235]. 
=============================================
[2019-03-23 02:22:51,532] A3C_AGENT_WORKER-Thread-15 INFO:Local step 139500, global step 2232854: loss 1.5870
[2019-03-23 02:22:51,535] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 139500, global step 2232854: learning rate 0.0010
[2019-03-23 02:22:52,569] A3C_AGENT_WORKER-Thread-3 INFO:Local step 140500, global step 2233336: loss -70.0958
[2019-03-23 02:22:52,571] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 140500, global step 2233337: learning rate 0.0010
[2019-03-23 02:22:52,953] A3C_AGENT_WORKER-Thread-14 INFO:Local step 140000, global step 2233517: loss 0.0051
[2019-03-23 02:22:52,954] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 140000, global step 2233517: learning rate 0.0010
[2019-03-23 02:22:53,135] A3C_AGENT_WORKER-Thread-9 INFO:Local step 140000, global step 2233602: loss 0.0006
[2019-03-23 02:22:53,141] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 140000, global step 2233605: learning rate 0.0010
[2019-03-23 02:22:54,053] A3C_AGENT_WORKER-Thread-20 INFO:Local step 139500, global step 2234034: loss 10.8267
[2019-03-23 02:22:54,055] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 139500, global step 2234035: learning rate 0.0010
[2019-03-23 02:22:57,833] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:22:57,840] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7073
[2019-03-23 02:22:57,846] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 94.0, 1.0, 2.0, 0.2187087860551916, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 237463.8860219664, 237463.8860219661, 77153.59588856906], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4598400.0000, 
sim time next is 4599000.0000, 
raw observation next is [14.0, 94.0, 1.0, 2.0, 0.2171041019188843, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 235721.1720064295, 235721.1720064295, 76950.67284745924], 
processed observation next is [1.0, 0.21739130434782608, 0.2727272727272727, 0.94, 1.0, 1.0, 0.021380127398605356, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08730413778015907, 0.08730413778015907, 0.1876845679206323], 
reward next is 0.8123, 
noisyNet noise sample is [array([-0.27708325], dtype=float32), -0.3347228]. 
=============================================
[2019-03-23 02:22:57,868] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[76.11198 ]
 [76.050865]
 [76.00986 ]
 [75.90306 ]
 [75.83744 ]], R is [[76.20549011]
 [76.25525665]
 [76.30340576]
 [76.35165405]
 [76.39755249]].
[2019-03-23 02:22:59,117] A3C_AGENT_WORKER-Thread-19 INFO:Local step 139500, global step 2236422: loss 14.5772
[2019-03-23 02:22:59,118] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 139500, global step 2236422: learning rate 0.0010
[2019-03-23 02:22:59,517] A3C_AGENT_WORKER-Thread-10 INFO:Local step 139500, global step 2236609: loss 13.5932
[2019-03-23 02:22:59,520] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 139500, global step 2236611: learning rate 0.0010
[2019-03-23 02:22:59,748] A3C_AGENT_WORKER-Thread-17 INFO:Local step 139500, global step 2236719: loss 9.6088
[2019-03-23 02:22:59,750] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 139500, global step 2236720: learning rate 0.0010
[2019-03-23 02:22:59,967] A3C_AGENT_WORKER-Thread-18 INFO:Local step 139500, global step 2236821: loss 10.0173
[2019-03-23 02:22:59,970] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 139500, global step 2236822: learning rate 0.0010
[2019-03-23 02:23:00,467] A3C_AGENT_WORKER-Thread-16 INFO:Local step 139500, global step 2237057: loss 21.9113
[2019-03-23 02:23:00,470] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 139500, global step 2237059: learning rate 0.0010
[2019-03-23 02:23:00,496] A3C_AGENT_WORKER-Thread-12 INFO:Local step 139500, global step 2237071: loss 15.8201
[2019-03-23 02:23:00,497] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 139500, global step 2237072: learning rate 0.0010
[2019-03-23 02:23:00,659] A3C_AGENT_WORKER-Thread-22 INFO:Local step 139500, global step 2237150: loss 14.6943
[2019-03-23 02:23:00,660] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 139500, global step 2237150: learning rate 0.0010
[2019-03-23 02:23:01,016] A3C_AGENT_WORKER-Thread-13 INFO:Local step 139500, global step 2237318: loss 20.4075
[2019-03-23 02:23:01,017] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 139500, global step 2237318: learning rate 0.0010
[2019-03-23 02:23:01,037] A3C_AGENT_WORKER-Thread-11 INFO:Local step 139500, global step 2237326: loss 8.9911
[2019-03-23 02:23:01,040] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 139500, global step 2237327: learning rate 0.0010
[2019-03-23 02:23:01,341] A3C_AGENT_WORKER-Thread-2 INFO:Local step 140000, global step 2237471: loss 0.0004
[2019-03-23 02:23:01,345] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 140000, global step 2237472: learning rate 0.0010
[2019-03-23 02:23:02,709] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.00000000e+00 1.00000000e+00 1.02215476e-35 0.00000000e+00
 4.80710379e-23], sum to 1.0000
[2019-03-23 02:23:02,717] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4498
[2019-03-23 02:23:02,729] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666667, 80.0, 1.0, 2.0, 0.4572556989520523, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 521364.2592235688, 521364.2592235688, 134843.7558349885], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4405200.0000, 
sim time next is 4405800.0000, 
raw observation next is [22.58333333333333, 80.5, 1.0, 2.0, 0.4569030265639091, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 520945.4239691026, 520945.4239691026, 134777.9213276618], 
processed observation next is [1.0, 1.0, 0.6628787878787876, 0.805, 1.0, 1.0, 0.3211287832048863, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19294274961818617, 0.19294274961818617, 0.328726637384541], 
reward next is 0.6713, 
noisyNet noise sample is [array([0.07174429], dtype=float32), -0.32903466]. 
=============================================
[2019-03-23 02:23:03,351] A3C_AGENT_WORKER-Thread-21 INFO:Local step 141000, global step 2238417: loss 0.0619
[2019-03-23 02:23:03,354] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 141000, global step 2238418: learning rate 0.0010
[2019-03-23 02:23:04,677] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 2.2332118e-36], sum to 1.0000
[2019-03-23 02:23:04,686] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9343
[2019-03-23 02:23:04,690] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.95, 50.83333333333334, 1.0, 2.0, 0.736830138976502, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 828423.4730449035, 828423.4730449035, 161671.6891784154], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4276200.0000, 
sim time next is 4276800.0000, 
raw observation next is [25.0, 50.0, 1.0, 2.0, 0.8188080572357047, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 919917.3795571381, 919917.3795571381, 172655.2521739741], 
processed observation next is [1.0, 0.5217391304347826, 0.7727272727272727, 0.5, 1.0, 1.0, 0.7735100715446308, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3407101405767178, 0.3407101405767178, 0.4211103711560344], 
reward next is 0.5789, 
noisyNet noise sample is [array([1.2895826], dtype=float32), -2.188839]. 
=============================================
[2019-03-23 02:23:07,627] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.1023435e-31], sum to 1.0000
[2019-03-23 02:23:07,638] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5005
[2019-03-23 02:23:07,644] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 97.0, 1.0, 2.0, 0.4079108068454945, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 456464.2349493925, 456464.2349493925, 124018.9380139027], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4329000.0000, 
sim time next is 4329600.0000, 
raw observation next is [18.0, 96.0, 1.0, 2.0, 0.3870605145154559, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 432423.4380063252, 432423.4380063252, 121891.0049315883], 
processed observation next is [1.0, 0.08695652173913043, 0.45454545454545453, 0.96, 1.0, 1.0, 0.2338256431443199, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16015682889123156, 0.16015682889123156, 0.29729513397948365], 
reward next is 0.7027, 
noisyNet noise sample is [array([0.7625948], dtype=float32), -1.5760499]. 
=============================================
[2019-03-23 02:23:08,623] A3C_AGENT_WORKER-Thread-15 INFO:Local step 140000, global step 2240933: loss 0.0173
[2019-03-23 02:23:08,628] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 140000, global step 2240933: learning rate 0.0010
[2019-03-23 02:23:09,230] A3C_AGENT_WORKER-Thread-3 INFO:Local step 141000, global step 2241216: loss 0.0279
[2019-03-23 02:23:09,232] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 141000, global step 2241217: learning rate 0.0010
[2019-03-23 02:23:09,954] A3C_AGENT_WORKER-Thread-14 INFO:Local step 140500, global step 2241514: loss 0.7078
[2019-03-23 02:23:09,957] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 140500, global step 2241514: learning rate 0.0010
[2019-03-23 02:23:10,165] A3C_AGENT_WORKER-Thread-9 INFO:Local step 140500, global step 2241610: loss 23.7738
[2019-03-23 02:23:10,168] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 140500, global step 2241610: learning rate 0.0010
[2019-03-23 02:23:11,053] A3C_AGENT_WORKER-Thread-20 INFO:Local step 140000, global step 2242027: loss 0.0007
[2019-03-23 02:23:11,056] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 140000, global step 2242028: learning rate 0.0010
[2019-03-23 02:23:15,986] A3C_AGENT_WORKER-Thread-19 INFO:Local step 140000, global step 2244353: loss 0.0162
[2019-03-23 02:23:15,990] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 140000, global step 2244353: learning rate 0.0010
[2019-03-23 02:23:16,529] A3C_AGENT_WORKER-Thread-10 INFO:Local step 140000, global step 2244607: loss 0.0082
[2019-03-23 02:23:16,535] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 140000, global step 2244608: learning rate 0.0010
[2019-03-23 02:23:16,711] A3C_AGENT_WORKER-Thread-17 INFO:Local step 140000, global step 2244692: loss 0.0114
[2019-03-23 02:23:16,713] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 140000, global step 2244692: learning rate 0.0010
[2019-03-23 02:23:17,099] A3C_AGENT_WORKER-Thread-18 INFO:Local step 140000, global step 2244874: loss 0.0060
[2019-03-23 02:23:17,101] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 140000, global step 2244875: learning rate 0.0010
[2019-03-23 02:23:17,394] A3C_AGENT_WORKER-Thread-16 INFO:Local step 140000, global step 2245017: loss 0.0005
[2019-03-23 02:23:17,397] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 140000, global step 2245017: learning rate 0.0010
[2019-03-23 02:23:17,501] A3C_AGENT_WORKER-Thread-12 INFO:Local step 140000, global step 2245071: loss 0.0052
[2019-03-23 02:23:17,503] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 140000, global step 2245071: learning rate 0.0010
[2019-03-23 02:23:17,758] A3C_AGENT_WORKER-Thread-22 INFO:Local step 140000, global step 2245187: loss 0.0003
[2019-03-23 02:23:17,760] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 140000, global step 2245187: learning rate 0.0010
[2019-03-23 02:23:18,143] A3C_AGENT_WORKER-Thread-13 INFO:Local step 140000, global step 2245368: loss 0.0022
[2019-03-23 02:23:18,145] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 140000, global step 2245368: learning rate 0.0010
[2019-03-23 02:23:18,226] A3C_AGENT_WORKER-Thread-11 INFO:Local step 140000, global step 2245408: loss 0.0091
[2019-03-23 02:23:18,227] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 140000, global step 2245408: learning rate 0.0010
[2019-03-23 02:23:18,351] A3C_AGENT_WORKER-Thread-2 INFO:Local step 140500, global step 2245471: loss 0.4619
[2019-03-23 02:23:18,353] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 140500, global step 2245471: learning rate 0.0010
[2019-03-23 02:23:20,581] A3C_AGENT_WORKER-Thread-21 INFO:Local step 141500, global step 2246521: loss 248.2261
[2019-03-23 02:23:20,583] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 141500, global step 2246521: learning rate 0.0010
[2019-03-23 02:23:21,383] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:23:21,396] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5034
[2019-03-23 02:23:21,401] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.3, 93.66666666666666, 1.0, 2.0, 0.4006218562699932, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 452601.3137815783, 452601.3137815783, 125544.1344724193], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5425800.0000, 
sim time next is 5426400.0000, 
raw observation next is [19.2, 94.33333333333334, 1.0, 2.0, 0.3992547469949708, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 450963.7613842101, 450963.7613842098, 125365.3954176857], 
processed observation next is [1.0, 0.8260869565217391, 0.509090909090909, 0.9433333333333335, 1.0, 1.0, 0.2490684337437135, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16702361532748522, 0.1670236153274851, 0.3057692571163066], 
reward next is 0.6942, 
noisyNet noise sample is [array([0.17682937], dtype=float32), 1.1313931]. 
=============================================
[2019-03-23 02:23:25,857] A3C_AGENT_WORKER-Thread-15 INFO:Local step 140500, global step 2249010: loss 91.1887
[2019-03-23 02:23:25,860] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 140500, global step 2249010: learning rate 0.0010
[2019-03-23 02:23:26,674] A3C_AGENT_WORKER-Thread-3 INFO:Local step 141500, global step 2249390: loss 83.2463
[2019-03-23 02:23:26,676] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 141500, global step 2249391: learning rate 0.0010
[2019-03-23 02:23:26,885] A3C_AGENT_WORKER-Thread-14 INFO:Local step 141000, global step 2249490: loss 0.0595
[2019-03-23 02:23:26,889] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 141000, global step 2249491: learning rate 0.0010
[2019-03-23 02:23:27,071] A3C_AGENT_WORKER-Thread-9 INFO:Local step 141000, global step 2249576: loss 0.0265
[2019-03-23 02:23:27,076] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 141000, global step 2249577: learning rate 0.0010
[2019-03-23 02:23:27,953] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 02:23:27,955] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 02:23:27,956] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 02:23:27,956] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:23:27,958] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 02:23:27,957] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:23:27,961] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 02:23:27,960] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 02:23:27,963] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:23:27,961] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:23:27,965] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:23:27,991] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run91
[2019-03-23 02:23:28,018] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run91
[2019-03-23 02:23:28,019] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run91
[2019-03-23 02:23:28,045] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run91
[2019-03-23 02:23:28,095] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run91
[2019-03-23 02:23:31,195] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.1131519], dtype=float32), -0.06553145]
[2019-03-23 02:23:31,196] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.538297605, 41.46706874, 1.0, 2.0, 0.2811175352790712, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 305227.4148736493, 305227.4148736493, 86025.07045667115]
[2019-03-23 02:23:31,198] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 02:23:31,201] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.6212539056920038
[2019-03-23 02:23:40,492] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.1131519], dtype=float32), -0.06553145]
[2019-03-23 02:23:40,494] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.16666666666667, 87.16666666666667, 1.0, 2.0, 0.4076093213860184, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 460796.874983707, 460796.8749837073, 126362.7373423741]
[2019-03-23 02:23:40,498] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 02:23:40,502] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.786457841380392
[2019-03-23 02:23:53,307] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.1131519], dtype=float32), -0.06553145]
[2019-03-23 02:23:53,308] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.06666666666667, 62.66666666666667, 1.0, 2.0, 0.3158584147488428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 345315.0134587779, 345315.0134587776, 117401.4671902024]
[2019-03-23 02:23:53,310] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 02:23:53,312] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.9353826244169875
[2019-03-23 02:24:08,401] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.1131519], dtype=float32), -0.06553145]
[2019-03-23 02:24:08,405] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.65, 87.0, 1.0, 2.0, 0.4530877480966967, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 516464.6555019957, 516464.6555019957, 138555.6230012649]
[2019-03-23 02:24:08,405] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 02:24:08,409] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.19398047095151771
[2019-03-23 02:24:24,158] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.1131519], dtype=float32), -0.06553145]
[2019-03-23 02:24:24,160] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [15.95797314, 83.05015861, 1.0, 2.0, 0.4424621218909354, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 480479.6599184216, 480479.6599184212, 109656.742601855]
[2019-03-23 02:24:24,163] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 02:24:24,165] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.16232947927604158
[2019-03-23 02:24:30,182] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.1131519], dtype=float32), -0.06553145]
[2019-03-23 02:24:30,184] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.7, 76.0, 1.0, 2.0, 0.5199138540541626, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 592513.3440292517, 592513.3440292514, 149227.898393425]
[2019-03-23 02:24:30,187] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 02:24:30,192] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.8167662991587668
[2019-03-23 02:24:32,420] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.1131519], dtype=float32), -0.06553145]
[2019-03-23 02:24:32,423] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [25.96666666666667, 61.0, 1.0, 2.0, 0.687979924623809, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 784979.1237970334, 784979.1237970334, 168510.3242942966]
[2019-03-23 02:24:32,425] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 02:24:32,427] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.8221068121480476
[2019-03-23 02:24:59,834] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.1131519], dtype=float32), -0.06553145]
[2019-03-23 02:24:59,834] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.05, 79.0, 1.0, 2.0, 0.3289080418854363, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 361795.9885302635, 361795.9885302635, 119135.9187752549]
[2019-03-23 02:24:59,835] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 02:24:59,838] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.4526259360798126
[2019-03-23 02:25:03,471] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.1131519], dtype=float32), -0.06553145]
[2019-03-23 02:25:03,473] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [26.45155936, 61.90096264, 1.0, 2.0, 0.5066058828112988, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 577887.7622193892, 577887.7622193889, 146774.2736524161]
[2019-03-23 02:25:03,474] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 02:25:03,480] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.23142924758012018
[2019-03-23 02:25:04,020] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.1131519], dtype=float32), -0.06553145]
[2019-03-23 02:25:04,021] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.33911664666667, 75.27339581999999, 1.0, 2.0, 0.4230457202509622, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 480137.3694916631, 480137.3694916627, 133385.9273851685]
[2019-03-23 02:25:04,023] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 02:25:04,027] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.11785130181747638
[2019-03-23 02:25:16,414] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8573.7387 1685196485.4270 183.0000
[2019-03-23 02:25:16,455] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8484.7678 1782227174.3278 148.0000
[2019-03-23 02:25:16,574] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8855.7542 1663858414.4981 105.0000
[2019-03-23 02:25:16,679] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9060.3047 1656272944.4788 80.0000
[2019-03-23 02:25:16,710] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8594.7458 1706946496.8729 456.0000
[2019-03-23 02:25:17,726] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 2250000, evaluation results [2250000.0, 8484.767828931952, 1782227174.327756, 148.0, 9060.304679780347, 1656272944.478839, 80.0, 8855.754186439062, 1663858414.498091, 105.0, 8594.745791844807, 1706946496.8729115, 456.0, 8573.738669671782, 1685196485.4269586, 183.0]
[2019-03-23 02:25:17,824] A3C_AGENT_WORKER-Thread-20 INFO:Local step 140500, global step 2250054: loss 0.4101
[2019-03-23 02:25:17,826] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 140500, global step 2250054: learning rate 0.0010
[2019-03-23 02:25:20,838] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:25:20,846] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4251
[2019-03-23 02:25:20,854] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 78.0, 1.0, 2.0, 0.3890477806826772, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 438424.6928726733, 438424.6928726733, 123879.0094364239], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4741800.0000, 
sim time next is 4742400.0000, 
raw observation next is [21.0, 78.0, 1.0, 2.0, 0.3869149613184792, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 435995.870744765, 435995.8707447647, 123676.6855286876], 
processed observation next is [1.0, 0.9130434782608695, 0.5909090909090909, 0.78, 1.0, 1.0, 0.23364370164809897, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16147995212769073, 0.16147995212769062, 0.30165045250899414], 
reward next is 0.6983, 
noisyNet noise sample is [array([1.7400894], dtype=float32), -0.4646439]. 
=============================================
[2019-03-23 02:25:22,681] A3C_AGENT_WORKER-Thread-19 INFO:Local step 140500, global step 2252355: loss -8.8105
[2019-03-23 02:25:22,683] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 140500, global step 2252355: learning rate 0.0010
[2019-03-23 02:25:23,134] A3C_AGENT_WORKER-Thread-10 INFO:Local step 140500, global step 2252570: loss 53.0917
[2019-03-23 02:25:23,139] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 140500, global step 2252570: learning rate 0.0010
[2019-03-23 02:25:23,411] A3C_AGENT_WORKER-Thread-17 INFO:Local step 140500, global step 2252697: loss 4.5725
[2019-03-23 02:25:23,414] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 140500, global step 2252698: learning rate 0.0010
[2019-03-23 02:25:23,665] A3C_AGENT_WORKER-Thread-18 INFO:Local step 140500, global step 2252818: loss 1.9957
[2019-03-23 02:25:23,671] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 140500, global step 2252822: learning rate 0.0010
[2019-03-23 02:25:23,998] A3C_AGENT_WORKER-Thread-16 INFO:Local step 140500, global step 2252978: loss 13.1391
[2019-03-23 02:25:24,002] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 140500, global step 2252979: learning rate 0.0010
[2019-03-23 02:25:24,192] A3C_AGENT_WORKER-Thread-12 INFO:Local step 140500, global step 2253069: loss -42.0945
[2019-03-23 02:25:24,196] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 140500, global step 2253070: learning rate 0.0010
[2019-03-23 02:25:24,448] A3C_AGENT_WORKER-Thread-22 INFO:Local step 140500, global step 2253191: loss 0.6410
[2019-03-23 02:25:24,450] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 140500, global step 2253191: learning rate 0.0010
[2019-03-23 02:25:24,775] A3C_AGENT_WORKER-Thread-13 INFO:Local step 140500, global step 2253349: loss 0.2288
[2019-03-23 02:25:24,778] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 140500, global step 2253350: learning rate 0.0010
[2019-03-23 02:25:24,811] A3C_AGENT_WORKER-Thread-2 INFO:Local step 141000, global step 2253364: loss 0.0270
[2019-03-23 02:25:24,816] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 141000, global step 2253365: learning rate 0.0010
[2019-03-23 02:25:24,921] A3C_AGENT_WORKER-Thread-11 INFO:Local step 140500, global step 2253418: loss -87.4020
[2019-03-23 02:25:24,923] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 140500, global step 2253418: learning rate 0.0010
[2019-03-23 02:25:25,025] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 2.3913425e-26], sum to 1.0000
[2019-03-23 02:25:25,032] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2688
[2019-03-23 02:25:25,039] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 99.00000000000001, 1.0, 2.0, 0.3426755535040948, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 378803.324047464, 378803.3240474643, 116547.6019180121], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4939800.0000, 
sim time next is 4940400.0000, 
raw observation next is [17.0, 98.0, 1.0, 2.0, 0.3346953635039078, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 369305.3286415187, 369305.328641519, 115679.5057193969], 
processed observation next is [1.0, 0.17391304347826086, 0.4090909090909091, 0.98, 1.0, 1.0, 0.1683692043798847, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13677975134871065, 0.13677975134871073, 0.282145135900968], 
reward next is 0.7179, 
noisyNet noise sample is [array([0.4455102], dtype=float32), -0.1871755]. 
=============================================
[2019-03-23 02:25:27,491] A3C_AGENT_WORKER-Thread-21 INFO:Local step 142000, global step 2254624: loss 7.2605
[2019-03-23 02:25:27,492] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 142000, global step 2254625: learning rate 0.0010
[2019-03-23 02:25:32,410] A3C_AGENT_WORKER-Thread-15 INFO:Local step 141000, global step 2256948: loss 0.0549
[2019-03-23 02:25:32,413] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 141000, global step 2256948: learning rate 0.0010
[2019-03-23 02:25:32,571] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 2.8773625e-36], sum to 1.0000
[2019-03-23 02:25:32,581] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9398
[2019-03-23 02:25:32,586] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.66666666666667, 76.33333333333334, 1.0, 2.0, 0.575222299540288, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 626649.5870117913, 626649.5870117916, 134516.0848540572], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4963200.0000, 
sim time next is 4963800.0000, 
raw observation next is [18.83333333333333, 74.66666666666667, 1.0, 2.0, 0.5768978054191314, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 627895.3046842897, 627895.3046842897, 134504.7182481926], 
processed observation next is [1.0, 0.43478260869565216, 0.4924242424242422, 0.7466666666666667, 1.0, 1.0, 0.47112225677391417, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23255381654973695, 0.23255381654973695, 0.32806028841022583], 
reward next is 0.6719, 
noisyNet noise sample is [array([0.55191463], dtype=float32), -1.0265447]. 
=============================================
[2019-03-23 02:25:33,285] A3C_AGENT_WORKER-Thread-3 INFO:Local step 142000, global step 2257365: loss 5.0192
[2019-03-23 02:25:33,288] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 142000, global step 2257365: learning rate 0.0010
[2019-03-23 02:25:33,634] A3C_AGENT_WORKER-Thread-14 INFO:Local step 141500, global step 2257527: loss -74.7580
[2019-03-23 02:25:33,638] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 141500, global step 2257528: learning rate 0.0010
[2019-03-23 02:25:34,011] A3C_AGENT_WORKER-Thread-9 INFO:Local step 141500, global step 2257704: loss -243.9565
[2019-03-23 02:25:34,013] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 141500, global step 2257704: learning rate 0.0010
[2019-03-23 02:25:34,630] A3C_AGENT_WORKER-Thread-20 INFO:Local step 141000, global step 2257998: loss 0.0091
[2019-03-23 02:25:34,633] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 141000, global step 2257999: learning rate 0.0010
[2019-03-23 02:25:39,301] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:25:39,310] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4189
[2019-03-23 02:25:39,316] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.5, 54.5, 1.0, 2.0, 0.4240064207110506, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 482801.4742347755, 482801.4742347755, 130529.5046082854], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5077800.0000, 
sim time next is 5078400.0000, 
raw observation next is [26.33333333333334, 55.66666666666667, 1.0, 2.0, 0.4262808864128693, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 485501.9858815597, 485501.9858815597, 130882.0250191078], 
processed observation next is [0.0, 0.782608695652174, 0.8333333333333336, 0.5566666666666668, 1.0, 1.0, 0.2828511080160866, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1798155503265036, 0.1798155503265036, 0.3192244512661166], 
reward next is 0.6808, 
noisyNet noise sample is [array([1.760207], dtype=float32), -0.5460572]. 
=============================================
[2019-03-23 02:25:39,593] A3C_AGENT_WORKER-Thread-19 INFO:Local step 141000, global step 2260347: loss 0.0067
[2019-03-23 02:25:39,594] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 141000, global step 2260347: learning rate 0.0010
[2019-03-23 02:25:39,885] A3C_AGENT_WORKER-Thread-10 INFO:Local step 141000, global step 2260483: loss 0.0222
[2019-03-23 02:25:39,887] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 141000, global step 2260484: learning rate 0.0010
[2019-03-23 02:25:40,250] A3C_AGENT_WORKER-Thread-17 INFO:Local step 141000, global step 2260657: loss 0.0191
[2019-03-23 02:25:40,253] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 141000, global step 2260658: learning rate 0.0010
[2019-03-23 02:25:40,463] A3C_AGENT_WORKER-Thread-18 INFO:Local step 141000, global step 2260757: loss 0.0079
[2019-03-23 02:25:40,465] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 141000, global step 2260757: learning rate 0.0010
[2019-03-23 02:25:40,849] A3C_AGENT_WORKER-Thread-16 INFO:Local step 141000, global step 2260945: loss 0.0196
[2019-03-23 02:25:40,854] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 141000, global step 2260945: learning rate 0.0010
[2019-03-23 02:25:41,192] A3C_AGENT_WORKER-Thread-12 INFO:Local step 141000, global step 2261102: loss 0.0365
[2019-03-23 02:25:41,196] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 141000, global step 2261103: learning rate 0.0010
[2019-03-23 02:25:41,227] A3C_AGENT_WORKER-Thread-22 INFO:Local step 141000, global step 2261120: loss 0.0367
[2019-03-23 02:25:41,229] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 141000, global step 2261121: learning rate 0.0010
[2019-03-23 02:25:41,635] A3C_AGENT_WORKER-Thread-11 INFO:Local step 141000, global step 2261315: loss 0.0192
[2019-03-23 02:25:41,639] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 141000, global step 2261315: learning rate 0.0010
[2019-03-23 02:25:41,648] A3C_AGENT_WORKER-Thread-13 INFO:Local step 141000, global step 2261322: loss 0.0317
[2019-03-23 02:25:41,650] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 141000, global step 2261323: learning rate 0.0010
[2019-03-23 02:25:42,080] A3C_AGENT_WORKER-Thread-2 INFO:Local step 141500, global step 2261527: loss -16.3065
[2019-03-23 02:25:42,087] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 141500, global step 2261527: learning rate 0.0010
[2019-03-23 02:25:44,284] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:25:44,292] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0568
[2019-03-23 02:25:44,297] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.66666666666666, 78.0, 1.0, 2.0, 0.4845303269570365, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 552880.7590074169, 552880.7590074167, 139415.468158776], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5167200.0000, 
sim time next is 5167800.0000, 
raw observation next is [23.5, 78.0, 1.0, 2.0, 0.478207707573754, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 545674.7989602352, 545674.7989602352, 138365.3176042429], 
processed observation next is [0.0, 0.8260869565217391, 0.7045454545454546, 0.78, 1.0, 1.0, 0.3477596344671925, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2021017773926797, 0.2021017773926797, 0.33747638440059247], 
reward next is 0.6625, 
noisyNet noise sample is [array([0.77442473], dtype=float32), 0.03201063]. 
=============================================
[2019-03-23 02:25:44,494] A3C_AGENT_WORKER-Thread-21 INFO:Local step 142500, global step 2262655: loss -256.0872
[2019-03-23 02:25:44,496] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 142500, global step 2262656: learning rate 0.0010
[2019-03-23 02:25:45,031] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:25:45,040] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4807
[2019-03-23 02:25:45,045] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 92.0, 1.0, 2.0, 0.3979866140240945, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 449276.5733919076, 449276.5733919076, 125104.1252526254], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5606400.0000, 
sim time next is 5607000.0000, 
raw observation next is [19.4, 91.5, 1.0, 2.0, 0.3963983772102604, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 447231.157843176, 447231.1578431763, 124818.7418316775], 
processed observation next is [1.0, 0.9130434782608695, 0.5181818181818181, 0.915, 1.0, 1.0, 0.24549797151282546, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16564116957154665, 0.16564116957154676, 0.3044359556870183], 
reward next is 0.6956, 
noisyNet noise sample is [array([-1.170423], dtype=float32), 0.96976024]. 
=============================================
[2019-03-23 02:25:45,069] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[69.6033 ]
 [69.5925 ]
 [69.59719]
 [69.55545]
 [69.49148]], R is [[69.56559753]
 [69.56481171]
 [69.56302643]
 [69.56005096]
 [69.55558777]].
[2019-03-23 02:25:49,509] A3C_AGENT_WORKER-Thread-15 INFO:Local step 141500, global step 2265020: loss 0.3122
[2019-03-23 02:25:49,511] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 141500, global step 2265021: learning rate 0.0010
[2019-03-23 02:25:50,227] A3C_AGENT_WORKER-Thread-3 INFO:Local step 142500, global step 2265363: loss -227.0995
[2019-03-23 02:25:50,229] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 142500, global step 2265365: learning rate 0.0010
[2019-03-23 02:25:50,917] A3C_AGENT_WORKER-Thread-14 INFO:Local step 142000, global step 2265685: loss 8.3068
[2019-03-23 02:25:50,918] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 142000, global step 2265686: learning rate 0.0010
[2019-03-23 02:25:51,362] A3C_AGENT_WORKER-Thread-9 INFO:Local step 142000, global step 2265899: loss 6.0024
[2019-03-23 02:25:51,365] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 142000, global step 2265899: learning rate 0.0010
[2019-03-23 02:25:51,678] A3C_AGENT_WORKER-Thread-20 INFO:Local step 141500, global step 2266050: loss -94.4358
[2019-03-23 02:25:51,680] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 141500, global step 2266050: learning rate 0.0010
[2019-03-23 02:25:53,380] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 5.1637252e-31 1.6024398e-22], sum to 1.0000
[2019-03-23 02:25:53,387] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8994
[2019-03-23 02:25:53,391] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.1, 66.0, 1.0, 2.0, 0.587630879465166, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 650224.9175589904, 650224.9175589908, 139081.1695278409], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6170400.0000, 
sim time next is 6171000.0000, 
raw observation next is [20.91666666666667, 68.5, 1.0, 2.0, 0.6169183629623812, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 684230.9146542558, 684230.9146542562, 142826.8690935177], 
processed observation next is [1.0, 0.43478260869565216, 0.5871212121212124, 0.685, 1.0, 1.0, 0.5211479537029765, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.25341885727935404, 0.25341885727935415, 0.34835821730126265], 
reward next is 0.6516, 
noisyNet noise sample is [array([-0.39333707], dtype=float32), -1.8162955]. 
=============================================
[2019-03-23 02:25:53,407] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[56.2242  ]
 [56.154755]
 [55.984573]
 [55.73914 ]
 [55.728317]], R is [[56.16604233]
 [56.26515961]
 [56.36611557]
 [56.46531296]
 [56.55952072]].
[2019-03-23 02:25:56,426] A3C_AGENT_WORKER-Thread-19 INFO:Local step 141500, global step 2268274: loss 17.4986
[2019-03-23 02:25:56,430] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 141500, global step 2268277: learning rate 0.0010
[2019-03-23 02:25:56,736] A3C_AGENT_WORKER-Thread-10 INFO:Local step 141500, global step 2268423: loss 63.8908
[2019-03-23 02:25:56,738] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 141500, global step 2268424: learning rate 0.0010
[2019-03-23 02:25:57,284] A3C_AGENT_WORKER-Thread-17 INFO:Local step 141500, global step 2268677: loss 46.1321
[2019-03-23 02:25:57,286] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 141500, global step 2268678: learning rate 0.0010
[2019-03-23 02:25:57,457] A3C_AGENT_WORKER-Thread-18 INFO:Local step 141500, global step 2268762: loss 37.9921
[2019-03-23 02:25:57,460] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 141500, global step 2268762: learning rate 0.0010
[2019-03-23 02:25:57,817] A3C_AGENT_WORKER-Thread-16 INFO:Local step 141500, global step 2268931: loss 44.6475
[2019-03-23 02:25:57,820] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 141500, global step 2268932: learning rate 0.0010
[2019-03-23 02:25:58,191] A3C_AGENT_WORKER-Thread-22 INFO:Local step 141500, global step 2269107: loss 246.3552
[2019-03-23 02:25:58,194] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 141500, global step 2269108: learning rate 0.0010
[2019-03-23 02:25:58,281] A3C_AGENT_WORKER-Thread-12 INFO:Local step 141500, global step 2269148: loss 51.3125
[2019-03-23 02:25:58,285] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 141500, global step 2269149: learning rate 0.0010
[2019-03-23 02:25:58,568] A3C_AGENT_WORKER-Thread-13 INFO:Local step 141500, global step 2269275: loss 3.5929
[2019-03-23 02:25:58,569] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 141500, global step 2269275: learning rate 0.0010
[2019-03-23 02:25:58,644] A3C_AGENT_WORKER-Thread-11 INFO:Local step 141500, global step 2269311: loss 1.0546
[2019-03-23 02:25:58,646] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 141500, global step 2269312: learning rate 0.0010
[2019-03-23 02:25:59,181] A3C_AGENT_WORKER-Thread-2 INFO:Local step 142000, global step 2269567: loss 6.3727
[2019-03-23 02:25:59,185] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 142000, global step 2269568: learning rate 0.0010
[2019-03-23 02:26:00,133] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 8.978523e-38 0.000000e+00], sum to 1.0000
[2019-03-23 02:26:00,136] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4971
[2019-03-23 02:26:00,144] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 97.0, 1.0, 2.0, 0.3678952480071623, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 409655.6112042373, 409655.611204237, 119698.3249908719], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5452800.0000, 
sim time next is 5453400.0000, 
raw observation next is [17.7, 97.0, 1.0, 2.0, 0.3624339245611045, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 403548.015248959, 403548.0152489587, 119243.9047283484], 
processed observation next is [1.0, 0.08695652173913043, 0.44090909090909086, 0.97, 1.0, 1.0, 0.20304240570138063, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1494622278699848, 0.1494622278699847, 0.29083879202036195], 
reward next is 0.7092, 
noisyNet noise sample is [array([0.6291216], dtype=float32), -0.009738575]. 
=============================================
[2019-03-23 02:26:01,312] A3C_AGENT_WORKER-Thread-21 INFO:Local step 143000, global step 2270584: loss 0.0835
[2019-03-23 02:26:01,313] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 143000, global step 2270584: learning rate 0.0010
[2019-03-23 02:26:03,808] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:26:03,815] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3200
[2019-03-23 02:26:03,820] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.35, 51.5, 1.0, 2.0, 0.4039150243074451, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 458284.4579574507, 458284.457957451, 127114.3841327558], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5941800.0000, 
sim time next is 5942400.0000, 
raw observation next is [26.06666666666667, 53.0, 1.0, 2.0, 0.4033240222321597, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 457676.7180965557, 457676.7180965557, 127105.0956472243], 
processed observation next is [1.0, 0.782608695652174, 0.8212121212121214, 0.53, 1.0, 1.0, 0.25415502779019955, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1695098955913169, 0.1695098955913169, 0.31001242840786414], 
reward next is 0.6900, 
noisyNet noise sample is [array([1.0363425], dtype=float32), -1.2835491]. 
=============================================
[2019-03-23 02:26:06,466] A3C_AGENT_WORKER-Thread-15 INFO:Local step 142000, global step 2273011: loss 6.2291
[2019-03-23 02:26:06,467] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 142000, global step 2273011: learning rate 0.0010
[2019-03-23 02:26:06,803] A3C_AGENT_WORKER-Thread-3 INFO:Local step 143000, global step 2273167: loss 0.0407
[2019-03-23 02:26:06,805] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 143000, global step 2273167: learning rate 0.0010
[2019-03-23 02:26:06,894] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:26:06,905] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4023
[2019-03-23 02:26:06,910] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [8.9, 89.33333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 131456.6506483555, 131456.6506483555, 55446.34579719703], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5719800.0000, 
sim time next is 5720400.0000, 
raw observation next is [8.8, 90.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 129994.9818127729, 129994.9818127729, 55257.28753502027], 
processed observation next is [0.0, 0.21739130434782608, 0.0363636363636364, 0.9, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.04814628956028626, 0.04814628956028626, 0.1347738720366348], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.7650006], dtype=float32), 2.5340528]. 
=============================================
[2019-03-23 02:26:07,357] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.4928977e-24 3.5757740e-22 1.4021626e-24 2.2946357e-30 1.0000000e+00], sum to 1.0000
[2019-03-23 02:26:07,366] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8977
[2019-03-23 02:26:07,370] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.88333333333333, 57.5, 1.0, 2.0, 0.3881803845756127, 1.0, 2.0, 0.3881803845756127, 1.0, 1.0, 0.7863354455626018, 6.911199999999999, 6.9112, 77.3421103, 1323977.627407689, 1323977.627407689, 295457.1503234716], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5586600.0000, 
sim time next is 5587200.0000, 
raw observation next is [26.6, 58.0, 1.0, 2.0, 0.379101742518786, 1.0, 2.0, 0.379101742518786, 1.0, 2.0, 0.7679075586533767, 6.9112, 6.9112, 77.3421103, 1293882.27136433, 1293882.27136433, 290793.8409298856], 
processed observation next is [1.0, 0.6956521739130435, 0.8454545454545456, 0.58, 1.0, 1.0, 0.22387717814848246, 1.0, 1.0, 0.22387717814848246, 1.0, 1.0, 0.6684393695048239, 0.0, 0.0, 0.5085185399722538, 0.47921565606086297, 0.47921565606086297, 0.7092532705606966], 
reward next is 0.2907, 
noisyNet noise sample is [array([-0.13876744], dtype=float32), -0.1879274]. 
=============================================
[2019-03-23 02:26:07,691] A3C_AGENT_WORKER-Thread-14 INFO:Local step 142500, global step 2273590: loss -273.5739
[2019-03-23 02:26:07,692] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 142500, global step 2273590: learning rate 0.0010
[2019-03-23 02:26:08,078] A3C_AGENT_WORKER-Thread-9 INFO:Local step 142500, global step 2273770: loss -107.2692
[2019-03-23 02:26:08,082] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 142500, global step 2273771: learning rate 0.0010
[2019-03-23 02:26:08,655] A3C_AGENT_WORKER-Thread-20 INFO:Local step 142000, global step 2274039: loss 6.7207
[2019-03-23 02:26:08,658] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 142000, global step 2274040: learning rate 0.0010
[2019-03-23 02:26:09,640] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:26:09,646] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0682
[2019-03-23 02:26:09,653] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.56666666666667, 75.0, 1.0, 2.0, 0.3756207784484725, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 412354.6914645118, 412354.6914645121, 118078.4604567704], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5905200.0000, 
sim time next is 5905800.0000, 
raw observation next is [19.95, 74.5, 1.0, 2.0, 0.4646550798449726, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 513195.4978170656, 513195.4978170656, 126586.8594365316], 
processed observation next is [1.0, 0.34782608695652173, 0.5431818181818181, 0.745, 1.0, 1.0, 0.33081884980621573, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1900724065989132, 0.1900724065989132, 0.30874843765007703], 
reward next is 0.6913, 
noisyNet noise sample is [array([1.3793117], dtype=float32), -0.6851057]. 
=============================================
[2019-03-23 02:26:10,668] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-23 02:26:10,671] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 02:26:10,671] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 02:26:10,672] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 02:26:10,673] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 02:26:10,673] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:26:10,675] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:26:10,674] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 02:26:10,673] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:26:10,682] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:26:10,677] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:26:10,701] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run92
[2019-03-23 02:26:10,728] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run92
[2019-03-23 02:26:10,752] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run92
[2019-03-23 02:26:10,774] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run92
[2019-03-23 02:26:10,774] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run92
[2019-03-23 02:26:15,522] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.40506026], dtype=float32), -0.09652602]
[2019-03-23 02:26:15,523] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [26.96666666666667, 35.66666666666667, 1.0, 2.0, 0.3472858337356737, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 382449.6034201058, 382449.6034201062, 120665.9123992981]
[2019-03-23 02:26:15,523] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 02:26:15,527] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.6823164939317433
[2019-03-23 02:26:40,309] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.40506026], dtype=float32), -0.09652602]
[2019-03-23 02:26:40,310] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.89508404, 48.38487048, 1.0, 2.0, 0.2961055131552219, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 321505.1805455085, 321505.1805455085, 101174.1064274313]
[2019-03-23 02:26:40,312] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 02:26:40,315] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.9641834960689094
[2019-03-23 02:26:51,142] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.40506026], dtype=float32), -0.09652602]
[2019-03-23 02:26:51,144] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [24.08081234666667, 71.00018912666667, 1.0, 2.0, 0.4784145531930238, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 545648.5715931511, 545648.5715931507, 141836.3562110755]
[2019-03-23 02:26:51,148] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 02:26:51,150] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 2.5588472e-36], sampled 0.9155773715648806
[2019-03-23 02:27:28,771] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.40506026], dtype=float32), -0.09652602]
[2019-03-23 02:27:28,772] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [16.51666666666667, 96.83333333333334, 1.0, 2.0, 0.3192319337842606, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 348263.8910562976, 348263.8910562976, 113060.8529179188]
[2019-03-23 02:27:28,773] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 02:27:28,777] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.9942066781061255
[2019-03-23 02:27:31,817] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.40506026], dtype=float32), -0.09652602]
[2019-03-23 02:27:31,819] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.36666666666667, 70.66666666666667, 1.0, 2.0, 0.3274554047841684, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 361133.5251837183, 361133.5251837183, 115070.6619871107]
[2019-03-23 02:27:31,821] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 02:27:31,823] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.3297187670001429
[2019-03-23 02:27:36,075] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.40506026], dtype=float32), -0.09652602]
[2019-03-23 02:27:36,078] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.1, 62.0, 1.0, 2.0, 0.7976801594589442, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 898545.3379758967, 898545.3379758967, 170829.6250690989]
[2019-03-23 02:27:36,079] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 02:27:36,082] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.4196682e-38 1.0000000e+00 0.0000000e+00 1.7793328e-34 1.4555905e-23], sampled 0.8015116526095762
[2019-03-23 02:27:39,198] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.40506026], dtype=float32), -0.09652602]
[2019-03-23 02:27:39,198] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.96666666666667, 70.33333333333333, 1.0, 2.0, 0.4707962830602375, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 536575.323834497, 536575.323834497, 140318.0844823491]
[2019-03-23 02:27:39,201] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 02:27:39,203] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 2.766047e-35], sampled 0.6683474830282373
[2019-03-23 02:27:58,850] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9065.5627 1657940122.0523 52.0000
[2019-03-23 02:27:59,111] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8449.8402 1794116871.9809 106.0000
[2019-03-23 02:27:59,133] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.5010 1690234930.6653 142.0000
[2019-03-23 02:27:59,336] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8630.9253 1716405620.2118 254.0000
[2019-03-23 02:27:59,411] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8854.7486 1667485918.6264 71.0000
[2019-03-23 02:28:00,429] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 2275000, evaluation results [2275000.0, 8449.840165102198, 1794116871.9808767, 106.0, 9065.56270975167, 1657940122.052333, 52.0, 8854.748597854505, 1667485918.6263669, 71.0, 8630.925348817318, 1716405620.2117937, 254.0, 8574.501000193999, 1690234930.6653159, 142.0]
[2019-03-23 02:28:02,946] A3C_AGENT_WORKER-Thread-19 INFO:Local step 142000, global step 2276191: loss 5.8772
[2019-03-23 02:28:02,948] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 142000, global step 2276192: learning rate 0.0010
[2019-03-23 02:28:03,676] A3C_AGENT_WORKER-Thread-10 INFO:Local step 142000, global step 2276537: loss 5.8557
[2019-03-23 02:28:03,684] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 142000, global step 2276537: learning rate 0.0010
[2019-03-23 02:28:04,120] A3C_AGENT_WORKER-Thread-17 INFO:Local step 142000, global step 2276750: loss 4.2142
[2019-03-23 02:28:04,122] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 142000, global step 2276750: learning rate 0.0010
[2019-03-23 02:28:04,312] A3C_AGENT_WORKER-Thread-18 INFO:Local step 142000, global step 2276835: loss 5.0604
[2019-03-23 02:28:04,316] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 142000, global step 2276835: learning rate 0.0010
[2019-03-23 02:28:04,754] A3C_AGENT_WORKER-Thread-16 INFO:Local step 142000, global step 2277052: loss 1.7765
[2019-03-23 02:28:04,756] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 142000, global step 2277052: learning rate 0.0010
[2019-03-23 02:28:04,958] A3C_AGENT_WORKER-Thread-22 INFO:Local step 142000, global step 2277144: loss 2.1162
[2019-03-23 02:28:04,964] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 142000, global step 2277147: learning rate 0.0010
[2019-03-23 02:28:05,090] A3C_AGENT_WORKER-Thread-12 INFO:Local step 142000, global step 2277204: loss 1.2233
[2019-03-23 02:28:05,094] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 142000, global step 2277206: learning rate 0.0010
[2019-03-23 02:28:05,337] A3C_AGENT_WORKER-Thread-13 INFO:Local step 142000, global step 2277322: loss 1.3265
[2019-03-23 02:28:05,338] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 142000, global step 2277322: learning rate 0.0010
[2019-03-23 02:28:05,487] A3C_AGENT_WORKER-Thread-2 INFO:Local step 142500, global step 2277396: loss -43.2999
[2019-03-23 02:28:05,489] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 142500, global step 2277396: learning rate 0.0010
[2019-03-23 02:28:05,720] A3C_AGENT_WORKER-Thread-11 INFO:Local step 142000, global step 2277501: loss 2.5751
[2019-03-23 02:28:05,723] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 142000, global step 2277501: learning rate 0.0010
[2019-03-23 02:28:07,627] A3C_AGENT_WORKER-Thread-21 INFO:Local step 143500, global step 2278400: loss 5.3213
[2019-03-23 02:28:07,630] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 143500, global step 2278401: learning rate 0.0010
[2019-03-23 02:28:09,812] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:28:09,821] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7401
[2019-03-23 02:28:09,827] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.9, 58.16666666666666, 1.0, 2.0, 0.5324297777200446, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 578290.1935460706, 578290.1935460706, 119568.9694382348], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6087000.0000, 
sim time next is 6087600.0000, 
raw observation next is [20.0, 58.0, 1.0, 2.0, 0.5560746390255966, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 603987.6431468566, 603987.6431468562, 122819.358387111], 
processed observation next is [1.0, 0.4782608695652174, 0.5454545454545454, 0.58, 1.0, 1.0, 0.4450932987819957, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22369912709142836, 0.22369912709142822, 0.29955941070027076], 
reward next is 0.7004, 
noisyNet noise sample is [array([-0.7958022], dtype=float32), 0.77809876]. 
=============================================
[2019-03-23 02:28:12,290] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:28:12,300] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9290
[2019-03-23 02:28:12,306] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.7, 64.5, 1.0, 2.0, 0.2824936449860206, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 306740.3754035458, 306740.3754035461, 101530.3981331386], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6132600.0000, 
sim time next is 6133200.0000, 
raw observation next is [19.6, 65.66666666666666, 1.0, 2.0, 0.2841987112749529, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 308592.3767524557, 308592.376752456, 102890.8096287652], 
processed observation next is [1.0, 1.0, 0.5272727272727273, 0.6566666666666666, 1.0, 1.0, 0.1052483890936911, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1142934728712799, 0.11429347287128, 0.2509531942165005], 
reward next is 0.7490, 
noisyNet noise sample is [array([1.8453381], dtype=float32), -1.3344449]. 
=============================================
[2019-03-23 02:28:13,020] A3C_AGENT_WORKER-Thread-15 INFO:Local step 142500, global step 2280961: loss 6.4485
[2019-03-23 02:28:13,023] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 142500, global step 2280962: learning rate 0.0010
[2019-03-23 02:28:13,230] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:28:13,240] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8382
[2019-03-23 02:28:13,244] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.2, 83.5, 1.0, 2.0, 0.3161477576902236, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 346088.1246260705, 346088.1246260705, 113271.9790076707], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5879400.0000, 
sim time next is 5880000.0000, 
raw observation next is [18.1, 83.0, 1.0, 2.0, 0.3127418085686972, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 341354.3634783121, 341354.3634783124, 112669.2677475614], 
processed observation next is [1.0, 0.043478260869565216, 0.45909090909090916, 0.83, 1.0, 1.0, 0.1409272607108715, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12642754202900447, 0.12642754202900458, 0.2748030920672229], 
reward next is 0.7252, 
noisyNet noise sample is [array([-0.9835851], dtype=float32), 0.31798458]. 
=============================================
[2019-03-23 02:28:13,255] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[66.07139 ]
 [66.18005 ]
 [66.189804]
 [66.162994]
 [66.10977 ]], R is [[66.22711182]
 [66.28856659]
 [66.34837341]
 [66.40749359]
 [66.46590424]].
[2019-03-23 02:28:13,310] A3C_AGENT_WORKER-Thread-3 INFO:Local step 143500, global step 2281096: loss 0.7818
[2019-03-23 02:28:13,313] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 143500, global step 2281096: learning rate 0.0010
[2019-03-23 02:28:14,354] A3C_AGENT_WORKER-Thread-14 INFO:Local step 143000, global step 2281589: loss 0.0672
[2019-03-23 02:28:14,357] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 143000, global step 2281589: learning rate 0.0010
[2019-03-23 02:28:14,740] A3C_AGENT_WORKER-Thread-9 INFO:Local step 143000, global step 2281779: loss 0.0183
[2019-03-23 02:28:14,742] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 143000, global step 2281779: learning rate 0.0010
[2019-03-23 02:28:15,421] A3C_AGENT_WORKER-Thread-20 INFO:Local step 142500, global step 2282095: loss -224.3514
[2019-03-23 02:28:15,423] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 142500, global step 2282096: learning rate 0.0010
[2019-03-23 02:28:19,946] A3C_AGENT_WORKER-Thread-19 INFO:Local step 142500, global step 2284228: loss -11.4826
[2019-03-23 02:28:19,948] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 142500, global step 2284228: learning rate 0.0010
[2019-03-23 02:28:20,792] A3C_AGENT_WORKER-Thread-10 INFO:Local step 142500, global step 2284636: loss -212.7395
[2019-03-23 02:28:20,796] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 142500, global step 2284638: learning rate 0.0010
[2019-03-23 02:28:21,028] A3C_AGENT_WORKER-Thread-17 INFO:Local step 142500, global step 2284746: loss -75.4013
[2019-03-23 02:28:21,032] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 142500, global step 2284746: learning rate 0.0010
[2019-03-23 02:28:21,163] A3C_AGENT_WORKER-Thread-18 INFO:Local step 142500, global step 2284812: loss 43.4947
[2019-03-23 02:28:21,167] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 142500, global step 2284812: learning rate 0.0010
[2019-03-23 02:28:21,717] A3C_AGENT_WORKER-Thread-16 INFO:Local step 142500, global step 2285070: loss 0.7411
[2019-03-23 02:28:21,719] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 142500, global step 2285070: learning rate 0.0010
[2019-03-23 02:28:21,981] A3C_AGENT_WORKER-Thread-22 INFO:Local step 142500, global step 2285197: loss -0.5070
[2019-03-23 02:28:21,984] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 142500, global step 2285197: learning rate 0.0010
[2019-03-23 02:28:22,030] A3C_AGENT_WORKER-Thread-12 INFO:Local step 142500, global step 2285219: loss 1.8071
[2019-03-23 02:28:22,033] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 142500, global step 2285219: learning rate 0.0010
[2019-03-23 02:28:22,208] A3C_AGENT_WORKER-Thread-13 INFO:Local step 142500, global step 2285302: loss 23.1505
[2019-03-23 02:28:22,211] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 142500, global step 2285302: learning rate 0.0010
[2019-03-23 02:28:22,312] A3C_AGENT_WORKER-Thread-2 INFO:Local step 143000, global step 2285351: loss 0.0096
[2019-03-23 02:28:22,315] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 143000, global step 2285351: learning rate 0.0010
[2019-03-23 02:28:22,622] A3C_AGENT_WORKER-Thread-11 INFO:Local step 142500, global step 2285496: loss 0.6197
[2019-03-23 02:28:22,623] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 142500, global step 2285496: learning rate 0.0010
[2019-03-23 02:28:24,446] A3C_AGENT_WORKER-Thread-21 INFO:Local step 144000, global step 2286362: loss 0.4435
[2019-03-23 02:28:24,449] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 144000, global step 2286362: learning rate 0.0010
[2019-03-23 02:28:24,588] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:28:24,597] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9142
[2019-03-23 02:28:24,603] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.58333333333333, 85.33333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 216157.9581074132, 216157.9581074132, 71347.53201714577], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6490200.0000, 
sim time next is 6490800.0000, 
raw observation next is [13.3, 87.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 211046.5767506244, 211046.5767506247, 70257.56040618251], 
processed observation next is [1.0, 0.13043478260869565, 0.24090909090909093, 0.87, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07816539879652755, 0.07816539879652766, 0.17135990342971344], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1347554], dtype=float32), 0.5730302]. 
=============================================
[2019-03-23 02:28:30,060] A3C_AGENT_WORKER-Thread-15 INFO:Local step 143000, global step 2289007: loss 0.0149
[2019-03-23 02:28:30,065] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 143000, global step 2289007: learning rate 0.0010
[2019-03-23 02:28:30,153] A3C_AGENT_WORKER-Thread-3 INFO:Local step 144000, global step 2289050: loss 0.3533
[2019-03-23 02:28:30,156] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 144000, global step 2289051: learning rate 0.0010
[2019-03-23 02:28:31,206] A3C_AGENT_WORKER-Thread-14 INFO:Local step 143500, global step 2289547: loss 3.7856
[2019-03-23 02:28:31,209] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 143500, global step 2289548: learning rate 0.0010
[2019-03-23 02:28:31,382] A3C_AGENT_WORKER-Thread-9 INFO:Local step 143500, global step 2289628: loss 3.9887
[2019-03-23 02:28:31,388] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 143500, global step 2289629: learning rate 0.0010
[2019-03-23 02:28:32,377] A3C_AGENT_WORKER-Thread-20 INFO:Local step 143000, global step 2290088: loss 0.2633
[2019-03-23 02:28:32,382] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 143000, global step 2290088: learning rate 0.0010
[2019-03-23 02:28:35,692] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 2.7580897e-29], sum to 1.0000
[2019-03-23 02:28:35,705] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7644
[2019-03-23 02:28:35,710] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.4, 59.0, 1.0, 2.0, 0.5837906452837808, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 658646.2421990681, 658646.2421990681, 156071.2182259955], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6274800.0000, 
sim time next is 6275400.0000, 
raw observation next is [29.4, 58.33333333333334, 1.0, 2.0, 0.5758733614785047, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 650539.0421652303, 650539.0421652303, 154781.9154890658], 
processed observation next is [0.0, 0.6521739130434783, 0.9727272727272727, 0.5833333333333335, 1.0, 1.0, 0.4698417018481308, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2409403859871223, 0.2409403859871223, 0.377516867046502], 
reward next is 0.6225, 
noisyNet noise sample is [array([1.2835001], dtype=float32), -0.5609302]. 
=============================================
[2019-03-23 02:28:36,905] A3C_AGENT_WORKER-Thread-19 INFO:Local step 143000, global step 2292228: loss 0.0767
[2019-03-23 02:28:36,909] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 143000, global step 2292232: learning rate 0.0010
[2019-03-23 02:28:37,812] A3C_AGENT_WORKER-Thread-10 INFO:Local step 143000, global step 2292654: loss 0.1437
[2019-03-23 02:28:37,818] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 143000, global step 2292654: learning rate 0.0010
[2019-03-23 02:28:37,910] A3C_AGENT_WORKER-Thread-17 INFO:Local step 143000, global step 2292701: loss 0.1552
[2019-03-23 02:28:37,913] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 143000, global step 2292701: learning rate 0.0010
[2019-03-23 02:28:38,135] A3C_AGENT_WORKER-Thread-18 INFO:Local step 143000, global step 2292805: loss 0.0310
[2019-03-23 02:28:38,138] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 143000, global step 2292807: learning rate 0.0010
[2019-03-23 02:28:38,329] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 8.0135632e-36 0.0000000e+00 2.0003048e-35], sum to 1.0000
[2019-03-23 02:28:38,339] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9812
[2019-03-23 02:28:38,344] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.2, 96.0, 1.0, 2.0, 0.3339662348996647, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 368194.653806314, 368194.6538063143, 115507.6279088112], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6737400.0000, 
sim time next is 6738000.0000, 
raw observation next is [17.2, 96.0, 1.0, 2.0, 0.3327475345741029, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 366845.3698344065, 366845.3698344062, 115414.8242359602], 
processed observation next is [1.0, 1.0, 0.41818181818181815, 0.96, 1.0, 1.0, 0.16593441821762858, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1358686554942246, 0.1358686554942245, 0.28149957130722], 
reward next is 0.7185, 
noisyNet noise sample is [array([-0.8181121], dtype=float32), -0.2875228]. 
=============================================
[2019-03-23 02:28:38,355] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[64.23676]
 [64.27244]
 [64.30247]
 [64.33652]
 [64.29611]], R is [[64.27264404]
 [64.34819031]
 [64.42276764]
 [64.49632263]
 [64.56827545]].
[2019-03-23 02:28:38,726] A3C_AGENT_WORKER-Thread-16 INFO:Local step 143000, global step 2293076: loss 0.1060
[2019-03-23 02:28:38,731] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 143000, global step 2293076: learning rate 0.0010
[2019-03-23 02:28:39,049] A3C_AGENT_WORKER-Thread-12 INFO:Local step 143000, global step 2293230: loss 0.0131
[2019-03-23 02:28:39,052] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 143000, global step 2293232: learning rate 0.0010
[2019-03-23 02:28:39,055] A3C_AGENT_WORKER-Thread-22 INFO:Local step 143000, global step 2293232: loss 0.2840
[2019-03-23 02:28:39,056] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 143000, global step 2293232: learning rate 0.0010
[2019-03-23 02:28:39,266] A3C_AGENT_WORKER-Thread-2 INFO:Local step 143500, global step 2293331: loss 1.8159
[2019-03-23 02:28:39,267] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 143500, global step 2293331: learning rate 0.0010
[2019-03-23 02:28:39,337] A3C_AGENT_WORKER-Thread-13 INFO:Local step 143000, global step 2293363: loss 0.0246
[2019-03-23 02:28:39,338] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 143000, global step 2293363: learning rate 0.0010
[2019-03-23 02:28:39,564] A3C_AGENT_WORKER-Thread-11 INFO:Local step 143000, global step 2293469: loss 0.0548
[2019-03-23 02:28:39,566] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 143000, global step 2293469: learning rate 0.0010
[2019-03-23 02:28:41,329] A3C_AGENT_WORKER-Thread-21 INFO:Local step 144500, global step 2294310: loss 0.1427
[2019-03-23 02:28:41,331] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 144500, global step 2294311: learning rate 0.0010
[2019-03-23 02:28:41,771] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:28:41,780] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1714
[2019-03-23 02:28:41,786] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.2, 67.0, 1.0, 2.0, 0.5507934204330711, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 624827.0678981702, 624827.0678981706, 150581.9868000615], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6354000.0000, 
sim time next is 6354600.0000, 
raw observation next is [27.28333333333333, 66.66666666666667, 1.0, 2.0, 0.5522087845604828, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 626359.9015990634, 626359.9015990634, 150794.4714093819], 
processed observation next is [0.0, 0.5652173913043478, 0.8765151515151515, 0.6666666666666667, 1.0, 1.0, 0.4402609807006035, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23198514874039386, 0.23198514874039386, 0.3677913936814192], 
reward next is 0.6322, 
noisyNet noise sample is [array([-1.2759087], dtype=float32), -0.027678255]. 
=============================================
[2019-03-23 02:28:41,944] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 2.3626578e-37 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 02:28:41,953] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3456
[2019-03-23 02:28:41,959] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 63.0, 1.0, 2.0, 0.5566576726741328, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 631169.8408765283, 631169.8408765281, 151464.6630192412], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6363000.0000, 
sim time next is 6363600.0000, 
raw observation next is [28.1, 62.33333333333333, 1.0, 2.0, 0.5550341871386186, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 629433.2856455931, 629433.2856455933, 151212.7632846793], 
processed observation next is [0.0, 0.6521739130434783, 0.9136363636363637, 0.6233333333333333, 1.0, 1.0, 0.44379273392327323, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.23312343912799743, 0.23312343912799752, 0.3688116177675105], 
reward next is 0.6312, 
noisyNet noise sample is [array([0.08908279], dtype=float32), -0.62352866]. 
=============================================
[2019-03-23 02:28:45,867] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:28:45,876] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9405
[2019-03-23 02:28:45,882] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.21666666666667, 54.66666666666666, 1.0, 2.0, 0.2683057285627661, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 291330.080690488, 291330.0806904877, 83642.44664131706], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6549000.0000, 
sim time next is 6549600.0000, 
raw observation next is [19.03333333333333, 55.33333333333334, 1.0, 2.0, 0.2656000983211814, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 288391.3988137332, 288391.3988137335, 83040.00956016789], 
processed observation next is [1.0, 0.8260869565217391, 0.5015151515151515, 0.5533333333333335, 1.0, 1.0, 0.08200012290147676, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10681162919027155, 0.10681162919027166, 0.2025366086833363], 
reward next is 0.7975, 
noisyNet noise sample is [array([0.45452392], dtype=float32), -0.061747205]. 
=============================================
[2019-03-23 02:28:46,016] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:28:46,023] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3379
[2019-03-23 02:28:46,028] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.46666666666667, 60.66666666666667, 1.0, 2.0, 0.4703362550775331, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 536689.5540262271, 536689.5540262271, 137545.7683330101], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6867600.0000, 
sim time next is 6868200.0000, 
raw observation next is [26.83333333333334, 59.33333333333334, 1.0, 2.0, 0.4738451890068294, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 540688.0024880238, 540688.0024880238, 138154.8452315489], 
processed observation next is [0.0, 0.4782608695652174, 0.8560606060606063, 0.5933333333333334, 1.0, 1.0, 0.34230648625853677, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20025481573630513, 0.20025481573630513, 0.33696303715011927], 
reward next is 0.6630, 
noisyNet noise sample is [array([-0.80194914], dtype=float32), -0.97694886]. 
=============================================
[2019-03-23 02:28:46,993] A3C_AGENT_WORKER-Thread-15 INFO:Local step 143500, global step 2296979: loss 2.0952
[2019-03-23 02:28:46,995] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 143500, global step 2296979: learning rate 0.0010
[2019-03-23 02:28:47,266] A3C_AGENT_WORKER-Thread-3 INFO:Local step 144500, global step 2297105: loss 0.1359
[2019-03-23 02:28:47,269] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 144500, global step 2297105: learning rate 0.0010
[2019-03-23 02:28:48,277] A3C_AGENT_WORKER-Thread-14 INFO:Local step 144000, global step 2297580: loss 1.5573
[2019-03-23 02:28:48,278] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 144000, global step 2297580: learning rate 0.0010
[2019-03-23 02:28:48,501] A3C_AGENT_WORKER-Thread-9 INFO:Local step 144000, global step 2297684: loss 0.7705
[2019-03-23 02:28:48,506] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 144000, global step 2297684: learning rate 0.0010
[2019-03-23 02:28:48,835] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:28:48,842] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1723
[2019-03-23 02:28:48,847] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 90.0, 1.0, 2.0, 0.3843316696609529, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 432749.6460264191, 432749.6460264194, 123270.7843542536], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6921000.0000, 
sim time next is 6921600.0000, 
raw observation next is [19.4, 90.0, 1.0, 2.0, 0.3844746335086342, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 432911.0818076715, 432911.0818076712, 123283.5611130108], 
processed observation next is [0.0, 0.08695652173913043, 0.5181818181818181, 0.9, 1.0, 1.0, 0.23059329188579272, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16033743770654502, 0.16033743770654488, 0.30069161247075804], 
reward next is 0.6993, 
noisyNet noise sample is [array([0.8619936], dtype=float32), 1.2344401]. 
=============================================
[2019-03-23 02:28:49,409] A3C_AGENT_WORKER-Thread-20 INFO:Local step 143500, global step 2298109: loss 3.4347
[2019-03-23 02:28:49,412] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 143500, global step 2298110: learning rate 0.0010
[2019-03-23 02:28:52,948] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:28:52,959] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4610
[2019-03-23 02:28:52,964] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.6, 83.33333333333334, 1.0, 2.0, 0.4391496702705293, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 499640.4693795475, 499640.4693795475, 131636.3044877597], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7413600.0000, 
sim time next is 7414200.0000, 
raw observation next is [21.6, 83.0, 1.0, 2.0, 0.4389912615326748, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 499356.6161539679, 499356.6161539679, 131523.0054827325], 
processed observation next is [1.0, 0.8260869565217391, 0.6181818181818183, 0.83, 1.0, 1.0, 0.2987390769158435, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18494689487183996, 0.18494689487183996, 0.32078781825056707], 
reward next is 0.6792, 
noisyNet noise sample is [array([0.95837486], dtype=float32), 1.4512507]. 
=============================================
[2019-03-23 02:28:53,439] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-23 02:28:53,440] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 02:28:53,441] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 02:28:53,442] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:28:53,442] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:28:53,442] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 02:28:53,445] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 02:28:53,444] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 02:28:53,446] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:28:53,446] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:28:53,447] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:28:53,479] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run93
[2019-03-23 02:28:53,480] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run93
[2019-03-23 02:28:53,528] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run93
[2019-03-23 02:28:53,529] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run93
[2019-03-23 02:28:53,579] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run93
[2019-03-23 02:29:07,989] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.23156288], dtype=float32), -0.0873409]
[2019-03-23 02:29:07,990] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [13.60297305333333, 92.55496337666668, 1.0, 2.0, 0.2149288850636435, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 233348.1837610501, 233348.1837610497, 79357.95404806502]
[2019-03-23 02:29:07,992] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 02:29:07,995] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.9266330030811029
[2019-03-23 02:29:21,048] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.23156288], dtype=float32), -0.0873409]
[2019-03-23 02:29:21,050] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [26.202702025, 66.593687555, 1.0, 2.0, 0.8397489763899356, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 95.55338755299063, 956251.9754934506, 956251.975493451, 196529.1885417624]
[2019-03-23 02:29:21,052] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 02:29:21,055] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.44254301854626155
[2019-03-23 02:29:27,472] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.23156288], dtype=float32), -0.0873409]
[2019-03-23 02:29:27,474] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.61666666666667, 41.66666666666667, 1.0, 2.0, 0.3282362143650185, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 356402.369322653, 356402.3693226527, 94451.67208872919]
[2019-03-23 02:29:27,477] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 02:29:27,480] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.02982221781150518
[2019-03-23 02:29:44,953] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.23156288], dtype=float32), -0.0873409]
[2019-03-23 02:29:44,954] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [17.71637194, 100.0, 1.0, 2.0, 0.4397081738028552, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 492165.2361733794, 492165.2361733794, 131269.3420537368]
[2019-03-23 02:29:44,956] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 02:29:44,958] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.9498824488239083
[2019-03-23 02:29:53,483] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.23156288], dtype=float32), -0.0873409]
[2019-03-23 02:29:53,483] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.32646125333333, 43.24639508666667, 1.0, 2.0, 0.3145434381684353, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 341530.3827485936, 341530.3827485932, 107756.3101964071]
[2019-03-23 02:29:53,485] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 02:29:53,487] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.3102790146902804
[2019-03-23 02:29:54,179] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.23156288], dtype=float32), -0.0873409]
[2019-03-23 02:29:54,181] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [27.59220048, 62.52407649, 1.0, 2.0, 0.8127735645411812, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 923424.9297878043, 923424.9297878043, 193286.5021688634]
[2019-03-23 02:29:54,181] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 02:29:54,184] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.4566479912774061
[2019-03-23 02:30:12,387] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.23156288], dtype=float32), -0.0873409]
[2019-03-23 02:30:12,390] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [15.5, 91.0, 1.0, 2.0, 0.2590756052447273, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 281304.9863206637, 281304.9863206634, 88639.69583176932]
[2019-03-23 02:30:12,391] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 02:30:12,394] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.18274322554278788
[2019-03-23 02:30:13,309] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.23156288], dtype=float32), -0.0873409]
[2019-03-23 02:30:13,312] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [9.95, 91.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 137756.7110469415, 137756.7110469415, 56256.91534860879]
[2019-03-23 02:30:13,313] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 02:30:13,316] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.19823013643756782
[2019-03-23 02:30:41,157] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.23156288], dtype=float32), -0.0873409]
[2019-03-23 02:30:41,158] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [14.13333333333333, 88.0, 1.0, 2.0, 0.2041413103191561, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 221633.9599775391, 221633.9599775391, 78425.96114570218]
[2019-03-23 02:30:41,160] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 02:30:41,164] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.9908991769250417
[2019-03-23 02:30:42,081] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.9032 1683814987.1225 207.0000
[2019-03-23 02:30:42,226] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8855.7542 1663858414.4981 105.0000
[2019-03-23 02:30:42,498] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9060.3047 1656272944.4788 80.0000
[2019-03-23 02:30:42,543] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8503.3429 1775883095.7819 167.0000
[2019-03-23 02:30:42,558] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.1207 1706030998.8507 465.0000
[2019-03-23 02:30:43,577] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 2300000, evaluation results [2300000.0, 8503.342878394848, 1775883095.7819405, 167.0, 9060.304679780347, 1656272944.478839, 80.0, 8855.754186439062, 1663858414.498091, 105.0, 8596.120681065504, 1706030998.8506613, 465.0, 8574.903242746012, 1683814987.1225224, 207.0]
[2019-03-23 02:30:44,005] A3C_AGENT_WORKER-Thread-19 INFO:Local step 143500, global step 2300209: loss 1.0802
[2019-03-23 02:30:44,009] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 143500, global step 2300209: learning rate 0.0010
[2019-03-23 02:30:44,851] A3C_AGENT_WORKER-Thread-10 INFO:Local step 143500, global step 2300613: loss 3.0573
[2019-03-23 02:30:44,854] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 143500, global step 2300613: learning rate 0.0010
[2019-03-23 02:30:44,864] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:30:44,873] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1296
[2019-03-23 02:30:44,880] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [11.1, 96.66666666666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 187939.2061498055, 187939.2061498057, 64439.88881794196], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6587400.0000, 
sim time next is 6588000.0000, 
raw observation next is [11.1, 96.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 186888.8648029277, 186888.864802928, 64202.10524088257], 
processed observation next is [1.0, 0.2608695652173913, 0.1409090909090909, 0.96, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.06921809807515841, 0.06921809807515852, 0.15659050058751847], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.196652], dtype=float32), 0.8030439]. 
=============================================
[2019-03-23 02:30:44,896] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[63.77449 ]
 [63.776295]
 [63.78903 ]
 [63.7957  ]
 [63.807045]], R is [[63.16739655]
 [62.53572464]
 [61.91036987]
 [61.2912674 ]
 [60.67835617]].
[2019-03-23 02:30:44,997] A3C_AGENT_WORKER-Thread-17 INFO:Local step 143500, global step 2300680: loss 1.2289
[2019-03-23 02:30:45,003] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 143500, global step 2300681: learning rate 0.0010
[2019-03-23 02:30:45,189] A3C_AGENT_WORKER-Thread-18 INFO:Local step 143500, global step 2300766: loss 2.0261
[2019-03-23 02:30:45,191] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 143500, global step 2300766: learning rate 0.0010
[2019-03-23 02:30:45,757] A3C_AGENT_WORKER-Thread-16 INFO:Local step 143500, global step 2301035: loss 1.6004
[2019-03-23 02:30:45,761] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 143500, global step 2301035: learning rate 0.0010
[2019-03-23 02:30:46,138] A3C_AGENT_WORKER-Thread-22 INFO:Local step 143500, global step 2301218: loss 1.2948
[2019-03-23 02:30:46,141] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 143500, global step 2301219: learning rate 0.0010
[2019-03-23 02:30:46,269] A3C_AGENT_WORKER-Thread-12 INFO:Local step 143500, global step 2301280: loss 2.1855
[2019-03-23 02:30:46,271] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 143500, global step 2301280: learning rate 0.0010
[2019-03-23 02:30:46,457] A3C_AGENT_WORKER-Thread-2 INFO:Local step 144000, global step 2301368: loss 0.4499
[2019-03-23 02:30:46,460] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 144000, global step 2301368: learning rate 0.0010
[2019-03-23 02:30:46,475] A3C_AGENT_WORKER-Thread-13 INFO:Local step 143500, global step 2301377: loss 0.8569
[2019-03-23 02:30:46,481] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 143500, global step 2301379: learning rate 0.0010
[2019-03-23 02:30:46,643] A3C_AGENT_WORKER-Thread-11 INFO:Local step 143500, global step 2301456: loss 1.1603
[2019-03-23 02:30:46,648] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 143500, global step 2301456: learning rate 0.0010
[2019-03-23 02:30:48,620] A3C_AGENT_WORKER-Thread-21 INFO:Local step 145000, global step 2302385: loss 0.0473
[2019-03-23 02:30:48,622] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 145000, global step 2302386: learning rate 0.0010
[2019-03-23 02:30:54,301] A3C_AGENT_WORKER-Thread-15 INFO:Local step 144000, global step 2305070: loss 0.4286
[2019-03-23 02:30:54,304] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 144000, global step 2305071: learning rate 0.0010
[2019-03-23 02:30:54,446] A3C_AGENT_WORKER-Thread-3 INFO:Local step 145000, global step 2305138: loss 0.0246
[2019-03-23 02:30:54,451] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 145000, global step 2305140: learning rate 0.0010
[2019-03-23 02:30:55,173] A3C_AGENT_WORKER-Thread-14 INFO:Local step 144500, global step 2305485: loss 0.2829
[2019-03-23 02:30:55,174] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 144500, global step 2305486: learning rate 0.0010
[2019-03-23 02:30:55,593] A3C_AGENT_WORKER-Thread-9 INFO:Local step 144500, global step 2305684: loss 0.0693
[2019-03-23 02:30:55,596] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 144500, global step 2305684: learning rate 0.0010
[2019-03-23 02:30:56,556] A3C_AGENT_WORKER-Thread-20 INFO:Local step 144000, global step 2306145: loss 0.9214
[2019-03-23 02:30:56,558] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 144000, global step 2306145: learning rate 0.0010
[2019-03-23 02:31:01,050] A3C_AGENT_WORKER-Thread-19 INFO:Local step 144000, global step 2308257: loss 0.7050
[2019-03-23 02:31:01,055] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 144000, global step 2308258: learning rate 0.0010
[2019-03-23 02:31:01,785] A3C_AGENT_WORKER-Thread-10 INFO:Local step 144000, global step 2308599: loss 1.3848
[2019-03-23 02:31:01,790] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 144000, global step 2308601: learning rate 0.0010
[2019-03-23 02:31:01,867] A3C_AGENT_WORKER-Thread-17 INFO:Local step 144000, global step 2308640: loss 0.4490
[2019-03-23 02:31:01,869] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 144000, global step 2308640: learning rate 0.0010
[2019-03-23 02:31:02,083] A3C_AGENT_WORKER-Thread-18 INFO:Local step 144000, global step 2308741: loss 0.6369
[2019-03-23 02:31:02,087] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 144000, global step 2308742: learning rate 0.0010
[2019-03-23 02:31:02,692] A3C_AGENT_WORKER-Thread-16 INFO:Local step 144000, global step 2309037: loss 0.1726
[2019-03-23 02:31:02,696] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 144000, global step 2309037: learning rate 0.0010
[2019-03-23 02:31:03,023] A3C_AGENT_WORKER-Thread-22 INFO:Local step 144000, global step 2309191: loss 0.3399
[2019-03-23 02:31:03,027] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 144000, global step 2309192: learning rate 0.0010
[2019-03-23 02:31:03,146] A3C_AGENT_WORKER-Thread-12 INFO:Local step 144000, global step 2309246: loss 0.2766
[2019-03-23 02:31:03,149] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 144000, global step 2309247: learning rate 0.0010
[2019-03-23 02:31:03,404] A3C_AGENT_WORKER-Thread-2 INFO:Local step 144500, global step 2309372: loss 0.1970
[2019-03-23 02:31:03,406] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 144500, global step 2309372: learning rate 0.0010
[2019-03-23 02:31:03,454] A3C_AGENT_WORKER-Thread-13 INFO:Local step 144000, global step 2309391: loss 0.0501
[2019-03-23 02:31:03,458] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 144000, global step 2309394: learning rate 0.0010
[2019-03-23 02:31:03,587] A3C_AGENT_WORKER-Thread-11 INFO:Local step 144000, global step 2309457: loss 0.4242
[2019-03-23 02:31:03,590] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 144000, global step 2309457: learning rate 0.0010
[2019-03-23 02:31:04,054] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:31:04,060] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3254
[2019-03-23 02:31:04,065] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.1, 64.0, 1.0, 2.0, 0.4743321270897157, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 541211.7624018831, 541211.7624018835, 138428.9786130454], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6951600.0000, 
sim time next is 6952200.0000, 
raw observation next is [26.36666666666667, 63.0, 1.0, 2.0, 0.4782813559206197, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 545673.291154663, 545673.291154663, 139057.5702528056], 
processed observation next is [0.0, 0.4782608695652174, 0.8348484848484851, 0.63, 1.0, 1.0, 0.3478516949007746, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20210121894617147, 0.20210121894617147, 0.3391648054946478], 
reward next is 0.6608, 
noisyNet noise sample is [array([-1.465645], dtype=float32), 0.042838927]. 
=============================================
[2019-03-23 02:31:05,785] A3C_AGENT_WORKER-Thread-21 INFO:Local step 145500, global step 2310489: loss 1.3590
[2019-03-23 02:31:05,788] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 145500, global step 2310490: learning rate 0.0010
[2019-03-23 02:31:10,473] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.0531915e-36 1.0000000e+00 0.0000000e+00 1.3397786e-28 3.2625457e-20], sum to 1.0000
[2019-03-23 02:31:10,482] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6641
[2019-03-23 02:31:10,488] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.2, 78.50000000000001, 1.0, 2.0, 0.8621988643796052, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 981920.1026605188, 981920.1026605188, 187503.7785165833], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7049400.0000, 
sim time next is 7050000.0000, 
raw observation next is [22.2, 78.0, 1.0, 2.0, 0.8366488165125474, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 952561.1287137798, 952561.1287137798, 183191.3920334814], 
processed observation next is [1.0, 0.6086956521739131, 0.6454545454545454, 0.78, 1.0, 1.0, 0.7958110206406843, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3528004180421407, 0.3528004180421407, 0.44680827325239364], 
reward next is 0.5532, 
noisyNet noise sample is [array([1.1670774], dtype=float32), 1.8978858]. 
=============================================
[2019-03-23 02:31:10,509] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[55.54242 ]
 [56.562546]
 [56.38398 ]
 [56.774925]
 [57.25192 ]], R is [[55.55267715]
 [55.53982544]
 [55.56663132]
 [55.58156204]
 [55.60725403]].
[2019-03-23 02:31:11,251] A3C_AGENT_WORKER-Thread-15 INFO:Local step 144500, global step 2313068: loss 0.1678
[2019-03-23 02:31:11,253] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 144500, global step 2313068: learning rate 0.0010
[2019-03-23 02:31:11,381] A3C_AGENT_WORKER-Thread-3 INFO:Local step 145500, global step 2313134: loss 3.3903
[2019-03-23 02:31:11,384] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 145500, global step 2313136: learning rate 0.0010
[2019-03-23 02:31:12,078] A3C_AGENT_WORKER-Thread-14 INFO:Local step 145000, global step 2313456: loss 0.0168
[2019-03-23 02:31:12,082] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 145000, global step 2313457: learning rate 0.0010
[2019-03-23 02:31:12,518] A3C_AGENT_WORKER-Thread-9 INFO:Local step 145000, global step 2313667: loss 0.0003
[2019-03-23 02:31:12,521] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 145000, global step 2313668: learning rate 0.0010
[2019-03-23 02:31:13,502] A3C_AGENT_WORKER-Thread-20 INFO:Local step 144500, global step 2314132: loss 0.7725
[2019-03-23 02:31:13,505] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 144500, global step 2314135: learning rate 0.0010
[2019-03-23 02:31:14,560] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 02:31:14,560] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:31:14,626] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run12
[2019-03-23 02:31:15,657] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.6220778e-29 1.6133778e-20], sum to 1.0000
[2019-03-23 02:31:15,664] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6325
[2019-03-23 02:31:15,669] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.63333333333333, 51.66666666666666, 1.0, 2.0, 0.741957112528922, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 823607.8158788003, 823607.8158788003, 157896.3794267509], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7134000.0000, 
sim time next is 7134600.0000, 
raw observation next is [23.71666666666667, 50.83333333333334, 1.0, 2.0, 0.7407568791102039, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 821524.2088065841, 821524.2088065841, 157461.8364247797], 
processed observation next is [1.0, 0.5652173913043478, 0.7143939393939395, 0.5083333333333334, 1.0, 1.0, 0.6759460988877549, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.30426822548392, 0.30426822548392, 0.3840532595726334], 
reward next is 0.6159, 
noisyNet noise sample is [array([0.6541579], dtype=float32), 1.5412085]. 
=============================================
[2019-03-23 02:31:17,597] A3C_AGENT_WORKER-Thread-19 INFO:Local step 144500, global step 2316173: loss 0.1917
[2019-03-23 02:31:17,601] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 144500, global step 2316174: learning rate 0.0010
[2019-03-23 02:31:18,315] A3C_AGENT_WORKER-Thread-17 INFO:Local step 144500, global step 2316510: loss 0.0368
[2019-03-23 02:31:18,322] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 144500, global step 2316512: learning rate 0.0010
[2019-03-23 02:31:18,328] A3C_AGENT_WORKER-Thread-10 INFO:Local step 144500, global step 2316514: loss 0.7372
[2019-03-23 02:31:18,332] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 144500, global step 2316516: learning rate 0.0010
[2019-03-23 02:31:18,666] A3C_AGENT_WORKER-Thread-18 INFO:Local step 144500, global step 2316674: loss 0.7684
[2019-03-23 02:31:18,668] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 144500, global step 2316675: learning rate 0.0010
[2019-03-23 02:31:19,256] A3C_AGENT_WORKER-Thread-16 INFO:Local step 144500, global step 2316951: loss 1.0944
[2019-03-23 02:31:19,257] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 144500, global step 2316952: learning rate 0.0010
[2019-03-23 02:31:19,391] A3C_AGENT_WORKER-Thread-22 INFO:Local step 144500, global step 2317013: loss 1.0669
[2019-03-23 02:31:19,394] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 144500, global step 2317015: learning rate 0.0010
[2019-03-23 02:31:19,588] A3C_AGENT_WORKER-Thread-12 INFO:Local step 144500, global step 2317103: loss 1.5277
[2019-03-23 02:31:19,596] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 144500, global step 2317104: learning rate 0.0010
[2019-03-23 02:31:19,841] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 02:31:19,842] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:31:19,910] A3C_AGENT_WORKER-Thread-2 INFO:Local step 145000, global step 2317256: loss 0.0065
[2019-03-23 02:31:19,912] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 145000, global step 2317256: learning rate 0.0010
[2019-03-23 02:31:19,930] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run12
[2019-03-23 02:31:20,044] A3C_AGENT_WORKER-Thread-13 INFO:Local step 144500, global step 2317300: loss 1.4420
[2019-03-23 02:31:20,048] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 144500, global step 2317300: learning rate 0.0010
[2019-03-23 02:31:20,146] A3C_AGENT_WORKER-Thread-11 INFO:Local step 144500, global step 2317361: loss 0.6180
[2019-03-23 02:31:20,147] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 144500, global step 2317361: learning rate 0.0010
[2019-03-23 02:31:20,285] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 5.7918906e-29], sum to 1.0000
[2019-03-23 02:31:20,292] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2707
[2019-03-23 02:31:20,295] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.11666666666667, 46.16666666666666, 1.0, 2.0, 0.3755295592029814, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 407804.021345856, 407804.0213458563, 114619.2463616031], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7217400.0000, 
sim time next is 7218000.0000, 
raw observation next is [23.3, 46.0, 1.0, 2.0, 0.3849124207254906, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 417997.6621101989, 417997.6621101992, 117286.7452809929], 
processed observation next is [1.0, 0.5652173913043478, 0.6954545454545454, 0.46, 1.0, 1.0, 0.2311405259068632, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1548139489297033, 0.1548139489297034, 0.28606523239266557], 
reward next is 0.7139, 
noisyNet noise sample is [array([-0.8442301], dtype=float32), 1.1847414]. 
=============================================
[2019-03-23 02:31:20,304] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[65.342155]
 [65.185265]
 [65.271805]
 [65.38311 ]
 [65.18307 ]], R is [[65.34220123]
 [65.40922546]
 [65.48156738]
 [65.55767822]
 [64.90209961]].
[2019-03-23 02:31:23,545] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0.0000000e+00 2.9167884e-17 0.0000000e+00 0.0000000e+00 1.0000000e+00], sum to 1.0000
[2019-03-23 02:31:23,555] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4859
[2019-03-23 02:31:23,565] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.7, 43.33333333333334, 1.0, 2.0, 0.3221982602494069, 1.0, 2.0, 0.3221982602494069, 1.0, 2.0, 0.6376794291212354, 6.911199999999999, 6.9112, 77.3421103, 1095144.375982817, 1095144.375982818, 249328.3929024917], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7312800.0000, 
sim time next is 7313400.0000, 
raw observation next is [25.8, 43.0, 1.0, 2.0, 0.3335429802434524, 1.0, 2.0, 0.3335429802434524, 1.0, 2.0, 0.6603951456095476, 6.911199999999999, 6.9112, 77.3421103, 1134008.477834024, 1134008.477834024, 253359.5920659677], 
processed observation next is [1.0, 0.6521739130434783, 0.8090909090909091, 0.43, 1.0, 1.0, 0.1669287253043155, 1.0, 1.0, 0.1669287253043155, 1.0, 1.0, 0.5148502080136395, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.4200031399385274, 0.4200031399385274, 0.6179502245511408], 
reward next is 0.3820, 
noisyNet noise sample is [array([0.05357123], dtype=float32), 1.1594943]. 
=============================================
[2019-03-23 02:31:27,387] A3C_AGENT_WORKER-Thread-15 INFO:Local step 145000, global step 2320919: loss 0.0024
[2019-03-23 02:31:27,389] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 145000, global step 2320919: learning rate 0.0010
[2019-03-23 02:31:28,324] A3C_AGENT_WORKER-Thread-14 INFO:Local step 145500, global step 2321351: loss 1.7372
[2019-03-23 02:31:28,330] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 145500, global step 2321353: learning rate 0.0010
[2019-03-23 02:31:28,719] A3C_AGENT_WORKER-Thread-9 INFO:Local step 145500, global step 2321535: loss 0.7516
[2019-03-23 02:31:28,722] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 145500, global step 2321535: learning rate 0.0010
[2019-03-23 02:31:29,556] A3C_AGENT_WORKER-Thread-20 INFO:Local step 145000, global step 2321930: loss 0.0037
[2019-03-23 02:31:29,558] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 145000, global step 2321931: learning rate 0.0010
[2019-03-23 02:31:34,205] A3C_AGENT_WORKER-Thread-19 INFO:Local step 145000, global step 2324121: loss 0.0662
[2019-03-23 02:31:34,210] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 145000, global step 2324121: learning rate 0.0010
[2019-03-23 02:31:34,783] A3C_AGENT_WORKER-Thread-10 INFO:Local step 145000, global step 2324394: loss 0.0428
[2019-03-23 02:31:34,786] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 145000, global step 2324396: learning rate 0.0010
[2019-03-23 02:31:34,928] A3C_AGENT_WORKER-Thread-17 INFO:Local step 145000, global step 2324462: loss 0.0450
[2019-03-23 02:31:34,930] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 145000, global step 2324462: learning rate 0.0010
[2019-03-23 02:31:35,443] A3C_AGENT_WORKER-Thread-18 INFO:Local step 145000, global step 2324703: loss 0.0689
[2019-03-23 02:31:35,446] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 145000, global step 2324703: learning rate 0.0010
[2019-03-23 02:31:35,843] A3C_AGENT_WORKER-Thread-22 INFO:Local step 145000, global step 2324896: loss 0.0464
[2019-03-23 02:31:35,846] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 145000, global step 2324896: learning rate 0.0010
[2019-03-23 02:31:36,026] A3C_AGENT_WORKER-Thread-16 INFO:Local step 145000, global step 2324977: loss 0.0127
[2019-03-23 02:31:36,028] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 145000, global step 2324978: learning rate 0.0010
[2019-03-23 02:31:36,072] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-23 02:31:36,077] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 02:31:36,078] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 02:31:36,078] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:31:36,080] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:31:36,080] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 02:31:36,082] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 02:31:36,081] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 02:31:36,085] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:31:36,085] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:31:36,086] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:31:36,105] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run94
[2019-03-23 02:31:36,132] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run94
[2019-03-23 02:31:36,168] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run94
[2019-03-23 02:31:36,194] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run94
[2019-03-23 02:31:36,216] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run94
[2019-03-23 02:31:36,981] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 02:31:36,981] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:31:36,984] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run12
[2019-03-23 02:32:00,179] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.29453212], dtype=float32), -0.08043502]
[2019-03-23 02:32:00,182] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.97025288666667, 82.66611929000001, 1.0, 2.0, 0.3901396007726339, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 438562.7910554719, 438562.7910554719, 127734.8637177766]
[2019-03-23 02:32:00,183] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 02:32:00,185] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.9982744854239128
[2019-03-23 02:32:09,984] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.29453212], dtype=float32), -0.08043502]
[2019-03-23 02:32:09,987] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.55, 47.33333333333334, 1.0, 2.0, 0.3086310417628391, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 335108.9294961317, 335108.9294961313, 98202.1113561058]
[2019-03-23 02:32:09,991] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 02:32:09,995] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.6342690304980783
[2019-03-23 02:32:16,997] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.29453212], dtype=float32), -0.08043502]
[2019-03-23 02:32:16,999] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [24.14604605, 74.41963345, 1.0, 2.0, 0.6723646215915734, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 767227.675239151, 767227.6752391506, 167793.4102688594]
[2019-03-23 02:32:17,002] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 02:32:17,006] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.8776098974833998
[2019-03-23 02:32:21,021] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.29453212], dtype=float32), -0.08043502]
[2019-03-23 02:32:21,022] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.53333333333333, 68.66666666666667, 1.0, 2.0, 0.8029304689540545, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 916197.1851447442, 916197.1851447439, 185548.8520796428]
[2019-03-23 02:32:21,025] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 02:32:21,031] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 5.390218e-37], sampled 0.9994097902026913
[2019-03-23 02:32:24,895] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.29453212], dtype=float32), -0.08043502]
[2019-03-23 02:32:24,896] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.81666666666667, 89.83333333333333, 1.0, 2.0, 0.3647705285348893, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 407803.0159127636, 407803.0159127636, 124475.0491471655]
[2019-03-23 02:32:24,897] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 02:32:24,900] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.5490554648783684
[2019-03-23 02:33:17,033] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.29453212], dtype=float32), -0.08043502]
[2019-03-23 02:33:17,035] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.4, 83.0, 1.0, 2.0, 0.3289440033748863, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 360843.0956374518, 360843.0956374521, 114454.8269818503]
[2019-03-23 02:33:17,038] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 02:33:17,041] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.7045768921286409
[2019-03-23 02:33:25,147] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8497.3572 1778886972.6530 164.0000
[2019-03-23 02:33:25,209] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.29453212], dtype=float32), -0.08043502]
[2019-03-23 02:33:25,209] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.15, 59.5, 1.0, 2.0, 0.5071901870054394, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 561331.3013250296, 561331.3013250296, 135295.8636383657]
[2019-03-23 02:33:25,210] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 02:33:25,213] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.4891616215850991
[2019-03-23 02:33:25,213] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9060.3047 1656272944.4788 80.0000
[2019-03-23 02:33:25,409] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8595.6253 1706728968.4916 457.0000
[2019-03-23 02:33:25,500] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8577.5813 1684106427.5402 194.0000
[2019-03-23 02:33:25,587] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8854.9574 1663902404.7778 105.0000
[2019-03-23 02:33:26,603] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 2325000, evaluation results [2325000.0, 8497.357159999765, 1778886972.6530232, 164.0, 9060.304679780347, 1656272944.478839, 80.0, 8854.957448082614, 1663902404.7778378, 105.0, 8595.625295299002, 1706728968.4916327, 457.0, 8577.581329204128, 1684106427.5402136, 194.0]
[2019-03-23 02:33:26,732] A3C_AGENT_WORKER-Thread-12 INFO:Local step 145000, global step 2325067: loss 0.0406
[2019-03-23 02:33:26,733] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 145000, global step 2325068: learning rate 0.0010
[2019-03-23 02:33:27,136] A3C_AGENT_WORKER-Thread-13 INFO:Local step 145000, global step 2325262: loss 0.0010
[2019-03-23 02:33:27,140] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 145000, global step 2325264: learning rate 0.0010
[2019-03-23 02:33:27,231] A3C_AGENT_WORKER-Thread-2 INFO:Local step 145500, global step 2325304: loss 0.4543
[2019-03-23 02:33:27,233] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 145500, global step 2325305: learning rate 0.0010
[2019-03-23 02:33:27,309] A3C_AGENT_WORKER-Thread-11 INFO:Local step 145000, global step 2325345: loss 0.0059
[2019-03-23 02:33:27,313] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 145000, global step 2325347: learning rate 0.0010
[2019-03-23 02:33:28,019] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 02:33:28,019] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:33:28,102] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run12
[2019-03-23 02:33:28,845] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 8.935578e-37], sum to 1.0000
[2019-03-23 02:33:28,851] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2809
[2019-03-23 02:33:28,854] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 78.0, 1.0, 2.0, 0.5989364072872911, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 675877.5474436692, 675877.5474436692, 145844.3754323102], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 46800.0000, 
sim time next is 47400.0000, 
raw observation next is [21.0, 78.0, 1.0, 2.0, 0.6799009471695455, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 767346.6318565047, 767346.6318565047, 155794.9044215466], 
processed observation next is [1.0, 0.5652173913043478, 0.5909090909090909, 0.78, 1.0, 1.0, 0.5998761839619319, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2842024562431499, 0.2842024562431499, 0.3799875717598698], 
reward next is 0.6200, 
noisyNet noise sample is [array([1.4111154], dtype=float32), -2.052628]. 
=============================================
[2019-03-23 02:33:33,206] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:33:33,215] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7052
[2019-03-23 02:33:33,221] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.85, 94.5, 1.0, 2.0, 0.2107672027969843, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 228839.2537800013, 228839.2537800013, 75827.8236372432], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7799400.0000, 
sim time next is 7800000.0000, 
raw observation next is [14.03333333333333, 94.0, 1.0, 2.0, 0.2143113220488628, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 232688.1808912402, 232688.1808912399, 76721.60341894062], 
processed observation next is [1.0, 0.2608695652173913, 0.27424242424242407, 0.94, 1.0, 1.0, 0.017889152561078488, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08618080773749637, 0.08618080773749626, 0.18712586199741615], 
reward next is 0.8129, 
noisyNet noise sample is [array([-0.6576679], dtype=float32), 1.4086844]. 
=============================================
[2019-03-23 02:33:33,236] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[68.61461 ]
 [68.69794 ]
 [68.770546]
 [68.83499 ]
 [68.87687 ]], R is [[68.66138458]
 [68.78982544]
 [68.91902161]
 [69.04821777]
 [69.1778183 ]].
[2019-03-23 02:33:33,879] A3C_AGENT_WORKER-Thread-15 INFO:Local step 145500, global step 2328808: loss 3.4549
[2019-03-23 02:33:33,880] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 145500, global step 2328808: learning rate 0.0010
[2019-03-23 02:33:34,993] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 02:33:34,994] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:33:35,079] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run12
[2019-03-23 02:33:35,737] A3C_AGENT_WORKER-Thread-20 INFO:Local step 145500, global step 2329744: loss 2.3228
[2019-03-23 02:33:35,740] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 145500, global step 2329745: learning rate 0.0010
[2019-03-23 02:33:37,465] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:33:37,476] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8723
[2019-03-23 02:33:37,482] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 71.33333333333333, 1.0, 2.0, 0.2565219037470286, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 278531.3763952542, 278531.3763952539, 89904.25207089241], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 222000.0000, 
sim time next is 222600.0000, 
raw observation next is [17.0, 76.66666666666667, 1.0, 2.0, 0.2502631652843804, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 271733.7423242621, 271733.7423242621, 86592.91608199707], 
processed observation next is [0.0, 0.5652173913043478, 0.4090909090909091, 0.7666666666666667, 1.0, 1.0, 0.06282895660547551, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10064212678676374, 0.10064212678676374, 0.2112022343463343], 
reward next is 0.7888, 
noisyNet noise sample is [array([-1.3747884], dtype=float32), 0.5382274]. 
=============================================
[2019-03-23 02:33:40,147] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:33:40,154] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4401
[2019-03-23 02:33:40,159] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 78.0, 1.0, 2.0, 0.3664819474398046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 408258.0036324394, 408258.0036324391, 119657.6117765325], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 72000.0000, 
sim time next is 72600.0000, 
raw observation next is [19.83333333333334, 77.16666666666667, 1.0, 2.0, 0.3616144131142311, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 401612.8042307149, 401612.8042307149, 118752.8348948238], 
processed observation next is [1.0, 0.8695652173913043, 0.5378787878787882, 0.7716666666666667, 1.0, 1.0, 0.20201801639278885, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14874548304841292, 0.14874548304841292, 0.2896410607190824], 
reward next is 0.7104, 
noisyNet noise sample is [array([0.288354], dtype=float32), 1.4172751]. 
=============================================
[2019-03-23 02:33:40,467] A3C_AGENT_WORKER-Thread-19 INFO:Local step 145500, global step 2332048: loss 0.5214
[2019-03-23 02:33:40,475] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 145500, global step 2332050: learning rate 0.0010
[2019-03-23 02:33:41,029] A3C_AGENT_WORKER-Thread-10 INFO:Local step 145500, global step 2332312: loss 0.9307
[2019-03-23 02:33:41,032] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 145500, global step 2332312: learning rate 0.0010
[2019-03-23 02:33:41,054] A3C_AGENT_WORKER-Thread-17 INFO:Local step 145500, global step 2332320: loss 0.5944
[2019-03-23 02:33:41,060] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 145500, global step 2332321: learning rate 0.0010
[2019-03-23 02:33:41,533] A3C_AGENT_WORKER-Thread-18 INFO:Local step 145500, global step 2332546: loss 0.4413
[2019-03-23 02:33:41,535] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 145500, global step 2332546: learning rate 0.0010
[2019-03-23 02:33:42,170] A3C_AGENT_WORKER-Thread-22 INFO:Local step 145500, global step 2332845: loss 1.5067
[2019-03-23 02:33:42,171] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 145500, global step 2332846: learning rate 0.0010
[2019-03-23 02:33:42,184] A3C_AGENT_WORKER-Thread-16 INFO:Local step 145500, global step 2332851: loss 0.3873
[2019-03-23 02:33:42,187] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 145500, global step 2332852: learning rate 0.0010
[2019-03-23 02:33:42,189] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 02:33:42,189] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:33:42,264] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run12
[2019-03-23 02:33:42,386] A3C_AGENT_WORKER-Thread-12 INFO:Local step 145500, global step 2332932: loss 0.6922
[2019-03-23 02:33:42,389] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 145500, global step 2332932: learning rate 0.0010
[2019-03-23 02:33:42,635] A3C_AGENT_WORKER-Thread-13 INFO:Local step 145500, global step 2333078: loss 0.5050
[2019-03-23 02:33:42,636] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 145500, global step 2333078: learning rate 0.0010
[2019-03-23 02:33:42,814] A3C_AGENT_WORKER-Thread-11 INFO:Local step 145500, global step 2333185: loss 0.4080
[2019-03-23 02:33:42,816] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 145500, global step 2333186: learning rate 0.0010
[2019-03-23 02:33:43,412] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:33:43,419] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1067
[2019-03-23 02:33:43,425] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.38333333333333, 50.5, 1.0, 2.0, 0.308035639032129, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 334484.2039011743, 334484.2039011743, 110329.1182433779], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7840200.0000, 
sim time next is 7840800.0000, 
raw observation next is [22.2, 51.0, 1.0, 2.0, 0.3078338686020184, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 334265.0337525255, 334265.0337525257, 108549.3515038055], 
processed observation next is [1.0, 0.782608695652174, 0.6454545454545454, 0.51, 1.0, 1.0, 0.13479233575252297, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12380186435278723, 0.1238018643527873, 0.26475451586294024], 
reward next is 0.7352, 
noisyNet noise sample is [array([-1.5804873], dtype=float32), 0.5583954]. 
=============================================
[2019-03-23 02:33:44,074] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 02:33:44,074] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:33:44,163] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run12
[2019-03-23 02:33:48,398] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 02:33:48,400] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:33:48,482] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run12
[2019-03-23 02:33:48,819] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 02:33:48,819] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:33:48,884] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run12
[2019-03-23 02:33:48,935] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 02:33:48,938] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:33:49,007] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run12
[2019-03-23 02:33:49,260] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 02:33:49,260] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:33:49,300] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run12
[2019-03-23 02:33:49,786] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 02:33:49,787] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:33:49,789] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 02:33:49,789] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:33:49,832] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run12
[2019-03-23 02:33:49,852] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 02:33:49,853] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:33:49,856] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run12
[2019-03-23 02:33:49,909] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run12
[2019-03-23 02:33:50,132] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 02:33:50,132] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:33:50,148] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 02:33:50,149] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:33:50,163] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run12
[2019-03-23 02:33:50,219] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run12
[2019-03-23 02:33:56,380] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:33:56,385] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4533
[2019-03-23 02:33:56,391] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333334, 67.33333333333334, 1.0, 2.0, 0.3515660000517705, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 390621.9738593232, 390621.973859323, 118026.3232397959], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 582000.0000, 
sim time next is 582600.0000, 
raw observation next is [21.16666666666666, 68.16666666666666, 1.0, 2.0, 0.350310368963443, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 389002.9354973461, 389002.9354973461, 117835.1224770189], 
processed observation next is [1.0, 0.7391304347826086, 0.5984848484848482, 0.6816666666666665, 1.0, 1.0, 0.1878879612043037, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14407516129531336, 0.14407516129531336, 0.2874027377488266], 
reward next is 0.7126, 
noisyNet noise sample is [array([0.5618072], dtype=float32), 0.23554826]. 
=============================================
[2019-03-23 02:33:58,041] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:33:58,044] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2044
[2019-03-23 02:33:58,048] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.66666666666667, 58.0, 1.0, 2.0, 0.4741563524772419, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 514963.9062736907, 514963.9062736907, 111697.1032793081], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 127200.0000, 
sim time next is 127800.0000, 
raw observation next is [20.0, 55.0, 1.0, 2.0, 0.4686396258251933, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 508969.2542337475, 508969.2542337478, 109680.535832024], 
processed observation next is [1.0, 0.4782608695652174, 0.5454545454545454, 0.55, 1.0, 1.0, 0.3357995322814916, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18850713119768425, 0.18850713119768436, 0.26751350202932683], 
reward next is 0.7325, 
noisyNet noise sample is [array([-1.654866], dtype=float32), -0.18645465]. 
=============================================
[2019-03-23 02:34:03,317] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:34:03,329] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8857
[2019-03-23 02:34:03,332] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.83333333333333, 90.0, 1.0, 2.0, 0.2610004215442877, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 283395.5659343686, 283395.5659343689, 91045.29785843243], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 245400.0000, 
sim time next is 246000.0000, 
raw observation next is [15.66666666666667, 92.0, 1.0, 2.0, 0.2604472569241227, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 282794.7623930607, 282794.7623930604, 91452.19246589244], 
processed observation next is [0.0, 0.8695652173913043, 0.3484848484848486, 0.92, 1.0, 1.0, 0.07555907115515334, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10473880088631879, 0.10473880088631865, 0.22305412796559132], 
reward next is 0.7769, 
noisyNet noise sample is [array([-0.6294524], dtype=float32), 0.6648931]. 
=============================================
[2019-03-23 02:34:03,351] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[81.82821 ]
 [81.71974 ]
 [81.51597 ]
 [81.440765]
 [81.36481 ]], R is [[81.8755722 ]
 [81.83475494]
 [81.79449463]
 [81.74478149]
 [81.68379211]].
[2019-03-23 02:34:04,833] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:34:04,845] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5296
[2019-03-23 02:34:04,850] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 88.00000000000001, 1.0, 2.0, 0.3986569959993617, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 450470.500832469, 450470.500832469, 125417.1214424027], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 785400.0000, 
sim time next is 786000.0000, 
raw observation next is [20.0, 88.0, 1.0, 2.0, 0.3980543219520277, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 449777.8037989632, 449777.8037989632, 125355.3590414407], 
processed observation next is [0.0, 0.08695652173913043, 0.5454545454545454, 0.88, 1.0, 1.0, 0.24756790244003463, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16658437177739377, 0.16658437177739377, 0.30574477814985535], 
reward next is 0.6943, 
noisyNet noise sample is [array([0.8233245], dtype=float32), -0.29701057]. 
=============================================
[2019-03-23 02:34:04,875] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[63.220924]
 [62.871178]
 [62.47113 ]
 [62.066544]
 [61.70594 ]], R is [[63.64892197]
 [63.70653534]
 [63.76293182]
 [63.81706238]
 [63.86899948]].
[2019-03-23 02:34:06,980] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:34:06,990] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0531
[2019-03-23 02:34:06,998] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 94.0, 1.0, 2.0, 0.2817113695939763, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 305890.6893435643, 305890.6893435643, 101263.3792874331], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 630000.0000, 
sim time next is 630600.0000, 
raw observation next is [16.33333333333334, 92.16666666666667, 1.0, 2.0, 0.2846519441505457, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 309084.6684161572, 309084.6684161575, 104140.7946434527], 
processed observation next is [1.0, 0.30434782608695654, 0.37878787878787906, 0.9216666666666667, 1.0, 1.0, 0.10581493018818208, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11447580311709525, 0.11447580311709536, 0.2540019381547627], 
reward next is 0.7460, 
noisyNet noise sample is [array([0.63265663], dtype=float32), -0.17752284]. 
=============================================
[2019-03-23 02:34:17,137] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-23 02:34:17,140] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 02:34:17,141] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:34:17,141] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 02:34:17,142] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 02:34:17,143] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:34:17,143] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:34:17,144] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 02:34:17,145] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 02:34:17,145] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:34:17,146] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:34:17,160] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run95
[2019-03-23 02:34:17,160] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run95
[2019-03-23 02:34:17,206] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run95
[2019-03-23 02:34:17,228] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run95
[2019-03-23 02:34:17,249] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run95
[2019-03-23 02:34:33,178] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.2141346], dtype=float32), -0.17358929]
[2019-03-23 02:34:33,180] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [28.45, 61.5, 1.0, 2.0, 0.7610221895269041, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9660390753887194, 6.933874714151989, 6.9112, 95.55329247594267, 1407132.819426059, 1398032.91633473, 307957.3944520875]
[2019-03-23 02:34:33,183] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 02:34:33,186] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 7.779288e-36], sampled 0.9361438085874426
[2019-03-23 02:34:33,187] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1407132.819426059 W.
[2019-03-23 02:34:49,841] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.2141346], dtype=float32), -0.17358929]
[2019-03-23 02:34:49,842] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.59541213333333, 57.50935721333335, 1.0, 2.0, 0.2783758135843236, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 302249.8025009547, 302249.8025009551, 88283.87088960464]
[2019-03-23 02:34:49,842] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 02:34:49,846] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.1359218181806472
[2019-03-23 02:34:56,976] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.2141346], dtype=float32), -0.17358929]
[2019-03-23 02:34:56,977] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [25.46666666666667, 52.66666666666666, 1.0, 2.0, 0.4197231153331802, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 474220.4500608154, 474220.4500608154, 131667.2529869531]
[2019-03-23 02:34:56,978] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 02:34:56,980] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.9186210669312368
[2019-03-23 02:35:21,356] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.2141346], dtype=float32), -0.17358929]
[2019-03-23 02:35:21,358] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.36666666666667, 79.0, 1.0, 2.0, 0.5227746669991393, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 595637.5459090617, 595637.5459090617, 149718.6631084433]
[2019-03-23 02:35:21,359] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 02:35:21,363] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.597186400715004
[2019-03-23 02:35:44,876] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.2141346], dtype=float32), -0.17358929]
[2019-03-23 02:35:44,876] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [25.42492172333333, 66.33790115833334, 1.0, 2.0, 0.4991986554785508, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 569563.4217241397, 569563.4217241397, 145404.0120923699]
[2019-03-23 02:35:44,878] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 02:35:44,883] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.8522896299490775
[2019-03-23 02:36:04,305] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.2141346], dtype=float32), -0.17358929]
[2019-03-23 02:36:04,307] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [13.82985252833333, 95.44763074166667, 1.0, 2.0, 0.2464431768111976, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 267570.8502570302, 267570.8502570306, 84461.31154383485]
[2019-03-23 02:36:04,309] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 02:36:04,316] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.7455257693744047
[2019-03-23 02:36:06,306] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8855.7542 1663858414.4981 105.0000
[2019-03-23 02:36:06,642] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8509.1701 1774193721.5874 173.0000
[2019-03-23 02:36:06,717] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9060.3047 1656272944.4788 80.0000
[2019-03-23 02:36:06,777] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8573.5427 1683387571.2268 214.0000
[2019-03-23 02:36:06,809] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.1207 1706030998.8507 465.0000
[2019-03-23 02:36:07,823] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 2350000, evaluation results [2350000.0, 8509.170135696857, 1774193721.5873961, 173.0, 9060.304679780347, 1656272944.478839, 80.0, 8855.754186439062, 1663858414.498091, 105.0, 8596.120681065504, 1706030998.8506613, 465.0, 8573.54267693097, 1683387571.2267911, 214.0]
[2019-03-23 02:36:16,404] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:36:16,412] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8877
[2019-03-23 02:36:16,414] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 60.66666666666667, 1.0, 2.0, 0.5883776255746244, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 663993.3428710415, 663993.3428710415, 156652.3847923617], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 823200.0000, 
sim time next is 823800.0000, 
raw observation next is [29.0, 59.33333333333334, 1.0, 2.0, 0.5773065214767891, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 652881.3656993136, 652881.3656993136, 154764.5450449057], 
processed observation next is [0.0, 0.5217391304347826, 0.9545454545454546, 0.5933333333333334, 1.0, 1.0, 0.4716331518459863, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.24180791322196798, 0.24180791322196798, 0.3774745001095261], 
reward next is 0.6225, 
noisyNet noise sample is [array([-0.753996], dtype=float32), -0.82010597]. 
=============================================
[2019-03-23 02:36:17,933] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:36:17,943] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3958
[2019-03-23 02:36:17,950] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666667, 59.33333333333334, 1.0, 2.0, 0.3490444835329646, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 387915.5333895166, 387915.5333895166, 117867.7223027814], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 681600.0000, 
sim time next is 682200.0000, 
raw observation next is [22.5, 60.5, 1.0, 2.0, 0.352157305959374, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 391542.7507208275, 391542.7507208278, 118182.6677609515], 
processed observation next is [1.0, 0.9130434782608695, 0.6590909090909091, 0.605, 1.0, 1.0, 0.19019663244921747, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14501583360030648, 0.1450158336003066, 0.28825040917305245], 
reward next is 0.7117, 
noisyNet noise sample is [array([-0.943639], dtype=float32), 0.62922287]. 
=============================================
[2019-03-23 02:36:26,803] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:36:26,815] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4925
[2019-03-23 02:36:26,824] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 97.0, 1.0, 2.0, 0.2454784669405881, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 266537.1315975906, 266537.1315975909, 81355.87748054546], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1017000.0000, 
sim time next is 1017600.0000, 
raw observation next is [14.0, 96.0, 1.0, 2.0, 0.2421092700621567, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 262877.9154920749, 262877.9154920749, 80512.92979419083], 
processed observation next is [1.0, 0.782608695652174, 0.2727272727272727, 0.96, 1.0, 1.0, 0.052636587577695876, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09736219092299071, 0.09736219092299071, 0.19637299949802642], 
reward next is 0.8036, 
noisyNet noise sample is [array([0.79696715], dtype=float32), -0.8229243]. 
=============================================
[2019-03-23 02:36:36,950] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:36:36,959] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9550
[2019-03-23 02:36:36,967] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 100.0, 1.0, 2.0, 0.5225369270488095, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 569166.4259660146, 569166.4259660146, 129421.4137858291], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 991800.0000, 
sim time next is 992400.0000, 
raw observation next is [16.0, 100.0, 1.0, 2.0, 0.5444411694666207, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 593176.8958891769, 593176.8958891769, 131535.2800694303], 
processed observation next is [1.0, 0.4782608695652174, 0.36363636363636365, 1.0, 1.0, 1.0, 0.4305514618332758, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21969514662562106, 0.21969514662562106, 0.3208177562669032], 
reward next is 0.6792, 
noisyNet noise sample is [array([0.55323976], dtype=float32), -1.4324559]. 
=============================================
[2019-03-23 02:36:38,361] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:36:38,378] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4713
[2019-03-23 02:36:38,383] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 97.0, 1.0, 2.0, 0.2454784669405881, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 266537.1315975906, 266537.1315975909, 81355.87748054546], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1017000.0000, 
sim time next is 1017600.0000, 
raw observation next is [14.0, 96.0, 1.0, 2.0, 0.2421092700621567, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 262877.9154920749, 262877.9154920749, 80512.92979419083], 
processed observation next is [1.0, 0.782608695652174, 0.2727272727272727, 0.96, 1.0, 1.0, 0.052636587577695876, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09736219092299071, 0.09736219092299071, 0.19637299949802642], 
reward next is 0.8036, 
noisyNet noise sample is [array([0.1838761], dtype=float32), 0.99536294]. 
=============================================
[2019-03-23 02:36:39,475] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:36:39,483] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2281
[2019-03-23 02:36:39,492] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [11.0, 100.0, 1.0, 2.0, 0.3005860483793121, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 326392.2616203327, 326392.2616203327, 78631.4097779441], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1836000.0000, 
sim time next is 1836600.0000, 
raw observation next is [11.5, 97.00000000000001, 1.0, 2.0, 0.4227401783580459, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 459096.3089998421, 459096.3089998421, 91167.46833331221], 
processed observation next is [1.0, 0.2608695652173913, 0.1590909090909091, 0.9700000000000002, 1.0, 1.0, 0.27842522294755734, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17003566999994152, 0.17003566999994152, 0.2223596788617371], 
reward next is 0.7776, 
noisyNet noise sample is [array([-0.8988752], dtype=float32), -1.1614655]. 
=============================================
[2019-03-23 02:36:43,931] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:36:43,938] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7260
[2019-03-23 02:36:43,942] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.5, 74.5, 1.0, 2.0, 0.2297860477742447, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 249494.149261091, 249494.1492610913, 79724.93259951092], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2010600.0000, 
sim time next is 2011200.0000, 
raw observation next is [16.66666666666666, 73.66666666666667, 1.0, 2.0, 0.2319022492918302, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 251792.4461660622, 251792.4461660625, 80246.44794003424], 
processed observation next is [0.0, 0.2608695652173913, 0.39393939393939365, 0.7366666666666667, 1.0, 1.0, 0.03987781161478774, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.093256461542986, 0.09325646154298611, 0.19572304375618108], 
reward next is 0.8043, 
noisyNet noise sample is [array([-0.4164564], dtype=float32), -0.5661323]. 
=============================================
[2019-03-23 02:36:45,846] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:36:45,855] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4770
[2019-03-23 02:36:45,862] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 47.00000000000001, 1.0, 2.0, 0.3233467762266972, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 354438.7178729446, 354438.7178729443, 113953.7686776238], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2045400.0000, 
sim time next is 2046000.0000, 
raw observation next is [24.0, 47.0, 1.0, 2.0, 0.3250133699460445, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 356271.0040993772, 356271.0040993772, 114075.4025684873], 
processed observation next is [0.0, 0.6956521739130435, 0.7272727272727273, 0.47, 1.0, 1.0, 0.15626671243255563, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13195222374051008, 0.13195222374051008, 0.27823268919143246], 
reward next is 0.7218, 
noisyNet noise sample is [array([-1.9397337], dtype=float32), -1.9373194]. 
=============================================
[2019-03-23 02:36:45,872] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[73.69999]
 [73.71104]
 [73.66417]
 [73.6718 ]
 [73.67143]], R is [[73.68281555]
 [73.66805267]
 [73.65355682]
 [73.6390686 ]
 [73.6246109 ]].
[2019-03-23 02:36:49,026] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.6218432e-36 1.1149546e-16 0.0000000e+00 0.0000000e+00 1.0000000e+00], sum to 1.0000
[2019-03-23 02:36:49,033] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4447
[2019-03-23 02:36:49,040] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.0, 61.33333333333334, 1.0, 2.0, 0.4786996665655172, 1.0, 2.0, 0.4786996665655172, 1.0, 2.0, 0.9685910601780264, 6.911200000000001, 6.9112, 77.72171232085162, 1615191.436726197, 1615191.436726197, 348694.5069784268], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1264200.0000, 
sim time next is 1264800.0000, 
raw observation next is [28.0, 60.66666666666667, 1.0, 2.0, 0.4843800062790149, 1.0, 2.0, 0.4843800062790149, 1.0, 2.0, 0.9800845427299201, 6.9112, 6.9112, 77.3421103, 1634396.653715919, 1634396.653715919, 351682.5998580758], 
processed observation next is [1.0, 0.6521739130434783, 0.9090909090909091, 0.6066666666666667, 1.0, 1.0, 0.35547500784876856, 1.0, 1.0, 0.35547500784876856, 1.0, 1.0, 0.9715493467570286, 0.0, 0.0, 0.5085185399722538, 0.6053320939688589, 0.6053320939688589, 0.8577624386782337], 
reward next is 0.1422, 
noisyNet noise sample is [array([0.31003508], dtype=float32), -2.0657396]. 
=============================================
[2019-03-23 02:36:50,173] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:36:50,184] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4914
[2019-03-23 02:36:50,192] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.4096522295407832, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 464383.1700406927, 464383.1700406927, 127365.3624115034], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1222200.0000, 
sim time next is 1222800.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4093470310794208, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 464033.1836421578, 464033.1836421578, 127333.8414738034], 
processed observation next is [1.0, 0.13043478260869565, 0.5, 1.0, 1.0, 1.0, 0.26168378884927596, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1718641420896881, 0.1718641420896881, 0.3105703450580571], 
reward next is 0.6894, 
noisyNet noise sample is [array([0.41540056], dtype=float32), 0.68291014]. 
=============================================
[2019-03-23 02:36:56,896] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:36:56,904] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0406
[2019-03-23 02:36:56,908] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.5, 84.0, 1.0, 2.0, 0.5974324199609771, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 671715.9862289042, 671715.9862289042, 158462.398007246], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1503000.0000, 
sim time next is 1503600.0000, 
raw observation next is [25.66666666666666, 82.33333333333334, 1.0, 2.0, 0.5935527365367729, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 667883.7677019787, 667883.7677019787, 157815.4811854893], 
processed observation next is [0.0, 0.391304347826087, 0.8030303030303028, 0.8233333333333335, 1.0, 1.0, 0.49194092067096606, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.24736435840814025, 0.24736435840814025, 0.3849158077694861], 
reward next is 0.6151, 
noisyNet noise sample is [array([-0.26864183], dtype=float32), -0.8127094]. 
=============================================
[2019-03-23 02:36:57,397] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 9.028271e-27], sum to 1.0000
[2019-03-23 02:36:57,410] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0944
[2019-03-23 02:36:57,419] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1422485.989230022 W.
[2019-03-23 02:36:57,424] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.0, 76.33333333333334, 1.0, 2.0, 0.7773897275324593, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9865530188920543, 6.911200000000001, 6.9112, 77.32846344354104, 1422485.989230022, 1422485.989230021, 312223.5348979967], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1347600.0000, 
sim time next is 1348200.0000, 
raw observation next is [26.5, 79.5, 1.0, 2.0, 0.4193222740254616, 1.0, 1.0, 0.4193222740254616, 1.0, 2.0, 0.8484480652943903, 6.911199999999998, 6.9112, 77.3421103, 1414604.421231637, 1414604.421231638, 316825.3593951321], 
processed observation next is [1.0, 0.6086956521739131, 0.8409090909090909, 0.795, 1.0, 1.0, 0.274152842531827, 1.0, 0.5, 0.274152842531827, 1.0, 1.0, 0.7834972361348435, -1.7763568394002506e-16, 0.0, 0.5085185399722538, 0.5239275634191248, 0.5239275634191252, 0.7727447790125174], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.10819475], dtype=float32), 1.1647611]. 
=============================================
[2019-03-23 02:36:59,171] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:36:59,182] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1253
[2019-03-23 02:36:59,186] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4895283028006488, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 558527.7051722655, 558527.7051722655, 140282.5963936864], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1392000.0000, 
sim time next is 1392600.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.4898317255907493, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 558874.0742087378, 558874.0742087378, 140317.3834192216], 
processed observation next is [0.0, 0.08695652173913043, 0.5909090909090909, 1.0, 1.0, 1.0, 0.36228965698843657, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20699039785508808, 0.20699039785508808, 0.3422375205346868], 
reward next is 0.6578, 
noisyNet noise sample is [array([0.3827617], dtype=float32), -0.31905928]. 
=============================================
[2019-03-23 02:37:00,067] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-23 02:37:00,069] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 02:37:00,069] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 02:37:00,071] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:37:00,071] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 02:37:00,071] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:37:00,072] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:37:00,073] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 02:37:00,076] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 02:37:00,076] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:37:00,077] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:37:00,097] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run96
[2019-03-23 02:37:00,124] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run96
[2019-03-23 02:37:00,145] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run96
[2019-03-23 02:37:00,167] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run96
[2019-03-23 02:37:00,168] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run96
[2019-03-23 02:37:13,735] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.29435056], dtype=float32), -0.18214208]
[2019-03-23 02:37:13,736] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.6, 42.0, 1.0, 2.0, 0.3955348990469906, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 446320.9693416511, 446320.9693416507, 129104.8660551799]
[2019-03-23 02:37:13,738] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 02:37:13,743] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.039910010504005444
[2019-03-23 02:37:46,190] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.29435056], dtype=float32), -0.18214208]
[2019-03-23 02:37:46,191] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [17.76666666666667, 70.0, 1.0, 2.0, 0.2568784897598239, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 278903.4155437775, 278903.4155437775, 91138.89777751178]
[2019-03-23 02:37:46,192] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 02:37:46,194] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.7304332374800856
[2019-03-23 02:38:01,434] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.29435056], dtype=float32), -0.18214208]
[2019-03-23 02:38:01,435] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.33333333333334, 93.0, 1.0, 2.0, 0.4579742266601688, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 522437.5545695174, 522437.5545695171, 139938.6678363185]
[2019-03-23 02:38:01,436] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 02:38:01,440] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.48804858938843576
[2019-03-23 02:38:16,372] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.29435056], dtype=float32), -0.18214208]
[2019-03-23 02:38:16,375] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.46666666666667, 83.66666666666667, 1.0, 2.0, 0.913374515457869, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32844313234509, 1040869.752948196, 1040869.752948196, 196632.9226825782]
[2019-03-23 02:38:16,376] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 02:38:16,378] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.1494113e-26], sampled 0.8137157597407265
[2019-03-23 02:38:30,568] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.29435056], dtype=float32), -0.18214208]
[2019-03-23 02:38:30,569] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [28.96666666666667, 46.33333333333334, 1.0, 2.0, 0.6856023607045554, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 782281.3014874886, 782281.3014874882, 168233.4462508255]
[2019-03-23 02:38:30,569] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 02:38:30,575] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.6767036896823474
[2019-03-23 02:38:49,418] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8854.9574 1663902404.7778 105.0000
[2019-03-23 02:38:49,445] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9059.4942 1656316253.3799 80.0000
[2019-03-23 02:38:49,855] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8595.3078 1706321224.9041 462.0000
[2019-03-23 02:38:49,857] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8572.7541 1683719637.8140 214.0000
[2019-03-23 02:38:49,913] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8497.2180 1777937447.3055 166.0000
[2019-03-23 02:38:50,933] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 2375000, evaluation results [2375000.0, 8497.21795701899, 1777937447.305532, 166.0, 9059.494152790281, 1656316253.3798783, 80.0, 8854.957448082614, 1663902404.7778378, 105.0, 8595.307754145371, 1706321224.904148, 462.0, 8572.754131484187, 1683719637.8139696, 214.0]
[2019-03-23 02:38:51,118] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:38:51,127] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2208
[2019-03-23 02:38:51,130] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.16666666666667, 99.00000000000001, 1.0, 2.0, 0.4865590593116092, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 555114.9260074164, 555114.9260074162, 140021.5029739678], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1408200.0000, 
sim time next is 1408800.0000, 
raw observation next is [21.33333333333334, 98.0, 1.0, 2.0, 0.4882802525372402, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 557044.1380693002, 557044.1380693002, 140320.937032418], 
processed observation next is [0.0, 0.30434782608695654, 0.6060606060606063, 0.98, 1.0, 1.0, 0.36035031567155024, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20631264372937044, 0.20631264372937044, 0.34224618788394634], 
reward next is 0.6578, 
noisyNet noise sample is [array([-0.393063], dtype=float32), 0.36184406]. 
=============================================
[2019-03-23 02:39:07,252] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 9.944394e-29], sum to 1.0000
[2019-03-23 02:39:07,264] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1264
[2019-03-23 02:39:07,271] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.66666666666667, 53.66666666666667, 1.0, 2.0, 0.2722786013033846, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 295645.1921975964, 295645.1921975961, 82226.65244440176], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1704000.0000, 
sim time next is 1704600.0000, 
raw observation next is [18.5, 52.5, 1.0, 2.0, 0.2618558258129114, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 284324.639673782, 284324.639673782, 79614.29908032565], 
processed observation next is [1.0, 0.7391304347826086, 0.4772727272727273, 0.525, 1.0, 1.0, 0.07731978226613923, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10530542210140073, 0.10530542210140073, 0.19418121726908696], 
reward next is 0.8058, 
noisyNet noise sample is [array([-0.26571107], dtype=float32), -0.48144776]. 
=============================================
[2019-03-23 02:39:07,772] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:39:07,781] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4451
[2019-03-23 02:39:07,786] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.5, 61.16666666666666, 1.0, 2.0, 0.2136651987938725, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 231986.4862860882, 231986.4862860882, 70134.49274681786], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1713000.0000, 
sim time next is 1713600.0000, 
raw observation next is [14.0, 63.0, 1.0, 2.0, 0.2089981045601468, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 226918.017700214, 226918.0177002137, 69433.30445470197], 
processed observation next is [1.0, 0.8695652173913043, 0.2727272727272727, 0.63, 1.0, 1.0, 0.011247630700183496, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08404371025933852, 0.0840437102593384, 0.1693495230602487], 
reward next is 0.8307, 
noisyNet noise sample is [array([-0.24346654], dtype=float32), 0.3026888]. 
=============================================
[2019-03-23 02:39:14,951] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:39:14,958] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8356
[2019-03-23 02:39:14,962] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.16666666666666, 41.16666666666666, 1.0, 2.0, 0.3577918199454289, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 401496.0735611017, 401496.0735611014, 120287.270890741], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2643000.0000, 
sim time next is 2643600.0000, 
raw observation next is [27.33333333333334, 40.33333333333334, 1.0, 2.0, 0.3572306478135433, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 400738.6364177393, 400738.6364177393, 120178.2257965106], 
processed observation next is [0.0, 0.6086956521739131, 0.878787878787879, 0.40333333333333343, 1.0, 1.0, 0.1965383097669291, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14842171719175531, 0.14842171719175531, 0.29311762389392826], 
reward next is 0.7069, 
noisyNet noise sample is [array([0.32590416], dtype=float32), 2.004365]. 
=============================================
[2019-03-23 02:39:18,370] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:39:18,380] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7130
[2019-03-23 02:39:18,398] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 100.0, 1.0, 2.0, 0.338122666654246, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 374140.7818413713, 374140.7818413716, 116348.409893502], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2703600.0000, 
sim time next is 2704200.0000, 
raw observation next is [17.46666666666667, 99.16666666666667, 1.0, 2.0, 0.3437084372444648, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 382045.6504955766, 382045.6504955766, 117476.3531818023], 
processed observation next is [0.0, 0.30434782608695654, 0.4303030303030304, 0.9916666666666667, 1.0, 1.0, 0.179635546555581, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14149838907243578, 0.14149838907243578, 0.2865276906873227], 
reward next is 0.7135, 
noisyNet noise sample is [array([0.14468908], dtype=float32), -0.9844944]. 
=============================================
[2019-03-23 02:39:19,739] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:39:19,751] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3189
[2019-03-23 02:39:19,757] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.83333333333333, 77.83333333333334, 1.0, 2.0, 0.2252544342944469, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 244572.6350061136, 244572.6350061138, 78150.92838640772], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2081400.0000, 
sim time next is 2082000.0000, 
raw observation next is [15.66666666666667, 78.66666666666667, 1.0, 2.0, 0.2230015674704277, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 242125.9496795052, 242125.9496795055, 77630.55503201055], 
processed observation next is [0.0, 0.08695652173913043, 0.3484848484848486, 0.7866666666666667, 1.0, 1.0, 0.02875195933803462, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.089676277659076, 0.08967627765907611, 0.18934281715124526], 
reward next is 0.8107, 
noisyNet noise sample is [array([0.79696244], dtype=float32), -1.6599481]. 
=============================================
[2019-03-23 02:39:19,776] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[70.84358 ]
 [70.48034 ]
 [70.39492 ]
 [70.408   ]
 [70.511055]], R is [[70.81118774]
 [70.91246033]
 [71.01113892]
 [71.10651398]
 [71.19888306]].
[2019-03-23 02:39:30,736] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:39:30,744] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1157
[2019-03-23 02:39:30,748] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 88.0, 1.0, 2.0, 0.3042870864071345, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 330412.4101245691, 330412.4101245691, 110409.7253532273], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2164800.0000, 
sim time next is 2165400.0000, 
raw observation next is [17.0, 88.0, 1.0, 2.0, 0.3032969092368858, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 329336.8547555919, 329336.8547555922, 110322.604075456], 
processed observation next is [1.0, 0.043478260869565216, 0.4090909090909091, 0.88, 1.0, 1.0, 0.1291211365461072, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12197661287244144, 0.12197661287244155, 0.26907952213525854], 
reward next is 0.7309, 
noisyNet noise sample is [array([-0.8661797], dtype=float32), 0.37613502]. 
=============================================
[2019-03-23 02:39:36,712] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:39:36,720] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5967
[2019-03-23 02:39:36,725] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.5, 77.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 207823.1936411183, 207823.1936411186, 68288.34416198186], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2269800.0000, 
sim time next is 2270400.0000, 
raw observation next is [13.66666666666667, 77.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 209577.5044586338, 209577.5044586338, 68811.16751033325], 
processed observation next is [1.0, 0.2608695652173913, 0.25757575757575774, 0.77, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.07762129794764215, 0.07762129794764215, 0.1678321158788616], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.0348796], dtype=float32), -0.8569477]. 
=============================================
[2019-03-23 02:39:40,507] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:39:40,513] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8384
[2019-03-23 02:39:40,518] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.16666666666666, 87.16666666666667, 1.0, 2.0, 0.4433668258906437, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 504607.5860928384, 504607.5860928387, 132227.4243100815], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3185400.0000, 
sim time next is 3186000.0000, 
raw observation next is [21.0, 88.0, 1.0, 2.0, 0.4425805201444099, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 503573.1896423055, 503573.1896423055, 132010.6880320405], 
processed observation next is [1.0, 0.9130434782608695, 0.5909090909090909, 0.88, 1.0, 1.0, 0.30322565018051234, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18650858875640944, 0.18650858875640944, 0.3219772878830256], 
reward next is 0.6780, 
noisyNet noise sample is [array([-0.52450633], dtype=float32), 1.0591754]. 
=============================================
[2019-03-23 02:39:40,539] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[76.8886 ]
 [76.8505 ]
 [76.8906 ]
 [76.80298]
 [76.78466]], R is [[76.84674072]
 [76.75577545]
 [76.66495514]
 [76.57406616]
 [76.48345184]].
[2019-03-23 02:39:41,627] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:39:41,634] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4013
[2019-03-23 02:39:41,638] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.5, 53.5, 1.0, 2.0, 0.2425322856159216, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 263337.3425577041, 263337.3425577038, 75565.2440867795], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2320200.0000, 
sim time next is 2320800.0000, 
raw observation next is [17.33333333333333, 54.0, 1.0, 2.0, 0.2410048894787761, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 261678.4762256738, 261678.4762256741, 75241.40098119726], 
processed observation next is [1.0, 0.8695652173913043, 0.42424242424242403, 0.54, 1.0, 1.0, 0.051256111848470114, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09691795415765696, 0.09691795415765707, 0.18351561214926163], 
reward next is 0.8165, 
noisyNet noise sample is [array([-0.27695662], dtype=float32), 0.48971167]. 
=============================================
[2019-03-23 02:39:43,076] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-23 02:39:43,079] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 02:39:43,080] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 02:39:43,081] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 02:39:43,081] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:39:43,081] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:39:43,083] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 02:39:43,082] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:39:43,084] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 02:39:43,087] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:39:43,088] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:39:43,111] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run97
[2019-03-23 02:39:43,137] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run97
[2019-03-23 02:39:43,138] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run97
[2019-03-23 02:39:43,161] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run97
[2019-03-23 02:39:43,184] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run97
[2019-03-23 02:40:01,232] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06510237], dtype=float32), -0.17922874]
[2019-03-23 02:40:01,236] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.35, 74.0, 1.0, 2.0, 0.5062638717271415, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 577623.8562667856, 577623.8562667856, 146257.5783911621]
[2019-03-23 02:40:01,237] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 02:40:01,240] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 7.009764e-37], sampled 0.7702271133501761
[2019-03-23 02:40:11,472] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06510237], dtype=float32), -0.17922874]
[2019-03-23 02:40:11,473] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [25.50521804, 53.20750065999999, 1.0, 2.0, 0.5012722907962776, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 567577.9578379033, 567577.9578379029, 140491.8415620938]
[2019-03-23 02:40:11,474] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 02:40:11,479] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.879200964089226
[2019-03-23 02:40:25,235] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06510237], dtype=float32), -0.17922874]
[2019-03-23 02:40:25,236] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.86666666666667, 78.33333333333333, 1.0, 2.0, 0.4553095221110327, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 519058.0886272414, 519058.0886272414, 138887.0698917605]
[2019-03-23 02:40:25,237] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 02:40:25,243] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.543421241508446
[2019-03-23 02:40:26,183] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06510237], dtype=float32), -0.17922874]
[2019-03-23 02:40:26,185] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.1, 90.0, 1.0, 2.0, 0.4528215753711531, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 515886.956987187, 515886.9569871866, 138140.2734766989]
[2019-03-23 02:40:26,187] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 02:40:26,188] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.03363863572055614
[2019-03-23 02:40:35,129] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06510237], dtype=float32), -0.17922874]
[2019-03-23 02:40:35,131] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.34296068, 83.97769383333333, 1.0, 2.0, 0.576708632895126, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 654213.7636499479, 654213.7636499476, 158251.0192097303]
[2019-03-23 02:40:35,133] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 02:40:35,135] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.21702410054877674
[2019-03-23 02:40:43,236] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06510237], dtype=float32), -0.17922874]
[2019-03-23 02:40:43,237] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.33333333333334, 98.0, 1.0, 2.0, 0.3813127037887906, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 428736.819226819, 428736.8192268193, 122690.0919120392]
[2019-03-23 02:40:43,238] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 02:40:43,241] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.9066961693235551
[2019-03-23 02:41:02,916] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06510237], dtype=float32), -0.17922874]
[2019-03-23 02:41:02,918] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [9.584290448333332, 76.779497185, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 160662.2660519697, 160662.2660519701, 63645.55885331957]
[2019-03-23 02:41:02,920] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 02:41:02,922] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.07617200219333997
[2019-03-23 02:41:14,787] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06510237], dtype=float32), -0.17922874]
[2019-03-23 02:41:14,789] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.43333333333333, 58.33333333333333, 1.0, 2.0, 0.4935862470575583, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 552934.613273065, 552934.6132730646, 132306.8447620911]
[2019-03-23 02:41:14,790] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 02:41:14,792] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.5312081911932641
[2019-03-23 02:41:32,284] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8603.1806 1707487575.5267 428.0000
[2019-03-23 02:41:32,330] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9059.4942 1656316253.3799 80.0000
[2019-03-23 02:41:32,522] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8579.2811 1685428955.7146 172.0000
[2019-03-23 02:41:32,529] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8482.3831 1784521401.8453 133.0000
[2019-03-23 02:41:32,611] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8854.9574 1663902404.7778 105.0000
[2019-03-23 02:41:33,634] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 2400000, evaluation results [2400000.0, 8482.38311295634, 1784521401.8453398, 133.0, 9059.494152790281, 1656316253.3798783, 80.0, 8854.957448082614, 1663902404.7778378, 105.0, 8603.18056368467, 1707487575.5267124, 428.0, 8579.281132889771, 1685428955.7145836, 172.0]
[2019-03-23 02:41:36,700] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:41:36,709] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7328
[2019-03-23 02:41:36,715] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 44.0, 1.0, 2.0, 0.7179897052013205, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 779994.9262664831, 779994.9262664829, 145871.7517543816], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2390400.0000, 
sim time next is 2391000.0000, 
raw observation next is [22.83333333333334, 44.33333333333334, 1.0, 2.0, 0.640325981129768, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 695563.8134817843, 695563.8134817843, 135842.683474238], 
processed observation next is [1.0, 0.6956521739130435, 0.6742424242424245, 0.4433333333333334, 1.0, 1.0, 0.55040747641221, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.25761622721547567, 0.25761622721547567, 0.3313236182298488], 
reward next is 0.6687, 
noisyNet noise sample is [array([0.81199855], dtype=float32), 0.6649512]. 
=============================================
[2019-03-23 02:41:36,735] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[74.04798]
 [74.0083 ]
 [74.17329]
 [74.83081]
 [74.61398]], R is [[74.7253952 ]
 [74.62236023]
 [74.51972961]
 [74.42938232]
 [74.36418152]].
[2019-03-23 02:41:39,032] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:41:39,038] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6730
[2019-03-23 02:41:39,044] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 97.0, 1.0, 2.0, 0.5201459316083114, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 592630.492742131, 592630.492742131, 145170.5312913271], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2928600.0000, 
sim time next is 2929200.0000, 
raw observation next is [22.0, 98.0, 1.0, 2.0, 0.5245952060498715, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 597424.4238375918, 597424.4238375918, 145955.0748403805], 
processed observation next is [1.0, 0.9130434782608695, 0.6363636363636364, 0.98, 1.0, 1.0, 0.40574400756233936, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22126830512503398, 0.22126830512503398, 0.35598798741556215], 
reward next is 0.6440, 
noisyNet noise sample is [array([-0.29151553], dtype=float32), 0.24073474]. 
=============================================
[2019-03-23 02:41:39,762] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:41:39,767] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3968
[2019-03-23 02:41:39,775] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.06666666666667, 98.0, 1.0, 2.0, 0.2966953167558924, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 322166.0996132002, 322166.0996132002, 110971.1713547505], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2605800.0000, 
sim time next is 2606400.0000, 
raw observation next is [16.0, 100.0, 1.0, 2.0, 0.3010933413535734, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 326943.2923857965, 326943.2923857968, 111266.3498857405], 
processed observation next is [0.0, 0.17391304347826086, 0.36363636363636365, 1.0, 1.0, 1.0, 0.12636667669196675, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12109010829103574, 0.12109010829103585, 0.27138134118473295], 
reward next is 0.7286, 
noisyNet noise sample is [array([1.26742], dtype=float32), 1.9670135]. 
=============================================
[2019-03-23 02:41:40,290] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 3.559468e-38], sum to 1.0000
[2019-03-23 02:41:40,303] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2864
[2019-03-23 02:41:40,311] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1339008.665488478 W.
[2019-03-23 02:41:40,316] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.0, 58.0, 1.0, 2.0, 0.3948802172358314, 1.0, 1.0, 0.3948802172358314, 1.0, 2.0, 0.7990774175073925, 6.911199999999999, 6.9112, 77.3421103, 1339008.665488478, 1339008.665488478, 302144.8701901005], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2814000.0000, 
sim time next is 2814600.0000, 
raw observation next is [28.0, 58.0, 1.0, 2.0, 0.7268743547105259, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9777082779544658, 6.9112, 6.9112, 77.32846343901166, 1373945.922410664, 1373945.922410664, 296632.7659047016], 
processed observation next is [1.0, 0.5652173913043478, 0.9090909090909091, 0.58, 1.0, 1.0, 0.6585929433881573, 0.0, 0.5, -0.25, 1.0, 1.0, 0.9681546827920942, 0.0, 0.0, 0.5084288128908737, 0.5088688601520978, 0.5088688601520978, 0.723494550987077], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2085985], dtype=float32), 1.0607699]. 
=============================================
[2019-03-23 02:41:46,463] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:41:46,471] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7163
[2019-03-23 02:41:46,474] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.3, 88.0, 1.0, 2.0, 0.2996883917528385, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 325417.2123549432, 325417.2123549429, 111172.2756192271], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2595600.0000, 
sim time next is 2596200.0000, 
raw observation next is [17.23333333333333, 89.00000000000001, 1.0, 2.0, 0.3046946669001047, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 331066.084637569, 331066.084637569, 111582.0363303281], 
processed observation next is [0.0, 0.043478260869565216, 0.41969696969696957, 0.8900000000000001, 1.0, 1.0, 0.13086833362513087, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12261706838428481, 0.12261706838428481, 0.27215130812275146], 
reward next is 0.7278, 
noisyNet noise sample is [array([-0.31629983], dtype=float32), -0.4793596]. 
=============================================
[2019-03-23 02:41:46,585] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:41:46,595] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6673
[2019-03-23 02:41:46,602] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 54.0, 1.0, 2.0, 0.2983717857477888, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 323987.096979467, 323987.096979467, 107925.308507375], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2571600.0000, 
sim time next is 2572200.0000, 
raw observation next is [21.5, 54.5, 1.0, 2.0, 0.2965085631743481, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 321963.2464294387, 321963.2464294384, 106289.690650369], 
processed observation next is [1.0, 0.782608695652174, 0.6136363636363636, 0.545, 1.0, 1.0, 0.1206357039679351, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11924564682571803, 0.11924564682571794, 0.25924314792772923], 
reward next is 0.7408, 
noisyNet noise sample is [array([0.18648078], dtype=float32), 0.25310117]. 
=============================================
[2019-03-23 02:41:52,827] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:41:52,835] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6877
[2019-03-23 02:41:52,841] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 88.0, 1.0, 2.0, 0.3325503606706393, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 366003.6382282531, 366003.6382282531, 115163.1286270642], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3217800.0000, 
sim time next is 3218400.0000, 
raw observation next is [18.0, 88.0, 1.0, 2.0, 0.3319069643410172, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 365292.9741728421, 365292.9741728424, 115114.7042421897], 
processed observation next is [0.0, 0.2608695652173913, 0.45454545454545453, 0.88, 1.0, 1.0, 0.16488370542627145, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13529369413808967, 0.13529369413808978, 0.2807675713224139], 
reward next is 0.7192, 
noisyNet noise sample is [array([1.9406719], dtype=float32), -0.55655843]. 
=============================================
[2019-03-23 02:41:53,684] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:41:53,693] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2772
[2019-03-23 02:41:53,697] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 68.33333333333333, 1.0, 2.0, 0.4740163278503434, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 540887.7400337274, 540887.7400337274, 137866.9902175103], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2729400.0000, 
sim time next is 2730000.0000, 
raw observation next is [25.0, 67.66666666666667, 1.0, 2.0, 0.4707563737724144, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 537141.6652244882, 537141.6652244885, 137288.7804439231], 
processed observation next is [0.0, 0.6086956521739131, 0.7727272727272727, 0.6766666666666667, 1.0, 1.0, 0.338445467215518, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1989413574905512, 0.19894135749055128, 0.3348506840095686], 
reward next is 0.6651, 
noisyNet noise sample is [array([1.3914036], dtype=float32), -0.26955926]. 
=============================================
[2019-03-23 02:41:53,712] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[65.65943 ]
 [65.59316 ]
 [65.440056]
 [65.347404]
 [65.25126 ]], R is [[65.74127197]
 [65.74760437]
 [65.75232697]
 [65.75518799]
 [65.75631714]].
[2019-03-23 02:41:55,511] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.7326181e-36 1.0000000e+00 2.0100345e-35 0.0000000e+00 6.9486010e-17], sum to 1.0000
[2019-03-23 02:41:55,518] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7476
[2019-03-23 02:41:55,526] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1247262.153258955 W.
[2019-03-23 02:41:55,537] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.66666666666667, 65.66666666666667, 1.0, 2.0, 0.3657278613441785, 1.0, 2.0, 0.3657278613441785, 1.0, 1.0, 0.7408542212423022, 6.911199999999999, 6.9112, 77.3421103, 1247262.153258955, 1247262.153258956, 285612.5851790467], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2803800.0000, 
sim time next is 2804400.0000, 
raw observation next is [26.0, 65.0, 1.0, 2.0, 0.4845119369147455, 1.0, 2.0, 0.4845119369147455, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846344333916, 1101424.508794817, 1101424.508794817, 227861.736992672], 
processed observation next is [1.0, 0.4782608695652174, 0.8181818181818182, 0.65, 1.0, 1.0, 0.3556399211434318, 1.0, 1.0, 0.3556399211434318, 0.0, 0.5, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129193267, 0.4079350032573396, 0.4079350032573396, 0.5557603341284683], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.4022828], dtype=float32), -0.841444]. 
=============================================
[2019-03-23 02:42:09,796] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:42:09,804] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6205
[2019-03-23 02:42:09,811] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 78.0, 1.0, 2.0, 0.4204687016382813, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 476645.2773611488, 476645.2773611488, 128393.1454628142], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3018000.0000, 
sim time next is 3018600.0000, 
raw observation next is [21.5, 78.0, 1.0, 2.0, 0.4157195898546904, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 470691.363906912, 470691.363906912, 127563.3650832239], 
processed observation next is [1.0, 0.9565217391304348, 0.6136363636363636, 0.78, 1.0, 1.0, 0.2696494873183629, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17433013478033776, 0.17433013478033776, 0.31113015873957045], 
reward next is 0.6889, 
noisyNet noise sample is [array([-0.25928867], dtype=float32), -1.6766326]. 
=============================================
[2019-03-23 02:42:15,886] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.7157842e-32 7.3417263e-19 5.9818394e-35 0.0000000e+00 1.0000000e+00], sum to 1.0000
[2019-03-23 02:42:15,895] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0466
[2019-03-23 02:42:15,898] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.0, 74.0, 1.0, 2.0, 0.5027754073258071, 1.0, 2.0, 0.4951761406045109, 1.0, 2.0, 0.9865530188920543, 6.9112, 6.9112, 77.3421103, 1670878.767324148, 1670878.767324148, 356202.8496797024], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3592800.0000, 
sim time next is 3593400.0000, 
raw observation next is [27.16666666666666, 73.33333333333334, 1.0, 2.0, 0.4505574554684544, 1.0, 2.0, 0.4505574554684544, 1.0, 2.0, 0.9116486890294827, 6.9112, 6.9112, 77.3421103, 1520119.281774411, 1520119.281774411, 332996.3638659131], 
processed observation next is [1.0, 0.6086956521739131, 0.871212121212121, 0.7333333333333334, 1.0, 1.0, 0.3131968193355679, 1.0, 1.0, 0.3131968193355679, 1.0, 1.0, 0.8737838414706898, 0.0, 0.0, 0.5085185399722538, 0.56300714139793, 0.56300714139793, 0.8121862533314954], 
reward next is 0.1878, 
noisyNet noise sample is [array([-0.9368214], dtype=float32), 0.16652432]. 
=============================================
[2019-03-23 02:42:19,324] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.5044210e-36 1.0000000e+00 6.3074585e-36 0.0000000e+00 4.7358598e-17], sum to 1.0000
[2019-03-23 02:42:19,335] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9068
[2019-03-23 02:42:19,344] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1256270.573680913 W.
[2019-03-23 02:42:19,349] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.33333333333334, 72.0, 1.0, 2.0, 0.3680046966128163, 1.0, 1.0, 0.3680046966128163, 1.0, 2.0, 0.7454052267828268, 6.9112, 6.9112, 77.3421103, 1256270.573680913, 1256270.573680913, 285754.244595243], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3162000.0000, 
sim time next is 3162600.0000, 
raw observation next is [24.0, 73.5, 1.0, 2.0, 0.5768490021816882, 1.0, 2.0, 0.5768490021816882, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1313808.338173635, 1313808.338173635, 249799.1179368765], 
processed observation next is [1.0, 0.6086956521739131, 0.7272727272727273, 0.735, 1.0, 1.0, 0.47106125272711025, 1.0, 1.0, 0.47106125272711025, 0.0, 0.5, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.48659568080505, 0.48659568080505, 0.6092661413094549], 
reward next is 0.3907, 
noisyNet noise sample is [array([-0.2867429], dtype=float32), 1.7373039]. 
=============================================
[2019-03-23 02:42:24,432] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 3.0639375e-31], sum to 1.0000
[2019-03-23 02:42:24,441] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6860
[2019-03-23 02:42:24,447] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 71.5, 1.0, 2.0, 0.8764335482035671, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 998999.192415434, 998999.192415434, 190800.1032021579], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3407400.0000, 
sim time next is 3408000.0000, 
raw observation next is [24.0, 69.33333333333333, 1.0, 2.0, 0.9399427475439973, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1072037.614974204, 1072037.614974204, 202375.0153663342], 
processed observation next is [1.0, 0.43478260869565216, 0.7272727272727273, 0.6933333333333332, 1.0, 1.0, 0.9249284344299965, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.39705096850896443, 0.39705096850896443, 0.49359759845447365], 
reward next is 0.5064, 
noisyNet noise sample is [array([-0.74816835], dtype=float32), 0.39084655]. 
=============================================
[2019-03-23 02:42:24,465] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[57.08786 ]
 [57.542755]
 [57.881374]
 [58.077988]
 [56.548935]], R is [[56.19471741]
 [56.16740417]
 [56.16287613]
 [56.18467712]
 [56.22955322]].
[2019-03-23 02:42:25,771] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-23 02:42:25,773] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 02:42:25,774] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:42:25,775] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 02:42:25,775] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:42:25,776] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 02:42:25,778] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 02:42:25,779] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:42:25,779] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:42:25,777] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 02:42:25,782] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:42:25,809] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run98
[2019-03-23 02:42:25,833] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run98
[2019-03-23 02:42:25,835] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run98
[2019-03-23 02:42:25,891] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run98
[2019-03-23 02:42:25,892] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run98
[2019-03-23 02:42:34,475] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00732164], dtype=float32), -0.17039555]
[2019-03-23 02:42:34,476] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.42585472, 71.97359266, 1.0, 2.0, 0.3599908030372692, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 392932.6536779043, 392932.6536779043, 120397.6825449681]
[2019-03-23 02:42:34,477] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 02:42:34,481] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.2947225236707066
[2019-03-23 02:43:05,191] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00732164], dtype=float32), -0.17039555]
[2019-03-23 02:43:05,194] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.53333333333333, 66.33333333333334, 1.0, 2.0, 0.3445493755848552, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 377310.3482754285, 377310.3482754285, 119684.9466061471]
[2019-03-23 02:43:05,195] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 02:43:05,199] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.13517419472423597
[2019-03-23 02:43:13,002] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00732164], dtype=float32), -0.17039555]
[2019-03-23 02:43:13,006] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [15.3, 84.0, 1.0, 2.0, 0.2201481481726017, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 239015.8617612167, 239015.8617612164, 82747.71791878561]
[2019-03-23 02:43:13,008] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 02:43:13,011] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.4573129219687886
[2019-03-23 02:43:25,286] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00732164], dtype=float32), -0.17039555]
[2019-03-23 02:43:25,286] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [15.01087881, 95.25712572666666, 1.0, 2.0, 0.2549005307044744, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 276755.370582875, 276755.3705828746, 92233.40874432038]
[2019-03-23 02:43:25,288] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 02:43:25,291] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.5382481393761855
[2019-03-23 02:43:32,971] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00732164], dtype=float32), -0.17039555]
[2019-03-23 02:43:32,972] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [17.63333333333333, 78.66666666666667, 1.0, 2.0, 0.2975347773559359, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 323057.4628511277, 323057.4628511277, 105405.47771653]
[2019-03-23 02:43:32,973] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 02:43:32,976] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.9718759727556658
[2019-03-23 02:43:35,595] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00732164], dtype=float32), -0.17039555]
[2019-03-23 02:43:35,596] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.963878475, 64.576067735, 1.0, 2.0, 0.308238631771733, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 334682.7354649568, 334682.7354649568, 113666.5857962056]
[2019-03-23 02:43:35,598] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 02:43:35,602] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.8484583812260686
[2019-03-23 02:43:42,960] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00732164], dtype=float32), -0.17039555]
[2019-03-23 02:43:42,961] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [18.8, 84.66666666666667, 1.0, 2.0, 0.3471459747151289, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 384517.0018844174, 384517.0018844171, 121511.7188479024]
[2019-03-23 02:43:42,962] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 02:43:42,965] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.9540334712684911
[2019-03-23 02:43:51,281] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00732164], dtype=float32), -0.17039555]
[2019-03-23 02:43:51,282] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.38922113333333, 53.88675150333333, 1.0, 2.0, 0.2850382640243089, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 95.55338769695034, 309485.4986608343, 309485.4986608336, 89980.94483237994]
[2019-03-23 02:43:51,284] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 02:43:51,290] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.5678121539936277
[2019-03-23 02:44:15,576] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.3759 1683904748.1959 203.0000
[2019-03-23 02:44:15,859] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.7327 1706110310.8563 462.0000
[2019-03-23 02:44:15,948] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8855.7542 1663858414.4981 105.0000
[2019-03-23 02:44:16,037] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8503.9343 1776968462.2336 167.0000
[2019-03-23 02:44:16,103] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9060.3047 1656272944.4788 80.0000
[2019-03-23 02:44:17,124] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 2425000, evaluation results [2425000.0, 8503.934304721997, 1776968462.2335877, 167.0, 9060.304679780347, 1656272944.478839, 80.0, 8855.754186439062, 1663858414.498091, 105.0, 8596.732737917102, 1706110310.8562737, 462.0, 8575.37586148563, 1683904748.1959155, 203.0]
[2019-03-23 02:44:27,978] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.4664097e-36 1.0000000e+00 5.3115567e-35 0.0000000e+00 5.0389971e-29], sum to 1.0000
[2019-03-23 02:44:27,989] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6444
[2019-03-23 02:44:27,993] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4953868921394505, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 565214.3218864396, 565214.3218864396, 140961.112006439], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3480000.0000, 
sim time next is 3480600.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.4985842704795703, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 568863.893145429, 568863.8931454286, 141332.6363376548], 
processed observation next is [1.0, 0.2608695652173913, 0.5909090909090909, 1.0, 1.0, 1.0, 0.3732303380994629, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2106903307946033, 0.2106903307946032, 0.34471374716501174], 
reward next is 0.6553, 
noisyNet noise sample is [array([-1.6397905], dtype=float32), -0.28271773]. 
=============================================
[2019-03-23 02:44:29,746] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.0000000e+00 1.5562757e-29 0.0000000e+00 0.0000000e+00 1.0000000e+00], sum to 1.0000
[2019-03-23 02:44:29,753] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1745
[2019-03-23 02:44:29,760] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.5, 62.0, 1.0, 2.0, 0.4817625541132495, 1.0, 2.0, 0.4817625541132495, 1.0, 2.0, 0.974788443849398, 6.911199999999999, 6.9112, 77.3421103, 1625552.157931136, 1625552.157931136, 350192.9157981474], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3511800.0000, 
sim time next is 3512400.0000, 
raw observation next is [28.66666666666666, 62.0, 1.0, 2.0, 0.5040730139445283, 1.0, 2.0, 0.4958249439138716, 1.0, 2.0, 0.9865530188920543, 6.9112, 6.9112, 77.3421103, 1673071.267333089, 1673071.267333089, 356434.7569513519], 
processed observation next is [1.0, 0.6521739130434783, 0.9393939393939391, 0.62, 1.0, 1.0, 0.38009126743066035, 1.0, 1.0, 0.3697811798923395, 1.0, 1.0, 0.9807900269886491, 0.0, 0.0, 0.5085185399722538, 0.6196560249381811, 0.6196560249381811, 0.8693530657350046], 
reward next is 0.1306, 
noisyNet noise sample is [array([0.89725065], dtype=float32), 0.041979022]. 
=============================================
[2019-03-23 02:44:31,244] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.4630335e-38 0.0000000e+00 1.7169256e-37], sum to 1.0000
[2019-03-23 02:44:31,253] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1317
[2019-03-23 02:44:31,259] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 89.0, 1.0, 2.0, 0.522040305851713, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 594731.6788406204, 594731.6788406204, 145454.4553651203], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3541800.0000, 
sim time next is 3542400.0000, 
raw observation next is [23.0, 89.0, 1.0, 2.0, 0.5211931520053485, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 593766.4607283936, 593766.4607283936, 145351.0432978942], 
processed observation next is [1.0, 0.0, 0.6818181818181818, 0.89, 1.0, 1.0, 0.40149144000668563, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2199135039734791, 0.2199135039734791, 0.3545147397509615], 
reward next is 0.6455, 
noisyNet noise sample is [array([-0.07196516], dtype=float32), 0.715448]. 
=============================================
[2019-03-23 02:44:33,529] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:44:33,535] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5560
[2019-03-23 02:44:33,541] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 100.0, 1.0, 2.0, 0.3060441292413962, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 332448.1188750243, 332448.1188750243, 111643.676123603], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4075200.0000, 
sim time next is 4075800.0000, 
raw observation next is [15.96666666666667, 100.0, 1.0, 2.0, 0.303579817062175, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 329644.1561145856, 329644.1561145854, 111433.2129561958], 
processed observation next is [1.0, 0.17391304347826086, 0.3621212121212123, 1.0, 1.0, 1.0, 0.12947477132771876, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12209042819058726, 0.12209042819058719, 0.2717883242834044], 
reward next is 0.7282, 
noisyNet noise sample is [array([1.4746985], dtype=float32), 0.84205216]. 
=============================================
[2019-03-23 02:44:34,645] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:44:34,653] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0116
[2019-03-23 02:44:34,658] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.66666666666667, 60.33333333333334, 1.0, 2.0, 0.4845356869596262, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 552882.4393330797, 552882.4393330797, 139450.8267605939], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4389600.0000, 
sim time next is 4390200.0000, 
raw observation next is [26.5, 61.5, 1.0, 2.0, 0.4845025824972178, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 552829.1257278018, 552829.1257278018, 139542.2160406086], 
processed observation next is [1.0, 0.8260869565217391, 0.8409090909090909, 0.615, 1.0, 1.0, 0.35562822812152217, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.204751528047334, 0.204751528047334, 0.3403468683917283], 
reward next is 0.6597, 
noisyNet noise sample is [array([-1.1607949], dtype=float32), -0.051844448]. 
=============================================
[2019-03-23 02:44:35,686] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:44:35,696] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1051
[2019-03-23 02:44:35,701] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.16666666666667, 99.0, 1.0, 2.0, 0.415113263172843, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 470819.6392746767, 470819.6392746764, 128053.3466705875], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4506600.0000, 
sim time next is 4507200.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4128911393411929, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 468108.59629214, 468108.59629214, 127708.348463142], 
processed observation next is [0.0, 0.17391304347826086, 0.5, 1.0, 1.0, 1.0, 0.2661139241764911, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17337355418227407, 0.17337355418227407, 0.3114837767393707], 
reward next is 0.6885, 
noisyNet noise sample is [array([0.12626031], dtype=float32), 0.08545328]. 
=============================================
[2019-03-23 02:44:36,642] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:44:36,649] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3925
[2019-03-23 02:44:36,653] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 73.0, 1.0, 2.0, 0.3030640803009556, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 329083.950449605, 329083.950449605, 111397.2903949815], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3841200.0000, 
sim time next is 3841800.0000, 
raw observation next is [19.0, 73.0, 1.0, 2.0, 0.2999969934747828, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 325752.4203570376, 325752.4203570373, 111191.381749966], 
processed observation next is [0.0, 0.4782608695652174, 0.5, 0.73, 1.0, 1.0, 0.1249962418434785, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1206490445766806, 0.12064904457668048, 0.2711984920730878], 
reward next is 0.7288, 
noisyNet noise sample is [array([0.4446578], dtype=float32), 0.41977575]. 
=============================================
[2019-03-23 02:44:41,733] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 6.8847166e-34 0.0000000e+00 8.7926628e-34], sum to 1.0000
[2019-03-23 02:44:41,740] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5126
[2019-03-23 02:44:41,748] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1093907.036555229 W.
[2019-03-23 02:44:41,752] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [22.33333333333333, 76.33333333333334, 1.0, 2.0, 0.9611551899664733, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1093907.036555229, 1093907.036555229, 203310.754325769], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3768000.0000, 
sim time next is 3768600.0000, 
raw observation next is [22.66666666666667, 74.66666666666667, 1.0, 2.0, 0.3238435459260463, 1.0, 1.0, 0.3238435459260463, 1.0, 1.0, 0.6524170871969966, 6.911199999999999, 6.9112, 77.3421103, 1109166.819022796, 1109166.819022796, 260550.4824164528], 
processed observation next is [1.0, 0.6086956521739131, 0.6666666666666669, 0.7466666666666667, 1.0, 1.0, 0.15480443240755787, 1.0, 0.5, 0.15480443240755787, 1.0, 0.5, 0.5034529817099953, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.4108025255639985, 0.4108025255639985, 0.6354889815035435], 
reward next is 0.3645, 
noisyNet noise sample is [array([0.07920592], dtype=float32), 0.05892045]. 
=============================================
[2019-03-23 02:44:45,994] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:44:46,004] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7127
[2019-03-23 02:44:46,011] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 94.0, 1.0, 2.0, 0.3289831895895513, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 359947.9792539942, 359947.9792539942, 114118.7584787035], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3807000.0000, 
sim time next is 3807600.0000, 
raw observation next is [17.0, 94.0, 1.0, 2.0, 0.3262836531354462, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 356984.613240531, 356984.6132405307, 113921.6011775242], 
processed observation next is [0.0, 0.043478260869565216, 0.4090909090909091, 0.94, 1.0, 1.0, 0.15785456641930776, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13221652342241888, 0.1322165234224188, 0.27785756384762], 
reward next is 0.7221, 
noisyNet noise sample is [array([1.5646762], dtype=float32), 1.2508148]. 
=============================================
[2019-03-23 02:44:50,307] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:44:50,314] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3570
[2019-03-23 02:44:50,320] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.16666666666666, 75.5, 1.0, 2.0, 0.2779464662118203, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 301801.3753891704, 301801.3753891704, 100836.160233344], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3887400.0000, 
sim time next is 3888000.0000, 
raw observation next is [18.0, 77.0, 1.0, 2.0, 0.2786365934781147, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 302550.9663039118, 302550.9663039121, 101343.2007627213], 
processed observation next is [0.0, 0.0, 0.45454545454545453, 0.77, 1.0, 1.0, 0.09829574184764336, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11205591344589326, 0.11205591344589337, 0.2471785384456617], 
reward next is 0.7528, 
noisyNet noise sample is [array([-0.47925016], dtype=float32), -0.024778564]. 
=============================================
[2019-03-23 02:44:50,344] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[74.66132 ]
 [74.68786 ]
 [74.71054 ]
 [74.731636]
 [74.73895 ]], R is [[74.6780014 ]
 [74.68527985]
 [74.69377136]
 [74.70354462]
 [74.71478271]].
[2019-03-23 02:44:51,103] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.0797648e-34 1.0000000e+00 6.0872676e-35 4.9903820e-32 5.6878081e-19], sum to 1.0000
[2019-03-23 02:44:51,112] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2096
[2019-03-23 02:44:51,119] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 94.0, 1.0, 2.0, 0.8794588539612582, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1003766.285679627, 1003766.285679627, 193641.5198910057], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4795200.0000, 
sim time next is 4795800.0000, 
raw observation next is [21.0, 95.0, 1.0, 2.0, 0.9624835210121118, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1098794.840906345, 1098794.840906345, 208815.1713416808], 
processed observation next is [1.0, 0.5217391304347826, 0.5909090909090909, 0.95, 1.0, 1.0, 0.9531044012651396, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.4069610521875352, 0.4069610521875352, 0.509305295955319], 
reward next is 0.4907, 
noisyNet noise sample is [array([-1.6296005], dtype=float32), 0.533423]. 
=============================================
[2019-03-23 02:44:55,372] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:44:55,386] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3154
[2019-03-23 02:44:55,391] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 99.00000000000001, 1.0, 2.0, 0.5022717021895925, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 563683.4274932903, 563683.4274932906, 133631.7807083645], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4327800.0000, 
sim time next is 4328400.0000, 
raw observation next is [18.0, 98.0, 1.0, 2.0, 0.4404130776099357, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 493637.5113401234, 493637.5113401237, 127311.9530728416], 
processed observation next is [1.0, 0.08695652173913043, 0.45454545454545453, 0.98, 1.0, 1.0, 0.3005163470124196, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18282870790374942, 0.18282870790374953, 0.3105169587142478], 
reward next is 0.6895, 
noisyNet noise sample is [array([-1.872182], dtype=float32), -0.16693]. 
=============================================
[2019-03-23 02:44:55,775] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.2142019e-38 1.0000000e+00 5.5537559e-36 0.0000000e+00 7.5215094e-19], sum to 1.0000
[2019-03-23 02:44:55,783] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0353
[2019-03-23 02:44:55,791] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 61.0, 1.0, 2.0, 0.8294197682384932, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 939714.5574870686, 939714.5574870683, 178478.0726506489], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4197000.0000, 
sim time next is 4197600.0000, 
raw observation next is [24.0, 61.0, 1.0, 2.0, 0.8511151631849156, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 964347.0689739428, 964347.0689739428, 181803.9437116452], 
processed observation next is [1.0, 0.6086956521739131, 0.7272727272727273, 0.61, 1.0, 1.0, 0.8138939539811446, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3571655811014603, 0.3571655811014603, 0.4434242529552322], 
reward next is 0.5566, 
noisyNet noise sample is [array([-1.5306735], dtype=float32), -0.83554953]. 
=============================================
[2019-03-23 02:44:56,171] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:44:56,173] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8460
[2019-03-23 02:44:56,178] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 97.0, 1.0, 2.0, 0.3364978791643826, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 370611.886268155, 370611.8862681552, 115554.324117872], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4051800.0000, 
sim time next is 4052400.0000, 
raw observation next is [17.0, 96.0, 1.0, 2.0, 0.3336270685226059, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 366746.3156904154, 366746.3156904157, 115077.1808452933], 
processed observation next is [1.0, 0.9130434782608695, 0.4090909090909091, 0.96, 1.0, 1.0, 0.16703383565325733, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13583196877422793, 0.13583196877422804, 0.2806760508421788], 
reward next is 0.7193, 
noisyNet noise sample is [array([1.0799104], dtype=float32), 0.2888115]. 
=============================================
[2019-03-23 02:44:59,210] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:44:59,218] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1873
[2019-03-23 02:44:59,226] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 95.0, 1.0, 2.0, 0.3366214463914776, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 368936.3511369004, 368936.3511369004, 114896.8123517901], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4039800.0000, 
sim time next is 4040400.0000, 
raw observation next is [17.0, 96.0, 1.0, 2.0, 0.3412567308602013, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 374726.9850521348, 374726.9850521348, 115494.0398005692], 
processed observation next is [1.0, 0.782608695652174, 0.4090909090909091, 0.96, 1.0, 1.0, 0.17657091357525162, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1387877722415314, 0.1387877722415314, 0.2816927800013883], 
reward next is 0.7183, 
noisyNet noise sample is [array([-0.7417331], dtype=float32), -0.17708834]. 
=============================================
[2019-03-23 02:45:00,795] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 6.969343e-37], sum to 1.0000
[2019-03-23 02:45:00,803] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7444
[2019-03-23 02:45:00,810] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333334, 83.33333333333334, 1.0, 2.0, 0.6283170086832588, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 709324.0597707562, 709324.0597707559, 149490.5556311172], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4095600.0000, 
sim time next is 4096200.0000, 
raw observation next is [20.66666666666666, 80.66666666666666, 1.0, 2.0, 0.6138051856021612, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 692782.3301771393, 692782.3301771393, 147663.7056236153], 
processed observation next is [1.0, 0.391304347826087, 0.5757575757575755, 0.8066666666666665, 1.0, 1.0, 0.5172564820027015, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2565860482137553, 0.2565860482137553, 0.36015537956979343], 
reward next is 0.6398, 
noisyNet noise sample is [array([0.3271653], dtype=float32), 0.8848764]. 
=============================================
[2019-03-23 02:45:02,682] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:45:02,695] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6900
[2019-03-23 02:45:02,700] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 100.0, 1.0, 2.0, 0.3338830136494165, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 369494.3693194262, 369494.3693194262, 116045.3552836621], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4165800.0000, 
sim time next is 4166400.0000, 
raw observation next is [17.0, 100.0, 1.0, 2.0, 0.3317172023239188, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 367084.251718208, 367084.2517182083, 115876.8800542723], 
processed observation next is [1.0, 0.21739130434782608, 0.4090909090909091, 1.0, 1.0, 1.0, 0.16464650290489852, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13595713026600298, 0.1359571302660031, 0.28262653671773735], 
reward next is 0.7174, 
noisyNet noise sample is [array([0.21695787], dtype=float32), 0.049024582]. 
=============================================
[2019-03-23 02:45:05,815] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 1.110339e-27], sum to 1.0000
[2019-03-23 02:45:05,826] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8455
[2019-03-23 02:45:05,835] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1417592.734422197 W.
[2019-03-23 02:45:05,848] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.5, 49.5, 1.0, 2.0, 0.6227147576865346, 1.0, 2.0, 0.6227147576865346, 0.0, 1.0, 0.0, 6.911200000000002, 6.9112, 77.32846344354104, 1417592.734422197, 1417592.734422196, 262796.9750505225], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4368600.0000, 
sim time next is 4369200.0000, 
raw observation next is [28.66666666666666, 49.0, 1.0, 2.0, 0.6326174890584673, 1.0, 2.0, 0.6326174890584673, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1439628.399482596, 1439628.399482596, 265904.3366020872], 
processed observation next is [1.0, 0.5652173913043478, 0.9393939393939391, 0.49, 1.0, 1.0, 0.5407718613230841, 1.0, 1.0, 0.5407718613230841, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.5331957035120726, 0.5331957035120726, 0.6485471624441151], 
reward next is 0.3515, 
noisyNet noise sample is [array([-0.6317239], dtype=float32), -0.40428168]. 
=============================================
[2019-03-23 02:45:07,128] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.6976924e-23], sum to 1.0000
[2019-03-23 02:45:07,138] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4795
[2019-03-23 02:45:07,144] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 61.0, 1.0, 2.0, 0.5567067951301787, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 629842.8550282681, 629842.8550282683, 141925.0812899932], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4194000.0000, 
sim time next is 4194600.0000, 
raw observation next is [24.0, 61.0, 1.0, 2.0, 0.6449444573677078, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 729939.0665772421, 729939.0665772421, 152559.013647104], 
processed observation next is [1.0, 0.5652173913043478, 0.7272727272727273, 0.61, 1.0, 1.0, 0.5561805717096346, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2703478024360156, 0.2703478024360156, 0.372095155236839], 
reward next is 0.6279, 
noisyNet noise sample is [array([1.4613291], dtype=float32), -0.13552268]. 
=============================================
[2019-03-23 02:45:08,711] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-23 02:45:08,711] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 02:45:08,712] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:45:08,712] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 02:45:08,713] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 02:45:08,714] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:45:08,715] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 02:45:08,715] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:45:08,717] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 02:45:08,718] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:45:08,719] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:45:08,741] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run99
[2019-03-23 02:45:08,768] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run99
[2019-03-23 02:45:08,793] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run99
[2019-03-23 02:45:08,794] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run99
[2019-03-23 02:45:08,851] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run99
[2019-03-23 02:45:46,468] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00819207], dtype=float32), -0.1563663]
[2019-03-23 02:45:46,469] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.13333333333334, 64.0, 1.0, 2.0, 0.4319025322627647, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 490478.1562570956, 490478.1562570956, 134469.2479865775]
[2019-03-23 02:45:46,471] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 02:45:46,475] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 2.9168506e-35], sampled 0.32222187603642183
[2019-03-23 02:46:07,502] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00819207], dtype=float32), -0.1563663]
[2019-03-23 02:46:07,502] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [29.56666666666667, 54.5, 1.0, 2.0, 0.6811635639731849, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 772833.5342694625, 772833.5342694625, 172925.3319785442]
[2019-03-23 02:46:07,504] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 02:46:07,506] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 1.3646025e-38 0.0000000e+00 6.3015118e-23], sampled 0.5438875174757769
[2019-03-23 02:46:17,569] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00819207], dtype=float32), -0.1563663]
[2019-03-23 02:46:17,571] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [27.05, 54.0, 1.0, 2.0, 0.4916409349360944, 0.0, 2.0, 0.0, 1.0, 1.0, 0.8763967361001089, 7.039443785009937, 6.9112, 95.55297633822428, 1109206.551503578, 1057739.435014346, 245515.2345793774]
[2019-03-23 02:46:17,571] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 02:46:17,574] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.4690152e-34 9.3664072e-02 9.8154983e-32 0.0000000e+00 9.0633589e-01], sampled 0.4157054456143129
[2019-03-23 02:46:19,378] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00819207], dtype=float32), -0.1563663]
[2019-03-23 02:46:19,378] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [17.0, 90.33333333333334, 1.0, 2.0, 0.3118798035550974, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 338637.4009202805, 338637.4009202801, 116302.3788558834]
[2019-03-23 02:46:19,380] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 02:46:19,387] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.39441988303024744
[2019-03-23 02:46:47,150] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00819207], dtype=float32), -0.1563663]
[2019-03-23 02:46:47,152] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.23909829166667, 82.73915060499999, 1.0, 2.0, 0.35362062098776, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 387961.4609157116, 387961.4609157116, 120613.6739178218]
[2019-03-23 02:46:47,155] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 02:46:47,157] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0.00000e+00 1.00000e+00 0.00000e+00 0.00000e+00 6.55416e-38], sampled 0.2678459930279722
[2019-03-23 02:46:47,362] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00819207], dtype=float32), -0.1563663]
[2019-03-23 02:46:47,364] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.41378868, 51.01587989666667, 1.0, 2.0, 0.3092532497895722, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 335784.7063526697, 335784.7063526693, 102514.9268374692]
[2019-03-23 02:46:47,365] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 02:46:47,367] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.056865126232144236
[2019-03-23 02:46:56,754] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8447.2906 1798122605.9500 78.0000
[2019-03-23 02:46:56,851] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8854.4009 1667964360.6035 63.0000
[2019-03-23 02:46:56,929] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1471 1659160883.7893 50.0000
[2019-03-23 02:46:57,006] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8630.7092 1721518441.9816 190.0000
[2019-03-23 02:46:57,008] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8580.0322 1692231048.7506 103.0000
[2019-03-23 02:46:58,025] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 2450000, evaluation results [2450000.0, 8447.29064008948, 1798122605.949976, 78.0, 9061.147099084945, 1659160883.7893171, 50.0, 8854.40085983106, 1667964360.6034982, 63.0, 8630.709221637802, 1721518441.9816155, 190.0, 8580.032249372374, 1692231048.7505968, 103.0]
[2019-03-23 02:46:58,092] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.8476564e-38], sum to 1.0000
[2019-03-23 02:46:58,095] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2829
[2019-03-23 02:46:58,099] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.73333333333333, 64.83333333333334, 1.0, 2.0, 0.3509505496826147, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 390161.467023998, 390161.467023998, 118070.4330310017], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4561800.0000, 
sim time next is 4562400.0000, 
raw observation next is [21.46666666666667, 65.66666666666667, 1.0, 2.0, 0.3466054271415271, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 384594.3838937971, 384594.3838937968, 117424.2939575268], 
processed observation next is [0.0, 0.8260869565217391, 0.6121212121212122, 0.6566666666666667, 1.0, 1.0, 0.18325678392690883, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14244236440511004, 0.14244236440510993, 0.28640071696957753], 
reward next is 0.7136, 
noisyNet noise sample is [array([-1.3543301], dtype=float32), 0.70072013]. 
=============================================
[2019-03-23 02:46:59,434] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0.000000e+00 8.197345e-13 0.000000e+00 0.000000e+00 1.000000e+00], sum to 1.0000
[2019-03-23 02:46:59,440] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6219
[2019-03-23 02:46:59,444] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.05, 48.5, 1.0, 2.0, 0.3439855142630908, 1.0, 2.0, 0.3439855142630908, 1.0, 2.0, 0.6936654524119766, 6.911199999999999, 6.9112, 77.3421103, 1178288.485836951, 1178288.485836951, 268956.3293522964], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4285800.0000, 
sim time next is 4286400.0000, 
raw observation next is [27.06666666666667, 48.66666666666666, 1.0, 2.0, 0.3432559736307714, 1.0, 2.0, 0.3432559736307714, 1.0, 2.0, 0.6924031371206703, 6.911199999999999, 6.9112, 77.3421103, 1175782.473323916, 1175782.473323916, 268965.6662882448], 
processed observation next is [1.0, 0.6086956521739131, 0.8666666666666668, 0.4866666666666666, 1.0, 1.0, 0.17906996703846426, 1.0, 1.0, 0.17906996703846426, 1.0, 1.0, 0.5605759101723862, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.43547499011996893, 0.43547499011996893, 0.6560138202152312], 
reward next is 0.3440, 
noisyNet noise sample is [array([-1.7099656], dtype=float32), -0.95608574]. 
=============================================
[2019-03-23 02:47:03,658] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.842481e-38 1.000000e+00 1.847358e-33 0.000000e+00 5.358269e-25], sum to 1.0000
[2019-03-23 02:47:03,669] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7960
[2019-03-23 02:47:03,672] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.58333333333333, 70.83333333333333, 1.0, 2.0, 0.4789125133302536, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 546475.4115835188, 546475.4115835188, 138376.9486350991], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4395000.0000, 
sim time next is 4395600.0000, 
raw observation next is [24.3, 72.0, 1.0, 2.0, 0.4780350990756967, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 545449.9106961541, 545449.9106961543, 138083.9603121591], 
processed observation next is [1.0, 0.9130434782608695, 0.740909090909091, 0.72, 1.0, 1.0, 0.3475438738446208, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20201848544302003, 0.20201848544302012, 0.33679014710282706], 
reward next is 0.6632, 
noisyNet noise sample is [array([0.14485008], dtype=float32), -0.65460634]. 
=============================================
[2019-03-23 02:47:09,641] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:47:09,650] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8169
[2019-03-23 02:47:09,657] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 74.0, 1.0, 2.0, 0.4722360088235781, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 538821.3565493055, 538821.3565493055, 137397.2972813739], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4446000.0000, 
sim time next is 4446600.0000, 
raw observation next is [24.16666666666666, 74.0, 1.0, 2.0, 0.4748782476574344, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 541870.428391696, 541870.428391696, 137942.2905197647], 
processed observation next is [0.0, 0.4782608695652174, 0.7348484848484845, 0.74, 1.0, 1.0, 0.343597809571793, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2006927512561837, 0.2006927512561837, 0.33644461102381634], 
reward next is 0.6636, 
noisyNet noise sample is [array([-0.6075447], dtype=float32), -1.2361246]. 
=============================================
[2019-03-23 02:47:17,391] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:47:17,402] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2357
[2019-03-23 02:47:17,407] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 73.0, 1.0, 2.0, 0.450669643669947, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 489443.0080883267, 489443.008088327, 112713.6244271066], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4611600.0000, 
sim time next is 4612200.0000, 
raw observation next is [18.16666666666667, 71.5, 1.0, 2.0, 0.4733025463578652, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 514036.1283371391, 514036.1283371391, 114855.7706701162], 
processed observation next is [1.0, 0.391304347826087, 0.4621212121212123, 0.715, 1.0, 1.0, 0.34162818294733144, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19038375123597745, 0.19038375123597745, 0.28013602602467363], 
reward next is 0.7199, 
noisyNet noise sample is [array([-0.57598096], dtype=float32), 0.04589224]. 
=============================================
[2019-03-23 02:47:19,436] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:47:19,445] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0345
[2019-03-23 02:47:19,450] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.5, 75.0, 1.0, 2.0, 0.2654499222873655, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 288228.2877667096, 288228.2877667098, 90730.96868612032], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4663800.0000, 
sim time next is 4664400.0000, 
raw observation next is [17.33333333333333, 75.66666666666666, 1.0, 2.0, 0.2629561672483062, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 285519.7477671632, 285519.7477671629, 89714.63813194231], 
processed observation next is [1.0, 1.0, 0.42424242424242403, 0.7566666666666666, 1.0, 1.0, 0.07869520906038277, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10574805472857897, 0.10574805472857886, 0.21881619056571294], 
reward next is 0.7812, 
noisyNet noise sample is [array([-0.8564157], dtype=float32), 0.28430876]. 
=============================================
[2019-03-23 02:47:21,137] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:47:21,146] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4876
[2019-03-23 02:47:21,152] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.33333333333333, 86.0, 1.0, 2.0, 0.2092439617810899, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 227185.0175480972, 227185.0175480972, 74442.4012568119], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4678800.0000, 
sim time next is 4679400.0000, 
raw observation next is [14.16666666666667, 87.0, 1.0, 2.0, 0.209025117192314, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 226947.3532913747, 226947.3532913744, 74234.40818137574], 
processed observation next is [1.0, 0.13043478260869565, 0.28030303030303044, 0.87, 1.0, 1.0, 0.011281396490392497, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08405457529310174, 0.08405457529310163, 0.18105953214969692], 
reward next is 0.8189, 
noisyNet noise sample is [array([0.7624912], dtype=float32), 0.58301747]. 
=============================================
[2019-03-23 02:47:24,571] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:47:24,577] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4349
[2019-03-23 02:47:24,581] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 88.0, 1.0, 2.0, 0.4164245419857624, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 465663.3848090976, 465663.3848090976, 124630.8229082895], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4760400.0000, 
sim time next is 4761000.0000, 
raw observation next is [19.0, 88.0, 1.0, 2.0, 0.3913498612772036, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 437522.8580516707, 437522.8580516704, 122392.2566251646], 
processed observation next is [1.0, 0.08695652173913043, 0.5, 0.88, 1.0, 1.0, 0.2391873265965045, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16204550298210027, 0.16204550298210016, 0.2985176990857673], 
reward next is 0.7015, 
noisyNet noise sample is [array([1.6743618], dtype=float32), 0.35908905]. 
=============================================
[2019-03-23 02:47:24,591] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[64.85363]
 [64.71449]
 [65.32997]
 [65.32791]
 [65.40626]], R is [[64.93690491]
 [64.98355865]
 [65.01821136]
 [65.07550049]
 [65.13225555]].
[2019-03-23 02:47:25,033] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:47:25,041] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0158
[2019-03-23 02:47:25,048] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 83.0, 1.0, 2.0, 0.3743948593897641, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 420372.9200172487, 420372.920017249, 121801.0573494533], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4750200.0000, 
sim time next is 4750800.0000, 
raw observation next is [20.0, 83.0, 1.0, 2.0, 0.3744310123891827, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 420412.3696039504, 420412.3696039506, 121803.578679793], 
processed observation next is [1.0, 1.0, 0.5454545454545454, 0.83, 1.0, 1.0, 0.21803876548647835, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15570828503850015, 0.1557082850385002, 0.29708189921900735], 
reward next is 0.7029, 
noisyNet noise sample is [array([1.4700779], dtype=float32), -0.7923613]. 
=============================================
[2019-03-23 02:47:30,320] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.7312840e-33 9.9879140e-01 1.8901975e-36 1.0023607e-29 1.2086742e-03], sum to 1.0000
[2019-03-23 02:47:30,331] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3237
[2019-03-23 02:47:30,340] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.8037509272623865, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 912664.6694679019, 912664.6694679019, 176058.476028282], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4872000.0000, 
sim time next is 4872600.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.7783446208208739, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 883752.6973242161, 883752.6973242161, 172274.1214511367], 
processed observation next is [1.0, 0.391304347826087, 0.5, 1.0, 1.0, 1.0, 0.7229307760260922, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3273158138237838, 0.3273158138237838, 0.4201807840271627], 
reward next is 0.5798, 
noisyNet noise sample is [array([0.6584025], dtype=float32), 1.401173]. 
=============================================
[2019-03-23 02:47:39,670] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:47:39,680] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6452
[2019-03-23 02:47:39,686] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.33333333333333, 99.00000000000001, 1.0, 2.0, 0.2691842994999393, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 292284.3318605743, 292284.331860574, 97367.85252260222], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5037000.0000, 
sim time next is 5037600.0000, 
raw observation next is [15.66666666666667, 98.0, 1.0, 2.0, 0.2775241911761065, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 301342.7163091036, 301342.7163091034, 102316.350568072], 
processed observation next is [0.0, 0.30434782608695654, 0.3484848484848486, 0.98, 1.0, 1.0, 0.0969052389701331, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11160841344781615, 0.11160841344781608, 0.24955207455627315], 
reward next is 0.7504, 
noisyNet noise sample is [array([-0.11835556], dtype=float32), 2.0001194]. 
=============================================
[2019-03-23 02:47:39,692] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:47:39,702] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3751
[2019-03-23 02:47:39,708] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.83333333333333, 57.66666666666666, 1.0, 2.0, 0.3578244616911648, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 401744.1689370301, 401744.1689370298, 120394.6555823595], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5053800.0000, 
sim time next is 5054400.0000, 
raw observation next is [24.0, 57.0, 1.0, 2.0, 0.358925786688955, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 403172.2497921279, 403172.2497921276, 120581.977078482], 
processed observation next is [0.0, 0.5217391304347826, 0.7272727272727273, 0.57, 1.0, 1.0, 0.1986572333611937, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1493230554785659, 0.14932305547856578, 0.29410238311824877], 
reward next is 0.7059, 
noisyNet noise sample is [array([0.04439778], dtype=float32), 1.9413553]. 
=============================================
[2019-03-23 02:47:40,539] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:47:40,553] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5368
[2019-03-23 02:47:40,559] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.53333333333333, 81.0, 1.0, 2.0, 0.3834742737396136, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 416435.2300283517, 416435.2300283517, 86788.5573630417], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5800800.0000, 
sim time next is 5801400.0000, 
raw observation next is [12.45, 81.5, 1.0, 2.0, 0.3833827008602873, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 416335.7435632223, 416335.7435632223, 86765.35600211655], 
processed observation next is [1.0, 0.13043478260869565, 0.20227272727272724, 0.815, 1.0, 1.0, 0.22922837607535912, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1541984235419342, 0.1541984235419342, 0.21162281951735742], 
reward next is 0.7884, 
noisyNet noise sample is [array([0.78361523], dtype=float32), 1.2285004]. 
=============================================
[2019-03-23 02:47:41,616] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:47:41,625] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8230
[2019-03-23 02:47:41,633] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.66666666666666, 70.33333333333334, 1.0, 2.0, 0.4307777053872642, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 490513.4912942767, 490513.4912942767, 131206.8318174518], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5088000.0000, 
sim time next is 5088600.0000, 
raw observation next is [23.5, 71.0, 1.0, 2.0, 0.4298905737969773, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 489385.7386165621, 489385.7386165624, 130990.6779060541], 
processed observation next is [0.0, 0.9130434782608695, 0.7045454545454546, 0.71, 1.0, 1.0, 0.2873632172462216, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18125397726539336, 0.18125397726539347, 0.319489458307449], 
reward next is 0.6805, 
noisyNet noise sample is [array([0.39142436], dtype=float32), 1.1613755]. 
=============================================
[2019-03-23 02:47:48,395] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-23 02:47:48,397] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 02:47:48,397] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 02:47:48,398] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 02:47:48,399] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:47:48,399] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 02:47:48,399] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:47:48,398] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:47:48,401] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:47:48,400] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 02:47:48,407] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:47:48,430] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run100
[2019-03-23 02:47:48,456] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run100
[2019-03-23 02:47:48,458] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run100
[2019-03-23 02:47:48,503] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run100
[2019-03-23 02:47:48,528] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run100
[2019-03-23 02:47:53,392] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00317804], dtype=float32), -0.15675868]
[2019-03-23 02:47:53,394] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [13.27860491166667, 90.43566163833334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 185218.8129210729, 185218.8129210725, 70925.25121274253]
[2019-03-23 02:47:53,395] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 02:47:53,397] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.131791951066782
[2019-03-23 02:48:09,645] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00317804], dtype=float32), -0.15675868]
[2019-03-23 02:48:09,647] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.0, 100.0, 1.0, 2.0, 0.4798588345607402, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 547490.0929183116, 547490.0929183112, 139179.9090240864]
[2019-03-23 02:48:09,651] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 02:48:09,653] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.2013264040490531
[2019-03-23 02:48:22,203] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00317804], dtype=float32), -0.15675868]
[2019-03-23 02:48:22,204] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.07489964833334, 75.258503585, 1.0, 2.0, 0.2690787657051455, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 292152.9703744932, 292152.9703744932, 102787.4978272556]
[2019-03-23 02:48:22,208] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 02:48:22,209] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.9233457105629498
[2019-03-23 02:48:37,418] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00317804], dtype=float32), -0.15675868]
[2019-03-23 02:48:37,419] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.51687681333333, 90.420670845, 1.0, 2.0, 0.4973886034225024, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 567190.5300078859, 567190.5300078859, 146064.3422550762]
[2019-03-23 02:48:37,419] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 02:48:37,421] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.6476088037596579
[2019-03-23 02:48:37,894] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00317804], dtype=float32), -0.15675868]
[2019-03-23 02:48:37,895] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.51352353, 84.82008243666667, 1.0, 2.0, 0.4503568717342903, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 512613.229295721, 512613.2292957207, 137350.7571603664]
[2019-03-23 02:48:37,896] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 02:48:37,898] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.26170222522550535
[2019-03-23 02:48:39,852] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00317804], dtype=float32), -0.15675868]
[2019-03-23 02:48:39,853] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [24.83333333333334, 78.0, 1.0, 2.0, 0.4785279371841401, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9451963673382671, 6.95287256947886, 6.9112, 77.32836336075901, 1086904.064802428, 1073369.68410411, 256290.0913257986]
[2019-03-23 02:48:39,855] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 02:48:39,859] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [9.2458894e-36 1.0000000e+00 4.7024768e-35 0.0000000e+00 3.5688317e-14], sampled 0.6856320573245528
[2019-03-23 02:48:39,861] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1086904.064802428 W.
[2019-03-23 02:48:43,202] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00317804], dtype=float32), -0.15675868]
[2019-03-23 02:48:43,203] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.65983293666667, 77.73715257666666, 1.0, 2.0, 0.3554699294953973, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 95.55338769695034, 394929.7870926338, 394929.7870926331, 122639.992857519]
[2019-03-23 02:48:43,204] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 02:48:43,208] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.28801744948514196
[2019-03-23 02:48:43,465] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00317804], dtype=float32), -0.15675868]
[2019-03-23 02:48:43,466] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [17.25, 85.5, 1.0, 2.0, 0.2988633972890608, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 324500.4419388228, 324500.4419388228, 113368.8353213586]
[2019-03-23 02:48:43,467] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 02:48:43,470] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.6597478021168716
[2019-03-23 02:48:55,008] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00317804], dtype=float32), -0.15675868]
[2019-03-23 02:48:55,009] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.66666666666667, 64.66666666666667, 1.0, 2.0, 0.3212066540639868, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 350791.8375990082, 350791.8375990078, 117646.6081238226]
[2019-03-23 02:48:55,010] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 02:48:55,011] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.4631468279947354
[2019-03-23 02:49:02,124] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00317804], dtype=float32), -0.15675868]
[2019-03-23 02:49:02,127] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.3, 78.0, 1.0, 2.0, 0.3272811312038689, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 360478.5514607484, 360478.5514607484, 114880.1570995462]
[2019-03-23 02:49:02,129] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 02:49:02,130] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.2561408532176316
[2019-03-23 02:49:02,340] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00317804], dtype=float32), -0.15675868]
[2019-03-23 02:49:02,341] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.059199325, 80.60588486, 1.0, 2.0, 0.4986858855615113, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 568084.306984302, 568084.3069843017, 146925.6646427083]
[2019-03-23 02:49:02,343] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 02:49:02,347] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.5831891481266026
[2019-03-23 02:49:05,561] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00317804], dtype=float32), -0.15675868]
[2019-03-23 02:49:05,561] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [27.14431782, 77.53865794, 1.0, 2.0, 0.8829732621614715, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 992353.820992867, 992353.8209928666, 208923.3927268523]
[2019-03-23 02:49:05,563] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 02:49:05,565] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 2.2378073e-37], sampled 0.8486867847705544
[2019-03-23 02:49:24,476] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00317804], dtype=float32), -0.15675868]
[2019-03-23 02:49:24,478] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.83796623333333, 95.76144149333334, 1.0, 2.0, 0.4564019030943448, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 520551.6701678553, 520551.6701678553, 139499.2669472277]
[2019-03-23 02:49:24,480] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 02:49:24,484] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.33959819677279335
[2019-03-23 02:49:29,466] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00317804], dtype=float32), -0.15675868]
[2019-03-23 02:49:29,469] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [14.7, 88.83333333333334, 1.0, 2.0, 0.2462391337243031, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 267349.2652035122, 267349.2652035122, 85311.18755120334]
[2019-03-23 02:49:29,470] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 02:49:29,472] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.19323773991407167
[2019-03-23 02:49:36,386] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00317804], dtype=float32), -0.15675868]
[2019-03-23 02:49:36,388] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [15.5, 72.0, 1.0, 2.0, 0.2179856979892436, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 236678.5994233573, 236678.599423357, 74197.07264871435]
[2019-03-23 02:49:36,389] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 02:49:36,392] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.44401752452341814
[2019-03-23 02:49:38,228] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9060.3047 1656272944.4788 80.0000
[2019-03-23 02:49:38,517] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8503.6716 1777223571.0604 167.0000
[2019-03-23 02:49:38,720] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8855.7542 1663858414.4981 105.0000
[2019-03-23 02:49:38,742] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.7327 1706110310.8563 462.0000
[2019-03-23 02:49:38,884] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00317804], dtype=float32), -0.15675868]
[2019-03-23 02:49:38,884] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.231434125, 85.497993275, 1.0, 2.0, 0.3757554490939147, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 423192.3676892074, 423192.3676892078, 126903.4781460694]
[2019-03-23 02:49:38,884] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 02:49:38,885] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.9088943150383224
[2019-03-23 02:49:38,939] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.0859 1683880081.0169 205.0000
[2019-03-23 02:49:39,954] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 2475000, evaluation results [2475000.0, 8503.671616486357, 1777223571.0604138, 167.0, 9060.304679780347, 1656272944.478839, 80.0, 8855.754186439062, 1663858414.498091, 105.0, 8596.732737917102, 1706110310.8562737, 462.0, 8575.085902823635, 1683880081.0169063, 205.0]
[2019-03-23 02:49:44,954] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:49:44,964] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8025
[2019-03-23 02:49:44,969] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.16666666666667, 93.16666666666667, 1.0, 2.0, 0.5068752241257342, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 577952.8474502056, 577952.8474502056, 143061.9153821508], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5248200.0000, 
sim time next is 5248800.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.5056882182467596, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 576685.3548402233, 576685.3548402233, 142793.1041668704], 
processed observation next is [1.0, 0.782608695652174, 0.6363636363636364, 0.94, 1.0, 1.0, 0.38211027280844945, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21358716845934198, 0.21358716845934198, 0.34827586382163517], 
reward next is 0.6517, 
noisyNet noise sample is [array([1.115575], dtype=float32), 0.42184284]. 
=============================================
[2019-03-23 02:49:46,011] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:49:46,020] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5633
[2019-03-23 02:49:46,026] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.6, 54.0, 1.0, 2.0, 0.7795324207606863, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 888431.4640024961, 888431.4640024964, 175490.20998047], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5306400.0000, 
sim time next is 5307000.0000, 
raw observation next is [26.78333333333333, 53.5, 1.0, 2.0, 0.896932698982629, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1022702.505068204, 1022702.505068204, 194633.6948404275], 
processed observation next is [1.0, 0.43478260869565216, 0.8537878787878787, 0.535, 1.0, 1.0, 0.8711658737282862, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3787787055808163, 0.3787787055808163, 0.47471632887909143], 
reward next is 0.5253, 
noisyNet noise sample is [array([-0.35610217], dtype=float32), 1.9830824]. 
=============================================
[2019-03-23 02:49:46,037] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[63.68469 ]
 [63.705467]
 [64.39302 ]
 [65.28369 ]
 [65.316414]], R is [[62.23638916]
 [62.18600082]
 [62.1309433 ]
 [62.09803009]
 [62.09580231]].
[2019-03-23 02:49:52,092] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 6.3038343e-26], sum to 1.0000
[2019-03-23 02:49:52,096] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2591
[2019-03-23 02:49:52,104] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.7, 90.0, 1.0, 2.0, 0.3882730225625858, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 438445.8692429641, 438445.8692429641, 124307.8239525083], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5376600.0000, 
sim time next is 5377200.0000, 
raw observation next is [19.6, 91.0, 1.0, 2.0, 0.3929615725017034, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 443823.5513670011, 443823.5513670011, 124776.7289476455], 
processed observation next is [1.0, 0.21739130434782608, 0.5272727272727273, 0.91, 1.0, 1.0, 0.2412019656271292, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1643790930988893, 0.1643790930988893, 0.3043334852381598], 
reward next is 0.6957, 
noisyNet noise sample is [array([-0.79152524], dtype=float32), 0.035511315]. 
=============================================
[2019-03-23 02:49:56,787] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.33145316e-35 1.00000000e+00 1.17944695e-32 1.25176170e-38
 9.36085756e-17], sum to 1.0000
[2019-03-23 02:49:56,794] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7470
[2019-03-23 02:49:56,798] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 92.0, 1.0, 2.0, 0.3979866140240945, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 449276.5733919076, 449276.5733919076, 125104.1252526254], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5606400.0000, 
sim time next is 5607000.0000, 
raw observation next is [19.4, 91.5, 1.0, 2.0, 0.3963983772102604, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 447231.157843176, 447231.1578431763, 124818.7418316775], 
processed observation next is [1.0, 0.9130434782608695, 0.5181818181818181, 0.915, 1.0, 1.0, 0.24549797151282546, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16564116957154665, 0.16564116957154676, 0.3044359556870183], 
reward next is 0.6956, 
noisyNet noise sample is [array([0.16544984], dtype=float32), 0.35547197]. 
=============================================
[2019-03-23 02:49:56,813] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[69.035324]
 [69.08132 ]
 [69.16664 ]
 [69.21393 ]
 [69.20062 ]], R is [[68.96337891]
 [68.96861267]
 [68.97279358]
 [68.97572327]
 [68.97710419]].
[2019-03-23 02:50:01,789] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:50:01,797] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3303
[2019-03-23 02:50:01,802] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.9, 93.0, 1.0, 2.0, 0.4202660818823336, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 476848.4641822498, 476848.4641822498, 128678.4248059488], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5602200.0000, 
sim time next is 5602800.0000, 
raw observation next is [19.8, 93.0, 1.0, 2.0, 0.4172552056339281, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 473109.8003643103, 473109.8003643103, 128160.2138668922], 
processed observation next is [1.0, 0.8695652173913043, 0.5363636363636364, 0.93, 1.0, 1.0, 0.2715690070424101, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1752258519867816, 0.1752258519867816, 0.31258588748022487], 
reward next is 0.6874, 
noisyNet noise sample is [array([-0.18710738], dtype=float32), -0.6577389]. 
=============================================
[2019-03-23 02:50:02,379] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:50:02,386] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2553
[2019-03-23 02:50:02,390] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.1, 72.0, 1.0, 2.0, 0.4679684258932576, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 533897.9383146506, 533897.9383146506, 136708.8839788983], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5596200.0000, 
sim time next is 5596800.0000, 
raw observation next is [22.9, 77.0, 1.0, 2.0, 0.4532681522586381, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 516707.1596471458, 516707.1596471455, 134242.6832562115], 
processed observation next is [1.0, 0.782608695652174, 0.6772727272727272, 0.77, 1.0, 1.0, 0.31658519032329757, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19137302209153548, 0.19137302209153537, 0.32742117867368653], 
reward next is 0.6726, 
noisyNet noise sample is [array([-0.5548573], dtype=float32), -1.3594317]. 
=============================================
[2019-03-23 02:50:09,409] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:50:09,416] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8138
[2019-03-23 02:50:09,421] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.23333333333333, 78.0, 1.0, 2.0, 0.4052238653511155, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 457808.1693314617, 457808.1693314614, 125969.8731700553], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6027600.0000, 
sim time next is 6028200.0000, 
raw observation next is [21.05, 78.0, 1.0, 2.0, 0.3971010281740681, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 447887.2529200168, 447887.2529200168, 124806.361142239], 
processed observation next is [1.0, 0.782608695652174, 0.5931818181818183, 0.78, 1.0, 1.0, 0.24637628521758512, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16588416774815437, 0.16588416774815437, 0.30440575888350974], 
reward next is 0.6956, 
noisyNet noise sample is [array([0.34740192], dtype=float32), -1.1908752]. 
=============================================
[2019-03-23 02:50:16,108] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:50:16,115] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8302
[2019-03-23 02:50:16,120] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [11.6, 86.0, 1.0, 2.0, 0.3831552477753869, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 416088.6344245707, 416088.6344245704, 86111.76563753016], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5809200.0000, 
sim time next is 5809800.0000, 
raw observation next is [11.6, 86.0, 1.0, 2.0, 0.382725916021067, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 415622.2009963131, 415622.2009963131, 86069.09877919152], 
processed observation next is [1.0, 0.21739130434782608, 0.1636363636363636, 0.86, 1.0, 1.0, 0.2284073950263337, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.153934148517153, 0.153934148517153, 0.2099246311687598], 
reward next is 0.7901, 
noisyNet noise sample is [array([0.87306905], dtype=float32), -1.5805098]. 
=============================================
[2019-03-23 02:50:27,195] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:50:27,204] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6502
[2019-03-23 02:50:27,209] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.7, 78.0, 1.0, 2.0, 0.3508312443426038, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 389179.7649636051, 389179.7649636051, 117712.148559336], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6035400.0000, 
sim time next is 6036000.0000, 
raw observation next is [19.6, 78.0, 1.0, 2.0, 0.3482529342171778, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 385741.5672069881, 385741.5672069878, 117278.5149623292], 
processed observation next is [1.0, 0.8695652173913043, 0.5272727272727273, 0.78, 1.0, 1.0, 0.18531616777147222, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1428672471136993, 0.1428672471136992, 0.28604515844470535], 
reward next is 0.7140, 
noisyNet noise sample is [array([0.83750993], dtype=float32), -0.7105494]. 
=============================================
[2019-03-23 02:50:27,225] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[75.80995]
 [75.73163]
 [75.64979]
 [75.56934]
 [75.73398]], R is [[75.96260071]
 [75.91587067]
 [75.86856842]
 [75.82067871]
 [75.77220917]].
[2019-03-23 02:50:30,550] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:50:30,563] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6580
[2019-03-23 02:50:30,567] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.93333333333333, 49.16666666666666, 1.0, 2.0, 0.3541324789199662, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 384558.8046003226, 384558.8046003223, 114983.4898363577], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6094200.0000, 
sim time next is 6094800.0000, 
raw observation next is [23.3, 48.0, 1.0, 2.0, 0.3568941268720532, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 387979.0790742683, 387979.0790742686, 115324.2746105087], 
processed observation next is [1.0, 0.5652173913043478, 0.6954545454545454, 0.48, 1.0, 1.0, 0.19611765859006647, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14369595521269196, 0.14369595521269207, 0.2812787185622163], 
reward next is 0.7187, 
noisyNet noise sample is [array([1.2507828], dtype=float32), -1.0282284]. 
=============================================
[2019-03-23 02:50:31,467] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-23 02:50:31,474] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 02:50:31,475] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 02:50:31,476] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:50:31,477] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 02:50:31,477] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:50:31,478] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:50:31,478] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 02:50:31,479] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 02:50:31,542] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:50:31,542] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:50:32,365] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run101
[2019-03-23 02:50:32,366] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run101
[2019-03-23 02:50:32,410] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run101
[2019-03-23 02:50:32,411] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run101
[2019-03-23 02:50:32,453] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run101
[2019-03-23 02:51:14,994] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06063047], dtype=float32), -0.1620172]
[2019-03-23 02:51:14,995] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.16666666666667, 93.0, 1.0, 2.0, 0.3650651323310464, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 400227.5362198022, 400227.5362198025, 117067.6901218358]
[2019-03-23 02:51:14,998] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 02:51:15,002] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.7578735611046189
[2019-03-23 02:51:32,809] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06063047], dtype=float32), -0.1620172]
[2019-03-23 02:51:32,811] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.11666666666667, 87.0, 1.0, 2.0, 0.527215726156823, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 600813.9714980833, 600813.971498083, 150141.0957843475]
[2019-03-23 02:51:32,812] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 02:51:32,815] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.33605286354039576
[2019-03-23 02:51:58,485] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06063047], dtype=float32), -0.1620172]
[2019-03-23 02:51:58,486] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.7, 79.66666666666667, 1.0, 2.0, 0.5464517458915252, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 623044.6141505452, 623044.6141505452, 149184.4044503894]
[2019-03-23 02:51:58,489] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 02:51:58,494] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.34348007486402277
[2019-03-23 02:52:22,889] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8502.1084 1777098729.9307 169.0000
[2019-03-23 02:52:22,903] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9060.3047 1656272944.4788 80.0000
[2019-03-23 02:52:22,905] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.7327 1706110310.8563 462.0000
[2019-03-23 02:52:22,933] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8855.7542 1663858414.4981 105.0000
[2019-03-23 02:52:22,947] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8573.5511 1683675740.5325 214.0000
[2019-03-23 02:52:23,965] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 2500000, evaluation results [2500000.0, 8502.108365859489, 1777098729.9307194, 169.0, 9060.304679780347, 1656272944.478839, 80.0, 8855.754186439062, 1663858414.498091, 105.0, 8596.732737917102, 1706110310.8562737, 462.0, 8573.551063965167, 1683675740.532508, 214.0]
