Using TensorFlow backend.
[2019-03-22 22:12:36,381] A3C_AGENT_MAIN INFO:Namespace(action_repeat_n=1, action_space='part3_v1', activation='linear', agent_num=5, check_args_only=False, clip_norm=5.0, debug_log_prob=0.0005, decay_steps=1000000, dropout_prob=0.0, end_e=0.0, env='Part3-NA-Pit-Train-v1', eval_act_func='part3_pit_det_v1', eval_env_res_max_keep=50, eval_epi_num=1, eval_freq=25000, forecast_dim=0, gamma=0.99, h_decay_bounds=[], h_regu_frac=[0.0], init_e=0.0, isNoisyNet=True, isNoisyNetEval_rmNoise=True, is_greedy_policy=False, is_learning_rate_decay_staircase=False, is_warm_start=False, job_mode='Train', learning_rate=0.001, learning_rate_decay_rate=1.0, learning_rate_decay_steps=100000, max_interactions=2500000, metric_func='part3_v1', model_dir='None', model_param=[19, 1], model_type='nn', num_threads=16, output='./Part3-NA-Pit-Train-v1-res1', p_loss_frac=1.0, raw_state_prcs_func='cslDx_1', reward_func='part3_v3', rmsprop_decay=0.99, rmsprop_epsil=1e-10, rmsprop_momet=0.0, rwd_e_para=1.0, rwd_p_para=1.0, save_freq=500000, save_max_to_keep=5, save_scope='all', sharedNet_type='Dense', state_dim=17, test_env=['Part3-NA-Pit-Test-v1', 'Part3-NA-Pit-Test-v2', 'Part3-NA-Pit-Test-v3', 'Part3-NA-Pit-Test-v4'], test_mode='Multiple', train_act_func='part3_pit_sto_v1', train_freq=5, v_loss_frac=0.5, violation_penalty_scl=50.0, weight_initer='glorot_uniform', window_len=21)
[2019-03-22 22:12:36,382] A3C_AGENT_MAIN INFO:Start compiling...
2019-03-22 22:12:36.413631: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
[2019-03-22 22:12:51,041] A3C_AGENT_MAIN INFO:Start the learning...
[2019-03-22 22:12:51,041] A3C_AGENT_MAIN INFO:Prepare the evaluation environments ['Part3-NA-Pit-Train-v1', 'Part3-NA-Pit-Test-v1', 'Part3-NA-Pit-Test-v2', 'Part3-NA-Pit-Test-v3', 'Part3-NA-Pit-Test-v4'] ...
[2019-03-22 22:12:51,051] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation worker starts!
[2019-03-22 22:12:51,053] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation worker starts!
[2019-03-22 22:12:51,055] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation worker starts!
[2019-03-22 22:12:51,060] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation worker starts!
[2019-03-22 22:12:51,063] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation worker starts!
[2019-03-22 22:12:51,064] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-22 22:12:51,064] A3C_AGENT_WORKER-Thread-2 INFO:Local worker starts!
[2019-03-22 22:12:51,118] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:12:51,119] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run1
[2019-03-22 22:12:52,065] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-22 22:12:52,067] A3C_AGENT_WORKER-Thread-3 INFO:Local worker starts!
[2019-03-22 22:12:52,130] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:12:52,130] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run1
[2019-03-22 22:12:52,265] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-22 22:12:52,266] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-22 22:12:52,267] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-22 22:12:52,267] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:12:52,267] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:12:52,268] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-22 22:12:52,268] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-22 22:12:52,268] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-22 22:12:52,269] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:12:52,269] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:12:52,269] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:12:52,273] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run1
[2019-03-22 22:12:52,274] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run1
[2019-03-22 22:12:52,274] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run1
[2019-03-22 22:12:52,297] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run1
[2019-03-22 22:12:52,305] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run1
[2019-03-22 22:12:53,068] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-22 22:12:53,069] A3C_AGENT_WORKER-Thread-9 INFO:Local worker starts!
[2019-03-22 22:12:53,126] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:12:53,127] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run1
[2019-03-22 22:12:54,070] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-22 22:12:54,070] A3C_AGENT_WORKER-Thread-10 INFO:Local worker starts!
[2019-03-22 22:12:54,127] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:12:54,128] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run1
[2019-03-22 22:12:55,071] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-22 22:12:55,073] A3C_AGENT_WORKER-Thread-11 INFO:Local worker starts!
[2019-03-22 22:12:55,153] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:12:55,154] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run1
[2019-03-22 22:12:56,073] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-22 22:12:56,074] A3C_AGENT_WORKER-Thread-12 INFO:Local worker starts!
[2019-03-22 22:12:56,147] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:12:56,147] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run1
[2019-03-22 22:12:57,075] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-22 22:12:57,076] A3C_AGENT_WORKER-Thread-13 INFO:Local worker starts!
[2019-03-22 22:12:57,147] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:12:57,148] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run1
[2019-03-22 22:12:58,077] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-22 22:12:58,078] A3C_AGENT_WORKER-Thread-14 INFO:Local worker starts!
[2019-03-22 22:12:58,166] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:12:58,167] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run1
[2019-03-22 22:12:59,079] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-22 22:12:59,080] A3C_AGENT_WORKER-Thread-15 INFO:Local worker starts!
[2019-03-22 22:12:59,157] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:12:59,157] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run1
[2019-03-22 22:13:00,081] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-22 22:13:00,086] A3C_AGENT_WORKER-Thread-16 INFO:Local worker starts!
[2019-03-22 22:13:00,180] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:13:00,181] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run1
[2019-03-22 22:13:01,086] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-22 22:13:01,091] A3C_AGENT_WORKER-Thread-17 INFO:Local worker starts!
[2019-03-22 22:13:01,189] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:13:01,191] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run1
[2019-03-22 22:13:02,092] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-22 22:13:02,093] A3C_AGENT_WORKER-Thread-18 INFO:Local worker starts!
[2019-03-22 22:13:02,179] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:13:02,180] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run1
[2019-03-22 22:13:03,094] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-22 22:13:03,095] A3C_AGENT_WORKER-Thread-19 INFO:Local worker starts!
[2019-03-22 22:13:03,183] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:13:03,184] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run1
[2019-03-22 22:13:04,096] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-22 22:13:04,097] A3C_AGENT_WORKER-Thread-20 INFO:Local worker starts!
[2019-03-22 22:13:04,172] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:13:04,173] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run1
[2019-03-22 22:13:05,098] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-22 22:13:05,099] A3C_AGENT_WORKER-Thread-21 INFO:Local worker starts!
[2019-03-22 22:13:05,185] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:13:05,185] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run1
[2019-03-22 22:13:06,100] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-22 22:13:06,101] A3C_AGENT_WORKER-Thread-22 INFO:Local worker starts!
[2019-03-22 22:13:06,189] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:13:06,190] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run1
[2019-03-22 22:13:58,520] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-22 22:13:58,522] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.02911991166667, 79.8270318, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 2.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 340463.7659236004, 340463.7659236004, 167379.5625089347]
[2019-03-22 22:13:58,522] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 22:13:58,525] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0.07845695 0.32536185 0.31742066 0.15463196 0.12412861], sampled 0.9296849235516218
[2019-03-22 22:14:35,223] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-22 22:14:35,225] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.56666666666667, 62.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 95.55338769695034, 291797.4223538049, 291797.4223538045, 126403.9423834335]
[2019-03-22 22:14:35,225] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 22:14:35,228] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0.05758787 0.0927356  0.35486338 0.23201083 0.2628024 ], sampled 0.903444376682741
[2019-03-22 22:14:45,251] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-22 22:14:45,252] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.085597655, 99.31869307333335, 1.0, 1.0, 0.4393851794474171, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 95.55311693178074, 498017.9371192227, 498017.9371192223, 134521.383459262]
[2019-03-22 22:14:45,255] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 22:14:45,258] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0.1205636  0.2387533  0.33580163 0.13021292 0.17466852], sampled 0.06873317745170993
[2019-03-22 22:14:58,354] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 2119.0504 2084795518.9465 592.0000
[2019-03-22 22:14:58,779] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 2513.6190 2139723903.6671 509.0000
[2019-03-22 22:14:58,820] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 2263.3172 2080466703.6150 567.0000
[2019-03-22 22:14:58,879] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 2217.7584 2074368810.5631 552.0000
[2019-03-22 22:14:58,955] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2089.7790 2098849400.2671 837.0000
[2019-03-22 22:14:59,971] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 0, evaluation results [0.0, 2513.6190148499754, 2139723903.6671364, 509.0, 2217.758389975883, 2074368810.5630565, 552.0, 2263.3172253546627, 2080466703.6149762, 567.0, 2089.778987363973, 2098849400.267111, 837.0, 2119.050436021084, 2084795518.9465456, 592.0]
[2019-03-22 22:15:03,503] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.1256075  0.2579346  0.5277171  0.06536281 0.02337797], sum to 1.0000
[2019-03-22 22:15:03,512] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8825
[2019-03-22 22:15:03,615] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 1.0, 0.3792573543955122, 6.9112, 6.9112, 77.32846344354104, 435669.2075647441, 435669.2075647441, 157766.9610023297], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 28200.0000, 
sim time next is 28800.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3849299230769969, 6.911200000000001, 6.9112, 77.32846344354104, 442116.8675478919, 442116.8675478916, 158565.9433133627], 
processed observation next is [1.0, 0.34782608695652173, 0.45454545454545453, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.12132846153856705, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1637469879807007, 0.16374698798070061, 0.38674620320332365], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.36335444], dtype=float32), -1.2244986]. 
=============================================
[2019-03-22 22:15:05,041] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.1671833e-04 4.5306799e-03 9.9037981e-01 4.1360557e-03 3.6768040e-05], sum to 1.0000
[2019-03-22 22:15:05,049] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0988
[2019-03-22 22:15:05,151] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.0, 78.0, 1.0, 2.0, 0.4287891149736566, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8483939699478302, 6.9112, 6.9112, 77.32846344354104, 971353.5013658251, 971353.5013658251, 221527.1265337223], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 48600.0000, 
sim time next is 49200.0000, 
raw observation next is [21.0, 78.0, 1.0, 2.0, 0.4304628399528503, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8519805084228457, 6.911200000000001, 6.9112, 77.32846344354104, 975334.7890800295, 975334.7890800291, 222268.8481765276], 
processed observation next is [1.0, 0.5652173913043478, 0.5909090909090909, 0.78, 1.0, 1.0, 0.2880785499410628, 0.0, 1.0, -0.25, 1.0, 1.0, 0.7885435834612082, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3612351070666776, 0.36123510706667744, 0.5421191418939697], 
reward next is 0.4579, 
noisyNet noise sample is [array([0.8071339], dtype=float32), -1.4261513]. 
=============================================
[2019-03-22 22:15:08,101] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.8826671e-03 9.7335362e-01 1.0534985e-02 9.1942213e-03 3.4421195e-05], sum to 1.0000
[2019-03-22 22:15:08,115] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0096
[2019-03-22 22:15:08,123] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.66666666666667, 80.33333333333333, 1.0, 2.0, 0.2163740384530835, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 234928.3128455211, 234928.3128455208, 74393.5491021593], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 92400.0000, 
sim time next is 93000.0000, 
raw observation next is [14.33333333333333, 81.16666666666667, 1.0, 2.0, 0.2124794135135589, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 230698.7173875274, 230698.7173875277, 73415.66208966363], 
processed observation next is [1.0, 0.043478260869565216, 0.28787878787878773, 0.8116666666666668, 1.0, 1.0, 0.015599266891948606, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08544396940278792, 0.08544396940278803, 0.17906259046259423], 
reward next is 0.8209, 
noisyNet noise sample is [array([0.54147124], dtype=float32), 1.2429144]. 
=============================================
[2019-03-22 22:15:08,141] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[21.255085]
 [20.87806 ]
 [21.605213]
 [22.125607]
 [22.320784]], R is [[21.84139442]
 [22.44153214]
 [23.03338432]
 [23.61674118]
 [23.38057327]].
[2019-03-22 22:15:11,902] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.6318569e-06 9.9996889e-01 6.8977970e-06 2.2560220e-05 1.3001439e-12], sum to 1.0000
[2019-03-22 22:15:11,916] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5190
[2019-03-22 22:15:12,017] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 43.0, 1.0, 2.0, 0.300684635535671, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 326499.3487163366, 326499.3487163369, 90544.81048211729], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 149400.0000, 
sim time next is 150000.0000, 
raw observation next is [22.0, 43.0, 1.0, 2.0, 0.3012090195589224, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 327068.9442233415, 327068.9442233415, 90462.14327483665], 
processed observation next is [1.0, 0.7391304347826086, 0.6363636363636364, 0.43, 1.0, 1.0, 0.12651127444865296, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12113664600864499, 0.12113664600864499, 0.220639373841065], 
reward next is 0.7794, 
noisyNet noise sample is [array([-0.6381858], dtype=float32), -0.7137796]. 
=============================================
[2019-03-22 22:15:12,033] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[85.2732  ]
 [85.278145]
 [85.34028 ]
 [85.51299 ]
 [85.45911 ]], R is [[85.11781311]
 [85.04579163]
 [84.96872711]
 [84.85980988]
 [84.67935944]].
[2019-03-22 22:15:14,494] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.9260895e-03 9.8487210e-01 4.9702646e-03 8.1361318e-03 9.5469448e-05], sum to 1.0000
[2019-03-22 22:15:14,504] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7104
[2019-03-22 22:15:14,603] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.5, 91.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 209490.0626140104, 209490.0626140106, 71258.66509146146], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 185400.0000, 
sim time next is 186000.0000, 
raw observation next is [13.66666666666667, 90.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 211020.3423804344, 211020.3423804347, 71690.96046971813], 
processed observation next is [0.0, 0.13043478260869565, 0.25757575757575774, 0.9, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07815568236312385, 0.07815568236312397, 0.174856001145654], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.76136374], dtype=float32), 1.6667136]. 
=============================================
[2019-03-22 22:15:14,621] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[18.268723]
 [18.261993]
 [18.121557]
 [18.264626]
 [18.36628 ]], R is [[18.1118679 ]
 [17.93074989]
 [17.75144196]
 [17.57392693]
 [17.39818764]].
[2019-03-22 22:15:16,126] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.4226880e-06 9.9979454e-01 1.0176888e-05 1.9191430e-04 1.5720541e-12], sum to 1.0000
[2019-03-22 22:15:16,138] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5465
[2019-03-22 22:15:16,231] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 75.0, 1.0, 2.0, 0.2647956508738085, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 287517.6630636335, 287517.6630636338, 96059.89764421132], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 207000.0000, 
sim time next is 207600.0000, 
raw observation next is [18.33333333333333, 74.33333333333333, 1.0, 2.0, 0.2716875572680008, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 295003.2308975053, 295003.2308975056, 100566.8172112323], 
processed observation next is [0.0, 0.391304347826087, 0.4696969696969695, 0.7433333333333333, 1.0, 1.0, 0.089609446585001, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10926045588796493, 0.10926045588796504, 0.24528492002739583], 
reward next is 0.7547, 
noisyNet noise sample is [array([0.2839171], dtype=float32), 1.4247464]. 
=============================================
[2019-03-22 22:15:20,528] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.7375129e-04 9.9867624e-01 4.0782001e-04 2.3032515e-04 1.1758984e-05], sum to 1.0000
[2019-03-22 22:15:20,541] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8472
[2019-03-22 22:15:20,636] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 206149.1706384155, 206149.1706384152, 71708.97026249368], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 271800.0000, 
sim time next is 272400.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 205805.1577237288, 205805.1577237285, 71644.80696632239], 
processed observation next is [0.0, 0.13043478260869565, 0.22727272727272727, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07622413249026992, 0.07622413249026982, 0.17474343162517655], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.01906308], dtype=float32), -0.44819856]. 
=============================================
[2019-03-22 22:15:22,112] A3C_AGENT_WORKER-Thread-10 INFO:Local step 500, global step 7877: loss 0.0264
[2019-03-22 22:15:22,165] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 500, global step 7877: learning rate 0.0010
[2019-03-22 22:15:22,199] A3C_AGENT_WORKER-Thread-15 INFO:Local step 500, global step 7893: loss 0.0518
[2019-03-22 22:15:22,200] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 500, global step 7893: learning rate 0.0010
[2019-03-22 22:15:22,315] A3C_AGENT_WORKER-Thread-17 INFO:Local step 500, global step 7936: loss 0.2758
[2019-03-22 22:15:22,319] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 500, global step 7936: learning rate 0.0010
[2019-03-22 22:15:22,351] A3C_AGENT_WORKER-Thread-19 INFO:Local step 500, global step 7952: loss 0.1436
[2019-03-22 22:15:22,354] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 500, global step 7953: learning rate 0.0010
[2019-03-22 22:15:22,368] A3C_AGENT_WORKER-Thread-21 INFO:Local step 500, global step 7959: loss 0.3451
[2019-03-22 22:15:22,371] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 500, global step 7960: learning rate 0.0010
[2019-03-22 22:15:22,408] A3C_AGENT_WORKER-Thread-9 INFO:Local step 500, global step 7973: loss 0.2006
[2019-03-22 22:15:22,415] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 500, global step 7973: learning rate 0.0010
[2019-03-22 22:15:22,427] A3C_AGENT_WORKER-Thread-14 INFO:Local step 500, global step 7980: loss 0.0497
[2019-03-22 22:15:22,429] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 500, global step 7980: learning rate 0.0010
[2019-03-22 22:15:22,432] A3C_AGENT_WORKER-Thread-3 INFO:Local step 500, global step 7981: loss 0.0457
[2019-03-22 22:15:22,433] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 500, global step 7981: learning rate 0.0010
[2019-03-22 22:15:22,448] A3C_AGENT_WORKER-Thread-16 INFO:Local step 500, global step 7986: loss 0.0252
[2019-03-22 22:15:22,453] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 500, global step 7988: learning rate 0.0010
[2019-03-22 22:15:22,454] A3C_AGENT_WORKER-Thread-11 INFO:Local step 500, global step 7988: loss 0.0306
[2019-03-22 22:15:22,458] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 500, global step 7989: learning rate 0.0010
[2019-03-22 22:15:22,471] A3C_AGENT_WORKER-Thread-12 INFO:Local step 500, global step 7995: loss 0.0264
[2019-03-22 22:15:22,474] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 500, global step 7995: learning rate 0.0010
[2019-03-22 22:15:22,545] A3C_AGENT_WORKER-Thread-18 INFO:Local step 500, global step 8027: loss 0.0169
[2019-03-22 22:15:22,548] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 500, global step 8027: learning rate 0.0010
[2019-03-22 22:15:22,562] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.3015760e-10 9.9999845e-01 8.2537866e-08 1.3981247e-06 8.8142274e-15], sum to 1.0000
[2019-03-22 22:15:22,563] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5200
[2019-03-22 22:15:22,568] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 70.5, 1.0, 2.0, 0.2328017302815452, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 252769.3291887488, 252769.3291887488, 86230.14968370399], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 297000.0000, 
sim time next is 297600.0000, 
raw observation next is [18.33333333333333, 68.33333333333333, 1.0, 2.0, 0.2333122390689602, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 253323.7690914676, 253323.7690914676, 86621.06360465166], 
processed observation next is [0.0, 0.43478260869565216, 0.4696969696969695, 0.6833333333333332, 1.0, 1.0, 0.04164029883620024, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09382361818202505, 0.09382361818202505, 0.2112708868406138], 
reward next is 0.7887, 
noisyNet noise sample is [array([-1.2241248], dtype=float32), 0.012021393]. 
=============================================
[2019-03-22 22:15:22,602] A3C_AGENT_WORKER-Thread-22 INFO:Local step 500, global step 8046: loss 0.0049
[2019-03-22 22:15:22,603] A3C_AGENT_WORKER-Thread-20 INFO:Local step 500, global step 8046: loss 0.0002
[2019-03-22 22:15:22,605] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 500, global step 8046: learning rate 0.0010
[2019-03-22 22:15:22,606] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 500, global step 8046: learning rate 0.0010
[2019-03-22 22:15:22,641] A3C_AGENT_WORKER-Thread-13 INFO:Local step 500, global step 8063: loss 0.0296
[2019-03-22 22:15:22,647] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 500, global step 8063: learning rate 0.0010
[2019-03-22 22:15:22,719] A3C_AGENT_WORKER-Thread-2 INFO:Local step 500, global step 8092: loss 0.1718
[2019-03-22 22:15:22,723] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 500, global step 8093: learning rate 0.0010
[2019-03-22 22:15:22,869] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.2571311e-12 1.0000000e+00 8.2762757e-09 3.0642774e-08 7.0416747e-17], sum to 1.0000
[2019-03-22 22:15:22,882] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1248
[2019-03-22 22:15:22,975] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 45.0, 1.0, 2.0, 0.2545822735931406, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 276424.7282769462, 276424.7282769459, 82668.51587932225], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 308400.0000, 
sim time next is 309000.0000, 
raw observation next is [21.0, 44.0, 1.0, 2.0, 0.2563920248457976, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 278390.3135770482, 278390.3135770485, 82105.32288452762], 
processed observation next is [0.0, 0.5652173913043478, 0.5909090909090909, 0.44, 1.0, 1.0, 0.07049003105724698, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10310752354705488, 0.10310752354705499, 0.2002568850842137], 
reward next is 0.7997, 
noisyNet noise sample is [array([-0.68392503], dtype=float32), -0.18097968]. 
=============================================
[2019-03-22 22:15:22,990] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[84.15464 ]
 [84.14442 ]
 [84.148056]
 [84.13291 ]
 [84.08931 ]], R is [[84.08609009]
 [84.04360199]
 [83.99954987]
 [83.95384216]
 [83.90637207]].
[2019-03-22 22:15:23,604] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.9672245e-10 9.9999714e-01 5.7113706e-08 2.8350530e-06 1.8323511e-14], sum to 1.0000
[2019-03-22 22:15:23,613] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6048
[2019-03-22 22:15:23,618] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.16666666666667, 42.66666666666667, 1.0, 2.0, 0.2670070200367589, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 289919.5046458542, 289919.5046458539, 87507.28186709319], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 313800.0000, 
sim time next is 314400.0000, 
raw observation next is [22.33333333333334, 42.33333333333334, 1.0, 2.0, 0.2689309280928402, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 292009.1348101647, 292009.134810165, 88314.71492694085], 
processed observation next is [0.0, 0.6521739130434783, 0.6515151515151518, 0.42333333333333345, 1.0, 1.0, 0.08616366011605023, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1081515314111721, 0.10815153141117222, 0.21540174372424598], 
reward next is 0.7846, 
noisyNet noise sample is [array([-0.10342826], dtype=float32), -0.9282544]. 
=============================================
[2019-03-22 22:15:26,917] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.6443595e-11 1.0000000e+00 2.1149329e-08 2.0783151e-08 1.0242875e-17], sum to 1.0000
[2019-03-22 22:15:26,928] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2495
[2019-03-22 22:15:26,938] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.0, 76.0, 1.0, 2.0, 0.3812699123825723, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 414040.3768443649, 414040.3768443651, 85245.9642569822], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 362400.0000, 
sim time next is 363000.0000, 
raw observation next is [12.0, 76.0, 1.0, 2.0, 0.381912716639745, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 414738.7283788644, 414738.7283788641, 85162.59497858699], 
processed observation next is [1.0, 0.17391304347826086, 0.18181818181818182, 0.76, 1.0, 1.0, 0.22739089579968125, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15360693643661644, 0.15360693643661635, 0.20771364628923655], 
reward next is 0.7923, 
noisyNet noise sample is [array([0.9203118], dtype=float32), 0.2741038]. 
=============================================
[2019-03-22 22:15:26,959] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[83.10191 ]
 [83.17113 ]
 [83.2003  ]
 [83.202576]
 [83.4583  ]], R is [[82.98149109]
 [82.94376373]
 [82.89969635]
 [82.87996674]
 [82.88928986]].
[2019-03-22 22:15:31,063] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.0527474e-10 9.9999988e-01 8.5264482e-08 3.8368064e-08 1.6857539e-15], sum to 1.0000
[2019-03-22 22:15:31,071] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3394
[2019-03-22 22:15:31,077] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.66666666666667, 96.0, 1.0, 2.0, 0.2038937499029703, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 221374.7443653102, 221374.7443653105, 75030.54034139331], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 426000.0000, 
sim time next is 426600.0000, 
raw observation next is [13.5, 97.0, 1.0, 2.0, 0.2025671736857859, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 219934.1074438305, 219934.1074438302, 74637.04924029895], 
processed observation next is [1.0, 0.9565217391304348, 0.25, 0.97, 1.0, 1.0, 0.003208967107232348, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08145707683104833, 0.08145707683104822, 0.18204158351292427], 
reward next is 0.8180, 
noisyNet noise sample is [array([-1.4342006], dtype=float32), 0.9120293]. 
=============================================
[2019-03-22 22:15:32,806] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.7283007e-07 9.9999809e-01 1.5386086e-06 4.3884012e-09 6.7556002e-15], sum to 1.0000
[2019-03-22 22:15:32,817] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3481
[2019-03-22 22:15:32,910] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.5389753544531629, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 585403.8496765246, 585403.8496765243, 110099.0083279956], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 448200.0000, 
sim time next is 448800.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.5340306161252266, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 580029.9563577559, 580029.9563577559, 109523.6740018485], 
processed observation next is [1.0, 0.17391304347826086, 0.22727272727272727, 1.0, 1.0, 1.0, 0.4175382701565332, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21482590976213184, 0.21482590976213184, 0.2671309121996305], 
reward next is 0.7329, 
noisyNet noise sample is [array([0.953737], dtype=float32), -0.72701067]. 
=============================================
[2019-03-22 22:15:33,600] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.7089316e-07 9.9999547e-01 4.0898422e-06 7.8861817e-08 5.5829025e-11], sum to 1.0000
[2019-03-22 22:15:33,612] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6807
[2019-03-22 22:15:33,620] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.2322523078341357, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 252172.6276719162, 252172.6276719159, 77146.6226580023], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 462600.0000, 
sim time next is 463200.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.2577871581723156, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 279905.5844561803, 279905.58445618, 79486.81044573913], 
processed observation next is [1.0, 0.34782608695652173, 0.22727272727272727, 1.0, 1.0, 1.0, 0.07223394771539451, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10366873498377048, 0.10366873498377037, 0.19387026937985155], 
reward next is 0.8061, 
noisyNet noise sample is [array([-1.0503826], dtype=float32), -1.278794]. 
=============================================
[2019-03-22 22:15:38,318] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.3015175e-11 1.0000000e+00 8.3983133e-11 1.2941616e-13 1.3234365e-22], sum to 1.0000
[2019-03-22 22:15:38,331] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6694
[2019-03-22 22:15:38,429] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.66666666666667, 96.0, 1.0, 2.0, 0.2124579870288766, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 230675.4481465858, 230675.4481465855, 75963.14582182984], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 534000.0000, 
sim time next is 534600.0000, 
raw observation next is [13.5, 97.0, 1.0, 2.0, 0.2093696984334703, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 227321.5670497013, 227321.5670497013, 75367.65968922015], 
processed observation next is [1.0, 0.17391304347826086, 0.25, 0.97, 1.0, 1.0, 0.011712123041837871, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08419317298137084, 0.08419317298137084, 0.18382356021761012], 
reward next is 0.8162, 
noisyNet noise sample is [array([-0.48885232], dtype=float32), -0.2999596]. 
=============================================
[2019-03-22 22:15:42,739] A3C_AGENT_WORKER-Thread-9 INFO:Local step 1000, global step 15883: loss 0.0056
[2019-03-22 22:15:42,742] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 1000, global step 15883: learning rate 0.0010
[2019-03-22 22:15:42,776] A3C_AGENT_WORKER-Thread-10 INFO:Local step 1000, global step 15894: loss 0.1064
[2019-03-22 22:15:42,777] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 1000, global step 15894: learning rate 0.0010
[2019-03-22 22:15:42,803] A3C_AGENT_WORKER-Thread-19 INFO:Local step 1000, global step 15902: loss 0.1356
[2019-03-22 22:15:42,808] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 1000, global step 15903: learning rate 0.0010
[2019-03-22 22:15:42,841] A3C_AGENT_WORKER-Thread-17 INFO:Local step 1000, global step 15918: loss 0.2257
[2019-03-22 22:15:42,843] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 1000, global step 15919: learning rate 0.0010
[2019-03-22 22:15:42,851] A3C_AGENT_WORKER-Thread-3 INFO:Local step 1000, global step 15922: loss 0.1889
[2019-03-22 22:15:42,855] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 1000, global step 15924: learning rate 0.0010
[2019-03-22 22:15:42,908] A3C_AGENT_WORKER-Thread-21 INFO:Local step 1000, global step 15947: loss 0.1908
[2019-03-22 22:15:42,913] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 1000, global step 15947: learning rate 0.0010
[2019-03-22 22:15:42,932] A3C_AGENT_WORKER-Thread-15 INFO:Local step 1000, global step 15955: loss 0.5687
[2019-03-22 22:15:42,934] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 1000, global step 15955: learning rate 0.0010
[2019-03-22 22:15:42,946] A3C_AGENT_WORKER-Thread-11 INFO:Local step 1000, global step 15961: loss 0.3723
[2019-03-22 22:15:42,949] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 1000, global step 15961: learning rate 0.0010
[2019-03-22 22:15:42,962] A3C_AGENT_WORKER-Thread-14 INFO:Local step 1000, global step 15966: loss 0.2017
[2019-03-22 22:15:42,963] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 1000, global step 15966: learning rate 0.0010
[2019-03-22 22:15:43,082] A3C_AGENT_WORKER-Thread-20 INFO:Local step 1000, global step 16014: loss 0.0651
[2019-03-22 22:15:43,085] A3C_AGENT_WORKER-Thread-16 INFO:Local step 1000, global step 16014: loss 0.0699
[2019-03-22 22:15:43,086] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 1000, global step 16014: learning rate 0.0010
[2019-03-22 22:15:43,089] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 1000, global step 16015: learning rate 0.0010
[2019-03-22 22:15:43,131] A3C_AGENT_WORKER-Thread-22 INFO:Local step 1000, global step 16032: loss 0.0608
[2019-03-22 22:15:43,133] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 1000, global step 16032: learning rate 0.0010
[2019-03-22 22:15:43,192] A3C_AGENT_WORKER-Thread-12 INFO:Local step 1000, global step 16052: loss 0.0151
[2019-03-22 22:15:43,194] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 1000, global step 16053: learning rate 0.0010
[2019-03-22 22:15:43,274] A3C_AGENT_WORKER-Thread-13 INFO:Local step 1000, global step 16083: loss 0.0135
[2019-03-22 22:15:43,279] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 1000, global step 16083: learning rate 0.0010
[2019-03-22 22:15:43,392] A3C_AGENT_WORKER-Thread-2 INFO:Local step 1000, global step 16135: loss 0.2795
[2019-03-22 22:15:43,395] A3C_AGENT_WORKER-Thread-18 INFO:Local step 1000, global step 16135: loss 0.1659
[2019-03-22 22:15:43,396] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 1000, global step 16135: learning rate 0.0010
[2019-03-22 22:15:43,401] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 1000, global step 16136: learning rate 0.0010
[2019-03-22 22:15:44,998] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.5685214e-13 1.0000000e+00 2.6175841e-11 2.5429623e-13 3.4948675e-18], sum to 1.0000
[2019-03-22 22:15:45,009] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2498
[2019-03-22 22:15:45,102] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.66666666666667, 90.33333333333334, 1.0, 2.0, 0.2846430769564107, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 309075.0370585172, 309075.0370585169, 107003.6708553076], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 631200.0000, 
sim time next is 631800.0000, 
raw observation next is [17.0, 88.5, 1.0, 2.0, 0.2888527293400111, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 313647.4933773316, 313647.4933773314, 110451.8874143725], 
processed observation next is [1.0, 0.30434782608695654, 0.4090909090909091, 0.885, 1.0, 1.0, 0.11106591167501387, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11616573828790058, 0.11616573828790053, 0.26939484735212804], 
reward next is 0.7306, 
noisyNet noise sample is [array([1.0271715], dtype=float32), 0.8640986]. 
=============================================
[2019-03-22 22:15:52,852] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.783114e-03 9.895036e-02 9.517206e-05 9.910364e-03 8.822610e-01], sum to 1.0000
[2019-03-22 22:15:52,866] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3077
[2019-03-22 22:15:52,957] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.66666666666666, 56.0, 1.0, 2.0, 0.6066453498917789, 1.0, 1.0, 0.6066453498917789, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1378834.330300053, 1378834.330300053, 259486.2054995453], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 744000.0000, 
sim time next is 744600.0000, 
raw observation next is [27.83333333333334, 55.5, 1.0, 2.0, 0.4167692768817012, 1.0, 2.0, 0.4167692768817012, 1.0, 1.0, 0.8439652507704217, 6.911199999999999, 6.9112, 77.3421103, 1417103.384465184, 1417103.384465184, 311145.3712970279], 
processed observation next is [1.0, 0.6086956521739131, 0.9015151515151518, 0.555, 1.0, 1.0, 0.27096159610212645, 1.0, 1.0, 0.27096159610212645, 1.0, 0.5, 0.7770932153863169, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.5248531053574755, 0.5248531053574755, 0.7588911495049462], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.02923929], dtype=float32), -0.13377741]. 
=============================================
[2019-03-22 22:16:00,167] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.7313057e-05 5.1267278e-08 3.7113288e-05 9.9994254e-01 2.9332427e-06], sum to 1.0000
[2019-03-22 22:16:00,178] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1037
[2019-03-22 22:16:00,184] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.5, 63.5, 1.0, 2.0, 0.2526189283730829, 1.0, 2.0, 0.2526189283730829, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 575113.3546649943, 575113.3546649939, 180566.5737038384], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 847800.0000, 
sim time next is 848400.0000, 
raw observation next is [26.33333333333334, 64.0, 1.0, 2.0, 0.2510452852780568, 1.0, 2.0, 0.2510452852780568, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 571701.5251186996, 571701.5251187, 180140.657035934], 
processed observation next is [0.0, 0.8260869565217391, 0.8333333333333336, 0.64, 1.0, 1.0, 0.063806606597571, 1.0, 1.0, 0.063806606597571, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2117413055995184, 0.2117413055995185, 0.4393674561852049], 
reward next is 0.5606, 
noisyNet noise sample is [array([-1.48942], dtype=float32), 1.2588015]. 
=============================================
[2019-03-22 22:16:01,831] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.6015176e-09 3.9407611e-02 2.6328533e-09 9.6059233e-01 2.5668816e-11], sum to 1.0000
[2019-03-22 22:16:01,839] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7119
[2019-03-22 22:16:01,845] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [19.83333333333334, 89.00000000000001, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 452862.7279485962, 452862.7279485965, 164674.3330018024], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 871800.0000, 
sim time next is 872400.0000, 
raw observation next is [19.66666666666667, 90.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 452940.8354143014, 452940.8354143014, 164580.6426086468], 
processed observation next is [0.0, 0.08695652173913043, 0.5303030303030305, 0.9, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16775586496825975, 0.16775586496825975, 0.4014162014845044], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.49836567], dtype=float32), 0.8915023]. 
=============================================
[2019-03-22 22:16:03,124] A3C_AGENT_WORKER-Thread-10 INFO:Local step 1500, global step 23826: loss 1.2941
[2019-03-22 22:16:03,128] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 1500, global step 23828: learning rate 0.0010
[2019-03-22 22:16:03,340] A3C_AGENT_WORKER-Thread-19 INFO:Local step 1500, global step 23911: loss 1.3824
[2019-03-22 22:16:03,344] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 1500, global step 23913: learning rate 0.0010
[2019-03-22 22:16:03,424] A3C_AGENT_WORKER-Thread-14 INFO:Local step 1500, global step 23944: loss 1.5350
[2019-03-22 22:16:03,428] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 1500, global step 23945: learning rate 0.0010
[2019-03-22 22:16:03,429] A3C_AGENT_WORKER-Thread-9 INFO:Local step 1500, global step 23947: loss 1.4887
[2019-03-22 22:16:03,439] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 1500, global step 23949: learning rate 0.0010
[2019-03-22 22:16:03,447] A3C_AGENT_WORKER-Thread-15 INFO:Local step 1500, global step 23950: loss 1.3030
[2019-03-22 22:16:03,451] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 1500, global step 23950: learning rate 0.0010
[2019-03-22 22:16:03,456] A3C_AGENT_WORKER-Thread-21 INFO:Local step 1500, global step 23953: loss 1.0836
[2019-03-22 22:16:03,462] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 1500, global step 23955: learning rate 0.0010
[2019-03-22 22:16:03,471] A3C_AGENT_WORKER-Thread-3 INFO:Local step 1500, global step 23959: loss 1.5270
[2019-03-22 22:16:03,473] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 1500, global step 23959: learning rate 0.0010
[2019-03-22 22:16:03,482] A3C_AGENT_WORKER-Thread-11 INFO:Local step 1500, global step 23964: loss 1.3626
[2019-03-22 22:16:03,485] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 1500, global step 23966: learning rate 0.0010
[2019-03-22 22:16:03,527] A3C_AGENT_WORKER-Thread-16 INFO:Local step 1500, global step 23981: loss 1.1096
[2019-03-22 22:16:03,533] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 1500, global step 23983: learning rate 0.0010
[2019-03-22 22:16:03,586] A3C_AGENT_WORKER-Thread-17 INFO:Local step 1500, global step 24006: loss 1.2156
[2019-03-22 22:16:03,589] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 1500, global step 24007: learning rate 0.0010
[2019-03-22 22:16:03,601] A3C_AGENT_WORKER-Thread-13 INFO:Local step 1500, global step 24012: loss 0.8495
[2019-03-22 22:16:03,604] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 1500, global step 24012: learning rate 0.0010
[2019-03-22 22:16:03,693] A3C_AGENT_WORKER-Thread-22 INFO:Local step 1500, global step 24050: loss 0.6332
[2019-03-22 22:16:03,697] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 1500, global step 24051: learning rate 0.0010
[2019-03-22 22:16:03,716] A3C_AGENT_WORKER-Thread-20 INFO:Local step 1500, global step 24059: loss 0.4557
[2019-03-22 22:16:03,720] A3C_AGENT_WORKER-Thread-2 INFO:Local step 1500, global step 24060: loss 0.7479
[2019-03-22 22:16:03,721] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 1500, global step 24060: learning rate 0.0010
[2019-03-22 22:16:03,721] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 1500, global step 24061: learning rate 0.0010
[2019-03-22 22:16:03,791] A3C_AGENT_WORKER-Thread-12 INFO:Local step 1500, global step 24085: loss 0.5756
[2019-03-22 22:16:03,795] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 1500, global step 24085: learning rate 0.0010
[2019-03-22 22:16:03,799] A3C_AGENT_WORKER-Thread-18 INFO:Local step 1500, global step 24089: loss 0.4811
[2019-03-22 22:16:03,803] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 1500, global step 24089: learning rate 0.0010
[2019-03-22 22:16:06,129] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-22 22:16:06,132] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-22 22:16:06,132] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-22 22:16:06,133] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:16:06,135] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-22 22:16:06,136] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-22 22:16:06,135] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:16:06,138] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:16:06,138] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:16:06,137] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-22 22:16:06,141] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:16:06,162] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run2
[2019-03-22 22:16:06,163] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run2
[2019-03-22 22:16:06,164] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run2
[2019-03-22 22:16:06,185] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run2
[2019-03-22 22:16:06,252] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run2
[2019-03-22 22:16:24,791] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.2775425], dtype=float32), 0.13769881]
[2019-03-22 22:16:24,794] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.21666666666667, 60.66666666666666, 1.0, 2.0, 0.5816492539874788, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 662985.4227219938, 662985.4227219938, 156885.0070976456]
[2019-03-22 22:16:24,795] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 22:16:24,798] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.3730497e-26 1.0000000e+00 2.6110221e-26 2.0091591e-14 9.8930168e-28], sampled 0.4496200886795383
[2019-03-22 22:16:53,313] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.2775425], dtype=float32), 0.13769881]
[2019-03-22 22:16:53,313] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.3, 61.66666666666667, 1.0, 2.0, 0.5311256961870804, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 604951.3865327421, 604951.3865327421, 150930.5464805978]
[2019-03-22 22:16:53,314] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 22:16:53,315] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.7158917e-27 1.0000000e+00 2.7386027e-27 3.2831559e-14 1.8479619e-28], sampled 0.5850103048319537
[2019-03-22 22:17:07,403] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.2775425], dtype=float32), 0.13769881]
[2019-03-22 22:17:07,404] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.91666666666667, 77.5, 1.0, 2.0, 0.2786368806913792, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 302551.2782646624, 302551.2782646621, 101028.7155958319]
[2019-03-22 22:17:07,405] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 22:17:07,407] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.8808331e-22 1.0000000e+00 3.6297156e-22 3.1131423e-13 8.5505478e-24], sampled 0.46546037277156493
[2019-03-22 22:17:10,001] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.2775425], dtype=float32), 0.13769881]
[2019-03-22 22:17:10,001] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.05, 69.83333333333333, 1.0, 2.0, 0.4219824704220616, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 478772.9241614001, 478772.9241613997, 133166.3055433196]
[2019-03-22 22:17:10,001] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 22:17:10,004] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [8.5483581e-25 1.0000000e+00 6.7641396e-25 1.4627814e-13 2.1040903e-26], sampled 0.7275389010316938
[2019-03-22 22:17:24,005] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.2775425], dtype=float32), 0.13769881]
[2019-03-22 22:17:24,006] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.33400928333333, 71.37294045000002, 1.0, 2.0, 0.3323895677043692, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 360913.4787095396, 360913.47870954, 105957.9963758559]
[2019-03-22 22:17:24,008] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 22:17:24,010] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.9940394e-23 1.0000000e+00 1.4845600e-23 4.9279266e-13 5.0676913e-25], sampled 0.3851712099543865
[2019-03-22 22:17:28,326] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.2775425], dtype=float32), 0.13769881]
[2019-03-22 22:17:28,329] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [27.4, 41.33333333333334, 1.0, 2.0, 0.3784012661098506, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 425757.6991161208, 425757.6991161204, 126913.5680752469]
[2019-03-22 22:17:28,330] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 22:17:28,333] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.0966552e-25 1.0000000e+00 7.4491839e-26 1.4310425e-13 6.1285803e-27], sampled 0.16168822231784863
[2019-03-22 22:17:59,744] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.2775425], dtype=float32), 0.13769881]
[2019-03-22 22:17:59,744] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [13.8, 78.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 214352.9149994753, 214352.9149994756, 69981.9586707609]
[2019-03-22 22:17:59,745] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 22:17:59,747] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.5972404e-21 1.0000000e+00 2.2295347e-21 6.8431057e-13 7.0891705e-23], sampled 0.04537322984532677
[2019-03-22 22:18:05,268] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.2775425], dtype=float32), 0.13769881]
[2019-03-22 22:18:05,268] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.15761076, 100.0, 1.0, 2.0, 0.4526289998830511, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 515973.8664228739, 515973.8664228735, 138559.6705626363]
[2019-03-22 22:18:05,268] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 22:18:05,269] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [6.3206895e-26 1.0000000e+00 8.6936096e-26 1.2149873e-13 1.5317403e-27], sampled 0.5219476736838556
[2019-03-22 22:18:09,946] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-22 22:18:09,989] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-22 22:18:10,036] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-22 22:18:10,067] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1147 1656209757.7786 80.0000
[2019-03-22 22:18:10,151] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-22 22:18:11,168] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 25000, evaluation results [25000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.114669779829, 1656209757.7786272, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-22 22:18:15,650] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.5867050e-23 1.0000000e+00 1.2690699e-24 3.0937757e-12 5.1008842e-22], sum to 1.0000
[2019-03-22 22:18:15,665] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1597
[2019-03-22 22:18:15,672] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 100.0, 1.0, 2.0, 0.4842278031282397, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 525908.0581059431, 525908.0581059431, 108840.2288272988], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1009800.0000, 
sim time next is 1010400.0000, 
raw observation next is [14.0, 100.0, 1.0, 2.0, 0.4788890421458148, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 520106.6575049819, 520106.6575049819, 108238.4175700115], 
processed observation next is [1.0, 0.6956521739130435, 0.2727272727272727, 1.0, 1.0, 1.0, 0.3486113026822685, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1926320953722155, 0.1926320953722155, 0.2639961404146622], 
reward next is 0.7360, 
noisyNet noise sample is [array([0.39977726], dtype=float32), -0.27691293]. 
=============================================
[2019-03-22 22:18:25,525] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.8300747e-33 1.0000000e+00 1.0347706e-30 6.6881258e-22 4.5345329e-31], sum to 1.0000
[2019-03-22 22:18:25,533] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3903
[2019-03-22 22:18:25,537] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 99.0, 1.0, 2.0, 0.3661890346864636, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 410372.3726361143, 410372.3726361143, 120725.5950456322], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1147800.0000, 
sim time next is 1148400.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.3687835925934727, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 413830.4518646052, 413830.4518646052, 121206.4192798456], 
processed observation next is [1.0, 0.30434782608695654, 0.45454545454545453, 1.0, 1.0, 1.0, 0.21097949074184086, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15327053772763155, 0.15327053772763155, 0.2956254128776722], 
reward next is 0.7044, 
noisyNet noise sample is [array([0.97967947], dtype=float32), -0.31854627]. 
=============================================
[2019-03-22 22:18:26,846] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.2548607e-29 1.0000000e+00 1.2235787e-27 2.4239300e-17 1.4823421e-30], sum to 1.0000
[2019-03-22 22:18:26,852] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9498
[2019-03-22 22:18:26,863] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1222159.026077215 W.
[2019-03-22 22:18:26,868] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.66666666666667, 67.33333333333334, 1.0, 2.0, 0.5944987461969665, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9792940846793796, 6.911200000000001, 6.9112, 77.32846344354104, 1222159.026077215, 1222159.026077215, 278626.1381661565], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1172400.0000, 
sim time next is 1173000.0000, 
raw observation next is [26.83333333333333, 66.66666666666666, 1.0, 2.0, 0.5752872399782356, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9784889219045906, 6.9112, 6.9112, 77.32846344354104, 1200994.354150088, 1200994.354150088, 275162.9038108183], 
processed observation next is [1.0, 0.5652173913043478, 0.8560606060606059, 0.6666666666666665, 1.0, 1.0, 0.46910904997279446, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9692698884351295, 0.0, 0.0, 0.5084288129206541, 0.4448127237592919, 0.4448127237592919, 0.6711290336849226], 
reward next is 0.3289, 
noisyNet noise sample is [array([1.3692558], dtype=float32), -1.008877]. 
=============================================
[2019-03-22 22:18:26,891] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[82.45934 ]
 [83.34707 ]
 [84.532234]
 [84.05114 ]
 [83.96507 ]], R is [[81.17436218]
 [80.36261749]
 [79.84191895]
 [79.50714111]
 [79.28795624]].
[2019-03-22 22:18:28,512] A3C_AGENT_WORKER-Thread-10 INFO:Local step 2000, global step 31817: loss 1.6236
[2019-03-22 22:18:28,514] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 2000, global step 31817: learning rate 0.0010
[2019-03-22 22:18:28,647] A3C_AGENT_WORKER-Thread-9 INFO:Local step 2000, global step 31872: loss 1.0856
[2019-03-22 22:18:28,654] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 2000, global step 31875: learning rate 0.0010
[2019-03-22 22:18:28,731] A3C_AGENT_WORKER-Thread-19 INFO:Local step 2000, global step 31903: loss 0.6204
[2019-03-22 22:18:28,733] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 2000, global step 31903: learning rate 0.0010
[2019-03-22 22:18:28,749] A3C_AGENT_WORKER-Thread-14 INFO:Local step 2000, global step 31908: loss 0.7784
[2019-03-22 22:18:28,751] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 2000, global step 31908: learning rate 0.0010
[2019-03-22 22:18:28,832] A3C_AGENT_WORKER-Thread-16 INFO:Local step 2000, global step 31942: loss 0.5206
[2019-03-22 22:18:28,834] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 2000, global step 31942: learning rate 0.0010
[2019-03-22 22:18:28,852] A3C_AGENT_WORKER-Thread-21 INFO:Local step 2000, global step 31949: loss 0.4161
[2019-03-22 22:18:28,860] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 2000, global step 31949: learning rate 0.0010
[2019-03-22 22:18:28,893] A3C_AGENT_WORKER-Thread-15 INFO:Local step 2000, global step 31965: loss 0.3892
[2019-03-22 22:18:28,896] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 2000, global step 31966: learning rate 0.0010
[2019-03-22 22:18:28,934] A3C_AGENT_WORKER-Thread-3 INFO:Local step 2000, global step 31980: loss 0.1993
[2019-03-22 22:18:28,939] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 2000, global step 31980: learning rate 0.0010
[2019-03-22 22:18:28,961] A3C_AGENT_WORKER-Thread-11 INFO:Local step 2000, global step 31988: loss 0.2418
[2019-03-22 22:18:28,963] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 2000, global step 31989: learning rate 0.0010
[2019-03-22 22:18:29,084] A3C_AGENT_WORKER-Thread-22 INFO:Local step 2000, global step 32037: loss 0.2166
[2019-03-22 22:18:29,093] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 2000, global step 32039: learning rate 0.0010
[2019-03-22 22:18:29,099] A3C_AGENT_WORKER-Thread-17 INFO:Local step 2000, global step 32044: loss 0.0754
[2019-03-22 22:18:29,100] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 2000, global step 32044: learning rate 0.0010
[2019-03-22 22:18:29,111] A3C_AGENT_WORKER-Thread-2 INFO:Local step 2000, global step 32048: loss 0.1255
[2019-03-22 22:18:29,115] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 2000, global step 32049: learning rate 0.0010
[2019-03-22 22:18:29,149] A3C_AGENT_WORKER-Thread-13 INFO:Local step 2000, global step 32062: loss 0.2013
[2019-03-22 22:18:29,155] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 2000, global step 32063: learning rate 0.0010
[2019-03-22 22:18:29,189] A3C_AGENT_WORKER-Thread-12 INFO:Local step 2000, global step 32076: loss 0.0942
[2019-03-22 22:18:29,190] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 2000, global step 32076: learning rate 0.0010
[2019-03-22 22:18:29,219] A3C_AGENT_WORKER-Thread-20 INFO:Local step 2000, global step 32085: loss 0.0616
[2019-03-22 22:18:29,221] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 2000, global step 32086: learning rate 0.0010
[2019-03-22 22:18:29,329] A3C_AGENT_WORKER-Thread-18 INFO:Local step 2000, global step 32135: loss 0.0939
[2019-03-22 22:18:29,330] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 2000, global step 32136: learning rate 0.0010
[2019-03-22 22:18:30,141] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 2.1707522e-38 1.4491991e-35 0.0000000e+00], sum to 1.0000
[2019-03-22 22:18:30,152] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7296
[2019-03-22 22:18:30,159] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.9, 83.66666666666667, 1.0, 2.0, 0.5210440839737538, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 593195.9301219936, 593195.9301219936, 145663.0709208692], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1212600.0000, 
sim time next is 1213200.0000, 
raw observation next is [24.0, 83.0, 1.0, 2.0, 0.5204269174985957, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 592477.8459733204, 592477.8459733204, 145598.9860243731], 
processed observation next is [1.0, 0.043478260869565216, 0.7272727272727273, 0.83, 1.0, 1.0, 0.4005336468732446, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21943623924937794, 0.21943623924937794, 0.3551194781082271], 
reward next is 0.6449, 
noisyNet noise sample is [array([0.07218132], dtype=float32), 1.1602049]. 
=============================================
[2019-03-22 22:18:34,536] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.2849341e-20 1.0000000e+00 2.0042710e-18 3.2496679e-11 3.2085318e-15], sum to 1.0000
[2019-03-22 22:18:34,549] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6335
[2019-03-22 22:18:34,661] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 94.0, 1.0, 2.0, 0.375395842396367, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 417883.6461790773, 417883.6461790773, 120261.4359890788], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1282800.0000, 
sim time next is 1283400.0000, 
raw observation next is [18.0, 94.0, 1.0, 2.0, 0.3730766893174353, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 415271.3984046483, 415271.3984046483, 120058.0559608062], 
processed observation next is [1.0, 0.8695652173913043, 0.45454545454545453, 0.94, 1.0, 1.0, 0.21634586164679412, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1538042216313512, 0.1538042216313512, 0.29282452673367365], 
reward next is 0.7072, 
noisyNet noise sample is [array([2.3808682], dtype=float32), -0.8209346]. 
=============================================
[2019-03-22 22:18:45,795] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.9081358e-25 1.0000000e+00 5.4607371e-27 5.9106244e-17 4.7235095e-21], sum to 1.0000
[2019-03-22 22:18:45,804] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9339
[2019-03-22 22:18:45,911] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 98.0, 1.0, 2.0, 0.4816483103512926, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 549602.0290041616, 549602.0290041614, 138957.5449397267], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1448400.0000, 
sim time next is 1449000.0000, 
raw observation next is [21.0, 97.0, 1.0, 2.0, 0.47712883238344, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 544440.3679564478, 544440.3679564478, 138197.7518135987], 
processed observation next is [0.0, 0.782608695652174, 0.5909090909090909, 0.97, 1.0, 1.0, 0.3464110404793, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20164458072461028, 0.20164458072461028, 0.33706768735024073], 
reward next is 0.6629, 
noisyNet noise sample is [array([1.0418842], dtype=float32), 0.7390502]. 
=============================================
[2019-03-22 22:18:45,943] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[67.731224]
 [67.67915 ]
 [67.61718 ]
 [67.5529  ]
 [67.5029  ]], R is [[67.75845337]
 [67.74195099]
 [67.72379303]
 [67.70441437]
 [67.68495941]].
[2019-03-22 22:18:49,165] A3C_AGENT_WORKER-Thread-10 INFO:Local step 2500, global step 39855: loss 0.0004
[2019-03-22 22:18:49,170] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 2500, global step 39856: learning rate 0.0010
[2019-03-22 22:18:49,260] A3C_AGENT_WORKER-Thread-9 INFO:Local step 2500, global step 39894: loss 0.0368
[2019-03-22 22:18:49,262] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 2500, global step 39894: learning rate 0.0010
[2019-03-22 22:18:49,274] A3C_AGENT_WORKER-Thread-19 INFO:Local step 2500, global step 39898: loss 0.0833
[2019-03-22 22:18:49,276] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 2500, global step 39899: learning rate 0.0010
[2019-03-22 22:18:49,285] A3C_AGENT_WORKER-Thread-16 INFO:Local step 2500, global step 39902: loss 0.0194
[2019-03-22 22:18:49,288] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 2500, global step 39902: learning rate 0.0010
[2019-03-22 22:18:49,341] A3C_AGENT_WORKER-Thread-3 INFO:Local step 2500, global step 39920: loss 0.0752
[2019-03-22 22:18:49,343] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 2500, global step 39920: learning rate 0.0010
[2019-03-22 22:18:49,422] A3C_AGENT_WORKER-Thread-15 INFO:Local step 2500, global step 39953: loss 0.0657
[2019-03-22 22:18:49,426] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 2500, global step 39953: learning rate 0.0010
[2019-03-22 22:18:49,431] A3C_AGENT_WORKER-Thread-21 INFO:Local step 2500, global step 39956: loss 0.0613
[2019-03-22 22:18:49,434] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 2500, global step 39956: learning rate 0.0010
[2019-03-22 22:18:49,443] A3C_AGENT_WORKER-Thread-11 INFO:Local step 2500, global step 39960: loss 0.0358
[2019-03-22 22:18:49,449] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 2500, global step 39962: learning rate 0.0010
[2019-03-22 22:18:49,485] A3C_AGENT_WORKER-Thread-14 INFO:Local step 2500, global step 39980: loss 0.0364
[2019-03-22 22:18:49,490] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 2500, global step 39981: learning rate 0.0010
[2019-03-22 22:18:49,519] A3C_AGENT_WORKER-Thread-17 INFO:Local step 2500, global step 39990: loss 0.0084
[2019-03-22 22:18:49,526] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 2500, global step 39991: learning rate 0.0010
[2019-03-22 22:18:49,601] A3C_AGENT_WORKER-Thread-22 INFO:Local step 2500, global step 40021: loss 0.0029
[2019-03-22 22:18:49,603] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 2500, global step 40023: learning rate 0.0010
[2019-03-22 22:18:49,681] A3C_AGENT_WORKER-Thread-2 INFO:Local step 2500, global step 40054: loss 0.0510
[2019-03-22 22:18:49,684] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 2500, global step 40056: learning rate 0.0010
[2019-03-22 22:18:49,715] A3C_AGENT_WORKER-Thread-12 INFO:Local step 2500, global step 40069: loss 0.0831
[2019-03-22 22:18:49,720] A3C_AGENT_WORKER-Thread-13 INFO:Local step 2500, global step 40070: loss 0.0700
[2019-03-22 22:18:49,720] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 2500, global step 40070: learning rate 0.0010
[2019-03-22 22:18:49,722] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 2500, global step 40070: learning rate 0.0010
[2019-03-22 22:18:49,879] A3C_AGENT_WORKER-Thread-20 INFO:Local step 2500, global step 40133: loss 0.0669
[2019-03-22 22:18:49,882] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 2500, global step 40133: learning rate 0.0010
[2019-03-22 22:18:49,947] A3C_AGENT_WORKER-Thread-18 INFO:Local step 2500, global step 40155: loss 0.0044
[2019-03-22 22:18:49,949] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 2500, global step 40155: learning rate 0.0010
[2019-03-22 22:19:01,420] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.5333863e-29 1.0000000e+00 4.8789776e-27 1.4917360e-15 2.8116851e-28], sum to 1.0000
[2019-03-22 22:19:01,427] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1434
[2019-03-22 22:19:01,436] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 90.0, 1.0, 2.0, 0.5569430480895754, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 617337.9318874725, 617337.9318874725, 136264.49852985], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1676400.0000, 
sim time next is 1677000.0000, 
raw observation next is [18.0, 89.0, 1.0, 2.0, 0.5398251500079626, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 597180.2348087722, 597180.2348087722, 134086.7102312262], 
processed observation next is [1.0, 0.391304347826087, 0.45454545454545453, 0.89, 1.0, 1.0, 0.42478143750995323, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2211778647439897, 0.2211778647439897, 0.3270407566615273], 
reward next is 0.6730, 
noisyNet noise sample is [array([0.24000096], dtype=float32), -1.0357827]. 
=============================================
[2019-03-22 22:19:01,459] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[72.876205]
 [72.84483 ]
 [72.80111 ]
 [72.766464]
 [72.71776 ]], R is [[72.83473206]
 [72.77403259]
 [72.70579529]
 [72.63748169]
 [72.56316376]].
[2019-03-22 22:19:02,214] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.9309161e-28 1.0000000e+00 2.3398878e-27 3.5145763e-13 2.2352227e-29], sum to 1.0000
[2019-03-22 22:19:02,223] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4524
[2019-03-22 22:19:02,322] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.25, 65.0, 1.0, 2.0, 0.4566659311500944, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 496632.5884228879, 496632.5884228876, 123292.5509885148], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1689000.0000, 
sim time next is 1689600.0000, 
raw observation next is [20.4, 64.0, 1.0, 2.0, 0.5587578680199821, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 608197.7997584784, 608197.7997584784, 132740.0796030096], 
processed observation next is [1.0, 0.5652173913043478, 0.5636363636363636, 0.64, 1.0, 1.0, 0.4484473350249775, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.225258444354992, 0.225258444354992, 0.32375629171465753], 
reward next is 0.6762, 
noisyNet noise sample is [array([0.2630732], dtype=float32), -0.94830304]. 
=============================================
[2019-03-22 22:19:03,754] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.5398390e-34 1.0000000e+00 1.5345312e-33 5.1123683e-18 8.0967206e-34], sum to 1.0000
[2019-03-22 22:19:03,764] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4801
[2019-03-22 22:19:03,772] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.5, 50.5, 1.0, 2.0, 0.2489060489384469, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 270259.7868428361, 270259.7868428361, 75466.98465493109], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1708200.0000, 
sim time next is 1708800.0000, 
raw observation next is [17.33333333333333, 51.0, 1.0, 2.0, 0.2451835334610601, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 266216.809253199, 266216.809253199, 74959.04740680095], 
processed observation next is [1.0, 0.782608695652174, 0.42424242424242403, 0.51, 1.0, 1.0, 0.056479416826325096, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09859881824192557, 0.09859881824192557, 0.18282694489463647], 
reward next is 0.8172, 
noisyNet noise sample is [array([0.91023886], dtype=float32), 0.8300815]. 
=============================================
[2019-03-22 22:19:09,552] A3C_AGENT_WORKER-Thread-10 INFO:Local step 3000, global step 47846: loss 0.0014
[2019-03-22 22:19:09,556] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 3000, global step 47847: learning rate 0.0010
[2019-03-22 22:19:09,666] A3C_AGENT_WORKER-Thread-11 INFO:Local step 3000, global step 47887: loss 0.0086
[2019-03-22 22:19:09,668] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 3000, global step 47888: learning rate 0.0010
[2019-03-22 22:19:09,739] A3C_AGENT_WORKER-Thread-16 INFO:Local step 3000, global step 47919: loss 0.0954
[2019-03-22 22:19:09,741] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 3000, global step 47919: learning rate 0.0010
[2019-03-22 22:19:09,745] A3C_AGENT_WORKER-Thread-9 INFO:Local step 3000, global step 47920: loss 0.1930
[2019-03-22 22:19:09,747] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 3000, global step 47921: learning rate 0.0010
[2019-03-22 22:19:09,783] A3C_AGENT_WORKER-Thread-21 INFO:Local step 3000, global step 47934: loss 0.3525
[2019-03-22 22:19:09,786] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 3000, global step 47934: learning rate 0.0010
[2019-03-22 22:19:09,806] A3C_AGENT_WORKER-Thread-17 INFO:Local step 3000, global step 47942: loss 0.1663
[2019-03-22 22:19:09,810] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 3000, global step 47943: learning rate 0.0010
[2019-03-22 22:19:09,816] A3C_AGENT_WORKER-Thread-19 INFO:Local step 3000, global step 47945: loss 0.0127
[2019-03-22 22:19:09,821] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 3000, global step 47945: learning rate 0.0010
[2019-03-22 22:19:09,839] A3C_AGENT_WORKER-Thread-3 INFO:Local step 3000, global step 47953: loss 0.0527
[2019-03-22 22:19:09,841] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 3000, global step 47953: learning rate 0.0010
[2019-03-22 22:19:09,869] A3C_AGENT_WORKER-Thread-14 INFO:Local step 3000, global step 47964: loss 0.1047
[2019-03-22 22:19:09,873] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 3000, global step 47964: learning rate 0.0010
[2019-03-22 22:19:09,874] A3C_AGENT_WORKER-Thread-15 INFO:Local step 3000, global step 47965: loss 0.0242
[2019-03-22 22:19:09,877] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 3000, global step 47965: learning rate 0.0010
[2019-03-22 22:19:09,911] A3C_AGENT_WORKER-Thread-22 INFO:Local step 3000, global step 47979: loss 0.0003
[2019-03-22 22:19:09,912] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 3000, global step 47979: learning rate 0.0010
[2019-03-22 22:19:10,065] A3C_AGENT_WORKER-Thread-2 INFO:Local step 3000, global step 48039: loss 0.0749
[2019-03-22 22:19:10,066] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 3000, global step 48039: learning rate 0.0010
[2019-03-22 22:19:10,183] A3C_AGENT_WORKER-Thread-20 INFO:Local step 3000, global step 48086: loss 0.1540
[2019-03-22 22:19:10,186] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 3000, global step 48086: learning rate 0.0010
[2019-03-22 22:19:10,202] A3C_AGENT_WORKER-Thread-12 INFO:Local step 3000, global step 48092: loss 0.1448
[2019-03-22 22:19:10,208] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 3000, global step 48094: learning rate 0.0010
[2019-03-22 22:19:10,229] A3C_AGENT_WORKER-Thread-13 INFO:Local step 3000, global step 48101: loss 0.0800
[2019-03-22 22:19:10,231] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 3000, global step 48103: learning rate 0.0010
[2019-03-22 22:19:10,526] A3C_AGENT_WORKER-Thread-18 INFO:Local step 3000, global step 48217: loss 0.1830
[2019-03-22 22:19:10,528] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 3000, global step 48218: learning rate 0.0010
[2019-03-22 22:19:10,707] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.781969e-32 1.000000e+00 9.752013e-37 5.505509e-23 0.000000e+00], sum to 1.0000
[2019-03-22 22:19:10,717] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4520
[2019-03-22 22:19:10,724] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.33333333333333, 61.66666666666667, 1.0, 2.0, 0.2076574415421734, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 225462.0662072988, 225462.0662072991, 70615.68025080557], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1812000.0000, 
sim time next is 1812600.0000, 
raw observation next is [15.0, 63.0, 1.0, 2.0, 0.2039200223960056, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 221403.2758436803, 221403.2758436801, 70055.96774573112], 
processed observation next is [1.0, 1.0, 0.3181818181818182, 0.63, 1.0, 1.0, 0.004900027995006981, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08200121327543715, 0.08200121327543708, 0.17086821401397834], 
reward next is 0.8291, 
noisyNet noise sample is [array([-0.26044747], dtype=float32), -0.472612]. 
=============================================
[2019-03-22 22:19:15,068] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-22 22:19:15,073] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-22 22:19:15,074] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-22 22:19:15,075] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-22 22:19:15,077] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-22 22:19:15,078] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-22 22:19:15,082] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:19:15,083] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:19:15,083] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:19:15,076] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:19:15,078] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:19:15,097] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run3
[2019-03-22 22:19:15,098] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run3
[2019-03-22 22:19:15,114] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run3
[2019-03-22 22:19:15,116] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run3
[2019-03-22 22:19:15,174] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run3
[2019-03-22 22:19:22,077] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.2510479], dtype=float32), -0.09855051]
[2019-03-22 22:19:22,079] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.8, 65.33333333333334, 1.0, 2.0, 0.4246812829604188, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 478267.972517081, 478267.972517081, 131287.5434233325]
[2019-03-22 22:19:22,079] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 22:19:22,082] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [6.6978957e-32 1.0000000e+00 2.6568589e-33 1.4764064e-21 4.4344037e-34], sampled 0.6897484664754646
[2019-03-22 22:20:01,267] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.2510479], dtype=float32), -0.09855051]
[2019-03-22 22:20:01,269] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.34412602, 85.85607527666667, 1.0, 2.0, 0.68811741917796, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 783927.2298479292, 783927.2298479292, 172073.0598270333]
[2019-03-22 22:20:01,271] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 22:20:01,274] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.0529359e-30 1.0000000e+00 2.1632458e-31 7.5847721e-14 4.0522506e-31], sampled 0.1922213055471388
[2019-03-22 22:20:28,311] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.2510479], dtype=float32), -0.09855051]
[2019-03-22 22:20:28,312] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.92959745, 77.70806336, 1.0, 2.0, 0.3292628523632448, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 360713.7869670819, 360713.7869670819, 118619.0465383593]
[2019-03-22 22:20:28,312] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 22:20:28,316] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.9422862e-31 1.0000000e+00 1.1302203e-32 5.2219876e-22 3.9387646e-33], sampled 0.951596151539936
[2019-03-22 22:20:39,701] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.2510479], dtype=float32), -0.09855051]
[2019-03-22 22:20:39,703] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [26.1, 54.0, 1.0, 2.0, 0.4188533316751809, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 475932.556197922, 475932.556197922, 129072.9868929396]
[2019-03-22 22:20:39,706] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 22:20:39,709] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.32094955e-30 1.00000000e+00 8.81281986e-32 4.35100492e-20
 3.80227959e-32], sampled 0.7652506516323707
[2019-03-22 22:20:50,914] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.2510479], dtype=float32), -0.09855051]
[2019-03-22 22:20:50,915] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.43333333333334, 71.33333333333334, 1.0, 2.0, 0.6302579647321433, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 719188.5956067394, 719188.5956067394, 161140.3164517927]
[2019-03-22 22:20:50,916] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 22:20:50,920] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [8.2976861e-33 1.0000000e+00 7.0535235e-34 3.5565672e-21 3.2396395e-35], sampled 0.6323669582205065
[2019-03-22 22:20:52,519] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.2510479], dtype=float32), -0.09855051]
[2019-03-22 22:20:52,519] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.25, 71.0, 1.0, 2.0, 0.5984029337569755, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 661115.1722356452, 661115.1722356456, 139867.8286366811]
[2019-03-22 22:20:52,520] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 22:20:52,522] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [5.9039315e-32 1.0000000e+00 2.4776366e-33 6.5163203e-22 1.4184672e-34], sampled 0.7919781742874235
[2019-03-22 22:21:16,927] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.2510479], dtype=float32), -0.09855051]
[2019-03-22 22:21:16,930] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.40871313, 54.32238126666666, 1.0, 2.0, 0.4014318384123552, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 438585.1173787077, 438585.1173787077, 123743.7627255642]
[2019-03-22 22:21:16,933] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 22:21:16,935] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.1726292e-30 1.0000000e+00 8.7288408e-32 4.5898830e-20 1.5208428e-32], sampled 0.3961645443364167
[2019-03-22 22:21:18,248] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9310 1705987275.5940 465.0000
[2019-03-22 22:21:18,322] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-22 22:21:18,618] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-22 22:21:18,893] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-22 22:21:18,932] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2492 1773187030.7201 173.0000
[2019-03-22 22:21:19,947] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 50000, evaluation results [50000.0, 8512.249193409023, 1773187030.7201214, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8596.931041181726, 1705987275.594041, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-22 22:21:27,232] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.3079363e-22 1.0000000e+00 3.9915006e-29 1.4335479e-09 3.5547458e-23], sum to 1.0000
[2019-03-22 22:21:27,244] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7012
[2019-03-22 22:21:27,251] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 66.0, 1.0, 2.0, 0.311930846753211, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 338715.3350989922, 338715.3350989919, 111998.6333007394], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1985400.0000, 
sim time next is 1986000.0000, 
raw observation next is [19.66666666666667, 66.66666666666666, 1.0, 2.0, 0.3050513298042205, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 331242.552168073, 331242.5521680727, 109356.4876598977], 
processed observation next is [1.0, 1.0, 0.5303030303030305, 0.6666666666666665, 1.0, 1.0, 0.13131416225527562, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12268242672891594, 0.12268242672891583, 0.26672314063389685], 
reward next is 0.7333, 
noisyNet noise sample is [array([-0.46195954], dtype=float32), 0.43599668]. 
=============================================
[2019-03-22 22:21:27,264] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[51.301   ]
 [51.28824 ]
 [51.27203 ]
 [51.25388 ]
 [51.231194]], R is [[51.53453064]
 [51.74601746]
 [51.95363998]
 [52.15732956]
 [52.3580513 ]].
[2019-03-22 22:21:34,858] A3C_AGENT_WORKER-Thread-10 INFO:Local step 3500, global step 55856: loss 0.0184
[2019-03-22 22:21:34,859] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 3500, global step 55856: learning rate 0.0010
[2019-03-22 22:21:34,895] A3C_AGENT_WORKER-Thread-11 INFO:Local step 3500, global step 55870: loss 0.0030
[2019-03-22 22:21:34,896] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 3500, global step 55870: learning rate 0.0010
[2019-03-22 22:21:34,910] A3C_AGENT_WORKER-Thread-16 INFO:Local step 3500, global step 55873: loss 0.0304
[2019-03-22 22:21:34,912] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 3500, global step 55874: learning rate 0.0010
[2019-03-22 22:21:34,952] A3C_AGENT_WORKER-Thread-21 INFO:Local step 3500, global step 55890: loss 0.0279
[2019-03-22 22:21:34,961] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 3500, global step 55891: learning rate 0.0010
[2019-03-22 22:21:34,976] A3C_AGENT_WORKER-Thread-19 INFO:Local step 3500, global step 55895: loss 0.0807
[2019-03-22 22:21:34,978] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 3500, global step 55895: learning rate 0.0010
[2019-03-22 22:21:35,061] A3C_AGENT_WORKER-Thread-3 INFO:Local step 3500, global step 55930: loss 0.0678
[2019-03-22 22:21:35,061] A3C_AGENT_WORKER-Thread-9 INFO:Local step 3500, global step 55930: loss 0.0897
[2019-03-22 22:21:35,066] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 3500, global step 55930: learning rate 0.0010
[2019-03-22 22:21:35,067] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 3500, global step 55930: learning rate 0.0010
[2019-03-22 22:21:35,128] A3C_AGENT_WORKER-Thread-17 INFO:Local step 3500, global step 55957: loss 0.0526
[2019-03-22 22:21:35,134] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 3500, global step 55957: learning rate 0.0010
[2019-03-22 22:21:35,139] A3C_AGENT_WORKER-Thread-14 INFO:Local step 3500, global step 55958: loss 0.0696
[2019-03-22 22:21:35,144] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 3500, global step 55960: learning rate 0.0010
[2019-03-22 22:21:35,190] A3C_AGENT_WORKER-Thread-15 INFO:Local step 3500, global step 55979: loss 0.0796
[2019-03-22 22:21:35,196] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 3500, global step 55979: learning rate 0.0010
[2019-03-22 22:21:35,317] A3C_AGENT_WORKER-Thread-22 INFO:Local step 3500, global step 56026: loss 0.0273
[2019-03-22 22:21:35,320] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 3500, global step 56026: learning rate 0.0010
[2019-03-22 22:21:35,389] A3C_AGENT_WORKER-Thread-12 INFO:Local step 3500, global step 56058: loss 0.0026
[2019-03-22 22:21:35,393] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 3500, global step 56058: learning rate 0.0010
[2019-03-22 22:21:35,427] A3C_AGENT_WORKER-Thread-2 INFO:Local step 3500, global step 56069: loss 0.0029
[2019-03-22 22:21:35,432] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 3500, global step 56070: learning rate 0.0010
[2019-03-22 22:21:35,588] A3C_AGENT_WORKER-Thread-13 INFO:Local step 3500, global step 56135: loss 0.0312
[2019-03-22 22:21:35,592] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 3500, global step 56135: learning rate 0.0010
[2019-03-22 22:21:35,611] A3C_AGENT_WORKER-Thread-20 INFO:Local step 3500, global step 56142: loss 0.0613
[2019-03-22 22:21:35,616] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 3500, global step 56143: learning rate 0.0010
[2019-03-22 22:21:35,861] A3C_AGENT_WORKER-Thread-18 INFO:Local step 3500, global step 56237: loss 0.1791
[2019-03-22 22:21:35,862] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 3500, global step 56237: learning rate 0.0010
[2019-03-22 22:21:55,069] A3C_AGENT_WORKER-Thread-11 INFO:Local step 4000, global step 63770: loss 0.2989
[2019-03-22 22:21:55,078] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 4000, global step 63773: learning rate 0.0010
[2019-03-22 22:21:55,187] A3C_AGENT_WORKER-Thread-10 INFO:Local step 4000, global step 63816: loss 0.2620
[2019-03-22 22:21:55,194] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 4000, global step 63817: learning rate 0.0010
[2019-03-22 22:21:55,269] A3C_AGENT_WORKER-Thread-19 INFO:Local step 4000, global step 63848: loss 0.0454
[2019-03-22 22:21:55,275] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 4000, global step 63849: learning rate 0.0010
[2019-03-22 22:21:55,311] A3C_AGENT_WORKER-Thread-21 INFO:Local step 4000, global step 63863: loss 0.1147
[2019-03-22 22:21:55,315] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 4000, global step 63864: learning rate 0.0010
[2019-03-22 22:21:55,331] A3C_AGENT_WORKER-Thread-16 INFO:Local step 4000, global step 63871: loss 0.1215
[2019-03-22 22:21:55,335] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 4000, global step 63872: learning rate 0.0010
[2019-03-22 22:21:55,445] A3C_AGENT_WORKER-Thread-3 INFO:Local step 4000, global step 63915: loss 0.0965
[2019-03-22 22:21:55,447] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 4000, global step 63915: learning rate 0.0010
[2019-03-22 22:21:55,507] A3C_AGENT_WORKER-Thread-15 INFO:Local step 4000, global step 63940: loss 0.0017
[2019-03-22 22:21:55,510] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 4000, global step 63941: learning rate 0.0010
[2019-03-22 22:21:55,567] A3C_AGENT_WORKER-Thread-14 INFO:Local step 4000, global step 63962: loss 0.0061
[2019-03-22 22:21:55,571] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 4000, global step 63962: learning rate 0.0010
[2019-03-22 22:21:55,608] A3C_AGENT_WORKER-Thread-9 INFO:Local step 4000, global step 63978: loss 0.1467
[2019-03-22 22:21:55,609] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 4000, global step 63978: learning rate 0.0010
[2019-03-22 22:21:55,629] A3C_AGENT_WORKER-Thread-17 INFO:Local step 4000, global step 63986: loss 0.0072
[2019-03-22 22:21:55,632] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 4000, global step 63987: learning rate 0.0010
[2019-03-22 22:21:55,775] A3C_AGENT_WORKER-Thread-22 INFO:Local step 4000, global step 64043: loss 0.0318
[2019-03-22 22:21:55,780] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 4000, global step 64044: learning rate 0.0010
[2019-03-22 22:21:55,818] A3C_AGENT_WORKER-Thread-2 INFO:Local step 4000, global step 64058: loss 0.0553
[2019-03-22 22:21:55,820] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 4000, global step 64058: learning rate 0.0010
[2019-03-22 22:21:55,981] A3C_AGENT_WORKER-Thread-12 INFO:Local step 4000, global step 64125: loss 0.0932
[2019-03-22 22:21:55,986] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 4000, global step 64127: learning rate 0.0010
[2019-03-22 22:21:56,076] A3C_AGENT_WORKER-Thread-13 INFO:Local step 4000, global step 64161: loss 0.3615
[2019-03-22 22:21:56,079] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 4000, global step 64162: learning rate 0.0010
[2019-03-22 22:21:56,157] A3C_AGENT_WORKER-Thread-20 INFO:Local step 4000, global step 64193: loss 0.2713
[2019-03-22 22:21:56,160] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 4000, global step 64194: learning rate 0.0010
[2019-03-22 22:21:56,327] A3C_AGENT_WORKER-Thread-18 INFO:Local step 4000, global step 64255: loss 0.0208
[2019-03-22 22:21:56,330] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 4000, global step 64256: learning rate 0.0010
[2019-03-22 22:21:59,440] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.3228200e-38 2.2332067e-33 0.0000000e+00], sum to 1.0000
[2019-03-22 22:21:59,449] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9084
[2019-03-22 22:21:59,456] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.5, 85.0, 1.0, 2.0, 0.5107542704587484, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 554734.2493160967, 554734.2493160967, 118852.9575844881], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2457000.0000, 
sim time next is 2457600.0000, 
raw observation next is [16.66666666666666, 86.0, 1.0, 2.0, 0.5086613968613858, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 552459.87099427, 552459.8709942702, 121546.0898237038], 
processed observation next is [1.0, 0.43478260869565216, 0.39393939393939365, 0.86, 1.0, 1.0, 0.3858267460767322, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2046147670349148, 0.20461476703491488, 0.2964538776187898], 
reward next is 0.7035, 
noisyNet noise sample is [array([0.47002944], dtype=float32), -0.2776333]. 
=============================================
[2019-03-22 22:22:00,125] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.288143e-36 1.000000e+00 1.560223e-36 8.091239e-23 0.000000e+00], sum to 1.0000
[2019-03-22 22:22:00,136] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0025
[2019-03-22 22:22:00,144] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.16666666666667, 81.16666666666667, 1.0, 2.0, 0.7217736557406981, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 784108.9739954432, 784108.9739954435, 145325.3740618487], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2463000.0000, 
sim time next is 2463600.0000, 
raw observation next is [17.33333333333334, 80.33333333333334, 1.0, 2.0, 0.6323432369262454, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 686886.3078188018, 686886.3078188018, 135763.7149635712], 
processed observation next is [1.0, 0.5217391304347826, 0.42424242424242453, 0.8033333333333335, 1.0, 1.0, 0.5404290461578067, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.25440233622918584, 0.25440233622918584, 0.3311310121062712], 
reward next is 0.6689, 
noisyNet noise sample is [array([0.93479174], dtype=float32), 0.5461845]. 
=============================================
[2019-03-22 22:22:01,211] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.1640299e-35 1.0000000e+00 1.0638890e-31 8.7900945e-16 8.7331241e-35], sum to 1.0000
[2019-03-22 22:22:01,225] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9688
[2019-03-22 22:22:01,233] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.1, 62.0, 1.0, 2.0, 0.7750995563830971, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 852048.0049246709, 852048.0049246709, 159149.7442285513], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2478600.0000, 
sim time next is 2479200.0000, 
raw observation next is [21.06666666666667, 61.33333333333334, 1.0, 2.0, 0.7715382515918809, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 846300.1983953983, 846300.1983953986, 158083.3251378278], 
processed observation next is [1.0, 0.6956521739130435, 0.5939393939393941, 0.6133333333333334, 1.0, 1.0, 0.7144228144898512, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3134445179242216, 0.3134445179242217, 0.38556908570201903], 
reward next is 0.6144, 
noisyNet noise sample is [array([0.72131777], dtype=float32), -2.0930774]. 
=============================================
[2019-03-22 22:22:14,956] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.1997899e-33 1.0000000e+00 4.0860718e-32 2.1354435e-23 1.4423540e-36], sum to 1.0000
[2019-03-22 22:22:14,971] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8653
[2019-03-22 22:22:14,979] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.1, 78.33333333333333, 1.0, 2.0, 0.3557309620517927, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 396828.2020843345, 396828.2020843347, 119025.9993830151], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2680800.0000, 
sim time next is 2681400.0000, 
raw observation next is [20.05, 79.16666666666667, 1.0, 2.0, 0.3575209519800368, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 399143.5646982838, 399143.5646982835, 119310.7120506737], 
processed observation next is [0.0, 0.0, 0.5477272727272727, 0.7916666666666667, 1.0, 1.0, 0.196901189975046, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14783094988825327, 0.14783094988825315, 0.29100173670896023], 
reward next is 0.7090, 
noisyNet noise sample is [array([0.02731118], dtype=float32), 1.2439414]. 
=============================================
[2019-03-22 22:22:15,632] A3C_AGENT_WORKER-Thread-11 INFO:Local step 4500, global step 71795: loss 0.0173
[2019-03-22 22:22:15,635] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 4500, global step 71795: learning rate 0.0010
[2019-03-22 22:22:15,761] A3C_AGENT_WORKER-Thread-10 INFO:Local step 4500, global step 71848: loss 0.0317
[2019-03-22 22:22:15,765] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 4500, global step 71848: learning rate 0.0010
[2019-03-22 22:22:15,792] A3C_AGENT_WORKER-Thread-21 INFO:Local step 4500, global step 71859: loss 0.0277
[2019-03-22 22:22:15,801] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 4500, global step 71860: learning rate 0.0010
[2019-03-22 22:22:15,809] A3C_AGENT_WORKER-Thread-19 INFO:Local step 4500, global step 71863: loss 0.0289
[2019-03-22 22:22:15,816] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 4500, global step 71866: learning rate 0.0010
[2019-03-22 22:22:15,826] A3C_AGENT_WORKER-Thread-16 INFO:Local step 4500, global step 71870: loss 0.0294
[2019-03-22 22:22:15,832] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 4500, global step 71870: learning rate 0.0010
[2019-03-22 22:22:15,838] A3C_AGENT_WORKER-Thread-15 INFO:Local step 4500, global step 71874: loss 0.0122
[2019-03-22 22:22:15,840] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 4500, global step 71874: learning rate 0.0010
[2019-03-22 22:22:15,895] A3C_AGENT_WORKER-Thread-3 INFO:Local step 4500, global step 71896: loss 0.0038
[2019-03-22 22:22:15,900] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 4500, global step 71896: learning rate 0.0010
[2019-03-22 22:22:15,990] A3C_AGENT_WORKER-Thread-14 INFO:Local step 4500, global step 71936: loss 0.0016
[2019-03-22 22:22:15,995] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 4500, global step 71936: learning rate 0.0010
[2019-03-22 22:22:16,183] A3C_AGENT_WORKER-Thread-9 INFO:Local step 4500, global step 72010: loss 0.0675
[2019-03-22 22:22:16,187] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 4500, global step 72011: learning rate 0.0010
[2019-03-22 22:22:16,269] A3C_AGENT_WORKER-Thread-17 INFO:Local step 4500, global step 72046: loss 0.0050
[2019-03-22 22:22:16,271] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 4500, global step 72046: learning rate 0.0010
[2019-03-22 22:22:16,278] A3C_AGENT_WORKER-Thread-2 INFO:Local step 4500, global step 72049: loss 0.0058
[2019-03-22 22:22:16,281] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 4500, global step 72049: learning rate 0.0010
[2019-03-22 22:22:16,308] A3C_AGENT_WORKER-Thread-22 INFO:Local step 4500, global step 72059: loss 0.0006
[2019-03-22 22:22:16,310] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 4500, global step 72059: learning rate 0.0010
[2019-03-22 22:22:16,334] A3C_AGENT_WORKER-Thread-12 INFO:Local step 4500, global step 72069: loss 0.0006
[2019-03-22 22:22:16,336] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 4500, global step 72069: learning rate 0.0010
[2019-03-22 22:22:16,538] A3C_AGENT_WORKER-Thread-20 INFO:Local step 4500, global step 72148: loss 0.0698
[2019-03-22 22:22:16,540] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 4500, global step 72148: learning rate 0.0010
[2019-03-22 22:22:16,571] A3C_AGENT_WORKER-Thread-13 INFO:Local step 4500, global step 72158: loss 0.0739
[2019-03-22 22:22:16,573] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 4500, global step 72158: learning rate 0.0010
[2019-03-22 22:22:16,961] A3C_AGENT_WORKER-Thread-18 INFO:Local step 4500, global step 72313: loss 0.0067
[2019-03-22 22:22:16,964] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 4500, global step 72313: learning rate 0.0010
[2019-03-22 22:22:18,234] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.7190677e-38 1.0000000e+00 1.5292252e-33 8.1020988e-26 0.0000000e+00], sum to 1.0000
[2019-03-22 22:22:18,244] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5824
[2019-03-22 22:22:18,250] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.33333333333334, 57.66666666666667, 1.0, 2.0, 0.4511995276312597, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 514515.0188324074, 514515.0188324074, 134310.0878085838], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2737200.0000, 
sim time next is 2737800.0000, 
raw observation next is [26.5, 56.0, 1.0, 2.0, 0.4470117758204592, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 509563.6637642221, 509563.6637642221, 133574.9505439058], 
processed observation next is [0.0, 0.6956521739130435, 0.8409090909090909, 0.56, 1.0, 1.0, 0.30876471977557396, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1887272828756378, 0.1887272828756378, 0.3257925623022093], 
reward next is 0.6742, 
noisyNet noise sample is [array([1.1410336], dtype=float32), -0.3409109]. 
=============================================
[2019-03-22 22:22:20,048] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.7221191e-37 1.0000000e+00 5.1368718e-37 1.2823197e-26 4.4280048e-38], sum to 1.0000
[2019-03-22 22:22:20,060] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5913
[2019-03-22 22:22:20,067] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 78.0, 1.0, 2.0, 0.4103057639828598, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 465104.7058717265, 465104.7058717265, 127413.4084215083], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2762400.0000, 
sim time next is 2763000.0000, 
raw observation next is [21.5, 78.0, 1.0, 2.0, 0.4059084020733732, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 459561.8725940645, 459561.8725940645, 126629.8482746088], 
processed observation next is [0.0, 1.0, 0.6136363636363636, 0.78, 1.0, 1.0, 0.25738550259171644, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17020810096076464, 0.17020810096076464, 0.3088532884746556], 
reward next is 0.6911, 
noisyNet noise sample is [array([1.7132021], dtype=float32), -1.9362072]. 
=============================================
[2019-03-22 22:22:20,089] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[75.57007]
 [75.61174]
 [75.64274]
 [75.65093]
 [75.65816]], R is [[75.43908691]
 [75.37393188]
 [75.30781555]
 [75.2409668 ]
 [75.17399597]].
[2019-03-22 22:22:23,836] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-22 22:22:23,839] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-22 22:22:23,840] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-22 22:22:23,841] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-22 22:22:23,842] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-22 22:22:23,843] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-22 22:22:23,841] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:22:23,844] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:22:23,845] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:22:23,844] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:22:23,843] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:22:23,864] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run4
[2019-03-22 22:22:23,885] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run4
[2019-03-22 22:22:23,886] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run4
[2019-03-22 22:22:23,886] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run4
[2019-03-22 22:22:23,926] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run4
[2019-03-22 22:22:26,518] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.3327801], dtype=float32), -0.025735231]
[2019-03-22 22:22:26,519] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [16.0, 77.0, 1.0, 2.0, 0.227373980264706, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 246874.5408641394, 246874.5408641394, 78567.62690610436]
[2019-03-22 22:22:26,520] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 22:22:26,526] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.2731294e-30 1.0000000e+00 5.7803248e-29 1.2775618e-22 5.0698635e-30], sampled 0.4409333580539263
[2019-03-22 22:22:29,477] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.3327801], dtype=float32), -0.025735231]
[2019-03-22 22:22:29,478] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.853610195, 57.68791866, 1.0, 2.0, 0.2388007102467615, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 259271.4022882671, 259271.4022882668, 91363.29562514194]
[2019-03-22 22:22:29,478] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 22:22:29,480] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.5429030e-31 1.0000000e+00 1.3678454e-29 9.2560433e-23 6.7094321e-31], sampled 0.7125481269963891
[2019-03-22 22:22:44,771] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.3327801], dtype=float32), -0.025735231]
[2019-03-22 22:22:44,771] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.32478819166667, 93.40629684166667, 1.0, 2.0, 0.4186682168898867, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 473688.3652673561, 473688.3652673561, 131961.0572740405]
[2019-03-22 22:22:44,771] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 22:22:44,774] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [8.4844944e-31 1.0000000e+00 6.5644305e-27 1.2386027e-18 2.3777591e-28], sampled 0.49401113460953094
[2019-03-22 22:22:54,473] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.3327801], dtype=float32), -0.025735231]
[2019-03-22 22:22:54,474] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.0, 90.0, 1.0, 2.0, 0.5969564549710767, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 676425.2205950181, 676425.2205950181, 151573.4928758502]
[2019-03-22 22:22:54,477] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 22:22:54,486] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.5440166e-30 1.0000000e+00 6.4145889e-28 4.0452809e-18 3.8406097e-29], sampled 0.6556501061392078
[2019-03-22 22:22:56,596] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.3327801], dtype=float32), -0.025735231]
[2019-03-22 22:22:56,596] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.74849833833333, 42.70757793333333, 1.0, 2.0, 0.2802599292640041, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 304296.0210588393, 304296.0210588393, 87287.34873224537]
[2019-03-22 22:22:56,597] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 22:22:56,603] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.5834711e-31 1.0000000e+00 5.4994893e-29 4.6751951e-22 2.4852984e-30], sampled 0.5554495558042917
[2019-03-22 22:22:59,081] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.3327801], dtype=float32), -0.025735231]
[2019-03-22 22:22:59,082] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.21236528666667, 71.51351547499999, 1.0, 2.0, 0.3334569335429897, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 362072.7893621293, 362072.7893621293, 117801.4087578561]
[2019-03-22 22:22:59,082] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 22:22:59,086] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [6.9916255e-31 1.0000000e+00 2.7483971e-28 4.2649756e-21 1.7483800e-29], sampled 0.08627515837436883
[2019-03-22 22:23:03,984] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.3327801], dtype=float32), -0.025735231]
[2019-03-22 22:23:03,984] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [27.8, 59.0, 1.0, 2.0, 0.524013562934252, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 596830.6969897773, 596830.6969897769, 150072.6404955131]
[2019-03-22 22:23:03,987] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 22:23:03,989] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.2552869e-32 1.0000000e+00 9.0325633e-30 2.3839291e-18 2.9829116e-29], sampled 0.044485747713009616
[2019-03-22 22:23:31,597] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.3327801], dtype=float32), -0.025735231]
[2019-03-22 22:23:31,600] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.32840312, 83.39322336166667, 1.0, 2.0, 0.397002120489316, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 447888.6088064973, 447888.608806497, 129187.5883766207]
[2019-03-22 22:23:31,602] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 22:23:31,604] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.1185772e-31 1.0000000e+00 1.7976224e-28 1.6152929e-20 8.6858681e-30], sampled 0.8584040609210655
[2019-03-22 22:23:39,125] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.3327801], dtype=float32), -0.025735231]
[2019-03-22 22:23:39,127] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.10530163833333, 98.56651956166667, 1.0, 2.0, 0.4820351425174208, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 549036.7853872775, 549036.7853872771, 141079.5767886441]
[2019-03-22 22:23:39,128] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 22:23:39,131] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.7142550e-30 1.0000000e+00 1.1282115e-27 1.3798484e-19 4.2697927e-29], sampled 0.847689748047339
[2019-03-22 22:23:48,290] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.3327801], dtype=float32), -0.025735231]
[2019-03-22 22:23:48,290] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [18.9, 90.0, 1.0, 2.0, 0.4967879897344893, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 556604.1288631391, 556604.1288631387, 136995.7856435804]
[2019-03-22 22:23:48,291] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 22:23:48,294] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.8861851e-29 1.0000000e+00 1.8981771e-26 2.0216415e-17 6.1812640e-28], sampled 0.0757274198946738
[2019-03-22 22:24:10,496] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.3327801], dtype=float32), -0.025735231]
[2019-03-22 22:24:10,497] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.09004112666667, 86.51976237333335, 1.0, 2.0, 0.2424721729341865, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 263258.4664090197, 263258.4664090193, 91950.37155299427]
[2019-03-22 22:24:10,498] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 22:24:10,503] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.6876577e-31 1.0000000e+00 1.2965329e-29 2.3280169e-22 9.8800281e-31], sampled 0.6384960596516378
[2019-03-22 22:24:27,224] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8598.8494 1705487039.1040 455.0000
[2019-03-22 22:24:27,545] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.3327801], dtype=float32), -0.025735231]
[2019-03-22 22:24:27,546] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.92129777, 53.9023053, 1.0, 2.0, 0.2469354780482419, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 268105.4758904767, 268105.4758904764, 81542.22087775126]
[2019-03-22 22:24:27,547] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 22:24:27,549] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [6.1705587e-31 1.0000000e+00 6.7566765e-28 2.5718334e-21 4.7276723e-29], sampled 0.8477172519061332
[2019-03-22 22:24:27,673] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8507.6406 1770974200.7695 169.0000
[2019-03-22 22:24:27,685] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.9940 1663737739.7118 104.0000
[2019-03-22 22:24:27,686] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1361 1656178005.9856 80.0000
[2019-03-22 22:24:27,905] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8577.8754 1682705644.1635 202.0000
[2019-03-22 22:24:28,920] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 75000, evaluation results [75000.0, 8507.640550729937, 1770974200.7694817, 169.0, 9061.136132309683, 1656178005.9856246, 80.0, 8856.994013198835, 1663737739.7117612, 104.0, 8598.849369838277, 1705487039.1039698, 455.0, 8577.875447937373, 1682705644.163458, 202.0]
[2019-03-22 22:24:36,665] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0280316e-36 1.0000000e+00 3.9492010e-28 5.0442921e-19 4.4510505e-32], sum to 1.0000
[2019-03-22 22:24:36,677] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4632
[2019-03-22 22:24:36,683] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.83333333333334, 89.83333333333334, 1.0, 2.0, 0.5231594874231991, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 596105.3683108569, 596105.3683108569, 145498.3814270614], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2923800.0000, 
sim time next is 2924400.0000, 
raw observation next is [22.66666666666667, 90.66666666666667, 1.0, 2.0, 0.5234163683763344, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 596512.5555762494, 596512.5555762494, 145414.4257577642], 
processed observation next is [1.0, 0.8695652173913043, 0.6666666666666669, 0.9066666666666667, 1.0, 1.0, 0.404270460470418, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22093057613935163, 0.22093057613935163, 0.35466933111649807], 
reward next is 0.6453, 
noisyNet noise sample is [array([-1.4438119], dtype=float32), -0.70576984]. 
=============================================
[2019-03-22 22:24:38,530] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.3532666e-36 1.0000000e+00 1.7838065e-32 4.0881331e-23 5.2425108e-35], sum to 1.0000
[2019-03-22 22:24:38,537] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8033
[2019-03-22 22:24:38,542] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 91.5, 1.0, 2.0, 0.5514712014379658, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 628659.4517007879, 628659.4517007879, 148711.536472957], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2961000.0000, 
sim time next is 2961600.0000, 
raw observation next is [22.66666666666666, 90.66666666666666, 1.0, 2.0, 0.5416122162698038, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 617304.9401360824, 617304.940136082, 147604.6980901794], 
processed observation next is [1.0, 0.2608695652173913, 0.6666666666666664, 0.9066666666666666, 1.0, 1.0, 0.4270152703372547, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22863145930966014, 0.22863145930966, 0.36001145875653506], 
reward next is 0.6400, 
noisyNet noise sample is [array([1.1291115], dtype=float32), 1.002438]. 
=============================================
[2019-03-22 22:24:41,235] A3C_AGENT_WORKER-Thread-11 INFO:Local step 5000, global step 79842: loss 24.3846
[2019-03-22 22:24:41,237] A3C_AGENT_WORKER-Thread-10 INFO:Local step 5000, global step 79843: loss 24.7656
[2019-03-22 22:24:41,238] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 5000, global step 79843: learning rate 0.0010
[2019-03-22 22:24:41,239] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 5000, global step 79843: learning rate 0.0010
[2019-03-22 22:24:41,413] A3C_AGENT_WORKER-Thread-19 INFO:Local step 5000, global step 79857: loss 110.7645
[2019-03-22 22:24:41,414] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 5000, global step 79858: learning rate 0.0010
[2019-03-22 22:24:41,512] A3C_AGENT_WORKER-Thread-21 INFO:Local step 5000, global step 79877: loss 28.8205
[2019-03-22 22:24:41,514] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 5000, global step 79877: learning rate 0.0010
[2019-03-22 22:24:41,603] A3C_AGENT_WORKER-Thread-3 INFO:Local step 5000, global step 79889: loss 6.8654
[2019-03-22 22:24:41,603] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 5000, global step 79889: learning rate 0.0010
[2019-03-22 22:24:41,723] A3C_AGENT_WORKER-Thread-15 INFO:Local step 5000, global step 79913: loss 22.2037
[2019-03-22 22:24:41,727] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 5000, global step 79913: learning rate 0.0010
[2019-03-22 22:24:41,805] A3C_AGENT_WORKER-Thread-16 INFO:Local step 5000, global step 79926: loss 69.7355
[2019-03-22 22:24:41,811] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 5000, global step 79926: learning rate 0.0010
[2019-03-22 22:24:41,943] A3C_AGENT_WORKER-Thread-14 INFO:Local step 5000, global step 79957: loss 37.8745
[2019-03-22 22:24:41,947] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 5000, global step 79957: learning rate 0.0010
[2019-03-22 22:24:42,044] A3C_AGENT_WORKER-Thread-17 INFO:Local step 5000, global step 79972: loss 13.0072
[2019-03-22 22:24:42,050] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 5000, global step 79975: learning rate 0.0010
[2019-03-22 22:24:42,206] A3C_AGENT_WORKER-Thread-9 INFO:Local step 5000, global step 80016: loss 40.3270
[2019-03-22 22:24:42,209] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 5000, global step 80017: learning rate 0.0010
[2019-03-22 22:24:42,312] A3C_AGENT_WORKER-Thread-2 INFO:Local step 5000, global step 80034: loss 11.3116
[2019-03-22 22:24:42,313] A3C_AGENT_WORKER-Thread-12 INFO:Local step 5000, global step 80034: loss 53.5167
[2019-03-22 22:24:42,315] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 5000, global step 80034: learning rate 0.0010
[2019-03-22 22:24:42,317] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 5000, global step 80034: learning rate 0.0010
[2019-03-22 22:24:42,524] A3C_AGENT_WORKER-Thread-22 INFO:Local step 5000, global step 80068: loss 93.8776
[2019-03-22 22:24:42,527] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 5000, global step 80068: learning rate 0.0010
[2019-03-22 22:24:42,773] A3C_AGENT_WORKER-Thread-13 INFO:Local step 5000, global step 80151: loss 37.3348
[2019-03-22 22:24:42,777] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 5000, global step 80152: learning rate 0.0010
[2019-03-22 22:24:42,782] A3C_AGENT_WORKER-Thread-20 INFO:Local step 5000, global step 80156: loss 184.9061
[2019-03-22 22:24:42,861] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 5000, global step 80157: learning rate 0.0010
[2019-03-22 22:24:43,211] A3C_AGENT_WORKER-Thread-18 INFO:Local step 5000, global step 80277: loss 29.5889
[2019-03-22 22:24:43,217] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 5000, global step 80278: learning rate 0.0010
[2019-03-22 22:24:48,419] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.3121577e-22 7.3188380e-03 5.7677175e-12 9.9268109e-01 2.7688552e-15], sum to 1.0000
[2019-03-22 22:24:48,432] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9389
[2019-03-22 22:24:48,438] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.0, 74.0, 1.0, 2.0, 0.5780014660084472, 1.0, 1.0, 0.5780014660084472, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1311039.087145277, 1311039.087145277, 252805.2021928974], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3076200.0000, 
sim time next is 3076800.0000, 
raw observation next is [25.33333333333333, 74.0, 1.0, 2.0, 0.5513780228078907, 1.0, 2.0, 0.5513780228078907, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1246744.059688761, 1246744.059688761, 247026.1596200923], 
processed observation next is [1.0, 0.6086956521739131, 0.7878787878787876, 0.74, 1.0, 1.0, 0.4392225285098634, 1.0, 1.0, 0.4392225285098634, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.4617570591439855, 0.4617570591439855, 0.6025028283416886], 
reward next is 0.3975, 
noisyNet noise sample is [array([0.10652895], dtype=float32), 2.0195005]. 
=============================================
[2019-03-22 22:24:49,036] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.1363522e-34 1.0000000e+00 5.2128519e-22 5.9544767e-19 1.9158775e-25], sum to 1.0000
[2019-03-22 22:24:49,046] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7653
[2019-03-22 22:24:49,051] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.16666666666667, 73.33333333333334, 1.0, 2.0, 0.5621985041663362, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 637518.8441695552, 637518.8441695552, 152161.6553943965], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3091800.0000, 
sim time next is 3092400.0000, 
raw observation next is [26.0, 74.0, 1.0, 2.0, 0.5628906973642842, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 638552.0046038725, 638552.0046038725, 152152.596992558], 
processed observation next is [1.0, 0.8260869565217391, 0.8181818181818182, 0.74, 1.0, 1.0, 0.4536133717053552, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2365007424458787, 0.2365007424458787, 0.37110389510380004], 
reward next is 0.6289, 
noisyNet noise sample is [array([0.16365048], dtype=float32), -0.90793645]. 
=============================================
[2019-03-22 22:25:02,408] A3C_AGENT_WORKER-Thread-11 INFO:Local step 5500, global step 87769: loss 0.3764
[2019-03-22 22:25:02,412] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 5500, global step 87770: learning rate 0.0010
[2019-03-22 22:25:02,594] A3C_AGENT_WORKER-Thread-10 INFO:Local step 5500, global step 87845: loss 0.1781
[2019-03-22 22:25:02,596] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 5500, global step 87845: learning rate 0.0010
[2019-03-22 22:25:02,623] A3C_AGENT_WORKER-Thread-19 INFO:Local step 5500, global step 87859: loss 0.1288
[2019-03-22 22:25:02,625] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 5500, global step 87859: learning rate 0.0010
[2019-03-22 22:25:02,649] A3C_AGENT_WORKER-Thread-15 INFO:Local step 5500, global step 87870: loss 0.1141
[2019-03-22 22:25:02,652] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 5500, global step 87871: learning rate 0.0010
[2019-03-22 22:25:02,693] A3C_AGENT_WORKER-Thread-21 INFO:Local step 5500, global step 87886: loss 0.0891
[2019-03-22 22:25:02,704] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 5500, global step 87888: learning rate 0.0010
[2019-03-22 22:25:02,714] A3C_AGENT_WORKER-Thread-16 INFO:Local step 5500, global step 87895: loss 0.0538
[2019-03-22 22:25:02,717] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 5500, global step 87896: learning rate 0.0010
[2019-03-22 22:25:02,720] A3C_AGENT_WORKER-Thread-3 INFO:Local step 5500, global step 87897: loss 0.0514
[2019-03-22 22:25:02,722] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 5500, global step 87897: learning rate 0.0010
[2019-03-22 22:25:02,860] A3C_AGENT_WORKER-Thread-14 INFO:Local step 5500, global step 87952: loss 0.0526
[2019-03-22 22:25:02,862] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 5500, global step 87952: learning rate 0.0010
[2019-03-22 22:25:02,909] A3C_AGENT_WORKER-Thread-17 INFO:Local step 5500, global step 87971: loss 0.0356
[2019-03-22 22:25:02,912] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 5500, global step 87972: learning rate 0.0010
[2019-03-22 22:25:02,925] A3C_AGENT_WORKER-Thread-9 INFO:Local step 5500, global step 87975: loss 0.0519
[2019-03-22 22:25:02,930] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 5500, global step 87975: learning rate 0.0010
[2019-03-22 22:25:03,031] A3C_AGENT_WORKER-Thread-12 INFO:Local step 5500, global step 88017: loss 0.0626
[2019-03-22 22:25:03,039] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 5500, global step 88019: learning rate 0.0010
[2019-03-22 22:25:03,058] A3C_AGENT_WORKER-Thread-2 INFO:Local step 5500, global step 88027: loss 0.0594
[2019-03-22 22:25:03,062] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 5500, global step 88027: learning rate 0.0010
[2019-03-22 22:25:03,207] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 3.695835e-35 0.000000e+00], sum to 1.0000
[2019-03-22 22:25:03,211] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1329
[2019-03-22 22:25:03,219] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 77.0, 1.0, 2.0, 0.2535364909210974, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 275288.8989798814, 275288.8989798814, 87202.81330190477], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3308400.0000, 
sim time next is 3309000.0000, 
raw observation next is [17.33333333333334, 75.5, 1.0, 2.0, 0.2564917191351824, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 278498.5925724228, 278498.5925724228, 88702.3849443147], 
processed observation next is [0.0, 0.30434782608695654, 0.42424242424242453, 0.755, 1.0, 1.0, 0.07061464891897802, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10314762687867511, 0.10314762687867511, 0.21634728035198708], 
reward next is 0.7837, 
noisyNet noise sample is [array([-0.02028264], dtype=float32), 0.13465199]. 
=============================================
[2019-03-22 22:25:03,237] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[74.70449]
 [74.71653]
 [74.75695]
 [74.79901]
 [74.84455]], R is [[74.72059631]
 [74.76069641]
 [74.80186462]
 [74.84407043]
 [74.88741302]].
[2019-03-22 22:25:03,319] A3C_AGENT_WORKER-Thread-22 INFO:Local step 5500, global step 88127: loss 0.0194
[2019-03-22 22:25:03,323] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 5500, global step 88128: learning rate 0.0010
[2019-03-22 22:25:03,388] A3C_AGENT_WORKER-Thread-13 INFO:Local step 5500, global step 88151: loss 0.0112
[2019-03-22 22:25:03,389] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 5500, global step 88151: learning rate 0.0010
[2019-03-22 22:25:03,559] A3C_AGENT_WORKER-Thread-20 INFO:Local step 5500, global step 88219: loss 0.0146
[2019-03-22 22:25:03,561] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 5500, global step 88220: learning rate 0.0010
[2019-03-22 22:25:03,802] A3C_AGENT_WORKER-Thread-18 INFO:Local step 5500, global step 88310: loss 0.1334
[2019-03-22 22:25:03,805] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 5500, global step 88311: learning rate 0.0010
[2019-03-22 22:25:09,774] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.2470305e-28 1.0000000e+00 1.7468501e-25 2.9494246e-18 5.8618437e-28], sum to 1.0000
[2019-03-22 22:25:09,788] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4152
[2019-03-22 22:25:09,799] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 78.0, 1.0, 2.0, 0.7326722754445353, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 832856.5561123712, 832856.5561123709, 166514.4028998267], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3402000.0000, 
sim time next is 3402600.0000, 
raw observation next is [22.0, 78.0, 1.0, 2.0, 0.7676562901952988, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 872918.2309250328, 872918.2309250328, 171746.4472320341], 
processed observation next is [1.0, 0.391304347826087, 0.6363636363636364, 0.78, 1.0, 1.0, 0.7095703627441236, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.32330304849075286, 0.32330304849075286, 0.41889377373666853], 
reward next is 0.5811, 
noisyNet noise sample is [array([0.4853868], dtype=float32), 1.9027423]. 
=============================================
[2019-03-22 22:25:12,790] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.2401665e-21 9.9999964e-01 5.8100639e-19 4.0286278e-07 2.4102528e-19], sum to 1.0000
[2019-03-22 22:25:12,798] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5843
[2019-03-22 22:25:12,805] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 89.0, 1.0, 2.0, 0.5238212741077436, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 596756.5050248498, 596756.5050248498, 145676.180149655], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3448800.0000, 
sim time next is 3449400.0000, 
raw observation next is [23.0, 89.0, 1.0, 2.0, 0.5223592442743391, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 595090.2240000144, 595090.2240000144, 145497.833076891], 
processed observation next is [1.0, 0.9565217391304348, 0.6818181818181818, 0.89, 1.0, 1.0, 0.40294905534292386, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22040378666667199, 0.22040378666667199, 0.3548727636021732], 
reward next is 0.6451, 
noisyNet noise sample is [array([0.44269943], dtype=float32), 0.39372757]. 
=============================================
[2019-03-22 22:25:16,526] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.3250096e-21 9.9997950e-01 6.3928156e-20 2.0518177e-05 4.7685381e-17], sum to 1.0000
[2019-03-22 22:25:16,534] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3719
[2019-03-22 22:25:16,542] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1138208.227448457 W.
[2019-03-22 22:25:16,548] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.0, 70.0, 1.0, 2.0, 0.5062110912757443, 1.0, 2.0, 0.5062110912757443, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1138208.227448457, 1138208.227448456, 237043.6282744843], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3501000.0000, 
sim time next is 3501600.0000, 
raw observation next is [27.0, 70.0, 1.0, 2.0, 0.4998380858355564, 1.0, 2.0, 0.4998380858355564, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1123864.404376839, 1123864.404376839, 235453.8775658561], 
processed observation next is [1.0, 0.5217391304347826, 0.8636363636363636, 0.7, 1.0, 1.0, 0.37479760729444545, 1.0, 1.0, 0.37479760729444545, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.41624607569512556, 0.41624607569512556, 0.5742777501606247], 
reward next is 0.4257, 
noisyNet noise sample is [array([0.23062797], dtype=float32), -2.5750172]. 
=============================================
[2019-03-22 22:25:21,207] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.1489745e-26 1.0000000e+00 3.5780708e-27 5.5255211e-22 1.8642829e-20], sum to 1.0000
[2019-03-22 22:25:21,223] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7830
[2019-03-22 22:25:21,319] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.00000000000001, 1.0, 2.0, 0.6337993601147939, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 722861.9095967278, 722861.909596728, 159170.2720467303], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3571800.0000, 
sim time next is 3572400.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.8081051394041989, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 921763.8787278692, 921763.8787278689, 185470.5326321287], 
processed observation next is [1.0, 0.34782608695652173, 0.6363636363636364, 0.94, 1.0, 1.0, 0.7601314242552487, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3413940291584701, 0.34139402915846995, 0.4523671527612895], 
reward next is 0.5476, 
noisyNet noise sample is [array([0.6747517], dtype=float32), 1.3142531]. 
=============================================
[2019-03-22 22:25:21,494] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.0676907e-15 9.9995351e-01 3.7107401e-18 4.6134635e-05 3.7977119e-07], sum to 1.0000
[2019-03-22 22:25:21,504] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8764
[2019-03-22 22:25:21,511] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1276048.223162207 W.
[2019-03-22 22:25:21,516] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.66666666666667, 89.0, 1.0, 2.0, 0.3782971461239379, 1.0, 2.0, 0.3782971461239379, 1.0, 1.0, 0.7647107816402018, 6.911199999999999, 6.9112, 77.3421103, 1276048.223162207, 1276048.223162207, 296830.1426633432], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3580800.0000, 
sim time next is 3581400.0000, 
raw observation next is [23.83333333333333, 89.0, 1.0, 2.0, 0.3685902462438742, 1.0, 2.0, 0.3685902462438742, 1.0, 2.0, 0.7457737255638386, 6.9112, 6.9112, 77.3421103, 1243269.586739317, 1243269.586739317, 292775.2262536], 
processed observation next is [1.0, 0.43478260869565216, 0.7196969696969695, 0.89, 1.0, 1.0, 0.21073780780484275, 1.0, 1.0, 0.21073780780484275, 1.0, 1.0, 0.6368196079483409, 0.0, 0.0, 0.5085185399722538, 0.4604702173108582, 0.4604702173108582, 0.7140859176917073], 
reward next is 0.2859, 
noisyNet noise sample is [array([-0.3914933], dtype=float32), -1.1558716]. 
=============================================
[2019-03-22 22:25:22,675] A3C_AGENT_WORKER-Thread-19 INFO:Local step 6000, global step 95806: loss 7.2208
[2019-03-22 22:25:22,677] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 6000, global step 95806: learning rate 0.0010
[2019-03-22 22:25:22,819] A3C_AGENT_WORKER-Thread-16 INFO:Local step 6000, global step 95864: loss -49.7379
[2019-03-22 22:25:22,821] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 6000, global step 95864: learning rate 0.0010
[2019-03-22 22:25:22,852] A3C_AGENT_WORKER-Thread-11 INFO:Local step 6000, global step 95876: loss 14.2064
[2019-03-22 22:25:22,854] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 6000, global step 95876: learning rate 0.0010
[2019-03-22 22:25:22,897] A3C_AGENT_WORKER-Thread-3 INFO:Local step 6000, global step 95891: loss -21.3244
[2019-03-22 22:25:22,899] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 6000, global step 95891: learning rate 0.0010
[2019-03-22 22:25:22,913] A3C_AGENT_WORKER-Thread-21 INFO:Local step 6000, global step 95897: loss -2.2592
[2019-03-22 22:25:22,916] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 6000, global step 95897: learning rate 0.0010
[2019-03-22 22:25:22,988] A3C_AGENT_WORKER-Thread-15 INFO:Local step 6000, global step 95927: loss -47.2819
[2019-03-22 22:25:22,992] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 6000, global step 95928: learning rate 0.0010
[2019-03-22 22:25:23,049] A3C_AGENT_WORKER-Thread-10 INFO:Local step 6000, global step 95950: loss -35.7988
[2019-03-22 22:25:23,052] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 6000, global step 95950: learning rate 0.0010
[2019-03-22 22:25:23,075] A3C_AGENT_WORKER-Thread-14 INFO:Local step 6000, global step 95957: loss -1.5166
[2019-03-22 22:25:23,078] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 6000, global step 95959: learning rate 0.0010
[2019-03-22 22:25:23,097] A3C_AGENT_WORKER-Thread-17 INFO:Local step 6000, global step 95966: loss 5.5889
[2019-03-22 22:25:23,099] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 6000, global step 95966: learning rate 0.0010
[2019-03-22 22:25:23,148] A3C_AGENT_WORKER-Thread-9 INFO:Local step 6000, global step 95987: loss 12.0707
[2019-03-22 22:25:23,155] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 6000, global step 95987: learning rate 0.0010
[2019-03-22 22:25:23,214] A3C_AGENT_WORKER-Thread-12 INFO:Local step 6000, global step 96013: loss 48.5428
[2019-03-22 22:25:23,217] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 6000, global step 96014: learning rate 0.0010
[2019-03-22 22:25:23,244] A3C_AGENT_WORKER-Thread-2 INFO:Local step 6000, global step 96023: loss 55.1293
[2019-03-22 22:25:23,245] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 6000, global step 96023: learning rate 0.0010
[2019-03-22 22:25:23,392] A3C_AGENT_WORKER-Thread-13 INFO:Local step 6000, global step 96081: loss -79.8422
[2019-03-22 22:25:23,394] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 6000, global step 96081: learning rate 0.0010
[2019-03-22 22:25:23,588] A3C_AGENT_WORKER-Thread-22 INFO:Local step 6000, global step 96158: loss -4.8957
[2019-03-22 22:25:23,593] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 6000, global step 96159: learning rate 0.0010
[2019-03-22 22:25:23,713] A3C_AGENT_WORKER-Thread-20 INFO:Local step 6000, global step 96206: loss 28.3570
[2019-03-22 22:25:23,716] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 6000, global step 96206: learning rate 0.0010
[2019-03-22 22:25:23,959] A3C_AGENT_WORKER-Thread-18 INFO:Local step 6000, global step 96297: loss -19.9325
[2019-03-22 22:25:23,965] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 6000, global step 96297: learning rate 0.0010
[2019-03-22 22:25:28,490] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.3266508e-18 9.9795973e-01 5.4579089e-15 2.0402914e-03 5.4430873e-14], sum to 1.0000
[2019-03-22 22:25:28,497] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2659
[2019-03-22 22:25:28,506] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1585319.30480568 W.
[2019-03-22 22:25:28,515] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.5, 56.5, 1.0, 2.0, 0.4698554724976782, 1.0, 2.0, 0.4698554724976782, 1.0, 1.0, 0.949052677460676, 6.9112, 6.9112, 77.3421103, 1585319.30480568, 1585319.30480568, 342626.0412614766], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3681000.0000, 
sim time next is 3681600.0000, 
raw observation next is [28.66666666666666, 56.0, 1.0, 2.0, 0.4778815555268857, 1.0, 2.0, 0.4778815555268857, 1.0, 2.0, 0.9661005757961528, 6.911199999999999, 6.9112, 77.3421103, 1612438.332815429, 1612438.332815429, 347544.2997160631], 
processed observation next is [1.0, 0.6086956521739131, 0.9393939393939391, 0.56, 1.0, 1.0, 0.3473519444086071, 1.0, 1.0, 0.3473519444086071, 1.0, 1.0, 0.9515722511373613, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.597199382524233, 0.597199382524233, 0.8476690236977148], 
reward next is 0.1523, 
noisyNet noise sample is [array([-0.63138765], dtype=float32), -0.44486904]. 
=============================================
[2019-03-22 22:25:28,602] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.6198490e-19 9.9872595e-01 2.9725578e-16 1.2739815e-03 9.6456343e-15], sum to 1.0000
[2019-03-22 22:25:28,613] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9030
[2019-03-22 22:25:28,624] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1501564.308023675 W.
[2019-03-22 22:25:28,632] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.0, 55.0, 1.0, 2.0, 0.6672814341088652, 1.0, 2.0, 0.6672814341088652, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1501564.308023675, 1501564.308023675, 281517.3349258516], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3682800.0000, 
sim time next is 3683400.0000, 
raw observation next is [29.0, 54.5, 1.0, 2.0, 0.4164741316061416, 1.0, 2.0, 0.4164741316061416, 1.0, 1.0, 0.8411389597645319, 6.911199999999999, 6.9112, 77.3421103, 1404984.153678027, 1404984.153678027, 314634.264216435], 
processed observation next is [1.0, 0.6521739130434783, 0.9545454545454546, 0.545, 1.0, 1.0, 0.270592664507677, 1.0, 1.0, 0.270592664507677, 1.0, 0.5, 0.7730556568064743, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.5203645013622322, 0.5203645013622322, 0.7674006444303293], 
reward next is 0.2326, 
noisyNet noise sample is [array([-0.63138765], dtype=float32), -0.44486904]. 
=============================================
[2019-03-22 22:25:33,214] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-22 22:25:33,214] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-22 22:25:33,215] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:25:33,216] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-22 22:25:33,217] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:25:33,218] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-22 22:25:33,221] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-22 22:25:33,221] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-22 22:25:33,225] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:25:33,226] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:25:33,228] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:25:33,245] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run5
[2019-03-22 22:25:33,246] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run5
[2019-03-22 22:25:33,264] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run5
[2019-03-22 22:25:33,283] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run5
[2019-03-22 22:25:33,284] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run5
[2019-03-22 22:26:05,084] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.28653002], dtype=float32), -0.10107639]
[2019-03-22 22:26:05,084] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [25.5, 48.0, 1.0, 2.0, 0.3644873344075987, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 408099.2056773676, 408099.2056773672, 124733.4704932334]
[2019-03-22 22:26:05,085] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 22:26:05,088] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.1775782e-37 0.0000000e+00], sampled 0.9642682144336313
[2019-03-22 22:26:49,224] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.28653002], dtype=float32), -0.10107639]
[2019-03-22 22:26:49,225] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.59673304666667, 88.69568814833333, 1.0, 2.0, 0.4138424397274514, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 465519.9861194795, 465519.9861194791, 130011.0044085281]
[2019-03-22 22:26:49,226] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 22:26:49,230] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.1062298e-38 1.0000000e+00 0.0000000e+00 3.5012674e-36 6.2112274e-38], sampled 0.8335890059995973
[2019-03-22 22:27:36,785] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1147 1656209757.7786 80.0000
[2019-03-22 22:27:37,174] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3486 1683344882.4587 214.0000
[2019-03-22 22:27:37,310] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9293 1705966326.6889 465.0000
[2019-03-22 22:27:37,444] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2492 1773187030.7201 173.0000
[2019-03-22 22:27:37,511] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5598 1663796639.0689 105.0000
[2019-03-22 22:27:38,578] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 100000, evaluation results [100000.0, 8512.249193409023, 1773187030.7201214, 173.0, 9061.114669779829, 1656209757.7786272, 80.0, 8856.559759326878, 1663796639.0688558, 105.0, 8596.929320447398, 1705966326.688919, 465.0, 8574.348638023737, 1683344882.4586744, 214.0]
[2019-03-22 22:27:40,614] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.9438466e-38], sum to 1.0000
[2019-03-22 22:27:40,624] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4625
[2019-03-22 22:27:40,631] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 88.0, 1.0, 2.0, 0.3421249238091587, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 376559.293360077, 376559.293360077, 115882.0099887087], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3789600.0000, 
sim time next is 3790200.0000, 
raw observation next is [18.0, 88.0, 1.0, 2.0, 0.3403920272148871, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 374643.6934151347, 374643.6934151347, 115749.1808570178], 
processed observation next is [1.0, 0.8695652173913043, 0.45454545454545453, 0.88, 1.0, 1.0, 0.17549003401860885, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13875692348708693, 0.13875692348708693, 0.282315075261019], 
reward next is 0.7177, 
noisyNet noise sample is [array([0.08885626], dtype=float32), 0.2469991]. 
=============================================
[2019-03-22 22:27:41,012] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 22:27:41,021] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8449
[2019-03-22 22:27:41,027] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 88.0, 1.0, 2.0, 0.3416763748208801, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 376289.4215244665, 376289.4215244662, 115931.8251060038], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3787200.0000, 
sim time next is 3787800.0000, 
raw observation next is [18.0, 88.00000000000001, 1.0, 2.0, 0.3424849355796491, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 376972.6417938228, 376972.6417938225, 115915.3641534386], 
processed observation next is [1.0, 0.8695652173913043, 0.45454545454545453, 0.8800000000000001, 1.0, 1.0, 0.17810616947456134, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1396194969606751, 0.13961949696067502, 0.28272040037424045], 
reward next is 0.7173, 
noisyNet noise sample is [array([0.44675425], dtype=float32), 2.0110424]. 
=============================================
[2019-03-22 22:27:42,519] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.2577694e-37], sum to 1.0000
[2019-03-22 22:27:42,529] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7955
[2019-03-22 22:27:42,535] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.16666666666667, 93.0, 1.0, 2.0, 0.3331910555174638, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 365070.8397355153, 365070.8397355153, 114607.8449930145], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3797400.0000, 
sim time next is 3798000.0000, 
raw observation next is [17.0, 94.0, 1.0, 2.0, 0.3329777706618763, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 364452.4026181274, 364452.4026181276, 114454.4346673623], 
processed observation next is [1.0, 1.0, 0.4090909090909091, 0.94, 1.0, 1.0, 0.16622221332734533, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1349823713400472, 0.13498237134004726, 0.2791571577252739], 
reward next is 0.7208, 
noisyNet noise sample is [array([-1.3094426], dtype=float32), 0.51860934]. 
=============================================
[2019-03-22 22:27:42,548] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[72.04179 ]
 [72.011024]
 [71.99119 ]
 [71.975464]
 [71.94117 ]], R is [[72.10276031]
 [72.10220337]
 [72.10126495]
 [72.09980011]
 [72.09771729]].
[2019-03-22 22:27:45,321] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.3482282e-35 1.1205146e-31 1.3666968e-38], sum to 1.0000
[2019-03-22 22:27:45,333] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8420
[2019-03-22 22:27:45,342] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 73.0, 1.0, 2.0, 0.2999969934747828, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 325752.4203570376, 325752.4203570373, 111191.381749966], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3841800.0000, 
sim time next is 3842400.0000, 
raw observation next is [19.0, 73.0, 1.0, 2.0, 0.2982750101389878, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 323881.9781609855, 323881.9781609857, 111076.2838134219], 
processed observation next is [0.0, 0.4782608695652174, 0.5, 0.73, 1.0, 1.0, 0.1228437626737347, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11995628820777242, 0.11995628820777247, 0.27091776539859], 
reward next is 0.7291, 
noisyNet noise sample is [array([-0.10854892], dtype=float32), -1.5568477]. 
=============================================
[2019-03-22 22:27:48,017] A3C_AGENT_WORKER-Thread-19 INFO:Local step 6500, global step 103707: loss 0.0032
[2019-03-22 22:27:48,022] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 6500, global step 103708: learning rate 0.0010
[2019-03-22 22:27:48,093] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.5930204e-38 1.0000000e+00 1.4162320e-37 5.9637954e-27 2.0100566e-36], sum to 1.0000
[2019-03-22 22:27:48,102] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6609
[2019-03-22 22:27:48,209] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 77.0, 1.0, 2.0, 0.281362457399602, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 305511.7109732488, 305511.710973249, 101643.3464513569], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3894600.0000, 
sim time next is 3895200.0000, 
raw observation next is [18.0, 77.0, 1.0, 2.0, 0.2816331722128767, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 305805.7535760876, 305805.7535760876, 101667.6814641793], 
processed observation next is [0.0, 0.08695652173913043, 0.45454545454545453, 0.77, 1.0, 1.0, 0.10204146526609587, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11326139021336577, 0.11326139021336577, 0.24796995479068124], 
reward next is 0.7520, 
noisyNet noise sample is [array([0.09545358], dtype=float32), 1.0980514]. 
=============================================
[2019-03-22 22:27:48,392] A3C_AGENT_WORKER-Thread-21 INFO:Local step 6500, global step 103819: loss 0.0487
[2019-03-22 22:27:48,393] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 6500, global step 103819: learning rate 0.0010
[2019-03-22 22:27:48,510] A3C_AGENT_WORKER-Thread-16 INFO:Local step 6500, global step 103871: loss 0.0791
[2019-03-22 22:27:48,514] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 6500, global step 103871: learning rate 0.0010
[2019-03-22 22:27:48,547] A3C_AGENT_WORKER-Thread-3 INFO:Local step 6500, global step 103884: loss 0.0670
[2019-03-22 22:27:48,552] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 6500, global step 103884: learning rate 0.0010
[2019-03-22 22:27:48,559] A3C_AGENT_WORKER-Thread-11 INFO:Local step 6500, global step 103886: loss 0.0688
[2019-03-22 22:27:48,561] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 6500, global step 103886: learning rate 0.0010
[2019-03-22 22:27:48,641] A3C_AGENT_WORKER-Thread-14 INFO:Local step 6500, global step 103917: loss 0.0418
[2019-03-22 22:27:48,645] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 6500, global step 103917: learning rate 0.0010
[2019-03-22 22:27:48,676] A3C_AGENT_WORKER-Thread-2 INFO:Local step 6500, global step 103935: loss 0.0235
[2019-03-22 22:27:48,678] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 6500, global step 103935: learning rate 0.0010
[2019-03-22 22:27:48,699] A3C_AGENT_WORKER-Thread-17 INFO:Local step 6500, global step 103943: loss 0.0597
[2019-03-22 22:27:48,704] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 6500, global step 103943: learning rate 0.0010
[2019-03-22 22:27:48,740] A3C_AGENT_WORKER-Thread-15 INFO:Local step 6500, global step 103959: loss 0.0137
[2019-03-22 22:27:48,743] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 6500, global step 103960: learning rate 0.0010
[2019-03-22 22:27:48,844] A3C_AGENT_WORKER-Thread-10 INFO:Local step 6500, global step 103995: loss 0.0195
[2019-03-22 22:27:48,847] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 6500, global step 103996: learning rate 0.0010
[2019-03-22 22:27:48,915] A3C_AGENT_WORKER-Thread-9 INFO:Local step 6500, global step 104024: loss 0.0042
[2019-03-22 22:27:48,920] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 6500, global step 104025: learning rate 0.0010
[2019-03-22 22:27:49,024] A3C_AGENT_WORKER-Thread-12 INFO:Local step 6500, global step 104062: loss 0.0087
[2019-03-22 22:27:49,027] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 6500, global step 104063: learning rate 0.0010
[2019-03-22 22:27:49,184] A3C_AGENT_WORKER-Thread-13 INFO:Local step 6500, global step 104128: loss 0.0382
[2019-03-22 22:27:49,185] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 6500, global step 104128: learning rate 0.0010
[2019-03-22 22:27:49,344] A3C_AGENT_WORKER-Thread-22 INFO:Local step 6500, global step 104191: loss 0.0622
[2019-03-22 22:27:49,347] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 6500, global step 104191: learning rate 0.0010
[2019-03-22 22:27:49,363] A3C_AGENT_WORKER-Thread-18 INFO:Local step 6500, global step 104200: loss 0.0895
[2019-03-22 22:27:49,369] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 6500, global step 104201: learning rate 0.0010
[2019-03-22 22:27:49,632] A3C_AGENT_WORKER-Thread-20 INFO:Local step 6500, global step 104302: loss 0.0556
[2019-03-22 22:27:49,634] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 6500, global step 104303: learning rate 0.0010
[2019-03-22 22:27:51,237] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.4509504e-38 2.4880797e-36 0.0000000e+00], sum to 1.0000
[2019-03-22 22:27:51,247] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2893
[2019-03-22 22:27:51,252] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 45.0, 1.0, 2.0, 0.3499843986518817, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 391461.5976313567, 391461.597631357, 119035.6675711657], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3937800.0000, 
sim time next is 3938400.0000, 
raw observation next is [26.0, 45.0, 1.0, 2.0, 0.3494400322035693, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 390849.9105148989, 390849.9105148989, 118990.4350787147], 
processed observation next is [0.0, 0.6086956521739131, 0.8181818181818182, 0.45, 1.0, 1.0, 0.1868000402544616, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14475922611662922, 0.14475922611662922, 0.2902205733627188], 
reward next is 0.7098, 
noisyNet noise sample is [array([0.7626741], dtype=float32), 1.0322008]. 
=============================================
[2019-03-22 22:27:53,078] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.4367791e-30 5.5551490e-38], sum to 1.0000
[2019-03-22 22:27:53,090] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3894
[2019-03-22 22:27:53,097] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.83333333333334, 53.66666666666667, 1.0, 2.0, 0.3220360675148651, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 353658.7723394582, 353658.7723394582, 114102.4062646259], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3960600.0000, 
sim time next is 3961200.0000, 
raw observation next is [22.66666666666667, 54.33333333333334, 1.0, 2.0, 0.3218633527582166, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 353224.7430109989, 353224.7430109992, 113999.1920340932], 
processed observation next is [0.0, 0.8695652173913043, 0.6666666666666669, 0.5433333333333334, 1.0, 1.0, 0.15232919094777073, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13082397889296254, 0.13082397889296268, 0.2780468098392517], 
reward next is 0.7220, 
noisyNet noise sample is [array([1.5803077], dtype=float32), 1.14004]. 
=============================================
[2019-03-22 22:27:55,402] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 8.941929e-35 5.967221e-38], sum to 1.0000
[2019-03-22 22:27:55,412] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5142
[2019-03-22 22:27:55,425] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.16666666666667, 88.00000000000001, 1.0, 2.0, 0.262118877870271, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 284610.3467631422, 284610.3467631419, 92286.6061526765], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3996600.0000, 
sim time next is 3997200.0000, 
raw observation next is [16.33333333333334, 88.0, 1.0, 2.0, 0.2649510883316621, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 287686.4884677681, 287686.4884677678, 94604.47702971786], 
processed observation next is [1.0, 0.2608695652173913, 0.37878787878787906, 0.88, 1.0, 1.0, 0.0811888604145776, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10655055128435857, 0.10655055128435843, 0.23074262690175087], 
reward next is 0.7693, 
noisyNet noise sample is [array([-0.89018166], dtype=float32), 0.4070401]. 
=============================================
[2019-03-22 22:27:58,051] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.6671917e-35 1.0000000e+00 1.8405889e-28 1.2395534e-32 6.1296822e-26], sum to 1.0000
[2019-03-22 22:27:58,062] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6911
[2019-03-22 22:27:58,068] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 94.0, 1.0, 2.0, 0.3345622444334198, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 366451.8598301183, 366451.8598301183, 114663.8665722539], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4039200.0000, 
sim time next is 4039800.0000, 
raw observation next is [17.0, 95.0, 1.0, 2.0, 0.3366214463914776, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 368936.3511369004, 368936.3511369004, 114896.8123517901], 
processed observation next is [1.0, 0.782608695652174, 0.4090909090909091, 0.95, 1.0, 1.0, 0.170776807989347, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1366430930136668, 0.1366430930136668, 0.28023612768729295], 
reward next is 0.7198, 
noisyNet noise sample is [array([1.1614827], dtype=float32), -2.8808777]. 
=============================================
[2019-03-22 22:28:02,806] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.9615694e-30 1.0000000e+00 1.0526132e-25 8.9302692e-13 9.8374860e-25], sum to 1.0000
[2019-03-22 22:28:02,814] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8453
[2019-03-22 22:28:02,821] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 78.0, 1.0, 2.0, 0.6603394179265698, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 745249.7138316043, 745249.7138316047, 153313.1234306427], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4096800.0000, 
sim time next is 4097400.0000, 
raw observation next is [21.16666666666667, 78.0, 1.0, 2.0, 0.6813598708037037, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 769873.564897728, 769873.5648977278, 156459.2659965756], 
processed observation next is [1.0, 0.43478260869565216, 0.5984848484848487, 0.78, 1.0, 1.0, 0.6016998385046296, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2851383573695289, 0.2851383573695288, 0.3816079658453063], 
reward next is 0.6184, 
noisyNet noise sample is [array([1.3243229], dtype=float32), -2.0166016]. 
=============================================
[2019-03-22 22:28:08,682] A3C_AGENT_WORKER-Thread-21 INFO:Local step 7000, global step 111751: loss 0.0618
[2019-03-22 22:28:08,685] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 7000, global step 111752: learning rate 0.0010
[2019-03-22 22:28:08,710] A3C_AGENT_WORKER-Thread-19 INFO:Local step 7000, global step 111764: loss 0.1404
[2019-03-22 22:28:08,714] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 7000, global step 111765: learning rate 0.0010
[2019-03-22 22:28:08,898] A3C_AGENT_WORKER-Thread-14 INFO:Local step 7000, global step 111836: loss 0.0517
[2019-03-22 22:28:08,904] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 7000, global step 111837: learning rate 0.0010
[2019-03-22 22:28:09,028] A3C_AGENT_WORKER-Thread-11 INFO:Local step 7000, global step 111882: loss 0.0528
[2019-03-22 22:28:09,033] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 7000, global step 111882: learning rate 0.0010
[2019-03-22 22:28:09,064] A3C_AGENT_WORKER-Thread-3 INFO:Local step 7000, global step 111894: loss 0.0889
[2019-03-22 22:28:09,069] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 7000, global step 111896: learning rate 0.0010
[2019-03-22 22:28:09,190] A3C_AGENT_WORKER-Thread-16 INFO:Local step 7000, global step 111947: loss 0.0486
[2019-03-22 22:28:09,193] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 7000, global step 111947: learning rate 0.0010
[2019-03-22 22:28:09,208] A3C_AGENT_WORKER-Thread-2 INFO:Local step 7000, global step 111953: loss 0.0086
[2019-03-22 22:28:09,212] A3C_AGENT_WORKER-Thread-15 INFO:Local step 7000, global step 111954: loss 0.0161
[2019-03-22 22:28:09,215] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 7000, global step 111953: learning rate 0.0010
[2019-03-22 22:28:09,224] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 7000, global step 111956: learning rate 0.0010
[2019-03-22 22:28:09,266] A3C_AGENT_WORKER-Thread-17 INFO:Local step 7000, global step 111977: loss 0.0095
[2019-03-22 22:28:09,268] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 7000, global step 111978: learning rate 0.0010
[2019-03-22 22:28:09,341] A3C_AGENT_WORKER-Thread-9 INFO:Local step 7000, global step 112008: loss 0.0181
[2019-03-22 22:28:09,343] A3C_AGENT_WORKER-Thread-10 INFO:Local step 7000, global step 112008: loss 0.0115
[2019-03-22 22:28:09,345] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 7000, global step 112008: learning rate 0.0010
[2019-03-22 22:28:09,345] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 7000, global step 112009: learning rate 0.0010
[2019-03-22 22:28:09,380] A3C_AGENT_WORKER-Thread-12 INFO:Local step 7000, global step 112021: loss 0.0145
[2019-03-22 22:28:09,382] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 7000, global step 112022: learning rate 0.0010
[2019-03-22 22:28:09,639] A3C_AGENT_WORKER-Thread-18 INFO:Local step 7000, global step 112120: loss 0.0060
[2019-03-22 22:28:09,642] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 7000, global step 112121: learning rate 0.0010
[2019-03-22 22:28:09,650] A3C_AGENT_WORKER-Thread-13 INFO:Local step 7000, global step 112123: loss 0.0055
[2019-03-22 22:28:09,652] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 7000, global step 112124: learning rate 0.0010
[2019-03-22 22:28:09,938] A3C_AGENT_WORKER-Thread-22 INFO:Local step 7000, global step 112236: loss 0.0051
[2019-03-22 22:28:09,942] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 7000, global step 112239: learning rate 0.0010
[2019-03-22 22:28:10,191] A3C_AGENT_WORKER-Thread-20 INFO:Local step 7000, global step 112333: loss 3.0758
[2019-03-22 22:28:10,195] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 7000, global step 112334: learning rate 0.0010
[2019-03-22 22:28:11,143] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.6317757e-32 1.0000000e+00 8.0707275e-26 3.0051716e-14 3.7278115e-25], sum to 1.0000
[2019-03-22 22:28:11,151] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9998
[2019-03-22 22:28:11,158] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.66666666666667, 83.0, 1.0, 2.0, 0.3642760232305241, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 407363.2806871947, 407363.2806871947, 120164.4267844521], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4225200.0000, 
sim time next is 4225800.0000, 
raw observation next is [19.33333333333333, 85.5, 1.0, 2.0, 0.3641662861324884, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 407150.983673771, 407150.983673771, 120114.7412731171], 
processed observation next is [1.0, 0.9130434782608695, 0.5151515151515149, 0.855, 1.0, 1.0, 0.2052078576656105, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1507966606199152, 0.1507966606199152, 0.29296278359296857], 
reward next is 0.7070, 
noisyNet noise sample is [array([-0.2517746], dtype=float32), 0.0022287646]. 
=============================================
[2019-03-22 22:28:14,030] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.1230936e-34 1.0000000e+00 7.0443957e-30 6.1362859e-24 1.6692341e-27], sum to 1.0000
[2019-03-22 22:28:14,039] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8691
[2019-03-22 22:28:14,045] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.66666666666667, 90.50000000000001, 1.0, 2.0, 0.4494370092156947, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 501803.3498673955, 501803.3498673955, 127311.9840802748], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4263000.0000, 
sim time next is 4263600.0000, 
raw observation next is [19.33333333333334, 87.0, 1.0, 2.0, 0.6101100186438727, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 684015.6169695109, 684015.6169695113, 145016.9211424236], 
processed observation next is [1.0, 0.34782608695652173, 0.5151515151515155, 0.87, 1.0, 1.0, 0.5126375233048408, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.25333911739611514, 0.2533391173961153, 0.35369980766444786], 
reward next is 0.6463, 
noisyNet noise sample is [array([0.54382724], dtype=float32), 2.172623]. 
=============================================
[2019-03-22 22:28:14,487] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.4730525e-29 1.0000000e+00 1.9104298e-21 1.9097442e-14 9.5649511e-24], sum to 1.0000
[2019-03-22 22:28:14,497] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1024
[2019-03-22 22:28:14,503] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.66666666666667, 80.0, 1.0, 2.0, 0.7533149192089412, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 849656.9011904761, 849656.9011904761, 165228.8048407145], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4264800.0000, 
sim time next is 4265400.0000, 
raw observation next is [21.33333333333334, 76.5, 1.0, 2.0, 0.7852106982956313, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 887349.087522032, 887349.0875220316, 170598.5347975518], 
processed observation next is [1.0, 0.34782608695652173, 0.6060606060606063, 0.765, 1.0, 1.0, 0.7315133728695391, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.32864781019334516, 0.32864781019334505, 0.416093987311102], 
reward next is 0.5839, 
noisyNet noise sample is [array([0.00783252], dtype=float32), -0.53973067]. 
=============================================
[2019-03-22 22:28:14,619] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.6602118e-25 9.9894589e-01 1.4607258e-18 1.0541643e-03 9.0498567e-16], sum to 1.0000
[2019-03-22 22:28:14,625] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6459
[2019-03-22 22:28:14,631] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.33333333333334, 49.16666666666667, 1.0, 2.0, 0.8234639553108187, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 926099.497715344, 926099.497715344, 173781.8780813472], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4277400.0000, 
sim time next is 4278000.0000, 
raw observation next is [25.66666666666667, 48.33333333333334, 1.0, 2.0, 0.7061304469333003, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 794876.7671065208, 794876.7671065208, 158128.5319669299], 
processed observation next is [1.0, 0.5217391304347826, 0.8030303030303032, 0.48333333333333345, 1.0, 1.0, 0.6326630586666254, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.29439880263204476, 0.29439880263204476, 0.38567934626080463], 
reward next is 0.6143, 
noisyNet noise sample is [array([-1.5977517], dtype=float32), -0.18694393]. 
=============================================
[2019-03-22 22:28:14,646] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[60.12533 ]
 [60.172535]
 [60.249893]
 [59.872017]
 [59.59645 ]], R is [[60.09296799]
 [60.06818008]
 [60.04637909]
 [60.05155182]
 [60.05386353]].
[2019-03-22 22:28:17,199] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.7666862e-35 1.0000000e+00 4.1454993e-31 4.0695870e-30 3.1386178e-32], sum to 1.0000
[2019-03-22 22:28:17,211] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7928
[2019-03-22 22:28:17,216] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.33333333333333, 86.33333333333334, 1.0, 2.0, 0.373699904059857, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 418545.254292322, 418545.2542923223, 121241.4696997538], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4319400.0000, 
sim time next is 4320000.0000, 
raw observation next is [19.0, 88.0, 1.0, 2.0, 0.3694703055992113, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 413133.1807921334, 413133.1807921334, 120576.7722836099], 
processed observation next is [1.0, 0.0, 0.5, 0.88, 1.0, 1.0, 0.2118378819990141, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1530122891822716, 0.1530122891822716, 0.2940896884966095], 
reward next is 0.7059, 
noisyNet noise sample is [array([-1.0414964], dtype=float32), 2.145784]. 
=============================================
[2019-03-22 22:28:17,230] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[68.300285]
 [68.26182 ]
 [68.220825]
 [68.18797 ]
 [68.16122 ]], R is [[67.74163818]
 [67.76851654]
 [67.79362488]
 [67.81716156]
 [67.83916473]].
[2019-03-22 22:28:25,985] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 22:28:25,996] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2325
[2019-03-22 22:28:26,004] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333334, 76.66666666666667, 1.0, 2.0, 0.4551952032457304, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 519183.3614703926, 519183.3614703923, 134958.5873680001], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4440000.0000, 
sim time next is 4440600.0000, 
raw observation next is [23.5, 76.0, 1.0, 2.0, 0.4575455761834382, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 521923.8685967285, 521923.8685967283, 135351.0051755031], 
processed observation next is [0.0, 0.391304347826087, 0.7045454545454546, 0.76, 1.0, 1.0, 0.32193197022929776, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19330513651730685, 0.19330513651730677, 0.3301244028670807], 
reward next is 0.6699, 
noisyNet noise sample is [array([-0.86506015], dtype=float32), 1.1847962]. 
=============================================
[2019-03-22 22:28:27,318] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 22:28:27,331] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8664
[2019-03-22 22:28:27,335] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.33333333333334, 72.66666666666667, 1.0, 2.0, 0.5180331971621116, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 590184.9280608207, 590184.9280608207, 144948.6276026574], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4465200.0000, 
sim time next is 4465800.0000, 
raw observation next is [25.0, 74.0, 1.0, 2.0, 0.5148289267140117, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 586756.4149830873, 586756.4149830873, 144338.029359015], 
processed observation next is [0.0, 0.6956521739130435, 0.7727272727272727, 0.74, 1.0, 1.0, 0.3935361583925146, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21731719073447678, 0.21731719073447678, 0.35204397404637805], 
reward next is 0.6480, 
noisyNet noise sample is [array([0.96631324], dtype=float32), 0.399595]. 
=============================================
[2019-03-22 22:28:28,942] A3C_AGENT_WORKER-Thread-19 INFO:Local step 7500, global step 119704: loss 0.0723
[2019-03-22 22:28:28,943] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 7500, global step 119704: learning rate 0.0010
[2019-03-22 22:28:29,092] A3C_AGENT_WORKER-Thread-21 INFO:Local step 7500, global step 119766: loss 0.0170
[2019-03-22 22:28:29,093] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 7500, global step 119766: learning rate 0.0010
[2019-03-22 22:28:29,115] A3C_AGENT_WORKER-Thread-14 INFO:Local step 7500, global step 119774: loss 0.0072
[2019-03-22 22:28:29,117] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 7500, global step 119774: learning rate 0.0010
[2019-03-22 22:28:29,344] A3C_AGENT_WORKER-Thread-3 INFO:Local step 7500, global step 119862: loss 0.0932
[2019-03-22 22:28:29,347] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 7500, global step 119863: learning rate 0.0010
[2019-03-22 22:28:29,462] A3C_AGENT_WORKER-Thread-11 INFO:Local step 7500, global step 119906: loss 0.0384
[2019-03-22 22:28:29,467] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 7500, global step 119908: learning rate 0.0010
[2019-03-22 22:28:29,499] A3C_AGENT_WORKER-Thread-10 INFO:Local step 7500, global step 119924: loss 0.0283
[2019-03-22 22:28:29,504] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 7500, global step 119924: learning rate 0.0010
[2019-03-22 22:28:29,515] A3C_AGENT_WORKER-Thread-2 INFO:Local step 7500, global step 119930: loss 0.0263
[2019-03-22 22:28:29,520] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 7500, global step 119931: learning rate 0.0010
[2019-03-22 22:28:29,537] A3C_AGENT_WORKER-Thread-9 INFO:Local step 7500, global step 119939: loss 0.0090
[2019-03-22 22:28:29,540] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 7500, global step 119940: learning rate 0.0010
[2019-03-22 22:28:29,609] A3C_AGENT_WORKER-Thread-16 INFO:Local step 7500, global step 119959: loss 0.0070
[2019-03-22 22:28:29,613] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 7500, global step 119963: learning rate 0.0010
[2019-03-22 22:28:29,655] A3C_AGENT_WORKER-Thread-15 INFO:Local step 7500, global step 119979: loss 0.0006
[2019-03-22 22:28:29,658] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 7500, global step 119981: learning rate 0.0010
[2019-03-22 22:28:29,782] A3C_AGENT_WORKER-Thread-17 INFO:Local step 7500, global step 120030: loss 0.0359
[2019-03-22 22:28:29,783] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 7500, global step 120030: learning rate 0.0010
[2019-03-22 22:28:29,934] A3C_AGENT_WORKER-Thread-12 INFO:Local step 7500, global step 120091: loss 0.0243
[2019-03-22 22:28:29,936] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 7500, global step 120092: learning rate 0.0010
[2019-03-22 22:28:29,996] A3C_AGENT_WORKER-Thread-18 INFO:Local step 7500, global step 120115: loss 0.0120
[2019-03-22 22:28:30,000] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 7500, global step 120115: learning rate 0.0010
[2019-03-22 22:28:30,026] A3C_AGENT_WORKER-Thread-13 INFO:Local step 7500, global step 120125: loss 0.0124
[2019-03-22 22:28:30,031] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 7500, global step 120127: learning rate 0.0010
[2019-03-22 22:28:30,491] A3C_AGENT_WORKER-Thread-22 INFO:Local step 7500, global step 120308: loss 0.0359
[2019-03-22 22:28:30,494] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 7500, global step 120308: learning rate 0.0010
[2019-03-22 22:28:30,611] A3C_AGENT_WORKER-Thread-20 INFO:Local step 7500, global step 120354: loss 0.0087
[2019-03-22 22:28:30,614] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 7500, global step 120354: learning rate 0.0010
[2019-03-22 22:28:39,506] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 4.6305607e-35 7.6594823e-33 4.8881449e-34], sum to 1.0000
[2019-03-22 22:28:39,522] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7768
[2019-03-22 22:28:39,528] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 48.5, 1.0, 2.0, 0.6860823231109369, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 754001.5772497415, 754001.5772497418, 148339.5795933605], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4638600.0000, 
sim time next is 4639200.0000, 
raw observation next is [23.33333333333333, 49.0, 1.0, 2.0, 0.6260306497869582, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 686966.6958731554, 686966.6958731554, 141283.0994558597], 
processed observation next is [1.0, 0.6956521739130435, 0.6969696969696968, 0.49, 1.0, 1.0, 0.5325383122336977, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2544321095826501, 0.2544321095826501, 0.3445929255020968], 
reward next is 0.6554, 
noisyNet noise sample is [array([0.03127306], dtype=float32), -0.5921482]. 
=============================================
[2019-03-22 22:28:42,517] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-22 22:28:42,520] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-22 22:28:42,521] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-22 22:28:42,521] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:28:42,523] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:28:42,523] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-22 22:28:42,523] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-22 22:28:42,526] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-22 22:28:42,525] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:28:42,529] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:28:42,529] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:28:42,548] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run6
[2019-03-22 22:28:42,549] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run6
[2019-03-22 22:28:42,549] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run6
[2019-03-22 22:28:42,550] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run6
[2019-03-22 22:28:42,625] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run6
[2019-03-22 22:29:39,479] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.20903338], dtype=float32), -0.1917669]
[2019-03-22 22:29:39,479] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [25.0, 78.0, 1.0, 2.0, 0.5947771498408321, 0.0, 2.0, 0.0, 1.0, 2.0, 0.97857159789892, 6.911199999999999, 6.9112, 77.32846344354104, 1223068.825822633, 1223068.825822633, 278044.6985186926]
[2019-03-22 22:29:39,479] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 22:29:39,481] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.6866134e-33 1.0000000e+00 2.8489798e-26 2.0637311e-12 1.5654909e-24], sampled 0.269886732219886
[2019-03-22 22:29:39,483] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1223068.825822633 W.
[2019-03-22 22:29:44,392] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.20903338], dtype=float32), -0.1917669]
[2019-03-22 22:29:44,392] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.3, 77.0, 1.0, 2.0, 0.3675328094544989, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 410240.7183115649, 410240.7183115646, 124413.9921417805]
[2019-03-22 22:29:44,394] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 22:29:44,397] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 1.096753e-37 0.000000e+00], sampled 0.030779575715789598
[2019-03-22 22:29:55,340] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.20903338], dtype=float32), -0.1917669]
[2019-03-22 22:29:55,342] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [14.79567833333333, 75.93345296000001, 1.0, 2.0, 0.2180109011059182, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 236694.9858729746, 236694.9858729749, 78319.74808138605]
[2019-03-22 22:29:55,343] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 22:29:55,348] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.26431491064036383
[2019-03-22 22:30:02,340] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.20903338], dtype=float32), -0.1917669]
[2019-03-22 22:30:02,341] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.25, 57.33333333333333, 1.0, 2.0, 0.3677837463516258, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 95.55338769695034, 414158.0874868209, 414158.0874868202, 126184.5757579278]
[2019-03-22 22:30:02,343] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 22:30:02,346] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.0000e+00 1.0000e+00 0.0000e+00 8.6428e-38 0.0000e+00], sampled 0.9146165748558345
[2019-03-22 22:30:06,557] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.20903338], dtype=float32), -0.1917669]
[2019-03-22 22:30:06,557] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.2, 88.66666666666667, 1.0, 2.0, 0.3666044076262011, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 411001.6812375383, 411001.681237538, 125160.1922225473]
[2019-03-22 22:30:06,558] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 22:30:06,560] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.8646797e-38 0.0000000e+00], sampled 0.21069552878712494
[2019-03-22 22:30:08,076] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.20903338], dtype=float32), -0.1917669]
[2019-03-22 22:30:08,077] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [26.98333333333333, 51.66666666666666, 1.0, 2.0, 0.4520954682472659, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 514631.824807533, 514631.8248075327, 137571.1255062092]
[2019-03-22 22:30:08,077] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 22:30:08,080] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 1.7395571e-38 5.2966703e-33 1.0003861e-36], sampled 0.3667945341114016
[2019-03-22 22:30:08,490] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.20903338], dtype=float32), -0.1917669]
[2019-03-22 22:30:08,493] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [27.83333333333334, 49.66666666666667, 1.0, 2.0, 0.4387434562475048, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338766425707, 500125.4736766899, 500125.4736766896, 137087.1818697546]
[2019-03-22 22:30:08,495] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 22:30:08,498] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0.0000000e+00 1.0000000e+00 4.1843344e-36 1.5433535e-27 1.7787705e-33], sampled 0.3748406221186309
[2019-03-22 22:30:10,990] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.20903338], dtype=float32), -0.1917669]
[2019-03-22 22:30:10,990] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.5, 66.0, 1.0, 2.0, 0.2931058704400538, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 318247.3688167782, 318247.3688167782, 107432.6659027897]
[2019-03-22 22:30:10,992] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 22:30:10,995] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.2043586e-38 0.0000000e+00], sampled 0.4877343973449483
[2019-03-22 22:30:23,282] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.20903338], dtype=float32), -0.1917669]
[2019-03-22 22:30:23,284] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.53333333333333, 84.66666666666667, 1.0, 2.0, 0.4047590227756183, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 457751.1879324687, 457751.1879324687, 130536.9911187448]
[2019-03-22 22:30:23,285] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 22:30:23,287] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.8976077e-36 1.5251608e-38], sampled 0.781462360946322
[2019-03-22 22:30:34,851] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.20903338], dtype=float32), -0.1917669]
[2019-03-22 22:30:34,852] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.31666666666667, 40.66666666666667, 1.0, 2.0, 0.3514916404392553, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 381661.3765092632, 381661.3765092632, 105775.5333012849]
[2019-03-22 22:30:34,853] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 22:30:34,855] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.8605369e-37 0.0000000e+00], sampled 0.5012053071996374
[2019-03-22 22:30:45,818] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5598 1663796639.0689 105.0000
[2019-03-22 22:30:45,951] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2492 1773187030.7201 173.0000
[2019-03-22 22:30:46,046] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1147 1656209757.7786 80.0000
[2019-03-22 22:30:46,119] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9309 1705967916.6745 465.0000
[2019-03-22 22:30:46,138] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3486 1683344882.4587 214.0000
[2019-03-22 22:30:47,153] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 125000, evaluation results [125000.0, 8512.249193409023, 1773187030.7201214, 173.0, 9061.114669779829, 1656209757.7786272, 80.0, 8856.559759326878, 1663796639.0688558, 105.0, 8596.930884973775, 1705967916.6744611, 465.0, 8574.348638023737, 1683344882.4586744, 214.0]
[2019-03-22 22:30:50,210] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.3579098e-37 1.0000000e+00 1.4693678e-34 8.5597830e-24 4.5804219e-27], sum to 1.0000
[2019-03-22 22:30:50,219] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0688
[2019-03-22 22:30:50,225] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333333, 77.16666666666666, 1.0, 2.0, 0.3988258622279365, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 450580.7021191473, 450580.7021191471, 125384.8336583239], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4740600.0000, 
sim time next is 4741200.0000, 
raw observation next is [21.0, 78.0, 1.0, 2.0, 0.3926610253617681, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 442744.5239819146, 442744.5239819146, 124333.6988661375], 
processed observation next is [1.0, 0.9130434782608695, 0.5909090909090909, 0.78, 1.0, 1.0, 0.24082628170221013, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16397945332663505, 0.16397945332663505, 0.30325292406375004], 
reward next is 0.6967, 
noisyNet noise sample is [array([-0.56660247], dtype=float32), -0.702557]. 
=============================================
[2019-03-22 22:30:51,189] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.0139173e-36 5.4788248e-28 7.1012326e-33], sum to 1.0000
[2019-03-22 22:30:51,201] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6169
[2019-03-22 22:30:51,206] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 83.0, 1.0, 2.0, 0.3746679383776181, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 420682.4972960377, 420682.497296038, 121825.7935257942], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4749600.0000, 
sim time next is 4750200.0000, 
raw observation next is [20.0, 83.0, 1.0, 2.0, 0.3743948593897641, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 420372.9200172487, 420372.920017249, 121801.0573494533], 
processed observation next is [1.0, 1.0, 0.5454545454545454, 0.83, 1.0, 1.0, 0.21799357423720508, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1556936740804625, 0.15569367408046259, 0.2970757496328129], 
reward next is 0.7029, 
noisyNet noise sample is [array([0.38140833], dtype=float32), 1.2253518]. 
=============================================
[2019-03-22 22:30:54,012] A3C_AGENT_WORKER-Thread-19 INFO:Local step 8000, global step 127692: loss 0.2254
[2019-03-22 22:30:54,019] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 8000, global step 127695: learning rate 0.0010
[2019-03-22 22:30:54,198] A3C_AGENT_WORKER-Thread-21 INFO:Local step 8000, global step 127761: loss 0.2106
[2019-03-22 22:30:54,202] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 8000, global step 127761: learning rate 0.0010
[2019-03-22 22:30:54,248] A3C_AGENT_WORKER-Thread-14 INFO:Local step 8000, global step 127781: loss 0.2069
[2019-03-22 22:30:54,251] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 8000, global step 127782: learning rate 0.0010
[2019-03-22 22:30:54,518] A3C_AGENT_WORKER-Thread-11 INFO:Local step 8000, global step 127884: loss 0.5489
[2019-03-22 22:30:54,520] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 8000, global step 127884: learning rate 0.0010
[2019-03-22 22:30:54,539] A3C_AGENT_WORKER-Thread-3 INFO:Local step 8000, global step 127892: loss 0.4772
[2019-03-22 22:30:54,542] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 8000, global step 127893: learning rate 0.0010
[2019-03-22 22:30:54,570] A3C_AGENT_WORKER-Thread-9 INFO:Local step 8000, global step 127901: loss 0.3623
[2019-03-22 22:30:54,572] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 8000, global step 127901: learning rate 0.0010
[2019-03-22 22:30:54,595] A3C_AGENT_WORKER-Thread-10 INFO:Local step 8000, global step 127913: loss 0.6437
[2019-03-22 22:30:54,597] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 8000, global step 127914: learning rate 0.0010
[2019-03-22 22:30:54,622] A3C_AGENT_WORKER-Thread-2 INFO:Local step 8000, global step 127922: loss 0.4082
[2019-03-22 22:30:54,628] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 8000, global step 127924: learning rate 0.0010
[2019-03-22 22:30:54,734] A3C_AGENT_WORKER-Thread-16 INFO:Local step 8000, global step 127967: loss 0.6538
[2019-03-22 22:30:54,735] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 8000, global step 127967: learning rate 0.0010
[2019-03-22 22:30:54,800] A3C_AGENT_WORKER-Thread-15 INFO:Local step 8000, global step 127988: loss 0.8300
[2019-03-22 22:30:54,803] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 8000, global step 127988: learning rate 0.0010
[2019-03-22 22:30:54,896] A3C_AGENT_WORKER-Thread-17 INFO:Local step 8000, global step 128029: loss 1.3838
[2019-03-22 22:30:54,901] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 8000, global step 128030: learning rate 0.0010
[2019-03-22 22:30:54,967] A3C_AGENT_WORKER-Thread-12 INFO:Local step 8000, global step 128055: loss 1.3805
[2019-03-22 22:30:54,970] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 8000, global step 128056: learning rate 0.0010
[2019-03-22 22:30:55,011] A3C_AGENT_WORKER-Thread-13 INFO:Local step 8000, global step 128071: loss 2.2795
[2019-03-22 22:30:55,013] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 8000, global step 128071: learning rate 0.0010
[2019-03-22 22:30:55,283] A3C_AGENT_WORKER-Thread-18 INFO:Local step 8000, global step 128175: loss 0.4286
[2019-03-22 22:30:55,285] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 8000, global step 128176: learning rate 0.0010
[2019-03-22 22:30:55,546] A3C_AGENT_WORKER-Thread-22 INFO:Local step 8000, global step 128275: loss 0.3833
[2019-03-22 22:30:55,550] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 8000, global step 128276: learning rate 0.0010
[2019-03-22 22:30:55,887] A3C_AGENT_WORKER-Thread-20 INFO:Local step 8000, global step 128409: loss 0.6391
[2019-03-22 22:30:55,890] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 8000, global step 128410: learning rate 0.0010
[2019-03-22 22:31:07,760] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.2017289e-33 1.0000000e+00 1.1533150e-35 1.4300668e-19 1.0775331e-27], sum to 1.0000
[2019-03-22 22:31:07,774] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2901
[2019-03-22 22:31:07,780] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.5, 77.5, 1.0, 2.0, 0.2806725808253456, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 304762.3877889157, 304762.3877889159, 95609.21051519265], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4998600.0000, 
sim time next is 4999200.0000, 
raw observation next is [17.33333333333333, 79.0, 1.0, 2.0, 0.2814307607021613, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 305585.9000288247, 305585.9000288244, 95915.65884235923], 
processed observation next is [1.0, 0.8695652173913043, 0.42424242424242403, 0.79, 1.0, 1.0, 0.10178845087770158, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11317996297363878, 0.11317996297363866, 0.23394063132282739], 
reward next is 0.7661, 
noisyNet noise sample is [array([-0.6587267], dtype=float32), 0.78361124]. 
=============================================
[2019-03-22 22:31:08,051] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.5516066e-28 1.0000000e+00 4.9089177e-29 4.6329831e-08 9.7369999e-21], sum to 1.0000
[2019-03-22 22:31:08,059] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1222
[2019-03-22 22:31:08,064] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 61.33333333333334, 1.0, 2.0, 0.2841714861711744, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 308562.8054544231, 308562.8054544228, 99303.53796131328], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4988400.0000, 
sim time next is 4989000.0000, 
raw observation next is [20.0, 60.66666666666666, 1.0, 2.0, 0.2837466399189732, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 308101.3472024469, 308101.3472024472, 97916.76415726473], 
processed observation next is [1.0, 0.7391304347826086, 0.5454545454545454, 0.6066666666666666, 1.0, 1.0, 0.10468329989871648, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11411161007498033, 0.11411161007498044, 0.2388213759933286], 
reward next is 0.7612, 
noisyNet noise sample is [array([-0.42489797], dtype=float32), 1.0115504]. 
=============================================
[2019-03-22 22:31:08,078] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[68.47797 ]
 [68.45247 ]
 [68.28476 ]
 [67.916145]
 [67.52496 ]], R is [[68.50891876]
 [68.58162689]
 [68.64928436]
 [68.7073822 ]
 [68.73750305]].
[2019-03-22 22:31:08,110] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.4254807e-27 1.0000000e+00 2.9357950e-27 4.6200083e-13 5.3771058e-18], sum to 1.0000
[2019-03-22 22:31:08,120] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2204
[2019-03-22 22:31:08,128] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.66666666666667, 69.66666666666667, 1.0, 2.0, 0.2819896484291571, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 306192.9480063909, 306192.9480063906, 97510.21112873477], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4994400.0000, 
sim time next is 4995000.0000, 
raw observation next is [18.5, 70.5, 1.0, 2.0, 0.2800564649246914, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 304093.1822056074, 304093.1822056074, 96639.38729623515], 
processed observation next is [1.0, 0.8260869565217391, 0.4772727272727273, 0.705, 1.0, 1.0, 0.10007058115586422, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11262710452059534, 0.11262710452059534, 0.23570582267374426], 
reward next is 0.7643, 
noisyNet noise sample is [array([-0.5907402], dtype=float32), -0.59337604]. 
=============================================
[2019-03-22 22:31:08,156] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[68.88269 ]
 [68.98238 ]
 [69.093925]
 [69.19145 ]
 [69.32106 ]], R is [[68.84867096]
 [68.92235565]
 [68.99329376]
 [69.06173706]
 [69.1302948 ]].
[2019-03-22 22:31:14,579] A3C_AGENT_WORKER-Thread-19 INFO:Local step 8500, global step 135738: loss 0.2116
[2019-03-22 22:31:14,582] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 8500, global step 135738: learning rate 0.0010
[2019-03-22 22:31:14,635] A3C_AGENT_WORKER-Thread-21 INFO:Local step 8500, global step 135759: loss 0.1262
[2019-03-22 22:31:14,638] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 8500, global step 135759: learning rate 0.0010
[2019-03-22 22:31:14,648] A3C_AGENT_WORKER-Thread-14 INFO:Local step 8500, global step 135761: loss 0.1421
[2019-03-22 22:31:14,655] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 8500, global step 135762: learning rate 0.0010
[2019-03-22 22:31:14,794] A3C_AGENT_WORKER-Thread-3 INFO:Local step 8500, global step 135819: loss 0.1520
[2019-03-22 22:31:14,798] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 8500, global step 135820: learning rate 0.0010
[2019-03-22 22:31:14,941] A3C_AGENT_WORKER-Thread-10 INFO:Local step 8500, global step 135876: loss 0.1365
[2019-03-22 22:31:14,943] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 8500, global step 135876: learning rate 0.0010
[2019-03-22 22:31:14,977] A3C_AGENT_WORKER-Thread-9 INFO:Local step 8500, global step 135889: loss 0.1511
[2019-03-22 22:31:14,979] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 8500, global step 135890: learning rate 0.0010
[2019-03-22 22:31:14,999] A3C_AGENT_WORKER-Thread-11 INFO:Local step 8500, global step 135899: loss 0.2614
[2019-03-22 22:31:15,004] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 8500, global step 135900: learning rate 0.0010
[2019-03-22 22:31:15,111] A3C_AGENT_WORKER-Thread-2 INFO:Local step 8500, global step 135942: loss 0.3381
[2019-03-22 22:31:15,114] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 8500, global step 135942: learning rate 0.0010
[2019-03-22 22:31:15,125] A3C_AGENT_WORKER-Thread-16 INFO:Local step 8500, global step 135947: loss 0.4617
[2019-03-22 22:31:15,127] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 8500, global step 135947: learning rate 0.0010
[2019-03-22 22:31:15,352] A3C_AGENT_WORKER-Thread-15 INFO:Local step 8500, global step 136035: loss 0.3273
[2019-03-22 22:31:15,356] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 8500, global step 136036: learning rate 0.0010
[2019-03-22 22:31:15,357] A3C_AGENT_WORKER-Thread-17 INFO:Local step 8500, global step 136036: loss 0.2299
[2019-03-22 22:31:15,367] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 8500, global step 136036: learning rate 0.0010
[2019-03-22 22:31:15,439] A3C_AGENT_WORKER-Thread-12 INFO:Local step 8500, global step 136067: loss 0.2540
[2019-03-22 22:31:15,442] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 8500, global step 136068: learning rate 0.0010
[2019-03-22 22:31:15,652] A3C_AGENT_WORKER-Thread-13 INFO:Local step 8500, global step 136150: loss 0.1089
[2019-03-22 22:31:15,654] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 8500, global step 136150: learning rate 0.0010
[2019-03-22 22:31:15,696] A3C_AGENT_WORKER-Thread-18 INFO:Local step 8500, global step 136165: loss 0.0767
[2019-03-22 22:31:15,701] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 8500, global step 136166: learning rate 0.0010
[2019-03-22 22:31:16,045] A3C_AGENT_WORKER-Thread-22 INFO:Local step 8500, global step 136304: loss 0.2770
[2019-03-22 22:31:16,047] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 8500, global step 136305: learning rate 0.0010
[2019-03-22 22:31:16,295] A3C_AGENT_WORKER-Thread-20 INFO:Local step 8500, global step 136401: loss 0.1553
[2019-03-22 22:31:16,297] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 8500, global step 136401: learning rate 0.0010
[2019-03-22 22:31:23,388] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.1072889e-26 9.9999809e-01 9.2236125e-20 1.9421050e-06 2.0445419e-15], sum to 1.0000
[2019-03-22 22:31:23,403] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7900
[2019-03-22 22:31:23,409] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 98.0, 1.0, 2.0, 0.8126797464545317, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 927692.6933182242, 927692.6933182242, 184310.1183163085], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5223000.0000, 
sim time next is 5223600.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.8308143683906011, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 948240.7515010262, 948240.7515010262, 188126.5201181379], 
processed observation next is [1.0, 0.4782608695652174, 0.5909090909090909, 1.0, 1.0, 1.0, 0.7885179604882514, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3512002783337134, 0.3512002783337134, 0.45884517101984856], 
reward next is 0.5412, 
noisyNet noise sample is [array([0.3992383], dtype=float32), 0.6095725]. 
=============================================
[2019-03-22 22:31:35,113] A3C_AGENT_WORKER-Thread-21 INFO:Local step 9000, global step 143780: loss 57.5460
[2019-03-22 22:31:35,116] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 9000, global step 143780: learning rate 0.0010
[2019-03-22 22:31:35,171] A3C_AGENT_WORKER-Thread-19 INFO:Local step 9000, global step 143805: loss 6.2768
[2019-03-22 22:31:35,173] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 9000, global step 143805: learning rate 0.0010
[2019-03-22 22:31:35,192] A3C_AGENT_WORKER-Thread-3 INFO:Local step 9000, global step 143811: loss -65.4788
[2019-03-22 22:31:35,197] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 9000, global step 143811: learning rate 0.0010
[2019-03-22 22:31:35,237] A3C_AGENT_WORKER-Thread-14 INFO:Local step 9000, global step 143823: loss -48.7545
[2019-03-22 22:31:35,239] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 9000, global step 143823: learning rate 0.0010
[2019-03-22 22:31:35,417] A3C_AGENT_WORKER-Thread-9 INFO:Local step 9000, global step 143896: loss 74.8527
[2019-03-22 22:31:35,419] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 9000, global step 143896: learning rate 0.0010
[2019-03-22 22:31:35,464] A3C_AGENT_WORKER-Thread-10 INFO:Local step 9000, global step 143907: loss 190.2143
[2019-03-22 22:31:35,467] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 9000, global step 143908: learning rate 0.0010
[2019-03-22 22:31:35,475] A3C_AGENT_WORKER-Thread-11 INFO:Local step 9000, global step 143911: loss 1.1318
[2019-03-22 22:31:35,479] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 9000, global step 143911: learning rate 0.0010
[2019-03-22 22:31:35,539] A3C_AGENT_WORKER-Thread-2 INFO:Local step 9000, global step 143940: loss 138.0606
[2019-03-22 22:31:35,541] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 9000, global step 143940: learning rate 0.0010
[2019-03-22 22:31:35,641] A3C_AGENT_WORKER-Thread-16 INFO:Local step 9000, global step 143976: loss 39.5728
[2019-03-22 22:31:35,643] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 9000, global step 143976: learning rate 0.0010
[2019-03-22 22:31:35,787] A3C_AGENT_WORKER-Thread-17 INFO:Local step 9000, global step 144036: loss 37.3252
[2019-03-22 22:31:35,789] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 9000, global step 144037: learning rate 0.0010
[2019-03-22 22:31:35,835] A3C_AGENT_WORKER-Thread-15 INFO:Local step 9000, global step 144054: loss 77.5164
[2019-03-22 22:31:35,838] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 9000, global step 144054: learning rate 0.0010
[2019-03-22 22:31:35,876] A3C_AGENT_WORKER-Thread-13 INFO:Local step 9000, global step 144068: loss 78.0087
[2019-03-22 22:31:35,877] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 9000, global step 144068: learning rate 0.0010
[2019-03-22 22:31:35,900] A3C_AGENT_WORKER-Thread-12 INFO:Local step 9000, global step 144075: loss 120.9095
[2019-03-22 22:31:35,903] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 9000, global step 144075: learning rate 0.0010
[2019-03-22 22:31:35,992] A3C_AGENT_WORKER-Thread-18 INFO:Local step 9000, global step 144112: loss 48.8204
[2019-03-22 22:31:35,995] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 9000, global step 144113: learning rate 0.0010
[2019-03-22 22:31:36,385] A3C_AGENT_WORKER-Thread-22 INFO:Local step 9000, global step 144265: loss -4.1654
[2019-03-22 22:31:36,388] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 9000, global step 144265: learning rate 0.0010
[2019-03-22 22:31:36,557] A3C_AGENT_WORKER-Thread-20 INFO:Local step 9000, global step 144330: loss 1.8115
[2019-03-22 22:31:36,559] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 9000, global step 144330: learning rate 0.0010
[2019-03-22 22:31:42,679] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.8029881e-27 1.0000000e+00 1.8005108e-29 1.1949966e-21 2.9792180e-20], sum to 1.0000
[2019-03-22 22:31:42,686] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2666
[2019-03-22 22:31:42,691] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.33333333333334, 61.0, 1.0, 2.0, 0.5013643930264776, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 571215.1654239085, 571215.1654239087, 142923.1076176438], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5506800.0000, 
sim time next is 5507400.0000, 
raw observation next is [27.51666666666667, 59.0, 1.0, 2.0, 0.4987478849266387, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 568553.0146244733, 568553.0146244733, 142271.1017772068], 
processed observation next is [1.0, 0.7391304347826086, 0.8871212121212122, 0.59, 1.0, 1.0, 0.3734348561582983, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21057519060165678, 0.21057519060165678, 0.34700268726148], 
reward next is 0.6530, 
noisyNet noise sample is [array([1.3925614], dtype=float32), 0.21793787]. 
=============================================
[2019-03-22 22:31:43,202] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.8867038e-31 1.0000000e+00 4.9314240e-28 7.2575528e-18 1.7692926e-22], sum to 1.0000
[2019-03-22 22:31:43,212] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0088
[2019-03-22 22:31:43,219] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.51666666666667, 59.0, 1.0, 2.0, 0.4987478865765455, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 568553.0146243977, 568553.0146243977, 142271.1042527954], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5507400.0000, 
sim time next is 5508000.0000, 
raw observation next is [27.7, 57.0, 1.0, 2.0, 0.4952167910257668, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 564781.6115448138, 564781.6115448138, 141493.1302258556], 
processed observation next is [1.0, 0.782608695652174, 0.8954545454545454, 0.57, 1.0, 1.0, 0.3690209887822085, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20917837464622735, 0.20917837464622735, 0.3451051956728185], 
reward next is 0.6549, 
noisyNet noise sample is [array([0.7781016], dtype=float32), 0.5957632]. 
=============================================
[2019-03-22 22:31:43,233] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[52.290096]
 [52.586163]
 [52.383797]
 [52.137375]
 [50.899624]], R is [[52.13286209]
 [52.26453018]
 [52.39329147]
 [52.51958466]
 [52.633564  ]].
[2019-03-22 22:31:45,720] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.2616506e-32 1.0000000e+00 1.2542264e-33 1.3777674e-24 2.3562021e-24], sum to 1.0000
[2019-03-22 22:31:45,732] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2773
[2019-03-22 22:31:45,740] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333334, 91.0, 1.0, 2.0, 0.4132946168885536, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 469408.0894266563, 469408.0894266563, 128367.4871523724], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5550000.0000, 
sim time next is 5550600.0000, 
raw observation next is [20.41666666666667, 90.5, 1.0, 2.0, 0.4133341685823857, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 469515.4178417821, 469515.4178417821, 128421.0199026589], 
processed observation next is [1.0, 0.21739130434782608, 0.5643939393939396, 0.905, 1.0, 1.0, 0.26666771072798207, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17389459920066003, 0.17389459920066003, 0.3132219997625827], 
reward next is 0.6868, 
noisyNet noise sample is [array([-1.7608397], dtype=float32), 1.1558642]. 
=============================================
[2019-03-22 22:31:51,052] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-22 22:31:51,056] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-22 22:31:51,059] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-22 22:31:51,060] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:31:51,061] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:31:51,062] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-22 22:31:51,064] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-22 22:31:51,064] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-22 22:31:51,067] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:31:51,069] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:31:51,067] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:31:51,088] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run7
[2019-03-22 22:31:51,090] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run7
[2019-03-22 22:31:51,107] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run7
[2019-03-22 22:31:51,108] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run7
[2019-03-22 22:31:51,161] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run7
[2019-03-22 22:32:01,847] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.24844056], dtype=float32), -0.21414198]
[2019-03-22 22:32:01,850] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [24.33333333333333, 54.66666666666667, 1.0, 2.0, 0.8184914555975605, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 921636.0766143061, 921636.0766143061, 173628.6547596423]
[2019-03-22 22:32:01,851] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 22:32:01,853] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.7492870e-29 1.0000000e+00 9.2537958e-28 9.1331438e-23 1.9916203e-17], sampled 0.4636439814142488
[2019-03-22 22:32:32,222] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.24844056], dtype=float32), -0.21414198]
[2019-03-22 22:32:32,224] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [17.59975286, 73.24372809, 1.0, 2.0, 0.2703056190942338, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 293485.3548641718, 293485.3548641718, 94557.85658961296]
[2019-03-22 22:32:32,224] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 22:32:32,227] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.8891216e-38 1.0000000e+00 0.0000000e+00 3.4146704e-37 1.0060991e-30], sampled 0.3383213891787249
[2019-03-22 22:32:46,870] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.24844056], dtype=float32), -0.21414198]
[2019-03-22 22:32:46,871] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.08333333333334, 86.33333333333334, 1.0, 2.0, 0.4396494667081988, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 499814.1341885441, 499814.1341885438, 135678.7000928717]
[2019-03-22 22:32:46,874] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 22:32:46,879] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.4125521e-35 1.0000000e+00 1.2089641e-34 1.2348822e-30 6.1730527e-24], sampled 0.8598981101505827
[2019-03-22 22:33:04,412] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.24844056], dtype=float32), -0.21414198]
[2019-03-22 22:33:04,412] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.94363588, 40.81314385, 1.0, 2.0, 0.4132506032785764, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 448746.3633039282, 448746.3633039278, 110285.4109234841]
[2019-03-22 22:33:04,412] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 22:33:04,417] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.5386529e-34 1.0000000e+00 1.5372263e-33 3.8007753e-30 1.7682324e-23], sampled 0.3144684040577803
[2019-03-22 22:33:39,048] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.24844056], dtype=float32), -0.21414198]
[2019-03-22 22:33:39,048] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [16.78333333333333, 90.5, 1.0, 2.0, 0.3091451968281812, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 335667.3505466122, 335667.3505466118, 116114.2383243489]
[2019-03-22 22:33:39,048] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 22:33:39,049] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.7717535e-37 1.0000000e+00 4.9133941e-37 2.0644874e-34 1.3620671e-27], sampled 0.6179710560431163
[2019-03-22 22:33:54,720] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2263 1772922583.1357 173.0000
[2019-03-22 22:33:54,985] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5896 1663766061.8834 105.0000
[2019-03-22 22:33:55,009] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9309 1705967916.6745 465.0000
[2019-03-22 22:33:55,231] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.9846 1683160853.8638 213.0000
[2019-03-22 22:33:55,259] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-22 22:33:56,273] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 150000, evaluation results [150000.0, 8512.226270214534, 1772922583.1357026, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8856.58956291602, 1663766061.8834455, 105.0, 8596.930884973775, 1705967916.6744611, 465.0, 8574.984562583924, 1683160853.8637543, 213.0]
[2019-03-22 22:33:56,700] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 4.685604e-37 4.517244e-34 5.174948e-30], sum to 1.0000
[2019-03-22 22:33:56,706] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0031
[2019-03-22 22:33:56,716] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.1, 99.5, 1.0, 2.0, 0.3481332337755834, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 385871.8532915084, 385871.8532915084, 117374.2371228994], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5641800.0000, 
sim time next is 5642400.0000, 
raw observation next is [17.0, 99.0, 1.0, 2.0, 0.3444215965631068, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 380823.3200114635, 380823.3200114632, 116715.8507654641], 
processed observation next is [0.0, 0.30434782608695654, 0.4090909090909091, 0.99, 1.0, 1.0, 0.18052699570388345, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1410456740783198, 0.1410456740783197, 0.28467280674503437], 
reward next is 0.7153, 
noisyNet noise sample is [array([0.59432334], dtype=float32), -0.22449847]. 
=============================================
[2019-03-22 22:33:59,612] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.6962322e-38 1.0000000e+00 0.0000000e+00 1.7823101e-32 1.5732484e-33], sum to 1.0000
[2019-03-22 22:33:59,619] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5282
[2019-03-22 22:33:59,625] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.5, 76.5, 1.0, 2.0, 0.2128307895924549, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 231080.3132566185, 231080.3132566188, 75100.36366147973], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5675400.0000, 
sim time next is 5676000.0000, 
raw observation next is [15.5, 76.0, 1.0, 2.0, 0.2120931116649998, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 230279.1923342038, 230279.1923342041, 74852.58385029194], 
processed observation next is [0.0, 0.6956521739130435, 0.3409090909090909, 0.76, 1.0, 1.0, 0.015116389581249744, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08528858975340882, 0.08528858975340893, 0.18256727768363887], 
reward next is 0.8174, 
noisyNet noise sample is [array([-0.35416827], dtype=float32), 0.22292791]. 
=============================================
[2019-03-22 22:33:59,641] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[77.22579]
 [77.28317]
 [77.32515]
 [77.35579]
 [77.36571]], R is [[77.21867371]
 [77.26331329]
 [77.30703735]
 [77.35002899]
 [77.39226532]].
[2019-03-22 22:34:00,640] A3C_AGENT_WORKER-Thread-21 INFO:Local step 9500, global step 151707: loss 8.2759
[2019-03-22 22:34:00,650] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 9500, global step 151708: learning rate 0.0010
[2019-03-22 22:34:00,786] A3C_AGENT_WORKER-Thread-19 INFO:Local step 9500, global step 151761: loss 8.3514
[2019-03-22 22:34:00,789] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 9500, global step 151761: learning rate 0.0010
[2019-03-22 22:34:00,913] A3C_AGENT_WORKER-Thread-3 INFO:Local step 9500, global step 151813: loss 7.5103
[2019-03-22 22:34:00,914] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 9500, global step 151813: learning rate 0.0010
[2019-03-22 22:34:01,021] A3C_AGENT_WORKER-Thread-14 INFO:Local step 9500, global step 151853: loss 7.2614
[2019-03-22 22:34:01,022] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 9500, global step 151853: learning rate 0.0010
[2019-03-22 22:34:01,103] A3C_AGENT_WORKER-Thread-11 INFO:Local step 9500, global step 151883: loss 6.6786
[2019-03-22 22:34:01,106] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 9500, global step 151884: learning rate 0.0010
[2019-03-22 22:34:01,238] A3C_AGENT_WORKER-Thread-9 INFO:Local step 9500, global step 151936: loss 6.5150
[2019-03-22 22:34:01,241] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 9500, global step 151936: learning rate 0.0010
[2019-03-22 22:34:01,293] A3C_AGENT_WORKER-Thread-16 INFO:Local step 9500, global step 151956: loss 6.6200
[2019-03-22 22:34:01,296] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 9500, global step 151956: learning rate 0.0010
[2019-03-22 22:34:01,310] A3C_AGENT_WORKER-Thread-2 INFO:Local step 9500, global step 151961: loss 6.2791
[2019-03-22 22:34:01,318] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 9500, global step 151963: learning rate 0.0010
[2019-03-22 22:34:01,356] A3C_AGENT_WORKER-Thread-10 INFO:Local step 9500, global step 151976: loss 6.0690
[2019-03-22 22:34:01,360] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 9500, global step 151976: learning rate 0.0010
[2019-03-22 22:34:01,441] A3C_AGENT_WORKER-Thread-17 INFO:Local step 9500, global step 152013: loss 5.8113
[2019-03-22 22:34:01,443] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 9500, global step 152013: learning rate 0.0010
[2019-03-22 22:34:01,572] A3C_AGENT_WORKER-Thread-13 INFO:Local step 9500, global step 152063: loss 5.0605
[2019-03-22 22:34:01,574] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 9500, global step 152063: learning rate 0.0010
[2019-03-22 22:34:01,621] A3C_AGENT_WORKER-Thread-15 INFO:Local step 9500, global step 152083: loss 5.0047
[2019-03-22 22:34:01,625] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 9500, global step 152084: learning rate 0.0010
[2019-03-22 22:34:01,678] A3C_AGENT_WORKER-Thread-12 INFO:Local step 9500, global step 152109: loss 4.4060
[2019-03-22 22:34:01,682] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 9500, global step 152109: learning rate 0.0010
[2019-03-22 22:34:01,741] A3C_AGENT_WORKER-Thread-18 INFO:Local step 9500, global step 152133: loss 4.5212
[2019-03-22 22:34:01,743] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 9500, global step 152133: learning rate 0.0010
[2019-03-22 22:34:01,996] A3C_AGENT_WORKER-Thread-22 INFO:Local step 9500, global step 152234: loss 3.0207
[2019-03-22 22:34:01,999] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 9500, global step 152234: learning rate 0.0010
[2019-03-22 22:34:02,182] A3C_AGENT_WORKER-Thread-20 INFO:Local step 9500, global step 152304: loss 1.2275
[2019-03-22 22:34:02,185] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 9500, global step 152305: learning rate 0.0010
[2019-03-22 22:34:03,413] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.8180011e-20 1.0000000e+00 6.6612343e-23 3.7118816e-22 5.2628169e-17], sum to 1.0000
[2019-03-22 22:34:03,424] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2878
[2019-03-22 22:34:03,428] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [9.200000000000001, 87.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 135966.7805900251, 135966.7805900248, 56021.77953916509], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5718000.0000, 
sim time next is 5718600.0000, 
raw observation next is [9.100000000000001, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 134505.1939309605, 134505.1939309608, 55841.02184192377], 
processed observation next is [0.0, 0.17391304347826086, 0.050000000000000065, 0.88, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.049816738492948334, 0.04981673849294845, 0.13619761424859456], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.57811564], dtype=float32), -0.29920596]. 
=============================================
[2019-03-22 22:34:05,711] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.5996678e-38 1.0000000e+00 3.6542062e-31 1.2378375e-18 4.2668002e-20], sum to 1.0000
[2019-03-22 22:34:05,720] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2428
[2019-03-22 22:34:05,726] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.83333333333334, 56.0, 1.0, 2.0, 0.2450528602968915, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 266074.8873714529, 266074.8873714526, 80480.8286805382], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5772000.0000, 
sim time next is 5772600.0000, 
raw observation next is [18.0, 59.5, 1.0, 2.0, 0.2371524130926898, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 257494.4241456849, 257494.4241456849, 78563.50410578282], 
processed observation next is [0.0, 0.8260869565217391, 0.45454545454545453, 0.595, 1.0, 1.0, 0.046440516365862244, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09536830523914255, 0.09536830523914255, 0.19161830269703126], 
reward next is 0.8084, 
noisyNet noise sample is [array([-0.45038274], dtype=float32), 0.47224492]. 
=============================================
[2019-03-22 22:34:13,055] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.2622147e-38 1.0000000e+00 1.4676425e-34 2.3427596e-23 4.4444269e-20], sum to 1.0000
[2019-03-22 22:34:13,066] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8602
[2019-03-22 22:34:13,072] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.55, 69.5, 1.0, 2.0, 0.327586895629065, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 361357.4710936822, 361357.4710936819, 115110.9246722401], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5869800.0000, 
sim time next is 5870400.0000, 
raw observation next is [20.36666666666667, 70.66666666666667, 1.0, 2.0, 0.3274554047841684, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 361133.5251837183, 361133.5251837183, 115070.6619871107], 
processed observation next is [1.0, 0.9565217391304348, 0.5621212121212124, 0.7066666666666667, 1.0, 1.0, 0.1593192559802105, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13375315747545122, 0.13375315747545122, 0.28066015118807486], 
reward next is 0.7193, 
noisyNet noise sample is [array([0.5529118], dtype=float32), 2.0959098]. 
=============================================
[2019-03-22 22:34:21,122] A3C_AGENT_WORKER-Thread-21 INFO:Local step 10000, global step 159733: loss 0.5445
[2019-03-22 22:34:21,126] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 10000, global step 159733: learning rate 0.0010
[2019-03-22 22:34:21,185] A3C_AGENT_WORKER-Thread-19 INFO:Local step 10000, global step 159753: loss 0.7561
[2019-03-22 22:34:21,189] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 10000, global step 159753: learning rate 0.0010
[2019-03-22 22:34:21,322] A3C_AGENT_WORKER-Thread-3 INFO:Local step 10000, global step 159801: loss 0.6574
[2019-03-22 22:34:21,324] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 10000, global step 159802: learning rate 0.0010
[2019-03-22 22:34:21,445] A3C_AGENT_WORKER-Thread-14 INFO:Local step 10000, global step 159852: loss 0.6442
[2019-03-22 22:34:21,448] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 10000, global step 159852: learning rate 0.0010
[2019-03-22 22:34:21,594] A3C_AGENT_WORKER-Thread-11 INFO:Local step 10000, global step 159906: loss 0.6579
[2019-03-22 22:34:21,600] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 10000, global step 159907: learning rate 0.0010
[2019-03-22 22:34:21,632] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.9945988e-34 1.0000000e+00 6.5053819e-25 7.0928290e-21 2.6719415e-26], sum to 1.0000
[2019-03-22 22:34:21,640] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9102
[2019-03-22 22:34:21,648] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.6, 71.0, 1.0, 2.0, 0.7057313621439792, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 793614.7219912338, 793614.721991234, 157683.2358871978], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5994000.0000, 
sim time next is 5994600.0000, 
raw observation next is [21.88333333333334, 70.16666666666667, 1.0, 2.0, 0.8066620956301606, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 908669.5095606619, 908669.5095606619, 172111.9295485898], 
processed observation next is [1.0, 0.391304347826087, 0.6310606060606063, 0.7016666666666667, 1.0, 1.0, 0.7583276195377006, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.33654426280024513, 0.33654426280024513, 0.4197851940209507], 
reward next is 0.5802, 
noisyNet noise sample is [array([1.3379929], dtype=float32), 0.6677801]. 
=============================================
[2019-03-22 22:34:21,697] A3C_AGENT_WORKER-Thread-16 INFO:Local step 10000, global step 159946: loss 0.6656
[2019-03-22 22:34:21,700] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 10000, global step 159946: learning rate 0.0010
[2019-03-22 22:34:21,701] A3C_AGENT_WORKER-Thread-2 INFO:Local step 10000, global step 159946: loss 0.8429
[2019-03-22 22:34:21,704] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 10000, global step 159946: learning rate 0.0010
[2019-03-22 22:34:21,796] A3C_AGENT_WORKER-Thread-9 INFO:Local step 10000, global step 159979: loss 0.6710
[2019-03-22 22:34:21,799] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 10000, global step 159980: learning rate 0.0010
[2019-03-22 22:34:21,814] A3C_AGENT_WORKER-Thread-10 INFO:Local step 10000, global step 159986: loss 0.8938
[2019-03-22 22:34:21,818] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 10000, global step 159986: learning rate 0.0010
[2019-03-22 22:34:21,870] A3C_AGENT_WORKER-Thread-17 INFO:Local step 10000, global step 160015: loss 0.6997
[2019-03-22 22:34:21,871] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 10000, global step 160016: learning rate 0.0010
[2019-03-22 22:34:21,919] A3C_AGENT_WORKER-Thread-13 INFO:Local step 10000, global step 160033: loss 0.4875
[2019-03-22 22:34:21,923] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 10000, global step 160033: learning rate 0.0010
[2019-03-22 22:34:21,947] A3C_AGENT_WORKER-Thread-12 INFO:Local step 10000, global step 160040: loss 0.8698
[2019-03-22 22:34:21,948] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 10000, global step 160040: learning rate 0.0010
[2019-03-22 22:34:22,083] A3C_AGENT_WORKER-Thread-15 INFO:Local step 10000, global step 160094: loss 0.5899
[2019-03-22 22:34:22,087] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 10000, global step 160095: learning rate 0.0010
[2019-03-22 22:34:22,151] A3C_AGENT_WORKER-Thread-18 INFO:Local step 10000, global step 160118: loss 0.5468
[2019-03-22 22:34:22,154] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 10000, global step 160118: learning rate 0.0010
[2019-03-22 22:34:22,431] A3C_AGENT_WORKER-Thread-22 INFO:Local step 10000, global step 160225: loss 0.3644
[2019-03-22 22:34:22,433] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 10000, global step 160225: learning rate 0.0010
[2019-03-22 22:34:22,475] A3C_AGENT_WORKER-Thread-20 INFO:Local step 10000, global step 160241: loss 0.6428
[2019-03-22 22:34:22,477] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 10000, global step 160241: learning rate 0.0010
[2019-03-22 22:34:25,454] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 22:34:25,465] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7868
[2019-03-22 22:34:25,473] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.9, 79.33333333333334, 1.0, 2.0, 0.2521725103478644, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 273807.4774870933, 273807.477487093, 82267.33641407182], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6056400.0000, 
sim time next is 6057000.0000, 
raw observation next is [15.8, 79.0, 1.0, 2.0, 0.2380766579582266, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 258498.2138179602, 258498.2138179599, 80062.18840564314], 
processed observation next is [1.0, 0.08695652173913043, 0.35454545454545455, 0.79, 1.0, 1.0, 0.047595822447783244, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09574007919183711, 0.09574007919183701, 0.1952736302576662], 
reward next is 0.8047, 
noisyNet noise sample is [array([0.54038864], dtype=float32), 0.7813816]. 
=============================================
[2019-03-22 22:34:25,484] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[70.07789 ]
 [70.0472  ]
 [70.03078 ]
 [69.957054]
 [69.99098 ]], R is [[70.12595367]
 [70.2240448 ]
 [70.31528473]
 [70.41067505]
 [70.50285339]].
[2019-03-22 22:34:31,966] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 6.2995088e-33 9.2869955e-37], sum to 1.0000
[2019-03-22 22:34:31,977] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0439
[2019-03-22 22:34:31,985] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.45, 81.0, 1.0, 2.0, 0.3082319729020636, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 334697.4687614769, 334697.4687614772, 103574.5208049504], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6150600.0000, 
sim time next is 6151200.0000, 
raw observation next is [17.36666666666667, 82.0, 1.0, 2.0, 0.3045641112961298, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 330713.3219586681, 330713.3219586681, 103802.7962675692], 
processed observation next is [1.0, 0.17391304347826086, 0.42575757575757595, 0.82, 1.0, 1.0, 0.13070513912016224, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12248641554024746, 0.12248641554024746, 0.25317755187212], 
reward next is 0.7468, 
noisyNet noise sample is [array([-1.0843018], dtype=float32), 1.0092517]. 
=============================================
[2019-03-22 22:34:33,649] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.4604225e-38 1.0000000e+00 1.0649574e-30 7.7886850e-25 2.6167774e-32], sum to 1.0000
[2019-03-22 22:34:33,660] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8834
[2019-03-22 22:34:33,664] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.81666666666667, 67.66666666666666, 1.0, 2.0, 0.5777653734166595, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 638976.8422333816, 638976.8422333816, 137920.2704973376], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6169800.0000, 
sim time next is 6170400.0000, 
raw observation next is [21.1, 66.0, 1.0, 2.0, 0.587630879465166, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 650224.9175589904, 650224.9175589908, 139081.1695278409], 
processed observation next is [1.0, 0.43478260869565216, 0.5954545454545456, 0.66, 1.0, 1.0, 0.4845385993314575, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.24082404354036682, 0.24082404354036696, 0.33922236470205097], 
reward next is 0.6608, 
noisyNet noise sample is [array([0.50890785], dtype=float32), 0.60526925]. 
=============================================
[2019-03-22 22:34:34,039] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.4935128e-37 1.0000000e+00 1.7997692e-29 2.5914659e-17 5.6980977e-28], sum to 1.0000
[2019-03-22 22:34:34,054] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4305
[2019-03-22 22:34:34,064] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.6, 71.0, 1.0, 2.0, 0.7577996304576934, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 852520.5961333811, 852520.5961333811, 164733.8354824267], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6177600.0000, 
sim time next is 6178200.0000, 
raw observation next is [21.7, 71.0, 1.0, 2.0, 0.7053934491185083, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 794043.6641460327, 794043.6641460327, 158031.4423889381], 
processed observation next is [1.0, 0.5217391304347826, 0.6227272727272727, 0.71, 1.0, 1.0, 0.6317418113981355, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2940902459800121, 0.2940902459800121, 0.3854425424120441], 
reward next is 0.6146, 
noisyNet noise sample is [array([-1.2724566], dtype=float32), -1.9643761]. 
=============================================
[2019-03-22 22:34:41,631] A3C_AGENT_WORKER-Thread-21 INFO:Local step 10500, global step 167738: loss 0.0728
[2019-03-22 22:34:41,634] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 10500, global step 167738: learning rate 0.0010
[2019-03-22 22:34:41,796] A3C_AGENT_WORKER-Thread-19 INFO:Local step 10500, global step 167801: loss 0.0019
[2019-03-22 22:34:41,798] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 10500, global step 167801: learning rate 0.0010
[2019-03-22 22:34:41,909] A3C_AGENT_WORKER-Thread-3 INFO:Local step 10500, global step 167844: loss 0.0145
[2019-03-22 22:34:41,913] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 10500, global step 167845: learning rate 0.0010
[2019-03-22 22:34:41,959] A3C_AGENT_WORKER-Thread-14 INFO:Local step 10500, global step 167861: loss 0.0175
[2019-03-22 22:34:41,962] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 10500, global step 167861: learning rate 0.0010
[2019-03-22 22:34:42,104] A3C_AGENT_WORKER-Thread-16 INFO:Local step 10500, global step 167923: loss 0.0007
[2019-03-22 22:34:42,105] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 10500, global step 167923: learning rate 0.0010
[2019-03-22 22:34:42,138] A3C_AGENT_WORKER-Thread-11 INFO:Local step 10500, global step 167935: loss 0.0060
[2019-03-22 22:34:42,139] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 10500, global step 167935: learning rate 0.0010
[2019-03-22 22:34:42,203] A3C_AGENT_WORKER-Thread-2 INFO:Local step 10500, global step 167961: loss 0.0415
[2019-03-22 22:34:42,205] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 10500, global step 167961: learning rate 0.0010
[2019-03-22 22:34:42,209] A3C_AGENT_WORKER-Thread-10 INFO:Local step 10500, global step 167962: loss 0.0188
[2019-03-22 22:34:42,211] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 10500, global step 167962: learning rate 0.0010
[2019-03-22 22:34:42,233] A3C_AGENT_WORKER-Thread-13 INFO:Local step 10500, global step 167969: loss 0.0137
[2019-03-22 22:34:42,240] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 10500, global step 167971: learning rate 0.0010
[2019-03-22 22:34:42,267] A3C_AGENT_WORKER-Thread-9 INFO:Local step 10500, global step 167980: loss 0.0233
[2019-03-22 22:34:42,272] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 10500, global step 167980: learning rate 0.0010
[2019-03-22 22:34:42,319] A3C_AGENT_WORKER-Thread-17 INFO:Local step 10500, global step 168000: loss 0.0657
[2019-03-22 22:34:42,321] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 10500, global step 168000: learning rate 0.0010
[2019-03-22 22:34:42,518] A3C_AGENT_WORKER-Thread-12 INFO:Local step 10500, global step 168078: loss 0.0086
[2019-03-22 22:34:42,521] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 10500, global step 168079: learning rate 0.0010
[2019-03-22 22:34:42,527] A3C_AGENT_WORKER-Thread-15 INFO:Local step 10500, global step 168081: loss 0.0080
[2019-03-22 22:34:42,529] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 10500, global step 168082: learning rate 0.0010
[2019-03-22 22:34:42,604] A3C_AGENT_WORKER-Thread-18 INFO:Local step 10500, global step 168112: loss 0.0002
[2019-03-22 22:34:42,605] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 10500, global step 168112: learning rate 0.0010
[2019-03-22 22:34:42,980] A3C_AGENT_WORKER-Thread-22 INFO:Local step 10500, global step 168263: loss 0.0006
[2019-03-22 22:34:42,983] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 10500, global step 168264: learning rate 0.0010
[2019-03-22 22:34:43,086] A3C_AGENT_WORKER-Thread-20 INFO:Local step 10500, global step 168301: loss 0.0470
[2019-03-22 22:34:43,090] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 10500, global step 168302: learning rate 0.0010
[2019-03-22 22:34:47,773] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 6.008832e-33 2.424044e-37], sum to 1.0000
[2019-03-22 22:34:47,784] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9950
[2019-03-22 22:34:47,790] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.25, 80.0, 1.0, 2.0, 0.5634859468535822, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 638479.5795716877, 638479.5795716877, 152518.5975798556], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6381000.0000, 
sim time next is 6381600.0000, 
raw observation next is [25.16666666666666, 80.33333333333334, 1.0, 2.0, 0.5621777641194718, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 637151.5862435669, 637151.5862435669, 152290.2793742855], 
processed observation next is [0.0, 0.8695652173913043, 0.78030303030303, 0.8033333333333335, 1.0, 1.0, 0.45272220514933975, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23598206897909887, 0.23598206897909887, 0.37143970579094027], 
reward next is 0.6286, 
noisyNet noise sample is [array([-0.7766707], dtype=float32), -0.47110325]. 
=============================================
[2019-03-22 22:34:48,927] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 7.4696412e-34 1.9637418e-35], sum to 1.0000
[2019-03-22 22:34:48,936] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5885
[2019-03-22 22:34:48,949] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.4, 74.66666666666666, 1.0, 2.0, 0.597521024136646, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 681756.8567969718, 681756.8567969721, 153715.0301932448], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6403200.0000, 
sim time next is 6403800.0000, 
raw observation next is [24.4, 74.33333333333334, 1.0, 2.0, 0.5791555697904275, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 660835.6190273796, 660835.6190273796, 151201.9765666981], 
processed observation next is [1.0, 0.08695652173913043, 0.7454545454545454, 0.7433333333333334, 1.0, 1.0, 0.4739444622380343, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.24475393297310355, 0.24475393297310355, 0.3687853086992637], 
reward next is 0.6312, 
noisyNet noise sample is [array([0.4144044], dtype=float32), -0.26826942]. 
=============================================
[2019-03-22 22:34:49,671] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 22:34:49,685] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1965
[2019-03-22 22:34:49,694] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.8, 71.0, 1.0, 2.0, 0.4880595761522142, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 556913.5545409712, 556913.5545409712, 139786.7202246134], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6417600.0000, 
sim time next is 6418200.0000, 
raw observation next is [24.9, 71.0, 1.0, 2.0, 0.4836757180308804, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 551879.2119674638, 551879.2119674636, 139478.9205815407], 
processed observation next is [1.0, 0.2608695652173913, 0.7681818181818181, 0.71, 1.0, 1.0, 0.3545946475386004, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20439970813609773, 0.20439970813609762, 0.34019248922327], 
reward next is 0.6598, 
noisyNet noise sample is [array([0.22565846], dtype=float32), -1.038722]. 
=============================================
[2019-03-22 22:34:52,196] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 3.1954020e-37 3.3045725e-33 4.6325196e-36], sum to 1.0000
[2019-03-22 22:34:52,205] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0692
[2019-03-22 22:34:52,214] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.93333333333333, 95.33333333333334, 1.0, 2.0, 0.7560319797272058, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 860548.0195438527, 860548.0195438529, 170823.6723032492], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6438000.0000, 
sim time next is 6438600.0000, 
raw observation next is [19.65, 96.5, 1.0, 2.0, 0.6830364057432368, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 776680.5422104098, 776680.5422104095, 159923.5391370106], 
processed observation next is [1.0, 0.5217391304347826, 0.5295454545454544, 0.965, 1.0, 1.0, 0.603795507179046, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.28765946007792953, 0.2876594600779295, 0.39005741252929416], 
reward next is 0.6099, 
noisyNet noise sample is [array([1.5712769], dtype=float32), 0.7069456]. 
=============================================
[2019-03-22 22:34:54,911] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 22:34:54,922] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8897
[2019-03-22 22:34:54,927] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.0, 77.0, 1.0, 2.0, 0.2082288009244206, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 226082.5583220183, 226082.5583220181, 73422.61797076499], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6485400.0000, 
sim time next is 6486000.0000, 
raw observation next is [15.0, 77.0, 1.0, 2.0, 0.2077073911741807, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 225516.3111111478, 225516.3111111478, 73371.7353245908], 
processed observation next is [1.0, 0.043478260869565216, 0.3181818181818182, 0.77, 1.0, 1.0, 0.009634238967725847, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08352455967079549, 0.08352455967079549, 0.17895545201119709], 
reward next is 0.8210, 
noisyNet noise sample is [array([-0.8946601], dtype=float32), 0.089972734]. 
=============================================
[2019-03-22 22:34:54,949] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[70.76041 ]
 [70.88969 ]
 [71.022194]
 [71.17152 ]
 [71.23209 ]], R is [[70.7539978 ]
 [70.86737823]
 [70.97955322]
 [71.0905838 ]
 [71.20040131]].
[2019-03-22 22:34:55,036] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.5305694e-38], sum to 1.0000
[2019-03-22 22:34:55,047] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4433
[2019-03-22 22:34:55,052] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.1, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 205156.1253947009, 205156.1253947012, 69063.11974416862], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6492000.0000, 
sim time next is 6492600.0000, 
raw observation next is [13.0, 88.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 203154.3702369949, 203154.3702369946, 68615.94282274973], 
processed observation next is [1.0, 0.13043478260869565, 0.22727272727272727, 0.885, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07524235934703515, 0.07524235934703503, 0.16735595810426762], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.1368355], dtype=float32), -0.81129336]. 
=============================================
[2019-03-22 22:34:55,950] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.9456617e-38 0.0000000e+00], sum to 1.0000
[2019-03-22 22:34:55,965] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2233
[2019-03-22 22:34:55,969] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.03333333333333, 85.33333333333334, 1.0, 2.0, 0.2068306439604302, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 224564.1714756488, 224564.1714756488, 73309.17502795758], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6506400.0000, 
sim time next is 6507000.0000, 
raw observation next is [14.4, 83.5, 1.0, 2.0, 0.204454487708134, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 221983.6964005556, 221983.6964005553, 73384.22220334488], 
processed observation next is [1.0, 0.30434782608695654, 0.29090909090909095, 0.835, 1.0, 1.0, 0.005568109635167469, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08221618385205763, 0.08221618385205752, 0.17898590781303628], 
reward next is 0.8210, 
noisyNet noise sample is [array([0.2251652], dtype=float32), -1.6263978]. 
=============================================
[2019-03-22 22:34:55,981] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[58.45332 ]
 [58.442013]
 [58.494778]
 [58.47187 ]
 [58.460064]], R is [[58.69296265]
 [58.92723083]
 [59.15702057]
 [58.56545258]
 [57.97979736]].
[2019-03-22 22:34:58,234] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 22:34:58,248] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1897
[2019-03-22 22:34:58,254] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.31666666666667, 49.83333333333334, 1.0, 2.0, 0.3697447049840054, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 401519.4005609863, 401519.4005609865, 95596.18491284885], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6526200.0000, 
sim time next is 6526800.0000, 
raw observation next is [20.5, 49.0, 1.0, 2.0, 0.425047333443745, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 461603.071506443, 461603.0715064427, 101484.5352522724], 
processed observation next is [1.0, 0.5652173913043478, 0.5681818181818182, 0.49, 1.0, 1.0, 0.2813091668046812, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17096410055794187, 0.17096410055794173, 0.24752325671285952], 
reward next is 0.7525, 
noisyNet noise sample is [array([0.04794709], dtype=float32), 0.8468372]. 
=============================================
[2019-03-22 22:34:59,473] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 22:34:59,483] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6624
[2019-03-22 22:34:59,487] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.9, 73.66666666666666, 1.0, 2.0, 0.2287854754034231, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 248407.4831936879, 248407.4831936876, 77000.64661245803], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6561600.0000, 
sim time next is 6562200.0000, 
raw observation next is [15.45, 76.83333333333334, 1.0, 2.0, 0.2234690021631683, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 242633.5976736057, 242633.5976736055, 76224.10775790681], 
processed observation next is [1.0, 0.9565217391304348, 0.3386363636363636, 0.7683333333333334, 1.0, 1.0, 0.029336252703960376, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08986429543466877, 0.0898642954346687, 0.18591245794611416], 
reward next is 0.8141, 
noisyNet noise sample is [array([0.75034106], dtype=float32), -0.3999143]. 
=============================================
[2019-03-22 22:35:00,225] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-22 22:35:00,232] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-22 22:35:00,233] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-22 22:35:00,234] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:35:00,235] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:35:00,236] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-22 22:35:00,238] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-22 22:35:00,240] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-22 22:35:00,242] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:35:00,245] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:35:00,242] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:35:00,265] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run8
[2019-03-22 22:35:00,265] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run8
[2019-03-22 22:35:00,266] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run8
[2019-03-22 22:35:00,302] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run8
[2019-03-22 22:35:00,343] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run8
[2019-03-22 22:35:29,136] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.22877865], dtype=float32), -0.2613883]
[2019-03-22 22:35:29,136] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.4, 72.0, 1.0, 2.0, 0.3708270577238343, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 415732.2783361297, 415732.2783361297, 125513.3535580326]
[2019-03-22 22:35:29,138] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 22:35:29,141] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.2664667235009903
[2019-03-22 22:35:36,476] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.22877865], dtype=float32), -0.2613883]
[2019-03-22 22:35:36,476] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.25, 47.16666666666667, 1.0, 2.0, 0.3432299009305835, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 372687.7217329507, 372687.7217329511, 91662.91421125486]
[2019-03-22 22:35:36,478] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 22:35:36,480] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.3801297483311977
[2019-03-22 22:36:02,507] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.22877865], dtype=float32), -0.2613883]
[2019-03-22 22:36:02,509] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [25.10193799, 54.01201686, 1.0, 2.0, 0.3699390772475197, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 417183.9003745656, 417183.9003745659, 126696.9219324496]
[2019-03-22 22:36:02,511] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 22:36:02,513] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.6071383878763218
[2019-03-22 22:36:13,827] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.22877865], dtype=float32), -0.2613883]
[2019-03-22 22:36:13,830] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.33333333333333, 75.66666666666666, 1.0, 2.0, 0.2629561672483062, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 285519.7477671632, 285519.7477671629, 89714.63813194231]
[2019-03-22 22:36:13,831] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 22:36:13,835] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.710064305444958
[2019-03-22 22:36:20,670] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.22877865], dtype=float32), -0.2613883]
[2019-03-22 22:36:20,673] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.23867588, 100.0, 1.0, 2.0, 0.5994653568815508, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 673546.9541925214, 673546.9541925214, 163134.7098372317]
[2019-03-22 22:36:20,674] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 22:36:20,676] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.9911610152264766
[2019-03-22 22:36:28,866] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.22877865], dtype=float32), -0.2613883]
[2019-03-22 22:36:28,868] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.85859400666666, 97.53570237999999, 1.0, 2.0, 0.4120241339695251, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 468342.7204261676, 468342.7204261676, 132901.959414806]
[2019-03-22 22:36:28,870] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 22:36:28,875] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.3141876876621056
[2019-03-22 22:36:49,117] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.22877865], dtype=float32), -0.2613883]
[2019-03-22 22:36:49,118] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.95, 80.0, 1.0, 2.0, 0.3728876973759027, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 420657.0652048053, 420657.065204805, 127035.6557582129]
[2019-03-22 22:36:49,119] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 22:36:49,122] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.9456344209670589
[2019-03-22 22:37:03,310] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9309 1705967916.6745 465.0000
[2019-03-22 22:37:03,903] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-22 22:37:03,914] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1147 1656209757.7786 80.0000
[2019-03-22 22:37:04,058] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3486 1683344882.4587 214.0000
[2019-03-22 22:37:04,148] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-22 22:37:05,166] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 175000, evaluation results [175000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.114669779829, 1656209757.7786272, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8596.930884973775, 1705967916.6744611, 465.0, 8574.348638023737, 1683344882.4586744, 214.0]
[2019-03-22 22:37:06,126] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 22:37:06,138] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3007
[2019-03-22 22:37:06,146] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [11.1, 96.66666666666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 187939.2061498055, 187939.2061498057, 64439.88881794196], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6587400.0000, 
sim time next is 6588000.0000, 
raw observation next is [11.1, 96.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 186888.8648029277, 186888.864802928, 64202.10524088257], 
processed observation next is [1.0, 0.2608695652173913, 0.1409090909090909, 0.96, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.06921809807515841, 0.06921809807515852, 0.15659050058751847], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.30792996], dtype=float32), -1.6800079]. 
=============================================
[2019-03-22 22:37:06,161] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[68.27259]
 [68.31008]
 [68.34762]
 [68.37714]
 [68.40038]], R is [[67.56865692]
 [66.89296722]
 [66.22403717]
 [65.5617981 ]
 [64.90618134]].
[2019-03-22 22:37:06,953] A3C_AGENT_WORKER-Thread-21 INFO:Local step 11000, global step 175707: loss 2.6723
[2019-03-22 22:37:06,956] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 11000, global step 175707: learning rate 0.0010
[2019-03-22 22:37:07,267] A3C_AGENT_WORKER-Thread-14 INFO:Local step 11000, global step 175823: loss 4.5276
[2019-03-22 22:37:07,270] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 11000, global step 175824: learning rate 0.0010
[2019-03-22 22:37:07,353] A3C_AGENT_WORKER-Thread-3 INFO:Local step 11000, global step 175857: loss 3.9032
[2019-03-22 22:37:07,357] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 11000, global step 175858: learning rate 0.0010
[2019-03-22 22:37:07,389] A3C_AGENT_WORKER-Thread-19 INFO:Local step 11000, global step 175869: loss 4.9898
[2019-03-22 22:37:07,395] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 11000, global step 175869: learning rate 0.0010
[2019-03-22 22:37:07,487] A3C_AGENT_WORKER-Thread-16 INFO:Local step 11000, global step 175908: loss 4.5191
[2019-03-22 22:37:07,489] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 11000, global step 175908: learning rate 0.0010
[2019-03-22 22:37:07,513] A3C_AGENT_WORKER-Thread-13 INFO:Local step 11000, global step 175919: loss 3.5810
[2019-03-22 22:37:07,520] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 11000, global step 175919: learning rate 0.0010
[2019-03-22 22:37:07,533] A3C_AGENT_WORKER-Thread-2 INFO:Local step 11000, global step 175926: loss 2.7473
[2019-03-22 22:37:07,536] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 11000, global step 175927: learning rate 0.0010
[2019-03-22 22:37:07,632] A3C_AGENT_WORKER-Thread-11 INFO:Local step 11000, global step 175963: loss 3.7927
[2019-03-22 22:37:07,638] A3C_AGENT_WORKER-Thread-9 INFO:Local step 11000, global step 175963: loss 3.6114
[2019-03-22 22:37:07,639] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 11000, global step 175963: learning rate 0.0010
[2019-03-22 22:37:07,641] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 11000, global step 175963: learning rate 0.0010
[2019-03-22 22:37:07,766] A3C_AGENT_WORKER-Thread-10 INFO:Local step 11000, global step 176023: loss 3.4145
[2019-03-22 22:37:07,769] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 11000, global step 176024: learning rate 0.0010
[2019-03-22 22:37:07,832] A3C_AGENT_WORKER-Thread-17 INFO:Local step 11000, global step 176049: loss 2.4806
[2019-03-22 22:37:07,836] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 11000, global step 176051: learning rate 0.0010
[2019-03-22 22:37:07,840] A3C_AGENT_WORKER-Thread-15 INFO:Local step 11000, global step 176051: loss 3.4431
[2019-03-22 22:37:07,843] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 11000, global step 176052: learning rate 0.0010
[2019-03-22 22:37:07,880] A3C_AGENT_WORKER-Thread-12 INFO:Local step 11000, global step 176069: loss 2.4852
[2019-03-22 22:37:07,882] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 11000, global step 176069: learning rate 0.0010
[2019-03-22 22:37:08,158] A3C_AGENT_WORKER-Thread-18 INFO:Local step 11000, global step 176176: loss 1.9296
[2019-03-22 22:37:08,162] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 11000, global step 176178: learning rate 0.0010
[2019-03-22 22:37:08,354] A3C_AGENT_WORKER-Thread-20 INFO:Local step 11000, global step 176253: loss 1.7925
[2019-03-22 22:37:08,357] A3C_AGENT_WORKER-Thread-22 INFO:Local step 11000, global step 176254: loss 1.7810
[2019-03-22 22:37:08,357] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 11000, global step 176254: learning rate 0.0010
[2019-03-22 22:37:08,363] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 11000, global step 176254: learning rate 0.0010
[2019-03-22 22:37:13,076] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.7484716e-31 7.3825118e-32], sum to 1.0000
[2019-03-22 22:37:13,085] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9135
[2019-03-22 22:37:13,094] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 89.0, 1.0, 2.0, 0.3716850397377511, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 416086.551290492, 416086.551290492, 120978.6557607885], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6680400.0000, 
sim time next is 6681000.0000, 
raw observation next is [18.9, 89.5, 1.0, 2.0, 0.3704024611223494, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 414437.0121586117, 414437.012158612, 120773.1929058636], 
processed observation next is [1.0, 0.30434782608695654, 0.49545454545454537, 0.895, 1.0, 1.0, 0.21300307640293675, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1534951896883747, 0.15349518968837483, 0.29456876318503317], 
reward next is 0.7054, 
noisyNet noise sample is [array([-0.6891343], dtype=float32), 0.9963641]. 
=============================================
[2019-03-22 22:37:13,118] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[68.161255]
 [68.105545]
 [68.044106]
 [67.99207 ]
 [67.99459 ]], R is [[68.23031616]
 [68.25294495]
 [68.27472687]
 [68.29496002]
 [68.31218719]].
[2019-03-22 22:37:14,218] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.0289876e-31 1.6219949e-32], sum to 1.0000
[2019-03-22 22:37:14,231] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3740
[2019-03-22 22:37:14,238] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.2, 93.66666666666666, 1.0, 2.0, 0.6518664969328933, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 728779.9248950768, 728779.9248950768, 149041.7657164647], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6693000.0000, 
sim time next is 6693600.0000, 
raw observation next is [18.1, 94.33333333333334, 1.0, 2.0, 0.6693770697184795, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 748370.1171846767, 748370.117184677, 151145.9321541288], 
processed observation next is [1.0, 0.4782608695652174, 0.45909090909090916, 0.9433333333333335, 1.0, 1.0, 0.5867213371480994, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.27717411747580617, 0.27717411747580634, 0.36864861501007024], 
reward next is 0.6314, 
noisyNet noise sample is [array([-1.5847012], dtype=float32), -0.3466282]. 
=============================================
[2019-03-22 22:37:16,110] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 3.2021443e-33], sum to 1.0000
[2019-03-22 22:37:16,119] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9064
[2019-03-22 22:37:16,126] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 97.0, 1.0, 2.0, 0.3562432626319031, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 396622.4417906591, 396622.4417906591, 118732.1885728334], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6727200.0000, 
sim time next is 6727800.0000, 
raw observation next is [17.7, 97.0, 1.0, 2.0, 0.3562318422108859, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 396608.3024093672, 396608.3024093675, 118730.6716286765], 
processed observation next is [1.0, 0.8695652173913043, 0.44090909090909086, 0.97, 1.0, 1.0, 0.19528980276360733, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1468919638553212, 0.1468919638553213, 0.2895870039723817], 
reward next is 0.7104, 
noisyNet noise sample is [array([0.61933434], dtype=float32), -0.0035554413]. 
=============================================
[2019-03-22 22:37:18,426] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 22:37:18,433] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1190
[2019-03-22 22:37:18,443] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.2, 93.0, 1.0, 2.0, 0.3216150273591896, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 352466.5883604378, 352466.5883604381, 113802.7531004965], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6753600.0000, 
sim time next is 6754200.0000, 
raw observation next is [17.2, 92.5, 1.0, 2.0, 0.3592081464821024, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 393478.911608036, 393478.911608036, 116505.8107564511], 
processed observation next is [1.0, 0.17391304347826086, 0.41818181818181815, 0.925, 1.0, 1.0, 0.199010183102628, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14573293022519854, 0.14573293022519854, 0.28416051404012466], 
reward next is 0.7158, 
noisyNet noise sample is [array([0.08012707], dtype=float32), 0.84663117]. 
=============================================
[2019-03-22 22:37:20,397] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.9593144e-29 5.5128309e-35], sum to 1.0000
[2019-03-22 22:37:20,407] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4717
[2019-03-22 22:37:20,416] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1255098.023620622 W.
[2019-03-22 22:37:20,423] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.7, 64.0, 1.0, 2.0, 0.9964689008021744, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.277086730254196, 6.9112, 77.32768968023734, 1255098.023620622, 1136266.686372727, 211848.294339017], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6787800.0000, 
sim time next is 6788400.0000, 
raw observation next is [24.8, 63.33333333333333, 1.0, 2.0, 0.3625230339047295, 1.0, 1.0, 0.3625230339047295, 1.0, 1.0, 0.7322225620407092, 6.9112, 6.9112, 77.3421103, 1241640.68792349, 1241640.68792349, 278046.9778834818], 
processed observation next is [1.0, 0.5652173913043478, 0.7636363636363637, 0.6333333333333333, 1.0, 1.0, 0.20315379238091186, 1.0, 0.5, 0.20315379238091186, 1.0, 0.5, 0.6174608029152989, 0.0, 0.0, 0.5085185399722538, 0.45986692145314445, 0.45986692145314445, 0.6781633606914191], 
reward next is 0.3218, 
noisyNet noise sample is [array([0.2747006], dtype=float32), 0.49285865]. 
=============================================
[2019-03-22 22:37:22,697] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.9022287e-25 7.2986817e-30], sum to 1.0000
[2019-03-22 22:37:22,708] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1551
[2019-03-22 22:37:22,715] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 72.66666666666667, 1.0, 2.0, 0.4081353229611981, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 462186.9833881573, 462186.9833881573, 126904.567516271], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6819600.0000, 
sim time next is 6820200.0000, 
raw observation next is [22.15, 73.5, 1.0, 2.0, 0.4062313020654916, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 459827.3802183582, 459827.3802183582, 126596.4186782655], 
processed observation next is [1.0, 0.9565217391304348, 0.6431818181818181, 0.735, 1.0, 1.0, 0.25778912758186445, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17030643711791044, 0.17030643711791044, 0.3087717528738183], 
reward next is 0.6912, 
noisyNet noise sample is [array([-0.14398877], dtype=float32), -0.8606205]. 
=============================================
[2019-03-22 22:37:25,085] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.0087927e-35 0.0000000e+00], sum to 1.0000
[2019-03-22 22:37:25,094] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4886
[2019-03-22 22:37:25,100] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.73333333333333, 95.0, 1.0, 2.0, 0.338642414237675, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 375566.0118740706, 375566.0118740706, 116730.6358912148], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6852000.0000, 
sim time next is 6852600.0000, 
raw observation next is [18.0, 94.5, 1.0, 2.0, 0.3439997495040985, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 382732.5125120567, 382732.512512057, 117651.9416518361], 
processed observation next is [0.0, 0.30434782608695654, 0.45454545454545453, 0.945, 1.0, 1.0, 0.1799996868801231, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14175278241187284, 0.14175278241187295, 0.28695595524838075], 
reward next is 0.7130, 
noisyNet noise sample is [array([0.15408342], dtype=float32), -0.6942465]. 
=============================================
[2019-03-22 22:37:27,373] A3C_AGENT_WORKER-Thread-21 INFO:Local step 11500, global step 183690: loss 0.0019
[2019-03-22 22:37:27,376] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 11500, global step 183690: learning rate 0.0010
[2019-03-22 22:37:27,687] A3C_AGENT_WORKER-Thread-14 INFO:Local step 11500, global step 183808: loss 0.0567
[2019-03-22 22:37:27,687] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 11500, global step 183808: learning rate 0.0010
[2019-03-22 22:37:27,878] A3C_AGENT_WORKER-Thread-3 INFO:Local step 11500, global step 183889: loss 0.0006
[2019-03-22 22:37:27,882] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 11500, global step 183889: learning rate 0.0010
[2019-03-22 22:37:27,981] A3C_AGENT_WORKER-Thread-9 INFO:Local step 11500, global step 183930: loss 0.0415
[2019-03-22 22:37:27,983] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 11500, global step 183930: learning rate 0.0010
[2019-03-22 22:37:27,991] A3C_AGENT_WORKER-Thread-19 INFO:Local step 11500, global step 183933: loss 0.0198
[2019-03-22 22:37:27,995] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 11500, global step 183933: learning rate 0.0010
[2019-03-22 22:37:28,008] A3C_AGENT_WORKER-Thread-16 INFO:Local step 11500, global step 183937: loss 0.0646
[2019-03-22 22:37:28,011] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 11500, global step 183938: learning rate 0.0010
[2019-03-22 22:37:28,017] A3C_AGENT_WORKER-Thread-13 INFO:Local step 11500, global step 183941: loss 0.0492
[2019-03-22 22:37:28,019] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 11500, global step 183941: learning rate 0.0010
[2019-03-22 22:37:28,027] A3C_AGENT_WORKER-Thread-2 INFO:Local step 11500, global step 183945: loss 0.0422
[2019-03-22 22:37:28,029] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 11500, global step 183945: learning rate 0.0010
[2019-03-22 22:37:28,139] A3C_AGENT_WORKER-Thread-11 INFO:Local step 11500, global step 183989: loss 0.0060
[2019-03-22 22:37:28,144] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 11500, global step 183990: learning rate 0.0010
[2019-03-22 22:37:28,181] A3C_AGENT_WORKER-Thread-10 INFO:Local step 11500, global step 184007: loss 0.0020
[2019-03-22 22:37:28,187] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 11500, global step 184009: learning rate 0.0010
[2019-03-22 22:37:28,313] A3C_AGENT_WORKER-Thread-15 INFO:Local step 11500, global step 184055: loss 0.0204
[2019-03-22 22:37:28,317] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 11500, global step 184057: learning rate 0.0010
[2019-03-22 22:37:28,327] A3C_AGENT_WORKER-Thread-12 INFO:Local step 11500, global step 184060: loss 0.0477
[2019-03-22 22:37:28,334] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 11500, global step 184063: learning rate 0.0010
[2019-03-22 22:37:28,351] A3C_AGENT_WORKER-Thread-17 INFO:Local step 11500, global step 184069: loss 0.0540
[2019-03-22 22:37:28,355] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 11500, global step 184069: learning rate 0.0010
[2019-03-22 22:37:28,493] A3C_AGENT_WORKER-Thread-22 INFO:Local step 11500, global step 184121: loss 0.0310
[2019-03-22 22:37:28,494] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 11500, global step 184122: learning rate 0.0010
[2019-03-22 22:37:28,632] A3C_AGENT_WORKER-Thread-18 INFO:Local step 11500, global step 184176: loss 0.0005
[2019-03-22 22:37:28,634] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 11500, global step 184176: learning rate 0.0010
[2019-03-22 22:37:28,809] A3C_AGENT_WORKER-Thread-20 INFO:Local step 11500, global step 184245: loss 0.0504
[2019-03-22 22:37:28,810] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 11500, global step 184245: learning rate 0.0010
[2019-03-22 22:37:34,136] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 1.785999e-32 8.700459e-30 2.147867e-33], sum to 1.0000
[2019-03-22 22:37:34,143] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2263
[2019-03-22 22:37:34,148] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 71.0, 1.0, 2.0, 0.4951950023491119, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 564949.2558362321, 564949.2558362321, 141083.2665683016], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6984000.0000, 
sim time next is 6984600.0000, 
raw observation next is [24.9, 71.5, 1.0, 2.0, 0.4929763313925222, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 562438.7489638311, 562438.7489638311, 140762.2795781337], 
processed observation next is [0.0, 0.8695652173913043, 0.7681818181818181, 0.715, 1.0, 1.0, 0.36622041424065277, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20831064776438188, 0.20831064776438188, 0.34332263311739925], 
reward next is 0.6567, 
noisyNet noise sample is [array([0.83191097], dtype=float32), -1.0620828]. 
=============================================
[2019-03-22 22:37:37,240] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 4.1002996e-38 9.6595972e-30 4.5188490e-33], sum to 1.0000
[2019-03-22 22:37:37,249] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9710
[2019-03-22 22:37:37,256] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 97.0, 1.0, 2.0, 0.6547068116146683, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 739756.6801315775, 739756.6801315778, 153078.4970378015], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7034400.0000, 
sim time next is 7035000.0000, 
raw observation next is [18.9, 96.33333333333334, 1.0, 2.0, 0.7359390082554287, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 832019.8966910738, 832019.8966910735, 163942.1890712533], 
processed observation next is [1.0, 0.43478260869565216, 0.49545454545454537, 0.9633333333333334, 1.0, 1.0, 0.6699237603192859, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3081555172929903, 0.3081555172929902, 0.39985899773476413], 
reward next is 0.6001, 
noisyNet noise sample is [array([-0.25532636], dtype=float32), 0.81338555]. 
=============================================
[2019-03-22 22:37:37,278] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[61.67772 ]
 [61.84129 ]
 [61.810863]
 [61.745476]
 [61.703197]], R is [[61.41430283]
 [61.42679596]
 [61.4632225 ]
 [61.49422455]
 [61.51568604]].
[2019-03-22 22:37:47,727] A3C_AGENT_WORKER-Thread-21 INFO:Local step 12000, global step 191670: loss 0.6675
[2019-03-22 22:37:47,733] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 12000, global step 191670: learning rate 0.0010
[2019-03-22 22:37:48,075] A3C_AGENT_WORKER-Thread-14 INFO:Local step 12000, global step 191812: loss 1.8465
[2019-03-22 22:37:48,080] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 12000, global step 191812: learning rate 0.0010
[2019-03-22 22:37:48,249] A3C_AGENT_WORKER-Thread-3 INFO:Local step 12000, global step 191881: loss 3.1287
[2019-03-22 22:37:48,251] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 12000, global step 191881: learning rate 0.0010
[2019-03-22 22:37:48,324] A3C_AGENT_WORKER-Thread-2 INFO:Local step 12000, global step 191909: loss 3.3462
[2019-03-22 22:37:48,327] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 12000, global step 191909: learning rate 0.0010
[2019-03-22 22:37:48,339] A3C_AGENT_WORKER-Thread-19 INFO:Local step 12000, global step 191912: loss 2.9149
[2019-03-22 22:37:48,341] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 12000, global step 191913: learning rate 0.0010
[2019-03-22 22:37:48,449] A3C_AGENT_WORKER-Thread-16 INFO:Local step 12000, global step 191954: loss 4.5284
[2019-03-22 22:37:48,455] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 12000, global step 191954: learning rate 0.0010
[2019-03-22 22:37:48,473] A3C_AGENT_WORKER-Thread-10 INFO:Local step 12000, global step 191963: loss 3.9272
[2019-03-22 22:37:48,478] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 12000, global step 191963: learning rate 0.0010
[2019-03-22 22:37:48,495] A3C_AGENT_WORKER-Thread-13 INFO:Local step 12000, global step 191971: loss 3.8943
[2019-03-22 22:37:48,500] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 12000, global step 191971: learning rate 0.0010
[2019-03-22 22:37:48,552] A3C_AGENT_WORKER-Thread-9 INFO:Local step 12000, global step 191992: loss 4.2659
[2019-03-22 22:37:48,560] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 12000, global step 191996: learning rate 0.0010
[2019-03-22 22:37:48,622] A3C_AGENT_WORKER-Thread-11 INFO:Local step 12000, global step 192022: loss 5.4295
[2019-03-22 22:37:48,631] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 12000, global step 192025: learning rate 0.0010
[2019-03-22 22:37:48,698] A3C_AGENT_WORKER-Thread-22 INFO:Local step 12000, global step 192049: loss 4.8119
[2019-03-22 22:37:48,699] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 12000, global step 192049: learning rate 0.0010
[2019-03-22 22:37:48,822] A3C_AGENT_WORKER-Thread-15 INFO:Local step 12000, global step 192098: loss 3.5575
[2019-03-22 22:37:48,826] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 12000, global step 192099: learning rate 0.0010
[2019-03-22 22:37:48,853] A3C_AGENT_WORKER-Thread-17 INFO:Local step 12000, global step 192108: loss 3.7146
[2019-03-22 22:37:48,860] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 12000, global step 192109: learning rate 0.0010
[2019-03-22 22:37:48,883] A3C_AGENT_WORKER-Thread-12 INFO:Local step 12000, global step 192122: loss 3.8365
[2019-03-22 22:37:48,888] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 12000, global step 192123: learning rate 0.0010
[2019-03-22 22:37:48,988] A3C_AGENT_WORKER-Thread-18 INFO:Local step 12000, global step 192160: loss 3.9167
[2019-03-22 22:37:48,994] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 12000, global step 192160: learning rate 0.0010
[2019-03-22 22:37:49,158] A3C_AGENT_WORKER-Thread-20 INFO:Local step 12000, global step 192218: loss 2.0343
[2019-03-22 22:37:49,162] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 12000, global step 192218: learning rate 0.0010
[2019-03-22 22:37:49,467] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.4851662e-38 1.0000000e+00 5.2696420e-34 1.9792986e-31 2.2461665e-34], sum to 1.0000
[2019-03-22 22:37:49,473] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5431
[2019-03-22 22:37:49,479] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.46666666666667, 51.66666666666667, 1.0, 2.0, 0.5249600223217463, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 570172.2780651575, 570172.2780651575, 122856.8347861835], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7208400.0000, 
sim time next is 7209000.0000, 
raw observation next is [21.65, 51.0, 1.0, 2.0, 0.5238294256168187, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 568943.5898739728, 568943.589873973, 123222.6516170113], 
processed observation next is [1.0, 0.43478260869565216, 0.6204545454545454, 0.51, 1.0, 1.0, 0.4047867820210233, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2107198481014714, 0.21071984810147149, 0.30054305272441784], 
reward next is 0.6995, 
noisyNet noise sample is [array([-2.2257786], dtype=float32), -0.7197028]. 
=============================================
[2019-03-22 22:37:49,510] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[67.62746]
 [67.33227]
 [67.02032]
 [66.66097]
 [66.33999]], R is [[67.89258575]
 [67.91400909]
 [67.92939758]
 [67.9479599 ]
 [67.96579742]].
[2019-03-22 22:37:54,023] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.1817492e-38 0.0000000e+00], sum to 1.0000
[2019-03-22 22:37:54,034] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9223
[2019-03-22 22:37:54,041] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.95, 78.0, 1.0, 2.0, 0.2159030953249356, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 234416.8626904767, 234416.8626904767, 74268.51364848802], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7283400.0000, 
sim time next is 7284000.0000, 
raw observation next is [15.5, 75.0, 1.0, 2.0, 0.2342758123674686, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 254370.2630565255, 254370.2630565255, 76647.16115181417], 
processed observation next is [1.0, 0.30434782608695654, 0.3409090909090909, 0.75, 1.0, 1.0, 0.04284476545933575, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09421120853945389, 0.09421120853945389, 0.18694429549222968], 
reward next is 0.8131, 
noisyNet noise sample is [array([0.26921278], dtype=float32), 0.953099]. 
=============================================
[2019-03-22 22:37:54,056] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[69.23279 ]
 [69.21432 ]
 [69.171394]
 [69.166435]
 [69.16319 ]], R is [[69.36346436]
 [69.48868561]
 [69.61647034]
 [69.74428558]
 [69.87228394]].
[2019-03-22 22:37:54,948] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 3.0766843e-36 3.6202525e-32 0.0000000e+00], sum to 1.0000
[2019-03-22 22:37:54,962] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2315
[2019-03-22 22:37:54,967] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.3, 55.0, 1.0, 2.0, 0.6239157501323502, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 693714.4128240601, 693714.4128240603, 144251.332419881], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7297200.0000, 
sim time next is 7297800.0000, 
raw observation next is [23.48333333333333, 54.16666666666667, 1.0, 2.0, 0.6541618984912589, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 728068.8285226012, 728068.8285226012, 147995.7401583294], 
processed observation next is [1.0, 0.4782608695652174, 0.7037878787878786, 0.5416666666666667, 1.0, 1.0, 0.5677023731140737, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.26965512167503747, 0.26965512167503747, 0.3609652198983644], 
reward next is 0.6390, 
noisyNet noise sample is [array([-0.48102328], dtype=float32), 1.606821]. 
=============================================
[2019-03-22 22:38:06,698] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 4.069108e-29 0.000000e+00], sum to 1.0000
[2019-03-22 22:38:06,709] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6188
[2019-03-22 22:38:06,715] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.03333333333333, 88.5, 1.0, 2.0, 0.3555883890692863, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 397541.1448824763, 397541.144882476, 119404.2769759259], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7458600.0000, 
sim time next is 7459200.0000, 
raw observation next is [19.4, 87.0, 1.0, 2.0, 0.3609300526984502, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 404458.9452599193, 404458.9452599193, 120279.062371921], 
processed observation next is [0.0, 0.34782608695652173, 0.5181818181818181, 0.87, 1.0, 1.0, 0.20116256587306272, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14979960935552566, 0.14979960935552566, 0.2933635667607829], 
reward next is 0.7066, 
noisyNet noise sample is [array([0.6406383], dtype=float32), 0.61615765]. 
=============================================
[2019-03-22 22:38:08,166] A3C_AGENT_WORKER-Thread-21 INFO:Local step 12500, global step 199651: loss 0.0159
[2019-03-22 22:38:08,169] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 12500, global step 199651: learning rate 0.0010
[2019-03-22 22:38:08,328] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.0913631e-33 0.0000000e+00], sum to 1.0000
[2019-03-22 22:38:08,341] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4000
[2019-03-22 22:38:08,349] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.9, 59.0, 1.0, 2.0, 0.5199796749313421, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 592113.7406778845, 592113.7406778845, 145432.5657201265], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7482000.0000, 
sim time next is 7482600.0000, 
raw observation next is [28.0, 58.0, 1.0, 2.0, 0.5165483996500125, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 588403.3335700224, 588403.3335700224, 144849.5180385669], 
processed observation next is [0.0, 0.6086956521739131, 0.9090909090909091, 0.58, 1.0, 1.0, 0.39568549956251564, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21792716058148975, 0.21792716058148975, 0.35329150741113874], 
reward next is 0.6467, 
noisyNet noise sample is [array([-0.3120063], dtype=float32), -0.044630025]. 
=============================================
[2019-03-22 22:38:08,649] A3C_AGENT_WORKER-Thread-3 INFO:Local step 12500, global step 199836: loss 0.0645
[2019-03-22 22:38:08,653] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 12500, global step 199836: learning rate 0.0010
[2019-03-22 22:38:08,733] A3C_AGENT_WORKER-Thread-2 INFO:Local step 12500, global step 199867: loss 0.0307
[2019-03-22 22:38:08,735] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 12500, global step 199867: learning rate 0.0010
[2019-03-22 22:38:08,789] A3C_AGENT_WORKER-Thread-14 INFO:Local step 12500, global step 199891: loss 0.0385
[2019-03-22 22:38:08,793] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 12500, global step 199891: learning rate 0.0010
[2019-03-22 22:38:08,865] A3C_AGENT_WORKER-Thread-19 INFO:Local step 12500, global step 199924: loss 0.0038
[2019-03-22 22:38:08,871] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 12500, global step 199926: learning rate 0.0010
[2019-03-22 22:38:08,956] A3C_AGENT_WORKER-Thread-16 INFO:Local step 12500, global step 199953: loss 0.0146
[2019-03-22 22:38:08,958] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 12500, global step 199954: learning rate 0.0010
[2019-03-22 22:38:09,037] A3C_AGENT_WORKER-Thread-10 INFO:Local step 12500, global step 199988: loss 0.0339
[2019-03-22 22:38:09,044] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 12500, global step 199990: learning rate 0.0010
[2019-03-22 22:38:09,072] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-22 22:38:09,072] A3C_AGENT_WORKER-Thread-11 INFO:Local step 12500, global step 200000: loss 0.0475
[2019-03-22 22:38:09,074] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 12500, global step 200000: learning rate 0.0010
[2019-03-22 22:38:09,075] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-22 22:38:09,078] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:38:09,078] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-22 22:38:09,078] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:38:09,080] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-22 22:38:09,080] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:38:09,082] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-22 22:38:09,083] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:38:09,084] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-22 22:38:09,085] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:38:09,106] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run9
[2019-03-22 22:38:09,106] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run9
[2019-03-22 22:38:09,123] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run9
[2019-03-22 22:38:09,125] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run9
[2019-03-22 22:38:09,160] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run9
[2019-03-22 22:38:27,402] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.11630003], dtype=float32), -0.20627742]
[2019-03-22 22:38:27,404] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.7, 90.0, 1.0, 2.0, 0.3910329020588126, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 441633.6080611654, 441633.6080611654, 128924.6802775176]
[2019-03-22 22:38:27,404] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 22:38:27,406] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.0745497e-33 0.0000000e+00], sampled 0.3800331889593497
[2019-03-22 22:38:34,691] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.11630003], dtype=float32), -0.20627742]
[2019-03-22 22:38:34,693] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [23.52454515, 87.12269488, 1.0, 2.0, 0.4960124467089539, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 564570.4513980435, 564570.4513980432, 146999.0892563255]
[2019-03-22 22:38:34,694] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 22:38:34,695] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.3532024e-32 3.7270190e-38], sampled 0.261447544130883
[2019-03-22 22:38:35,032] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.11630003], dtype=float32), -0.20627742]
[2019-03-22 22:38:35,035] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [25.66666666666667, 66.5, 1.0, 2.0, 0.9089119453541956, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1037360.607639513, 1037360.607639512, 201769.9195354933]
[2019-03-22 22:38:35,037] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 22:38:35,040] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 8.4784399e-32 7.8327306e-23 3.1773282e-29], sampled 0.22792537304827032
[2019-03-22 22:38:35,484] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.11630003], dtype=float32), -0.20627742]
[2019-03-22 22:38:35,485] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.0, 78.0, 1.0, 2.0, 0.4246618138523653, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 482499.4537468406, 482499.4537468406, 129611.0896374589]
[2019-03-22 22:38:35,487] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 22:38:35,491] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 4.393167e-35 0.000000e+00], sampled 0.6116225009557034
[2019-03-22 22:38:54,971] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.11630003], dtype=float32), -0.20627742]
[2019-03-22 22:38:54,972] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [26.86666666666667, 55.5, 1.0, 2.0, 0.4867511444264693, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 555127.6365237116, 555127.6365237116, 142683.2103514161]
[2019-03-22 22:38:54,975] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 22:38:54,979] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 4.935329e-32 4.593224e-37], sampled 0.8109820426046753
[2019-03-22 22:39:26,314] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.11630003], dtype=float32), -0.20627742]
[2019-03-22 22:39:26,314] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.66666666666666, 90.0, 1.0, 2.0, 0.7663534722333056, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 872366.3751490691, 872366.3751490691, 172393.6668257076]
[2019-03-22 22:39:26,315] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 22:39:26,320] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 1.0078377e-33 2.1289273e-24 3.0776196e-31], sampled 0.7341689851825044
[2019-03-22 22:39:28,172] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.11630003], dtype=float32), -0.20627742]
[2019-03-22 22:39:28,172] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [12.8, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 199493.5621724292, 199493.5621724292, 72019.39982052438]
[2019-03-22 22:39:28,173] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 22:39:28,176] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 1.523051e-37 0.000000e+00], sampled 0.9995175944325073
[2019-03-22 22:40:07,708] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.11630003], dtype=float32), -0.20627742]
[2019-03-22 22:40:07,708] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [28.2, 56.16666666666667, 1.0, 2.0, 0.5061700043625438, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 576893.0009884045, 576893.0009884045, 143291.9260216209]
[2019-03-22 22:40:07,709] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 22:40:07,712] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.1365982e-31 1.0511909e-36], sampled 0.03521835284738317
[2019-03-22 22:40:12,552] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1147 1656209757.7786 80.0000
[2019-03-22 22:40:12,808] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.1205 1706011712.0071 465.0000
[2019-03-22 22:40:12,813] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-22 22:40:12,950] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2492 1773187030.7201 173.0000
[2019-03-22 22:40:13,050] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3485 1683325900.1134 214.0000
[2019-03-22 22:40:14,065] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 200000, evaluation results [200000.0, 8512.249193409023, 1773187030.7201214, 173.0, 9061.114669779829, 1656209757.7786272, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8596.120523818729, 1706011712.007094, 465.0, 8574.348472942609, 1683325900.1133502, 214.0]
[2019-03-22 22:40:14,092] A3C_AGENT_WORKER-Thread-13 INFO:Local step 12500, global step 200016: loss 0.0434
[2019-03-22 22:40:14,095] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 12500, global step 200017: learning rate 0.0010
[2019-03-22 22:40:14,106] A3C_AGENT_WORKER-Thread-22 INFO:Local step 12500, global step 200021: loss 0.0543
[2019-03-22 22:40:14,113] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 12500, global step 200022: learning rate 0.0010
[2019-03-22 22:40:14,115] A3C_AGENT_WORKER-Thread-9 INFO:Local step 12500, global step 200024: loss 0.0752
[2019-03-22 22:40:14,120] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 12500, global step 200024: learning rate 0.0010
[2019-03-22 22:40:14,125] A3C_AGENT_WORKER-Thread-15 INFO:Local step 12500, global step 200028: loss 0.0027
[2019-03-22 22:40:14,128] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 12500, global step 200028: learning rate 0.0010
[2019-03-22 22:40:14,136] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 2.3732832e-35 1.8173997e-33 7.0110706e-38], sum to 1.0000
[2019-03-22 22:40:14,147] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9173
[2019-03-22 22:40:14,155] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.2, 70.66666666666667, 1.0, 2.0, 0.4525117243922129, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 516082.6810059867, 516082.6810059867, 134589.2335200417], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7507200.0000, 
sim time next is 7507800.0000, 
raw observation next is [24.1, 71.5, 1.0, 2.0, 0.4540598878160192, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 517879.6437557714, 517879.6437557714, 134819.2941018456], 
processed observation next is [0.0, 0.9130434782608695, 0.7318181818181819, 0.715, 1.0, 1.0, 0.317574859770024, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1918072754651005, 0.1918072754651005, 0.3288275465898673], 
reward next is 0.6712, 
noisyNet noise sample is [array([0.06850356], dtype=float32), -1.2818223]. 
=============================================
[2019-03-22 22:40:14,410] A3C_AGENT_WORKER-Thread-18 INFO:Local step 12500, global step 200137: loss 0.0282
[2019-03-22 22:40:14,413] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 12500, global step 200138: learning rate 0.0010
[2019-03-22 22:40:14,424] A3C_AGENT_WORKER-Thread-12 INFO:Local step 12500, global step 200142: loss 0.0660
[2019-03-22 22:40:14,428] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 12500, global step 200142: learning rate 0.0010
[2019-03-22 22:40:14,476] A3C_AGENT_WORKER-Thread-17 INFO:Local step 12500, global step 200161: loss 0.1233
[2019-03-22 22:40:14,479] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 12500, global step 200162: learning rate 0.0010
[2019-03-22 22:40:14,549] A3C_AGENT_WORKER-Thread-20 INFO:Local step 12500, global step 200188: loss 0.0897
[2019-03-22 22:40:14,553] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 12500, global step 200190: learning rate 0.0010
[2019-03-22 22:40:20,741] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 3.808671e-30 8.015494e-35], sum to 1.0000
[2019-03-22 22:40:20,749] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4804
[2019-03-22 22:40:20,760] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 94.0, 1.0, 2.0, 0.4260671260385807, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 483981.3286240124, 483981.3286240124, 129656.836226231], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7593600.0000, 
sim time next is 7594200.0000, 
raw observation next is [20.0, 94.5, 1.0, 2.0, 0.4296281300568536, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 488201.9236421685, 488201.9236421685, 130147.7679519947], 
processed observation next is [0.0, 0.9130434782608695, 0.5454545454545454, 0.945, 1.0, 1.0, 0.2870351625710669, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18081552727487724, 0.18081552727487724, 0.3174335803707188], 
reward next is 0.6826, 
noisyNet noise sample is [array([0.39952362], dtype=float32), 0.639317]. 
=============================================
[2019-03-22 22:40:27,086] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.5197878e-31 0.0000000e+00], sum to 1.0000
[2019-03-22 22:40:27,103] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6824
[2019-03-22 22:40:27,110] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 93.0, 1.0, 2.0, 0.4407139699946828, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 501734.1074849449, 501734.1074849449, 132108.725417749], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7689600.0000, 
sim time next is 7690200.0000, 
raw observation next is [20.5, 92.5, 1.0, 2.0, 0.4368992372754404, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 497232.2300953661, 497232.2300953664, 131558.7512803515], 
processed observation next is [1.0, 0.0, 0.5681818181818182, 0.925, 1.0, 1.0, 0.29612404659430047, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18416008522050595, 0.1841600852205061, 0.3208750031228086], 
reward next is 0.6791, 
noisyNet noise sample is [array([0.97455084], dtype=float32), 0.0043105907]. 
=============================================
[2019-03-22 22:40:31,443] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.00000e+00 1.00000e+00 0.00000e+00 3.00391e-37 0.00000e+00], sum to 1.0000
[2019-03-22 22:40:31,459] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3822
[2019-03-22 22:40:31,470] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.6, 49.0, 1.0, 2.0, 0.3013042007309557, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 327172.3318229844, 327172.3318229844, 95682.64743009555], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7754400.0000, 
sim time next is 7755000.0000, 
raw observation next is [21.23333333333334, 50.16666666666667, 1.0, 2.0, 0.3007723331743212, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 326594.6074472924, 326594.6074472927, 94383.26778052784], 
processed observation next is [1.0, 0.782608695652174, 0.6015151515151519, 0.5016666666666667, 1.0, 1.0, 0.12596541646790152, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12096096572121942, 0.12096096572121952, 0.23020309214762888], 
reward next is 0.7698, 
noisyNet noise sample is [array([0.12507884], dtype=float32), 1.9256876]. 
=============================================
[2019-03-22 22:40:31,487] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[71.63384 ]
 [71.638084]
 [71.678246]
 [71.72111 ]
 [71.68263 ]], R is [[71.70630646]
 [71.755867  ]
 [71.80718231]
 [71.86034393]
 [71.9146347 ]].
[2019-03-22 22:40:31,966] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 22:40:31,980] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2319
[2019-03-22 22:40:31,988] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 57.0, 1.0, 2.0, 0.2634547819740115, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 286061.3065405964, 286061.3065405966, 82893.75139396286], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7762200.0000, 
sim time next is 7762800.0000, 
raw observation next is [18.8, 57.00000000000001, 1.0, 2.0, 0.2637373726887939, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 286368.2361327061, 286368.2361327064, 82922.64395202066], 
processed observation next is [1.0, 0.8695652173913043, 0.49090909090909096, 0.5700000000000001, 1.0, 1.0, 0.07967171586099234, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10606230967878004, 0.10606230967878015, 0.20225035110248943], 
reward next is 0.7977, 
noisyNet noise sample is [array([0.33339852], dtype=float32), 0.7715253]. 
=============================================
[2019-03-22 22:40:33,483] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 2.417211e-37 0.000000e+00], sum to 1.0000
[2019-03-22 22:40:33,494] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2063
[2019-03-22 22:40:33,497] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.1, 71.5, 1.0, 2.0, 0.2272084861113551, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 246694.8076583036, 246694.8076583033, 76584.23276568142], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7776600.0000, 
sim time next is 7777200.0000, 
raw observation next is [16.1, 71.0, 1.0, 2.0, 0.2264193013020804, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 245837.722608995, 245837.7226089953, 76315.42309985054], 
processed observation next is [1.0, 0.0, 0.3681818181818182, 0.71, 1.0, 1.0, 0.03302412662760049, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09105100837370185, 0.09105100837370196, 0.18613517829231838], 
reward next is 0.8139, 
noisyNet noise sample is [array([0.25229442], dtype=float32), 1.7041545]. 
=============================================
[2019-03-22 22:40:33,707] A3C_AGENT_WORKER-Thread-21 INFO:Local step 13000, global step 207669: loss 0.4762
[2019-03-22 22:40:33,712] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 13000, global step 207669: learning rate 0.0010
[2019-03-22 22:40:34,187] A3C_AGENT_WORKER-Thread-3 INFO:Local step 13000, global step 207857: loss 0.1124
[2019-03-22 22:40:34,190] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 13000, global step 207857: learning rate 0.0010
[2019-03-22 22:40:34,220] A3C_AGENT_WORKER-Thread-14 INFO:Local step 13000, global step 207869: loss 0.1664
[2019-03-22 22:40:34,223] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 13000, global step 207870: learning rate 0.0010
[2019-03-22 22:40:34,223] A3C_AGENT_WORKER-Thread-2 INFO:Local step 13000, global step 207870: loss 0.1206
[2019-03-22 22:40:34,230] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 13000, global step 207870: learning rate 0.0010
[2019-03-22 22:40:34,321] A3C_AGENT_WORKER-Thread-19 INFO:Local step 13000, global step 207907: loss 0.1997
[2019-03-22 22:40:34,323] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 13000, global step 207908: learning rate 0.0010
[2019-03-22 22:40:34,414] A3C_AGENT_WORKER-Thread-11 INFO:Local step 13000, global step 207946: loss 0.2152
[2019-03-22 22:40:34,420] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 13000, global step 207946: learning rate 0.0010
[2019-03-22 22:40:34,459] A3C_AGENT_WORKER-Thread-16 INFO:Local step 13000, global step 207959: loss 0.2656
[2019-03-22 22:40:34,466] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 13000, global step 207959: learning rate 0.0010
[2019-03-22 22:40:34,499] A3C_AGENT_WORKER-Thread-9 INFO:Local step 13000, global step 207973: loss 0.3333
[2019-03-22 22:40:34,506] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 13000, global step 207976: learning rate 0.0010
[2019-03-22 22:40:34,557] A3C_AGENT_WORKER-Thread-13 INFO:Local step 13000, global step 207998: loss 0.2850
[2019-03-22 22:40:34,562] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 13000, global step 207999: learning rate 0.0010
[2019-03-22 22:40:34,613] A3C_AGENT_WORKER-Thread-22 INFO:Local step 13000, global step 208019: loss 0.2310
[2019-03-22 22:40:34,626] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 13000, global step 208021: learning rate 0.0010
[2019-03-22 22:40:34,641] A3C_AGENT_WORKER-Thread-10 INFO:Local step 13000, global step 208027: loss 0.3094
[2019-03-22 22:40:34,645] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 13000, global step 208027: learning rate 0.0010
[2019-03-22 22:40:34,734] A3C_AGENT_WORKER-Thread-15 INFO:Local step 13000, global step 208064: loss 0.2351
[2019-03-22 22:40:34,736] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 13000, global step 208064: learning rate 0.0010
[2019-03-22 22:40:34,891] A3C_AGENT_WORKER-Thread-18 INFO:Local step 13000, global step 208123: loss 0.2219
[2019-03-22 22:40:34,895] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 13000, global step 208124: learning rate 0.0010
[2019-03-22 22:40:34,960] A3C_AGENT_WORKER-Thread-12 INFO:Local step 13000, global step 208150: loss 0.2134
[2019-03-22 22:40:34,964] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 13000, global step 208150: learning rate 0.0010
[2019-03-22 22:40:35,003] A3C_AGENT_WORKER-Thread-17 INFO:Local step 13000, global step 208169: loss 0.1923
[2019-03-22 22:40:35,006] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 13000, global step 208170: learning rate 0.0010
[2019-03-22 22:40:35,074] A3C_AGENT_WORKER-Thread-20 INFO:Local step 13000, global step 208196: loss 0.2201
[2019-03-22 22:40:35,077] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 13000, global step 208196: learning rate 0.0010
[2019-03-22 22:40:44,320] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.0177784e-33 1.0000000e+00 2.8266493e-32 6.9192096e-11 3.9842544e-24], sum to 1.0000
[2019-03-22 22:40:44,330] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7222
[2019-03-22 22:40:44,336] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.2, 80.0, 1.0, 2.0, 0.3433032002095644, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 379559.5120849389, 379559.5120849389, 116619.7040335433], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7946400.0000, 
sim time next is 7947000.0000, 
raw observation next is [19.1, 79.5, 1.0, 2.0, 0.3364177068271973, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 370945.6715920239, 370945.6715920242, 115708.5361232433], 
processed observation next is [1.0, 1.0, 0.5045454545454546, 0.795, 1.0, 1.0, 0.1705221335339966, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13738728577482368, 0.1373872857748238, 0.28221594176400805], 
reward next is 0.7178, 
noisyNet noise sample is [array([-0.6049031], dtype=float32), -0.78362817]. 
=============================================
[2019-03-22 22:40:44,352] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[65.2368  ]
 [65.28678 ]
 [65.33013 ]
 [65.360756]
 [65.40778 ]], R is [[65.25011444]
 [65.31317139]
 [65.37313843]
 [65.42933655]
 [65.48014832]].
[2019-03-22 22:40:44,898] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 22:40:44,899] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:40:44,900] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run2
[2019-03-22 22:40:45,331] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 22:40:45,332] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:40:45,334] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run2
[2019-03-22 22:40:45,389] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 22:40:45,389] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:40:45,391] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run2
[2019-03-22 22:40:45,437] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 22:40:45,437] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:40:45,439] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run2
[2019-03-22 22:40:45,462] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 22:40:45,462] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:40:45,464] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run2
[2019-03-22 22:40:45,492] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 22:40:45,492] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:40:45,494] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run2
[2019-03-22 22:40:45,509] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 22:40:45,509] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:40:45,512] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run2
[2019-03-22 22:40:45,537] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 22:40:45,537] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:40:45,539] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run2
[2019-03-22 22:40:45,588] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 22:40:45,589] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:40:45,590] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run2
[2019-03-22 22:40:45,607] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 22:40:45,608] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 22:40:45,608] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:40:45,608] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:40:45,610] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run2
[2019-03-22 22:40:45,611] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run2
[2019-03-22 22:40:45,643] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 22:40:45,645] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:40:45,646] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run2
[2019-03-22 22:40:45,662] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 22:40:45,663] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:40:45,664] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run2
[2019-03-22 22:40:45,686] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 22:40:45,686] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:40:45,688] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run2
[2019-03-22 22:40:45,710] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 22:40:45,710] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:40:45,712] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run2
[2019-03-22 22:40:45,731] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 22:40:45,732] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:40:45,734] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run2
[2019-03-22 22:40:47,858] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.1842891e-24 0.0000000e+00], sum to 1.0000
[2019-03-22 22:40:47,865] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4491
[2019-03-22 22:40:47,870] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.16666666666667, 99.00000000000001, 1.0, 2.0, 0.3982470326265929, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 441226.6053496612, 441226.6053496615, 121346.4317065424], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 15000.0000, 
sim time next is 15600.0000, 
raw observation next is [17.33333333333334, 98.0, 1.0, 2.0, 0.3831273535372345, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 424926.6573616679, 424926.6573616679, 120271.6975321613], 
processed observation next is [1.0, 0.17391304347826086, 0.42424242424242453, 0.98, 1.0, 1.0, 0.22890919192154308, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1573802434672844, 0.1573802434672844, 0.29334560373697877], 
reward next is 0.7067, 
noisyNet noise sample is [array([-0.0566441], dtype=float32), -0.8964049]. 
=============================================
[2019-03-22 22:40:48,258] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.1804877e-25 2.4905650e-38], sum to 1.0000
[2019-03-22 22:40:48,270] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5580
[2019-03-22 22:40:48,282] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.2, 92.0, 1.0, 2.0, 0.3388304157663543, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 370374.5747171245, 370374.5747171245, 114710.5160800163], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 12000.0000, 
sim time next is 12600.0000, 
raw observation next is [17.15, 94.0, 1.0, 2.0, 0.3412905856755625, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 374197.0404064208, 374197.0404064211, 115291.5377216183], 
processed observation next is [1.0, 0.13043478260869565, 0.41590909090909084, 0.94, 1.0, 1.0, 0.17661323209445307, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13859149644682253, 0.13859149644682264, 0.28119887249175196], 
reward next is 0.7188, 
noisyNet noise sample is [array([-0.8586448], dtype=float32), -0.4597604]. 
=============================================
[2019-03-22 22:40:50,604] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.6940470e-37 9.7022969e-01 3.1253111e-33 2.9770283e-02 8.2201263e-27], sum to 1.0000
[2019-03-22 22:40:50,616] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0776
[2019-03-22 22:40:50,622] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 78.0, 1.0, 2.0, 0.7976717250269119, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 900781.1432157028, 900781.1432157028, 172018.5576469767], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 48000.0000, 
sim time next is 48600.0000, 
raw observation next is [21.0, 78.0, 1.0, 2.0, 0.8597977885455421, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 971353.5013658251, 971353.5013658251, 181422.0536080012], 
processed observation next is [1.0, 0.5652173913043478, 0.5909090909090909, 0.78, 1.0, 1.0, 0.8247472356819276, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3597605560614167, 0.3597605560614167, 0.4424928136780517], 
reward next is 0.5575, 
noisyNet noise sample is [array([-0.9917693], dtype=float32), 0.357661]. 
=============================================
[2019-03-22 22:40:57,332] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.2822851e-33 1.0000000e+00 1.1139487e-28 2.2733152e-08 3.4484432e-22], sum to 1.0000
[2019-03-22 22:40:57,348] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5576
[2019-03-22 22:40:57,363] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 40.5, 1.0, 2.0, 0.7292823569229089, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 792272.808342057, 792272.8083420567, 140042.3745130112], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 145800.0000, 
sim time next is 146400.0000, 
raw observation next is [22.33333333333334, 41.33333333333333, 1.0, 2.0, 0.721375858075303, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 783676.4723637482, 783676.4723637486, 139024.9072993421], 
processed observation next is [1.0, 0.6956521739130435, 0.6515151515151518, 0.4133333333333333, 1.0, 1.0, 0.6517198225941286, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.29025054531990674, 0.2902505453199069, 0.33908513975449295], 
reward next is 0.6609, 
noisyNet noise sample is [array([-0.14192739], dtype=float32), -1.0945746]. 
=============================================
[2019-03-22 22:41:08,397] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 4.9496087e-29 4.7667505e-22 4.1502092e-26], sum to 1.0000
[2019-03-22 22:41:08,412] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4629
[2019-03-22 22:41:08,421] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 47.0, 1.0, 2.0, 0.2544651459166911, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 276297.5152451047, 276297.5152451047, 84340.84794374097], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 307200.0000, 
sim time next is 307800.0000, 
raw observation next is [21.0, 46.0, 1.0, 2.0, 0.2546378112402543, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 276485.0480412148, 276485.0480412148, 83481.32024831037], 
processed observation next is [0.0, 0.5652173913043478, 0.5909090909090909, 0.46, 1.0, 1.0, 0.06829726405031787, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10240186964489438, 0.10240186964489438, 0.20361297621539115], 
reward next is 0.7964, 
noisyNet noise sample is [array([-0.2056741], dtype=float32), 0.3030778]. 
=============================================
[2019-03-22 22:41:11,414] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.5928609e-35 1.0000000e+00 5.3259680e-33 3.6689990e-23 2.0094468e-25], sum to 1.0000
[2019-03-22 22:41:11,424] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7188
[2019-03-22 22:41:11,428] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.33333333333333, 73.0, 1.0, 2.0, 0.4013425615439996, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 435848.0570052839, 435848.0570052839, 87132.82908379873], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 355200.0000, 
sim time next is 355800.0000, 
raw observation next is [12.16666666666667, 74.5, 1.0, 2.0, 0.3989642651722201, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 433264.1353941091, 433264.1353941091, 86884.34481548284], 
processed observation next is [1.0, 0.08695652173913043, 0.18939393939393953, 0.745, 1.0, 1.0, 0.24870533146527513, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1604681982941145, 0.1604681982941145, 0.211913036135324], 
reward next is 0.7881, 
noisyNet noise sample is [array([1.289538], dtype=float32), 0.6101239]. 
=============================================
[2019-03-22 22:41:12,156] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.8702832e-32 1.0000000e+00 4.5955304e-25 2.5913343e-12 2.2075861e-17], sum to 1.0000
[2019-03-22 22:41:12,165] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5656
[2019-03-22 22:41:12,170] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.0, 76.0, 1.0, 2.0, 0.4036793678666473, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 438386.9147525621, 438386.9147525624, 87338.52293764117], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 366000.0000, 
sim time next is 366600.0000, 
raw observation next is [12.0, 76.0, 1.0, 2.0, 0.4045741202479435, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 439359.0352040612, 439359.0352040612, 87422.60501869289], 
processed observation next is [1.0, 0.21739130434782608, 0.18181818181818182, 0.76, 1.0, 1.0, 0.2557176503099293, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16272556859409673, 0.16272556859409673, 0.21322586589925097], 
reward next is 0.7868, 
noisyNet noise sample is [array([-0.35558113], dtype=float32), -1.4617553]. 
=============================================
[2019-03-22 22:41:12,987] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 3.5157452e-38 1.2595659e-21 3.5875283e-27], sum to 1.0000
[2019-03-22 22:41:12,995] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8363
[2019-03-22 22:41:12,999] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.33333333333333, 52.66666666666667, 1.0, 2.0, 0.3134383769773016, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 340352.8849060478, 340352.8849060478, 84373.13666761125], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 385800.0000, 
sim time next is 386400.0000, 
raw observation next is [18.66666666666667, 53.33333333333334, 1.0, 2.0, 0.3273420636274033, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 355455.9793134736, 355455.9793134733, 87035.19037939725], 
processed observation next is [1.0, 0.4782608695652174, 0.4848484848484851, 0.5333333333333334, 1.0, 1.0, 0.15917757953425413, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13165036270869393, 0.13165036270869382, 0.21228095214487133], 
reward next is 0.7877, 
noisyNet noise sample is [array([0.10069977], dtype=float32), 0.5194127]. 
=============================================
[2019-03-22 22:41:14,958] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.51023841e-34 1.00000000e+00 1.07813121e-31 1.09757005e-13
 5.96834278e-21], sum to 1.0000
[2019-03-22 22:41:14,965] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6722
[2019-03-22 22:41:14,977] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 100.0, 1.0, 2.0, 0.3681674054140427, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 399805.8486275278, 399805.8486275278, 96160.51015611415], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 484800.0000, 
sim time next is 485400.0000, 
raw observation next is [14.0, 100.0, 1.0, 2.0, 0.3655832532680859, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 396998.4819075973, 396998.4819075976, 95814.59698060619], 
processed observation next is [1.0, 0.6086956521739131, 0.2727272727272727, 1.0, 1.0, 1.0, 0.20697906658510734, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1470364747805916, 0.1470364747805917, 0.23369413897708827], 
reward next is 0.7663, 
noisyNet noise sample is [array([-0.19612314], dtype=float32), -1.2156885]. 
=============================================
[2019-03-22 22:41:19,860] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-22 22:41:19,868] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-22 22:41:19,871] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:41:19,872] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-22 22:41:19,874] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-22 22:41:19,875] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:41:19,875] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:41:19,878] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-22 22:41:19,877] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-22 22:41:19,879] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:41:19,880] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:41:19,885] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run10
[2019-03-22 22:41:19,904] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run10
[2019-03-22 22:41:19,906] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run10
[2019-03-22 22:41:19,922] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run10
[2019-03-22 22:41:19,943] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run10
[2019-03-22 22:42:19,243] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.3174083], dtype=float32), -0.0988662]
[2019-03-22 22:42:19,244] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.53313127, 85.25627339000002, 1.0, 2.0, 0.4149905183623588, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 471855.7766409019, 471855.7766409019, 133314.4343687252]
[2019-03-22 22:42:19,245] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 22:42:19,249] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 5.5562635e-26 5.6363353e-35], sampled 0.6700521004426954
[2019-03-22 22:42:40,310] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.3174083], dtype=float32), -0.0988662]
[2019-03-22 22:42:40,310] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [26.66666666666667, 65.66666666666667, 1.0, 2.0, 0.5218380826145657, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 594123.4860657229, 594123.4860657229, 145742.1117716992]
[2019-03-22 22:42:40,311] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 22:42:40,315] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 6.3930593e-38 9.2920533e-24 2.4535399e-33], sampled 0.6920078581791245
[2019-03-22 22:43:23,461] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8511.2006 1773125597.9331 173.0000
[2019-03-22 22:43:23,563] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-22 22:43:23,566] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.6114 1705915178.0512 463.0000
[2019-03-22 22:43:23,670] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1147 1656209757.7786 80.0000
[2019-03-22 22:43:23,713] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8576.5099 1683038559.7237 211.0000
[2019-03-22 22:43:24,728] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 225000, evaluation results [225000.0, 8511.200619874178, 1773125597.933107, 173.0, 9061.114669779829, 1656209757.7786272, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.61139901066, 1705915178.0512094, 463.0, 8576.509925841292, 1683038559.723658, 211.0]
[2019-03-22 22:43:25,220] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.2089893e-38 9.8660477e-25 9.7637949e-33], sum to 1.0000
[2019-03-22 22:43:25,229] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7130
[2019-03-22 22:43:25,236] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.83333333333333, 95.0, 1.0, 2.0, 0.2174339369115658, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 236079.3778573271, 236079.3778573269, 76652.31302033232], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 533400.0000, 
sim time next is 534000.0000, 
raw observation next is [13.66666666666667, 96.0, 1.0, 2.0, 0.2124579870288766, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 230675.4481465858, 230675.4481465855, 75963.14582182984], 
processed observation next is [1.0, 0.17391304347826086, 0.25757575757575774, 0.96, 1.0, 1.0, 0.015572483786095749, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08543535116540216, 0.08543535116540203, 0.18527596541909716], 
reward next is 0.8147, 
noisyNet noise sample is [array([-0.12808278], dtype=float32), 1.2332531]. 
=============================================
[2019-03-22 22:43:25,245] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[71.66761 ]
 [71.70558 ]
 [71.742325]
 [71.79266 ]
 [71.84027 ]], R is [[71.74243164]
 [71.83805084]
 [71.93331909]
 [72.02754211]
 [72.12069702]].
[2019-03-22 22:43:31,649] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.0017138e-35 1.0000000e+00 1.8488513e-27 1.4280965e-11 7.3494581e-27], sum to 1.0000
[2019-03-22 22:43:31,663] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4775
[2019-03-22 22:43:31,668] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.83333333333334, 51.16666666666667, 1.0, 2.0, 0.8761942696788816, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 985407.5946260479, 985407.5946260479, 181557.6298455923], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 658200.0000, 
sim time next is 658800.0000, 
raw observation next is [25.0, 50.0, 1.0, 2.0, 0.8691320172362696, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 976901.4015197947, 976901.4015197947, 180218.2552593128], 
processed observation next is [1.0, 0.6521739130434783, 0.7727272727272727, 0.5, 1.0, 1.0, 0.836415021545337, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3618153338962203, 0.3618153338962203, 0.4395567201446654], 
reward next is 0.5604, 
noisyNet noise sample is [array([0.76830715], dtype=float32), -0.95537275]. 
=============================================
[2019-03-22 22:43:34,727] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 2.254453e-24 6.116350e-32], sum to 1.0000
[2019-03-22 22:43:34,746] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0521
[2019-03-22 22:43:34,755] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 54.00000000000001, 1.0, 2.0, 0.3570614532631875, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 398743.653440301, 398743.6534403013, 119323.6220791017], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 674400.0000, 
sim time next is 675000.0000, 
raw observation next is [24.0, 54.0, 1.0, 2.0, 0.3603318432004838, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 402399.7669560779, 402399.7669560777, 119591.2852842359], 
processed observation next is [1.0, 0.8260869565217391, 0.7272727272727273, 0.54, 1.0, 1.0, 0.2004148040006047, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1490369507244733, 0.14903695072447323, 0.29168606166886807], 
reward next is 0.7083, 
noisyNet noise sample is [array([0.46590644], dtype=float32), -0.90665346]. 
=============================================
[2019-03-22 22:43:34,766] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[78.073555]
 [78.111855]
 [78.0827  ]
 [78.1363  ]
 [78.26779 ]], R is [[77.92948914]
 [77.85916138]
 [77.78951263]
 [77.7202301 ]
 [77.65103149]].
[2019-03-22 22:43:36,536] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 6.3166193e-25 4.8244237e-17 1.0973086e-24], sum to 1.0000
[2019-03-22 22:43:36,546] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8919
[2019-03-22 22:43:36,560] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 54.5, 1.0, 2.0, 0.4207321994038681, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 470742.1919842254, 470742.1919842256, 125130.4178360193], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 651000.0000, 
sim time next is 651600.0000, 
raw observation next is [24.0, 54.0, 1.0, 2.0, 0.4696473163292594, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 525076.7476214888, 525076.7476214888, 129507.3613147756], 
processed observation next is [1.0, 0.5652173913043478, 0.7272727272727273, 0.54, 1.0, 1.0, 0.33705914541157417, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1944728694894403, 0.1944728694894403, 0.3158716129628673], 
reward next is 0.6841, 
noisyNet noise sample is [array([0.7301281], dtype=float32), 0.15795068]. 
=============================================
[2019-03-22 22:43:51,718] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 6.4488335e-30 5.7409909e-36], sum to 1.0000
[2019-03-22 22:43:51,726] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1139
[2019-03-22 22:43:51,733] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.5, 91.0, 1.0, 2.0, 0.397842992404662, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 448927.8060381822, 448927.8060381825, 124986.4763372672], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 869400.0000, 
sim time next is 870000.0000, 
raw observation next is [19.66666666666666, 90.0, 1.0, 2.0, 0.398400083759033, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 449757.1277672657, 449757.1277672654, 125149.6602856817], 
processed observation next is [0.0, 0.043478260869565216, 0.53030303030303, 0.9, 1.0, 1.0, 0.24800010469879125, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16657671398787618, 0.16657671398787607, 0.30524307386751637], 
reward next is 0.6948, 
noisyNet noise sample is [array([2.2121782], dtype=float32), 0.8082078]. 
=============================================
[2019-03-22 22:43:51,758] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[70.578606]
 [70.651405]
 [70.65166 ]
 [70.674355]
 [70.64516 ]], R is [[70.49539185]
 [70.48558807]
 [70.47632599]
 [70.4675827 ]
 [70.45875549]].
[2019-03-22 22:43:54,526] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.3372638e-28 1.8188623e-34], sum to 1.0000
[2019-03-22 22:43:54,539] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0541
[2019-03-22 22:43:54,548] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 78.0, 1.0, 2.0, 0.4207531146341484, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 477854.9397061106, 477854.9397061106, 129067.7339261814], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 922800.0000, 
sim time next is 923400.0000, 
raw observation next is [22.0, 78.0, 1.0, 2.0, 0.4205261525713064, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 477596.632462753, 477596.632462753, 129045.3115916112], 
processed observation next is [0.0, 0.6956521739130435, 0.6363636363636364, 0.78, 1.0, 1.0, 0.27565769071413293, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17688764165287146, 0.17688764165287146, 0.3147446624185639], 
reward next is 0.6853, 
noisyNet noise sample is [array([-0.1599008], dtype=float32), -0.6253754]. 
=============================================
[2019-03-22 22:44:01,788] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.8911365e-27 6.8367774e-32], sum to 1.0000
[2019-03-22 22:44:01,794] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0863
[2019-03-22 22:44:01,803] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 94.0, 1.0, 2.0, 0.2007832028598781, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 217996.7552727728, 217996.7552727731, 72219.32742409389], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1029600.0000, 
sim time next is 1030200.0000, 
raw observation next is [13.0, 94.00000000000001, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 214758.466735268, 214758.4667352683, 71717.11296587366], 
processed observation next is [1.0, 0.9565217391304348, 0.22727272727272727, 0.9400000000000002, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07954017286491408, 0.07954017286491419, 0.17491978772164307], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2563788], dtype=float32), 1.500507]. 
=============================================
[2019-03-22 22:44:04,234] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.3742833e-37 4.7274138e-24 2.4416655e-24], sum to 1.0000
[2019-03-22 22:44:04,248] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1144
[2019-03-22 22:44:04,254] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.83333333333333, 89.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 204860.326698278, 204860.3266982783, 70792.40557364283], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1061400.0000, 
sim time next is 1062000.0000, 
raw observation next is [14.0, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 206347.7515168814, 206347.7515168817, 71223.34684343611], 
processed observation next is [1.0, 0.30434782608695654, 0.2727272727272727, 0.88, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07642509315440052, 0.07642509315440063, 0.17371548010594173], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.06499957], dtype=float32), -0.28278914]. 
=============================================
[2019-03-22 22:44:04,288] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[57.03105 ]
 [57.052204]
 [57.11521 ]
 [57.128967]
 [57.018417]], R is [[56.48512268]
 [55.92027283]
 [55.36106873]
 [54.80745697]
 [54.25938416]].
[2019-03-22 22:44:15,044] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.0547980e-32 2.3490285e-34], sum to 1.0000
[2019-03-22 22:44:15,054] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8085
[2019-03-22 22:44:15,058] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 97.0, 1.0, 2.0, 0.3749921202029073, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 419469.2839158336, 419469.2839158339, 121110.6124046775], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1290600.0000, 
sim time next is 1291200.0000, 
raw observation next is [18.0, 96.0, 1.0, 2.0, 0.3725725530435011, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 416158.528658566, 416158.5286585663, 120637.4910260988], 
processed observation next is [1.0, 0.9565217391304348, 0.45454545454545453, 0.96, 1.0, 1.0, 0.21571569130437637, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1541327883920615, 0.1541327883920616, 0.29423778299048486], 
reward next is 0.7058, 
noisyNet noise sample is [array([0.6991235], dtype=float32), 1.6204447]. 
=============================================
[2019-03-22 22:44:18,261] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.5875886e-36 1.5807058e-28 3.4970261e-34], sum to 1.0000
[2019-03-22 22:44:18,269] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0186
[2019-03-22 22:44:18,277] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 62.0, 1.0, 2.0, 0.4881269404630141, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 556416.7832407503, 556416.7832407501, 141059.6510149435], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1273200.0000, 
sim time next is 1273800.0000, 
raw observation next is [27.0, 62.0, 1.0, 2.0, 0.4918959455501623, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 560715.0427291199, 560715.0427291199, 141497.9863878386], 
processed observation next is [1.0, 0.7391304347826086, 0.8636363636363636, 0.62, 1.0, 1.0, 0.36486993193770284, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20767223804782217, 0.20767223804782217, 0.34511703997033805], 
reward next is 0.6549, 
noisyNet noise sample is [array([0.31157005], dtype=float32), -0.9605341]. 
=============================================
[2019-03-22 22:44:25,925] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.1949625e-32 5.1155843e-34], sum to 1.0000
[2019-03-22 22:44:25,938] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7517
[2019-03-22 22:44:25,946] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4900237159042586, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 559093.2280906494, 559093.2280906494, 140339.440657704], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1387800.0000, 
sim time next is 1388400.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.4903943248721098, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 559516.2396494407, 559516.2396494405, 140382.1529747561], 
processed observation next is [0.0, 0.043478260869565216, 0.5909090909090909, 1.0, 1.0, 1.0, 0.36299290609013724, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20722823690720027, 0.2072282369072002, 0.34239549506038075], 
reward next is 0.6576, 
noisyNet noise sample is [array([0.9513045], dtype=float32), 1.2628461]. 
=============================================
[2019-03-22 22:44:28,326] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.5522878e-35 2.2162748e-34], sum to 1.0000
[2019-03-22 22:44:28,338] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9184
[2019-03-22 22:44:28,345] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.83333333333333, 84.0, 1.0, 2.0, 0.5163759435443515, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 587938.3514546127, 587938.3514546123, 145049.4242709595], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1421400.0000, 
sim time next is 1422000.0000, 
raw observation next is [24.0, 83.0, 1.0, 2.0, 0.5168726633754579, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 588438.3445232944, 588438.3445232946, 145159.603319414], 
processed observation next is [0.0, 0.4782608695652174, 0.7272727272727273, 0.83, 1.0, 1.0, 0.3960908292193223, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21794012760122014, 0.21794012760122022, 0.3540478129741805], 
reward next is 0.6460, 
noisyNet noise sample is [array([1.4253383], dtype=float32), 0.80591476]. 
=============================================
[2019-03-22 22:44:28,358] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[63.489418]
 [63.49819 ]
 [63.50503 ]
 [63.511326]
 [63.51853 ]], R is [[63.5059433 ]
 [63.5171051 ]
 [63.52830505]
 [63.539505  ]
 [63.55092621]].
[2019-03-22 22:44:28,525] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-22 22:44:28,529] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-22 22:44:28,531] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:44:28,533] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-22 22:44:28,535] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-22 22:44:28,534] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-22 22:44:28,538] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-22 22:44:28,537] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:44:28,539] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:44:28,542] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:44:28,540] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:44:28,557] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run11
[2019-03-22 22:44:28,574] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run11
[2019-03-22 22:44:28,575] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run11
[2019-03-22 22:44:28,612] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run11
[2019-03-22 22:44:28,612] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run11
[2019-03-22 22:45:08,991] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.09133355], dtype=float32), -0.0954981]
[2019-03-22 22:45:08,992] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [28.31666666666667, 62.16666666666666, 1.0, 2.0, 0.5703485617287087, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9108637804897056, 7.010072958777482, 6.9112, 95.55300057982711, 1192114.221173821, 1152434.268046766, 270443.0827368022]
[2019-03-22 22:45:08,995] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 22:45:08,997] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 9.2151710e-24 4.8854395e-35], sampled 0.4710421385047273
[2019-03-22 22:45:08,999] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1192114.221173821 W.
[2019-03-22 22:45:20,492] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.09133355], dtype=float32), -0.0954981]
[2019-03-22 22:45:20,492] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [14.26398828166667, 90.01861517333334, 1.0, 2.0, 0.2480237495429999, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 269287.3105564056, 269287.3105564052, 84681.72580169281]
[2019-03-22 22:45:20,492] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 22:45:20,494] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.7577996230002445
[2019-03-22 22:45:45,034] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.09133355], dtype=float32), -0.0954981]
[2019-03-22 22:45:45,037] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [25.32034728666667, 60.11321990833333, 1.0, 2.0, 0.4281072661836893, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 486848.4060613294, 486848.4060613294, 134670.002006326]
[2019-03-22 22:45:45,037] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 22:45:45,040] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.0599564e-37 0.0000000e+00], sampled 0.17852957898156752
[2019-03-22 22:46:24,392] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.09133355], dtype=float32), -0.0954981]
[2019-03-22 22:46:24,394] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.510572665, 84.52825591000001, 1.0, 2.0, 0.3514590130844674, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 388436.6489448725, 388436.6489448722, 121509.119777716]
[2019-03-22 22:46:24,395] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 22:46:24,400] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.7917328936711516
[2019-03-22 22:46:32,416] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2492 1773187030.7201 173.0000
[2019-03-22 22:46:32,506] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-22 22:46:32,576] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1147 1656209757.7786 80.0000
[2019-03-22 22:46:32,727] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9309 1705967916.6745 465.0000
[2019-03-22 22:46:32,865] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-22 22:46:33,879] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 250000, evaluation results [250000.0, 8512.249193409023, 1773187030.7201214, 173.0, 9061.114669779829, 1656209757.7786272, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8596.930884973775, 1705967916.6744611, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-22 22:46:38,721] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 3.6469098e-38 7.6442375e-35 5.2204618e-34], sum to 1.0000
[2019-03-22 22:46:38,730] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8432
[2019-03-22 22:46:38,738] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 100.0, 1.0, 2.0, 0.4393252832915737, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 500687.5591286489, 500687.5591286492, 132614.6647174618], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1486200.0000, 
sim time next is 1486800.0000, 
raw observation next is [20.0, 100.0, 1.0, 2.0, 0.4401578927354424, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 501637.3154195556, 501637.3154195556, 132701.0575883019], 
processed observation next is [0.0, 0.21739130434782608, 0.5454545454545454, 1.0, 1.0, 1.0, 0.300197365919303, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1857915983035391, 0.1857915983035391, 0.323661116069029], 
reward next is 0.6763, 
noisyNet noise sample is [array([1.4727938], dtype=float32), -0.64637136]. 
=============================================
[2019-03-22 22:46:47,020] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.38448683e-36 1.00000000e+00 3.35090453e-19 1.02917705e-14
 2.37730881e-18], sum to 1.0000
[2019-03-22 22:46:47,031] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9910
[2019-03-22 22:46:47,040] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1151293.828606835 W.
[2019-03-22 22:46:47,045] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.0, 62.0, 1.0, 2.0, 0.5297182008872661, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9627589687595719, 6.932430471869117, 6.9112, 77.32839380130991, 1151293.828606835, 1144398.611791848, 263851.3723728245], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1605600.0000, 
sim time next is 1606200.0000, 
raw observation next is [27.0, 62.0, 1.0, 2.0, 0.7221337101938852, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9754343735610613, 6.911199999999999, 6.9112, 79.9714070182785, 1370308.76270012, 1370308.76270012, 294648.9406981179], 
processed observation next is [1.0, 0.6086956521739131, 0.8636363636363636, 0.62, 1.0, 1.0, 0.6526671377423565, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9649062479443733, -8.881784197001253e-17, 0.0, 0.5258059675217038, 0.5075217639630074, 0.5075217639630074, 0.7186559529222387], 
reward next is 0.2813, 
noisyNet noise sample is [array([0.3984583], dtype=float32), 0.054001987]. 
=============================================
[2019-03-22 22:46:50,993] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 9.266147e-38 1.080603e-36], sum to 1.0000
[2019-03-22 22:46:51,003] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6418
[2019-03-22 22:46:51,013] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.33333333333334, 86.66666666666667, 1.0, 2.0, 0.5099413959795429, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 571837.7592976615, 571837.7592976615, 134209.6560856178], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1671600.0000, 
sim time next is 1672200.0000, 
raw observation next is [19.0, 88.5, 1.0, 2.0, 0.5868703835635005, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 657681.9496089137, 657681.949608914, 142259.283505335], 
processed observation next is [1.0, 0.34782608695652173, 0.5, 0.885, 1.0, 1.0, 0.4835879794543756, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.24358590726256063, 0.24358590726256074, 0.3469738622081342], 
reward next is 0.6530, 
noisyNet noise sample is [array([-2.4876444], dtype=float32), -0.45955336]. 
=============================================
[2019-03-22 22:46:55,161] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 2.2568217e-37], sum to 1.0000
[2019-03-22 22:46:55,175] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8246
[2019-03-22 22:46:55,182] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [9.0, 71.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 148761.7633045556, 148761.7633045556, 57692.69487715534], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1734000.0000, 
sim time next is 1734600.0000, 
raw observation next is [9.0, 71.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 148598.1639636967, 148598.1639636969, 57666.618675635], 
processed observation next is [1.0, 0.043478260869565216, 0.045454545454545456, 0.71, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.055036357023591366, 0.05503635702359144, 0.14065028945276828], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.4605052], dtype=float32), -2.7760317]. 
=============================================
[2019-03-22 22:46:55,392] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 3.4341153e-33], sum to 1.0000
[2019-03-22 22:46:55,398] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8087
[2019-03-22 22:46:55,404] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [8.0, 81.0, 1.0, 2.0, 0.3290618638575187, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 357324.1714810968, 357324.1714810965, 77200.29902041587], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1740000.0000, 
sim time next is 1740600.0000, 
raw observation next is [8.0, 81.0, 1.0, 2.0, 0.3289944173467223, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 357250.9052531076, 357250.9052531073, 77202.99928950048], 
processed observation next is [1.0, 0.13043478260869565, 0.0, 0.81, 1.0, 1.0, 0.16124302168340285, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13231515009374356, 0.13231515009374345, 0.18829999826707436], 
reward next is 0.8117, 
noisyNet noise sample is [array([-0.89062685], dtype=float32), 0.5005695]. 
=============================================
[2019-03-22 22:47:04,580] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.3627195e-38 3.8353148e-34 3.5551327e-34], sum to 1.0000
[2019-03-22 22:47:04,591] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3616
[2019-03-22 22:47:04,602] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 47.33333333333334, 1.0, 2.0, 0.4352191223864313, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 472655.0440725543, 472655.0440725543, 113792.3284437084], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1862400.0000, 
sim time next is 1863000.0000, 
raw observation next is [22.5, 48.0, 1.0, 2.0, 0.4914315241354952, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 533736.1398290531, 533736.1398290531, 122972.4837889017], 
processed observation next is [1.0, 0.5652173913043478, 0.6590909090909091, 0.48, 1.0, 1.0, 0.3642894051693689, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19768005178853817, 0.19768005178853817, 0.29993288729000417], 
reward next is 0.7001, 
noisyNet noise sample is [array([-1.7235938], dtype=float32), -0.05643559]. 
=============================================
[2019-03-22 22:47:04,617] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[64.929665]
 [65.0245  ]
 [64.95506 ]
 [64.93375 ]
 [64.94766 ]], R is [[64.88305664]
 [64.95668793]
 [65.05091095]
 [65.1466217 ]
 [65.23755646]].
[2019-03-22 22:47:06,841] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 22:47:06,855] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9370
[2019-03-22 22:47:06,859] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 71.33333333333333, 1.0, 2.0, 0.2852572488578103, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 309742.1379636796, 309742.1379636799, 107085.9293260492], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1906800.0000, 
sim time next is 1907400.0000, 
raw observation next is [19.0, 72.16666666666667, 1.0, 2.0, 0.2888374084542975, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 313630.8520011691, 313630.8520011694, 109999.0954940097], 
processed observation next is [1.0, 0.043478260869565216, 0.5, 0.7216666666666667, 1.0, 1.0, 0.11104676056787187, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11615957481524782, 0.11615957481524793, 0.2682904768146578], 
reward next is 0.7317, 
noisyNet noise sample is [array([0.57965326], dtype=float32), 1.3130301]. 
=============================================
[2019-03-22 22:47:09,381] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 3.6019342e-23 7.4322721e-17 1.6189601e-24], sum to 1.0000
[2019-03-22 22:47:09,383] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6936
[2019-03-22 22:47:09,386] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1218400.181923689 W.
[2019-03-22 22:47:09,391] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.66666666666666, 76.33333333333334, 1.0, 2.0, 0.5348928042354174, 1.0, 2.0, 0.5348928042354174, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344351869, 1218400.181923689, 1218400.181923689, 238802.5802431914], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1943400.0000, 
sim time next is 1944000.0000, 
raw observation next is [24.0, 74.0, 1.0, 2.0, 0.6039810301192988, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9710269305385165, 6.911199999999999, 6.9112, 77.32846344354091, 1237524.342572536, 1237524.342572536, 272353.7899919759], 
processed observation next is [1.0, 0.5217391304347826, 0.7272727272727273, 0.74, 1.0, 1.0, 0.5049762876491235, 0.0, 0.5, -0.25, 1.0, 0.5, 0.9586099007693095, -8.881784197001253e-17, 0.0, 0.5084288129206532, 0.4583423491009393, 0.4583423491009393, 0.6642775365657948], 
reward next is 0.3357, 
noisyNet noise sample is [array([-0.7790167], dtype=float32), 0.61256945]. 
=============================================
[2019-03-22 22:47:09,430] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[48.8512  ]
 [48.43313 ]
 [47.85975 ]
 [47.02122 ]
 [47.365265]], R is [[48.2626152 ]
 [48.1975441 ]
 [48.13188934]
 [47.96274948]
 [47.80270004]].
[2019-03-22 22:47:14,510] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 22:47:14,519] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4153
[2019-03-22 22:47:14,523] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.7, 51.5, 1.0, 2.0, 0.302540847628208, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 328515.6032048526, 328515.6032048526, 101857.8654947354], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2057400.0000, 
sim time next is 2058000.0000, 
raw observation next is [21.46666666666667, 52.0, 1.0, 2.0, 0.2989033880609099, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 324564.5301464162, 324564.530146416, 99710.21119717359], 
processed observation next is [0.0, 0.8260869565217391, 0.6121212121212122, 0.52, 1.0, 1.0, 0.12362923507613734, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12020908523941341, 0.12020908523941333, 0.24319563706627703], 
reward next is 0.7568, 
noisyNet noise sample is [array([1.4038594], dtype=float32), -1.1587155]. 
=============================================
[2019-03-22 22:47:14,540] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[78.54567 ]
 [78.510086]
 [78.4732  ]
 [78.433464]
 [78.37985 ]], R is [[78.56045532]
 [78.52641296]
 [78.48723602]
 [78.44273376]
 [78.39229584]].
[2019-03-22 22:47:16,651] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 22:47:16,667] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9403
[2019-03-22 22:47:16,674] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 50.0, 1.0, 2.0, 0.3062407257859033, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 333129.9888656656, 333129.9888656659, 111820.5866665606], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2035800.0000, 
sim time next is 2036400.0000, 
raw observation next is [23.0, 51.0, 1.0, 2.0, 0.3055668565939638, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 333443.2306736806, 333443.2306736803, 112146.1514458017], 
processed observation next is [0.0, 0.5652173913043478, 0.6818181818181818, 0.51, 1.0, 1.0, 0.13195857074245476, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12349749284210393, 0.12349749284210382, 0.27352719864829683], 
reward next is 0.7265, 
noisyNet noise sample is [array([-0.8833441], dtype=float32), -0.035215117]. 
=============================================
[2019-03-22 22:47:23,117] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.3559842e-37 9.0821416e-38], sum to 1.0000
[2019-03-22 22:47:23,128] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5297
[2019-03-22 22:47:23,134] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 57.5, 1.0, 2.0, 0.4066450148784183, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 461026.6945226644, 461026.6945226647, 127118.4752269735], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2140200.0000, 
sim time next is 2140800.0000, 
raw observation next is [24.66666666666667, 58.66666666666667, 1.0, 2.0, 0.4034230153898311, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 457021.5594731956, 457021.5594731959, 126577.4475576583], 
processed observation next is [0.0, 0.782608695652174, 0.7575757575757578, 0.5866666666666667, 1.0, 1.0, 0.25427876923728887, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1692672442493317, 0.16926724424933182, 0.30872548184794707], 
reward next is 0.6913, 
noisyNet noise sample is [array([0.6032111], dtype=float32), 2.4886937]. 
=============================================
[2019-03-22 22:47:25,196] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.3549382e-36 4.9489844e-37], sum to 1.0000
[2019-03-22 22:47:25,210] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1332
[2019-03-22 22:47:25,218] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.33333333333333, 92.0, 1.0, 2.0, 0.2925533324136691, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 317667.0640787348, 317667.0640787348, 104572.8205716028], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2169600.0000, 
sim time next is 2170200.0000, 
raw observation next is [16.16666666666667, 93.0, 1.0, 2.0, 0.2903003716646869, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 315219.9089858207, 315219.9089858204, 103238.5737234071], 
processed observation next is [1.0, 0.08695652173913043, 0.37121212121212144, 0.93, 1.0, 1.0, 0.11287546458085863, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11674811443919286, 0.11674811443919275, 0.25180139932538315], 
reward next is 0.7482, 
noisyNet noise sample is [array([1.1290157], dtype=float32), 0.92948145]. 
=============================================
[2019-03-22 22:47:30,331] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 6.1312940e-34 1.7986066e-32], sum to 1.0000
[2019-03-22 22:47:30,348] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4509
[2019-03-22 22:47:30,352] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.33333333333334, 90.0, 1.0, 2.0, 0.3620586376727502, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 402596.5531961287, 402596.553196129, 118989.8332839525], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2236800.0000, 
sim time next is 2237400.0000, 
raw observation next is [18.0, 91.0, 1.0, 2.0, 0.3563380626768728, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 394938.3102833663, 394938.3102833663, 118004.2577244148], 
processed observation next is [1.0, 0.9130434782608695, 0.45454545454545453, 0.91, 1.0, 1.0, 0.19542257834609097, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14627344825309863, 0.14627344825309863, 0.2878152627424751], 
reward next is 0.7122, 
noisyNet noise sample is [array([-0.13502061], dtype=float32), 0.375749]. 
=============================================
[2019-03-22 22:47:31,558] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.0833253e-34 1.0293197e-34], sum to 1.0000
[2019-03-22 22:47:31,568] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9622
[2019-03-22 22:47:31,576] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.5, 79.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 208184.6357216056, 208184.6357216054, 68781.07007607991], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2266200.0000, 
sim time next is 2266800.0000, 
raw observation next is [13.33333333333333, 78.66666666666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 206301.6512992327, 206301.651299233, 68081.35380338714], 
processed observation next is [1.0, 0.21739130434782608, 0.2424242424242423, 0.7866666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07640801899971582, 0.07640801899971593, 0.16605208244728573], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.05627782], dtype=float32), 0.9642608]. 
=============================================
[2019-03-22 22:47:38,024] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-22 22:47:38,025] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-22 22:47:38,025] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:47:38,027] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-22 22:47:38,028] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:47:38,029] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-22 22:47:38,032] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-22 22:47:38,035] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:47:38,035] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:47:38,035] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-22 22:47:38,037] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:47:38,058] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run12
[2019-03-22 22:47:38,059] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run12
[2019-03-22 22:47:38,059] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run12
[2019-03-22 22:47:38,060] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run12
[2019-03-22 22:47:38,135] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run12
[2019-03-22 22:47:43,151] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.14257883], dtype=float32), -0.1384757]
[2019-03-22 22:47:43,153] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [13.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 208843.8812389034, 208843.8812389034, 72176.7859448839]
[2019-03-22 22:47:43,153] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 22:47:43,156] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 2.137163e-38 0.000000e+00], sampled 0.28118457320123924
[2019-03-22 22:48:29,661] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.14257883], dtype=float32), -0.1384757]
[2019-03-22 22:48:29,662] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.7, 57.5, 1.0, 2.0, 0.3457179678488476, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 383051.2544352637, 383051.2544352633, 121447.2432500256]
[2019-03-22 22:48:29,664] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 22:48:29,666] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.0070009114067494105
[2019-03-22 22:48:47,758] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.14257883], dtype=float32), -0.1384757]
[2019-03-22 22:48:47,759] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.5, 81.0, 1.0, 2.0, 0.4567682410844019, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 520774.3644148069, 520774.3644148067, 134734.4428809145]
[2019-03-22 22:48:47,759] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 22:48:47,761] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 5.052929e-38 0.000000e+00], sampled 0.6963680236345486
[2019-03-22 22:49:11,353] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.14257883], dtype=float32), -0.1384757]
[2019-03-22 22:49:11,356] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.08333333333334, 50.33333333333334, 1.0, 2.0, 0.2589688699922936, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 281173.5571912065, 281173.5571912061, 84328.39910216419]
[2019-03-22 22:49:11,360] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 22:49:11,363] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.6131048972929897
[2019-03-22 22:49:17,294] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.14257883], dtype=float32), -0.1384757]
[2019-03-22 22:49:17,294] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.98214991166667, 82.33964595666667, 1.0, 2.0, 0.3437530462758926, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 379663.4612944278, 379663.4612944275, 120819.5391242577]
[2019-03-22 22:49:17,297] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 22:49:17,302] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 7.192329e-37 0.000000e+00], sampled 0.9079408603231466
[2019-03-22 22:49:17,924] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.14257883], dtype=float32), -0.1384757]
[2019-03-22 22:49:17,927] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [30.26898872, 70.96595116, 1.0, 2.0, 0.7424309597316114, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 834291.7417654452, 834291.7417654452, 184668.3927750869]
[2019-03-22 22:49:17,927] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 22:49:17,930] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.2430603e-35 0.0000000e+00], sampled 0.7548807836711933
[2019-03-22 22:49:41,254] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-22 22:49:41,778] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5598 1663796639.0689 105.0000
[2019-03-22 22:49:41,843] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9309 1705967916.6745 465.0000
[2019-03-22 22:49:41,934] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2492 1773187030.7201 173.0000
[2019-03-22 22:49:41,962] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-22 22:49:42,979] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 275000, evaluation results [275000.0, 8512.249193409023, 1773187030.7201214, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8856.559759326878, 1663796639.0688558, 105.0, 8596.930884973775, 1705967916.6744611, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-22 22:49:52,601] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 22:49:52,615] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4065
[2019-03-22 22:49:52,620] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.66666666666667, 96.0, 1.0, 2.0, 0.2298017837542441, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 249511.239254183, 249511.239254183, 77761.96465695878], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2492400.0000, 
sim time next is 2493000.0000, 
raw observation next is [13.5, 97.0, 1.0, 2.0, 0.228056143231091, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 247615.3975675354, 247615.3975675357, 77320.18341793786], 
processed observation next is [1.0, 0.8695652173913043, 0.25, 0.97, 1.0, 1.0, 0.03507017903886373, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09170940650649459, 0.0917094065064947, 0.1885858132144826], 
reward next is 0.8114, 
noisyNet noise sample is [array([0.5240401], dtype=float32), 0.012690109]. 
=============================================
[2019-03-22 22:49:52,632] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[79.10885 ]
 [79.14111 ]
 [79.202194]
 [79.27542 ]
 [79.37714 ]], R is [[79.10168457]
 [79.1210022 ]
 [79.13911438]
 [79.15607452]
 [79.17269135]].
[2019-03-22 22:49:52,686] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 22:49:52,695] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8264
[2019-03-22 22:49:52,702] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 99.0, 1.0, 2.0, 0.2080465194059355, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 225884.6018387255, 225884.6018387258, 74169.50239568285], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2501400.0000, 
sim time next is 2502000.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.2106226913409049, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 228682.3144302696, 228682.3144302693, 74714.27643076492], 
processed observation next is [1.0, 1.0, 0.22727272727272727, 1.0, 1.0, 1.0, 0.013278364176131097, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08469715349269244, 0.08469715349269233, 0.18222994251406077], 
reward next is 0.8178, 
noisyNet noise sample is [array([0.46350536], dtype=float32), -0.81443626]. 
=============================================
[2019-03-22 22:49:52,731] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[76.63258]
 [76.61348]
 [76.59589]
 [76.58367]
 [76.58738]], R is [[76.72473907]
 [76.77658844]
 [76.82888794]
 [76.88134766]
 [76.93408203]].
[2019-03-22 22:49:53,343] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 22:49:53,354] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5537
[2019-03-22 22:49:53,361] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.03333333333333, 72.83333333333334, 1.0, 2.0, 0.2704506271629876, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 293659.744473611, 293659.744473611, 93692.17717937451], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2589000.0000, 
sim time next is 2589600.0000, 
raw observation next is [17.96666666666667, 72.66666666666667, 1.0, 2.0, 0.2689957622498824, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 292079.5538256, 292079.5538256003, 92613.73274041944], 
processed observation next is [1.0, 1.0, 0.4530303030303031, 0.7266666666666667, 1.0, 1.0, 0.08624470281235301, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10817761252800001, 0.10817761252800011, 0.22588715302541326], 
reward next is 0.7741, 
noisyNet noise sample is [array([1.9352756], dtype=float32), 0.91013193]. 
=============================================
[2019-03-22 22:49:55,625] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.2149652e-36 2.3622459e-35], sum to 1.0000
[2019-03-22 22:49:55,637] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1677
[2019-03-22 22:49:55,642] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.5, 97.0, 1.0, 2.0, 0.3548798373433263, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 385370.6961087743, 385370.696108774, 90200.22303614173], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2536200.0000, 
sim time next is 2536800.0000, 
raw observation next is [13.66666666666667, 96.0, 1.0, 2.0, 0.3704849794754739, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 402323.6244982646, 402323.6244982646, 92453.41329469038], 
processed observation next is [1.0, 0.34782608695652173, 0.25757575757575774, 0.96, 1.0, 1.0, 0.21310622434434232, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14900874981417206, 0.14900874981417206, 0.2254961299870497], 
reward next is 0.7745, 
noisyNet noise sample is [array([1.0479518], dtype=float32), -0.6465037]. 
=============================================
[2019-03-22 22:49:58,075] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 22:49:58,083] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2029
[2019-03-22 22:49:58,090] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 53.0, 1.0, 2.0, 0.3004900835019469, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 326288.0229123501, 326288.0229123498, 111223.6385874089], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2570400.0000, 
sim time next is 2571000.0000, 
raw observation next is [21.83333333333334, 53.5, 1.0, 2.0, 0.2994166606624122, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 325122.0539989893, 325122.053998989, 109604.1437926083], 
processed observation next is [1.0, 0.782608695652174, 0.628787878787879, 0.535, 1.0, 1.0, 0.12427082582801521, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12041557555518122, 0.1204155755551811, 0.2673271799819715], 
reward next is 0.7327, 
noisyNet noise sample is [array([-1.2746292], dtype=float32), -0.33449343]. 
=============================================
[2019-03-22 22:49:58,110] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[75.2272  ]
 [75.107605]
 [75.001076]
 [74.87856 ]
 [74.64775 ]], R is [[75.30319977]
 [75.27889252]
 [75.25437927]
 [75.22956085]
 [75.20478058]].
[2019-03-22 22:49:58,783] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 22:49:58,793] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9160
[2019-03-22 22:49:58,801] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.5, 44.5, 1.0, 2.0, 0.3365027540866403, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 373957.9669475067, 373957.966947507, 116883.9812712907], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2633400.0000, 
sim time next is 2634000.0000, 
raw observation next is [25.66666666666666, 43.66666666666667, 1.0, 2.0, 0.3354314050176002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 372687.9675948397, 372687.9675948397, 116768.1307959988], 
processed observation next is [0.0, 0.4782608695652174, 0.8030303030303028, 0.4366666666666667, 1.0, 1.0, 0.16928925627200025, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13803258059068138, 0.13803258059068138, 0.2848003190146312], 
reward next is 0.7152, 
noisyNet noise sample is [array([-0.05932846], dtype=float32), -1.1240467]. 
=============================================
[2019-03-22 22:49:58,817] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[73.24882 ]
 [73.23387 ]
 [73.217995]
 [73.19336 ]
 [73.153015]], R is [[73.23703003]
 [73.2195816 ]
 [73.2019043 ]
 [73.18379211]
 [73.16448975]].
[2019-03-22 22:50:11,577] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 5.513005e-33 9.705229e-34], sum to 1.0000
[2019-03-22 22:50:11,592] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8811
[2019-03-22 22:50:11,597] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.66666666666667, 84.66666666666667, 1.0, 2.0, 0.4225183278159551, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 467828.2884330085, 467828.2884330085, 123303.539291293], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2773200.0000, 
sim time next is 2773800.0000, 
raw observation next is [18.5, 85.5, 1.0, 2.0, 0.372814955211629, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 412156.6682671129, 412156.6682671126, 118913.7250003651], 
processed observation next is [1.0, 0.08695652173913043, 0.4772727272727273, 0.855, 1.0, 1.0, 0.21601869401453622, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1526506178767085, 0.15265061787670836, 0.2900334756106466], 
reward next is 0.7100, 
noisyNet noise sample is [array([-1.0758506], dtype=float32), 0.66346955]. 
=============================================
[2019-03-22 22:50:12,864] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 22:50:12,876] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0125
[2019-03-22 22:50:12,881] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.16666666666666, 53.5, 1.0, 2.0, 0.4539434750516321, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 517622.3969420854, 517622.3969420857, 134557.6573431547], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2832600.0000, 
sim time next is 2833200.0000, 
raw observation next is [27.0, 54.0, 1.0, 2.0, 0.4534432325591438, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 516981.9379101463, 516981.9379101463, 134383.1450693497], 
processed observation next is [1.0, 0.8260869565217391, 0.8636363636363636, 0.54, 1.0, 1.0, 0.31680404069892976, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19147479181857271, 0.19147479181857271, 0.32776376846182853], 
reward next is 0.6722, 
noisyNet noise sample is [array([-0.8426658], dtype=float32), 0.0021382226]. 
=============================================
[2019-03-22 22:50:14,437] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.0534798e-27 1.1570142e-24 1.5193349e-25], sum to 1.0000
[2019-03-22 22:50:14,444] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7429
[2019-03-22 22:50:14,448] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 58.0, 1.0, 2.0, 0.3125194795185743, 1.0, 1.0, 0.3125194795185743, 1.0, 2.0, 0.6327268656963743, 6.911199999999999, 6.9112, 77.3421103, 1061338.098291254, 1061338.098291254, 266493.5573931006], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2812200.0000, 
sim time next is 2812800.0000, 
raw observation next is [28.0, 58.0, 1.0, 2.0, 0.9985322255105104, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.108010052088998, 6.9112, 77.32807287351511, 1200131.164387672, 1136211.607776923, 222130.5319880825], 
processed observation next is [1.0, 0.5652173913043478, 0.9090909090909091, 0.58, 1.0, 1.0, 0.9981652818881378, 0.0, 0.5, -0.25, 0.0, 0.5, -0.4285714285714286, 0.019681005208899816, 0.0, 0.508426244952201, 0.4444930238472859, 0.420819113991453, 0.5417817853367866], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2046844], dtype=float32), -0.29365337]. 
=============================================
[2019-03-22 22:50:17,694] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.3069799e-38], sum to 1.0000
[2019-03-22 22:50:17,704] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9849
[2019-03-22 22:50:17,709] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 88.0, 1.0, 2.0, 0.4306204356474761, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 489912.9799970651, 489912.9799970651, 130759.8451974902], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2868600.0000, 
sim time next is 2869200.0000, 
raw observation next is [21.0, 88.0, 1.0, 2.0, 0.4290373977863206, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 488108.1295351337, 488108.1295351337, 130598.8121108446], 
processed observation next is [1.0, 0.21739130434782608, 0.5909090909090909, 0.88, 1.0, 1.0, 0.2862967472329007, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18078078871671618, 0.18078078871671618, 0.31853368807523075], 
reward next is 0.6815, 
noisyNet noise sample is [array([-0.85336614], dtype=float32), -0.13739128]. 
=============================================
[2019-03-22 22:50:20,982] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 22:50:20,991] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3138
[2019-03-22 22:50:21,000] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1258679.717636341 W.
[2019-03-22 22:50:21,005] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.0, 85.66666666666666, 1.0, 2.0, 0.5595370789421235, 1.0, 2.0, 0.5595370789421235, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1258679.717636341, 1258679.717636341, 250770.8015930712], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2911200.0000, 
sim time next is 2911800.0000, 
raw observation next is [23.5, 87.33333333333334, 1.0, 2.0, 0.5480225363594815, 1.0, 2.0, 0.5480225363594815, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1236679.386720908, 1236679.386720908, 246814.1169487069], 
processed observation next is [1.0, 0.6956521739130435, 0.7045454545454546, 0.8733333333333334, 1.0, 1.0, 0.4350281704493518, 1.0, 1.0, 0.4350281704493518, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.45802940248922525, 0.45802940248922525, 0.6019856510944072], 
reward next is 0.3980, 
noisyNet noise sample is [array([0.74760824], dtype=float32), -0.95664644]. 
=============================================
[2019-03-22 22:50:22,189] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.4174692e-37 1.2903219e-35], sum to 1.0000
[2019-03-22 22:50:22,197] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5261
[2019-03-22 22:50:22,204] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 100.0, 1.0, 2.0, 0.5347879761405113, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 608365.5635725994, 608365.5635725994, 147686.8222854604], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2930400.0000, 
sim time next is 2931000.0000, 
raw observation next is [22.0, 100.0, 1.0, 2.0, 0.5387412197649603, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 612770.6160130345, 612770.6160130348, 148238.9721753299], 
processed observation next is [1.0, 0.9565217391304348, 0.6363636363636364, 1.0, 1.0, 1.0, 0.4234265247062003, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22695208000482758, 0.22695208000482772, 0.36155846872031683], 
reward next is 0.6384, 
noisyNet noise sample is [array([-1.6991955], dtype=float32), 0.25591844]. 
=============================================
[2019-03-22 22:50:22,223] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[51.01097]
 [51.05495]
 [51.10695]
 [51.14469]
 [51.17321]], R is [[51.07762527]
 [51.20663834]
 [51.33652878]
 [51.46717453]
 [51.59842682]].
[2019-03-22 22:50:30,432] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 22:50:30,445] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0911
[2019-03-22 22:50:30,451] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.66666666666667, 90.33333333333334, 1.0, 2.0, 0.5151619809911334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 566928.0022361483, 566928.0022361481, 130612.805272925], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3054000.0000, 
sim time next is 3054600.0000, 
raw observation next is [18.0, 88.5, 1.0, 2.0, 0.5971463425209921, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 659216.9347269076, 659216.9347269076, 139555.353085059], 
processed observation next is [1.0, 0.34782608695652173, 0.45454545454545453, 0.885, 1.0, 1.0, 0.49643292815124007, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.24415442026922504, 0.24415442026922504, 0.3403789099635585], 
reward next is 0.6596, 
noisyNet noise sample is [array([0.7150317], dtype=float32), -1.0567824]. 
=============================================
[2019-03-22 22:50:30,601] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.3276934e-38], sum to 1.0000
[2019-03-22 22:50:30,610] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1700
[2019-03-22 22:50:30,616] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.66666666666667, 84.83333333333333, 1.0, 2.0, 0.6708715562364163, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 744099.6701978096, 744099.6701978096, 148992.5632211259], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3055800.0000, 
sim time next is 3056400.0000, 
raw observation next is [19.0, 83.0, 1.0, 2.0, 0.637339368367105, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 707971.1381887508, 707971.1381887508, 145521.5284168232], 
processed observation next is [1.0, 0.391304347826087, 0.5, 0.83, 1.0, 1.0, 0.5466742104588812, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2622115326625003, 0.2622115326625003, 0.3549305571142029], 
reward next is 0.6451, 
noisyNet noise sample is [array([0.26998076], dtype=float32), -0.18148904]. 
=============================================
[2019-03-22 22:50:30,654] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 22:50:30,668] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9576
[2019-03-22 22:50:30,679] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 94.0, 1.0, 2.0, 0.3600210623058818, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 394142.466407791, 394142.4664077907, 116488.2947526514], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3051000.0000, 
sim time next is 3051600.0000, 
raw observation next is [17.0, 94.0, 1.0, 2.0, 0.3600933062669908, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 394191.1064212906, 394191.1064212906, 116483.1888988426], 
processed observation next is [1.0, 0.30434782608695654, 0.4090909090909091, 0.94, 1.0, 1.0, 0.2001166328337385, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14599670608195947, 0.14599670608195947, 0.2841053387776649], 
reward next is 0.7159, 
noisyNet noise sample is [array([-0.44440624], dtype=float32), 0.40930578]. 
=============================================
[2019-03-22 22:50:39,022] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.2576776e-38 5.1351255e-38], sum to 1.0000
[2019-03-22 22:50:39,036] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2084
[2019-03-22 22:50:39,043] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.33333333333334, 81.33333333333334, 1.0, 2.0, 0.342507099184474, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 379922.3204154904, 379922.3204154907, 117056.193512522], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3222600.0000, 
sim time next is 3223200.0000, 
raw observation next is [19.66666666666667, 79.66666666666667, 1.0, 2.0, 0.346075628026196, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 384551.010362335, 384551.010362335, 117608.1172950291], 
processed observation next is [0.0, 0.30434782608695654, 0.5303030303030305, 0.7966666666666667, 1.0, 1.0, 0.182594535032745, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14242630013419816, 0.14242630013419816, 0.2868490665732417], 
reward next is 0.7132, 
noisyNet noise sample is [array([-0.91313165], dtype=float32), 0.582647]. 
=============================================
[2019-03-22 22:50:41,597] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 22:50:41,607] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4172
[2019-03-22 22:50:41,613] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.5, 85.5, 1.0, 2.0, 0.3347106426395264, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 369515.2290233215, 369515.2290233218, 115755.7572529381], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3220200.0000, 
sim time next is 3220800.0000, 
raw observation next is [18.66666666666667, 84.66666666666666, 1.0, 2.0, 0.3361326417527807, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 371483.8775799058, 371483.8775799061, 116017.8437109445], 
processed observation next is [0.0, 0.2608695652173913, 0.4848484848484851, 0.8466666666666666, 1.0, 1.0, 0.17016580219097582, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13758662132589103, 0.13758662132589114, 0.28297035051449876], 
reward next is 0.7170, 
noisyNet noise sample is [array([0.25659332], dtype=float32), 1.4916928]. 
=============================================
[2019-03-22 22:50:46,038] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 22:50:46,053] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6165
[2019-03-22 22:50:46,058] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.16666666666666, 63.33333333333334, 1.0, 2.0, 0.3282302873860313, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 360380.6544991916, 360380.6544991918, 114520.8501141153], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3275400.0000, 
sim time next is 3276000.0000, 
raw observation next is [21.0, 64.0, 1.0, 2.0, 0.3267167580758213, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 358350.8647250884, 358350.8647250881, 114275.557592501], 
processed observation next is [0.0, 0.9565217391304348, 0.5909090909090909, 0.64, 1.0, 1.0, 0.1583959475947766, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13272254249077348, 0.13272254249077337, 0.2787208721768317], 
reward next is 0.7213, 
noisyNet noise sample is [array([-0.7367628], dtype=float32), -0.8181682]. 
=============================================
[2019-03-22 22:50:46,084] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[72.757645]
 [72.73881 ]
 [72.72256 ]
 [72.71242 ]
 [72.71255 ]], R is [[72.79623413]
 [72.78895569]
 [72.78115082]
 [72.77277374]
 [72.7637558 ]].
[2019-03-22 22:50:47,041] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-22 22:50:47,044] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-22 22:50:47,045] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:50:47,046] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-22 22:50:47,046] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:50:47,048] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-22 22:50:47,049] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:50:47,050] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-22 22:50:47,051] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-22 22:50:47,052] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:50:47,053] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:50:47,077] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run13
[2019-03-22 22:50:47,077] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run13
[2019-03-22 22:50:47,096] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run13
[2019-03-22 22:50:47,118] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run13
[2019-03-22 22:50:47,158] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run13
[2019-03-22 22:50:58,567] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.2287642], dtype=float32), -0.17636956]
[2019-03-22 22:50:58,569] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [15.5, 97.0, 1.0, 2.0, 0.284225209023529, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 308621.1580152831, 308621.1580152833, 98590.95506391548]
[2019-03-22 22:50:58,571] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 22:50:58,574] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.40558718163396457
[2019-03-22 22:51:56,165] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.2287642], dtype=float32), -0.17636956]
[2019-03-22 22:51:56,167] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.93543459666667, 89.87562375666667, 1.0, 2.0, 0.4549569597546461, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 518193.442101634, 518193.442101634, 138205.3800089988]
[2019-03-22 22:51:56,169] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 22:51:56,173] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.2291009859805846
[2019-03-22 22:51:58,454] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.2287642], dtype=float32), -0.17636956]
[2019-03-22 22:51:58,455] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [26.85545212, 98.36921483, 1.0, 2.0, 0.7221804232073832, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 811520.2352537748, 811520.2352537744, 181438.5043737086]
[2019-03-22 22:51:58,455] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 22:51:58,457] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.13534877649998434
[2019-03-22 22:52:10,200] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.2287642], dtype=float32), -0.17636956]
[2019-03-22 22:52:10,202] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [17.4, 90.0, 1.0, 2.0, 0.3841912306953381, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 420444.2444658649, 420444.2444658653, 122615.6451383038]
[2019-03-22 22:52:10,204] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 22:52:10,207] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.8134012092596987
[2019-03-22 22:52:24,447] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.2287642], dtype=float32), -0.17636956]
[2019-03-22 22:52:24,447] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.15, 61.5, 1.0, 2.0, 0.4140213166153907, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 468824.8877978684, 468824.8877978681, 131773.92332737]
[2019-03-22 22:52:24,448] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 22:52:24,450] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.6912911260029148
[2019-03-22 22:52:49,656] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.2287642], dtype=float32), -0.17636956]
[2019-03-22 22:52:49,656] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [17.26999735333333, 62.87802595833334, 1.0, 2.0, 0.251206593796163, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 272743.8103426193, 272743.8103426193, 83759.64970116019]
[2019-03-22 22:52:49,656] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 22:52:49,657] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.382030288052551
[2019-03-22 22:52:51,027] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-22 22:52:51,039] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-22 22:52:51,207] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-22 22:52:51,254] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-22 22:52:51,285] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1147 1656209757.7786 80.0000
[2019-03-22 22:52:52,301] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 300000, evaluation results [300000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.114669779829, 1656209757.7786272, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-22 22:52:54,085] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 22:52:54,098] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7113
[2019-03-22 22:52:54,106] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 64.33333333333334, 1.0, 2.0, 0.2859606606910335, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 310506.1705741361, 310506.1705741361, 107082.2427293034], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3316800.0000, 
sim time next is 3317400.0000, 
raw observation next is [20.5, 62.5, 1.0, 2.0, 0.2918493521509614, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 316902.4027919875, 316902.4027919878, 110649.7960178242], 
processed observation next is [0.0, 0.391304347826087, 0.5681818181818182, 0.625, 1.0, 1.0, 0.11481169018870176, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11737126029332871, 0.11737126029332882, 0.26987755126298585], 
reward next is 0.7301, 
noisyNet noise sample is [array([1.5064864], dtype=float32), 0.37123728]. 
=============================================
[2019-03-22 22:52:56,110] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 22:52:56,122] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1641
[2019-03-22 22:52:56,126] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.83333333333333, 57.66666666666666, 1.0, 2.0, 0.3708213607793349, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 416481.600271365, 416481.600271365, 121556.9777359468], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3348600.0000, 
sim time next is 3349200.0000, 
raw observation next is [23.66666666666666, 58.33333333333334, 1.0, 2.0, 0.3698788242839443, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 415231.9830190928, 415231.9830190928, 121382.7265581327], 
processed observation next is [0.0, 0.782608695652174, 0.7121212121212118, 0.5833333333333335, 1.0, 1.0, 0.21234853035493037, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15378962334040475, 0.15378962334040475, 0.29605543062959194], 
reward next is 0.7039, 
noisyNet noise sample is [array([-0.650794], dtype=float32), -0.3577584]. 
=============================================
[2019-03-22 22:53:07,842] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.6739222e-36 1.0000000e+00 3.8416999e-26 6.5350698e-28 1.2536097e-25], sum to 1.0000
[2019-03-22 22:53:07,855] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5275
[2019-03-22 22:53:07,866] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.3, 59.0, 1.0, 2.0, 0.5263861284300337, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 598256.7646738593, 598256.7646738593, 146957.3922189923], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3519000.0000, 
sim time next is 3519600.0000, 
raw observation next is [28.2, 58.66666666666667, 1.0, 2.0, 0.5232106983933746, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 595148.2117016345, 595148.2117016345, 146276.8255444508], 
processed observation next is [1.0, 0.7391304347826086, 0.9181818181818181, 0.5866666666666667, 1.0, 1.0, 0.40401337299171824, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22042526359319795, 0.22042526359319795, 0.35677274523036784], 
reward next is 0.6432, 
noisyNet noise sample is [array([2.065015], dtype=float32), 2.6005611]. 
=============================================
[2019-03-22 22:53:09,915] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.2682881e-37 1.0000000e+00 1.0242891e-29 5.9385283e-27 1.5322177e-22], sum to 1.0000
[2019-03-22 22:53:09,925] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5213
[2019-03-22 22:53:09,932] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 89.0, 1.0, 2.0, 0.5200956688984502, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 592517.5530709184, 592517.5530709182, 145215.8398494398], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3546000.0000, 
sim time next is 3546600.0000, 
raw observation next is [23.0, 89.0, 1.0, 2.0, 0.5194324076624407, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 591762.0347431514, 591762.0347431514, 145134.9000248478], 
processed observation next is [1.0, 0.043478260869565216, 0.6818181818181818, 0.89, 1.0, 1.0, 0.39929050957805085, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21917112397894495, 0.21917112397894495, 0.35398756103621415], 
reward next is 0.6460, 
noisyNet noise sample is [array([-0.21956304], dtype=float32), -0.08631991]. 
=============================================
[2019-03-22 22:53:14,983] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.3069101e-38 4.8643151e-27], sum to 1.0000
[2019-03-22 22:53:14,992] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3025
[2019-03-22 22:53:15,000] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4909441627371197, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 560144.4145530548, 560144.4145530548, 140443.4164300306], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3634200.0000, 
sim time next is 3634800.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.4908950554917673, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 560088.3960884822, 560088.3960884825, 140437.6339953282], 
processed observation next is [1.0, 0.043478260869565216, 0.5909090909090909, 1.0, 1.0, 1.0, 0.36361881936470913, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20744014669943786, 0.20744014669943794, 0.3425308146227517], 
reward next is 0.6575, 
noisyNet noise sample is [array([0.61828065], dtype=float32), 0.102515794]. 
=============================================
[2019-03-22 22:53:18,874] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.1248164e-20 1.0000000e+00 6.7548912e-15 2.1772757e-11 9.4455893e-12], sum to 1.0000
[2019-03-22 22:53:18,885] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8101
[2019-03-22 22:53:18,895] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1501509.651948165 W.
[2019-03-22 22:53:18,900] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.0, 55.0, 1.0, 2.0, 0.6675699785278162, 1.0, 2.0, 0.6675699785278162, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1501509.651948165, 1501509.651948166, 281746.3060763963], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3682800.0000, 
sim time next is 3683400.0000, 
raw observation next is [29.0, 54.5, 1.0, 2.0, 0.7554349000303339, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9792026210117866, 6.911200000000001, 6.9112, 77.32846344354104, 1404931.38988113, 1404931.389881129, 302584.9258355026], 
processed observation next is [1.0, 0.6521739130434783, 0.9545454545454546, 0.545, 1.0, 1.0, 0.6942936250379173, 0.0, 0.5, -0.25, 1.0, 0.5, 0.9702894585882665, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.5203449592152334, 0.5203449592152329, 0.7380120142329333], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.24700509], dtype=float32), -0.887641]. 
=============================================
[2019-03-22 22:53:25,166] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 3.4437065e-32], sum to 1.0000
[2019-03-22 22:53:25,177] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1705
[2019-03-22 22:53:25,189] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 61.33333333333334, 1.0, 2.0, 0.3502664164084716, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 385923.1959674479, 385923.1959674479, 116645.7701271802], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3777600.0000, 
sim time next is 3778200.0000, 
raw observation next is [21.5, 62.0, 1.0, 2.0, 0.338840473992072, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 372731.1374586791, 372731.1374586794, 115556.7777223553], 
processed observation next is [1.0, 0.7391304347826086, 0.6136363636363636, 0.62, 1.0, 1.0, 0.17355059249009, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1380485694291404, 0.1380485694291405, 0.2818457993228178], 
reward next is 0.7182, 
noisyNet noise sample is [array([0.3587444], dtype=float32), 0.4947918]. 
=============================================
[2019-03-22 22:53:28,766] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 22:53:28,775] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2622
[2019-03-22 22:53:28,787] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 91.0, 1.0, 2.0, 0.3035894200521386, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 329664.7430723908, 329664.7430723908, 111437.9921957529], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3828600.0000, 
sim time next is 3829200.0000, 
raw observation next is [17.0, 92.0, 1.0, 2.0, 0.3059755500244424, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 333014.0746635186, 333014.0746635189, 111863.0364523563], 
processed observation next is [0.0, 0.30434782608695654, 0.4090909090909091, 0.92, 1.0, 1.0, 0.13246943753055296, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12333854617167354, 0.12333854617167368, 0.2728366742740398], 
reward next is 0.7272, 
noisyNet noise sample is [array([0.45952797], dtype=float32), 0.0320044]. 
=============================================
[2019-03-22 22:53:49,112] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.8091485e-25 9.9999893e-01 6.2593884e-15 4.5055203e-11 1.0376508e-06], sum to 1.0000
[2019-03-22 22:53:49,125] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9075
[2019-03-22 22:53:49,134] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 61.0, 1.0, 2.0, 0.7787311099919151, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 882194.3048339175, 882194.3048339178, 170973.5633573097], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4204800.0000, 
sim time next is 4205400.0000, 
raw observation next is [23.83333333333333, 62.33333333333334, 1.0, 2.0, 0.9299526526207123, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.80011322483053, 1054171.47627914, 1054171.476279139, 194830.4418325239], 
processed observation next is [1.0, 0.6956521739130435, 0.7196969696969695, 0.6233333333333334, 1.0, 1.0, 0.9124408157758903, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5115298746479492, 0.3904338801033852, 0.3904338801033848, 0.4751961995915217], 
reward next is 0.5248, 
noisyNet noise sample is [array([-0.3283063], dtype=float32), 0.60082495]. 
=============================================
[2019-03-22 22:53:49,546] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 5.6702489e-38 2.9309423e-32], sum to 1.0000
[2019-03-22 22:53:49,558] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1065
[2019-03-22 22:53:49,563] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.01666666666667, 93.83333333333334, 1.0, 2.0, 0.387194063649728, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 436268.4387637442, 436268.4387637442, 123678.8869751588], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4132200.0000, 
sim time next is 4132800.0000, 
raw observation next is [19.0, 94.0, 1.0, 2.0, 0.3897315702250438, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 439144.6452877032, 439144.6452877029, 123912.5768618318], 
processed observation next is [1.0, 0.8695652173913043, 0.5, 0.94, 1.0, 1.0, 0.2371644627813047, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16264616492137154, 0.16264616492137146, 0.30222579722397996], 
reward next is 0.6978, 
noisyNet noise sample is [array([0.9784012], dtype=float32), -0.48138985]. 
=============================================
[2019-03-22 22:53:51,777] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.7378667e-37 1.7434062e-35], sum to 1.0000
[2019-03-22 22:53:51,789] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5421
[2019-03-22 22:53:51,795] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 100.0, 1.0, 2.0, 0.3476129454877033, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 384745.5986814389, 384745.5986814389, 117115.3510552561], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4164000.0000, 
sim time next is 4164600.0000, 
raw observation next is [17.0, 100.0, 1.0, 2.0, 0.3414421557515168, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 377893.0332580754, 377893.0332580751, 116632.4574402677], 
processed observation next is [1.0, 0.17391304347826086, 0.4090909090909091, 1.0, 1.0, 1.0, 0.176802694689396, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1399603826881761, 0.13996038268817598, 0.2844694083908968], 
reward next is 0.7155, 
noisyNet noise sample is [array([1.4704212], dtype=float32), 2.0600305]. 
=============================================
[2019-03-22 22:53:52,928] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 2.2957644e-38 9.5919825e-33 1.8644570e-24], sum to 1.0000
[2019-03-22 22:53:52,938] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9124
[2019-03-22 22:53:52,944] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 88.0, 1.0, 2.0, 0.60041602885514, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 672287.2169718116, 672287.2169718116, 143534.6176156666], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4182600.0000, 
sim time next is 4183200.0000, 
raw observation next is [19.0, 88.0, 1.0, 2.0, 0.632546321756383, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 708378.406584792, 708378.406584792, 147279.545905466], 
processed observation next is [1.0, 0.43478260869565216, 0.5, 0.88, 1.0, 1.0, 0.5406829021954788, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.26236237280918223, 0.26236237280918223, 0.359218404647478], 
reward next is 0.6408, 
noisyNet noise sample is [array([0.78998196], dtype=float32), -1.4678777]. 
=============================================
[2019-03-22 22:53:53,553] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.9890625e-29 1.0000000e+00 2.8603013e-21 3.3399544e-08 6.9663986e-09], sum to 1.0000
[2019-03-22 22:53:53,562] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0221
[2019-03-22 22:53:53,570] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 73.66666666666667, 1.0, 2.0, 0.6873739079803649, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 776324.9240734034, 776324.9240734037, 157045.2751916531], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4188000.0000, 
sim time next is 4188600.0000, 
raw observation next is [22.0, 71.5, 1.0, 2.0, 0.711742953954235, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 803961.5186584187, 803961.5186584187, 160292.1537693249], 
processed observation next is [1.0, 0.4782608695652174, 0.6363636363636364, 0.715, 1.0, 1.0, 0.6396786924427939, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.29776352542904394, 0.29776352542904394, 0.39095647260810956], 
reward next is 0.6090, 
noisyNet noise sample is [array([-1.8044786], dtype=float32), -0.29524758]. 
=============================================
[2019-03-22 22:53:54,406] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.1900133e-37 1.0000000e+00 1.0767220e-30 1.8670950e-19 4.7637849e-23], sum to 1.0000
[2019-03-22 22:53:54,415] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0721
[2019-03-22 22:53:54,422] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 94.0, 1.0, 2.0, 0.3068004210912782, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 333142.4682113059, 333142.4682113059, 103826.8948120292], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4251600.0000, 
sim time next is 4252200.0000, 
raw observation next is [16.0, 95.0, 1.0, 2.0, 0.2942196758952476, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 319477.0462490141, 319477.0462490144, 104538.7488213434], 
processed observation next is [1.0, 0.21739130434782608, 0.36363636363636365, 0.95, 1.0, 1.0, 0.1177745948690595, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11832483194407929, 0.1183248319440794, 0.2549725581008376], 
reward next is 0.7450, 
noisyNet noise sample is [array([-0.3171812], dtype=float32), 0.3456266]. 
=============================================
[2019-03-22 22:53:56,239] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-22 22:53:56,240] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-22 22:53:56,241] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:53:56,241] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-22 22:53:56,243] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-22 22:53:56,244] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:53:56,246] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:53:56,245] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-22 22:53:56,249] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-22 22:53:56,252] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:53:56,253] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:53:56,268] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run14
[2019-03-22 22:53:56,290] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run14
[2019-03-22 22:53:56,309] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run14
[2019-03-22 22:53:56,311] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run14
[2019-03-22 22:53:56,311] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run14
[2019-03-22 22:54:19,197] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.2222578], dtype=float32), -0.12535939]
[2019-03-22 22:54:19,198] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.40169682, 95.84190797, 1.0, 2.0, 0.4806350259757756, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 547989.0642970108, 547989.0642970108, 141691.6861568913]
[2019-03-22 22:54:19,199] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 22:54:19,203] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 6.0145793e-36 1.2791407e-31], sampled 0.43637793576310646
[2019-03-22 22:54:21,965] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.2222578], dtype=float32), -0.12535939]
[2019-03-22 22:54:21,967] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [28.05427703666667, 50.99922475666666, 1.0, 2.0, 0.8262421813208202, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 943025.4582921584, 943025.4582921584, 190503.7473928989]
[2019-03-22 22:54:21,968] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 22:54:21,973] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 4.7029538e-38 3.7761082e-29 2.7535777e-23], sampled 0.6054967859038748
[2019-03-22 22:54:31,937] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.2222578], dtype=float32), -0.12535939]
[2019-03-22 22:54:31,938] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [16.9, 56.5, 1.0, 2.0, 0.2346418876028867, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 254755.1163640545, 254755.1163640548, 79058.11864901704]
[2019-03-22 22:54:31,940] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 22:54:31,943] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.8411706320279446
[2019-03-22 22:54:36,749] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.2222578], dtype=float32), -0.12535939]
[2019-03-22 22:54:36,750] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.5, 51.5, 1.0, 2.0, 0.3077902368861069, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 334217.6394587437, 334217.6394587437, 111717.6878319394]
[2019-03-22 22:54:36,750] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 22:54:36,753] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.5057771e-36 3.0266248e-31], sampled 0.7046383621022204
[2019-03-22 22:54:36,778] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.2222578], dtype=float32), -0.12535939]
[2019-03-22 22:54:36,779] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.19860473666667, 42.4822296, 1.0, 2.0, 0.3578546560614218, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 388572.7854391027, 388572.7854391027, 96832.80340343351]
[2019-03-22 22:54:36,780] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 22:54:36,783] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.4915963e-34], sampled 0.32762896802273067
[2019-03-22 22:54:56,447] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.2222578], dtype=float32), -0.12535939]
[2019-03-22 22:54:56,449] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.0, 92.0, 1.0, 2.0, 0.3059755500244424, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 333014.0746635186, 333014.0746635189, 111863.0364523563]
[2019-03-22 22:54:56,450] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 22:54:56,453] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.1388268e-38 8.3431291e-35], sampled 0.03295697420286081
[2019-03-22 22:55:13,240] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.2222578], dtype=float32), -0.12535939]
[2019-03-22 22:55:13,242] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [26.33333333333334, 62.0, 1.0, 2.0, 0.5007431505240222, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 571326.2133349403, 571326.2133349403, 145585.6910204482]
[2019-03-22 22:55:13,242] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 22:55:13,246] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.0643266e-38 2.5998823e-32], sampled 0.38338313950516156
[2019-03-22 22:55:45,924] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.2222578], dtype=float32), -0.12535939]
[2019-03-22 22:55:45,925] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.6, 79.33333333333334, 1.0, 2.0, 0.4142636210118869, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 460185.8168507281, 460185.8168507278, 127493.5266204349]
[2019-03-22 22:55:45,925] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 22:55:45,928] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.5969096e-35 1.0974308e-30], sampled 0.17724888343959444
[2019-03-22 22:55:59,821] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-22 22:55:59,924] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-22 22:56:00,150] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3485 1683325900.1134 214.0000
[2019-03-22 22:56:00,188] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-22 22:56:00,251] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5598 1663796639.0689 105.0000
[2019-03-22 22:56:01,266] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 325000, evaluation results [325000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8856.559759326878, 1663796639.0688558, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8574.348472942609, 1683325900.1133502, 214.0]
[2019-03-22 22:56:13,663] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.4864209e-35 1.0000000e+00 2.7841822e-34 4.7646647e-20 3.6998382e-14], sum to 1.0000
[2019-03-22 22:56:13,675] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5366
[2019-03-22 22:56:13,681] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.16666666666667, 82.33333333333333, 1.0, 2.0, 0.4519359174699271, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 515058.2956889392, 515058.2956889389, 133913.3874377168], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4408800.0000, 
sim time next is 4409400.0000, 
raw observation next is [22.08333333333334, 82.66666666666667, 1.0, 2.0, 0.4501315958248431, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 512940.0684763797, 512940.0684763797, 133641.2210744674], 
processed observation next is [0.0, 0.0, 0.6401515151515155, 0.8266666666666667, 1.0, 1.0, 0.3126644947810538, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18997780313939988, 0.18997780313939988, 0.3259541977426034], 
reward next is 0.6740, 
noisyNet noise sample is [array([1.0128852], dtype=float32), -0.7220186]. 
=============================================
[2019-03-22 22:56:15,310] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.1806510e-29 4.7245907e-21], sum to 1.0000
[2019-03-22 22:56:15,321] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3043
[2019-03-22 22:56:15,328] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 78.0, 1.0, 2.0, 0.4507269448755032, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 513946.6334416406, 513946.6334416409, 134206.9373651471], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4438800.0000, 
sim time next is 4439400.0000, 
raw observation next is [23.16666666666667, 77.33333333333333, 1.0, 2.0, 0.4528364569371474, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 516424.3005388851, 516424.3005388851, 134564.4740044223], 
processed observation next is [0.0, 0.391304347826087, 0.6893939393939396, 0.7733333333333333, 1.0, 1.0, 0.3160455711714342, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19126825945884635, 0.19126825945884635, 0.32820603415712757], 
reward next is 0.6718, 
noisyNet noise sample is [array([1.4372755], dtype=float32), 0.35238278]. 
=============================================
[2019-03-22 22:56:17,011] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 3.869358e-37 8.650349e-24 8.747565e-19], sum to 1.0000
[2019-03-22 22:56:17,022] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2518
[2019-03-22 22:56:17,029] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.83333333333334, 70.66666666666667, 1.0, 2.0, 0.5232435374464531, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 595782.0606361036, 595782.0606361036, 145870.3612189721], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4453800.0000, 
sim time next is 4454400.0000, 
raw observation next is [25.66666666666667, 71.33333333333334, 1.0, 2.0, 0.5234923997765956, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 596190.3507727259, 596190.3507727257, 145801.2488793267], 
processed observation next is [0.0, 0.5652173913043478, 0.8030303030303032, 0.7133333333333334, 1.0, 1.0, 0.4043654997207444, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2208112410269355, 0.22081124102693542, 0.3556128021446993], 
reward next is 0.6444, 
noisyNet noise sample is [array([-0.11976085], dtype=float32), 0.7209921]. 
=============================================
[2019-03-22 22:56:20,156] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 7.3290133e-29 2.2651377e-28], sum to 1.0000
[2019-03-22 22:56:20,169] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1051
[2019-03-22 22:56:20,176] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.4115835389797709, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 466568.9707149618, 466568.9707149621, 127545.2985791925], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4510800.0000, 
sim time next is 4511400.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4113768146016772, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 466334.5678638094, 466334.5678638094, 127525.714095674], 
processed observation next is [0.0, 0.21739130434782608, 0.5, 1.0, 1.0, 1.0, 0.26422101825209643, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1727165066162257, 0.1727165066162257, 0.3110383270626195], 
reward next is 0.6890, 
noisyNet noise sample is [array([-1.8886302], dtype=float32), -0.47925612]. 
=============================================
[2019-03-22 22:56:21,475] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.00000000e+00 1.00000000e+00 1.98562143e-38 3.97920334e-28
 1.19876756e-29], sum to 1.0000
[2019-03-22 22:56:21,488] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4380
[2019-03-22 22:56:21,497] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.5000855555840359, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 570316.6669871402, 570316.6669871402, 142096.0399269016], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4528200.0000, 
sim time next is 4528800.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.5011842725540635, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 571569.7665009546, 571569.7665009544, 142225.7567633785], 
processed observation next is [0.0, 0.43478260869565216, 0.6363636363636364, 0.94, 1.0, 1.0, 0.37648034069257935, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21169250611146467, 0.2116925061114646, 0.34689208966677687], 
reward next is 0.6531, 
noisyNet noise sample is [array([-0.6445104], dtype=float32), -1.0447576]. 
=============================================
[2019-03-22 22:56:23,331] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 2.6260973e-32], sum to 1.0000
[2019-03-22 22:56:23,337] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8291
[2019-03-22 22:56:23,342] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 61.0, 1.0, 2.0, 0.394285823898136, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 445763.2176520425, 445763.2176520422, 125158.3583429876], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4557600.0000, 
sim time next is 4558200.0000, 
raw observation next is [23.66666666666667, 61.5, 1.0, 2.0, 0.3916464178770229, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 442134.3473048862, 442134.3473048862, 124540.634238768], 
processed observation next is [0.0, 0.782608695652174, 0.7121212121212124, 0.615, 1.0, 1.0, 0.23955802234627863, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16375346196477267, 0.16375346196477267, 0.3037576444848], 
reward next is 0.6962, 
noisyNet noise sample is [array([-0.11604779], dtype=float32), 2.0313673]. 
=============================================
[2019-03-22 22:56:32,870] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 9.9461192e-33 2.5337225e-26 3.0711038e-13], sum to 1.0000
[2019-03-22 22:56:32,879] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2217
[2019-03-22 22:56:32,884] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 61.33333333333333, 1.0, 2.0, 0.5300316826756711, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 575683.9979979505, 575683.9979979503, 129618.3491055833], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4701000.0000, 
sim time next is 4701600.0000, 
raw observation next is [21.0, 60.0, 1.0, 2.0, 0.5201519362201849, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 565164.3220961037, 565164.3220961037, 128770.2886701927], 
processed observation next is [1.0, 0.43478260869565216, 0.5909090909090909, 0.6, 1.0, 1.0, 0.40018992027523104, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20932011929485322, 0.20932011929485322, 0.31407387480534804], 
reward next is 0.6859, 
noisyNet noise sample is [array([-0.24700446], dtype=float32), 1.1700495]. 
=============================================
[2019-03-22 22:56:37,270] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 3.4574793e-37 2.3699226e-31 3.0286505e-28], sum to 1.0000
[2019-03-22 22:56:37,284] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2788
[2019-03-22 22:56:37,288] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 88.0, 1.0, 2.0, 0.3733073735179695, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 417253.5642220335, 417253.5642220338, 120820.615024676], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4762200.0000, 
sim time next is 4762800.0000, 
raw observation next is [19.0, 88.0, 1.0, 2.0, 0.3725841335426084, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 416434.4870345797, 416434.4870345797, 120755.520941281], 
processed observation next is [1.0, 0.13043478260869565, 0.5, 0.88, 1.0, 1.0, 0.21573016692826047, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15423499519799247, 0.15423499519799247, 0.2945256608323927], 
reward next is 0.7055, 
noisyNet noise sample is [array([0.24967954], dtype=float32), -0.2568065]. 
=============================================
[2019-03-22 22:56:40,637] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0015665e-35 1.0000000e+00 1.8750410e-32 1.3018175e-19 3.0703009e-17], sum to 1.0000
[2019-03-22 22:56:40,649] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9895
[2019-03-22 22:56:40,654] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.2922170487562445, 1.0, 1.0, 0.2922170487562445, 1.0, 2.0, 0.5919247585385456, 6.9112, 6.9112, 77.3421103, 995284.690843704, 995284.690843704, 257562.1207831599], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4806000.0000, 
sim time next is 4806600.0000, 
raw observation next is [22.0, 95.0, 1.0, 2.0, 0.8397288464402703, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846332382694, 956727.6273755782, 956727.6273755782, 191957.3641737721], 
processed observation next is [1.0, 0.6521739130434783, 0.6363636363636364, 0.95, 1.0, 1.0, 0.7996610580503379, 0.0, 0.5, -0.25, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.508428812133543, 0.3543435656946586, 0.3543435656946586, 0.46818869310676126], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.00033291], dtype=float32), 0.51797736]. 
=============================================
[2019-03-22 22:56:46,153] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 9.2646321e-37 5.0487776e-34 9.4793982e-26], sum to 1.0000
[2019-03-22 22:56:46,160] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0505
[2019-03-22 22:56:46,166] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 73.0, 1.0, 2.0, 0.451454307156508, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 490295.6098316061, 490295.6098316061, 122643.1556273166], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4970400.0000, 
sim time next is 4971000.0000, 
raw observation next is [19.0, 73.0, 1.0, 2.0, 0.4175922576878713, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 453503.0538684455, 453503.0538684452, 119854.6015666464], 
processed observation next is [1.0, 0.5217391304347826, 0.5, 0.73, 1.0, 1.0, 0.2719903221098391, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1679640940253502, 0.1679640940253501, 0.2923282965040156], 
reward next is 0.7077, 
noisyNet noise sample is [array([0.8943856], dtype=float32), -0.6934661]. 
=============================================
[2019-03-22 22:56:46,193] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[61.58395 ]
 [61.282448]
 [61.113346]
 [60.857037]
 [60.766857]], R is [[61.89448929]
 [61.97641373]
 [62.0402832 ]
 [62.09690475]
 [62.13264084]].
[2019-03-22 22:56:46,680] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 8.6514686e-32 7.0092042e-29 2.5531909e-22], sum to 1.0000
[2019-03-22 22:56:46,690] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0573
[2019-03-22 22:56:46,698] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 82.16666666666667, 1.0, 2.0, 0.9122416741472431, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1040238.859719652, 1040238.859719652, 197318.6827937914], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4889400.0000, 
sim time next is 4890000.0000, 
raw observation next is [22.0, 81.33333333333334, 1.0, 2.0, 0.908648665886109, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1035805.686494122, 1035805.686494122, 196246.1589008042], 
processed observation next is [1.0, 0.6086956521739131, 0.6363636363636364, 0.8133333333333335, 1.0, 1.0, 0.8858108323576364, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.38363173573856374, 0.38363173573856374, 0.478649168050742], 
reward next is 0.5214, 
noisyNet noise sample is [array([0.78116184], dtype=float32), 1.5439751]. 
=============================================
[2019-03-22 22:56:46,710] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[53.846535]
 [54.294014]
 [54.898746]
 [55.14989 ]
 [55.431885]], R is [[53.56997299]
 [53.55300903]
 [53.54636765]
 [53.57778168]
 [53.61346054]].
[2019-03-22 22:56:47,799] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.5290936e-36 1.0425047e-37], sum to 1.0000
[2019-03-22 22:56:47,808] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1453
[2019-03-22 22:56:47,818] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 94.0, 1.0, 2.0, 0.3915224532148444, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 441312.3786047756, 441312.3786047759, 124151.7704161575], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4919400.0000, 
sim time next is 4920000.0000, 
raw observation next is [18.66666666666667, 96.0, 1.0, 2.0, 0.3883494562087395, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 437259.0299480187, 437259.0299480187, 123616.1909732122], 
processed observation next is [1.0, 0.9565217391304348, 0.4848484848484851, 0.96, 1.0, 1.0, 0.23543682026092436, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16194778886963657, 0.16194778886963657, 0.3015029048127127], 
reward next is 0.6985, 
noisyNet noise sample is [array([-0.5581996], dtype=float32), -0.13935316]. 
=============================================
[2019-03-22 22:56:47,830] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[68.86029 ]
 [68.83788 ]
 [68.80896 ]
 [68.798546]
 [68.78707 ]], R is [[68.89043427]
 [68.89871979]
 [68.90536499]
 [68.91015625]
 [68.91321564]].
[2019-03-22 22:56:50,466] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.7227118e-31 2.6902906e-33], sum to 1.0000
[2019-03-22 22:56:50,470] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4303
[2019-03-22 22:56:50,477] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.66666666666666, 96.0, 1.0, 2.0, 0.3186770620333149, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 347715.9353761618, 347715.9353761618, 113042.6516407595], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4948800.0000, 
sim time next is 4949400.0000, 
raw observation next is [16.83333333333334, 95.0, 1.0, 2.0, 0.3230682688909025, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 352947.4073236616, 352947.4073236613, 113506.7247491548], 
processed observation next is [1.0, 0.2608695652173913, 0.40151515151515177, 0.95, 1.0, 1.0, 0.15383533611362812, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1307212619717265, 0.13072126197172643, 0.27684567011988975], 
reward next is 0.7232, 
noisyNet noise sample is [array([1.8368791], dtype=float32), -1.5093304]. 
=============================================
[2019-03-22 22:56:55,356] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 22:56:55,366] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8110
[2019-03-22 22:56:55,372] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 100.0, 1.0, 2.0, 0.2396032199161574, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 260156.1633263934, 260156.1633263934, 82221.0953935364], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5023800.0000, 
sim time next is 5024400.0000, 
raw observation next is [14.0, 100.0, 1.0, 2.0, 0.2403248374617912, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 260939.8907420854, 260939.8907420854, 82295.60234217563], 
processed observation next is [0.0, 0.13043478260869565, 0.2727272727272727, 1.0, 1.0, 1.0, 0.05040604682723899, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09664440397855015, 0.09664440397855015, 0.20072098132237956], 
reward next is 0.7993, 
noisyNet noise sample is [array([-2.095604], dtype=float32), 1.0653573]. 
=============================================
[2019-03-22 22:56:59,960] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.9390132e-33 1.7312512e-28], sum to 1.0000
[2019-03-22 22:56:59,971] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8813
[2019-03-22 22:56:59,977] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.83333333333334, 75.5, 1.0, 2.0, 0.4970978800757197, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 566506.8998635687, 566506.8998635684, 142264.4322041772], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5137800.0000, 
sim time next is 5138400.0000, 
raw observation next is [24.66666666666667, 77.0, 1.0, 2.0, 0.5006073544442183, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 570390.3987810084, 570390.3987810081, 142797.5310649717], 
processed observation next is [0.0, 0.4782608695652174, 0.7575757575757578, 0.77, 1.0, 1.0, 0.3757591930552729, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21125570325222534, 0.21125570325222523, 0.3482866611340773], 
reward next is 0.6517, 
noisyNet noise sample is [array([-1.9643605], dtype=float32), 0.7854725]. 
=============================================
[2019-03-22 22:57:05,202] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-22 22:57:05,205] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-22 22:57:05,207] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-22 22:57:05,207] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:57:05,207] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:57:05,208] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-22 22:57:05,211] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-22 22:57:05,212] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-22 22:57:05,212] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:57:05,215] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:57:05,214] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 22:57:05,235] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run15
[2019-03-22 22:57:05,253] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run15
[2019-03-22 22:57:05,271] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run15
[2019-03-22 22:57:05,294] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run15
[2019-03-22 22:57:05,310] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run15
[2019-03-22 22:57:41,313] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.34762833], dtype=float32), -0.14144413]
[2019-03-22 22:57:41,314] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [17.3, 51.0, 1.0, 2.0, 0.3109775985148606, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 337657.5163806478, 337657.5163806478, 85590.47077238429]
[2019-03-22 22:57:41,314] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 22:57:41,320] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 2.1943254e-35], sampled 0.5917436180073365
[2019-03-22 22:58:28,482] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.34762833], dtype=float32), -0.14144413]
[2019-03-22 22:58:28,482] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [25.3, 49.0, 1.0, 2.0, 0.3743337284839511, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 419634.8586446171, 419634.8586446175, 125795.7326900273]
[2019-03-22 22:58:28,482] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 22:58:28,484] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 5.3288606e-38], sampled 0.4621618472410668
[2019-03-22 22:58:31,119] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.34762833], dtype=float32), -0.14144413]
[2019-03-22 22:58:31,121] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [26.1, 56.5, 1.0, 2.0, 0.4407213397510574, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 501828.2810824841, 501828.2810824841, 136563.300434016]
[2019-03-22 22:58:31,122] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 22:58:31,125] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 2.0991092e-36], sampled 0.7126368266545873
[2019-03-22 22:58:31,926] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.34762833], dtype=float32), -0.14144413]
[2019-03-22 22:58:31,927] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [25.70057667, 63.28874145, 1.0, 2.0, 0.4824773330446243, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 550436.6983236442, 550436.6983236442, 142755.5430062443]
[2019-03-22 22:58:31,928] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 22:58:31,930] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 2.3366417e-34], sampled 0.8631613838068609
[2019-03-22 22:58:51,501] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.34762833], dtype=float32), -0.14144413]
[2019-03-22 22:58:51,502] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.76666666666667, 70.33333333333333, 1.0, 2.0, 0.3792224764391993, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 425854.6748331828, 425854.6748331828, 126567.8602739887]
[2019-03-22 22:58:51,503] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 22:58:51,507] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.8813996e-36], sampled 0.3344191765809773
[2019-03-22 22:58:59,686] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.34762833], dtype=float32), -0.14144413]
[2019-03-22 22:58:59,687] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [25.71699191333333, 41.61297087999999, 1.0, 2.0, 0.7910679885867222, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 877308.3888002393, 877308.3888002393, 168309.3960681349]
[2019-03-22 22:58:59,688] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 22:58:59,691] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 2.2022656e-36 4.3746278e-32 3.6794092e-25], sampled 0.5231941889034862
[2019-03-22 22:59:08,847] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9310 1705987275.5940 465.0000
[2019-03-22 22:59:08,919] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2494 1773207034.4548 173.0000
[2019-03-22 22:59:09,189] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3485 1683325900.1134 214.0000
[2019-03-22 22:59:09,297] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1147 1656209757.7786 80.0000
[2019-03-22 22:59:09,305] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5598 1663796639.0689 105.0000
[2019-03-22 22:59:10,323] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 350000, evaluation results [350000.0, 8512.249429056992, 1773207034.4547563, 173.0, 9061.114669779829, 1656209757.7786272, 80.0, 8856.559759326878, 1663796639.0688558, 105.0, 8596.931041181726, 1705987275.594041, 465.0, 8574.348472942609, 1683325900.1133502, 214.0]
[2019-03-22 22:59:18,118] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.3333976e-29 9.9999094e-01 8.0697472e-22 9.0597759e-06 2.1731579e-10], sum to 1.0000
[2019-03-22 22:59:18,131] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5635
[2019-03-22 22:59:18,136] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.03333333333333, 73.0, 1.0, 2.0, 0.3372064789246605, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 372113.1516304688, 372113.1516304688, 115881.8677688317], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5275200.0000, 
sim time next is 5275800.0000, 
raw observation next is [19.95, 73.0, 1.0, 2.0, 0.3314884391501637, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 365239.7284622306, 365239.7284622303, 115238.0096597298], 
processed observation next is [1.0, 0.043478260869565216, 0.5431818181818181, 0.73, 1.0, 1.0, 0.16436054893770458, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13527397350452985, 0.13527397350452974, 0.2810683162432434], 
reward next is 0.7189, 
noisyNet noise sample is [array([0.18058044], dtype=float32), -0.6042696]. 
=============================================
[2019-03-22 22:59:18,444] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.4669363e-30 1.5557128e-09 1.4309159e-22 9.5495775e-14 1.0000000e+00], sum to 1.0000
[2019-03-22 22:59:18,457] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3720
[2019-03-22 22:59:18,463] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [18.8, 89.0, 1.0, 2.0, 0.3488247498972732, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 389454.8216068432, 389454.8216068435, 118619.1428547765], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5286000.0000, 
sim time next is 5286600.0000, 
raw observation next is [18.8, 88.5, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 1.0, 0.3, 6.911199999999999, 6.9112, 77.3421103, 386382.6334656695, 386382.6334656698, 173405.1950875618], 
processed observation next is [1.0, 0.17391304347826086, 0.49090909090909096, 0.885, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 0.5, 0.0, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.1431046790613591, 0.14310467906135918, 0.42293950021356536], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0619277], dtype=float32), 0.0443161]. 
=============================================
[2019-03-22 22:59:18,936] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.7213813e-28 1.0000000e+00 5.2926686e-19 3.2973912e-09 3.1632170e-09], sum to 1.0000
[2019-03-22 22:59:18,951] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2025
[2019-03-22 22:59:18,955] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 88.0, 1.0, 2.0, 0.344817918708679, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 384382.3004495944, 384382.3004495944, 118034.0926126718], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5287200.0000, 
sim time next is 5287800.0000, 
raw observation next is [18.8, 87.5, 1.0, 2.0, 0.3433468143561927, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 382398.1299351614, 382398.1299351614, 117768.2579528532], 
processed observation next is [1.0, 0.17391304347826086, 0.49090909090909096, 0.875, 1.0, 1.0, 0.17918351794524084, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14162893701302273, 0.14162893701302273, 0.28723965354354436], 
reward next is 0.7128, 
noisyNet noise sample is [array([-2.4319599], dtype=float32), -1.1356223]. 
=============================================
[2019-03-22 22:59:24,010] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 8.5948745e-28 4.0125998e-21 2.8540648e-15], sum to 1.0000
[2019-03-22 22:59:24,019] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9636
[2019-03-22 22:59:24,024] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.11666666666667, 79.33333333333334, 1.0, 2.0, 0.4659635051582689, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 531633.2535090592, 531633.2535090592, 136582.0090406086], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5361000.0000, 
sim time next is 5361600.0000, 
raw observation next is [22.93333333333333, 79.66666666666667, 1.0, 2.0, 0.4624986099105453, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 527594.4086957108, 527594.4086957106, 135930.1338090384], 
processed observation next is [1.0, 0.043478260869565216, 0.6787878787878786, 0.7966666666666667, 1.0, 1.0, 0.3281232623881816, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19540533655396697, 0.19540533655396689, 0.33153691172936195], 
reward next is 0.6685, 
noisyNet noise sample is [array([0.06883572], dtype=float32), 1.7833048]. 
=============================================
[2019-03-22 22:59:34,051] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 5.521658e-32], sum to 1.0000
[2019-03-22 22:59:34,060] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3812
[2019-03-22 22:59:34,066] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.06666666666667, 63.66666666666667, 1.0, 2.0, 0.4794442009617305, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 547070.1049327882, 547070.1049327882, 138872.1390800025], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5512800.0000, 
sim time next is 5513400.0000, 
raw observation next is [25.8, 65.5, 1.0, 2.0, 0.481388225503187, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 549271.6752122573, 549271.675212257, 139199.9087801524], 
processed observation next is [1.0, 0.8260869565217391, 0.8090909090909091, 0.655, 1.0, 1.0, 0.35173528187898373, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20343395378231752, 0.2034339537823174, 0.339511972634518], 
reward next is 0.6605, 
noisyNet noise sample is [array([-0.5134418], dtype=float32), 1.5175436]. 
=============================================
[2019-03-22 22:59:34,598] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 6.3043310e-36 7.4966041e-30 2.1393147e-17], sum to 1.0000
[2019-03-22 22:59:34,607] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7285
[2019-03-22 22:59:34,616] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.15, 81.5, 1.0, 2.0, 0.4463129999856838, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 508438.2413994059, 508438.2413994059, 133053.3941472343], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5527800.0000, 
sim time next is 5528400.0000, 
raw observation next is [21.96666666666667, 82.33333333333334, 1.0, 2.0, 0.4439149907131262, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 505576.9033397907, 505576.9033397904, 132653.1193118897], 
processed observation next is [1.0, 1.0, 0.6348484848484849, 0.8233333333333335, 1.0, 1.0, 0.3048937383914077, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18725070494066323, 0.18725070494066312, 0.3235441934436334], 
reward next is 0.6765, 
noisyNet noise sample is [array([0.43555716], dtype=float32), 0.8369759]. 
=============================================
[2019-03-22 22:59:38,945] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 2.0832734e-37 0.0000000e+00 4.0979708e-30], sum to 1.0000
[2019-03-22 22:59:38,956] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6593
[2019-03-22 22:59:38,959] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.7, 82.0, 1.0, 2.0, 0.4393059081802318, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 499921.5128512738, 499921.5128512738, 131751.1010463098], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5597400.0000, 
sim time next is 5598000.0000, 
raw observation next is [20.5, 87.0, 1.0, 2.0, 0.4245287692314325, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 481669.434549061, 481669.434549061, 129077.6790261347], 
processed observation next is [1.0, 0.8260869565217391, 0.5681818181818182, 0.87, 1.0, 1.0, 0.2806609615392906, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1783960868700226, 0.1783960868700226, 0.31482360738081633], 
reward next is 0.6852, 
noisyNet noise sample is [array([0.23418014], dtype=float32), 0.06096115]. 
=============================================
[2019-03-22 22:59:38,971] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[49.053314]
 [48.71266 ]
 [48.438007]
 [47.590088]
 [46.90332 ]], R is [[49.88581085]
 [50.06560898]
 [50.23753357]
 [50.40172195]
 [50.5588913 ]].
[2019-03-22 22:59:42,853] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 5.4312150e-35 4.6321874e-27], sum to 1.0000
[2019-03-22 22:59:42,865] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4103
[2019-03-22 22:59:42,869] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.43333333333333, 97.0, 1.0, 2.0, 0.3842121643695404, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 432121.6260765143, 432121.6260765143, 123004.8795526978], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5635200.0000, 
sim time next is 5635800.0000, 
raw observation next is [18.25, 97.0, 1.0, 2.0, 0.3786374002901878, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 424959.6156763367, 424959.615676337, 122077.3357094135], 
processed observation next is [0.0, 0.21739130434782608, 0.4659090909090909, 0.97, 1.0, 1.0, 0.2232967503627347, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15739245025049506, 0.15739245025049517, 0.29774959929125244], 
reward next is 0.7023, 
noisyNet noise sample is [array([0.53229827], dtype=float32), 2.658701]. 
=============================================
[2019-03-22 22:59:43,135] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 9.703208e-31], sum to 1.0000
[2019-03-22 22:59:43,150] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3407
[2019-03-22 22:59:43,157] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.8, 88.0, 1.0, 2.0, 0.2578950711482401, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 280022.7902179685, 280022.7902179688, 88273.61305290573], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5661000.0000, 
sim time next is 5661600.0000, 
raw observation next is [15.9, 87.33333333333333, 1.0, 2.0, 0.2579427562230403, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 280074.5816400938, 280074.5816400941, 88509.1945888216], 
processed observation next is [0.0, 0.5217391304347826, 0.3590909090909091, 0.8733333333333333, 1.0, 1.0, 0.07242844527880037, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10373132653336808, 0.1037313265333682, 0.2158760843629795], 
reward next is 0.7841, 
noisyNet noise sample is [array([-0.37378153], dtype=float32), -0.30920306]. 
=============================================
[2019-03-22 22:59:44,926] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 1.624226e-37], sum to 1.0000
[2019-03-22 22:59:44,935] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1774
[2019-03-22 22:59:44,942] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.6, 74.0, 1.0, 2.0, 0.2116034279376582, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 229747.3947471854, 229747.3947471857, 74391.79374336688], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5677800.0000, 
sim time next is 5678400.0000, 
raw observation next is [15.7, 73.0, 1.0, 2.0, 0.21366325472341, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 231984.3750128008, 231984.3750128005, 74537.32473470323], 
processed observation next is [0.0, 0.7391304347826086, 0.35, 0.73, 1.0, 1.0, 0.01707906840426248, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08592013889362993, 0.08592013889362982, 0.1817983530114713], 
reward next is 0.8182, 
noisyNet noise sample is [array([0.77468544], dtype=float32), -0.88718665]. 
=============================================
[2019-03-22 23:00:00,307] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 2.0389639e-20], sum to 1.0000
[2019-03-22 23:00:00,318] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9122
[2019-03-22 23:00:00,327] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.2, 76.5, 1.0, 2.0, 0.2503044072005459, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 271778.5349785483, 271778.5349785483, 87907.36971247607], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5895000.0000, 
sim time next is 5895600.0000, 
raw observation next is [17.2, 76.0, 1.0, 2.0, 0.2481930609325699, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 269485.4168681987, 269485.4168681987, 87155.96487345401], 
processed observation next is [1.0, 0.21739130434782608, 0.41818181818181815, 0.76, 1.0, 1.0, 0.060241326165712365, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09980941365488842, 0.09980941365488842, 0.21257552408159514], 
reward next is 0.7874, 
noisyNet noise sample is [array([-1.0862964], dtype=float32), 2.24484]. 
=============================================
[2019-03-22 23:00:02,161] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.8897269e-38 1.0000000e+00 7.5021955e-34 9.7390754e-37 7.4355525e-27], sum to 1.0000
[2019-03-22 23:00:02,172] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4905
[2019-03-22 23:00:02,181] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.63333333333333, 51.33333333333334, 1.0, 2.0, 0.8416515847427172, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 957670.7667713922, 957670.7667713922, 183413.5135892179], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5923200.0000, 
sim time next is 5923800.0000, 
raw observation next is [26.9, 50.0, 1.0, 2.0, 0.8787530682669181, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 999982.4502289703, 999982.4502289703, 189390.0657191497], 
processed observation next is [1.0, 0.5652173913043478, 0.859090909090909, 0.5, 1.0, 1.0, 0.8484413353336475, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.37036387045517416, 0.37036387045517416, 0.46192698955890166], 
reward next is 0.5381, 
noisyNet noise sample is [array([-0.44262847], dtype=float32), -0.07514109]. 
=============================================
[2019-03-22 23:00:14,283] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-22 23:00:14,284] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-22 23:00:14,285] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:00:14,286] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-22 23:00:14,287] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-22 23:00:14,288] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:00:14,288] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:00:14,291] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-22 23:00:14,292] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-22 23:00:14,293] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:00:14,294] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:00:14,319] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run16
[2019-03-22 23:00:14,336] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run16
[2019-03-22 23:00:14,338] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run16
[2019-03-22 23:00:14,388] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run16
[2019-03-22 23:00:14,389] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run16
[2019-03-22 23:00:29,559] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.5896836], dtype=float32), 0.08843139]
[2019-03-22 23:00:29,560] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.0, 94.0, 1.0, 2.0, 0.3883298200932211, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 437734.1677225465, 437734.1677225465, 123879.1313302246]
[2019-03-22 23:00:29,564] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:00:29,567] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.3342135e-29], sampled 0.9978800508667045
[2019-03-22 23:00:52,297] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.5896836], dtype=float32), 0.08843139]
[2019-03-22 23:00:52,299] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.24964065, 73.118169765, 1.0, 2.0, 0.2783562634490807, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 302228.5703753644, 302228.5703753644, 101882.0407258049]
[2019-03-22 23:00:52,301] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:00:52,304] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 3.2182426e-36], sampled 0.577116775862122
[2019-03-22 23:01:10,067] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.5896836], dtype=float32), 0.08843139]
[2019-03-22 23:01:10,069] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [23.23758114333333, 91.01657463666666, 1.0, 2.0, 0.5456882703671553, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 620109.4012401093, 620109.4012401093, 153697.9387202508]
[2019-03-22 23:01:10,069] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:01:10,074] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 9.6862906e-27], sampled 0.20110750753403106
[2019-03-22 23:01:25,427] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.5896836], dtype=float32), 0.08843139]
[2019-03-22 23:01:25,430] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.178321485, 94.21691036499999, 1.0, 2.0, 0.3223183604178075, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 349974.8296093236, 349974.8296093236, 114443.9167293482]
[2019-03-22 23:01:25,433] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:01:25,438] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 3.7275869e-31], sampled 0.015315977790933522
[2019-03-22 23:02:17,401] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-22 23:02:17,486] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9513 1705935940.2592 465.0000
[2019-03-22 23:02:17,673] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1148 1656229146.4555 80.0000
[2019-03-22 23:02:17,706] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2494 1773207034.4548 173.0000
[2019-03-22 23:02:17,752] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3791 1683296663.2329 214.0000
[2019-03-22 23:02:18,767] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 375000, evaluation results [375000.0, 8512.249429056992, 1773207034.4547563, 173.0, 9061.114827412715, 1656229146.4555063, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8596.951295847348, 1705935940.259201, 465.0, 8574.379088229873, 1683296663.232874, 214.0]
[2019-03-22 23:02:31,102] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.3025458e-35 1.0935288e-28], sum to 1.0000
[2019-03-22 23:02:31,114] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3149
[2019-03-22 23:02:31,119] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.2, 87.0, 1.0, 2.0, 0.4681175417543252, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 534133.1537381273, 534133.1537381273, 137025.6336151569], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6328800.0000, 
sim time next is 6329400.0000, 
raw observation next is [22.28333333333333, 87.0, 1.0, 2.0, 0.4701628329898694, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 536483.7820127475, 536483.7820127471, 137381.8144449272], 
processed observation next is [0.0, 0.2608695652173913, 0.6492424242424242, 0.87, 1.0, 1.0, 0.3377035412373367, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19869769704175833, 0.1986976970417582, 0.3350775962071395], 
reward next is 0.6649, 
noisyNet noise sample is [array([-0.09026147], dtype=float32), 0.3647951]. 
=============================================
[2019-03-22 23:02:36,104] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 2.3683138e-31], sum to 1.0000
[2019-03-22 23:02:36,111] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8697
[2019-03-22 23:02:36,116] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.2, 67.0, 1.0, 2.0, 0.550042919360701, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 623976.0803555283, 623976.0803555286, 150485.0832039163], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6352800.0000, 
sim time next is 6353400.0000, 
raw observation next is [27.2, 67.0, 1.0, 2.0, 0.550490128503446, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 624483.2287971501, 624483.2287971501, 150542.7905304362], 
processed observation next is [0.0, 0.5217391304347826, 0.8727272727272727, 0.67, 1.0, 1.0, 0.4381126606293075, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2312900847396852, 0.2312900847396852, 0.3671775378791127], 
reward next is 0.6328, 
noisyNet noise sample is [array([-0.88067096], dtype=float32), 0.69400215]. 
=============================================
[2019-03-22 23:02:38,315] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.00000000e+00 1.00000000e+00 0.00000000e+00 1.09775037e-35
 1.19323796e-29], sum to 1.0000
[2019-03-22 23:02:38,325] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4044
[2019-03-22 23:02:38,331] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 76.0, 1.0, 2.0, 0.5306374092415602, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 604106.6554694513, 604106.6554694513, 146853.6684796929], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6386400.0000, 
sim time next is 6387000.0000, 
raw observation next is [25.0, 76.0, 1.0, 2.0, 0.5270084509968368, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 600051.6713762527, 600051.6713762527, 146347.2077498414], 
processed observation next is [0.0, 0.9565217391304348, 0.7727272727272727, 0.76, 1.0, 1.0, 0.40876056374604597, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22224135976898246, 0.22224135976898246, 0.3569444091459546], 
reward next is 0.6431, 
noisyNet noise sample is [array([-0.02497444], dtype=float32), -0.031062204]. 
=============================================
[2019-03-22 23:02:38,343] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[61.373203]
 [61.36045 ]
 [61.364452]
 [61.368515]
 [61.376255]], R is [[61.39836502]
 [61.42620087]
 [61.45139313]
 [61.47423172]
 [61.49502182]].
[2019-03-22 23:02:41,424] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.5794504e-30 1.4177487e-25 1.3088682e-27], sum to 1.0000
[2019-03-22 23:02:41,440] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4946
[2019-03-22 23:02:41,449] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.43333333333333, 97.66666666666667, 1.0, 2.0, 0.6454321332224735, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 727851.0400586452, 727851.0400586452, 151163.1067690374], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6441600.0000, 
sim time next is 6442200.0000, 
raw observation next is [18.25, 96.5, 1.0, 2.0, 0.685815237600987, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 771109.5708998215, 771109.5708998211, 155091.8846550043], 
processed observation next is [1.0, 0.5652173913043478, 0.4659090909090909, 0.965, 1.0, 1.0, 0.6072690470012336, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.28559613737030426, 0.2855961373703041, 0.3782728894024495], 
reward next is 0.6217, 
noisyNet noise sample is [array([-0.00640877], dtype=float32), 1.1844528]. 
=============================================
[2019-03-22 23:02:42,601] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.2776102e-32 1.0656486e-37], sum to 1.0000
[2019-03-22 23:02:42,612] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5627
[2019-03-22 23:02:42,619] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 72.33333333333334, 1.0, 2.0, 0.3568955481932563, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 393536.5653918713, 393536.5653918713, 117268.8249083241], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6456000.0000, 
sim time next is 6456600.0000, 
raw observation next is [20.0, 71.0, 1.0, 2.0, 0.3431822689477147, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 377000.5856255842, 377000.5856255842, 115694.5253542133], 
processed observation next is [1.0, 0.7391304347826086, 0.5454545454545454, 0.71, 1.0, 1.0, 0.17897783618464336, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13962984652799415, 0.13962984652799415, 0.2821817691566178], 
reward next is 0.7178, 
noisyNet noise sample is [array([-0.28759637], dtype=float32), -1.1717846]. 
=============================================
[2019-03-22 23:02:49,881] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.3775319e-36 3.8245704e-37], sum to 1.0000
[2019-03-22 23:02:49,890] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0571
[2019-03-22 23:02:49,897] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.81666666666667, 69.66666666666667, 1.0, 2.0, 0.2220422816768761, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 241084.1384045786, 241084.1384045788, 74669.809151459], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6567000.0000, 
sim time next is 6567600.0000, 
raw observation next is [15.53333333333333, 72.33333333333334, 1.0, 2.0, 0.2191455298933444, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 237938.198271567, 237938.1982715668, 74503.39042978284], 
processed observation next is [1.0, 0.0, 0.34242424242424224, 0.7233333333333334, 1.0, 1.0, 0.02393191236668049, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0881252586190989, 0.08812525861909881, 0.18171558641410449], 
reward next is 0.8183, 
noisyNet noise sample is [array([0.9977669], dtype=float32), -0.8109942]. 
=============================================
[2019-03-22 23:03:10,053] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 3.582259e-37 0.000000e+00], sum to 1.0000
[2019-03-22 23:03:10,066] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1176
[2019-03-22 23:03:10,077] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.66666666666667, 83.0, 1.0, 2.0, 0.3859867166942655, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 436057.7829173497, 436057.7829173494, 124216.844483614], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6856800.0000, 
sim time next is 6857400.0000, 
raw observation next is [21.13333333333334, 80.5, 1.0, 2.0, 0.3906567917194714, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 441856.3276353395, 441856.3276353395, 124949.6191654665], 
processed observation next is [0.0, 0.34782608695652173, 0.5969696969696973, 0.805, 1.0, 1.0, 0.2383209896493392, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1636504917167924, 0.1636504917167924, 0.30475516869625974], 
reward next is 0.6952, 
noisyNet noise sample is [array([0.30671066], dtype=float32), -0.26976442]. 
=============================================
[2019-03-22 23:03:17,264] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 3.694659e-38 9.498861e-36 2.864264e-29], sum to 1.0000
[2019-03-22 23:03:17,274] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5841
[2019-03-22 23:03:17,277] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.7, 58.0, 1.0, 2.0, 0.4967064981049163, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 566314.1229057565, 566314.1229057565, 141917.8560337452], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6956400.0000, 
sim time next is 6957000.0000, 
raw observation next is [27.7, 58.0, 1.0, 2.0, 0.4972360187250106, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 566917.837599674, 566917.837599674, 141980.2583644099], 
processed observation next is [0.0, 0.5217391304347826, 0.8954545454545454, 0.58, 1.0, 1.0, 0.3715450234062632, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20996956948136075, 0.20996956948136075, 0.3462933130839266], 
reward next is 0.6537, 
noisyNet noise sample is [array([0.52875865], dtype=float32), -0.7539013]. 
=============================================
[2019-03-22 23:03:17,296] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[67.677956]
 [67.61442 ]
 [67.56492 ]
 [67.51405 ]
 [67.47973 ]], R is [[67.72125244]
 [67.69789886]
 [67.67488098]
 [67.6524353 ]
 [67.63121796]].
[2019-03-22 23:03:21,259] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 8.252151e-37], sum to 1.0000
[2019-03-22 23:03:21,271] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4343
[2019-03-22 23:03:21,281] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 96.0, 1.0, 2.0, 0.4328517320730246, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 490583.7373656559, 490583.7373656556, 129522.880800824], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7017600.0000, 
sim time next is 7018200.0000, 
raw observation next is [19.4, 96.0, 1.0, 2.0, 0.4164821455198286, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 471978.468900367, 471978.468900367, 127912.8348188421], 
processed observation next is [1.0, 0.21739130434782608, 0.5181818181818181, 0.96, 1.0, 1.0, 0.2706026818997857, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17480684033346924, 0.17480684033346924, 0.3119825239483954], 
reward next is 0.6880, 
noisyNet noise sample is [array([0.91550446], dtype=float32), 1.4888232]. 
=============================================
[2019-03-22 23:03:22,227] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 6.6264470e-35 1.7367701e-33 4.7009236e-32], sum to 1.0000
[2019-03-22 23:03:22,235] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9036
[2019-03-22 23:03:22,239] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.3, 91.5, 1.0, 2.0, 0.3579503458705839, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 398541.8136338969, 398541.8136338966, 118876.7831089272], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7079400.0000, 
sim time next is 7080000.0000, 
raw observation next is [18.3, 91.0, 1.0, 2.0, 0.3549638959779459, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 394882.5952383589, 394882.5952383587, 118496.5870456925], 
processed observation next is [1.0, 0.9565217391304348, 0.4681818181818182, 0.91, 1.0, 1.0, 0.1937048699724324, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14625281305124405, 0.14625281305124396, 0.28901606596510365], 
reward next is 0.7110, 
noisyNet noise sample is [array([0.01547741], dtype=float32), 1.6641523]. 
=============================================
[2019-03-22 23:03:22,256] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[59.62194 ]
 [59.606857]
 [59.595745]
 [59.589577]
 [59.56186 ]], R is [[59.7541275 ]
 [59.866642  ]
 [59.97714615]
 [60.08575439]
 [60.19246674]].
[2019-03-22 23:03:22,704] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-22 23:03:22,706] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-22 23:03:22,707] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:03:22,709] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-22 23:03:22,712] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-22 23:03:22,714] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:03:22,713] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-22 23:03:22,715] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:03:22,718] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:03:22,717] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-22 23:03:22,721] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:03:22,744] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run17
[2019-03-22 23:03:22,745] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run17
[2019-03-22 23:03:22,782] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run17
[2019-03-22 23:03:22,800] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run17
[2019-03-22 23:03:22,801] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run17
[2019-03-22 23:05:16,159] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.5759985], dtype=float32), 0.10377901]
[2019-03-22 23:05:16,161] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.73660413, 93.83919522333333, 1.0, 2.0, 0.3425950574946798, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 379748.2294900888, 379748.2294900888, 121269.9632795155]
[2019-03-22 23:05:16,162] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:05:16,165] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.5903861e-37 3.3886582e-34], sampled 0.6328780540425122
[2019-03-22 23:05:25,151] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-22 23:05:25,500] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2492 1773187030.7201 173.0000
[2019-03-22 23:05:25,799] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-22 23:05:25,938] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5599 1663815647.6096 105.0000
[2019-03-22 23:05:25,951] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9309 1705967916.6745 465.0000
[2019-03-22 23:05:26,969] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 400000, evaluation results [400000.0, 8512.249193409023, 1773187030.7201214, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8856.559925897878, 1663815647.6095803, 105.0, 8596.930884973775, 1705967916.6744611, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-22 23:05:29,356] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.2691143e-37 0.0000000e+00], sum to 1.0000
[2019-03-22 23:05:29,364] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6414
[2019-03-22 23:05:29,368] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 92.0, 1.0, 2.0, 0.3803812412426033, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 426480.7519735183, 426480.7519735183, 122018.9246141035], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7072800.0000, 
sim time next is 7073400.0000, 
raw observation next is [18.8, 92.5, 1.0, 2.0, 0.3811428879522196, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 427635.4516747369, 427635.4516747372, 122227.2655873203], 
processed observation next is [1.0, 0.8695652173913043, 0.49090909090909096, 0.925, 1.0, 1.0, 0.2264286099402745, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15838350062027293, 0.15838350062027304, 0.2981152819202934], 
reward next is 0.7019, 
noisyNet noise sample is [array([-1.5916107], dtype=float32), -1.5607474]. 
=============================================
[2019-03-22 23:05:38,219] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 5.2603803e-35 6.6831167e-25 2.5531909e-22], sum to 1.0000
[2019-03-22 23:05:38,229] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8234
[2019-03-22 23:05:38,234] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.9, 67.0, 1.0, 2.0, 0.4031471280923986, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 437808.6538219318, 437808.6538219318, 100427.6633211725], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7202400.0000, 
sim time next is 7203000.0000, 
raw observation next is [18.35, 65.0, 1.0, 2.0, 0.4156810941984856, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 451426.5765175346, 451426.5765175346, 102911.3263784887], 
processed observation next is [1.0, 0.34782608695652173, 0.4704545454545455, 0.65, 1.0, 1.0, 0.26960136774810695, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16719502833982763, 0.16719502833982763, 0.25100323506948463], 
reward next is 0.7490, 
noisyNet noise sample is [array([1.5690349], dtype=float32), 0.5968492]. 
=============================================
[2019-03-22 23:05:38,248] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[55.917305]
 [55.964935]
 [56.154232]
 [56.31739 ]
 [56.281826]], R is [[56.16145706]
 [56.35489655]
 [56.55562973]
 [56.77378845]
 [57.01044083]].
[2019-03-22 23:05:44,405] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.5640688e-38 1.0000000e+00 1.7792827e-37 3.4581345e-32 1.8191773e-31], sum to 1.0000
[2019-03-22 23:05:44,414] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4403
[2019-03-22 23:05:44,419] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 46.0, 1.0, 2.0, 0.4642284765516339, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 515373.3937662491, 515373.3937662491, 127524.4245233088], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7304400.0000, 
sim time next is 7305000.0000, 
raw observation next is [25.18333333333334, 45.5, 1.0, 2.0, 0.5630220458679718, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 625691.989744781, 625691.989744781, 137496.6502664478], 
processed observation next is [1.0, 0.5652173913043478, 0.7810606060606063, 0.455, 1.0, 1.0, 0.45377755733496467, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23173777397954853, 0.23173777397954853, 0.335357683576702], 
reward next is 0.6646, 
noisyNet noise sample is [array([-0.54404616], dtype=float32), 0.17301801]. 
=============================================
[2019-03-22 23:05:44,439] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[80.10618 ]
 [80.0718  ]
 [80.14822 ]
 [80.121254]
 [79.68755 ]], R is [[79.66173553]
 [79.55408478]
 [79.43929291]
 [79.33068085]
 [79.22848511]].
[2019-03-22 23:05:49,607] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.6615635e-30 3.4226211e-32 6.4726721e-28], sum to 1.0000
[2019-03-22 23:05:49,623] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9414
[2019-03-22 23:05:49,628] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666666, 71.16666666666667, 1.0, 2.0, 0.8692718157800038, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 986604.6346777448, 986604.6346777448, 185763.6218621689], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7377000.0000, 
sim time next is 7377600.0000, 
raw observation next is [23.13333333333333, 69.33333333333334, 1.0, 2.0, 0.8241360033544222, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 936358.1759241133, 936358.1759241135, 179536.7853590552], 
processed observation next is [1.0, 0.391304347826087, 0.6878787878787876, 0.6933333333333335, 1.0, 1.0, 0.7801700041930276, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.34679932441633826, 0.3467993244163383, 0.43789459843672], 
reward next is 0.5621, 
noisyNet noise sample is [array([-0.8151597], dtype=float32), 2.1460211]. 
=============================================
[2019-03-22 23:05:51,691] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:05:51,701] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1523
[2019-03-22 23:05:51,707] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.16666666666667, 68.0, 1.0, 2.0, 0.4791114716166387, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 546665.227444737, 546665.227444737, 138976.5654148711], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7406400.0000, 
sim time next is 7407000.0000, 
raw observation next is [24.15, 72.0, 1.0, 2.0, 0.4443708584850745, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 506986.7386376961, 506986.7386376961, 134270.2380343258], 
processed observation next is [1.0, 0.7391304347826086, 0.734090909090909, 0.72, 1.0, 1.0, 0.3054635731063431, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18777286616210967, 0.18777286616210967, 0.3274883854495751], 
reward next is 0.6725, 
noisyNet noise sample is [array([0.5898989], dtype=float32), -0.96201634]. 
=============================================
[2019-03-22 23:05:51,719] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[52.832733]
 [50.786278]
 [47.952206]
 [47.57752 ]
 [47.74209 ]], R is [[53.74087524]
 [53.86450195]
 [53.79047012]
 [53.41415405]
 [53.13178635]].
[2019-03-22 23:05:52,158] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:05:52,169] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3182
[2019-03-22 23:05:52,178] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.6, 83.66666666666667, 1.0, 2.0, 0.4376473911660486, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 498025.2525524452, 498025.2525524452, 131576.1662350282], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7413000.0000, 
sim time next is 7413600.0000, 
raw observation next is [21.6, 83.33333333333334, 1.0, 2.0, 0.4391496702711206, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 499640.4693795475, 499640.4693795475, 131636.304487179], 
processed observation next is [1.0, 0.8260869565217391, 0.6181818181818183, 0.8333333333333335, 1.0, 1.0, 0.2989370878389007, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18505202569612872, 0.18505202569612872, 0.32106415728580245], 
reward next is 0.6789, 
noisyNet noise sample is [array([-1.6000453], dtype=float32), -0.5832828]. 
=============================================
[2019-03-22 23:05:56,519] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.8008410e-36 2.4941832e-34 6.3323914e-27], sum to 1.0000
[2019-03-22 23:05:56,531] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9922
[2019-03-22 23:05:56,538] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.15, 65.0, 1.0, 2.0, 0.5327459462694448, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 605695.1948700343, 605695.1948700347, 147636.8027553156], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7475400.0000, 
sim time next is 7476000.0000, 
raw observation next is [27.33333333333334, 63.66666666666667, 1.0, 2.0, 0.530969659239717, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 603845.5365854681, 603845.5365854681, 147316.7683450024], 
processed observation next is [0.0, 0.5217391304347826, 0.878787878787879, 0.6366666666666667, 1.0, 1.0, 0.41371207404964616, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22364649503165485, 0.22364649503165485, 0.35930919108537174], 
reward next is 0.6407, 
noisyNet noise sample is [array([0.06306286], dtype=float32), -0.34380022]. 
=============================================
[2019-03-22 23:05:56,547] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[65.17934 ]
 [65.17891 ]
 [65.19615 ]
 [65.229996]
 [65.257904]], R is [[65.18223572]
 [65.1703186 ]
 [65.15822601]
 [65.14659882]
 [65.13640594]].
[2019-03-22 23:05:56,996] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:05:57,006] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7519
[2019-03-22 23:05:57,009] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.36666666666667, 61.16666666666667, 1.0, 2.0, 0.4783238998506125, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 545808.2865918113, 545808.2865918113, 138544.2010422015], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7494600.0000, 
sim time next is 7495200.0000, 
raw observation next is [26.1, 62.0, 1.0, 2.0, 0.4752412647219403, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 542285.1186328741, 542285.1186328741, 137985.1391010228], 
processed observation next is [0.0, 0.782608695652174, 0.8227272727272728, 0.62, 1.0, 1.0, 0.3440515809024253, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20084634023439782, 0.20084634023439782, 0.3365491197585922], 
reward next is 0.6635, 
noisyNet noise sample is [array([-0.4011638], dtype=float32), -0.61392814]. 
=============================================
[2019-03-22 23:06:04,891] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.6293746e-32 4.4977048e-29], sum to 1.0000
[2019-03-22 23:06:04,901] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3016
[2019-03-22 23:06:04,906] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.05, 96.0, 1.0, 2.0, 0.4364758971397096, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 496616.6179523598, 496616.6179523601, 131385.0327189366], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7597800.0000, 
sim time next is 7598400.0000, 
raw observation next is [20.06666666666667, 96.0, 1.0, 2.0, 0.4366455857491289, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 496849.2294847692, 496849.2294847689, 131440.2816305559], 
processed observation next is [0.0, 0.9565217391304348, 0.5484848484848487, 0.96, 1.0, 1.0, 0.29580698218641105, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18401823314250712, 0.18401823314250698, 0.3205860527574534], 
reward next is 0.6794, 
noisyNet noise sample is [array([-0.69587594], dtype=float32), 0.16424441]. 
=============================================
[2019-03-22 23:06:10,410] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 1.115756e-36], sum to 1.0000
[2019-03-22 23:06:10,421] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3352
[2019-03-22 23:06:10,426] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 87.66666666666667, 1.0, 2.0, 0.4801964000530251, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 547941.5427234143, 547941.5427234146, 138837.3613164925], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7676400.0000, 
sim time next is 7677000.0000, 
raw observation next is [22.15, 89.0, 1.0, 2.0, 0.480173045748175, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 547916.299239073, 547916.299239073, 138814.8170976414], 
processed observation next is [1.0, 0.8695652173913043, 0.6431818181818181, 0.89, 1.0, 1.0, 0.3502163071852187, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20293196268113814, 0.20293196268113814, 0.33857272462839366], 
reward next is 0.6614, 
noisyNet noise sample is [array([-1.1365945], dtype=float32), -0.88111097]. 
=============================================
[2019-03-22 23:06:10,455] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[69.43242]
 [69.34048]
 [69.55903]
 [69.91324]
 [69.78653]], R is [[69.29374695]
 [69.26217651]
 [69.2305603 ]
 [69.19868469]
 [69.16629791]].
[2019-03-22 23:06:18,538] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:06:18,546] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4014
[2019-03-22 23:06:18,554] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.73333333333333, 78.0, 1.0, 2.0, 0.2581353653524849, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 280283.7771472135, 280283.7771472135, 86620.47034872555], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7804200.0000, 
sim time next is 7804800.0000, 
raw observation next is [17.2, 75.0, 1.0, 2.0, 0.2772305623653217, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 301023.7881197027, 301023.7881197027, 89284.79496065024], 
processed observation next is [1.0, 0.34782608695652173, 0.41818181818181815, 0.75, 1.0, 1.0, 0.09653820295665208, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11149029189618619, 0.11149029189618619, 0.2177677925869518], 
reward next is 0.7822, 
noisyNet noise sample is [array([-0.5486742], dtype=float32), 0.19579393]. 
=============================================
[2019-03-22 23:06:23,650] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:06:23,651] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:06:23,700] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run3
[2019-03-22 23:06:26,529] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:06:26,530] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:06:26,569] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run3
[2019-03-22 23:06:28,246] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:06:28,246] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:06:28,256] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run3
[2019-03-22 23:06:28,331] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:06:28,331] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:06:28,338] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run3
[2019-03-22 23:06:28,420] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:06:28,420] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:06:28,432] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run3
[2019-03-22 23:06:28,597] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:06:28,597] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:06:28,606] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run3
[2019-03-22 23:06:28,686] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:06:28,687] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:06:28,693] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run3
[2019-03-22 23:06:28,894] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:06:28,895] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:06:28,904] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run3
[2019-03-22 23:06:28,958] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:06:28,958] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:06:28,965] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run3
[2019-03-22 23:06:28,983] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:06:28,984] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:06:28,989] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:06:28,990] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:06:28,999] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run3
[2019-03-22 23:06:29,018] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:06:29,019] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:06:29,022] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run3
[2019-03-22 23:06:29,037] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:06:29,039] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:06:29,039] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:06:29,041] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:06:29,045] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run3
[2019-03-22 23:06:29,066] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run3
[2019-03-22 23:06:29,081] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:06:29,081] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:06:29,087] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run3
[2019-03-22 23:06:29,104] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run3
[2019-03-22 23:06:29,125] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:06:29,126] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:06:29,127] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run3
[2019-03-22 23:06:30,212] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-22 23:06:30,213] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-22 23:06:30,219] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-22 23:06:30,221] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:06:30,221] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-22 23:06:30,222] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:06:30,223] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:06:30,226] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run18
[2019-03-22 23:06:30,241] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-22 23:06:30,243] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:06:30,244] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run18
[2019-03-22 23:06:30,264] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-22 23:06:30,265] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:06:30,266] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run18
[2019-03-22 23:06:30,283] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run18
[2019-03-22 23:06:30,305] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run18
[2019-03-22 23:06:39,870] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.35270676], dtype=float32), 0.007890927]
[2019-03-22 23:06:39,874] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.76768779, 69.79145202999999, 1.0, 2.0, 0.3932264669581655, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 436444.1581301268, 436444.1581301264, 125551.7064330988]
[2019-03-22 23:06:39,874] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:06:39,877] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.07830342858250394
[2019-03-22 23:07:14,940] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.35270676], dtype=float32), 0.007890927]
[2019-03-22 23:07:14,941] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [30.84513682666667, 66.25025775333333, 1.0, 2.0, 0.757932195183162, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9684127518861766, 6.936314787157817, 6.9112, 95.55330086476866, 1400248.244836741, 1390169.08142027, 310197.5627974763]
[2019-03-22 23:07:14,943] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:07:14,946] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.9728037278510062
[2019-03-22 23:07:14,947] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1400248.244836741 W.
[2019-03-22 23:07:31,652] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.35270676], dtype=float32), 0.007890927]
[2019-03-22 23:07:31,653] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [25.46666666666667, 54.66666666666667, 1.0, 2.0, 0.4054421548634141, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 459301.1135418376, 459301.1135418373, 131094.6228738112]
[2019-03-22 23:07:31,653] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:07:31,655] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.1709685979928528
[2019-03-22 23:07:39,207] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.35270676], dtype=float32), 0.007890927]
[2019-03-22 23:07:39,208] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [29.76666666666667, 58.66666666666667, 1.0, 2.0, 0.8066018456570228, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9823142678909691, 6.91690230676235, 6.9112, 95.55334016325322, 1455021.366212855, 1452732.893490188, 320697.5273697834]
[2019-03-22 23:07:39,210] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:07:39,213] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.13370469712059252
[2019-03-22 23:07:39,216] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1455021.366212855 W.
[2019-03-22 23:08:07,344] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.35270676], dtype=float32), 0.007890927]
[2019-03-22 23:08:07,349] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.8, 65.0, 1.0, 2.0, 0.7399584999928879, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 834530.2526303837, 834530.252630384, 163379.8761383714]
[2019-03-22 23:08:07,350] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:08:07,353] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.6908579688418149
[2019-03-22 23:08:27,937] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.35270676], dtype=float32), 0.007890927]
[2019-03-22 23:08:27,937] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.98333333333333, 56.83333333333333, 1.0, 2.0, 0.371199399105191, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 417015.211197045, 417015.211197045, 125966.4482468061]
[2019-03-22 23:08:27,937] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:08:27,942] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.3579749024034372
[2019-03-22 23:08:33,734] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1147 1656209757.7786 80.0000
[2019-03-22 23:08:33,905] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3485 1683325900.1134 214.0000
[2019-03-22 23:08:34,271] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2492 1773187030.7201 173.0000
[2019-03-22 23:08:34,305] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9309 1705967916.6745 465.0000
[2019-03-22 23:08:34,327] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5598 1663796639.0689 105.0000
[2019-03-22 23:08:35,342] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 425000, evaluation results [425000.0, 8512.249193409023, 1773187030.7201214, 173.0, 9061.114669779829, 1656209757.7786272, 80.0, 8856.559759326878, 1663796639.0688558, 105.0, 8596.930884973775, 1705967916.6744611, 465.0, 8574.348472942609, 1683325900.1133502, 214.0]
[2019-03-22 23:08:41,991] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 6.3543584e-36], sum to 1.0000
[2019-03-22 23:08:42,002] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4605
[2019-03-22 23:08:42,009] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 45.33333333333334, 1.0, 2.0, 0.5034682804334641, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 546816.4268587272, 546816.4268587272, 117563.5642722662], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 134400.0000, 
sim time next is 135000.0000, 
raw observation next is [22.5, 45.0, 1.0, 2.0, 0.549294069083331, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 596618.3193232376, 596618.3193232379, 123414.1199568784], 
processed observation next is [1.0, 0.5652173913043478, 0.6590909090909091, 0.45, 1.0, 1.0, 0.4366175863541637, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22096974789749543, 0.22096974789749552, 0.30101004867531317], 
reward next is 0.6990, 
noisyNet noise sample is [array([-0.68398094], dtype=float32), 0.56329036]. 
=============================================
[2019-03-22 23:08:42,019] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[63.687725]
 [63.844772]
 [64.005486]
 [63.8176  ]
 [63.657116]], R is [[63.40542984]
 [63.48463821]
 [63.57130051]
 [63.6699791 ]
 [63.76899719]].
[2019-03-22 23:08:42,643] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.00000e+00 1.00000e+00 0.00000e+00 0.00000e+00 7.46462e-36], sum to 1.0000
[2019-03-22 23:08:42,651] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1875
[2019-03-22 23:08:42,656] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.16666666666667, 81.16666666666667, 1.0, 2.0, 0.2179299627227795, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 236618.0699777342, 236618.0699777339, 71552.29938191458], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 105000.0000, 
sim time next is 105600.0000, 
raw observation next is [13.33333333333333, 80.33333333333334, 1.0, 2.0, 0.2040620959460709, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 221557.5653196349, 221557.5653196349, 70616.69212668146], 
processed observation next is [1.0, 0.21739130434782608, 0.2424242424242423, 0.8033333333333335, 1.0, 1.0, 0.005077619932588595, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.0820583575257907, 0.0820583575257907, 0.17223583445532065], 
reward next is 0.8278, 
noisyNet noise sample is [array([-0.9627044], dtype=float32), 1.4682075]. 
=============================================
[2019-03-22 23:08:46,491] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:08:46,500] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8077
[2019-03-22 23:08:46,506] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 214612.8955391621, 214612.8955391624, 72657.42617681305], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 187200.0000, 
sim time next is 187800.0000, 
raw observation next is [13.83333333333333, 89.00000000000001, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 214108.1917454251, 214108.1917454248, 72418.21090997373], 
processed observation next is [0.0, 0.17391304347826086, 0.265151515151515, 0.8900000000000001, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07929933027608338, 0.07929933027608325, 0.176629782707253], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.2858346], dtype=float32), 2.4573042]. 
=============================================
[2019-03-22 23:08:53,451] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:08:53,463] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9665
[2019-03-22 23:08:53,470] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.5, 60.0, 1.0, 2.0, 0.2358030444268437, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 256028.926264074, 256028.926264074, 86538.04332669434], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 300600.0000, 
sim time next is 301200.0000, 
raw observation next is [19.66666666666666, 58.66666666666666, 1.0, 2.0, 0.2384791834871076, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 258935.3832114004, 258935.3832114002, 86528.41864877228], 
processed observation next is [0.0, 0.4782608695652174, 0.53030303030303, 0.5866666666666666, 1.0, 1.0, 0.04809897935888447, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09590199378200015, 0.09590199378200008, 0.21104492353359092], 
reward next is 0.7890, 
noisyNet noise sample is [array([1.4961138], dtype=float32), -1.3006798]. 
=============================================
[2019-03-22 23:08:56,460] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:08:56,461] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3185
[2019-03-22 23:08:56,469] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.33333333333334, 78.0, 1.0, 2.0, 0.3338839464651738, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 368405.8839521983, 368405.883952198, 115617.1847371731], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 589200.0000, 
sim time next is 589800.0000, 
raw observation next is [19.16666666666667, 78.0, 1.0, 2.0, 0.329323214129508, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 362372.2059997437, 362372.2059997437, 114895.1213015903], 
processed observation next is [1.0, 0.8260869565217391, 0.5075757575757578, 0.78, 1.0, 1.0, 0.16165401766188497, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13421192814805322, 0.13421192814805322, 0.2802320031746105], 
reward next is 0.7198, 
noisyNet noise sample is [array([-1.1826538], dtype=float32), -0.95750517]. 
=============================================
[2019-03-22 23:08:58,513] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.7768911e-37 1.8872652e-36], sum to 1.0000
[2019-03-22 23:08:58,525] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0763
[2019-03-22 23:08:58,532] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.66666666666667, 70.0, 1.0, 2.0, 0.4020820652749905, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 436651.5003234555, 436651.5003234555, 86871.54180559152], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 354000.0000, 
sim time next is 354600.0000, 
raw observation next is [12.5, 71.5, 1.0, 2.0, 0.4041894618642209, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 438941.1156739252, 438941.1156739252, 87395.81485484118], 
processed observation next is [1.0, 0.08695652173913043, 0.20454545454545456, 0.715, 1.0, 1.0, 0.2552368273302761, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16257078358293525, 0.16257078358293525, 0.213160524036198], 
reward next is 0.7868, 
noisyNet noise sample is [array([1.0329367], dtype=float32), 0.26230633]. 
=============================================
[2019-03-22 23:09:14,271] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:09:14,278] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0641
[2019-03-22 23:09:14,283] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.33333333333334, 93.00000000000001, 1.0, 2.0, 0.3886544649159174, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 438634.255897726, 438634.2558977258, 124204.0760112324], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 799800.0000, 
sim time next is 800400.0000, 
raw observation next is [19.66666666666667, 92.0, 1.0, 2.0, 0.3950171694603548, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 446675.0952701232, 446675.0952701232, 125276.7800462557], 
processed observation next is [0.0, 0.2608695652173913, 0.5303030303030305, 0.92, 1.0, 1.0, 0.2437714618254435, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.165435220470416, 0.165435220470416, 0.3055531220640383], 
reward next is 0.6944, 
noisyNet noise sample is [array([-1.0065681], dtype=float32), 1.2576011]. 
=============================================
[2019-03-22 23:09:16,247] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:09:16,259] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4159
[2019-03-22 23:09:16,264] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 83.0, 1.0, 2.0, 0.3090515487600479, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 336381.7657014254, 336381.7657014257, 112079.4184215995], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 599400.0000, 
sim time next is 600000.0000, 
raw observation next is [18.0, 83.0, 1.0, 2.0, 0.3082229669572233, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 335473.6806785108, 335473.6806785105, 112020.6322384634], 
processed observation next is [1.0, 0.9565217391304348, 0.45454545454545453, 0.83, 1.0, 1.0, 0.13527870869652908, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12424951136241141, 0.1242495113624113, 0.27322105424015464], 
reward next is 0.7268, 
noisyNet noise sample is [array([0.42389], dtype=float32), -0.26638213]. 
=============================================
[2019-03-22 23:09:16,283] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[71.98976]
 [71.99468]
 [72.00576]
 [72.02775]
 [72.03265]], R is [[71.99108124]
 [71.99781036]
 [72.00423431]
 [72.01037598]
 [72.01647949]].
[2019-03-22 23:09:18,815] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 5.1636188e-34 1.6661899e-31], sum to 1.0000
[2019-03-22 23:09:18,822] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4831
[2019-03-22 23:09:18,834] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 78.0, 1.0, 2.0, 0.5463303557785397, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 608946.6629538839, 608946.6629538842, 136462.1287462997], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 637200.0000, 
sim time next is 637800.0000, 
raw observation next is [20.33333333333334, 76.5, 1.0, 2.0, 0.6315616232192878, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 705701.734411776, 705701.734411776, 146500.2643616847], 
processed observation next is [1.0, 0.391304347826087, 0.5606060606060609, 0.765, 1.0, 1.0, 0.5394520290241097, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2613710127451022, 0.2613710127451022, 0.3573177179553286], 
reward next is 0.6427, 
noisyNet noise sample is [array([0.14068647], dtype=float32), -0.5001565]. 
=============================================
[2019-03-22 23:09:26,954] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.7050206e-37], sum to 1.0000
[2019-03-22 23:09:26,964] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2316
[2019-03-22 23:09:26,972] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 69.0, 1.0, 2.0, 0.4454684337838318, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 507457.4713057235, 507457.4713057235, 132944.0150970208], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 772200.0000, 
sim time next is 772800.0000, 
raw observation next is [24.0, 69.0, 1.0, 2.0, 0.4439931461398561, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 505774.9920237183, 505774.9920237183, 132790.3793027496], 
processed observation next is [1.0, 0.9565217391304348, 0.7272727272727273, 0.69, 1.0, 1.0, 0.30499143267482004, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18732407111989566, 0.18732407111989566, 0.3238789739091454], 
reward next is 0.6761, 
noisyNet noise sample is [array([1.6020788], dtype=float32), 0.12450355]. 
=============================================
[2019-03-22 23:09:34,314] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.4486387e-38 0.0000000e+00], sum to 1.0000
[2019-03-22 23:09:34,323] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9122
[2019-03-22 23:09:34,331] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.66666666666667, 84.83333333333334, 1.0, 2.0, 0.4143074187384453, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 469293.7190316743, 469293.7190316743, 127560.360537297], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 864600.0000, 
sim time next is 865200.0000, 
raw observation next is [20.33333333333334, 86.66666666666667, 1.0, 2.0, 0.4116634911824745, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 465949.9574798418, 465949.9574798418, 127087.0489482878], 
processed observation next is [0.0, 0.0, 0.5606060606060609, 0.8666666666666667, 1.0, 1.0, 0.26457936397809306, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17257405832586734, 0.17257405832586734, 0.30996841206899467], 
reward next is 0.6900, 
noisyNet noise sample is [array([0.07169473], dtype=float32), 0.62372017]. 
=============================================
[2019-03-22 23:09:39,299] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-22 23:09:39,300] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-22 23:09:39,302] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-22 23:09:39,304] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-22 23:09:39,305] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:09:39,306] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-22 23:09:39,306] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:09:39,303] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-22 23:09:39,309] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:09:39,311] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:09:39,312] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:09:39,328] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run19
[2019-03-22 23:09:39,346] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run19
[2019-03-22 23:09:39,347] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run19
[2019-03-22 23:09:39,379] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run19
[2019-03-22 23:09:39,415] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run19
[2019-03-22 23:10:00,340] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.09092371], dtype=float32), -0.04644357]
[2019-03-22 23:10:00,340] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.286405595, 95.00363825, 1.0, 2.0, 0.3580785179508121, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 399910.7228236995, 399910.7228236991, 123741.573160617]
[2019-03-22 23:10:00,340] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:10:00,342] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 5.4215094e-34 2.3377805e-36], sampled 0.1841077388004817
[2019-03-22 23:10:15,332] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.09092371], dtype=float32), -0.04644357]
[2019-03-22 23:10:15,333] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [12.57986897666667, 83.415708775, 1.0, 2.0, 0.2048311561777582, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 222383.0565306139, 222383.0565306135, 74457.44290726542]
[2019-03-22 23:10:15,336] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:10:15,340] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.2253353e-34 2.5968243e-36], sampled 0.3150669772775997
[2019-03-22 23:10:31,808] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.09092371], dtype=float32), -0.04644357]
[2019-03-22 23:10:31,811] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [23.948106085, 56.38086945, 1.0, 2.0, 0.3705959474940336, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 416053.1598851246, 416053.1598851242, 125773.8050496885]
[2019-03-22 23:10:31,813] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:10:31,815] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.38351898820141606
[2019-03-22 23:10:33,840] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.09092371], dtype=float32), -0.04644357]
[2019-03-22 23:10:33,840] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.24845036666667, 90.1464837, 1.0, 2.0, 0.4856226834693103, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 554023.987325473, 554023.9873254726, 144086.0619225822]
[2019-03-22 23:10:33,841] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:10:33,844] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.9427322e-33 1.0435767e-34], sampled 0.009650532114204746
[2019-03-22 23:10:51,753] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.09092371], dtype=float32), -0.04644357]
[2019-03-22 23:10:51,754] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [15.14112696, 88.43382073, 1.0, 2.0, 0.2653664505711165, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 288121.3484403372, 288121.3484403368, 89554.74078993405]
[2019-03-22 23:10:51,756] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:10:51,759] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.6153464e-35 6.8799544e-37], sampled 0.346825945228286
[2019-03-22 23:11:43,026] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1147 1656209757.7786 80.0000
[2019-03-22 23:11:43,105] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2492 1773187030.7201 173.0000
[2019-03-22 23:11:43,431] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-22 23:11:43,440] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3485 1683325900.1134 214.0000
[2019-03-22 23:11:43,468] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5599 1663815647.6096 105.0000
[2019-03-22 23:11:44,482] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 450000, evaluation results [450000.0, 8512.249193409023, 1773187030.7201214, 173.0, 9061.114669779829, 1656209757.7786272, 80.0, 8856.559925897878, 1663815647.6095803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8574.348472942609, 1683325900.1133502, 214.0]
[2019-03-22 23:11:49,248] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.8066267e-37 1.3215440e-23 1.2226313e-20], sum to 1.0000
[2019-03-22 23:11:49,258] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7407
[2019-03-22 23:11:49,265] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 95.0, 1.0, 2.0, 0.2538127178594478, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 275588.9100510245, 275588.9100510248, 77222.12043549075], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1044600.0000, 
sim time next is 1045200.0000, 
raw observation next is [13.0, 96.0, 1.0, 2.0, 0.2331403962920159, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 253137.1385556061, 253137.1385556058, 76114.36011376113], 
processed observation next is [1.0, 0.08695652173913043, 0.22727272727272727, 0.96, 1.0, 1.0, 0.041425495365019875, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0937544957613356, 0.09375449576133549, 0.18564478076527105], 
reward next is 0.8144, 
noisyNet noise sample is [array([-0.5638809], dtype=float32), 0.5881535]. 
=============================================
[2019-03-22 23:11:50,618] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.7465992e-30 9.8127318e-36], sum to 1.0000
[2019-03-22 23:11:50,629] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8623
[2019-03-22 23:11:50,637] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.2183762793758613, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 237102.7776516576, 237102.7776516579, 75565.10749927536], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1026000.0000, 
sim time next is 1026600.0000, 
raw observation next is [13.0, 99.00000000000001, 1.0, 2.0, 0.2171047667991586, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 235721.8940763198, 235721.8940763195, 75130.6892695007], 
processed observation next is [1.0, 0.9130434782608695, 0.22727272727272727, 0.9900000000000001, 1.0, 1.0, 0.021380958498948242, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08730440521345177, 0.08730440521345166, 0.18324558358414805], 
reward next is 0.8168, 
noisyNet noise sample is [array([-0.21229918], dtype=float32), -1.626335]. 
=============================================
[2019-03-22 23:11:52,233] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 6.5114036e-36 6.7636701e-34], sum to 1.0000
[2019-03-22 23:11:52,245] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2729
[2019-03-22 23:11:52,251] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.2103458055161532, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 228381.616741498, 228381.616741498, 74711.9384266465], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1050000.0000, 
sim time next is 1050600.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.2106566671909558, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 228719.2121773427, 228719.212177343, 74739.9931597964], 
processed observation next is [1.0, 0.13043478260869565, 0.22727272727272727, 1.0, 1.0, 1.0, 0.013320833988694734, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08471081932494175, 0.08471081932494184, 0.18229266624340587], 
reward next is 0.8177, 
noisyNet noise sample is [array([1.0075573], dtype=float32), 0.3448099]. 
=============================================
[2019-03-22 23:11:56,154] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.2635772e-32 0.0000000e+00], sum to 1.0000
[2019-03-22 23:11:56,164] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2386
[2019-03-22 23:11:56,175] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 88.0, 1.0, 2.0, 0.4723908245916151, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 538987.4454171299, 538987.4454171297, 137360.7091459497], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1377600.0000, 
sim time next is 1378200.0000, 
raw observation next is [22.0, 88.0, 1.0, 2.0, 0.4718678408199585, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 538390.3324297393, 538390.3324297395, 137302.8325949929], 
processed observation next is [1.0, 0.9565217391304348, 0.6363636363636364, 0.88, 1.0, 1.0, 0.33983480102494806, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19940382682582936, 0.19940382682582947, 0.3348849575487632], 
reward next is 0.6651, 
noisyNet noise sample is [array([-1.120786], dtype=float32), -2.214473]. 
=============================================
[2019-03-22 23:12:06,855] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.5709440e-35 8.7439354e-25 2.2719004e-32], sum to 1.0000
[2019-03-22 23:12:06,867] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5317
[2019-03-22 23:12:06,872] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.16666666666667, 99.0, 1.0, 2.0, 0.3497153406719635, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 387578.0292217608, 387578.0292217605, 117478.4418744882], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1302600.0000, 
sim time next is 1303200.0000, 
raw observation next is [17.0, 100.0, 1.0, 2.0, 0.3485047797178193, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 385853.2730918831, 385853.2730918831, 117231.7214344386], 
processed observation next is [1.0, 0.08695652173913043, 0.4090909090909091, 1.0, 1.0, 1.0, 0.1856309746472741, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14290861966366042, 0.14290861966366042, 0.28593102788887464], 
reward next is 0.7141, 
noisyNet noise sample is [array([-0.06697569], dtype=float32), 0.2991508]. 
=============================================
[2019-03-22 23:12:10,992] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.9895899e-35 1.0000000e+00 5.9205169e-29 1.5354349e-23 1.2979735e-28], sum to 1.0000
[2019-03-22 23:12:11,001] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1349
[2019-03-22 23:12:11,011] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1235461.939800404 W.
[2019-03-22 23:12:11,017] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.83333333333333, 89.0, 1.0, 2.0, 0.549416963803102, 1.0, 2.0, 0.549416963803102, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846344338547, 1235461.939800404, 1235461.939800404, 248166.9251075019], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1331400.0000, 
sim time next is 1332000.0000, 
raw observation next is [24.0, 89.0, 1.0, 2.0, 0.4073206814525417, 1.0, 2.0, 0.4073206814525417, 1.0, 1.0, 0.8234247699309626, 6.9112, 6.9112, 77.3421103, 1374067.340135716, 1374067.340135716, 310527.2434566068], 
processed observation next is [1.0, 0.43478260869565216, 0.7272727272727273, 0.89, 1.0, 1.0, 0.2591508518156771, 1.0, 1.0, 0.2591508518156771, 1.0, 0.5, 0.7477496713299467, 0.0, 0.0, 0.5085185399722538, 0.5089138296798947, 0.5089138296798947, 0.7573835206258702], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2292497], dtype=float32), 0.60330045]. 
=============================================
[2019-03-22 23:12:11,035] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[53.43446 ]
 [53.454365]
 [52.791275]
 [53.009007]
 [53.41864 ]], R is [[52.39860153]
 [52.26932907]
 [52.03957367]
 [51.82157516]
 [51.69940567]].
[2019-03-22 23:12:14,446] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.2068565e-37 2.9178582e-31], sum to 1.0000
[2019-03-22 23:12:14,456] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9055
[2019-03-22 23:12:14,463] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 88.0, 1.0, 2.0, 0.4725131786463901, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 539127.2168520706, 539127.2168520706, 137374.6078489301], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1377000.0000, 
sim time next is 1377600.0000, 
raw observation next is [22.0, 88.0, 1.0, 2.0, 0.4723908245916151, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 538987.4454171299, 538987.4454171297, 137360.7091459497], 
processed observation next is [1.0, 0.9565217391304348, 0.6363636363636364, 0.88, 1.0, 1.0, 0.3404885307395188, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1996249797841222, 0.1996249797841221, 0.33502611986817], 
reward next is 0.6650, 
noisyNet noise sample is [array([-1.5646554], dtype=float32), -0.83789366]. 
=============================================
[2019-03-22 23:12:23,072] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.4270612e-38 2.5528304e-37], sum to 1.0000
[2019-03-22 23:12:23,082] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1500
[2019-03-22 23:12:23,087] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.5, 74.5, 1.0, 2.0, 0.6191868178795072, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 695813.4065992214, 695813.4065992214, 161599.2810034892], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1510200.0000, 
sim time next is 1510800.0000, 
raw observation next is [27.66666666666666, 73.0, 1.0, 2.0, 0.6147844078796242, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 690862.6657883872, 690862.6657883872, 160973.3350896789], 
processed observation next is [0.0, 0.4782608695652174, 0.8939393939393937, 0.73, 1.0, 1.0, 0.5184805098495302, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.25587506140310634, 0.25587506140310634, 0.39261789046263146], 
reward next is 0.6074, 
noisyNet noise sample is [array([1.2663888], dtype=float32), 2.9554083]. 
=============================================
[2019-03-22 23:12:23,584] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:12:23,595] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9204
[2019-03-22 23:12:23,600] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 83.0, 1.0, 2.0, 0.5280178341762001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 600927.1305036757, 600927.1305036757, 146669.6466276669], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1537200.0000, 
sim time next is 1537800.0000, 
raw observation next is [23.83333333333333, 83.0, 1.0, 2.0, 0.5195216299752871, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 591708.3866010632, 591708.3866010634, 145281.41620854], 
processed observation next is [0.0, 0.8260869565217391, 0.7196969696969695, 0.83, 1.0, 1.0, 0.3994020374691088, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21915125429669008, 0.21915125429669016, 0.35434491758180486], 
reward next is 0.6457, 
noisyNet noise sample is [array([-0.47442287], dtype=float32), 1.0469052]. 
=============================================
[2019-03-22 23:12:27,117] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 3.3073766e-38 2.0893309e-36 9.9059298e-36], sum to 1.0000
[2019-03-22 23:12:27,126] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7119
[2019-03-22 23:12:27,131] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.4133360006749084, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 468596.3374331864, 468596.3374331864, 127739.1804569113], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1567200.0000, 
sim time next is 1567800.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4118452584959689, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 466881.7560643575, 466881.7560643578, 127581.0889667423], 
processed observation next is [1.0, 0.13043478260869565, 0.5, 1.0, 1.0, 1.0, 0.26480657311996114, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17291916891272502, 0.17291916891272513, 0.31117338772376174], 
reward next is 0.6888, 
noisyNet noise sample is [array([0.9237818], dtype=float32), -0.57100195]. 
=============================================
[2019-03-22 23:12:29,269] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.7341600e-35 1.0000000e+00 2.3100909e-32 8.7569632e-23 1.2712843e-24], sum to 1.0000
[2019-03-22 23:12:29,282] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5809
[2019-03-22 23:12:29,290] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 77.33333333333333, 1.0, 2.0, 0.435104706808237, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 494981.2308277451, 494981.2308277451, 131175.3896127745], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1626600.0000, 
sim time next is 1627200.0000, 
raw observation next is [22.0, 78.0, 1.0, 2.0, 0.4246618138523647, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 482499.4537468406, 482499.4537468406, 129611.0896374595], 
processed observation next is [1.0, 0.8695652173913043, 0.6363636363636364, 0.78, 1.0, 1.0, 0.2808272673154558, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17870350138771873, 0.17870350138771873, 0.31612460887185245], 
reward next is 0.6839, 
noisyNet noise sample is [array([0.8312749], dtype=float32), 0.810271]. 
=============================================
[2019-03-22 23:12:45,597] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-22 23:12:45,600] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-22 23:12:45,602] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-22 23:12:45,602] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:12:45,603] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:12:45,604] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-22 23:12:45,603] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-22 23:12:45,607] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:12:45,605] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-22 23:12:45,608] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:12:45,609] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:12:45,625] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run20
[2019-03-22 23:12:45,625] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run20
[2019-03-22 23:12:45,625] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run20
[2019-03-22 23:12:45,670] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run20
[2019-03-22 23:12:45,683] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run20
[2019-03-22 23:12:48,349] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02594814], dtype=float32), -0.046146687]
[2019-03-22 23:12:48,351] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.3, 32.0, 1.0, 2.0, 0.44993097003302, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 488593.5493708466, 488593.5493708462, 106441.0005949644]
[2019-03-22 23:12:48,353] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:12:48,359] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 5.277195e-38], sampled 0.6137254659568837
[2019-03-22 23:12:50,209] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02594814], dtype=float32), -0.046146687]
[2019-03-22 23:12:50,211] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [14.0, 100.0, 1.0, 2.0, 0.2165895910683857, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 235162.4058737841, 235162.4058737838, 79659.84258211734]
[2019-03-22 23:12:50,212] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:12:50,214] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.1463789e-38 2.2843751e-36], sampled 0.4675540411706145
[2019-03-22 23:13:08,507] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02594814], dtype=float32), -0.046146687]
[2019-03-22 23:13:08,509] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.21778486833333, 48.02931000833334, 1.0, 2.0, 0.3413304408389755, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 376812.5780538575, 376812.5780538572, 120566.6641757672]
[2019-03-22 23:13:08,510] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:13:08,513] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.8909325985853228
[2019-03-22 23:13:12,068] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02594814], dtype=float32), -0.046146687]
[2019-03-22 23:13:12,070] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [13.63333333333333, 75.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 212654.1571905318, 212654.1571905321, 73584.85464166896]
[2019-03-22 23:13:12,071] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:13:12,073] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 8.513026e-38], sampled 0.6530911250782051
[2019-03-22 23:13:39,076] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02594814], dtype=float32), -0.046146687]
[2019-03-22 23:13:39,077] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [26.03333333333333, 67.0, 1.0, 2.0, 0.5170655484794257, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 589440.5643561084, 589440.5643561081, 148676.3315607735]
[2019-03-22 23:13:39,079] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:13:39,084] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 7.824884e-36], sampled 0.11501011583269427
[2019-03-22 23:13:49,667] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02594814], dtype=float32), -0.046146687]
[2019-03-22 23:13:49,669] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.39027531, 89.79195553000001, 1.0, 2.0, 0.3279986302175271, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 362705.3821372176, 362705.3821372173, 119811.5873147149]
[2019-03-22 23:13:49,670] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:13:49,672] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 5.1326581e-38 4.1071116e-37], sampled 0.4303824041716684
[2019-03-22 23:14:11,463] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02594814], dtype=float32), -0.046146687]
[2019-03-22 23:14:11,464] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [10.98157264, 98.95865333666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 189767.3627816797, 189767.3627816793, 69302.44390893966]
[2019-03-22 23:14:11,465] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:14:11,471] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 4.5549913e-38], sampled 0.28200803430924215
[2019-03-22 23:14:24,004] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02594814], dtype=float32), -0.046146687]
[2019-03-22 23:14:24,005] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.94296631166667, 100.0, 1.0, 2.0, 0.4343583063937161, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 494729.7689429778, 494729.7689429775, 136090.4820948377]
[2019-03-22 23:14:24,006] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:14:24,011] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 3.989218e-36], sampled 0.16051668306831046
[2019-03-22 23:14:29,679] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5598 1663796639.0689 105.0000
[2019-03-22 23:14:29,750] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9513 1705935940.2592 465.0000
[2019-03-22 23:14:29,829] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2492 1773187030.7201 173.0000
[2019-03-22 23:14:29,926] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3485 1683325900.1134 214.0000
[2019-03-22 23:14:29,953] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-22 23:14:30,970] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 475000, evaluation results [475000.0, 8512.249193409023, 1773187030.7201214, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8856.559759326878, 1663796639.0688558, 105.0, 8596.951295847348, 1705935940.259201, 465.0, 8574.348472942609, 1683325900.1133502, 214.0]
[2019-03-22 23:14:42,185] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.7667405e-37 0.0000000e+00], sum to 1.0000
[2019-03-22 23:14:42,193] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1449
[2019-03-22 23:14:42,198] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 62.0, 1.0, 2.0, 0.2644885912613343, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 287184.1563457995, 287184.1563457995, 88203.91022268523], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2068200.0000, 
sim time next is 2068800.0000, 
raw observation next is [19.0, 61.33333333333334, 1.0, 2.0, 0.2640895725558325, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 286750.7704217014, 286750.7704217017, 87476.38076381951], 
processed observation next is [0.0, 0.9565217391304348, 0.5, 0.6133333333333334, 1.0, 1.0, 0.0801119656947906, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1062039890450746, 0.1062039890450747, 0.21335702625321834], 
reward next is 0.7866, 
noisyNet noise sample is [array([0.04145205], dtype=float32), 0.15931888]. 
=============================================
[2019-03-22 23:14:50,214] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 7.7062393e-30 2.3685458e-26 6.3131986e-25], sum to 1.0000
[2019-03-22 23:14:50,222] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2022
[2019-03-22 23:14:50,231] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 88.0, 1.0, 2.0, 0.2068176744543286, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 224550.0867219673, 224550.086721967, 73866.35059509781], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2259000.0000, 
sim time next is 2259600.0000, 
raw observation next is [14.0, 86.0, 1.0, 2.0, 0.2007183842717476, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 217926.3638899961, 217926.3638899961, 72695.78707766421], 
processed observation next is [1.0, 0.13043478260869565, 0.2727272727272727, 0.86, 1.0, 1.0, 0.0008979803396844815, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08071346810740597, 0.08071346810740597, 0.1773067977504005], 
reward next is 0.8227, 
noisyNet noise sample is [array([1.4539864], dtype=float32), 0.12522188]. 
=============================================
[2019-03-22 23:14:55,019] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 3.323688e-33], sum to 1.0000
[2019-03-22 23:14:55,031] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9427
[2019-03-22 23:14:55,035] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 50.33333333333334, 1.0, 2.0, 0.4432515561294963, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 481382.7166398385, 481382.7166398385, 102728.5243073171], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2298000.0000, 
sim time next is 2298600.0000, 
raw observation next is [20.0, 51.0, 1.0, 2.0, 0.4382627629221416, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 475962.1052652029, 475962.1052652029, 102608.0105089959], 
processed observation next is [1.0, 0.6086956521739131, 0.5454545454545454, 0.51, 1.0, 1.0, 0.29782845365267696, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1762822612093344, 0.1762822612093344, 0.25026344026584363], 
reward next is 0.7497, 
noisyNet noise sample is [array([0.94939536], dtype=float32), 0.15732403]. 
=============================================
[2019-03-22 23:14:56,016] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 2.8203290e-38 2.4077314e-30 3.1123268e-18], sum to 1.0000
[2019-03-22 23:14:56,027] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3060
[2019-03-22 23:14:56,033] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 49.0, 1.0, 2.0, 0.66783722568083, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 729005.7919091202, 729005.7919091198, 144653.7262074559], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2560800.0000, 
sim time next is 2561400.0000, 
raw observation next is [23.0, 48.5, 1.0, 2.0, 0.6752108454484443, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 735933.8831511517, 735933.8831511517, 145121.9819652691], 
processed observation next is [1.0, 0.6521739130434783, 0.6818181818181818, 0.485, 1.0, 1.0, 0.5940135568105553, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2725681048707969, 0.2725681048707969, 0.3539560535738271], 
reward next is 0.6460, 
noisyNet noise sample is [array([-0.60088164], dtype=float32), -0.15724476]. 
=============================================
[2019-03-22 23:14:59,294] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.6517396e-34 2.4887334e-37], sum to 1.0000
[2019-03-22 23:14:59,304] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1441
[2019-03-22 23:14:59,309] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 94.0, 1.0, 2.0, 0.2256888858049184, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 245044.4646382963, 245044.4646382965, 77859.71286907907], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2422800.0000, 
sim time next is 2423400.0000, 
raw observation next is [14.0, 93.00000000000001, 1.0, 2.0, 0.222592565278794, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 241681.7615560542, 241681.7615560539, 77139.50474541729], 
processed observation next is [1.0, 0.043478260869565216, 0.2727272727272727, 0.9300000000000002, 1.0, 1.0, 0.028240706598492496, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08951176353927934, 0.08951176353927923, 0.18814513352540801], 
reward next is 0.8119, 
noisyNet noise sample is [array([1.1458817], dtype=float32), -1.0412465]. 
=============================================
[2019-03-22 23:15:06,603] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 7.463001e-35], sum to 1.0000
[2019-03-22 23:15:06,613] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3835
[2019-03-22 23:15:06,616] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 73.83333333333333, 1.0, 2.0, 0.4352927615585795, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 495440.4586287397, 495440.4586287397, 131433.9917251087], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2757000.0000, 
sim time next is 2757600.0000, 
raw observation next is [23.0, 73.0, 1.0, 2.0, 0.4306256816267961, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 489852.8281156737, 489852.8281156737, 130697.7673557353], 
processed observation next is [0.0, 0.9565217391304348, 0.6818181818181818, 0.73, 1.0, 1.0, 0.2882821020334951, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18142697337617544, 0.18142697337617544, 0.3187750423310617], 
reward next is 0.6812, 
noisyNet noise sample is [array([0.8625165], dtype=float32), 0.75084484]. 
=============================================
[2019-03-22 23:15:13,799] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.8053979e-36 1.0000000e+00 1.2131509e-32 1.7941971e-28 6.2938303e-21], sum to 1.0000
[2019-03-22 23:15:13,806] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9256
[2019-03-22 23:15:13,818] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1362366.21834463 W.
[2019-03-22 23:15:13,823] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.0, 74.0, 1.0, 2.0, 0.7197102007623072, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9810377492881246, 6.911199999999999, 6.9112, 77.32846344354104, 1362366.21834463, 1362366.21834463, 298625.4493343608], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2884800.0000, 
sim time next is 2885400.0000, 
raw observation next is [26.0, 74.0, 1.0, 2.0, 0.7563668047223268, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9810620813301292, 6.9112, 6.9112, 77.32846344354104, 1403852.008748179, 1403852.008748179, 304482.1864427709], 
processed observation next is [1.0, 0.391304347826087, 0.8181818181818182, 0.74, 1.0, 1.0, 0.6954585059029084, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9729458304716131, 0.0, 0.0, 0.5084288129206541, 0.5199451884252515, 0.5199451884252515, 0.7426394791287094], 
reward next is 0.2574, 
noisyNet noise sample is [array([0.16645823], dtype=float32), 1.1536307]. 
=============================================
[2019-03-22 23:15:15,895] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 2.4420418e-36], sum to 1.0000
[2019-03-22 23:15:15,904] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1826
[2019-03-22 23:15:15,910] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.13333333333333, 86.5, 1.0, 2.0, 0.3337410210009448, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 367219.0439096661, 367219.0439096658, 115215.2644516828], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2688600.0000, 
sim time next is 2689200.0000, 
raw observation next is [18.0, 87.0, 1.0, 2.0, 0.3313946150528904, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 364161.6539481933, 364161.6539481935, 114864.6702881015], 
processed observation next is [0.0, 0.13043478260869565, 0.45454545454545453, 0.87, 1.0, 1.0, 0.164243268816113, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.134874686647479, 0.13487468664747906, 0.28015773241000363], 
reward next is 0.7198, 
noisyNet noise sample is [array([0.86742425], dtype=float32), 0.5668009]. 
=============================================
[2019-03-22 23:15:16,245] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.2499447e-31 1.1318880e-28], sum to 1.0000
[2019-03-22 23:15:16,255] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6924
[2019-03-22 23:15:16,261] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.33333333333333, 95.83333333333334, 1.0, 2.0, 0.3901628728109616, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 441413.7162250432, 441413.7162250429, 124977.5258011693], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2706600.0000, 
sim time next is 2707200.0000, 
raw observation next is [19.8, 95.0, 1.0, 2.0, 0.4025271629625695, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 456707.5714443323, 456707.5714443323, 126983.2167137312], 
processed observation next is [0.0, 0.34782608695652173, 0.5363636363636364, 0.95, 1.0, 1.0, 0.25315895370321184, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16915095238678973, 0.16915095238678973, 0.3097151627164176], 
reward next is 0.6903, 
noisyNet noise sample is [array([0.11949085], dtype=float32), -0.30631676]. 
=============================================
[2019-03-22 23:15:19,897] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.1377498e-35], sum to 1.0000
[2019-03-22 23:15:19,904] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5873
[2019-03-22 23:15:19,909] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 77.16666666666667, 1.0, 2.0, 0.4558523252216941, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 519717.6403145128, 519717.6403145128, 134617.2083243223], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2754600.0000, 
sim time next is 2755200.0000, 
raw observation next is [23.0, 76.33333333333334, 1.0, 2.0, 0.449454701619887, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 512247.4449161446, 512247.4449161446, 133679.3111002813], 
processed observation next is [0.0, 0.9130434782608695, 0.6818181818181818, 0.7633333333333334, 1.0, 1.0, 0.3118183770248587, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18972127589486837, 0.18972127589486837, 0.32604710024458855], 
reward next is 0.6740, 
noisyNet noise sample is [array([1.7115661], dtype=float32), -0.76528007]. 
=============================================
[2019-03-22 23:15:22,753] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-22 23:15:22,755] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-22 23:15:22,755] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:15:22,756] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-22 23:15:22,757] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:15:22,757] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-22 23:15:22,758] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-22 23:15:22,759] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-22 23:15:22,760] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:15:22,761] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:15:22,761] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:15:22,768] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run21
[2019-03-22 23:15:22,769] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run21
[2019-03-22 23:15:22,808] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run21
[2019-03-22 23:15:22,809] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run21
[2019-03-22 23:15:22,823] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run21
[2019-03-22 23:15:43,001] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.0795663], dtype=float32), 0.06871208]
[2019-03-22 23:15:43,001] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [29.2, 51.5, 1.0, 2.0, 0.5159532626866289, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 588007.5918647599, 588007.5918647596, 148739.604593846]
[2019-03-22 23:15:43,002] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:15:43,007] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 6.996163e-38], sampled 0.3481801906710419
[2019-03-22 23:15:50,683] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.0795663], dtype=float32), 0.06871208]
[2019-03-22 23:15:50,684] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.9, 44.5, 1.0, 2.0, 0.3301405848777875, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 358546.5878690833, 358546.5878690833, 117593.9951625148]
[2019-03-22 23:15:50,685] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:15:50,688] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.40977822095318295
[2019-03-22 23:15:57,078] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.0795663], dtype=float32), 0.06871208]
[2019-03-22 23:15:57,081] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.2, 83.0, 1.0, 2.0, 0.362801880636035, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 402943.1151232622, 402943.1151232618, 123172.6863235036]
[2019-03-22 23:15:57,082] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:15:57,085] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 8.589309e-34], sampled 0.834649284014615
[2019-03-22 23:16:30,194] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.0795663], dtype=float32), 0.06871208]
[2019-03-22 23:16:30,195] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.21315408166667, 93.79817648666666, 1.0, 2.0, 0.36800593206181, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 411052.8092965586, 411052.8092965583, 124577.7232443044]
[2019-03-22 23:16:30,196] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:16:30,201] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 7.0401224e-38 6.3107378e-34], sampled 0.20974977293264419
[2019-03-22 23:17:04,481] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.0795663], dtype=float32), 0.06871208]
[2019-03-22 23:17:04,483] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.0, 53.66666666666667, 1.0, 2.0, 0.4302555030401666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 467219.061715302, 467219.061715302, 108541.1357576411]
[2019-03-22 23:17:04,485] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:17:04,488] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.1910475e-34], sampled 0.9849765450773712
[2019-03-22 23:17:11,506] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3485 1683325900.1134 214.0000
[2019-03-22 23:17:11,726] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2492 1773187030.7201 173.0000
[2019-03-22 23:17:11,731] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1147 1656209757.7786 80.0000
[2019-03-22 23:17:11,818] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9309 1705967916.6745 465.0000
[2019-03-22 23:17:11,855] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5598 1663796639.0689 105.0000
[2019-03-22 23:17:12,867] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 500000, evaluation results [500000.0, 8512.249193409023, 1773187030.7201214, 173.0, 9061.114669779829, 1656209757.7786272, 80.0, 8856.559759326878, 1663796639.0688558, 105.0, 8596.930884973775, 1705967916.6744611, 465.0, 8574.348472942609, 1683325900.1133502, 214.0]
[2019-03-22 23:17:21,808] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:17:21,814] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8732
[2019-03-22 23:17:21,820] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1612227.092768802 W.
[2019-03-22 23:17:21,824] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.0, 58.0, 1.0, 2.0, 0.4757951672464321, 1.0, 1.0, 0.4757951672464321, 1.0, 1.0, 0.9625265862533281, 6.9112, 6.9112, 79.40912272735903, 1612227.092768802, 1612227.092768802, 345150.1202220471], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2985600.0000, 
sim time next is 2986200.0000, 
raw observation next is [28.0, 58.0, 1.0, 2.0, 0.7526288810683355, 1.0, 2.0, 0.7526288810683355, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846205732638, 1697172.266349678, 1697172.266349678, 307939.0669225747], 
processed observation next is [1.0, 0.5652173913043478, 0.9090909090909091, 0.58, 1.0, 1.0, 0.6907861013354194, 1.0, 1.0, 0.6907861013354194, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288038063973, 0.6285823208702511, 0.6285823208702511, 0.7510708949331091], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.4015409], dtype=float32), -0.087794565]. 
=============================================
[2019-03-22 23:17:22,241] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:17:22,254] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2871
[2019-03-22 23:17:22,263] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1309345.397437549 W.
[2019-03-22 23:17:22,267] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.0, 56.5, 1.0, 2.0, 0.385977615673035, 1.0, 2.0, 0.385977615673035, 1.0, 2.0, 0.7811641259048551, 6.9112, 6.9112, 77.3421103, 1309345.397437549, 1309345.397437549, 297816.1339389728], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2989800.0000, 
sim time next is 2990400.0000, 
raw observation next is [28.0, 56.0, 1.0, 2.0, 0.3904591235151531, 1.0, 2.0, 0.3904591235151531, 1.0, 2.0, 0.7903479469186069, 6.911199999999999, 6.9112, 77.3421103, 1325224.837731988, 1325224.837731988, 299632.8792800267], 
processed observation next is [1.0, 0.6086956521739131, 0.9090909090909091, 0.56, 1.0, 1.0, 0.23807390439394135, 1.0, 1.0, 0.23807390439394135, 1.0, 1.0, 0.7004970670265813, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.49082401397481035, 0.49082401397481035, 0.730811900682992], 
reward next is 0.2692, 
noisyNet noise sample is [array([0.2605467], dtype=float32), 0.20281787]. 
=============================================
[2019-03-22 23:17:29,237] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.9092430e-35 1.0000000e+00 1.4501692e-32 2.8118245e-28 6.9867268e-29], sum to 1.0000
[2019-03-22 23:17:29,245] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5835
[2019-03-22 23:17:29,255] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1116566.497690658 W.
[2019-03-22 23:17:29,259] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.0, 73.0, 1.0, 2.0, 0.326001995697633, 1.0, 2.0, 0.326001995697633, 1.0, 1.0, 0.6580315806121142, 6.911200000000001, 6.9112, 77.3421103, 1116566.497690658, 1116566.497690658, 263085.3136904248], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3142800.0000, 
sim time next is 3143400.0000, 
raw observation next is [23.16666666666667, 72.33333333333334, 1.0, 2.0, 0.2681146035024405, 1.0, 2.0, 0.2681146035024405, 1.0, 2.0, 0.5410669397548309, 6.911199999999999, 6.9112, 77.3421103, 918150.3900139563, 918150.3900139566, 243093.8369372734], 
processed observation next is [1.0, 0.391304347826087, 0.6893939393939396, 0.7233333333333334, 1.0, 1.0, 0.08514325437805059, 1.0, 1.0, 0.08514325437805059, 1.0, 1.0, 0.34438134250690133, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.340055700005169, 0.3400557000051691, 0.5929117974079838], 
reward next is 0.4071, 
noisyNet noise sample is [array([1.1685936], dtype=float32), 0.0017019403]. 
=============================================
[2019-03-22 23:17:35,747] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:17:35,756] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8261
[2019-03-22 23:17:35,764] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 94.0, 1.0, 2.0, 0.3645855074911151, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 406043.0221035048, 406043.0221035051, 119459.646047894], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3211200.0000, 
sim time next is 3211800.0000, 
raw observation next is [18.0, 93.00000000000001, 1.0, 2.0, 0.3601109401147968, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 400312.99613095, 400312.9961309497, 118785.0320296126], 
processed observation next is [0.0, 0.17391304347826086, 0.45454545454545453, 0.9300000000000002, 1.0, 1.0, 0.20013867514349595, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1482640726410926, 0.14826407264109248, 0.2897195903161283], 
reward next is 0.7103, 
noisyNet noise sample is [array([1.8817517], dtype=float32), -0.38109747]. 
=============================================
[2019-03-22 23:17:39,848] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.7906164e-33 3.4564815e-27], sum to 1.0000
[2019-03-22 23:17:39,858] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5692
[2019-03-22 23:17:39,865] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.5, 52.0, 1.0, 2.0, 0.3539829664932418, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 395815.8042386255, 395815.8042386255, 119305.3243197409], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3331800.0000, 
sim time next is 3332400.0000, 
raw observation next is [24.66666666666666, 51.33333333333333, 1.0, 2.0, 0.3545308839610326, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 396586.1177366619, 396586.1177366622, 119422.1978878781], 
processed observation next is [0.0, 0.5652173913043478, 0.7575757575757573, 0.5133333333333333, 1.0, 1.0, 0.19316360495129073, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14688374730987477, 0.14688374730987488, 0.2912736533850685], 
reward next is 0.7087, 
noisyNet noise sample is [array([0.04069864], dtype=float32), -0.9908741]. 
=============================================
[2019-03-22 23:17:52,914] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.0000000e+00 1.5418366e-14 1.6482667e-32 1.0000000e+00 2.0713629e-11], sum to 1.0000
[2019-03-22 23:17:52,925] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3300
[2019-03-22 23:17:52,930] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.0, 89.0, 1.0, 2.0, 0.261527486393537, 1.0, 2.0, 0.261527486393537, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 594297.3061063971, 594297.3061063968, 182886.2108075572], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3543600.0000, 
sim time next is 3544200.0000, 
raw observation next is [23.0, 89.0, 1.0, 2.0, 0.2615934906690494, 1.0, 2.0, 0.2615934906690494, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 594446.6126932054, 594446.6126932054, 182897.6943394502], 
processed observation next is [1.0, 0.0, 0.6818181818181818, 0.89, 1.0, 1.0, 0.07699186333631175, 1.0, 1.0, 0.07699186333631175, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22016541210859458, 0.22016541210859458, 0.4460919374132931], 
reward next is 0.5539, 
noisyNet noise sample is [array([-0.1700154], dtype=float32), -0.69710326]. 
=============================================
[2019-03-22 23:17:56,501] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.1171981e-22 2.0743256e-17 3.6889470e-20 1.0000000e+00 1.0153256e-11], sum to 1.0000
[2019-03-22 23:17:56,509] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9944
[2019-03-22 23:17:56,513] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.0, 70.0, 1.0, 2.0, 0.7229429344931744, 1.0, 2.0, 0.7229429344931744, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1626226.354878452, 1626226.354878452, 299101.0440352823], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3602400.0000, 
sim time next is 3603000.0000, 
raw observation next is [27.0, 70.0, 1.0, 2.0, 0.6978141626823593, 1.0, 2.0, 0.6978141626823593, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1569621.985146333, 1569621.985146333, 291103.4192570247], 
processed observation next is [1.0, 0.6956521739130435, 0.8636363636363636, 0.7, 1.0, 1.0, 0.6222677033529491, 1.0, 1.0, 0.6222677033529491, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.5813414759801233, 0.5813414759801233, 0.7100083396512797], 
reward next is 0.2900, 
noisyNet noise sample is [array([-0.5960799], dtype=float32), 0.3782213]. 
=============================================
[2019-03-22 23:17:56,522] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[44.343204]
 [44.001072]
 [44.030106]
 [43.955475]
 [43.689663]], R is [[44.55724716]
 [44.38216019]
 [44.17367935]
 [43.98083496]
 [43.80047226]].
[2019-03-22 23:17:59,149] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.2374043e-27 2.1740991e-09 1.2597430e-22 1.0000000e+00 3.3337197e-14], sum to 1.0000
[2019-03-22 23:17:59,156] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2643
[2019-03-22 23:17:59,161] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.33333333333334, 57.0, 1.0, 2.0, 0.6826243702856282, 1.0, 2.0, 0.6826243702856282, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1539961.390127318, 1539961.390127317, 285370.755456323], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3680400.0000, 
sim time next is 3681000.0000, 
raw observation next is [28.5, 56.5, 1.0, 2.0, 0.7033128485197163, 1.0, 2.0, 0.7033128485197163, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1585259.94240751, 1585259.942407509, 292137.5495127194], 
processed observation next is [1.0, 0.6086956521739131, 0.9318181818181818, 0.565, 1.0, 1.0, 0.6291410606496453, 1.0, 1.0, 0.6291410606496453, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.5871333120027815, 0.5871333120027812, 0.7125306085676083], 
reward next is 0.2875, 
noisyNet noise sample is [array([-0.13484497], dtype=float32), -1.8604325]. 
=============================================
[2019-03-22 23:17:59,171] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[47.343773]
 [47.557167]
 [47.653442]
 [47.604134]
 [47.76065 ]], R is [[46.89672089]
 [46.7317276 ]
 [46.58255005]
 [46.44225693]
 [46.2946701 ]].
[2019-03-22 23:18:05,021] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-22 23:18:05,023] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-22 23:18:05,023] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:18:05,024] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-22 23:18:05,024] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-22 23:18:05,025] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:18:05,026] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-22 23:18:05,027] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-22 23:18:05,028] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:18:05,032] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:18:05,033] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:18:05,049] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run22
[2019-03-22 23:18:05,067] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run22
[2019-03-22 23:18:05,087] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run22
[2019-03-22 23:18:05,090] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run22
[2019-03-22 23:18:05,128] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run22
[2019-03-22 23:18:07,801] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.03164644], dtype=float32), 0.08467609]
[2019-03-22 23:18:07,802] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.33333333333334, 44.0, 1.0, 2.0, 0.2963405640984612, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 321780.7646069791, 321780.7646069794, 87671.68328800777]
[2019-03-22 23:18:07,805] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:18:07,809] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.3604796e-37 9.9932277e-01 1.4275002e-29 6.7720457e-04 1.4069000e-18], sampled 0.6851596014214669
[2019-03-22 23:18:20,123] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.03164644], dtype=float32), 0.08467609]
[2019-03-22 23:18:20,124] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.97106271333333, 75.14164871666667, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 410770.0296012584, 410770.0296012581, 141055.2474251748]
[2019-03-22 23:18:20,126] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:18:20,131] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [7.5332106e-34 4.3621153e-01 2.2062258e-25 5.6378841e-01 3.6341690e-15], sampled 0.2502878652635182
[2019-03-22 23:18:56,511] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.03164644], dtype=float32), 0.08467609]
[2019-03-22 23:18:56,512] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [17.94955186, 88.859403645, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 373199.5235095904, 373199.5235095901, 153285.6400552536]
[2019-03-22 23:18:56,513] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:18:56,516] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0.0000000e+00 1.7856441e-05 2.9717376e-30 9.9998212e-01 1.7725079e-17], sampled 0.7830461164120944
[2019-03-22 23:19:42,238] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.03164644], dtype=float32), 0.08467609]
[2019-03-22 23:19:42,242] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.35, 86.0, 1.0, 2.0, 0.2941064223886962, 1.0, 2.0, 0.2941064223886962, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 671048.6811917028, 671048.6811917028, 188684.8759216385]
[2019-03-22 23:19:42,244] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:19:42,248] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.1280174e-32 6.6914927e-04 1.0639270e-25 9.9933088e-01 9.5557461e-16], sampled 0.5064826995955235
[2019-03-22 23:19:52,633] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.03164644], dtype=float32), 0.08467609]
[2019-03-22 23:19:52,636] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.0, 71.0, 1.0, 2.0, 0.3655838100484462, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 407930.9998164004, 407930.9998164001, 124193.8789229324]
[2019-03-22 23:19:52,638] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:19:52,640] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.6472111e-38 9.9918717e-01 4.3715956e-29 8.1283279e-04 1.6503349e-18], sampled 0.11888423656323821
[2019-03-22 23:19:53,278] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 6304.4909 1891257805.6733 49.0000
[2019-03-22 23:19:53,366] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 6563.3840 1887428167.7050 25.0000
[2019-03-22 23:19:53,410] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 6451.5121 1890857867.3856 168.0000
[2019-03-22 23:19:53,555] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 6816.9960 1865444409.8794 19.0000
[2019-03-22 23:19:53,563] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 6374.7194 1956031021.0756 50.0000
[2019-03-22 23:19:54,583] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 525000, evaluation results [525000.0, 6374.71936925417, 1956031021.0755954, 50.0, 6816.996039320486, 1865444409.879366, 19.0, 6563.38399352708, 1887428167.7049737, 25.0, 6451.512128668883, 1890857867.3856187, 168.0, 6304.490852093805, 1891257805.673279, 49.0]
[2019-03-22 23:19:58,683] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.6792609e-35 9.9610484e-01 2.2219175e-29 3.8952301e-03 3.1104184e-12], sum to 1.0000
[2019-03-22 23:19:58,692] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0905
[2019-03-22 23:19:58,699] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 94.0, 1.0, 2.0, 0.3275885088853079, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 358442.2080257083, 358442.2080257086, 114025.8127586152], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4054800.0000, 
sim time next is 4055400.0000, 
raw observation next is [17.0, 94.0, 1.0, 2.0, 0.3240118310927082, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 354511.8315758604, 354511.8315758601, 113763.8922943915], 
processed observation next is [1.0, 0.9565217391304348, 0.4090909090909091, 0.94, 1.0, 1.0, 0.15501478886588524, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13130067836142978, 0.13130067836142967, 0.2774729080351012], 
reward next is 0.7225, 
noisyNet noise sample is [array([0.81599045], dtype=float32), -1.4891669]. 
=============================================
[2019-03-22 23:20:00,430] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.9297724e-30 6.0795884e-27], sum to 1.0000
[2019-03-22 23:20:00,439] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7402
[2019-03-22 23:20:00,444] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 77.0, 1.0, 2.0, 0.281362457399602, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 305511.7109732488, 305511.710973249, 101643.3464513569], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3894600.0000, 
sim time next is 3895200.0000, 
raw observation next is [18.0, 77.0, 1.0, 2.0, 0.2816331722128767, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 305805.7535760876, 305805.7535760876, 101667.6814641793], 
processed observation next is [0.0, 0.08695652173913043, 0.45454545454545453, 0.77, 1.0, 1.0, 0.10204146526609587, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11326139021336577, 0.11326139021336577, 0.24796995479068124], 
reward next is 0.7520, 
noisyNet noise sample is [array([1.559273], dtype=float32), -0.56399524]. 
=============================================
[2019-03-22 23:20:02,391] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.5098297e-31 5.1687086e-32], sum to 1.0000
[2019-03-22 23:20:02,403] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8016
[2019-03-22 23:20:02,406] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.66666666666667, 65.33333333333334, 1.0, 2.0, 0.2840223197589025, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 308400.7842698295, 308400.7842698292, 103096.5108253885], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3882000.0000, 
sim time next is 3882600.0000, 
raw observation next is [19.5, 66.0, 1.0, 2.0, 0.2814211908837305, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 305575.5055704106, 305575.5055704109, 101681.064408825], 
processed observation next is [0.0, 0.9565217391304348, 0.5227272727272727, 0.66, 1.0, 1.0, 0.10177648860466314, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11317611317422614, 0.11317611317422627, 0.24800259611908537], 
reward next is 0.7520, 
noisyNet noise sample is [array([-1.6077605], dtype=float32), 0.563894]. 
=============================================
[2019-03-22 23:20:07,898] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.1192348e-33 1.0000000e+00 6.4377187e-24 1.6997781e-09 1.0425036e-09], sum to 1.0000
[2019-03-22 23:20:07,906] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3316
[2019-03-22 23:20:07,914] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.6248095501886834, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 702660.8492792225, 702660.8492792229, 147708.1369978712], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4027800.0000, 
sim time next is 4028400.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.5559538064592562, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 625048.1083154102, 625048.1083154102, 139782.7034766708], 
processed observation next is [1.0, 0.6521739130434783, 0.45454545454545453, 1.0, 1.0, 1.0, 0.4449422580740702, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23149929937607786, 0.23149929937607786, 0.34093342311383124], 
reward next is 0.6591, 
noisyNet noise sample is [array([-0.42858785], dtype=float32), 1.2740451]. 
=============================================
[2019-03-22 23:20:11,462] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.1977919e-22 3.6313683e-27], sum to 1.0000
[2019-03-22 23:20:11,471] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3919
[2019-03-22 23:20:11,475] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 94.0, 1.0, 2.0, 0.3203920165441284, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 350534.1715083456, 350534.1715083456, 113500.329389377], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4056000.0000, 
sim time next is 4056600.0000, 
raw observation next is [17.0, 94.0, 1.0, 2.0, 0.3183658651175765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 348304.471991756, 348304.471991756, 113352.2780809082], 
processed observation next is [1.0, 0.9565217391304348, 0.4090909090909091, 0.94, 1.0, 1.0, 0.14795733139697057, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12900165629324295, 0.12900165629324295, 0.2764689709290444], 
reward next is 0.7235, 
noisyNet noise sample is [array([0.9732431], dtype=float32), 0.42723987]. 
=============================================
[2019-03-22 23:20:13,475] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.0323598e-29 3.5340852e-31], sum to 1.0000
[2019-03-22 23:20:13,484] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5808
[2019-03-22 23:20:13,490] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.03333333333333, 93.66666666666667, 1.0, 2.0, 0.3950727021860171, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 445161.5284507537, 445161.5284507534, 124387.3081308146], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4126800.0000, 
sim time next is 4127400.0000, 
raw observation next is [19.05, 93.5, 1.0, 2.0, 0.39456541663106, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 444578.7129983312, 444578.7129983312, 124336.0125386583], 
processed observation next is [1.0, 0.782608695652174, 0.5022727272727273, 0.935, 1.0, 1.0, 0.24320677078882497, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1646587825919745, 0.1646587825919745, 0.30325856716745925], 
reward next is 0.6967, 
noisyNet noise sample is [array([0.10683767], dtype=float32), 0.34251028]. 
=============================================
[2019-03-22 23:20:17,712] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 3.6734460e-34 3.1845360e-29 1.8301638e-28], sum to 1.0000
[2019-03-22 23:20:17,722] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8041
[2019-03-22 23:20:17,728] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.33333333333333, 100.0, 1.0, 2.0, 0.3564747640241976, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 396904.1222395512, 396904.1222395512, 118760.473071331], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4160400.0000, 
sim time next is 4161000.0000, 
raw observation next is [17.16666666666667, 100.0, 1.0, 2.0, 0.3506536856992221, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 389439.7549645434, 389439.7549645437, 117884.6045559631], 
processed observation next is [1.0, 0.13043478260869565, 0.4166666666666669, 1.0, 1.0, 1.0, 0.18831710712402763, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14423694628316422, 0.14423694628316433, 0.28752342574625145], 
reward next is 0.7125, 
noisyNet noise sample is [array([-0.23036502], dtype=float32), -0.9556042]. 
=============================================
[2019-03-22 23:20:17,753] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[68.27204 ]
 [68.1969  ]
 [68.086235]
 [68.11952 ]
 [68.34263 ]], R is [[68.38942719]
 [68.4158783 ]
 [68.44042206]
 [68.46193695]
 [68.47497559]].
[2019-03-22 23:20:19,657] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 2.5418601e-29 2.4340904e-28 4.9802580e-27], sum to 1.0000
[2019-03-22 23:20:19,665] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8505
[2019-03-22 23:20:19,671] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 73.0, 1.0, 2.0, 0.3722995342442969, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 416520.5610183658, 416520.5610183658, 120913.6645891307], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4219200.0000, 
sim time next is 4219800.0000, 
raw observation next is [21.0, 73.0, 1.0, 2.0, 0.3694187056996227, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 413068.2036801926, 413068.2036801929, 120569.4749687512], 
processed observation next is [1.0, 0.8695652173913043, 0.5909090909090909, 0.73, 1.0, 1.0, 0.21177338212452837, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15298822358525652, 0.15298822358525663, 0.2940718901676858], 
reward next is 0.7059, 
noisyNet noise sample is [array([0.07985949], dtype=float32), 1.055654]. 
=============================================
[2019-03-22 23:20:24,663] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:20:24,670] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6241
[2019-03-22 23:20:24,679] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1231678.495341404 W.
[2019-03-22 23:20:24,682] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.0, 47.0, 1.0, 2.0, 0.5998837851535661, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9623653899829537, 6.911200000000001, 6.9112, 77.32846344354104, 1231678.495341404, 1231678.495341404, 262510.9767043666], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4293600.0000, 
sim time next is 4294200.0000, 
raw observation next is [27.0, 46.0, 1.0, 2.0, 0.5893909381421979, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9606156790537997, 6.911199999999999, 6.9112, 77.32846344354104, 1218658.988632371, 1218658.988632371, 259067.8873389098], 
processed observation next is [1.0, 0.6956521739130435, 0.8636363636363636, 0.46, 1.0, 1.0, 0.48673867267774734, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9437366843625712, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.4513551809749522, 0.4513551809749522, 0.6318728959485604], 
reward next is 0.3681, 
noisyNet noise sample is [array([0.2812689], dtype=float32), -0.040909797]. 
=============================================
[2019-03-22 23:20:28,474] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 2.6458382e-38 1.9226933e-33 1.1841485e-33], sum to 1.0000
[2019-03-22 23:20:28,482] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0436
[2019-03-22 23:20:28,486] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.71666666666667, 66.16666666666667, 1.0, 2.0, 0.4887500771652356, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 557643.9623406285, 557643.9623406285, 140176.1758741798], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4392600.0000, 
sim time next is 4393200.0000, 
raw observation next is [25.43333333333334, 67.33333333333334, 1.0, 2.0, 0.4872124733008381, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 555923.6936237278, 555923.6936237278, 139845.5044243959], 
processed observation next is [1.0, 0.8695652173913043, 0.7924242424242428, 0.6733333333333335, 1.0, 1.0, 0.3590155916260476, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20589766430508435, 0.20589766430508435, 0.3410865961570632], 
reward next is 0.6589, 
noisyNet noise sample is [array([-0.9743647], dtype=float32), 1.4110777]. 
=============================================
[2019-03-22 23:20:33,683] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.1685989e-34 1.4073824e-31], sum to 1.0000
[2019-03-22 23:20:33,694] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4591
[2019-03-22 23:20:33,699] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 94.0, 1.0, 2.0, 0.4658377317987498, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 531325.9048920163, 531325.9048920163, 136095.0528246023], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4486800.0000, 
sim time next is 4487400.0000, 
raw observation next is [21.0, 94.0, 1.0, 2.0, 0.4665026708271701, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 532084.7747815601, 532084.7747815601, 136167.0684927535], 
processed observation next is [0.0, 0.9565217391304348, 0.5909090909090909, 0.94, 1.0, 1.0, 0.3331283385339626, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19706843510428151, 0.19706843510428151, 0.3321148012018378], 
reward next is 0.6679, 
noisyNet noise sample is [array([1.0704576], dtype=float32), -0.60010076]. 
=============================================
[2019-03-22 23:20:34,947] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:20:34,957] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9845
[2019-03-22 23:20:34,961] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.4113712844941463, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 466327.9541286997, 466327.9541286997, 127524.9551303941], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4510200.0000, 
sim time next is 4510800.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4115835389797709, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 466568.9707149618, 466568.9707149621, 127545.2985791925], 
processed observation next is [0.0, 0.21739130434782608, 0.5, 1.0, 1.0, 1.0, 0.2644794237247136, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1728033224870229, 0.17280332248702301, 0.31108609409559146], 
reward next is 0.6889, 
noisyNet noise sample is [array([-1.6211092], dtype=float32), 1.4212108]. 
=============================================
[2019-03-22 23:20:39,635] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 3.3229415e-32], sum to 1.0000
[2019-03-22 23:20:39,645] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2657
[2019-03-22 23:20:39,657] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.66666666666667, 61.5, 1.0, 2.0, 0.3916464178770229, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 442134.3473048862, 442134.3473048862, 124540.634238768], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4558200.0000, 
sim time next is 4558800.0000, 
raw observation next is [23.33333333333333, 62.0, 1.0, 2.0, 0.385802221056345, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 434612.0813089209, 434612.0813089206, 123508.5103774434], 
processed observation next is [0.0, 0.782608695652174, 0.6969696969696968, 0.62, 1.0, 1.0, 0.2322527763204312, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16096743752182258, 0.16096743752182244, 0.30124026921327657], 
reward next is 0.6988, 
noisyNet noise sample is [array([1.2199955], dtype=float32), -0.21350452]. 
=============================================
[2019-03-22 23:20:41,626] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:20:41,635] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2654
[2019-03-22 23:20:41,640] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.83333333333333, 46.5, 1.0, 2.0, 0.6317883361924831, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 692024.1951508492, 692024.1951508494, 141495.6057775584], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4629000.0000, 
sim time next is 4629600.0000, 
raw observation next is [24.0, 47.0, 1.0, 2.0, 0.6520553433708458, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 717218.7433849239, 717218.7433849239, 144689.0339296748], 
processed observation next is [1.0, 0.6086956521739131, 0.7272727272727273, 0.47, 1.0, 1.0, 0.5650691792135573, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2656365716240459, 0.2656365716240459, 0.3529000827553044], 
reward next is 0.6471, 
noisyNet noise sample is [array([0.7421251], dtype=float32), -0.73175853]. 
=============================================
[2019-03-22 23:20:45,459] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.4300540e-36 2.4782063e-31], sum to 1.0000
[2019-03-22 23:20:45,466] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5364
[2019-03-22 23:20:45,472] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 64.0, 1.0, 2.0, 0.2623934285852774, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 284908.542996777, 284908.5429967767, 90439.90025318418], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4657800.0000, 
sim time next is 4658400.0000, 
raw observation next is [19.0, 64.0, 1.0, 2.0, 0.2625592744363857, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 285088.6723127135, 285088.6723127138, 90457.66656843868], 
processed observation next is [1.0, 0.9565217391304348, 0.5, 0.64, 1.0, 1.0, 0.07819909304548213, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10558839715285685, 0.10558839715285696, 0.2206284550449724], 
reward next is 0.7794, 
noisyNet noise sample is [array([-1.4398652], dtype=float32), -0.3342095]. 
=============================================
[2019-03-22 23:20:46,885] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-22 23:20:46,887] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-22 23:20:46,888] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:20:46,890] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-22 23:20:46,890] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-22 23:20:46,892] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-22 23:20:46,893] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:20:46,894] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:20:46,894] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-22 23:20:46,895] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:20:46,899] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:20:46,911] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run23
[2019-03-22 23:20:46,912] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run23
[2019-03-22 23:20:46,929] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run23
[2019-03-22 23:20:46,967] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run23
[2019-03-22 23:20:46,985] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run23
[2019-03-22 23:20:54,676] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.15401715], dtype=float32), 0.009034989]
[2019-03-22 23:20:54,679] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.99781933666667, 90.45809224666667, 1.0, 2.0, 0.3332101436362357, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 367875.8378539062, 367875.8378539062, 119967.4790754076]
[2019-03-22 23:20:54,680] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:20:54,685] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.1563385131970082
[2019-03-22 23:20:55,188] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.15401715], dtype=float32), 0.009034989]
[2019-03-22 23:20:55,189] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [14.977030735, 79.37975765, 1.0, 2.0, 0.2578572914207317, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 61.63163626896797, 280002.2855354256, 280002.2855354256, 69936.90747132264]
[2019-03-22 23:20:55,190] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:20:55,193] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.6669711627137269
[2019-03-22 23:21:13,757] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.15401715], dtype=float32), 0.009034989]
[2019-03-22 23:21:13,758] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [26.06158131166666, 70.97009700333334, 1.0, 2.0, 0.5260469014638866, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 598588.5057239042, 598588.5057239038, 150751.8105989957]
[2019-03-22 23:21:13,758] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:21:13,762] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.5576202429410938
[2019-03-22 23:21:25,297] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.15401715], dtype=float32), 0.009034989]
[2019-03-22 23:21:25,299] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [27.56380803, 52.97376048333334, 1.0, 2.0, 0.445234936844045, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 507662.1706961438, 507662.1706961438, 137997.1431851865]
[2019-03-22 23:21:25,301] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:21:25,305] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.0166933419949018
[2019-03-22 23:21:34,028] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.15401715], dtype=float32), 0.009034989]
[2019-03-22 23:21:34,028] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [27.6, 66.0, 1.0, 2.0, 0.5488671785502495, 0.0, 2.0, 0.0, 1.0, 2.0, 0.904550109894152, 7.018612419075069, 6.9112, 95.55297159003605, 1168008.908424363, 1124901.889945516, 266515.7168846969]
[2019-03-22 23:21:34,030] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:21:34,033] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.4807554679511602
[2019-03-22 23:21:34,035] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1168008.908424363 W.
[2019-03-22 23:21:41,169] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.15401715], dtype=float32), 0.009034989]
[2019-03-22 23:21:41,170] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [15.15879324, 92.68145222, 1.0, 2.0, 0.2504113264512448, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 271880.1654017458, 271880.1654017454, 90828.33560039733]
[2019-03-22 23:21:41,172] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:21:41,174] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.5846625122118709
[2019-03-22 23:21:51,977] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.15401715], dtype=float32), 0.009034989]
[2019-03-22 23:21:51,978] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.67593365333333, 97.94561300000001, 1.0, 2.0, 0.3833886966769186, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 432586.0677243407, 432586.0677243404, 128002.8258479726]
[2019-03-22 23:21:51,980] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:21:51,983] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.29309168861690815
[2019-03-22 23:22:09,030] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.15401715], dtype=float32), 0.009034989]
[2019-03-22 23:22:09,033] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [18.06666666666667, 65.0, 1.0, 2.0, 0.2604767318123636, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 282811.0923107989, 282811.0923107985, 89269.60198206529]
[2019-03-22 23:22:09,036] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:22:09,039] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.14834606868962075
[2019-03-22 23:22:14,357] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.15401715], dtype=float32), 0.009034989]
[2019-03-22 23:22:14,358] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.6, 66.0, 1.0, 2.0, 0.4267281686356003, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 483856.8010232613, 483856.8010232613, 133413.1918194233]
[2019-03-22 23:22:14,359] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:22:14,363] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.10645676909556334
[2019-03-22 23:22:18,330] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.15401715], dtype=float32), 0.009034989]
[2019-03-22 23:22:18,332] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.93852823833333, 98.65624038666667, 1.0, 2.0, 0.4816632899328148, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 548632.4407428331, 548632.4407428327, 141060.2895738234]
[2019-03-22 23:22:18,336] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:22:18,339] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.0698831484411877
[2019-03-22 23:22:35,053] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9309 1705967916.6745 465.0000
[2019-03-22 23:22:35,108] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1147 1656209757.7786 80.0000
[2019-03-22 23:22:35,309] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3485 1683325900.1134 214.0000
[2019-03-22 23:22:35,346] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5598 1663796639.0689 105.0000
[2019-03-22 23:22:35,362] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-22 23:22:36,378] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 550000, evaluation results [550000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.114669779829, 1656209757.7786272, 80.0, 8856.559759326878, 1663796639.0688558, 105.0, 8596.930884973775, 1705967916.6744611, 465.0, 8574.348472942609, 1683325900.1133502, 214.0]
[2019-03-22 23:22:39,788] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 5.2967284e-34 1.1913483e-25 6.6760739e-28], sum to 1.0000
[2019-03-22 23:22:39,800] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5302
[2019-03-22 23:22:39,805] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 76.33333333333334, 1.0, 2.0, 0.4049217289042442, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 458276.484005087, 458276.4840050873, 126431.0794457696], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4740000.0000, 
sim time next is 4740600.0000, 
raw observation next is [21.33333333333333, 77.16666666666666, 1.0, 2.0, 0.3988258622279365, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 450580.7021191473, 450580.7021191471, 125384.8336583239], 
processed observation next is [1.0, 0.8695652173913043, 0.6060606060606059, 0.7716666666666666, 1.0, 1.0, 0.24853232778492057, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1668817415256101, 0.16688174152561006, 0.30581666745932656], 
reward next is 0.6942, 
noisyNet noise sample is [array([-2.8372705], dtype=float32), 0.8561733]. 
=============================================
[2019-03-22 23:22:40,658] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 4.9452202e-33 5.0480781e-29 1.2265506e-20], sum to 1.0000
[2019-03-22 23:22:40,669] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5970
[2019-03-22 23:22:40,680] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 88.0, 1.0, 2.0, 0.3631303394337053, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 405833.5393905484, 405833.5393905484, 119957.6590568011], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4758000.0000, 
sim time next is 4758600.0000, 
raw observation next is [19.0, 88.0, 1.0, 2.0, 0.3626766045012074, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 405324.367637117, 405324.3676371168, 119919.4738540799], 
processed observation next is [1.0, 0.043478260869565216, 0.5, 0.88, 1.0, 1.0, 0.20334575562650925, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15012013616189518, 0.15012013616189512, 0.29248652159531685], 
reward next is 0.7075, 
noisyNet noise sample is [array([1.4378535], dtype=float32), -1.7167628]. 
=============================================
[2019-03-22 23:22:42,463] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 6.503354e-38 9.127520e-34], sum to 1.0000
[2019-03-22 23:22:42,473] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8630
[2019-03-22 23:22:42,478] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 54.0, 1.0, 2.0, 0.4104290692738911, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 466192.9422165355, 466192.9422165353, 128124.3672719698], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5068800.0000, 
sim time next is 5069400.0000, 
raw observation next is [26.16666666666667, 53.5, 1.0, 2.0, 0.4102529054731964, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 466069.7535352261, 466069.7535352261, 128169.7922333078], 
processed observation next is [0.0, 0.6956521739130435, 0.825757575757576, 0.535, 1.0, 1.0, 0.2628161318414955, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17261842723526893, 0.17261842723526893, 0.3126092493495312], 
reward next is 0.6874, 
noisyNet noise sample is [array([0.59916073], dtype=float32), -0.77031434]. 
=============================================
[2019-03-22 23:23:09,117] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.1179143e-36 1.0000000e+00 3.4090098e-29 6.6968516e-16 1.2700444e-15], sum to 1.0000
[2019-03-22 23:23:09,130] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0422
[2019-03-22 23:23:09,134] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 88.5, 1.0, 2.0, 0.3463383450589265, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 386364.8930751084, 386364.8930751081, 118280.8254743329], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5286600.0000, 
sim time next is 5287200.0000, 
raw observation next is [18.8, 88.0, 1.0, 2.0, 0.3448448837378084, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 384382.3768627165, 384382.3768627162, 118023.1314280397], 
processed observation next is [1.0, 0.17391304347826086, 0.49090909090909096, 0.88, 1.0, 1.0, 0.1810561046722605, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1423638432824876, 0.1423638432824875, 0.2878612961659505], 
reward next is 0.7121, 
noisyNet noise sample is [array([1.213735], dtype=float32), 0.32052815]. 
=============================================
[2019-03-22 23:23:10,196] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.7347727e-23 2.7613517e-06 3.5907992e-15 9.9999726e-01 4.6278630e-09], sum to 1.0000
[2019-03-22 23:23:10,208] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0721
[2019-03-22 23:23:10,215] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.15, 52.5, 1.0, 2.0, 0.4863681506593135, 1.0, 2.0, 0.4863681506593135, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1110311.221889808, 1110311.221889808, 223975.902344228], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5308200.0000, 
sim time next is 5308800.0000, 
raw observation next is [27.33333333333334, 52.0, 1.0, 2.0, 0.4982651921123975, 1.0, 2.0, 0.4982651921123975, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1137242.739643378, 1137242.739643378, 227289.6747432472], 
processed observation next is [1.0, 0.43478260869565216, 0.878787878787879, 0.52, 1.0, 1.0, 0.3728314901404968, 1.0, 1.0, 0.3728314901404968, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.4212010146827326, 0.4212010146827326, 0.5543650603493834], 
reward next is 0.4456, 
noisyNet noise sample is [array([-0.26734617], dtype=float32), 0.22247046]. 
=============================================
[2019-03-22 23:23:10,281] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.4869219e-38 1.0000000e+00 2.1748722e-30 7.6082915e-17 9.3350351e-18], sum to 1.0000
[2019-03-22 23:23:10,289] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4912
[2019-03-22 23:23:10,295] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 87.0, 1.0, 2.0, 0.3654690796483525, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 409798.6016070553, 409798.6016070553, 120776.3513155978], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5292600.0000, 
sim time next is 5293200.0000, 
raw observation next is [19.4, 87.0, 1.0, 2.0, 0.3600727966504393, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 403759.4451947517, 403759.445194752, 120332.7219176318], 
processed observation next is [1.0, 0.2608695652173913, 0.5181818181818181, 0.87, 1.0, 1.0, 0.2000909958130491, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14954053525731545, 0.14954053525731556, 0.293494443701541], 
reward next is 0.7065, 
noisyNet noise sample is [array([0.44081402], dtype=float32), -0.9190671]. 
=============================================
[2019-03-22 23:23:19,472] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.8476076e-30 1.3539098e-17 3.3769195e-24], sum to 1.0000
[2019-03-22 23:23:19,481] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5077
[2019-03-22 23:23:19,486] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.2, 98.33333333333334, 1.0, 2.0, 0.367187016179823, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 406955.1389708584, 406955.1389708587, 118861.8228177175], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5458200.0000, 
sim time next is 5458800.0000, 
raw observation next is [17.2, 96.66666666666667, 1.0, 2.0, 0.3486163038528191, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 385243.85949181, 385243.85949181, 116953.3028510193], 
processed observation next is [1.0, 0.17391304347826086, 0.41818181818181815, 0.9666666666666667, 1.0, 1.0, 0.18577037981602387, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1426829109228926, 0.1426829109228926, 0.2852519581732178], 
reward next is 0.7147, 
noisyNet noise sample is [array([-0.17886858], dtype=float32), 1.4788488]. 
=============================================
[2019-03-22 23:23:25,150] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.3355289e-31 1.0000000e+00 2.1924708e-25 1.6564332e-20 9.0481865e-11], sum to 1.0000
[2019-03-22 23:23:25,155] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5745
[2019-03-22 23:23:25,164] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.91666666666666, 85.0, 1.0, 2.0, 0.4819242261284669, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 549357.0145560117, 549357.0145560119, 137269.8572336963], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5557800.0000, 
sim time next is 5558400.0000, 
raw observation next is [22.2, 84.0, 1.0, 2.0, 0.4748860031107675, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 541532.4642420349, 541532.4642420349, 136838.2826110884], 
processed observation next is [1.0, 0.34782608695652173, 0.6454545454545454, 0.84, 1.0, 1.0, 0.34360750388845934, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20056757934890182, 0.20056757934890182, 0.33375190880753264], 
reward next is 0.6662, 
noisyNet noise sample is [array([1.0879773], dtype=float32), -1.3770207]. 
=============================================
[2019-03-22 23:23:25,847] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.4451155e-27 1.0000000e+00 2.9670100e-23 1.5820210e-28 3.3441697e-22], sum to 1.0000
[2019-03-22 23:23:25,854] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3217
[2019-03-22 23:23:25,861] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1307893.904801889 W.
[2019-03-22 23:23:25,867] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.65, 64.5, 1.0, 2.0, 0.3858936830494317, 1.0, 2.0, 0.3858936830494317, 1.0, 2.0, 0.7807766015910004, 6.9112, 6.9112, 77.3421103, 1307893.904801889, 1307893.904801889, 298188.7159372959], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5571000.0000, 
sim time next is 5571600.0000, 
raw observation next is [26.83333333333334, 63.66666666666666, 1.0, 2.0, 0.5329774776655101, 1.0, 2.0, 0.5329774776655101, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1206287.681576027, 1206287.681576027, 241883.5354320726], 
processed observation next is [1.0, 0.4782608695652174, 0.8560606060606063, 0.6366666666666666, 1.0, 1.0, 0.41622184708188753, 1.0, 1.0, 0.41622184708188753, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.44677321539852854, 0.44677321539852854, 0.5899598425172502], 
reward next is 0.4100, 
noisyNet noise sample is [array([1.6420487], dtype=float32), 0.19979301]. 
=============================================
[2019-03-22 23:23:27,251] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.3940027e-37 1.0000000e+00 6.6978005e-30 5.9317814e-27 2.2692523e-15], sum to 1.0000
[2019-03-22 23:23:27,262] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9288
[2019-03-22 23:23:27,270] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 97.0, 1.0, 2.0, 0.3589811782144647, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 399992.3133341134, 399992.3133341137, 119088.2580765155], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5637600.0000, 
sim time next is 5638200.0000, 
raw observation next is [17.61666666666667, 97.5, 1.0, 2.0, 0.3552354329223684, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 395406.4689061129, 395406.4689061129, 118611.7071059617], 
processed observation next is [0.0, 0.2608695652173913, 0.4371212121212123, 0.975, 1.0, 1.0, 0.1940442911529605, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14644684033559738, 0.14644684033559738, 0.28929684659990657], 
reward next is 0.7107, 
noisyNet noise sample is [array([-2.5919583], dtype=float32), 0.72842133]. 
=============================================
[2019-03-22 23:23:28,696] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-22 23:23:28,698] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-22 23:23:28,699] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:23:28,700] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-22 23:23:28,700] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:23:28,701] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-22 23:23:28,701] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-22 23:23:28,703] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-22 23:23:28,702] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:23:28,704] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:23:28,705] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:23:28,719] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run24
[2019-03-22 23:23:28,720] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run24
[2019-03-22 23:23:28,748] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run24
[2019-03-22 23:23:28,749] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run24
[2019-03-22 23:23:28,783] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run24
[2019-03-22 23:23:42,799] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13206756], dtype=float32), -0.0059191966]
[2019-03-22 23:23:42,802] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [16.0, 100.0, 1.0, 2.0, 0.5225369270488095, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 569166.4259660146, 569166.4259660146, 129421.4137858291]
[2019-03-22 23:23:42,802] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:23:42,805] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 4.8961593e-38 3.1050921e-26 1.3547999e-15], sampled 0.48686913205613724
[2019-03-22 23:23:55,837] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13206756], dtype=float32), -0.0059191966]
[2019-03-22 23:23:55,838] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.95316761, 57.56723973, 1.0, 2.0, 0.3460662318431242, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 384233.0101608636, 384233.0101608632, 121798.4710282572]
[2019-03-22 23:23:55,839] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:23:55,844] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 5.4740153e-37 5.0806771e-26], sampled 0.2982445186250785
[2019-03-22 23:24:32,170] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.13206756], dtype=float32), -0.0059191966]
[2019-03-22 23:24:32,172] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.1, 61.66666666666666, 1.0, 2.0, 0.3473135517976789, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 377123.2446276966, 377123.2446276963, 112272.6370282795]
[2019-03-22 23:24:32,175] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:24:32,179] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.1773465e-37 9.6665790e-27], sampled 0.4767456127798354
[2019-03-22 23:24:54,529] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13206756], dtype=float32), -0.0059191966]
[2019-03-22 23:24:54,531] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [28.28601718, 44.51390163, 1.0, 2.0, 0.4481559374122705, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 510019.9928070154, 510019.9928070151, 137033.2255227216]
[2019-03-22 23:24:54,532] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:24:54,533] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.1631729e-34 3.8941017e-22], sampled 0.506600000829033
[2019-03-22 23:25:16,492] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1148 1656229146.4555 80.0000
[2019-03-22 23:25:16,754] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8510.7981 1774069077.9369 171.0000
[2019-03-22 23:25:16,761] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.7166 1663843543.7098 104.0000
[2019-03-22 23:25:16,858] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8598.6070 1706111692.2664 458.0000
[2019-03-22 23:25:16,902] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8576.7572 1683994991.3295 202.0000
[2019-03-22 23:25:17,918] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 575000, evaluation results [575000.0, 8510.7981115222, 1774069077.9368825, 171.0, 9061.114827412715, 1656229146.4555063, 80.0, 8856.71664715407, 1663843543.7098331, 104.0, 8598.607003464262, 1706111692.2663853, 458.0, 8576.757213360988, 1683994991.3294787, 202.0]
[2019-03-22 23:25:23,878] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 2.1352790e-32 6.4512164e-31 5.0482953e-27], sum to 1.0000
[2019-03-22 23:25:23,887] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9772
[2019-03-22 23:25:23,893] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.2, 80.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 163825.1198455309, 163825.1198455306, 59662.14610197004], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5729400.0000, 
sim time next is 5730000.0000, 
raw observation next is [12.56666666666667, 78.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 168400.7160472721, 168400.7160472718, 60264.87630088159], 
processed observation next is [0.0, 0.30434782608695654, 0.20757575757575772, 0.78, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.062370635573063736, 0.062370635573063625, 0.14698750317288192], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0359409], dtype=float32), -1.4149635]. 
=============================================
[2019-03-22 23:25:23,905] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[12.273302]
 [12.284451]
 [12.338953]
 [12.42605 ]
 [12.498313]], R is [[12.16527271]
 [12.04362011]
 [11.92318439]
 [11.80395222]
 [11.68591309]].
[2019-03-22 23:25:28,171] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.1968813e-37 1.0000000e+00 1.0215511e-34 2.3548419e-27 1.8873323e-11], sum to 1.0000
[2019-03-22 23:25:28,182] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9238
[2019-03-22 23:25:28,188] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.1, 40.0, 1.0, 2.0, 0.6306286421085451, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 699188.1758646414, 699188.1758646414, 144264.9951820124], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5846400.0000, 
sim time next is 5847000.0000, 
raw observation next is [26.1, 40.0, 1.0, 2.0, 0.6536154876647402, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 724592.7691808047, 724592.7691808047, 146849.2125700663], 
processed observation next is [1.0, 0.6956521739130435, 0.8227272727272728, 0.4, 1.0, 1.0, 0.5670193595809252, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.26836769228918694, 0.26836769228918694, 0.3581688111465032], 
reward next is 0.6418, 
noisyNet noise sample is [array([-1.5853364], dtype=float32), 0.1487027]. 
=============================================
[2019-03-22 23:25:28,196] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[89.40533 ]
 [89.362976]
 [89.14625 ]
 [88.89124 ]
 [88.91405 ]], R is [[89.1241684 ]
 [88.88105774]
 [88.64474487]
 [88.40608978]
 [88.1612854 ]].
[2019-03-22 23:25:36,818] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 5.8840696e-35], sum to 1.0000
[2019-03-22 23:25:36,826] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8889
[2019-03-22 23:25:36,833] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.9, 86.0, 1.0, 2.0, 0.3596648097439566, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 400047.4688087259, 400047.4688087259, 118845.3233514278], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5971800.0000, 
sim time next is 5972400.0000, 
raw observation next is [18.8, 87.0, 1.0, 2.0, 0.3623252315029062, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 403125.8987719535, 403125.8987719535, 119108.6854888294], 
processed observation next is [1.0, 0.13043478260869565, 0.49090909090909096, 0.87, 1.0, 1.0, 0.2029065393786327, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14930588843405684, 0.14930588843405684, 0.2905089889971449], 
reward next is 0.7095, 
noisyNet noise sample is [array([0.91871214], dtype=float32), -0.42348528]. 
=============================================
[2019-03-22 23:25:39,002] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.00000000e+00 1.00000000e+00 0.00000000e+00 1.15097795e-33
 3.90505106e-29], sum to 1.0000
[2019-03-22 23:25:39,012] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4428
[2019-03-22 23:25:39,015] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.18333333333334, 57.33333333333334, 1.0, 2.0, 0.5425585023612614, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 618447.8603398817, 618447.8603398817, 144062.2070800166], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6007800.0000, 
sim time next is 6008400.0000, 
raw observation next is [26.1, 58.0, 1.0, 2.0, 0.5720666394398197, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 652171.7836738107, 652171.7836738104, 147697.0861364275], 
processed observation next is [1.0, 0.5652173913043478, 0.8227272727272728, 0.58, 1.0, 1.0, 0.4650832992997746, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.24154510506437432, 0.24154510506437424, 0.3602367954547012], 
reward next is 0.6398, 
noisyNet noise sample is [array([-0.19548707], dtype=float32), 0.56484437]. 
=============================================
[2019-03-22 23:25:39,043] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 6.0155095e-32], sum to 1.0000
[2019-03-22 23:25:39,050] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1909
[2019-03-22 23:25:39,058] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 93.0, 1.0, 2.0, 0.3730914719869907, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 418937.6158976897, 418937.6158976897, 121703.9032088505], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6232800.0000, 
sim time next is 6233400.0000, 
raw observation next is [18.8, 93.0, 1.0, 2.0, 0.3726212670907644, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 418407.5580881356, 418407.5580881356, 121662.8808242553], 
processed observation next is [0.0, 0.13043478260869565, 0.49090909090909096, 0.93, 1.0, 1.0, 0.21577658386345544, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15496576225486505, 0.15496576225486505, 0.2967387337176959], 
reward next is 0.7033, 
noisyNet noise sample is [array([-1.4591615], dtype=float32), -0.0024176587]. 
=============================================
[2019-03-22 23:25:39,963] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.1292785e-36 9.4096053e-20], sum to 1.0000
[2019-03-22 23:25:39,969] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4860
[2019-03-22 23:25:39,973] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.21666666666667, 79.5, 1.0, 2.0, 0.222952192437141, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 242072.3269541627, 242072.3269541624, 76342.89285292955], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6059400.0000, 
sim time next is 6060000.0000, 
raw observation next is [14.93333333333333, 81.0, 1.0, 2.0, 0.2146084313724729, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 233010.8441407656, 233010.8441407659, 75210.82078903647], 
processed observation next is [1.0, 0.13043478260869565, 0.315151515151515, 0.81, 1.0, 1.0, 0.018260539215591114, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.086300312644728, 0.08630031264472811, 0.18344102631472312], 
reward next is 0.8166, 
noisyNet noise sample is [array([0.06127866], dtype=float32), -1.7353648]. 
=============================================
[2019-03-22 23:25:39,981] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[64.689476]
 [64.61298 ]
 [64.55168 ]
 [64.510826]
 [64.48317 ]], R is [[64.84275818]
 [65.00812531]
 [65.17136383]
 [65.33117676]
 [65.48628998]].
[2019-03-22 23:25:40,513] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.0778193e-31 2.9802764e-19], sum to 1.0000
[2019-03-22 23:25:40,524] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6043
[2019-03-22 23:25:40,528] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.08333333333334, 78.0, 1.0, 2.0, 0.3614013664797929, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 403041.3700029799, 403041.3700029802, 119435.7380630513], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6033000.0000, 
sim time next is 6033600.0000, 
raw observation next is [20.0, 78.0, 1.0, 2.0, 0.3585110038058201, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 399367.7840600715, 399367.7840600715, 119007.5550599395], 
processed observation next is [1.0, 0.8695652173913043, 0.5454545454545454, 0.78, 1.0, 1.0, 0.19813875475727513, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14791399409632278, 0.14791399409632278, 0.2902623294144866], 
reward next is 0.7097, 
noisyNet noise sample is [array([-0.5201346], dtype=float32), 0.16613051]. 
=============================================
[2019-03-22 23:25:43,156] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 2.5833212e-26], sum to 1.0000
[2019-03-22 23:25:43,168] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7241
[2019-03-22 23:25:43,173] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.98333333333333, 64.0, 1.0, 2.0, 0.4048433545346309, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 439651.5502084343, 439651.5502084346, 98996.34648637447], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6081000.0000, 
sim time next is 6081600.0000, 
raw observation next is [18.26666666666667, 63.0, 1.0, 2.0, 0.4057018061961669, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 440584.2334525276, 440584.2334525276, 99752.77436433031], 
processed observation next is [1.0, 0.391304347826087, 0.4666666666666668, 0.63, 1.0, 1.0, 0.2571272577452086, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16317934572315837, 0.16317934572315837, 0.24329944966909833], 
reward next is 0.7567, 
noisyNet noise sample is [array([0.15535246], dtype=float32), -2.194627]. 
=============================================
[2019-03-22 23:25:44,975] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:25:44,982] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3816
[2019-03-22 23:25:44,988] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.5, 78.50000000000001, 1.0, 2.0, 0.5110364669248925, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 582153.9823542649, 582153.9823542652, 144156.4392360478], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6340200.0000, 
sim time next is 6340800.0000, 
raw observation next is [24.6, 78.0, 1.0, 2.0, 0.5150617458155319, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 586685.3482929809, 586685.3482929809, 144690.8589337199], 
processed observation next is [0.0, 0.391304347826087, 0.7545454545454546, 0.78, 1.0, 1.0, 0.3938271822694148, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21729086973814107, 0.21729086973814107, 0.3529045339846827], 
reward next is 0.6471, 
noisyNet noise sample is [array([0.40462163], dtype=float32), 0.68709874]. 
=============================================
[2019-03-22 23:25:49,479] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.2615014e-38 1.0000000e+00 1.2528709e-29 2.7765452e-27 1.6318906e-21], sum to 1.0000
[2019-03-22 23:25:49,488] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0977
[2019-03-22 23:25:49,493] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.36666666666667, 76.0, 1.0, 2.0, 0.6174881692839621, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 689727.9462602743, 689727.9462602743, 144779.0078720468], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6172800.0000, 
sim time next is 6173400.0000, 
raw observation next is [20.18333333333333, 78.5, 1.0, 2.0, 0.607136479421419, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 679379.2565546185, 679379.2565546185, 144112.2768819263], 
processed observation next is [1.0, 0.43478260869565216, 0.5537878787878786, 0.785, 1.0, 1.0, 0.5089205992767737, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2516219468720809, 0.2516219468720809, 0.3514933582486007], 
reward next is 0.6485, 
noisyNet noise sample is [array([-0.57251275], dtype=float32), 0.7431929]. 
=============================================
[2019-03-22 23:25:53,298] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 7.2551166e-33], sum to 1.0000
[2019-03-22 23:25:53,307] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8642
[2019-03-22 23:25:53,313] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.3, 95.0, 1.0, 2.0, 0.3648163523906655, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 408363.9273135548, 408363.9273135545, 120390.5969732762], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6240000.0000, 
sim time next is 6240600.0000, 
raw observation next is [18.3, 94.5, 1.0, 2.0, 0.3623117237766121, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 405265.1532556924, 405265.1532556924, 120047.474171607], 
processed observation next is [0.0, 0.21739130434782608, 0.4681818181818182, 0.945, 1.0, 1.0, 0.2028896547207651, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1500982049095157, 0.1500982049095157, 0.29279871749172437], 
reward next is 0.7072, 
noisyNet noise sample is [array([-1.1966615], dtype=float32), -0.128128]. 
=============================================
[2019-03-22 23:25:54,084] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 2.6346813e-36], sum to 1.0000
[2019-03-22 23:25:54,092] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1578
[2019-03-22 23:25:54,099] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.2, 89.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 193864.3179972029, 193864.3179972026, 65901.30770244595], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6501600.0000, 
sim time next is 6502200.0000, 
raw observation next is [12.38333333333333, 89.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 205942.0933168971, 205942.0933168968, 68067.63350489954], 
processed observation next is [1.0, 0.2608695652173913, 0.19924242424242405, 0.89, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07627484937662855, 0.07627484937662844, 0.16601861830463302], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.8585595], dtype=float32), 0.11297673]. 
=============================================
[2019-03-22 23:26:00,630] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.5664295e-36 1.0000000e+00 6.4105149e-32 5.4849855e-31 2.2344578e-27], sum to 1.0000
[2019-03-22 23:26:00,642] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4192
[2019-03-22 23:26:00,649] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.6, 91.0, 1.0, 2.0, 0.8006128884854756, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 913902.5402597273, 913902.5402597273, 181799.0309368665], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6426000.0000, 
sim time next is 6426600.0000, 
raw observation next is [21.33333333333334, 91.33333333333334, 1.0, 2.0, 0.969147303010344, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 82.73331824632892, 1106301.080583458, 1106301.080583458, 211706.8050501671], 
processed observation next is [1.0, 0.391304347826087, 0.6060606060606063, 0.9133333333333334, 1.0, 1.0, 0.9614341287629299, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.543965325467503, 0.40974114095683634, 0.40974114095683634, 0.5163580610979686], 
reward next is 0.4836, 
noisyNet noise sample is [array([1.4947501], dtype=float32), 1.6497499]. 
=============================================
[2019-03-22 23:26:02,361] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 6.2771871e-37 1.8352413e-26], sum to 1.0000
[2019-03-22 23:26:02,370] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9707
[2019-03-22 23:26:02,383] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 69.66666666666667, 1.0, 2.0, 0.3387713363795454, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 370892.8106745802, 370892.8106745805, 114911.097322427], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6457200.0000, 
sim time next is 6457800.0000, 
raw observation next is [20.0, 68.33333333333333, 1.0, 2.0, 0.3313716016734754, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 361536.328370843, 361536.3283708433, 113929.7773570245], 
processed observation next is [1.0, 0.7391304347826086, 0.5454545454545454, 0.6833333333333332, 1.0, 1.0, 0.16421450209184424, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13390234384105298, 0.13390234384105307, 0.27787750574884024], 
reward next is 0.7221, 
noisyNet noise sample is [array([-2.0369177], dtype=float32), -0.86486536]. 
=============================================
[2019-03-22 23:26:02,481] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 6.8870968e-37 3.2317047e-34 6.4694518e-24], sum to 1.0000
[2019-03-22 23:26:02,489] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8268
[2019-03-22 23:26:02,492] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.6, 73.0, 1.0, 2.0, 0.5078891182024328, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 579492.9837543307, 579492.9837543307, 142392.9261750766], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6421200.0000, 
sim time next is 6421800.0000, 
raw observation next is [24.5, 73.5, 1.0, 2.0, 0.4875527366354728, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 556291.5873972651, 556291.5873972651, 139981.9098529117], 
processed observation next is [1.0, 0.30434782608695654, 0.75, 0.735, 1.0, 1.0, 0.359440920794341, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20603392125824635, 0.20603392125824635, 0.34141929232417484], 
reward next is 0.6586, 
noisyNet noise sample is [array([-1.1633126], dtype=float32), 2.0627549]. 
=============================================
[2019-03-22 23:26:05,559] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:26:05,569] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4006
[2019-03-22 23:26:05,576] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.5, 75.0, 1.0, 2.0, 0.2186431782385491, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 237392.6347049871, 237392.6347049874, 75188.25774682713], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6474000.0000, 
sim time next is 6474600.0000, 
raw observation next is [15.5, 75.0, 1.0, 2.0, 0.2184418313415192, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 237173.9682709924, 237173.9682709927, 75164.1622824411], 
processed observation next is [1.0, 0.9565217391304348, 0.3409090909090909, 0.75, 1.0, 1.0, 0.023052289176898992, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08784221047073792, 0.08784221047073804, 0.18332722507912463], 
reward next is 0.8167, 
noisyNet noise sample is [array([-1.3317825], dtype=float32), 1.2697957]. 
=============================================
[2019-03-22 23:26:06,687] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:26:06,702] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0902
[2019-03-22 23:26:06,709] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.41666666666667, 75.83333333333333, 1.0, 2.0, 0.2179004204796491, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 236585.9866031965, 236585.9866031965, 75149.08572564187], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6477000.0000, 
sim time next is 6477600.0000, 
raw observation next is [15.33333333333333, 76.66666666666667, 1.0, 2.0, 0.2182949285429692, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 237014.4291914853, 237014.4291914853, 75229.76846226396], 
processed observation next is [1.0, 1.0, 0.3333333333333332, 0.7666666666666667, 1.0, 1.0, 0.022868660678711482, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08778312192277234, 0.08778312192277234, 0.18348724015186332], 
reward next is 0.8165, 
noisyNet noise sample is [array([0.30282003], dtype=float32), 0.38702333]. 
=============================================
[2019-03-22 23:26:07,927] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.1902608e-28], sum to 1.0000
[2019-03-22 23:26:07,936] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4058
[2019-03-22 23:26:07,940] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 57.0, 1.0, 2.0, 0.4353145576061355, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 472758.7386672294, 472758.7386672294, 101307.8654451065], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6516000.0000, 
sim time next is 6516600.0000, 
raw observation next is [18.71666666666667, 57.5, 1.0, 2.0, 0.4510384059444616, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 489843.6985975142, 489843.6985975142, 102847.9012556882], 
processed observation next is [1.0, 0.43478260869565216, 0.48712121212121223, 0.575, 1.0, 1.0, 0.31379800743057695, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1814235920731534, 0.1814235920731534, 0.25084853964802], 
reward next is 0.7492, 
noisyNet noise sample is [array([-1.0277175], dtype=float32), 0.28354385]. 
=============================================
[2019-03-22 23:26:09,273] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.0016888e-35 4.9420015e-23], sum to 1.0000
[2019-03-22 23:26:09,282] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0055
[2019-03-22 23:26:09,290] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.23333333333333, 77.33333333333333, 1.0, 2.0, 0.5909098276717671, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 650118.9431124664, 650118.9431124664, 138136.6186362879], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6770400.0000, 
sim time next is 6771000.0000, 
raw observation next is [19.61666666666667, 77.16666666666667, 1.0, 2.0, 0.6117938129872159, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 677163.7648368177, 677163.7648368181, 141757.5626392849], 
processed observation next is [1.0, 0.34782608695652173, 0.5280303030303032, 0.7716666666666667, 1.0, 1.0, 0.5147422662340199, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.25080139438400656, 0.2508013943840067, 0.34575015277874366], 
reward next is 0.6542, 
noisyNet noise sample is [array([0.03805622], dtype=float32), 0.35956064]. 
=============================================
[2019-03-22 23:26:09,309] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[79.82707 ]
 [80.15522 ]
 [80.767715]
 [81.40436 ]
 [81.65253 ]], R is [[79.52189636]
 [79.38975525]
 [79.2711792 ]
 [79.17836761]
 [79.11958313]].
[2019-03-22 23:26:10,638] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-22 23:26:10,639] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-22 23:26:10,641] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-22 23:26:10,641] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:26:10,642] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-22 23:26:10,643] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:26:10,642] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-22 23:26:10,646] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:26:10,647] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:26:10,641] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-22 23:26:10,652] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:26:10,666] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run25
[2019-03-22 23:26:10,667] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run25
[2019-03-22 23:26:10,703] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run25
[2019-03-22 23:26:10,705] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run25
[2019-03-22 23:26:10,722] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run25
[2019-03-22 23:26:17,309] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.07928191], dtype=float32), 0.022730641]
[2019-03-22 23:26:17,311] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.41250432833333, 51.75007118166667, 1.0, 2.0, 0.2291808490577049, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 248824.7367121816, 248824.7367121816, 76765.42832078332]
[2019-03-22 23:26:17,313] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:26:17,314] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.7384358152841662
[2019-03-22 23:26:18,323] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.07928191], dtype=float32), 0.022730641]
[2019-03-22 23:26:18,324] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [14.83333333333333, 89.00000000000001, 1.0, 2.0, 0.2345604325951616, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 254679.376816901, 254679.3768169013, 80254.30294790174]
[2019-03-22 23:26:18,325] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:26:18,332] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.863993600922194
[2019-03-22 23:26:20,440] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.07928191], dtype=float32), 0.022730641]
[2019-03-22 23:26:20,441] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [26.0, 49.0, 1.0, 2.0, 0.9625467646528522, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1089310.147527853, 1089310.147527853, 198879.6903166499]
[2019-03-22 23:26:20,443] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:26:20,446] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.6026856e-33 2.0549102e-26], sampled 0.07930028785821164
[2019-03-22 23:26:20,447] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1089310.147527853 W.
[2019-03-22 23:26:21,242] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.07928191], dtype=float32), 0.022730641]
[2019-03-22 23:26:21,244] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.2, 39.0, 1.0, 2.0, 0.3883602532843591, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 421708.5963649246, 421708.5963649249, 114503.6877381404]
[2019-03-22 23:26:21,246] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:26:21,247] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.7328445472338923
[2019-03-22 23:26:28,993] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.07928191], dtype=float32), 0.022730641]
[2019-03-22 23:26:28,995] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.25, 86.0, 1.0, 2.0, 0.4702262102638826, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 536426.183746273, 536426.1837462727, 141290.2866111378]
[2019-03-22 23:26:28,997] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:26:29,000] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 9.340604e-38], sampled 0.2898965650468144
[2019-03-22 23:26:29,710] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.07928191], dtype=float32), 0.022730641]
[2019-03-22 23:26:29,712] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.31714996, 80.35448539, 1.0, 2.0, 0.4858617647562593, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 553776.8247900858, 553776.8247900858, 141989.2766836965]
[2019-03-22 23:26:29,713] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:26:29,716] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 3.6377988e-36], sampled 0.4368636834210702
[2019-03-22 23:26:55,970] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.07928191], dtype=float32), 0.022730641]
[2019-03-22 23:26:55,971] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.547146405, 92.90110440000001, 1.0, 2.0, 0.3246121020527587, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 353974.1993135199, 353974.1993135199, 117695.9823762001]
[2019-03-22 23:26:55,972] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:26:55,976] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.23152229993227313
[2019-03-22 23:27:04,179] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.07928191], dtype=float32), 0.022730641]
[2019-03-22 23:27:04,179] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.598345795, 54.63074352, 1.0, 2.0, 0.3233541052303061, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 354208.0301198314, 354208.0301198311, 118183.1366725447]
[2019-03-22 23:27:04,180] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:27:04,184] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.3515601755610067
[2019-03-22 23:27:11,828] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.07928191], dtype=float32), 0.022730641]
[2019-03-22 23:27:11,830] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.0, 90.0, 1.0, 2.0, 0.4084261488867494, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 462388.4454970419, 462388.4454970416, 131182.881633042]
[2019-03-22 23:27:11,832] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:27:11,834] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 3.9342046e-38], sampled 0.9522681605066475
[2019-03-22 23:27:22,675] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.07928191], dtype=float32), 0.022730641]
[2019-03-22 23:27:22,676] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.64892118, 92.11981135333333, 1.0, 2.0, 0.3565648651936961, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 399053.0961922347, 399053.0961922347, 123997.4073871064]
[2019-03-22 23:27:22,677] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:27:22,679] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.5480462042353083
[2019-03-22 23:27:39,160] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.07928191], dtype=float32), 0.022730641]
[2019-03-22 23:27:39,161] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [12.89298876, 84.13195631, 1.0, 2.0, 0.201556511111431, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 218827.1612911561, 218827.1612911561, 74826.64364809674]
[2019-03-22 23:27:39,164] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:27:39,168] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.866288942652971
[2019-03-22 23:27:45,322] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.07928191], dtype=float32), 0.022730641]
[2019-03-22 23:27:45,323] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.9, 65.0, 1.0, 2.0, 0.3834802665825162, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 432014.236849494, 432014.236849494, 127640.2473294011]
[2019-03-22 23:27:45,325] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:27:45,330] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.18033429736244877
[2019-03-22 23:27:57,956] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9309 1705967916.6745 465.0000
[2019-03-22 23:27:58,251] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1148 1656229146.4555 80.0000
[2019-03-22 23:27:58,260] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2492 1773187030.7201 173.0000
[2019-03-22 23:27:58,532] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5599 1663815647.6096 105.0000
[2019-03-22 23:27:58,567] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3485 1683325900.1134 214.0000
[2019-03-22 23:27:59,584] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 600000, evaluation results [600000.0, 8512.249193409023, 1773187030.7201214, 173.0, 9061.114827412715, 1656229146.4555063, 80.0, 8856.559925897878, 1663815647.6095803, 105.0, 8596.930884973775, 1705967916.6744611, 465.0, 8574.348472942609, 1683325900.1133502, 214.0]
[2019-03-22 23:28:01,567] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.7077172e-35], sum to 1.0000
[2019-03-22 23:28:01,575] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4198
[2019-03-22 23:28:01,580] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 63.0, 1.0, 2.0, 0.3764471005033654, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 408800.8385666298, 408800.8385666301, 104562.6630565849], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6602400.0000, 
sim time next is 6603000.0000, 
raw observation next is [19.68333333333333, 62.33333333333333, 1.0, 2.0, 0.4664964862048044, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 506640.4699528163, 506640.4699528163, 115663.1891734445], 
processed observation next is [1.0, 0.43478260869565216, 0.5310606060606059, 0.6233333333333333, 1.0, 1.0, 0.33312060775600544, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18764461850104308, 0.18764461850104308, 0.2821053394474256], 
reward next is 0.7179, 
noisyNet noise sample is [array([-1.1416501], dtype=float32), -1.2888021]. 
=============================================
[2019-03-22 23:28:01,605] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[58.11296 ]
 [57.750286]
 [57.157665]
 [56.48415 ]
 [55.970154]], R is [[58.21103287]
 [58.37388992]
 [58.54374695]
 [58.71009827]
 [58.86783981]].
[2019-03-22 23:28:06,301] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 2.4553702e-37 3.5651093e-37 1.0834946e-32], sum to 1.0000
[2019-03-22 23:28:06,309] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2755
[2019-03-22 23:28:06,315] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.8, 82.0, 1.0, 2.0, 0.6308139089435315, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 706999.0456158122, 706999.0456158122, 147320.4838007579], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6685800.0000, 
sim time next is 6686400.0000, 
raw observation next is [19.6, 83.0, 1.0, 2.0, 0.5276803137566501, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 590708.9990413617, 590708.9990413614, 135594.6654839713], 
processed observation next is [1.0, 0.391304347826087, 0.5272727272727273, 0.83, 1.0, 1.0, 0.4096003921958126, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2187811107560599, 0.21878111075605977, 0.33071869630236905], 
reward next is 0.6693, 
noisyNet noise sample is [array([1.3188405], dtype=float32), 1.2499287]. 
=============================================
[2019-03-22 23:28:09,048] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 4.5634278e-30], sum to 1.0000
[2019-03-22 23:28:09,057] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5041
[2019-03-22 23:28:09,063] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.3, 93.0, 1.0, 2.0, 0.3681859759762563, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 410849.3698832141, 410849.3698832141, 120094.4352903036], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6718200.0000, 
sim time next is 6718800.0000, 
raw observation next is [18.3, 93.0, 1.0, 2.0, 0.3661041197434904, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 408521.7013301789, 408521.7013301786, 119921.4914555787], 
processed observation next is [1.0, 0.782608695652174, 0.4681818181818182, 0.93, 1.0, 1.0, 0.20763014967936297, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15130433382599218, 0.15130433382599207, 0.2924914425745822], 
reward next is 0.7075, 
noisyNet noise sample is [array([-0.9232092], dtype=float32), 0.08116525]. 
=============================================
[2019-03-22 23:28:09,374] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 6.360213e-33], sum to 1.0000
[2019-03-22 23:28:09,384] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1784
[2019-03-22 23:28:09,387] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.53333333333333, 98.66666666666667, 1.0, 2.0, 0.3639510070105123, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 405565.9464399148, 405565.9464399145, 119505.8757424804], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6733200.0000, 
sim time next is 6733800.0000, 
raw observation next is [17.45, 98.0, 1.0, 2.0, 0.3582718134634832, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 398332.9101059245, 398332.9101059248, 118664.6720466662], 
processed observation next is [1.0, 0.9565217391304348, 0.4295454545454545, 0.98, 1.0, 1.0, 0.19783976682935397, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14753070744663868, 0.14753070744663882, 0.28942602938211265], 
reward next is 0.7106, 
noisyNet noise sample is [array([-0.7137488], dtype=float32), -1.9525995]. 
=============================================
[2019-03-22 23:28:10,315] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 4.3108674e-31], sum to 1.0000
[2019-03-22 23:28:10,322] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5075
[2019-03-22 23:28:10,330] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.2, 90.0, 1.0, 2.0, 0.3265575088015993, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 355750.8621235488, 355750.8621235485, 113402.0108787447], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6757200.0000, 
sim time next is 6757800.0000, 
raw observation next is [17.16666666666667, 89.0, 1.0, 2.0, 0.3154883412537207, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 342819.1929298263, 342819.1929298266, 112325.1447113402], 
processed observation next is [1.0, 0.21739130434782608, 0.4166666666666669, 0.89, 1.0, 1.0, 0.14436042656715087, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12697007145549125, 0.12697007145549133, 0.2739637675886346], 
reward next is 0.7260, 
noisyNet noise sample is [array([-0.5571231], dtype=float32), -1.8828037]. 
=============================================
[2019-03-22 23:28:11,050] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 2.1292858e-38], sum to 1.0000
[2019-03-22 23:28:11,059] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5639
[2019-03-22 23:28:11,062] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.2, 93.0, 1.0, 2.0, 0.3216150273591896, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 352466.5883604378, 352466.5883604381, 113802.7531004965], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6753600.0000, 
sim time next is 6754200.0000, 
raw observation next is [17.2, 92.5, 1.0, 2.0, 0.3592081464821024, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 393478.911608036, 393478.911608036, 116505.8107564511], 
processed observation next is [1.0, 0.17391304347826086, 0.41818181818181815, 0.925, 1.0, 1.0, 0.199010183102628, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14573293022519854, 0.14573293022519854, 0.28416051404012466], 
reward next is 0.7158, 
noisyNet noise sample is [array([-1.262571], dtype=float32), -0.24467236]. 
=============================================
[2019-03-22 23:28:11,267] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 6.0269877e-34], sum to 1.0000
[2019-03-22 23:28:11,276] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9440
[2019-03-22 23:28:11,284] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.16666666666667, 89.0, 1.0, 2.0, 0.3154883412537207, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 342819.1929298263, 342819.1929298266, 112325.1447113402], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6757800.0000, 
sim time next is 6758400.0000, 
raw observation next is [17.13333333333333, 88.0, 1.0, 2.0, 0.2986826663400237, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 324324.7793338061, 324324.7793338058, 111103.646914126], 
processed observation next is [1.0, 0.21739130434782608, 0.415151515151515, 0.88, 1.0, 1.0, 0.12335333292502963, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1201202886421504, 0.12012028864215028, 0.2709845046686], 
reward next is 0.7290, 
noisyNet noise sample is [array([1.711168], dtype=float32), -0.926958]. 
=============================================
[2019-03-22 23:28:25,427] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.0207098e-37 1.0000000e+00 1.9778193e-31 1.0457059e-24 7.3091474e-18], sum to 1.0000
[2019-03-22 23:28:25,436] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2911
[2019-03-22 23:28:25,442] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 97.0, 1.0, 2.0, 0.4942499567241984, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 557922.7358343714, 557922.7358343714, 134424.8859271218], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7028400.0000, 
sim time next is 7029000.0000, 
raw observation next is [18.8, 97.0, 1.0, 2.0, 0.5903960097014547, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 666808.4837820142, 666808.4837820145, 145155.3578883803], 
processed observation next is [1.0, 0.34782608695652173, 0.49090909090909096, 0.97, 1.0, 1.0, 0.4879950121268183, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.24696610510444972, 0.2469661051044498, 0.3540374582643422], 
reward next is 0.6460, 
noisyNet noise sample is [array([1.1517872], dtype=float32), -0.9624026]. 
=============================================
[2019-03-22 23:28:25,453] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[67.19502 ]
 [67.83306 ]
 [67.81608 ]
 [67.78287 ]
 [67.700066]], R is [[66.30902863]
 [66.31807709]
 [66.35016632]
 [66.382164  ]
 [66.41374207]].
[2019-03-22 23:28:34,413] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.8694220e-34 1.0000000e+00 1.6781967e-29 2.6120256e-28 7.7484139e-17], sum to 1.0000
[2019-03-22 23:28:34,425] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9811
[2019-03-22 23:28:34,431] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.3, 44.66666666666666, 1.0, 2.0, 0.7769412797872727, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 853558.8635240407, 853558.8635240407, 159207.7011483223], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7228200.0000, 
sim time next is 7228800.0000, 
raw observation next is [24.4, 45.0, 1.0, 2.0, 0.8100081966237735, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 892182.0018925531, 892182.0018925531, 164231.8794847278], 
processed observation next is [1.0, 0.6956521739130435, 0.7454545454545454, 0.45, 1.0, 1.0, 0.7625102457797169, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.33043777847872335, 0.33043777847872335, 0.40056555971884833], 
reward next is 0.5994, 
noisyNet noise sample is [array([-0.33188054], dtype=float32), -0.20102644]. 
=============================================
[2019-03-22 23:28:34,583] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 2.6028534e-29], sum to 1.0000
[2019-03-22 23:28:34,594] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7076
[2019-03-22 23:28:34,600] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.9, 98.0, 1.0, 2.0, 0.3303368309730801, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 363572.8956297837, 363572.8956297837, 115002.1656544499], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7453800.0000, 
sim time next is 7454400.0000, 
raw observation next is [17.0, 97.33333333333334, 1.0, 2.0, 0.3311451201359346, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 364653.6879245663, 364653.6879245663, 115133.9148289881], 
processed observation next is [0.0, 0.2608695652173913, 0.4090909090909091, 0.9733333333333334, 1.0, 1.0, 0.16393140016991825, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13505692145354306, 0.13505692145354306, 0.2808144264121661], 
reward next is 0.7192, 
noisyNet noise sample is [array([0.81915486], dtype=float32), -1.2101871]. 
=============================================
[2019-03-22 23:28:36,984] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.2681205e-33 1.0000000e+00 9.1510109e-28 1.4918877e-25 2.3317015e-10], sum to 1.0000
[2019-03-22 23:28:36,994] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0713
[2019-03-22 23:28:36,999] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.9, 43.33333333333334, 1.0, 2.0, 0.7850076798930545, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 853624.2656079446, 853624.2656079449, 157368.6043812418], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7225800.0000, 
sim time next is 7226400.0000, 
raw observation next is [24.0, 43.66666666666667, 1.0, 2.0, 0.7900278830005295, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 861457.7595928891, 861457.7595928891, 158733.883059541], 
processed observation next is [1.0, 0.6521739130434783, 0.7272727272727273, 0.4366666666666667, 1.0, 1.0, 0.7375348537506617, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3190584294788478, 0.3190584294788478, 0.3871558123403439], 
reward next is 0.6128, 
noisyNet noise sample is [array([0.45612326], dtype=float32), 0.99886674]. 
=============================================
[2019-03-22 23:28:37,676] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.5658656e-26], sum to 1.0000
[2019-03-22 23:28:37,684] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8745
[2019-03-22 23:28:37,689] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.16666666666667, 52.0, 1.0, 2.0, 0.3059426331513106, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 332210.7119884035, 332210.7119884032, 111322.8554638674], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7238400.0000, 
sim time next is 7239000.0000, 
raw observation next is [21.88333333333334, 53.5, 1.0, 2.0, 0.3037000757149186, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 329774.7840462131, 329774.7840462134, 110816.393410165], 
processed observation next is [1.0, 0.782608695652174, 0.6310606060606063, 0.535, 1.0, 1.0, 0.12962509464364821, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12213880890600484, 0.12213880890600495, 0.2702838863662561], 
reward next is 0.7297, 
noisyNet noise sample is [array([-0.5686148], dtype=float32), 1.144826]. 
=============================================
[2019-03-22 23:28:37,722] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[70.51633]
 [70.67769]
 [70.87432]
 [71.13874]
 [71.49824]], R is [[70.39080811]
 [70.41537476]
 [70.43786621]
 [70.45904541]
 [70.47947693]].
[2019-03-22 23:28:39,755] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 8.853756e-33 6.306722e-33 8.649211e-20], sum to 1.0000
[2019-03-22 23:28:39,765] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2140
[2019-03-22 23:28:39,769] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.18333333333333, 62.66666666666666, 1.0, 2.0, 0.430988492086108, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 468058.2990259976, 468058.2990259976, 108003.523079349], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7290600.0000, 
sim time next is 7291200.0000, 
raw observation next is [19.56666666666667, 62.33333333333334, 1.0, 2.0, 0.4590376567941428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 498535.623159236, 498535.623159236, 114012.7726571581], 
processed observation next is [1.0, 0.391304347826087, 0.5257575757575759, 0.6233333333333334, 1.0, 1.0, 0.3237970709926785, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1846428233923096, 0.1846428233923096, 0.2780799333101417], 
reward next is 0.7219, 
noisyNet noise sample is [array([0.35531402], dtype=float32), 1.4418627]. 
=============================================
[2019-03-22 23:28:43,974] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.2877606e-34], sum to 1.0000
[2019-03-22 23:28:43,982] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0086
[2019-03-22 23:28:43,987] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.13333333333333, 91.0, 1.0, 2.0, 0.5039877562917138, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 574946.8118413716, 574946.8118413716, 142206.6411741319], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7582800.0000, 
sim time next is 7583400.0000, 
raw observation next is [21.85, 91.0, 1.0, 2.0, 0.4950602386115943, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 564907.62761187, 564907.62761187, 140573.3972594918], 
processed observation next is [0.0, 0.782608695652174, 0.6295454545454546, 0.91, 1.0, 1.0, 0.36882529826449284, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20922504726365554, 0.20922504726365554, 0.3428619445353458], 
reward next is 0.6571, 
noisyNet noise sample is [array([-0.85954857], dtype=float32), 0.089347795]. 
=============================================
[2019-03-22 23:28:47,544] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.8438836e-36 1.5944394e-30], sum to 1.0000
[2019-03-22 23:28:47,556] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7234
[2019-03-22 23:28:47,564] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.35, 92.0, 1.0, 2.0, 0.4733233603294595, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 539971.8632725861, 539971.8632725865, 137171.4383427846], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7684200.0000, 
sim time next is 7684800.0000, 
raw observation next is [21.26666666666667, 92.33333333333334, 1.0, 2.0, 0.4694875148423834, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 535559.9652041629, 535559.9652041629, 136657.9127043033], 
processed observation next is [1.0, 0.9565217391304348, 0.6030303030303031, 0.9233333333333335, 1.0, 1.0, 0.33685939355297917, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19835554266820848, 0.19835554266820848, 0.3333119822056178], 
reward next is 0.6667, 
noisyNet noise sample is [array([-0.17246574], dtype=float32), 1.4574003]. 
=============================================
[2019-03-22 23:28:48,536] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 3.6011073e-32], sum to 1.0000
[2019-03-22 23:28:48,545] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3548
[2019-03-22 23:28:48,550] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.86666666666667, 98.5, 1.0, 2.0, 0.3337298015087308, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 367534.4966217313, 367534.4966217316, 115338.0015511576], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7447800.0000, 
sim time next is 7448400.0000, 
raw observation next is [16.8, 99.0, 1.0, 2.0, 0.3330412526856016, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 366682.7148065521, 366682.7148065524, 115251.6484719345], 
processed observation next is [0.0, 0.21739130434782608, 0.4, 0.99, 1.0, 1.0, 0.16630156585700195, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1358084128913156, 0.1358084128913157, 0.2811015816388646], 
reward next is 0.7189, 
noisyNet noise sample is [array([0.7031873], dtype=float32), -1.1159415]. 
=============================================
[2019-03-22 23:28:52,196] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-22 23:28:52,198] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-22 23:28:52,199] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-22 23:28:52,200] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:28:52,201] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:28:52,202] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-22 23:28:52,203] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-22 23:28:52,204] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-22 23:28:52,207] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:28:52,208] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:28:52,208] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:28:52,228] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run26
[2019-03-22 23:28:52,249] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run26
[2019-03-22 23:28:52,251] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run26
[2019-03-22 23:28:52,272] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run26
[2019-03-22 23:28:52,312] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run26
[2019-03-22 23:29:00,002] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.27074707], dtype=float32), 0.0064885165]
[2019-03-22 23:29:00,003] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [14.0, 94.0, 1.0, 2.0, 0.211704010206047, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 229856.6272607542, 229856.6272607542, 76358.68356001898]
[2019-03-22 23:29:00,004] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:29:00,007] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 2.4302766e-36], sampled 0.10180964369223544
[2019-03-22 23:29:03,215] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.27074707], dtype=float32), 0.0064885165]
[2019-03-22 23:29:03,216] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.11666666666667, 43.16666666666667, 1.0, 2.0, 0.306047337883558, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 332302.7904673467, 332302.7904673467, 96199.54303467838]
[2019-03-22 23:29:03,217] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:29:03,220] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.6080180641763611
[2019-03-22 23:29:11,137] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.27074707], dtype=float32), 0.0064885165]
[2019-03-22 23:29:11,138] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [27.90975707333333, 74.86441198666668, 1.0, 2.0, 0.8412109530752008, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 945381.1442428398, 945381.1442428398, 201387.0163105768]
[2019-03-22 23:29:11,140] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:29:11,144] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.9250177e-37 6.6109178e-28], sampled 0.9505538372718131
[2019-03-22 23:29:17,496] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.27074707], dtype=float32), 0.0064885165]
[2019-03-22 23:29:17,498] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.0, 90.0, 1.0, 2.0, 0.3776623395012781, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 423297.5514513781, 423297.5514513781, 126046.1637093766]
[2019-03-22 23:29:17,501] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:29:17,504] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 8.317707e-35], sampled 0.01580545182993165
[2019-03-22 23:29:39,424] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.27074707], dtype=float32), 0.0064885165]
[2019-03-22 23:29:39,426] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.9, 89.0, 1.0, 2.0, 0.3546017523447813, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 396228.9036424035, 396228.9036424035, 123549.1711935959]
[2019-03-22 23:29:39,427] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:29:39,428] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 3.1821114e-34], sampled 0.8614185781053422
[2019-03-22 23:29:54,869] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.27074707], dtype=float32), 0.0064885165]
[2019-03-22 23:29:54,871] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.83333333333334, 57.33333333333334, 1.0, 2.0, 0.2751662792696297, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 298781.65004457, 298781.65004457, 90449.28975431381]
[2019-03-22 23:29:54,872] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:29:54,875] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.4430828196814679
[2019-03-22 23:30:00,129] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.27074707], dtype=float32), 0.0064885165]
[2019-03-22 23:30:00,132] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [13.89759198, 96.249075085, 1.0, 2.0, 0.2231572062110335, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 242283.4684042317, 242283.4684042317, 82546.02197115264]
[2019-03-22 23:30:00,135] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:30:00,139] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.16770886223945847
[2019-03-22 23:30:01,521] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.27074707], dtype=float32), 0.0064885165]
[2019-03-22 23:30:01,523] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [23.33520372, 86.97900564, 1.0, 2.0, 0.4994592100889692, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 568925.7808313243, 568925.7808313239, 147055.6781146864]
[2019-03-22 23:30:01,525] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:30:01,528] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 5.0162573e-34], sampled 0.9075166560199978
[2019-03-22 23:30:02,343] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.27074707], dtype=float32), 0.0064885165]
[2019-03-22 23:30:02,345] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.0, 83.0, 1.0, 2.0, 0.4371479130335169, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 498049.0336379699, 498049.0336379702, 132181.8080656275]
[2019-03-22 23:30:02,345] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:30:02,348] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.3100244e-31], sampled 0.5321917137662987
[2019-03-22 23:30:18,019] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.27074707], dtype=float32), 0.0064885165]
[2019-03-22 23:30:18,021] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [25.11425369333334, 72.82597500666668, 1.0, 2.0, 0.5147775193464567, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 586705.0258119879, 586705.0258119876, 148554.7449898474]
[2019-03-22 23:30:18,024] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:30:18,028] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 2.1359073e-31], sampled 0.8570323967184053
[2019-03-22 23:30:40,325] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1147 1656209757.7786 80.0000
[2019-03-22 23:30:40,390] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9310 1705987275.5940 465.0000
[2019-03-22 23:30:40,434] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5598 1663796639.0689 105.0000
[2019-03-22 23:30:40,444] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3485 1683325900.1134 214.0000
[2019-03-22 23:30:40,462] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2494 1773207034.4548 173.0000
[2019-03-22 23:30:41,477] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 625000, evaluation results [625000.0, 8512.249429056992, 1773207034.4547563, 173.0, 9061.114669779829, 1656209757.7786272, 80.0, 8856.559759326878, 1663796639.0688558, 105.0, 8596.931041181726, 1705987275.594041, 465.0, 8574.348472942609, 1683325900.1133502, 214.0]
[2019-03-22 23:30:44,186] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.1154564e-37 1.0000000e+00 2.2943431e-33 1.0697819e-31 1.1686657e-19], sum to 1.0000
[2019-03-22 23:30:44,196] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3137
[2019-03-22 23:30:44,202] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.88333333333334, 52.16666666666667, 1.0, 2.0, 0.5324168176856131, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 578276.1088357155, 578276.1088357155, 129111.6087984236], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7816200.0000, 
sim time next is 7816800.0000, 
raw observation next is [22.16666666666667, 51.33333333333334, 1.0, 2.0, 0.5307422687356788, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 576456.2454268778, 576456.2454268778, 129684.2508464807], 
processed observation next is [1.0, 0.4782608695652174, 0.6439393939393941, 0.5133333333333334, 1.0, 1.0, 0.4134278359195984, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21350231312106582, 0.21350231312106582, 0.3163030508450749], 
reward next is 0.6837, 
noisyNet noise sample is [array([-0.5628992], dtype=float32), 0.06921377]. 
=============================================
[2019-03-22 23:30:52,383] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:30:52,385] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:30:52,428] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run4
[2019-03-22 23:30:54,122] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:30:54,123] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:30:54,160] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run4
[2019-03-22 23:31:04,397] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:31:04,398] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:31:04,434] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run4
[2019-03-22 23:31:04,503] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:31:04,505] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:31:04,531] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run4
[2019-03-22 23:31:05,533] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:31:05,534] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:31:05,547] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run4
[2019-03-22 23:31:05,885] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:31:05,885] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:31:05,898] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run4
[2019-03-22 23:31:05,912] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:31:05,915] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:31:05,940] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run4
[2019-03-22 23:31:05,961] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:31:05,962] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:31:05,975] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run4
[2019-03-22 23:31:05,994] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:31:05,995] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:31:06,017] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run4
[2019-03-22 23:31:06,043] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:31:06,045] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:31:06,055] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run4
[2019-03-22 23:31:06,111] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:31:06,112] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:31:06,119] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run4
[2019-03-22 23:31:06,140] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:31:06,140] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:31:06,144] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run4
[2019-03-22 23:31:06,188] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:31:06,188] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:31:06,190] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run4
[2019-03-22 23:31:06,225] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:31:06,226] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:31:06,228] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run4
[2019-03-22 23:31:06,254] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:31:06,254] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:31:06,267] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run4
[2019-03-22 23:31:06,315] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:31:06,320] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:31:06,323] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run4
[2019-03-22 23:31:07,492] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.0489032e-37 4.7312253e-37 0.0000000e+00], sum to 1.0000
[2019-03-22 23:31:07,492] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6833
[2019-03-22 23:31:07,499] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.8, 90.33333333333334, 1.0, 2.0, 0.3283026773660909, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 361444.063750102, 361444.063750102, 114894.7602144249], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6000.0000, 
sim time next is 6600.0000, 
raw observation next is [17.75, 92.16666666666667, 1.0, 2.0, 0.3328626004379693, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 367466.3072438791, 367466.3072438791, 115614.3906471943], 
processed observation next is [1.0, 0.043478260869565216, 0.4431818181818182, 0.9216666666666667, 1.0, 1.0, 0.1660782505474616, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13609863231254782, 0.13609863231254782, 0.28198631865169344], 
reward next is 0.7180, 
noisyNet noise sample is [array([-1.3493569], dtype=float32), -0.9945143]. 
=============================================
[2019-03-22 23:31:07,954] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.1504227e-35 1.2864293e-35], sum to 1.0000
[2019-03-22 23:31:07,957] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5654
[2019-03-22 23:31:07,961] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.3, 87.5, 1.0, 2.0, 0.8086087739816027, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 917089.1860781237, 917089.1860781237, 176008.7295427828], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 34200.0000, 
sim time next is 34800.0000, 
raw observation next is [20.53333333333333, 86.0, 1.0, 2.0, 0.7514199133160946, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 852386.5117498012, 852386.5117498016, 167848.6027280441], 
processed observation next is [1.0, 0.391304347826087, 0.5696969696969696, 0.86, 1.0, 1.0, 0.6892748916451182, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.31569870805548195, 0.31569870805548206, 0.40938683592205877], 
reward next is 0.5906, 
noisyNet noise sample is [array([0.6108868], dtype=float32), -0.4590372]. 
=============================================
[2019-03-22 23:31:08,922] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.2043335e-34 7.4226109e-32], sum to 1.0000
[2019-03-22 23:31:08,934] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1645
[2019-03-22 23:31:08,937] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.5, 62.66666666666667, 1.0, 2.0, 0.5027630886267299, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 546050.0884987417, 546050.0884987417, 111444.9751243851], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 119400.0000, 
sim time next is 120000.0000, 
raw observation next is [19.0, 61.33333333333334, 1.0, 2.0, 0.4991750342260038, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 542150.9358102024, 542150.9358102027, 113064.0230000756], 
processed observation next is [1.0, 0.391304347826087, 0.5, 0.6133333333333334, 1.0, 1.0, 0.3739687927825047, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20079664289266755, 0.2007966428926677, 0.27576590975628196], 
reward next is 0.7242, 
noisyNet noise sample is [array([-0.37217474], dtype=float32), 1.8374001]. 
=============================================
[2019-03-22 23:31:08,945] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[62.988655]
 [63.27871 ]
 [63.45305 ]
 [63.792828]
 [64.32411 ]], R is [[63.05899429]
 [63.15658951]
 [63.26564789]
 [63.37678146]
 [63.49259567]].
[2019-03-22 23:31:18,809] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 6.6882737e-31 3.2759644e-09 4.9088385e-12], sum to 1.0000
[2019-03-22 23:31:18,818] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5431
[2019-03-22 23:31:18,823] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 83.0, 1.0, 2.0, 0.3046101367155888, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 331520.6916012447, 331520.6916012444, 111767.4649504162], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 602400.0000, 
sim time next is 603000.0000, 
raw observation next is [18.0, 83.0, 1.0, 2.0, 0.3046434892528854, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 331555.6471144638, 331555.6471144636, 111769.2550915364], 
processed observation next is [1.0, 1.0, 0.45454545454545453, 0.83, 1.0, 1.0, 0.13080436156610675, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12279838782017177, 0.1227983878201717, 0.27260793924764976], 
reward next is 0.7274, 
noisyNet noise sample is [array([-1.6495551], dtype=float32), -0.8247843]. 
=============================================
[2019-03-22 23:31:18,839] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[68.68874]
 [68.67575]
 [68.67039]
 [68.6386 ]
 [68.63231]], R is [[68.74008179]
 [68.78007507]
 [68.81957245]
 [68.85852051]
 [68.89688873]].
[2019-03-22 23:31:19,666] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.0125983e-23 7.8742670e-27], sum to 1.0000
[2019-03-22 23:31:19,675] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0295
[2019-03-22 23:31:19,684] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.33333333333334, 69.0, 1.0, 2.0, 0.2815254242352801, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 305688.7208169056, 305688.7208169053, 106909.0406400628], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 234600.0000, 
sim time next is 235200.0000, 
raw observation next is [18.66666666666667, 74.0, 1.0, 2.0, 0.283334489679721, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 307653.6794868903, 307653.6794868903, 107466.9080343884], 
processed observation next is [0.0, 0.7391304347826086, 0.4848484848484851, 0.74, 1.0, 1.0, 0.10416811209965127, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11394580721736679, 0.11394580721736679, 0.2621144098399717], 
reward next is 0.7379, 
noisyNet noise sample is [array([1.3317473], dtype=float32), -0.22505435]. 
=============================================
[2019-03-22 23:31:23,092] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 3.7722957e-35 3.6764508e-24 7.5993054e-23], sum to 1.0000
[2019-03-22 23:31:23,100] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8977
[2019-03-22 23:31:23,106] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.66666666666666, 55.00000000000001, 1.0, 2.0, 0.3546590966063494, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 395468.6744896457, 395468.6744896454, 118867.8198843345], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 678000.0000, 
sim time next is 678600.0000, 
raw observation next is [23.5, 55.5, 1.0, 2.0, 0.3521409941842671, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 392303.5166022091, 392303.5166022094, 118511.1596716252], 
processed observation next is [1.0, 0.8695652173913043, 0.7045454545454546, 0.555, 1.0, 1.0, 0.19017624273033384, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14529759874155893, 0.14529759874155904, 0.2890516089551834], 
reward next is 0.7109, 
noisyNet noise sample is [array([0.44998315], dtype=float32), -1.3427101]. 
=============================================
[2019-03-22 23:31:33,617] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-22 23:31:33,622] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-22 23:31:33,622] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:31:33,624] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-22 23:31:33,625] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-22 23:31:33,628] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:31:33,627] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-22 23:31:33,630] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:31:33,630] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-22 23:31:33,631] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:31:33,634] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:31:33,655] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run27
[2019-03-22 23:31:33,676] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run27
[2019-03-22 23:31:33,696] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run27
[2019-03-22 23:31:33,697] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run27
[2019-03-22 23:31:33,698] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run27
[2019-03-22 23:32:03,767] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08709571], dtype=float32), -0.08548309]
[2019-03-22 23:32:03,768] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [15.63333333333333, 52.66666666666667, 1.0, 2.0, 0.2182135406592891, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 236915.035505458, 236915.0355054584, 75014.39733530415]
[2019-03-22 23:32:03,771] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:32:03,772] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 8.6522344e-38 6.4519976e-33], sampled 0.08085287647934603
[2019-03-22 23:32:04,658] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08709571], dtype=float32), -0.08548309]
[2019-03-22 23:32:04,659] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.0, 83.0, 1.0, 2.0, 0.3831842627687571, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 430324.9633657968, 430324.963365797, 122595.8501004071]
[2019-03-22 23:32:04,659] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:32:04,665] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 2.439317e-26 2.842937e-23], sampled 0.8988968416886598
[2019-03-22 23:32:22,069] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08709571], dtype=float32), -0.08548309]
[2019-03-22 23:32:22,071] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.86666666666667, 78.66666666666667, 1.0, 2.0, 0.573349278581334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 653889.7379266912, 653889.7379266908, 155293.2880825112]
[2019-03-22 23:32:22,072] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:32:22,076] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 3.8829745e-38 7.6050840e-21 4.3421221e-18], sampled 0.2186688830708633
[2019-03-22 23:32:58,014] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08709571], dtype=float32), -0.08548309]
[2019-03-22 23:32:58,015] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.44284466333334, 67.83603668, 1.0, 2.0, 0.4113657805875268, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 458967.1898591414, 458967.1898591414, 128058.0392396772]
[2019-03-22 23:32:58,017] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:32:58,021] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.0332061e-28 3.4428912e-25], sampled 0.28357655307675245
[2019-03-22 23:33:04,213] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08709571], dtype=float32), -0.08548309]
[2019-03-22 23:33:04,214] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.76542517, 49.10774322666667, 1.0, 2.0, 0.5589049043390242, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 623818.4337284906, 623818.4337284906, 142461.4685499019]
[2019-03-22 23:33:04,217] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:33:04,219] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.8491538e-25 1.7015574e-22], sampled 0.6881563059595315
[2019-03-22 23:33:21,436] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5598 1663796639.0689 105.0000
[2019-03-22 23:33:21,873] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2492 1773187030.7201 173.0000
[2019-03-22 23:33:21,874] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9309 1705967916.6745 465.0000
[2019-03-22 23:33:22,130] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.6166 1683282454.6264 214.0000
[2019-03-22 23:33:22,150] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1147 1656209757.7786 80.0000
[2019-03-22 23:33:23,166] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 650000, evaluation results [650000.0, 8512.249193409023, 1773187030.7201214, 173.0, 9061.114669779829, 1656209757.7786272, 80.0, 8856.559759326878, 1663796639.0688558, 105.0, 8596.930884973775, 1705967916.6744611, 465.0, 8574.616569649173, 1683282454.6264086, 214.0]
[2019-03-22 23:33:25,369] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 7.8428443e-21 1.3150647e-26], sum to 1.0000
[2019-03-22 23:33:25,377] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6267
[2019-03-22 23:33:25,383] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.5, 91.0, 1.0, 2.0, 0.269937531616472, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 293102.4489958705, 293102.4489958703, 89944.50596835648], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 498600.0000, 
sim time next is 499200.0000, 
raw observation next is [15.33333333333333, 92.0, 1.0, 2.0, 0.2651514992907338, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 287904.1610614254, 287904.1610614251, 88883.56395309416], 
processed observation next is [1.0, 0.782608695652174, 0.3333333333333332, 0.92, 1.0, 1.0, 0.08143937411341721, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10663117076349089, 0.10663117076349078, 0.2167891803734004], 
reward next is 0.7832, 
noisyNet noise sample is [array([0.08656623], dtype=float32), 0.16766933]. 
=============================================
[2019-03-22 23:33:31,462] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.3626224e-28 1.2052254e-26], sum to 1.0000
[2019-03-22 23:33:31,469] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4650
[2019-03-22 23:33:31,473] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.66666666666667, 82.66666666666667, 1.0, 2.0, 0.2978207712674755, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 323388.5787942487, 323388.578794249, 111045.2712561978], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 606000.0000, 
sim time next is 606600.0000, 
raw observation next is [17.5, 82.5, 1.0, 2.0, 0.2921716766551349, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 317252.5105693174, 317252.5105693171, 106335.309973859], 
processed observation next is [1.0, 0.0, 0.4318181818181818, 0.825, 1.0, 1.0, 0.11521459581891859, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11750092984048792, 0.11750092984048781, 0.25935441457038777], 
reward next is 0.7406, 
noisyNet noise sample is [array([0.9372154], dtype=float32), -0.7145384]. 
=============================================
[2019-03-22 23:33:34,497] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.6579457e-37 8.8175747e-29], sum to 1.0000
[2019-03-22 23:33:34,507] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7295
[2019-03-22 23:33:34,515] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.33333333333333, 49.33333333333333, 1.0, 2.0, 0.3570670266541407, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 400628.2014294617, 400628.2014294617, 120200.3128425167], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 668400.0000, 
sim time next is 669000.0000, 
raw observation next is [25.16666666666667, 49.66666666666667, 1.0, 2.0, 0.3557345737944984, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 398734.2405109353, 398734.240510935, 119896.6321566705], 
processed observation next is [1.0, 0.7391304347826086, 0.7803030303030305, 0.4966666666666667, 1.0, 1.0, 0.194668217243123, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14767934833738344, 0.14767934833738333, 0.29243081013822075], 
reward next is 0.7076, 
noisyNet noise sample is [array([-0.4822428], dtype=float32), -0.32575873]. 
=============================================
[2019-03-22 23:33:34,526] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[49.433105]
 [48.214165]
 [46.445724]
 [44.115738]
 [41.136864]], R is [[51.03647232]
 [51.23293686]
 [51.42704391]
 [51.61453629]
 [51.75892258]].
[2019-03-22 23:33:35,664] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.6720412e-36 7.1504716e-30], sum to 1.0000
[2019-03-22 23:33:35,671] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6911
[2019-03-22 23:33:35,676] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.83333333333334, 73.83333333333334, 1.0, 2.0, 0.4262215540744966, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 484693.9777531825, 484693.9777531822, 130124.8197263539], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 778200.0000, 
sim time next is 778800.0000, 
raw observation next is [22.66666666666667, 74.66666666666667, 1.0, 2.0, 0.4245079565911599, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 482638.7408401244, 482638.7408401244, 129861.5666511574], 
processed observation next is [0.0, 0.0, 0.6666666666666669, 0.7466666666666667, 1.0, 1.0, 0.28063494573894987, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17875508920004607, 0.17875508920004607, 0.31673552841745706], 
reward next is 0.6833, 
noisyNet noise sample is [array([1.1390101], dtype=float32), 1.6961164]. 
=============================================
[2019-03-22 23:33:46,307] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.5824077e-35 9.3576275e-28 5.6005427e-20], sum to 1.0000
[2019-03-22 23:33:46,310] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0108
[2019-03-22 23:33:46,314] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 94.0, 1.0, 2.0, 0.3973816380588974, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 447967.610409422, 447967.610409422, 124703.2344385727], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 867600.0000, 
sim time next is 868200.0000, 
raw observation next is [19.16666666666667, 93.00000000000001, 1.0, 2.0, 0.3964403217125555, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 446931.3163672245, 446931.3163672248, 124632.4948233106], 
processed observation next is [0.0, 0.043478260869565216, 0.5075757575757578, 0.9300000000000002, 1.0, 1.0, 0.24555040214069435, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1655301171730461, 0.16553011717304622, 0.30398169469100145], 
reward next is 0.6960, 
noisyNet noise sample is [array([-0.5834305], dtype=float32), -0.76870614]. 
=============================================
[2019-03-22 23:33:51,728] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.7588847e-34 3.7850419e-33 1.3054693e-24], sum to 1.0000
[2019-03-22 23:33:51,738] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9304
[2019-03-22 23:33:51,742] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.4037840598119037, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 457721.0301406559, 457721.0301406559, 126807.5164927755], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 964200.0000, 
sim time next is 964800.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4035722058976944, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 457478.0937093977, 457478.0937093977, 126785.8008715732], 
processed observation next is [1.0, 0.17391304347826086, 0.5, 1.0, 1.0, 1.0, 0.25446525737211795, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16943633100348063, 0.16943633100348063, 0.3092336606623737], 
reward next is 0.6908, 
noisyNet noise sample is [array([0.27004522], dtype=float32), -0.18212387]. 
=============================================
[2019-03-22 23:34:00,319] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 2.4406658e-34], sum to 1.0000
[2019-03-22 23:34:00,328] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3191
[2019-03-22 23:34:00,335] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 88.0, 1.0, 2.0, 0.3187681011604869, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 350472.040807142, 350472.040807142, 114019.5130803875], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1130400.0000, 
sim time next is 1131000.0000, 
raw observation next is [18.0, 88.00000000000001, 1.0, 2.0, 0.3542486664005419, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 389891.347963838, 389891.3479638383, 116795.3823514859], 
processed observation next is [1.0, 0.08695652173913043, 0.45454545454545453, 0.8800000000000001, 1.0, 1.0, 0.1928108330006774, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14440420294956963, 0.14440420294956974, 0.2848667862231363], 
reward next is 0.7151, 
noisyNet noise sample is [array([-0.46838135], dtype=float32), 0.6078167]. 
=============================================
[2019-03-22 23:34:00,351] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[73.2319  ]
 [73.103035]
 [72.98305 ]
 [72.82858 ]
 [72.64688 ]], R is [[73.39073181]
 [73.37872314]
 [73.36847687]
 [73.3600235 ]
 [73.35338593]].
[2019-03-22 23:34:05,899] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 1.142498e-37], sum to 1.0000
[2019-03-22 23:34:05,909] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6046
[2019-03-22 23:34:05,916] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.16666666666667, 100.0, 1.0, 2.0, 0.3866448887817771, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 434711.5299646939, 434711.5299646936, 123144.2789557678], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1314600.0000, 
sim time next is 1315200.0000, 
raw observation next is [18.33333333333334, 100.0, 1.0, 2.0, 0.3953364935859477, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 445281.1869832939, 445281.1869832939, 124317.3155118235], 
processed observation next is [1.0, 0.21739130434782608, 0.46969696969696995, 1.0, 1.0, 1.0, 0.24417061698243459, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1649189581419607, 0.1649189581419607, 0.30321296466298414], 
reward next is 0.6968, 
noisyNet noise sample is [array([1.0306605], dtype=float32), 0.53346694]. 
=============================================
[2019-03-22 23:34:06,969] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.2958223e-26 1.0000000e+00 3.4478497e-23 4.1687752e-18 4.0028736e-15], sum to 1.0000
[2019-03-22 23:34:06,974] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7223
[2019-03-22 23:34:06,983] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1191628.202394985 W.
[2019-03-22 23:34:06,987] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.0, 86.0, 1.0, 2.0, 0.3503887393998046, 1.0, 2.0, 0.3503887393998046, 1.0, 2.0, 0.7095985293928871, 6.911199999999999, 6.9112, 77.3421103, 1191628.202394985, 1191628.202394986, 280911.7379036336], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1243800.0000, 
sim time next is 1244400.0000, 
raw observation next is [23.33333333333334, 83.33333333333334, 1.0, 2.0, 0.5238070629033219, 1.0, 2.0, 0.5238070629033219, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846343378287, 1188995.746635513, 1188995.746635514, 238279.2603088442], 
processed observation next is [1.0, 0.391304347826087, 0.6969696969696972, 0.8333333333333335, 1.0, 1.0, 0.40475882862915236, 1.0, 1.0, 0.40475882862915236, 0.0, 0.5, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288128564949, 0.44036879505018994, 0.4403687950501904, 0.5811689275825469], 
reward next is 0.4188, 
noisyNet noise sample is [array([-0.743799], dtype=float32), 0.9795744]. 
=============================================
[2019-03-22 23:34:12,145] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 7.392062e-33], sum to 1.0000
[2019-03-22 23:34:12,154] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6920
[2019-03-22 23:34:12,163] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1783547.171408305 W.
[2019-03-22 23:34:12,167] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.66666666666666, 70.0, 1.0, 2.0, 0.5694504358665337, 1.0, 2.0, 0.528513654874874, 1.0, 2.0, 0.9865530188920543, 6.911199999999998, 6.9112, 77.3421103, 1783547.171408305, 1783547.171408305, 368562.3445443334], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1345200.0000, 
sim time next is 1345800.0000, 
raw observation next is [27.83333333333334, 70.0, 1.0, 2.0, 0.5630740118040224, 1.0, 2.0, 0.5253254428436186, 1.0, 2.0, 0.9865530188920543, 6.911199999999999, 6.9112, 77.3421103, 1772771.230131658, 1772771.230131658, 367341.1157696248], 
processed observation next is [1.0, 0.5652173913043478, 0.9015151515151518, 0.7, 1.0, 1.0, 0.45384251475502796, 1.0, 1.0, 0.4066568035545232, 1.0, 1.0, 0.9807900269886491, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.6565819370857993, 0.6565819370857993, 0.8959539409015239], 
reward next is 0.1040, 
noisyNet noise sample is [array([0.5100438], dtype=float32), 0.8108742]. 
=============================================
[2019-03-22 23:34:16,081] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-22 23:34:16,084] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-22 23:34:16,085] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:34:16,086] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-22 23:34:16,087] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-22 23:34:16,088] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:34:16,091] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-22 23:34:16,090] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-22 23:34:16,092] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:34:16,094] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:34:16,095] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:34:16,109] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run28
[2019-03-22 23:34:16,109] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run28
[2019-03-22 23:34:16,151] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run28
[2019-03-22 23:34:16,151] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run28
[2019-03-22 23:34:16,152] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run28
[2019-03-22 23:34:22,659] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.20122123], dtype=float32), -0.07595031]
[2019-03-22 23:34:22,662] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [16.0, 72.0, 1.0, 2.0, 0.2134411880630266, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 231743.2092218061, 231743.2092218059, 75062.76469372556]
[2019-03-22 23:34:22,663] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:34:22,666] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.5167349962613954
[2019-03-22 23:34:29,215] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.20122123], dtype=float32), -0.07595031]
[2019-03-22 23:34:29,219] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.0, 94.0, 1.0, 2.0, 0.3968974137275388, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 447268.2773017752, 447268.2773017752, 124577.6318029966]
[2019-03-22 23:34:29,220] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:34:29,222] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.20459772665039844
[2019-03-22 23:34:34,677] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.20122123], dtype=float32), -0.07595031]
[2019-03-22 23:34:34,678] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.5, 82.0, 1.0, 2.0, 0.5019691124791721, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 572501.520894948, 572501.520894948, 146444.7409781678]
[2019-03-22 23:34:34,680] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:34:34,683] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 7.5158722e-38 3.7483082e-37], sampled 0.10656797145426011
[2019-03-22 23:34:35,268] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.20122123], dtype=float32), -0.07595031]
[2019-03-22 23:34:35,268] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.5, 89.0, 1.0, 2.0, 0.5848958770694448, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9787608881909172, 6.911199999999999, 6.9112, 77.32845937619504, 1211695.322870021, 1211695.322870021, 276774.4417203172]
[2019-03-22 23:34:35,270] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:34:35,271] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.22169752e-37 1.00000000e+00 1.01167856e-32 3.04791633e-26
 1.71946039e-24], sampled 0.5591820742687532
[2019-03-22 23:34:35,274] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1211695.322870021 W.
[2019-03-22 23:34:36,896] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.20122123], dtype=float32), -0.07595031]
[2019-03-22 23:34:36,897] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [29.3, 52.0, 1.0, 2.0, 0.5176857691134724, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 589621.8160833674, 589621.8160833671, 149302.2540806688]
[2019-03-22 23:34:36,899] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:34:36,901] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.1583469917487066
[2019-03-22 23:34:52,162] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.20122123], dtype=float32), -0.07595031]
[2019-03-22 23:34:52,163] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.8, 79.0, 1.0, 2.0, 0.4633905680756907, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 528299.7898496737, 528299.7898496734, 139790.199622259]
[2019-03-22 23:34:52,164] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:34:52,166] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.30212808768036103
[2019-03-22 23:35:20,913] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.20122123], dtype=float32), -0.07595031]
[2019-03-22 23:35:20,915] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.0, 75.5, 1.0, 2.0, 0.4109997911643531, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 465888.201940909, 465888.201940909, 127476.618261315]
[2019-03-22 23:35:20,916] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:35:20,919] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.8356566924720171
[2019-03-22 23:35:34,985] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.20122123], dtype=float32), -0.07595031]
[2019-03-22 23:35:34,987] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [13.67814612333333, 80.61390165, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 194446.260716189, 194446.2607161886, 71340.7511091258]
[2019-03-22 23:35:34,987] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:35:34,990] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.6281457094555624
[2019-03-22 23:35:38,512] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.20122123], dtype=float32), -0.07595031]
[2019-03-22 23:35:38,514] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.691626825, 81.94107307666667, 1.0, 2.0, 0.2855596361077509, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 310051.733937508, 310051.7339375084, 97673.05518005887]
[2019-03-22 23:35:38,514] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:35:38,516] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.23518084031896502
[2019-03-22 23:35:55,142] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.20122123], dtype=float32), -0.07595031]
[2019-03-22 23:35:55,142] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.13333333333334, 59.66666666666667, 1.0, 2.0, 0.2778990973117507, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 301732.0722927636, 301732.0722927633, 92635.31677221772]
[2019-03-22 23:35:55,144] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:35:55,148] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.8183073543857936
[2019-03-22 23:36:04,815] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-22 23:36:04,851] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2492 1773187030.7201 173.0000
[2019-03-22 23:36:04,852] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3485 1683325900.1134 214.0000
[2019-03-22 23:36:04,874] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1147 1656209757.7786 80.0000
[2019-03-22 23:36:04,907] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9309 1705967916.6745 465.0000
[2019-03-22 23:36:05,920] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 675000, evaluation results [675000.0, 8512.249193409023, 1773187030.7201214, 173.0, 9061.114669779829, 1656209757.7786272, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8596.930884973775, 1705967916.6744611, 465.0, 8574.348472942609, 1683325900.1133502, 214.0]
[2019-03-22 23:36:07,002] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.4376995e-37 4.9936089e-36], sum to 1.0000
[2019-03-22 23:36:07,008] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1239
[2019-03-22 23:36:07,015] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.83333333333334, 89.83333333333333, 1.0, 2.0, 0.5095866048450346, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 580689.2642840884, 580689.2642840884, 143803.9165157384], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1414200.0000, 
sim time next is 1414800.0000, 
raw observation next is [23.0, 89.0, 1.0, 2.0, 0.5106320915119257, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 581764.8880698587, 581764.8880698587, 144042.1791593184], 
processed observation next is [0.0, 0.391304347826087, 0.6818181818181818, 0.89, 1.0, 1.0, 0.38829011438990707, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2154684770629106, 0.2154684770629106, 0.35132238819345946], 
reward next is 0.6487, 
noisyNet noise sample is [array([-1.1621643], dtype=float32), -1.1833446]. 
=============================================
[2019-03-22 23:36:09,317] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.2953442e-36 2.8980058e-36], sum to 1.0000
[2019-03-22 23:36:09,326] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4544
[2019-03-22 23:36:09,331] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4795200614083098, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 547103.4982555248, 547103.4982555251, 139141.1342918906], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1474200.0000, 
sim time next is 1474800.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.4796548861777623, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 547257.3457211268, 547257.3457211268, 139156.5975824313], 
processed observation next is [0.0, 0.043478260869565216, 0.5909090909090909, 1.0, 1.0, 1.0, 0.34956860772220283, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20268790582263954, 0.20268790582263954, 0.33940633556690564], 
reward next is 0.6606, 
noisyNet noise sample is [array([-0.40636346], dtype=float32), 0.95599663]. 
=============================================
[2019-03-22 23:36:11,739] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 9.4253905e-32 7.5380621e-32], sum to 1.0000
[2019-03-22 23:36:11,749] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9118
[2019-03-22 23:36:11,754] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 83.0, 1.0, 2.0, 0.5171125550062422, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 588677.044754659, 588677.044754659, 145214.2793242243], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1525200.0000, 
sim time next is 1525800.0000, 
raw observation next is [24.0, 83.0, 1.0, 2.0, 0.5169159529019093, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 588453.6895724321, 588453.6895724321, 145189.9616189466], 
processed observation next is [0.0, 0.6521739130434783, 0.7272727272727273, 0.83, 1.0, 1.0, 0.3961449411273866, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21794581095275262, 0.21794581095275262, 0.35412185760718684], 
reward next is 0.6459, 
noisyNet noise sample is [array([0.49469548], dtype=float32), 0.47225103]. 
=============================================
[2019-03-22 23:36:12,458] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.6716616e-35 1.5426527e-35], sum to 1.0000
[2019-03-22 23:36:12,466] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0907
[2019-03-22 23:36:12,472] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 83.0, 1.0, 2.0, 0.5173895005407687, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 588991.8875350053, 588991.8875350053, 145248.3893840361], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1524600.0000, 
sim time next is 1525200.0000, 
raw observation next is [24.0, 83.0, 1.0, 2.0, 0.5171125550062422, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 588677.044754659, 588677.044754659, 145214.2793242243], 
processed observation next is [0.0, 0.6521739130434783, 0.7272727272727273, 0.83, 1.0, 1.0, 0.3963906937578027, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21802853509431813, 0.21802853509431813, 0.3541811690834739], 
reward next is 0.6458, 
noisyNet noise sample is [array([0.22368631], dtype=float32), 2.4349341]. 
=============================================
[2019-03-22 23:36:14,679] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 2.5055452e-38 0.0000000e+00 2.0618026e-35], sum to 1.0000
[2019-03-22 23:36:14,692] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1172
[2019-03-22 23:36:14,696] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.5, 97.0, 1.0, 2.0, 0.4097371484134872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 465090.1615321406, 465090.1615321409, 127812.172276992], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1564200.0000, 
sim time next is 1564800.0000, 
raw observation next is [19.33333333333334, 98.0, 1.0, 2.0, 0.4034527608565712, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 457761.6987657626, 457761.6987657628, 127071.9953535845], 
processed observation next is [1.0, 0.08695652173913043, 0.5151515151515155, 0.98, 1.0, 1.0, 0.254315951070714, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16954136991324542, 0.16954136991324548, 0.30993169598435244], 
reward next is 0.6901, 
noisyNet noise sample is [array([-2.688209], dtype=float32), 0.9123959]. 
=============================================
[2019-03-22 23:36:20,494] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.8513755e-38 1.0000000e+00 3.5494534e-35 1.3489995e-28 8.0921738e-21], sum to 1.0000
[2019-03-22 23:36:20,497] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0144
[2019-03-22 23:36:20,503] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [11.83333333333333, 67.66666666666667, 1.0, 2.0, 0.3498293371033401, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 379884.1204316977, 379884.1204316977, 80894.25596262216], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1756200.0000, 
sim time next is 1756800.0000, 
raw observation next is [12.0, 67.0, 1.0, 2.0, 0.3198090102308421, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 347273.0254660732, 347273.0254660735, 78390.37939883879], 
processed observation next is [1.0, 0.34782608695652173, 0.18181818181818182, 0.67, 1.0, 1.0, 0.14976126278855256, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12861963906150858, 0.1286196390615087, 0.19119604731424095], 
reward next is 0.8088, 
noisyNet noise sample is [array([1.050387], dtype=float32), 0.3111526]. 
=============================================
[2019-03-22 23:36:32,463] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.00000000e+00 1.00000000e+00 0.00000000e+00 1.17638635e-33
 1.93408905e-32], sum to 1.0000
[2019-03-22 23:36:32,475] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8526
[2019-03-22 23:36:32,482] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 47.0, 1.0, 2.0, 0.2926590305459958, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 317781.873182393, 317781.8731823933, 92606.77470753247], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1884000.0000, 
sim time next is 1884600.0000, 
raw observation next is [21.5, 47.5, 1.0, 2.0, 0.2905007508038699, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 315437.5593408735, 315437.5593408732, 91855.82729417612], 
processed observation next is [1.0, 0.8260869565217391, 0.6136363636363636, 0.475, 1.0, 1.0, 0.11312593850483735, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.116828725681805, 0.1168287256818049, 0.22403860315652713], 
reward next is 0.7760, 
noisyNet noise sample is [array([-1.2149069], dtype=float32), -0.2899972]. 
=============================================
[2019-03-22 23:36:33,439] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 5.690592e-32], sum to 1.0000
[2019-03-22 23:36:33,447] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7334
[2019-03-22 23:36:33,452] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 62.66666666666667, 1.0, 2.0, 0.3185895329045737, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 347899.4605713063, 347899.4605713063, 113135.4576459969], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1982400.0000, 
sim time next is 1983000.0000, 
raw observation next is [21.0, 63.33333333333334, 1.0, 2.0, 0.3199383960239821, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 350002.444053184, 350002.444053184, 113455.6366983611], 
processed observation next is [1.0, 0.9565217391304348, 0.5909090909090909, 0.6333333333333334, 1.0, 1.0, 0.1499229950299776, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1296305348345126, 0.1296305348345126, 0.2767210651179539], 
reward next is 0.7233, 
noisyNet noise sample is [array([-0.43029177], dtype=float32), 0.23224732]. 
=============================================
[2019-03-22 23:36:33,462] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[84.2284  ]
 [84.232216]
 [84.24343 ]
 [84.255775]
 [84.27115 ]], R is [[84.10751343]
 [83.9905014 ]
 [83.87526703]
 [83.76190948]
 [83.65054321]].
[2019-03-22 23:36:36,050] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.9952527e-38 1.0000000e+00 7.6336305e-35 4.6107029e-32 9.8252796e-21], sum to 1.0000
[2019-03-22 23:36:36,061] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9482
[2019-03-22 23:36:36,068] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1213832.85191478 W.
[2019-03-22 23:36:36,074] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.5, 59.0, 1.0, 2.0, 0.53157334213381, 1.0, 1.0, 0.53157334213381, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846219938884, 1213832.85191478, 1213832.85191478, 233995.6374278521], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1960200.0000, 
sim time next is 1960800.0000, 
raw observation next is [25.33333333333333, 58.33333333333334, 1.0, 2.0, 0.3485856448123138, 1.0, 2.0, 0.3485856448123138, 1.0, 1.0, 0.7039564345680467, 6.911199999999999, 6.9112, 77.3421103, 1193900.264541524, 1193900.264541524, 272242.0086177441], 
processed observation next is [1.0, 0.6956521739130435, 0.7878787878787876, 0.5833333333333335, 1.0, 1.0, 0.18573205601539222, 1.0, 1.0, 0.18573205601539222, 1.0, 0.5, 0.5770806208114954, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.4421852831635274, 0.4421852831635274, 0.6640048990676685], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.696632], dtype=float32), -0.16911854]. 
=============================================
[2019-03-22 23:36:43,005] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:36:43,012] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9533
[2019-03-22 23:36:43,017] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.83333333333333, 53.5, 1.0, 2.0, 0.2891996545530016, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 314024.3198489147, 314024.3198489144, 94823.98857258345], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2059800.0000, 
sim time next is 2060400.0000, 
raw observation next is [20.66666666666667, 54.0, 1.0, 2.0, 0.2870705815993807, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 311711.7480839394, 311711.7480839391, 93865.72858879293], 
processed observation next is [0.0, 0.8695652173913043, 0.575757575757576, 0.54, 1.0, 1.0, 0.10883822699922586, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11544879558664423, 0.1154487955866441, 0.2289408014360803], 
reward next is 0.7711, 
noisyNet noise sample is [array([0.1702618], dtype=float32), 0.6141532]. 
=============================================
[2019-03-22 23:36:48,558] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 4.542046e-31 7.053461e-29], sum to 1.0000
[2019-03-22 23:36:48,571] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5491
[2019-03-22 23:36:48,575] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.83333333333334, 66.33333333333333, 1.0, 2.0, 0.3990155798460281, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 450675.481824262, 450675.481824262, 125332.0199746338], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2149800.0000, 
sim time next is 2150400.0000, 
raw observation next is [22.66666666666667, 63.66666666666667, 1.0, 2.0, 0.3843124371951248, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 431724.8638178151, 431724.8638178149, 122757.663670957], 
processed observation next is [0.0, 0.9130434782608695, 0.6666666666666669, 0.6366666666666667, 1.0, 1.0, 0.230390546493906, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1598980977103019, 0.1598980977103018, 0.29940893578282196], 
reward next is 0.7006, 
noisyNet noise sample is [array([0.44200313], dtype=float32), -0.35234746]. 
=============================================
[2019-03-22 23:36:52,970] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 7.4573098e-35 2.8005375e-31 7.5672014e-29], sum to 1.0000
[2019-03-22 23:36:52,985] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7120
[2019-03-22 23:36:52,991] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.33333333333333, 88.0, 1.0, 2.0, 0.251172741984909, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 272721.6303271385, 272721.6303271385, 84235.3245141737], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2248800.0000, 
sim time next is 2249400.0000, 
raw observation next is [15.16666666666667, 88.0, 1.0, 2.0, 0.245471373000391, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 266529.4269847108, 266529.4269847105, 82629.28908373471], 
processed observation next is [1.0, 0.0, 0.3257575757575759, 0.88, 1.0, 1.0, 0.05683921625048875, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09871460258692992, 0.09871460258692981, 0.2015348514237432], 
reward next is 0.7985, 
noisyNet noise sample is [array([-0.25096786], dtype=float32), 0.44030377]. 
=============================================
[2019-03-22 23:36:55,247] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 7.5248705e-33 3.0267264e-25 4.4625978e-23], sum to 1.0000
[2019-03-22 23:36:55,258] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1339
[2019-03-22 23:36:55,264] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 49.0, 1.0, 2.0, 0.4775696281607517, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 518672.9180760542, 518672.9180760542, 105329.8919374796], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2373000.0000, 
sim time next is 2373600.0000, 
raw observation next is [20.0, 49.0, 1.0, 2.0, 0.4514325599324419, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 490271.9796547513, 490271.9796547513, 102623.3222844337], 
processed observation next is [1.0, 0.4782608695652174, 0.5454545454545454, 0.49, 1.0, 1.0, 0.31429069991555236, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18158221468694494, 0.18158221468694494, 0.2503007860595944], 
reward next is 0.7497, 
noisyNet noise sample is [array([-1.359049], dtype=float32), 0.015212957]. 
=============================================
[2019-03-22 23:36:55,414] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 2.7636449e-33 2.0110966e-24 6.6009452e-26], sum to 1.0000
[2019-03-22 23:36:55,427] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1282
[2019-03-22 23:36:55,432] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 49.0, 1.0, 2.0, 0.4579874057043435, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 497394.4195252951, 497394.4195252951, 103097.7578915724], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2376000.0000, 
sim time next is 2376600.0000, 
raw observation next is [20.16666666666667, 49.0, 1.0, 2.0, 0.5281241436045295, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 573610.937584163, 573610.937584163, 111508.6633198299], 
processed observation next is [1.0, 0.5217391304347826, 0.5530303030303032, 0.49, 1.0, 1.0, 0.4101551795056619, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21244849540154187, 0.21244849540154187, 0.2719723495605607], 
reward next is 0.7280, 
noisyNet noise sample is [array([-0.3009403], dtype=float32), 0.19291973]. 
=============================================
[2019-03-22 23:36:55,732] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 9.849011e-33 1.185264e-34], sum to 1.0000
[2019-03-22 23:36:55,739] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8965
[2019-03-22 23:36:55,745] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.33333333333333, 65.0, 1.0, 2.0, 0.2132344119431555, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 231518.649161564, 231518.6491615637, 71653.8768136338], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2274000.0000, 
sim time next is 2274600.0000, 
raw observation next is [15.66666666666667, 62.0, 1.0, 2.0, 0.222307766814425, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 241372.4624861468, 241372.4624861465, 72440.69674194157], 
processed observation next is [1.0, 0.30434782608695654, 0.3484848484848486, 0.62, 1.0, 1.0, 0.027884708518031223, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08939720832820253, 0.08939720832820242, 0.1766846261998575], 
reward next is 0.8233, 
noisyNet noise sample is [array([-0.20911755], dtype=float32), -0.4526321]. 
=============================================
[2019-03-22 23:36:58,814] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-22 23:36:58,815] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-22 23:36:58,816] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-22 23:36:58,817] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:36:58,820] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:36:58,819] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-22 23:36:58,822] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-22 23:36:58,823] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:36:58,820] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-22 23:36:58,824] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:36:58,825] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:36:58,843] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run29
[2019-03-22 23:36:58,865] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run29
[2019-03-22 23:36:58,866] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run29
[2019-03-22 23:36:58,884] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run29
[2019-03-22 23:36:58,929] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run29
[2019-03-22 23:37:04,924] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.27768707], dtype=float32), -0.12004728]
[2019-03-22 23:37:04,926] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.94534212333333, 58.55658386333334, 1.0, 2.0, 0.4353726845618516, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 472778.0501647929, 472778.0501647929, 107621.6056358666]
[2019-03-22 23:37:04,933] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:37:04,935] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 8.460033e-30 3.805111e-31], sampled 0.1147379092844456
[2019-03-22 23:37:40,212] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.27768707], dtype=float32), -0.12004728]
[2019-03-22 23:37:40,213] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.50701901333333, 95.16698388, 1.0, 2.0, 0.4822931252934618, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 550210.1632663801, 550210.1632663797, 143758.9779817565]
[2019-03-22 23:37:40,214] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:37:40,219] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 6.2637694e-29 2.2895468e-30], sampled 0.3757965949634403
[2019-03-22 23:37:46,819] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.27768707], dtype=float32), -0.12004728]
[2019-03-22 23:37:46,822] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.07281315166667, 99.21683696166667, 1.0, 2.0, 0.5537201625792697, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 631035.5696895049, 631035.5696895049, 149603.8265569423]
[2019-03-22 23:37:46,822] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:37:46,826] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0.0000000e+00 1.0000000e+00 2.5566982e-38 4.0414504e-28 7.9347426e-30], sampled 0.9911745085683569
[2019-03-22 23:38:00,722] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.27768707], dtype=float32), -0.12004728]
[2019-03-22 23:38:00,723] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [25.78185707, 75.172840615, 1.0, 2.0, 0.529493180329554, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 601562.565460114, 601562.5654601137, 151734.3268299504]
[2019-03-22 23:38:00,724] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:38:00,728] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.2065616e-30 2.1940621e-31], sampled 0.9203268322342143
[2019-03-22 23:38:12,899] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.27768707], dtype=float32), -0.12004728]
[2019-03-22 23:38:12,900] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.72545291666667, 87.02377434, 1.0, 2.0, 0.4000416356167019, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 449477.2533787345, 449477.2533787342, 128506.5259275438]
[2019-03-22 23:38:12,901] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:38:12,904] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0.00000000e+00 1.00000000e+00 0.00000000e+00 2.74378789e-28
 1.17900346e-29], sampled 0.2406033801620886
[2019-03-22 23:38:37,348] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.27768707], dtype=float32), -0.12004728]
[2019-03-22 23:38:37,348] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.886889595, 44.57187142833333, 1.0, 2.0, 0.3217554979859295, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 349363.4932229783, 349363.4932229779, 106679.6272337318]
[2019-03-22 23:38:37,349] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:38:37,353] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.8090163e-36 5.5646987e-36], sampled 0.6458792358214334
[2019-03-22 23:38:47,033] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2492 1773187030.7201 173.0000
[2019-03-22 23:38:47,404] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1147 1656209757.7786 80.0000
[2019-03-22 23:38:47,427] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5598 1663796639.0689 105.0000
[2019-03-22 23:38:47,455] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9309 1705967916.6745 465.0000
[2019-03-22 23:38:47,499] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3485 1683325900.1134 214.0000
[2019-03-22 23:38:48,513] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 700000, evaluation results [700000.0, 8512.249193409023, 1773187030.7201214, 173.0, 9061.114669779829, 1656209757.7786272, 80.0, 8856.559759326878, 1663796639.0688558, 105.0, 8596.930884973775, 1705967916.6744611, 465.0, 8574.348472942609, 1683325900.1133502, 214.0]
[2019-03-22 23:38:48,652] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.3220258e-33 2.5212931e-27], sum to 1.0000
[2019-03-22 23:38:48,661] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6097
[2019-03-22 23:38:48,667] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.5, 60.0, 1.0, 2.0, 0.2280086640041034, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 247563.8331610166, 247563.8331610163, 74020.7684770285], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2331000.0000, 
sim time next is 2331600.0000, 
raw observation next is [16.33333333333333, 62.66666666666666, 1.0, 2.0, 0.2251962912502317, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 244509.4896483058, 244509.4896483058, 74126.92849449825], 
processed observation next is [1.0, 1.0, 0.37878787878787856, 0.6266666666666666, 1.0, 1.0, 0.0314953640627896, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09055907024011327, 0.09055907024011327, 0.18079738657194694], 
reward next is 0.8192, 
noisyNet noise sample is [array([0.87979084], dtype=float32), -0.72058135]. 
=============================================
[2019-03-22 23:39:03,429] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.9208369e-35 1.5034865e-31], sum to 1.0000
[2019-03-22 23:39:03,438] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6043
[2019-03-22 23:39:03,444] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333334, 65.0, 1.0, 2.0, 0.385714962007895, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 436095.4351498336, 436095.4351498336, 124398.348831439], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2626800.0000, 
sim time next is 2627400.0000, 
raw observation next is [23.66666666666666, 63.0, 1.0, 2.0, 0.3856553894711949, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 436041.9658796682, 436041.9658796682, 124401.4356588352], 
processed observation next is [0.0, 0.391304347826087, 0.7121212121212118, 0.63, 1.0, 1.0, 0.23206923683899358, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16149702439987712, 0.16149702439987712, 0.30341813575325655], 
reward next is 0.6966, 
noisyNet noise sample is [array([0.54018676], dtype=float32), -0.6298323]. 
=============================================
[2019-03-22 23:39:14,202] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0615456e-24 1.0000000e+00 1.0555693e-24 3.9158624e-12 1.6057017e-14], sum to 1.0000
[2019-03-22 23:39:14,214] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5417
[2019-03-22 23:39:14,219] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.66666666666667, 70.33333333333334, 1.0, 2.0, 0.8545573430584206, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 974085.9132189885, 974085.9132189885, 187291.6801772783], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2799600.0000, 
sim time next is 2800200.0000, 
raw observation next is [23.83333333333333, 69.66666666666666, 1.0, 2.0, 0.8327067659312388, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 949303.6042604332, 949303.6042604332, 183989.2453981549], 
processed observation next is [1.0, 0.391304347826087, 0.7196969696969695, 0.6966666666666665, 1.0, 1.0, 0.7908834574140485, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.35159392750386415, 0.35159392750386415, 0.44875425706867045], 
reward next is 0.5512, 
noisyNet noise sample is [array([0.93071884], dtype=float32), -0.21062957]. 
=============================================
[2019-03-22 23:39:19,025] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.2275360e-35 1.0000000e+00 8.0875486e-35 1.2309276e-29 6.4133639e-21], sum to 1.0000
[2019-03-22 23:39:19,030] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9479
[2019-03-22 23:39:19,037] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1507353.981827444 W.
[2019-03-22 23:39:19,041] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.0, 74.0, 1.0, 2.0, 0.4467788994924498, 1.0, 1.0, 0.4467788994924498, 1.0, 2.0, 0.9040032365791008, 6.911199999999999, 6.9112, 77.3421103, 1507353.981827444, 1507353.981827444, 330984.6728030471], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2890800.0000, 
sim time next is 2891400.0000, 
raw observation next is [27.16666666666666, 73.33333333333334, 1.0, 2.0, 0.4537398154906694, 1.0, 2.0, 0.4537398154906694, 1.0, 2.0, 0.9180878108485983, 6.9112, 6.9112, 77.3421103, 1530870.643957538, 1530870.643957538, 334702.4788274909], 
processed observation next is [1.0, 0.4782608695652174, 0.871212121212121, 0.7333333333333334, 1.0, 1.0, 0.3171747693633367, 1.0, 1.0, 0.3171747693633367, 1.0, 1.0, 0.8829825869265691, 0.0, 0.0, 0.5085185399722538, 0.5669891273916807, 0.5669891273916807, 0.8163475093353436], 
reward next is 0.1837, 
noisyNet noise sample is [array([0.7195148], dtype=float32), 1.0030558]. 
=============================================
[2019-03-22 23:39:26,859] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.00000000e+00 1.00000000e+00 1.63562205e-38 1.03141755e-36
 5.41070646e-33], sum to 1.0000
[2019-03-22 23:39:26,870] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9261
[2019-03-22 23:39:26,875] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.5, 91.0, 1.0, 2.0, 0.3940419402645693, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 433069.2221214545, 433069.2221214548, 119710.9644436762], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3033000.0000, 
sim time next is 3033600.0000, 
raw observation next is [17.33333333333333, 92.0, 1.0, 2.0, 0.3740748820799013, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 410596.1727665297, 410596.17276653, 117935.0126010674], 
processed observation next is [1.0, 0.08695652173913043, 0.42424242424242403, 0.92, 1.0, 1.0, 0.21759360259987662, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1520726565801962, 0.1520726565801963, 0.2876463721977254], 
reward next is 0.7124, 
noisyNet noise sample is [array([-0.3285636], dtype=float32), 2.506444]. 
=============================================
[2019-03-22 23:39:31,035] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.7981535e-31 9.3569177e-01 9.2674285e-25 6.4308204e-02 3.4971787e-12], sum to 1.0000
[2019-03-22 23:39:31,046] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2817
[2019-03-22 23:39:31,049] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.66666666666667, 75.5, 1.0, 2.0, 0.2820036572344925, 1.0, 2.0, 0.2820036572344925, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 637300.1421179833, 637300.142117983, 188030.8984609138], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3093000.0000, 
sim time next is 3093600.0000, 
raw observation next is [25.33333333333334, 77.0, 1.0, 2.0, 0.5583339321444494, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 633590.8453979105, 633590.8453979102, 151468.9430013572], 
processed observation next is [1.0, 0.8260869565217391, 0.7878787878787882, 0.77, 1.0, 1.0, 0.44791741518056166, 0.0, 0.5, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.23466327607330018, 0.2346632760733001, 0.36943644634477363], 
reward next is 0.6306, 
noisyNet noise sample is [array([-0.8157476], dtype=float32), -1.5625312]. 
=============================================
[2019-03-22 23:39:33,038] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.3521650e-28 1.3242985e-07 1.1722081e-23 9.9999976e-01 8.8260130e-08], sum to 1.0000
[2019-03-22 23:39:33,048] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2948
[2019-03-22 23:39:33,054] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.0, 73.0, 1.0, 2.0, 0.4069118940185464, 1.0, 1.0, 0.4069118940185464, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 928513.9307163517, 928513.930716352, 203255.3771028489], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3140400.0000, 
sim time next is 3141000.0000, 
raw observation next is [23.0, 73.0, 1.0, 2.0, 0.4702161149358338, 1.0, 2.0, 0.4702161149358338, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1073633.969822726, 1073633.969822727, 218090.6099491758], 
processed observation next is [1.0, 0.34782608695652173, 0.6818181818181818, 0.73, 1.0, 1.0, 0.33777014366979224, 1.0, 1.0, 0.33777014366979224, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.39764221104545405, 0.3976422110454544, 0.5319283169492093], 
reward next is 0.4681, 
noisyNet noise sample is [array([-0.91855556], dtype=float32), -0.5360958]. 
=============================================
[2019-03-22 23:39:33,072] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[55.82529 ]
 [57.91203 ]
 [58.22462 ]
 [58.040844]
 [57.84909 ]], R is [[54.59069443]
 [54.54904175]
 [54.65405655]
 [54.77375412]
 [54.89122391]].
[2019-03-22 23:39:41,282] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-22 23:39:41,286] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-22 23:39:41,287] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:39:41,288] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-22 23:39:41,289] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:39:41,290] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-22 23:39:41,291] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-22 23:39:41,291] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:39:41,292] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:39:41,292] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-22 23:39:41,293] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:39:41,306] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run30
[2019-03-22 23:39:41,307] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run30
[2019-03-22 23:39:41,308] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run30
[2019-03-22 23:39:41,363] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run30
[2019-03-22 23:39:41,382] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run30
[2019-03-22 23:40:02,492] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.15747637], dtype=float32), -0.20875423]
[2019-03-22 23:40:02,494] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.81666666666667, 74.0, 1.0, 2.0, 0.475873668627157, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 542817.0756666809, 542817.0756666806, 141734.6516847993]
[2019-03-22 23:40:02,495] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:40:02,498] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 3.919272e-37], sampled 0.17766780593291853
[2019-03-22 23:40:35,478] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.15747637], dtype=float32), -0.20875423]
[2019-03-22 23:40:35,480] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.61201855666667, 78.74067073, 1.0, 2.0, 0.335795462430695, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 371986.3668190666, 371986.3668190663, 120658.3212341519]
[2019-03-22 23:40:35,480] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:40:35,482] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.7735629566456562
[2019-03-22 23:40:59,267] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.15747637], dtype=float32), -0.20875423]
[2019-03-22 23:40:59,269] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [11.1, 77.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 162228.5255568689, 162228.5255568689, 59449.46271651904]
[2019-03-22 23:40:59,269] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:40:59,274] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.5071923907026713
[2019-03-22 23:41:00,788] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.15747637], dtype=float32), -0.20875423]
[2019-03-22 23:41:00,789] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [16.53333333333333, 92.0, 1.0, 2.0, 0.3061567139234039, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 332421.5825976938, 332421.5825976938, 114303.581312536]
[2019-03-22 23:41:00,792] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:41:00,794] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.9607448161751642
[2019-03-22 23:41:02,921] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.15747637], dtype=float32), -0.20875423]
[2019-03-22 23:41:02,922] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [14.75195548, 81.833071765, 1.0, 2.0, 0.2098400947433741, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 227822.239620233, 227822.2396202327, 78990.18191745061]
[2019-03-22 23:41:02,924] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:41:02,926] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.15772334867768523
[2019-03-22 23:41:09,284] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.15747637], dtype=float32), -0.20875423]
[2019-03-22 23:41:09,286] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.746186525, 60.142421615, 1.0, 2.0, 0.3740700412392658, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 406186.0448580802, 406186.0448580802, 96488.45775205431]
[2019-03-22 23:41:09,287] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:41:09,290] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.14259838735199193
[2019-03-22 23:41:28,866] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3485 1683325900.1134 214.0000
[2019-03-22 23:41:29,141] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1147 1656209757.7786 80.0000
[2019-03-22 23:41:29,279] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2492 1773187030.7201 173.0000
[2019-03-22 23:41:29,300] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5598 1663796639.0689 105.0000
[2019-03-22 23:41:29,366] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9309 1705967916.6745 465.0000
[2019-03-22 23:41:30,381] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 725000, evaluation results [725000.0, 8512.249193409023, 1773187030.7201214, 173.0, 9061.114669779829, 1656209757.7786272, 80.0, 8856.559759326878, 1663796639.0688558, 105.0, 8596.930884973775, 1705967916.6744611, 465.0, 8574.348472942609, 1683325900.1133502, 214.0]
[2019-03-22 23:41:37,480] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.5218423e-28 1.0000000e+00 2.7848918e-28 5.4168896e-15 4.3197897e-16], sum to 1.0000
[2019-03-22 23:41:37,487] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7211
[2019-03-22 23:41:37,493] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1088993.762974493 W.
[2019-03-22 23:41:37,499] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.0, 65.0, 1.0, 2.0, 0.4769231506055157, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9361023119095141, 6.954955443791988, 6.9112, 77.32832873285868, 1088993.762974493, 1074782.914540617, 247413.1930739362], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3411000.0000, 
sim time next is 3411600.0000, 
raw observation next is [25.0, 65.0, 1.0, 2.0, 0.5155002189743041, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9509779570922535, 6.94031640783156, 6.9112, 77.32836452689378, 1136721.33749262, 1127264.935858867, 254457.5917335571], 
processed observation next is [1.0, 0.4782608695652174, 0.7727272727272727, 0.65, 1.0, 1.0, 0.39437527371788006, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9299685101317909, 0.0029116407831559776, 0.0, 0.5084281625511614, 0.42100790277504446, 0.41750553179958033, 0.620628272520871], 
reward next is 0.2338, 
noisyNet noise sample is [array([1.0041133], dtype=float32), 0.06992888]. 
=============================================
[2019-03-22 23:41:42,460] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.1901986e-35 1.0000000e+00 5.7271288e-34 5.4925651e-31 9.4575055e-27], sum to 1.0000
[2019-03-22 23:41:42,467] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4213
[2019-03-22 23:41:42,474] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1532845.861940311 W.
[2019-03-22 23:41:42,479] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.0, 62.0, 1.0, 2.0, 0.4543244655094427, 1.0, 2.0, 0.4543244655094427, 1.0, 2.0, 0.9192707796724112, 6.911199999999999, 6.9112, 77.3421103, 1532845.861940311, 1532845.861940311, 335017.095883277], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3508200.0000, 
sim time next is 3508800.0000, 
raw observation next is [28.0, 62.0, 1.0, 2.0, 0.690015477100775, 1.0, 2.0, 0.690015477100775, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1552056.03460679, 1552056.034606789, 288658.8287852854], 
processed observation next is [1.0, 0.6086956521739131, 0.9090909090909091, 0.62, 1.0, 1.0, 0.6125193463759687, 1.0, 1.0, 0.6125193463759687, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.5748355683728852, 0.5748355683728849, 0.7040459238665497], 
reward next is 0.2960, 
noisyNet noise sample is [array([-0.96672475], dtype=float32), -0.3017493]. 
=============================================
[2019-03-22 23:41:49,903] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.0559298e-31 2.6102798e-15 5.1103223e-25 1.5618452e-18 1.0000000e+00], sum to 1.0000
[2019-03-22 23:41:49,913] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4839
[2019-03-22 23:41:49,917] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3334395516243016, 6.911199999999999, 6.9112, 77.3421103, 562887.6613035155, 562887.6613035158, 210977.8167476677], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3628200.0000, 
sim time next is 3628800.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3331633563224898, 6.9112, 6.9112, 77.3421103, 562423.5917135655, 562423.5917135655, 210915.5111168785], 
processed observation next is [1.0, 0.0, 0.5909090909090909, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.04737622331784256, 0.0, 0.0, 0.5085185399722538, 0.20830503396798722, 0.20830503396798722, 0.5144280758948256], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.86060846], dtype=float32), 0.27920136]. 
=============================================
[2019-03-22 23:41:53,605] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.2977163e-23 9.9996865e-01 3.1577741e-22 1.1008737e-20 3.1305928e-05], sum to 1.0000
[2019-03-22 23:41:53,613] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2934
[2019-03-22 23:41:53,619] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1612640.157842976 W.
[2019-03-22 23:41:53,626] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.0, 52.5, 1.0, 2.0, 0.9364958766352388, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9774992687630617, 6.911200000000001, 6.9112, 77.32846344354104, 1612640.157842976, 1612640.157842976, 332366.772190173], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3685800.0000, 
sim time next is 3686400.0000, 
raw observation next is [29.0, 52.0, 1.0, 2.0, 0.4750454229553738, 1.0, 1.0, 0.4750454229553738, 1.0, 2.0, 0.9608807856968613, 6.911199999999999, 6.9112, 77.3421103, 1609115.81429929, 1609115.814299291, 343693.5633430448], 
processed observation next is [1.0, 0.6956521739130435, 0.9545454545454546, 0.52, 1.0, 1.0, 0.34380677869421716, 1.0, 0.5, 0.34380677869421716, 1.0, 1.0, 0.9441154081383732, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.5959688201108482, 0.5959688201108485, 0.8382769837635239], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.6822516], dtype=float32), -0.016268086]. 
=============================================
[2019-03-22 23:41:55,784] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.5891216e-36 1.0000000e+00 8.1538054e-36 1.5665100e-27 2.5306185e-21], sum to 1.0000
[2019-03-22 23:41:55,793] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2136
[2019-03-22 23:41:55,796] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 73.0, 1.0, 2.0, 0.4979845432941101, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 566471.1982369834, 566471.1982369836, 137703.3712796796], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3741600.0000, 
sim time next is 3742200.0000, 
raw observation next is [23.0, 73.0, 1.0, 2.0, 0.496638861981465, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 564934.6802743151, 564934.6802743151, 137552.0235782385], 
processed observation next is [1.0, 0.30434782608695654, 0.6818181818181818, 0.73, 1.0, 1.0, 0.3707985774768312, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20923506676826484, 0.20923506676826484, 0.33549274043472804], 
reward next is 0.6645, 
noisyNet noise sample is [array([-0.19189756], dtype=float32), -0.4246797]. 
=============================================
[2019-03-22 23:41:57,871] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.7698764e-31 1.0000000e+00 5.7715113e-29 4.5800514e-21 3.2746421e-19], sum to 1.0000
[2019-03-22 23:41:57,879] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8680
[2019-03-22 23:41:57,884] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 54.66666666666666, 1.0, 2.0, 0.6556134778846244, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 745746.9379086051, 745746.9379086054, 156519.108478048], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3761400.0000, 
sim time next is 3762000.0000, 
raw observation next is [26.0, 54.0, 1.0, 2.0, 0.6583121628900295, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 748368.3572888302, 748368.3572888299, 156495.0882001111], 
processed observation next is [1.0, 0.5652173913043478, 0.8181818181818182, 0.54, 1.0, 1.0, 0.5728902036125368, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2771734656625297, 0.2771734656625296, 0.38169533707344167], 
reward next is 0.6183, 
noisyNet noise sample is [array([1.0700228], dtype=float32), 0.9806149]. 
=============================================
[2019-03-22 23:41:57,896] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[44.597614]
 [44.12047 ]
 [43.426746]
 [42.367313]
 [40.328854]], R is [[45.23363113]
 [45.39954376]
 [45.56509781]
 [45.72877884]
 [45.78157043]].
[2019-03-22 23:42:12,479] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 3.5442269e-37 1.4125325e-27 1.2921358e-33], sum to 1.0000
[2019-03-22 23:42:12,489] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5208
[2019-03-22 23:42:12,497] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.6248095502053795, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 702660.8492792225, 702660.8492792229, 147708.136990939], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4027800.0000, 
sim time next is 4028400.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.5559538064643551, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 625048.1083154102, 625048.1083154102, 139782.7034745242], 
processed observation next is [1.0, 0.6521739130434783, 0.45454545454545453, 1.0, 1.0, 1.0, 0.44494225808044385, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23149929937607786, 0.23149929937607786, 0.3409334231085956], 
reward next is 0.6591, 
noisyNet noise sample is [array([-1.418349], dtype=float32), -2.5424554]. 
=============================================
[2019-03-22 23:42:19,124] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 4.2661881e-32 1.1544568e-32 9.4280224e-38], sum to 1.0000
[2019-03-22 23:42:19,135] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3344
[2019-03-22 23:42:19,139] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 94.0, 1.0, 2.0, 0.3233467958571533, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 353783.3540624561, 353783.3540624561, 113716.1826719446], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4238400.0000, 
sim time next is 4239000.0000, 
raw observation next is [17.0, 94.0, 1.0, 2.0, 0.3222822818910813, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 352606.1782801722, 352606.1782801719, 113635.9357746284], 
processed observation next is [1.0, 0.043478260869565216, 0.4090909090909091, 0.94, 1.0, 1.0, 0.15285285236385163, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1305948808445082, 0.1305948808445081, 0.27716081896250827], 
reward next is 0.7228, 
noisyNet noise sample is [array([-1.2591581], dtype=float32), -0.43542254]. 
=============================================
[2019-03-22 23:42:19,149] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[59.023304]
 [59.03818 ]
 [59.144333]
 [59.097466]
 [59.053585]], R is [[59.13898849]
 [59.2702446 ]
 [59.39983749]
 [59.52713776]
 [59.65071106]].
[2019-03-22 23:42:23,275] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-22 23:42:23,277] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-22 23:42:23,279] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:42:23,280] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-22 23:42:23,280] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-22 23:42:23,281] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-22 23:42:23,282] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:42:23,283] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:42:23,281] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:42:23,286] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-22 23:42:23,288] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:42:23,307] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run31
[2019-03-22 23:42:23,307] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run31
[2019-03-22 23:42:23,307] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run31
[2019-03-22 23:42:23,378] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run31
[2019-03-22 23:42:23,379] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run31
[2019-03-22 23:42:40,880] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05762751], dtype=float32), -0.12197161]
[2019-03-22 23:42:40,883] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.0, 100.0, 1.0, 2.0, 0.417511172905341, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 473297.5456650748, 473297.5456650748, 128114.3003765524]
[2019-03-22 23:42:40,883] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:42:40,888] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.417431419802172
[2019-03-22 23:42:56,651] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05762751], dtype=float32), -0.12197161]
[2019-03-22 23:42:56,652] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [14.37547080333333, 84.34824332, 1.0, 2.0, 0.4730475875263688, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 513707.3101382867, 513707.3101382863, 106007.4481927018]
[2019-03-22 23:42:56,654] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:42:56,655] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.6577390312470562
[2019-03-22 23:43:10,450] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05762751], dtype=float32), -0.12197161]
[2019-03-22 23:43:10,452] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.3, 61.0, 1.0, 2.0, 0.2660501228869527, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 288863.8233280518, 288863.8233280515, 94024.16912398755]
[2019-03-22 23:43:10,454] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:43:10,459] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.14131464784606362
[2019-03-22 23:43:24,112] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05762751], dtype=float32), -0.12197161]
[2019-03-22 23:43:24,113] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.37058883, 78.31674023, 1.0, 2.0, 0.3479551283283089, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 378855.296847392, 378855.2968473917, 119183.6695015379]
[2019-03-22 23:43:24,114] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:43:24,121] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.9610713121739954
[2019-03-22 23:43:33,921] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05762751], dtype=float32), -0.12197161]
[2019-03-22 23:43:33,922] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.7, 50.66666666666667, 1.0, 2.0, 0.2885706582033782, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 313321.8598707663, 313321.859870766, 102937.0498103712]
[2019-03-22 23:43:33,923] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:43:33,926] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.3550009643036207
[2019-03-22 23:43:34,587] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05762751], dtype=float32), -0.12197161]
[2019-03-22 23:43:34,588] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.15, 62.0, 1.0, 2.0, 0.3286382496286463, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 364700.4556364336, 364700.4556364333, 120382.0323289839]
[2019-03-22 23:43:34,591] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:43:34,593] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.1931114667987036
[2019-03-22 23:43:51,216] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05762751], dtype=float32), -0.12197161]
[2019-03-22 23:43:51,219] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [15.0, 78.0, 1.0, 2.0, 0.2101189782432851, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 228135.2827212985, 228135.2827212982, 73904.17749299668]
[2019-03-22 23:43:51,221] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:43:51,224] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.6809353754405276
[2019-03-22 23:43:51,628] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05762751], dtype=float32), -0.12197161]
[2019-03-22 23:43:51,630] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.85, 75.5, 1.0, 2.0, 0.4124216488615392, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 456145.7580713874, 456145.758071387, 126570.6603961776]
[2019-03-22 23:43:51,631] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:43:51,635] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.5013472694528189
[2019-03-22 23:43:53,661] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05762751], dtype=float32), -0.12197161]
[2019-03-22 23:43:53,662] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [28.33333333333334, 42.33333333333334, 1.0, 2.0, 0.6748349445413401, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 766151.3600280838, 766151.3600280834, 162291.5848829263]
[2019-03-22 23:43:53,664] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:43:53,669] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.00000e+00 1.00000e+00 0.00000e+00 0.00000e+00 9.59624e-38], sampled 0.02429115094251999
[2019-03-22 23:44:11,214] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3485 1683325900.1134 214.0000
[2019-03-22 23:44:11,407] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5598 1663796639.0689 105.0000
[2019-03-22 23:44:11,488] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2492 1773187030.7201 173.0000
[2019-03-22 23:44:11,579] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1147 1656209757.7786 80.0000
[2019-03-22 23:44:11,756] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9309 1705967916.6745 465.0000
[2019-03-22 23:44:12,775] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 750000, evaluation results [750000.0, 8512.249193409023, 1773187030.7201214, 173.0, 9061.114669779829, 1656209757.7786272, 80.0, 8856.559759326878, 1663796639.0688558, 105.0, 8596.930884973775, 1705967916.6744611, 465.0, 8574.348472942609, 1683325900.1133502, 214.0]
[2019-03-22 23:44:25,824] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 6.0653080e-38 5.1497809e-30 4.6828455e-25], sum to 1.0000
[2019-03-22 23:44:25,830] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1978
[2019-03-22 23:44:25,836] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 74.0, 1.0, 2.0, 0.4656966369495772, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 531347.9162433195, 531347.9162433193, 136639.6898242805], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4442400.0000, 
sim time next is 4443000.0000, 
raw observation next is [24.0, 74.0, 1.0, 2.0, 0.4671966534209401, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 533067.0538699378, 533067.0538699378, 136837.4633476663], 
processed observation next is [0.0, 0.43478260869565216, 0.7272727272727273, 0.74, 1.0, 1.0, 0.33399581677617507, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19743224217405103, 0.19743224217405103, 0.3337499106040641], 
reward next is 0.6663, 
noisyNet noise sample is [array([-0.7726436], dtype=float32), 0.8226557]. 
=============================================
[2019-03-22 23:44:25,854] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[64.52395 ]
 [64.51939 ]
 [64.524826]
 [64.5238  ]
 [64.52346 ]], R is [[64.5497818 ]
 [64.5710144 ]
 [64.5931778 ]
 [64.61618042]
 [64.63989258]].
[2019-03-22 23:44:30,179] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 6.2225427e-37 1.0388366e-37], sum to 1.0000
[2019-03-22 23:44:30,185] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9579
[2019-03-22 23:44:30,189] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.16666666666667, 100.0, 1.0, 2.0, 0.4449557909459974, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 507284.966883476, 507284.966883476, 133467.11256976], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4518600.0000, 
sim time next is 4519200.0000, 
raw observation next is [20.33333333333334, 100.0, 1.0, 2.0, 0.4511348534099952, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 514532.581520561, 514532.581520561, 134488.909614847], 
processed observation next is [0.0, 0.30434782608695654, 0.5606060606060609, 1.0, 1.0, 1.0, 0.31391856676249397, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19056762278539296, 0.19056762278539296, 0.3280217307679195], 
reward next is 0.6720, 
noisyNet noise sample is [array([0.6306169], dtype=float32), 0.5785943]. 
=============================================
[2019-03-22 23:44:31,394] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.0436084e-36 1.1624265e-36], sum to 1.0000
[2019-03-22 23:44:31,402] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4447
[2019-03-22 23:44:31,406] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 61.0, 1.0, 2.0, 0.3920858247548311, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 443272.4404316834, 443272.4404316834, 124956.748800857], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4555800.0000, 
sim time next is 4556400.0000, 
raw observation next is [24.0, 61.0, 1.0, 2.0, 0.3919146581026086, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 443078.2587879354, 443078.2587879357, 124940.8538533637], 
processed observation next is [0.0, 0.7391304347826086, 0.7272727272727273, 0.61, 1.0, 1.0, 0.23989332262826074, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16410305881034645, 0.16410305881034656, 0.30473378988625294], 
reward next is 0.6953, 
noisyNet noise sample is [array([-1.9092672], dtype=float32), -0.06604851]. 
=============================================
[2019-03-22 23:44:32,697] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 2.5735927e-34], sum to 1.0000
[2019-03-22 23:44:32,704] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8279
[2019-03-22 23:44:32,709] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.2, 66.5, 1.0, 2.0, 0.3423534170074698, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 379123.8651269781, 379123.8651269784, 116790.2951851773], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4563000.0000, 
sim time next is 4563600.0000, 
raw observation next is [20.93333333333333, 67.33333333333334, 1.0, 2.0, 0.3381004059802352, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 373633.9483600216, 373633.9483600219, 116156.2684696315], 
processed observation next is [0.0, 0.8260869565217391, 0.5878787878787878, 0.6733333333333335, 1.0, 1.0, 0.172625507475294, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13838294383704502, 0.13838294383704516, 0.28330797187715], 
reward next is 0.7167, 
noisyNet noise sample is [array([1.5531994], dtype=float32), 0.513096]. 
=============================================
[2019-03-22 23:44:34,216] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 2.7347900e-36 3.6946676e-26 6.6407614e-30], sum to 1.0000
[2019-03-22 23:44:34,226] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3290
[2019-03-22 23:44:34,233] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.66666666666667, 67.0, 1.0, 2.0, 0.4769368671368446, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 517985.3306623686, 517985.3306623686, 114339.4439905226], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4614000.0000, 
sim time next is 4614600.0000, 
raw observation next is [18.83333333333333, 65.5, 1.0, 2.0, 0.4768876951464195, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 517931.8981425468, 517931.8981425468, 113949.9874655151], 
processed observation next is [1.0, 0.391304347826087, 0.4924242424242422, 0.655, 1.0, 1.0, 0.34610961893302433, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.191826628941684, 0.191826628941684, 0.2779267986963783], 
reward next is 0.7221, 
noisyNet noise sample is [array([1.1649288], dtype=float32), -1.2533963]. 
=============================================
[2019-03-22 23:44:38,349] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:44:38,358] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2468
[2019-03-22 23:44:38,361] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.16666666666666, 71.5, 1.0, 2.0, 0.2713445375397821, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 294630.6610925209, 294630.6610925212, 93463.95625335885], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4661400.0000, 
sim time next is 4662000.0000, 
raw observation next is [18.0, 73.0, 1.0, 2.0, 0.271330701424718, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 294615.6330454065, 294615.6330454065, 93795.8601171539], 
processed observation next is [1.0, 1.0, 0.45454545454545453, 0.73, 1.0, 1.0, 0.08916337678089747, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10911690112792832, 0.10911690112792832, 0.22877039052964368], 
reward next is 0.7712, 
noisyNet noise sample is [array([-1.2737534], dtype=float32), -1.1645257]. 
=============================================
[2019-03-22 23:44:38,376] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[76.33011 ]
 [76.33126 ]
 [76.332115]
 [76.33696 ]
 [76.356476]], R is [[76.36335754]
 [76.37176514]
 [76.38102722]
 [76.39134216]
 [76.40296936]].
[2019-03-22 23:44:43,438] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 3.1213701e-36 2.2952758e-29 1.7369675e-27], sum to 1.0000
[2019-03-22 23:44:43,445] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3121
[2019-03-22 23:44:43,453] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.3953641430104596, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 443939.5993233135, 443939.5993233137, 123627.7004669477], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4767600.0000, 
sim time next is 4768200.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.3869987012530124, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 434510.9341381144, 434510.9341381144, 122879.0777390965], 
processed observation next is [1.0, 0.17391304347826086, 0.45454545454545453, 1.0, 1.0, 1.0, 0.23374837656626546, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16092997560670905, 0.16092997560670905, 0.2997050676563329], 
reward next is 0.7003, 
noisyNet noise sample is [array([0.9151949], dtype=float32), 0.028866751]. 
=============================================
[2019-03-22 23:44:44,194] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.9989298e-37 1.0000000e+00 4.9447773e-29 3.1840040e-20 3.6860091e-19], sum to 1.0000
[2019-03-22 23:44:44,202] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9475
[2019-03-22 23:44:44,211] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.4348517041375213, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 492995.6457677584, 492995.6457677584, 129815.7426434156], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4780800.0000, 
sim time next is 4781400.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4954007559871142, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 561752.2466626638, 561752.2466626638, 136056.625884002], 
processed observation next is [1.0, 0.34782608695652173, 0.5, 1.0, 1.0, 1.0, 0.3692509449838927, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20805638765283843, 0.20805638765283843, 0.3318454289853707], 
reward next is 0.6682, 
noisyNet noise sample is [array([1.0846262], dtype=float32), 0.41362587]. 
=============================================
[2019-03-22 23:44:47,281] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.2041970e-33 5.1384565e-12 4.4755658e-18 6.2126250e-12 1.0000000e+00], sum to 1.0000
[2019-03-22 23:44:47,292] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9381
[2019-03-22 23:44:47,299] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [21.0, 94.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3105774296011332, 6.9112, 6.9112, 77.3421103, 526581.29751033, 526581.29751033, 204111.9356831611], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4832400.0000, 
sim time next is 4833000.0000, 
raw observation next is [21.0, 94.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3098437237804084, 6.9112, 6.9112, 77.3421103, 525341.7001854717, 525341.7001854717, 203953.8125444226], 
processed observation next is [1.0, 0.9565217391304348, 0.5909090909090909, 0.94, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.014062462543440617, 0.0, 0.0, 0.5085185399722538, 0.1945710000686932, 0.1945710000686932, 0.4974483232790795], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2261523], dtype=float32), -0.28392965]. 
=============================================
[2019-03-22 23:44:47,308] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[39.06227 ]
 [39.160988]
 [39.134567]
 [38.9282  ]
 [40.547695]], R is [[38.85122299]
 [38.46271133]
 [38.07808304]
 [37.69730377]
 [37.32033157]].
[2019-03-22 23:45:01,072] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.3910515e-37 4.0565461e-33], sum to 1.0000
[2019-03-22 23:45:01,085] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1058
[2019-03-22 23:45:01,087] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.33333333333333, 63.83333333333334, 1.0, 2.0, 0.4185759729005124, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 475827.4721132774, 475827.4721132774, 129223.0133811333], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5082600.0000, 
sim time next is 5083200.0000, 
raw observation next is [24.0, 65.0, 1.0, 2.0, 0.4146797079580976, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 471063.2728545679, 471063.2728545679, 128565.6206473902], 
processed observation next is [0.0, 0.8695652173913043, 0.7272727272727273, 0.65, 1.0, 1.0, 0.268349634947622, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17446787883502515, 0.17446787883502515, 0.31357468450582976], 
reward next is 0.6864, 
noisyNet noise sample is [array([0.1129597], dtype=float32), 0.3509142]. 
=============================================
[2019-03-22 23:45:05,694] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-22 23:45:05,697] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-22 23:45:05,698] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-22 23:45:05,699] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-22 23:45:05,700] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-22 23:45:05,701] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:45:05,700] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:45:05,702] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-22 23:45:05,703] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:45:05,703] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:45:05,705] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:45:05,722] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run32
[2019-03-22 23:45:05,745] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run32
[2019-03-22 23:45:05,745] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run32
[2019-03-22 23:45:05,789] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run32
[2019-03-22 23:45:05,806] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run32
[2019-03-22 23:45:37,841] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.10631415], dtype=float32), -0.103490986]
[2019-03-22 23:45:37,844] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [14.50266923666667, 99.664520345, 1.0, 2.0, 0.2400835489986611, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 260664.5117269498, 260664.5117269498, 89852.1515753465]
[2019-03-22 23:45:37,847] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:45:37,850] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.42718631676625285
[2019-03-22 23:46:02,878] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.10631415], dtype=float32), -0.103490986]
[2019-03-22 23:46:02,880] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [28.9, 53.0, 1.0, 2.0, 0.8133852271138542, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 926843.6953904758, 926843.6953904758, 191546.957038004]
[2019-03-22 23:46:02,882] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:46:02,888] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.3731706e-32 1.0000000e+00 1.4724921e-28 2.8156401e-17 3.9402024e-13], sampled 0.9909743798475442
[2019-03-22 23:46:21,177] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10631415], dtype=float32), -0.103490986]
[2019-03-22 23:46:21,177] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.2, 80.0, 1.0, 2.0, 0.3708973221167883, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 415419.3743083589, 415419.3743083593, 125334.5420579741]
[2019-03-22 23:46:21,178] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:46:21,182] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.5933661e-34 6.8016369e-31], sampled 0.6719297994170174
[2019-03-22 23:46:36,897] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.10631415], dtype=float32), -0.103490986]
[2019-03-22 23:46:36,898] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.1626757, 89.10594768, 1.0, 2.0, 0.314774248430682, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 342578.7956159973, 342578.7956159973, 116774.9074355799]
[2019-03-22 23:46:36,900] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:46:36,903] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.5247268e-35 4.0046565e-32], sampled 0.03469233418414153
[2019-03-22 23:46:39,056] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.10631415], dtype=float32), -0.103490986]
[2019-03-22 23:46:39,059] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.81772779666667, 96.22208277166668, 1.0, 2.0, 0.4522144170027805, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 515791.1552794317, 515791.1552794317, 139098.2071258513]
[2019-03-22 23:46:39,061] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:46:39,066] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 6.891526e-33 3.365748e-29], sampled 0.8899637705938462
[2019-03-22 23:46:40,423] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.10631415], dtype=float32), -0.103490986]
[2019-03-22 23:46:40,424] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [28.87981790666667, 61.99676677333333, 1.0, 2.0, 0.5946894222681633, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 669800.1633545101, 669800.1633545101, 162118.8487433254]
[2019-03-22 23:46:40,427] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:46:40,430] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 3.7899630e-36 1.5299000e-28 1.5347915e-22], sampled 0.928061412973604
[2019-03-22 23:46:49,046] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.10631415], dtype=float32), -0.103490986]
[2019-03-22 23:46:49,047] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [27.13313725, 76.21207249, 1.0, 2.0, 0.6228871209192458, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 699878.499252457, 699878.4992524567, 166431.8335349342]
[2019-03-22 23:46:49,047] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:46:49,049] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0.0000000e+00 1.0000000e+00 6.3625354e-35 3.3630709e-26 2.0783065e-20], sampled 0.10048501143745703
[2019-03-22 23:46:53,873] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.1148 1683769448.3564 211.0000
[2019-03-22 23:46:53,938] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8511.5130 1773248123.2886 173.0000
[2019-03-22 23:46:53,962] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7153 1706022735.7380 462.0000
[2019-03-22 23:46:53,994] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1147 1656209757.7786 80.0000
[2019-03-22 23:46:54,025] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5599 1663815647.6096 105.0000
[2019-03-22 23:46:55,043] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 775000, evaluation results [775000.0, 8511.513039158031, 1773248123.2886405, 173.0, 9061.114669779829, 1656209757.7786272, 80.0, 8856.559925897878, 1663815647.6095803, 105.0, 8597.715314517782, 1706022735.7380106, 462.0, 8574.114802843751, 1683769448.3564365, 211.0]
[2019-03-22 23:47:00,336] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.1745351e-32 1.0000000e+00 1.3029542e-28 2.7529997e-12 7.0978545e-16], sum to 1.0000
[2019-03-22 23:47:00,346] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6869
[2019-03-22 23:47:00,351] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666666, 98.0, 1.0, 2.0, 0.2534526470295483, 1.0, 2.0, 0.2534526470295483, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 576672.2709430654, 576672.270943065, 181004.8365259165], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5262000.0000, 
sim time next is 5262600.0000, 
raw observation next is [21.58333333333334, 99.0, 1.0, 2.0, 0.5084619539386082, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 579391.3993883285, 579391.3993883285, 143683.5529981905], 
processed observation next is [1.0, 0.9130434782608695, 0.6174242424242427, 0.99, 1.0, 1.0, 0.38557744242326014, 0.0, 0.5, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21458940718086242, 0.21458940718086242, 0.3504476902394891], 
reward next is 0.6496, 
noisyNet noise sample is [array([-0.28211054], dtype=float32), 0.12494674]. 
=============================================
[2019-03-22 23:47:01,331] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.1713106e-31 1.0000000e+00 7.7646380e-22 5.4366760e-09 1.4515614e-09], sum to 1.0000
[2019-03-22 23:47:01,341] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1284
[2019-03-22 23:47:01,349] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.75, 97.0, 1.0, 2.0, 0.501996970511029, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 572350.5364314921, 572350.5364314923, 142537.1257191903], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5261400.0000, 
sim time next is 5262000.0000, 
raw observation next is [21.66666666666666, 98.0, 1.0, 2.0, 0.5058364066148405, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 576672.2709430654, 576672.2709430654, 143065.83348937], 
processed observation next is [1.0, 0.9130434782608695, 0.621212121212121, 0.98, 1.0, 1.0, 0.38229550826855063, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2135823225715057, 0.2135823225715057, 0.3489410572911464], 
reward next is 0.6511, 
noisyNet noise sample is [array([0.1581498], dtype=float32), -0.46916297]. 
=============================================
[2019-03-22 23:47:01,367] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[70.03076]
 [69.95233]
 [69.79014]
 [69.55113]
 [69.42818]], R is [[70.15343475]
 [70.10425568]
 [70.05635834]
 [70.00912476]
 [69.96264648]].
[2019-03-22 23:47:01,978] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.00000000e+00 1.00000000e+00 4.27560962e-30 4.88646938e-18
 1.26093175e-20], sum to 1.0000
[2019-03-22 23:47:01,988] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7983
[2019-03-22 23:47:01,996] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.53333333333333, 95.50000000000001, 1.0, 2.0, 0.456989340514413, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 521076.4940981691, 521076.4940981691, 134841.9180862928], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5271000.0000, 
sim time next is 5271600.0000, 
raw observation next is [20.46666666666667, 91.0, 1.0, 2.0, 0.4388699437748358, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 499331.1433509759, 499331.1433509759, 131615.3541176119], 
processed observation next is [1.0, 0.0, 0.5666666666666668, 0.91, 1.0, 1.0, 0.2985874297185447, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18493746050036144, 0.18493746050036144, 0.3210130588234436], 
reward next is 0.6790, 
noisyNet noise sample is [array([-1.2728009], dtype=float32), -0.1975973]. 
=============================================
[2019-03-22 23:47:03,377] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.4438698e-26 1.0000000e+00 8.7849880e-26 8.6617352e-14 1.1238063e-09], sum to 1.0000
[2019-03-22 23:47:03,386] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0501
[2019-03-22 23:47:03,394] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1095888.589571409 W.
[2019-03-22 23:47:03,397] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.8, 51.66666666666666, 1.0, 2.0, 0.4805657384073008, 1.0, 2.0, 0.4805657384073008, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846335610695, 1095888.589571409, 1095888.589571409, 224451.679418681], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5310600.0000, 
sim time next is 5311200.0000, 
raw observation next is [27.9, 52.33333333333334, 1.0, 2.0, 0.496682392777726, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9468420153770797, 6.952035734469702, 6.9112, 77.3283621135107, 1115065.684799101, 1101803.090857674, 253570.3743812568], 
processed observation next is [1.0, 0.4782608695652174, 0.9045454545454544, 0.5233333333333334, 1.0, 1.0, 0.3708529909721575, 0.0, 0.5, -0.25, 1.0, 0.5, 0.9240600219672569, 0.004083573446970234, 0.0, 0.5084281466833498, 0.4129872906663337, 0.40807521883617554, 0.6184643277591629], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.22133295], dtype=float32), -0.03031995]. 
=============================================
[2019-03-22 23:47:05,498] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.1527131e-34 1.0000000e+00 2.5785657e-26 4.9520703e-19 1.9911357e-23], sum to 1.0000
[2019-03-22 23:47:05,509] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3604
[2019-03-22 23:47:05,515] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.3, 46.0, 1.0, 2.0, 0.4382676588829048, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 499171.5162843823, 499171.5162843823, 132107.9648686245], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5338800.0000, 
sim time next is 5339400.0000, 
raw observation next is [27.93333333333334, 47.33333333333334, 1.0, 2.0, 0.4324641424019862, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 492333.4743460142, 492333.4743460142, 131267.3257015943], 
processed observation next is [1.0, 0.8260869565217391, 0.9060606060606063, 0.47333333333333344, 1.0, 1.0, 0.29058017800248276, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1823457312392645, 0.1823457312392645, 0.32016420902827875], 
reward next is 0.6798, 
noisyNet noise sample is [array([0.66877675], dtype=float32), -0.72544324]. 
=============================================
[2019-03-22 23:47:07,732] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.2144860e-37 1.0000000e+00 3.6542861e-33 2.9208167e-26 2.6347134e-27], sum to 1.0000
[2019-03-22 23:47:07,742] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3893
[2019-03-22 23:47:07,746] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.93333333333333, 92.0, 1.0, 2.0, 0.3518032575916891, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 389649.6757228731, 389649.6757228731, 117545.0443791511], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5470800.0000, 
sim time next is 5471400.0000, 
raw observation next is [18.11666666666667, 91.0, 1.0, 2.0, 0.3498332119065929, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 387883.0020734861, 387883.0020734858, 117557.9158269835], 
processed observation next is [1.0, 0.30434782608695654, 0.459848484848485, 0.91, 1.0, 1.0, 0.18729151488324108, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1436603711383282, 0.14366037113832808, 0.28672662396825244], 
reward next is 0.7133, 
noisyNet noise sample is [array([-0.16486242], dtype=float32), 0.55456334]. 
=============================================
[2019-03-22 23:47:24,789] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 9.612360e-38 8.836578e-34], sum to 1.0000
[2019-03-22 23:47:24,796] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8052
[2019-03-22 23:47:24,801] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.1, 67.33333333333334, 1.0, 2.0, 0.2162510434541037, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 234794.7386791859, 234794.7386791856, 74044.73906437184], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5682000.0000, 
sim time next is 5682600.0000, 
raw observation next is [16.1, 66.5, 1.0, 2.0, 0.2154935001095687, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 233972.0375768875, 233972.0375768872, 73723.28705125193], 
processed observation next is [0.0, 0.782608695652174, 0.3681818181818182, 0.665, 1.0, 1.0, 0.01936687513696085, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08665631021366203, 0.08665631021366192, 0.17981289524695593], 
reward next is 0.8202, 
noisyNet noise sample is [array([1.2489326], dtype=float32), -1.7679375]. 
=============================================
[2019-03-22 23:47:28,375] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 3.6050547e-38 5.6960724e-37 7.6770002e-34], sum to 1.0000
[2019-03-22 23:47:28,383] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4987
[2019-03-22 23:47:28,390] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.6, 44.66666666666667, 1.0, 2.0, 0.2635062868501601, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 286117.247396831, 286117.2473968313, 85982.3348165472], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5754000.0000, 
sim time next is 5754600.0000, 
raw observation next is [21.6, 44.0, 1.0, 2.0, 0.2637696549332583, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 286403.298783711, 286403.298783711, 85351.95854995919], 
processed observation next is [0.0, 0.6086956521739131, 0.6181818181818183, 0.44, 1.0, 1.0, 0.07971206866657289, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10607529584581889, 0.10607529584581889, 0.20817550865843706], 
reward next is 0.7918, 
noisyNet noise sample is [array([0.64070773], dtype=float32), -1.7132244]. 
=============================================
[2019-03-22 23:47:30,247] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.7034136e-31 8.4147240e-28 5.7524853e-26], sum to 1.0000
[2019-03-22 23:47:30,255] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2375
[2019-03-22 23:47:30,261] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.16666666666667, 59.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 198118.4631819413, 198118.463181941, 65289.58035960855], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5790000.0000, 
sim time next is 5790600.0000, 
raw observation next is [13.95, 59.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 195131.8243712529, 195131.8243712529, 64575.91349236379], 
processed observation next is [1.0, 0.0, 0.27045454545454545, 0.59, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.072271046063427, 0.072271046063427, 0.1575022280301556], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.16599815], dtype=float32), 0.27926725]. 
=============================================
[2019-03-22 23:47:31,039] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.7094306e-36 9.3263814e-34 1.7340219e-34], sum to 1.0000
[2019-03-22 23:47:31,048] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2285
[2019-03-22 23:47:31,055] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [11.6, 86.0, 1.0, 2.0, 0.3843669964197777, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 417405.1014805901, 417405.1014805898, 86249.13341938303], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5808000.0000, 
sim time next is 5808600.0000, 
raw observation next is [11.6, 86.0, 1.0, 2.0, 0.3835354935600098, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 416501.7403817616, 416501.7403817616, 86152.28665494948], 
processed observation next is [1.0, 0.21739130434782608, 0.1636363636363636, 0.86, 1.0, 1.0, 0.22941936695001225, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1542599038450969, 0.1542599038450969, 0.21012752842670604], 
reward next is 0.7899, 
noisyNet noise sample is [array([-1.1956657], dtype=float32), 0.31079572]. 
=============================================
[2019-03-22 23:47:33,388] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 2.4108385e-37 2.7750330e-33 1.2705354e-20], sum to 1.0000
[2019-03-22 23:47:33,398] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2850
[2019-03-22 23:47:33,403] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.55, 51.5, 1.0, 2.0, 0.5203649098200159, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 574606.5656912666, 574606.5656912666, 131785.7267437475], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5830200.0000, 
sim time next is 5830800.0000, 
raw observation next is [23.83333333333333, 51.66666666666667, 1.0, 2.0, 0.5467068271760119, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 606332.9451821918, 606332.9451821921, 135340.9749438456], 
processed observation next is [1.0, 0.4782608695652174, 0.7196969696969695, 0.5166666666666667, 1.0, 1.0, 0.4333835339700149, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22456775747488586, 0.22456775747488597, 0.3300999388874283], 
reward next is 0.6699, 
noisyNet noise sample is [array([0.2736058], dtype=float32), 1.7571126]. 
=============================================
[2019-03-22 23:47:37,466] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:47:37,474] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7670
[2019-03-22 23:47:37,481] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 78.0, 1.0, 2.0, 0.2751438139095884, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 298757.2491657132, 298757.2491657132, 103332.1416403499], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5902200.0000, 
sim time next is 5902800.0000, 
raw observation next is [18.26666666666667, 77.33333333333334, 1.0, 2.0, 0.2832275259413657, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 307537.4981042835, 307537.4981042838, 108018.1155877664], 
processed observation next is [1.0, 0.30434782608695654, 0.4666666666666668, 0.7733333333333334, 1.0, 1.0, 0.1040344074267071, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11390277707566057, 0.11390277707566067, 0.2634588185067473], 
reward next is 0.7365, 
noisyNet noise sample is [array([1.3644787], dtype=float32), -0.37705603]. 
=============================================
[2019-03-22 23:47:41,437] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.7224434e-36 7.5762227e-34 3.7193004e-34], sum to 1.0000
[2019-03-22 23:47:41,445] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0715
[2019-03-22 23:47:41,451] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.05, 73.5, 1.0, 2.0, 0.6727169408303043, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 754541.0401853174, 754541.0401853172, 152605.0408732859], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5992200.0000, 
sim time next is 5992800.0000, 
raw observation next is [21.23333333333333, 72.66666666666666, 1.0, 2.0, 0.696261420215147, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 781838.3346676693, 781838.3346676693, 155941.6953197869], 
processed observation next is [1.0, 0.34782608695652173, 0.6015151515151514, 0.7266666666666666, 1.0, 1.0, 0.6203267752689338, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.28956975358061826, 0.28956975358061826, 0.38034559834094367], 
reward next is 0.6197, 
noisyNet noise sample is [array([-1.2315191], dtype=float32), -1.0494858]. 
=============================================
[2019-03-22 23:47:47,713] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-22 23:47:47,714] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-22 23:47:47,715] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-22 23:47:47,717] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-22 23:47:47,717] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:47:47,716] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-22 23:47:47,722] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:47:47,720] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:47:47,719] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-22 23:47:47,725] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:47:47,729] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:47:47,747] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run33
[2019-03-22 23:47:47,748] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run33
[2019-03-22 23:47:47,767] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run33
[2019-03-22 23:47:47,810] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run33
[2019-03-22 23:47:47,831] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run33
[2019-03-22 23:48:33,824] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.14134954], dtype=float32), -0.11231462]
[2019-03-22 23:48:33,825] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.03333333333333, 69.0, 1.0, 2.0, 0.2543417186074037, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 276148.507283554, 276148.507283554, 91822.03093612788]
[2019-03-22 23:48:33,826] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:48:33,827] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.0003630711877607995
[2019-03-22 23:49:09,448] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.14134954], dtype=float32), -0.11231462]
[2019-03-22 23:49:09,449] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [16.9, 65.5, 1.0, 2.0, 0.235056617452829, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 255205.4919652527, 255205.4919652527, 82087.48893174589]
[2019-03-22 23:49:09,451] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:49:09,454] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.6426600694104152
[2019-03-22 23:49:27,745] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.14134954], dtype=float32), -0.11231462]
[2019-03-22 23:49:27,746] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [17.83333333333333, 67.66666666666667, 1.0, 2.0, 0.2517052811707765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 273285.3758103579, 273285.3758103575, 89019.01895667046]
[2019-03-22 23:49:27,747] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:49:27,752] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.0470424994184353
[2019-03-22 23:49:34,849] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2494 1773207034.4548 173.0000
[2019-03-22 23:49:35,324] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3485 1683325900.1134 214.0000
[2019-03-22 23:49:35,343] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9309 1705967916.6745 465.0000
[2019-03-22 23:49:35,491] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1147 1656209757.7786 80.0000
[2019-03-22 23:49:35,534] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5598 1663796639.0689 105.0000
[2019-03-22 23:49:36,549] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 800000, evaluation results [800000.0, 8512.249429056992, 1773207034.4547563, 173.0, 9061.114669779829, 1656209757.7786272, 80.0, 8856.559759326878, 1663796639.0688558, 105.0, 8596.930884973775, 1705967916.6744611, 465.0, 8574.348472942609, 1683325900.1133502, 214.0]
[2019-03-22 23:49:37,305] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:49:37,312] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3814
[2019-03-22 23:49:37,321] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.23333333333333, 74.33333333333334, 1.0, 2.0, 0.3047623738166435, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 330928.6801185993, 330928.6801185996, 85953.0659444408], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6510000.0000, 
sim time next is 6510600.0000, 
raw observation next is [16.6, 72.5, 1.0, 2.0, 0.3603728374510388, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 391338.0487111797, 391338.04871118, 92570.44622069082], 
processed observation next is [1.0, 0.34782608695652173, 0.390909090909091, 0.725, 1.0, 1.0, 0.2004660468137985, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14494001804117768, 0.1449400180411778, 0.22578157614802638], 
reward next is 0.7742, 
noisyNet noise sample is [array([0.05150741], dtype=float32), 0.6049196]. 
=============================================
[2019-03-22 23:49:41,996] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.49591100e-27 9.99999881e-01 9.59288594e-20 8.29961166e-08
 1.05256893e-10], sum to 1.0000
[2019-03-22 23:49:42,003] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9521
[2019-03-22 23:49:42,008] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.7, 59.33333333333334, 1.0, 2.0, 0.8030477331876708, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 897151.8221003935, 897151.8221003937, 168157.277990934], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6194400.0000, 
sim time next is 6195000.0000, 
raw observation next is [22.7, 58.16666666666666, 1.0, 2.0, 0.7919119269971999, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 882595.4293117553, 882595.4293117553, 165759.633021353], 
processed observation next is [1.0, 0.6956521739130435, 0.6681818181818181, 0.5816666666666666, 1.0, 1.0, 0.7398899087465, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3268871960413909, 0.3268871960413909, 0.4042917878569585], 
reward next is 0.5957, 
noisyNet noise sample is [array([-0.97776943], dtype=float32), 0.5905757]. 
=============================================
[2019-03-22 23:49:42,017] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[56.10258 ]
 [56.04485 ]
 [55.919186]
 [55.44804 ]
 [55.88306 ]], R is [[56.30771637]
 [56.33449936]
 [56.35832977]
 [56.38026428]
 [56.37628555]].
[2019-03-22 23:49:43,903] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 5.4466218e-38 0.0000000e+00 1.2274005e-38], sum to 1.0000
[2019-03-22 23:49:43,915] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9220
[2019-03-22 23:49:43,922] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 90.0, 1.0, 2.0, 0.380256785741901, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 428143.4395354501, 428143.4395354498, 122905.183814356], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6221400.0000, 
sim time next is 6222000.0000, 
raw observation next is [19.4, 90.0, 1.0, 2.0, 0.3803906800847105, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 428300.1522868263, 428300.1522868266, 122919.9767905589], 
processed observation next is [0.0, 0.0, 0.5181818181818181, 0.9, 1.0, 1.0, 0.2254883501058881, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15862968603215788, 0.158629686032158, 0.29980482144038756], 
reward next is 0.7002, 
noisyNet noise sample is [array([0.40650257], dtype=float32), -0.8185837]. 
=============================================
[2019-03-22 23:49:43,936] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[65.71606 ]
 [65.78878 ]
 [65.921906]
 [65.961426]
 [66.00187 ]], R is [[65.88002777]
 [65.92146301]
 [65.962677  ]
 [66.00408936]
 [66.04584503]].
[2019-03-22 23:49:49,354] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 7.075284e-38 8.814530e-33], sum to 1.0000
[2019-03-22 23:49:49,364] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7460
[2019-03-22 23:49:49,372] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.7, 85.0, 1.0, 2.0, 0.480688355695413, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 548499.9041544797, 548499.9041544797, 138931.1401921162], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6318000.0000, 
sim time next is 6318600.0000, 
raw observation next is [22.7, 85.00000000000001, 1.0, 2.0, 0.4794394293299687, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 547075.5558893878, 547075.5558893878, 138773.7109742645], 
processed observation next is [0.0, 0.13043478260869565, 0.6681818181818181, 0.8500000000000001, 1.0, 1.0, 0.34929928666246085, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20262057625532884, 0.20262057625532884, 0.3384724657908891], 
reward next is 0.6615, 
noisyNet noise sample is [array([-0.3603988], dtype=float32), 1.5344712]. 
=============================================
[2019-03-22 23:50:07,424] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:50:07,430] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6045
[2019-03-22 23:50:07,439] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 87.0, 1.0, 2.0, 0.3546811154972031, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 394626.879989803, 394626.879989803, 118498.9633035187], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6646800.0000, 
sim time next is 6647400.0000, 
raw observation next is [18.8, 87.0, 1.0, 2.0, 0.3539400499467937, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 393802.0607554178, 393802.0607554181, 118439.8755832229], 
processed observation next is [1.0, 0.9565217391304348, 0.49090909090909096, 0.87, 1.0, 1.0, 0.19242506243349208, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14585261509459918, 0.1458526150945993, 0.28887774532493393], 
reward next is 0.7111, 
noisyNet noise sample is [array([-0.8530348], dtype=float32), -1.7808076]. 
=============================================
[2019-03-22 23:50:07,814] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.5399306e-37 0.0000000e+00], sum to 1.0000
[2019-03-22 23:50:07,821] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0425
[2019-03-22 23:50:07,826] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 81.0, 1.0, 2.0, 0.3503321829841609, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 389135.5371804103, 389135.53718041, 117881.302196748], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6642000.0000, 
sim time next is 6642600.0000, 
raw observation next is [19.3, 82.0, 1.0, 2.0, 0.3510860570259114, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 389933.466036078, 389933.4660360777, 117924.5876472589], 
processed observation next is [1.0, 0.9130434782608695, 0.5136363636363637, 0.82, 1.0, 1.0, 0.18885757128238922, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14441980223558445, 0.14441980223558434, 0.2876209454811193], 
reward next is 0.7124, 
noisyNet noise sample is [array([-0.2002823], dtype=float32), 0.51637197]. 
=============================================
[2019-03-22 23:50:08,113] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.9100016e-37 0.0000000e+00], sum to 1.0000
[2019-03-22 23:50:08,121] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6304
[2019-03-22 23:50:08,127] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.1, 88.5, 1.0, 2.0, 0.3735551285688242, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 418395.6395305334, 418395.6395305331, 121235.2961611246], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6679800.0000, 
sim time next is 6680400.0000, 
raw observation next is [19.0, 89.0, 1.0, 2.0, 0.3716850397377511, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 416086.551290492, 416086.551290492, 120978.6557607885], 
processed observation next is [1.0, 0.30434782608695654, 0.5, 0.89, 1.0, 1.0, 0.21460629967218883, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15410613010758964, 0.15410613010758964, 0.29506989209948414], 
reward next is 0.7049, 
noisyNet noise sample is [array([-1.1810743], dtype=float32), 0.20895182]. 
=============================================
[2019-03-22 23:50:08,494] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 6.4255557e-37 1.8620234e-27 3.8078621e-35], sum to 1.0000
[2019-03-22 23:50:08,506] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8817
[2019-03-22 23:50:08,509] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.36666666666667, 83.16666666666666, 1.0, 2.0, 0.4017418652030438, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 453239.4138405949, 453239.4138405946, 125290.4405125337], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7062600.0000, 
sim time next is 7063200.0000, 
raw observation next is [20.0, 84.0, 1.0, 2.0, 0.3978911757420431, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 447754.3705668236, 447754.3705668236, 124335.2827988064], 
processed observation next is [1.0, 0.782608695652174, 0.5454545454545454, 0.84, 1.0, 1.0, 0.24736396967755384, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1658349520617865, 0.1658349520617865, 0.30325678731416195], 
reward next is 0.6967, 
noisyNet noise sample is [array([1.0524633], dtype=float32), 1.0632722]. 
=============================================
[2019-03-22 23:50:20,996] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:50:21,004] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3628
[2019-03-22 23:50:21,008] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.01666666666667, 50.16666666666667, 1.0, 2.0, 0.4489230770831815, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 511995.1692648393, 511995.1692648393, 134225.3021221694], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6875400.0000, 
sim time next is 6876000.0000, 
raw observation next is [28.3, 49.0, 1.0, 2.0, 0.4496585873620294, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 512856.4319574132, 512856.4319574132, 134350.9044932619], 
processed observation next is [0.0, 0.6086956521739131, 0.9227272727272727, 0.49, 1.0, 1.0, 0.31207323420253674, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18994682665089377, 0.18994682665089377, 0.3276851329103949], 
reward next is 0.6723, 
noisyNet noise sample is [array([-0.23339364], dtype=float32), -1.1240541]. 
=============================================
[2019-03-22 23:50:21,024] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[72.39512 ]
 [72.37146 ]
 [72.342575]
 [72.30647 ]
 [72.255516]], R is [[72.38374329]
 [72.33252716]
 [72.28211975]
 [72.23246765]
 [72.18358612]].
[2019-03-22 23:50:22,774] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:50:22,778] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3323
[2019-03-22 23:50:22,785] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.7, 75.5, 1.0, 2.0, 0.3967638941618714, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 448493.8240224267, 448493.8240224267, 125341.1558277779], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6911400.0000, 
sim time next is 6912000.0000, 
raw observation next is [21.6, 76.0, 1.0, 2.0, 0.3960999828481452, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 447635.6409918158, 447635.6409918158, 125216.6373911098], 
processed observation next is [0.0, 0.0, 0.6181818181818183, 0.76, 1.0, 1.0, 0.24512497856018145, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16579097814511695, 0.16579097814511695, 0.30540643266124345], 
reward next is 0.6946, 
noisyNet noise sample is [array([-0.37898996], dtype=float32), -0.41862348]. 
=============================================
[2019-03-22 23:50:22,806] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[69.86545 ]
 [69.843124]
 [69.81856 ]
 [69.79599 ]
 [69.7685  ]], R is [[69.63484192]
 [69.63278198]
 [69.63043213]
 [69.62775421]
 [69.62470245]].
[2019-03-22 23:50:23,607] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 8.485735e-36 2.055231e-34], sum to 1.0000
[2019-03-22 23:50:23,613] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1677
[2019-03-22 23:50:23,619] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.7, 73.0, 1.0, 2.0, 0.40616657910601, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 461029.0853858349, 461029.0853858349, 127467.9363543071], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6944400.0000, 
sim time next is 6945000.0000, 
raw observation next is [22.98333333333333, 72.33333333333334, 1.0, 2.0, 0.4124970964526269, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 468706.0787372441, 468706.0787372441, 128456.2558659949], 
processed observation next is [0.0, 0.391304347826087, 0.6810606060606059, 0.7233333333333334, 1.0, 1.0, 0.26562137056578355, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1735948439767571, 0.1735948439767571, 0.3133079411365729], 
reward next is 0.6867, 
noisyNet noise sample is [array([1.0801371], dtype=float32), -1.2334377]. 
=============================================
[2019-03-22 23:50:23,638] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[68.16044 ]
 [68.16487 ]
 [68.18574 ]
 [68.208534]
 [68.23475 ]], R is [[68.14385223]
 [68.15151978]
 [68.16134644]
 [68.17334747]
 [68.18750763]].
[2019-03-22 23:50:29,199] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-22 23:50:29,199] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-22 23:50:29,200] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:50:29,201] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-22 23:50:29,201] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:50:29,202] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-22 23:50:29,203] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:50:29,204] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-22 23:50:29,205] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-22 23:50:29,205] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:50:29,206] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:50:29,229] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run34
[2019-03-22 23:50:29,247] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run34
[2019-03-22 23:50:29,270] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run34
[2019-03-22 23:50:29,298] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run34
[2019-03-22 23:50:29,299] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run34
[2019-03-22 23:50:43,334] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.12127197], dtype=float32), -0.09273525]
[2019-03-22 23:50:43,335] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.49069849, 92.13880262, 1.0, 2.0, 0.3614925587407489, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 403632.2343833736, 403632.2343833739, 123978.5359833293]
[2019-03-22 23:50:43,337] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:50:43,340] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00
 1.16593105e-35], sampled 0.5304036571679853
[2019-03-22 23:51:04,420] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.12127197], dtype=float32), -0.09273525]
[2019-03-22 23:51:04,421] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [28.01666666666667, 49.33333333333334, 1.0, 2.0, 0.4816168025811256, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 549161.6696841405, 549161.6696841401, 141896.5947079282]
[2019-03-22 23:51:04,423] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:51:04,428] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0.0000000e+00 1.0000000e+00 5.4214982e-38 3.6931488e-32 9.9188594e-29], sampled 0.7757906946876838
[2019-03-22 23:51:31,097] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.12127197], dtype=float32), -0.09273525]
[2019-03-22 23:51:31,097] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.75, 75.5, 1.0, 2.0, 0.524700629631703, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 598014.0010189416, 598014.0010189413, 149760.009526589]
[2019-03-22 23:51:31,098] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:51:31,101] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 1.6393700e-38 4.8308226e-36 2.5599264e-32], sampled 0.2609339311207928
[2019-03-22 23:52:11,685] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.12127197], dtype=float32), -0.09273525]
[2019-03-22 23:52:11,687] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [17.95, 59.0, 1.0, 2.0, 0.2402128949383955, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 260804.9762078609, 260804.9762078606, 83049.59720067732]
[2019-03-22 23:52:11,689] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:52:11,692] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.17999646472625408
[2019-03-22 23:52:14,743] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.12127197], dtype=float32), -0.09273525]
[2019-03-22 23:52:14,745] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.88333333333333, 62.0, 1.0, 2.0, 0.2512859703225243, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 272844.6073602961, 272844.6073602958, 80910.63413861017]
[2019-03-22 23:52:14,746] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:52:14,749] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.15928095411408993
[2019-03-22 23:52:16,865] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5598 1663796639.0689 105.0000
[2019-03-22 23:52:16,975] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1147 1656209757.7786 80.0000
[2019-03-22 23:52:17,033] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9309 1705967916.6745 465.0000
[2019-03-22 23:52:17,065] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2492 1773187030.7201 173.0000
[2019-03-22 23:52:17,102] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-22 23:52:18,119] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 825000, evaluation results [825000.0, 8512.249193409023, 1773187030.7201214, 173.0, 9061.114669779829, 1656209757.7786272, 80.0, 8856.559759326878, 1663796639.0688558, 105.0, 8596.930884973775, 1705967916.6744611, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-22 23:52:31,614] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.2066468e-38 1.0000000e+00 7.4697397e-38 1.7316008e-21 1.3051178e-21], sum to 1.0000
[2019-03-22 23:52:31,622] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3102
[2019-03-22 23:52:31,628] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 96.0, 1.0, 2.0, 0.4507615392728437, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 512783.5124364225, 512783.5124364225, 132751.4167379587], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7620000.0000, 
sim time next is 7620600.0000, 
raw observation next is [20.0, 96.0, 1.0, 2.0, 0.4432919125899546, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 504275.2511788327, 504275.251178833, 131981.4748362347], 
processed observation next is [1.0, 0.17391304347826086, 0.5454545454545454, 0.96, 1.0, 1.0, 0.3041148907374432, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18676861154771582, 0.18676861154771593, 0.32190603618593827], 
reward next is 0.6781, 
noisyNet noise sample is [array([0.05203114], dtype=float32), -1.4040554]. 
=============================================
[2019-03-22 23:52:33,949] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.1618629e-37 1.0000000e+00 7.9536446e-32 3.7950950e-23 1.8428511e-28], sum to 1.0000
[2019-03-22 23:52:33,959] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9205
[2019-03-22 23:52:33,966] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.55, 44.5, 1.0, 2.0, 0.9281228769052476, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1036321.652059497, 1036321.652059497, 186078.9973958394], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7306200.0000, 
sim time next is 7306800.0000, 
raw observation next is [25.73333333333333, 44.0, 1.0, 2.0, 0.946288603644319, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1057946.324428792, 1057946.324428793, 189467.1445150287], 
processed observation next is [1.0, 0.5652173913043478, 0.8060606060606059, 0.44, 1.0, 1.0, 0.9328607545553987, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3918319720106637, 0.3918319720106641, 0.4621149866220212], 
reward next is 0.5379, 
noisyNet noise sample is [array([-2.6519907], dtype=float32), 0.8335427]. 
=============================================
[2019-03-22 23:52:35,540] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:52:35,550] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3273
[2019-03-22 23:52:35,558] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.56666666666667, 64.0, 1.0, 2.0, 0.3460219646549009, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 382720.0924864077, 382720.0924864077, 116888.6733455548], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7334400.0000, 
sim time next is 7335000.0000, 
raw observation next is [21.45, 65.0, 1.0, 2.0, 0.3482366799740802, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 385406.0895297232, 385406.0895297232, 117151.8298110812], 
processed observation next is [1.0, 0.9130434782608695, 0.6113636363636363, 0.65, 1.0, 1.0, 0.18529584996760023, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14274299612211971, 0.14274299612211971, 0.2857361702709298], 
reward next is 0.7143, 
noisyNet noise sample is [array([-1.0514339], dtype=float32), -1.7744054]. 
=============================================
[2019-03-22 23:52:35,569] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[69.36311]
 [69.37948]
 [69.39939]
 [69.39743]
 [69.42148]], R is [[69.35778046]
 [69.37910461]
 [69.40093231]
 [69.42311859]
 [69.44550323]].
[2019-03-22 23:52:36,506] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 8.333896e-37 0.000000e+00], sum to 1.0000
[2019-03-22 23:52:36,516] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3390
[2019-03-22 23:52:36,522] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.23333333333333, 50.33333333333333, 1.0, 2.0, 0.2931929871096225, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 318361.8561670016, 318361.8561670013, 93795.13015765889], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7753200.0000, 
sim time next is 7753800.0000, 
raw observation next is [21.41666666666667, 49.66666666666667, 1.0, 2.0, 0.297559723490116, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 323105.025991474, 323105.0259914738, 94760.36186428656], 
processed observation next is [1.0, 0.7391304347826086, 0.6098484848484851, 0.4966666666666667, 1.0, 1.0, 0.12194965436264499, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11966852814499036, 0.11966852814499031, 0.23112283381533308], 
reward next is 0.7689, 
noisyNet noise sample is [array([2.3566287], dtype=float32), 0.14077748]. 
=============================================
[2019-03-22 23:52:45,780] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.1704024e-32 9.6910898e-28 3.5455521e-22], sum to 1.0000
[2019-03-22 23:52:45,790] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4805
[2019-03-22 23:52:45,795] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.36666666666667, 97.66666666666666, 1.0, 2.0, 0.4515701834948514, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 514821.1712968913, 514821.1712968913, 134145.6738456565], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7533600.0000, 
sim time next is 7534200.0000, 
raw observation next is [20.18333333333333, 98.83333333333334, 1.0, 2.0, 0.4498093771873603, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 512743.2269326216, 512743.2269326216, 133850.8807998749], 
processed observation next is [0.0, 0.17391304347826086, 0.5537878787878786, 0.9883333333333334, 1.0, 1.0, 0.31226172148420034, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18990489886393394, 0.18990489886393394, 0.3264655629265241], 
reward next is 0.6735, 
noisyNet noise sample is [array([-0.5263098], dtype=float32), -1.2669237]. 
=============================================
[2019-03-22 23:52:48,307] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:52:48,308] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:52:48,347] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run5
[2019-03-22 23:52:50,360] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.00000000e+00 1.00000000e+00 0.00000000e+00 1.06743985e-35
 0.00000000e+00], sum to 1.0000
[2019-03-22 23:52:50,368] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0245
[2019-03-22 23:52:50,375] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 96.0, 1.0, 2.0, 0.4942522916645378, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 562303.283348729, 562303.2833487287, 137369.4274253843], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7618200.0000, 
sim time next is 7618800.0000, 
raw observation next is [20.0, 96.0, 1.0, 2.0, 0.4492539438612752, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 511081.6595593743, 511081.6595593743, 132609.6928125504], 
processed observation next is [1.0, 0.17391304347826086, 0.5454545454545454, 0.96, 1.0, 1.0, 0.31156742982659397, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.189289503540509, 0.189289503540509, 0.32343827515256196], 
reward next is 0.6766, 
noisyNet noise sample is [array([-0.38006237], dtype=float32), 0.20901963]. 
=============================================
[2019-03-22 23:52:50,695] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:52:50,697] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:52:50,737] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run5
[2019-03-22 23:52:52,404] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:52:52,412] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8707
[2019-03-22 23:52:52,417] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.2, 92.0, 1.0, 2.0, 0.3388304157663543, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 370374.5747171245, 370374.5747171245, 114710.5160800163], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 12000.0000, 
sim time next is 12600.0000, 
raw observation next is [17.15, 94.0, 1.0, 2.0, 0.3412905856755625, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 374197.0404064208, 374197.0404064211, 115291.5377216183], 
processed observation next is [1.0, 0.13043478260869565, 0.41590909090909084, 0.94, 1.0, 1.0, 0.17661323209445307, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13859149644682253, 0.13859149644682264, 0.28119887249175196], 
reward next is 0.7188, 
noisyNet noise sample is [array([-0.92544264], dtype=float32), 0.77268076]. 
=============================================
[2019-03-22 23:52:55,416] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:52:55,423] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3514
[2019-03-22 23:52:55,430] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.55, 98.5, 1.0, 2.0, 0.3865303722301818, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 435821.9960464936, 435821.9960464934, 123783.3296016119], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7702200.0000, 
sim time next is 7702800.0000, 
raw observation next is [18.46666666666667, 99.0, 1.0, 2.0, 0.3847707133363872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 433706.648248483, 433706.6482484833, 123556.1284471774], 
processed observation next is [1.0, 0.13043478260869565, 0.4757575757575758, 0.99, 1.0, 1.0, 0.23096339167048396, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1606320919438826, 0.1606320919438827, 0.3013564108467741], 
reward next is 0.6986, 
noisyNet noise sample is [array([0.46058837], dtype=float32), 0.18026385]. 
=============================================
[2019-03-22 23:52:56,812] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:52:56,820] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6737
[2019-03-22 23:52:56,824] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.31666666666667, 64.16666666666666, 1.0, 2.0, 0.5693184755325924, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 619152.7825665998, 619152.7825665998, 133606.6788435992], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7725000.0000, 
sim time next is 7725600.0000, 
raw observation next is [20.5, 63.0, 1.0, 2.0, 0.5725455457118394, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 622777.9667844238, 622777.9667844238, 133958.6089821036], 
processed observation next is [1.0, 0.43478260869565216, 0.5681818181818182, 0.63, 1.0, 1.0, 0.46568193213979914, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23065850621645326, 0.23065850621645326, 0.32672831459049656], 
reward next is 0.6733, 
noisyNet noise sample is [array([0.27400097], dtype=float32), -0.94938713]. 
=============================================
[2019-03-22 23:53:01,825] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:53:01,835] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2490
[2019-03-22 23:53:01,842] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 88.0, 1.0, 2.0, 0.2021783428299338, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 219511.845226851, 219511.8452268513, 73345.06017512913], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 180000.0000, 
sim time next is 180600.0000, 
raw observation next is [13.83333333333333, 89.00000000000001, 1.0, 2.0, 0.2008235813382162, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 218040.6053062343, 218040.6053062343, 73038.65774945846], 
processed observation next is [0.0, 0.08695652173913043, 0.265151515151515, 0.8900000000000001, 1.0, 1.0, 0.0010294766727702437, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08075577974304975, 0.08075577974304975, 0.178143067681606], 
reward next is 0.8219, 
noisyNet noise sample is [array([0.19206958], dtype=float32), -0.7249175]. 
=============================================
[2019-03-22 23:53:03,990] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:53:03,990] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:53:04,045] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run5
[2019-03-22 23:53:04,115] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:53:04,124] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4902
[2019-03-22 23:53:04,131] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 75.5, 1.0, 2.0, 0.3139364942141804, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 344346.3121472817, 344346.3121472817, 113367.0955649175], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7883400.0000, 
sim time next is 7884000.0000, 
raw observation next is [19.4, 76.0, 1.0, 2.0, 0.3151232930001099, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 346049.1007995286, 346049.1007995283, 113600.9403405605], 
processed observation next is [1.0, 0.2608695652173913, 0.5181818181818181, 0.76, 1.0, 1.0, 0.14390411625013733, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12816633362945504, 0.12816633362945493, 0.2770754642452695], 
reward next is 0.7229, 
noisyNet noise sample is [array([0.18953021], dtype=float32), -1.4207525]. 
=============================================
[2019-03-22 23:53:04,145] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[73.82487 ]
 [73.821144]
 [73.8013  ]
 [73.79831 ]
 [73.75326 ]], R is [[73.81124115]
 [73.79662323]
 [73.78274536]
 [73.76947021]
 [73.75643921]].
[2019-03-22 23:53:04,681] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:53:04,682] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:53:04,715] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run5
[2019-03-22 23:53:07,660] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:53:07,661] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:53:07,699] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run5
[2019-03-22 23:53:08,027] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:53:08,028] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:53:08,041] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run5
[2019-03-22 23:53:08,388] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:53:08,389] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:53:08,412] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run5
[2019-03-22 23:53:08,489] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:53:08,490] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:53:08,510] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run5
[2019-03-22 23:53:08,593] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:53:08,593] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:53:08,604] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run5
[2019-03-22 23:53:08,740] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:53:08,741] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:53:08,754] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run5
[2019-03-22 23:53:08,846] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:53:08,847] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:53:08,854] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run5
[2019-03-22 23:53:08,988] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:53:08,989] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:53:08,997] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:53:08,998] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:53:08,999] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run5
[2019-03-22 23:53:09,017] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:53:09,019] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:53:09,028] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run5
[2019-03-22 23:53:09,045] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:53:09,046] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:53:09,046] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run5
[2019-03-22 23:53:09,050] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:53:09,046] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:53:09,053] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run5
[2019-03-22 23:53:09,076] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run5
[2019-03-22 23:53:09,669] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-22 23:53:09,674] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-22 23:53:09,675] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:53:09,676] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run35
[2019-03-22 23:53:09,695] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-22 23:53:09,696] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:53:09,697] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run35
[2019-03-22 23:53:09,722] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-22 23:53:09,723] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:53:09,724] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-22 23:53:09,725] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:53:09,726] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run35
[2019-03-22 23:53:09,743] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-22 23:53:09,744] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:53:09,745] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run35
[2019-03-22 23:53:09,822] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run35
[2019-03-22 23:53:23,043] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.03660117], dtype=float32), -0.042737916]
[2019-03-22 23:53:23,044] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.48333333333333, 42.5, 1.0, 2.0, 0.3948404320536469, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 445488.9129230489, 445488.9129230485, 129015.289528677]
[2019-03-22 23:53:23,045] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:53:23,048] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.8815578447187657
[2019-03-22 23:53:23,387] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.03660117], dtype=float32), -0.042737916]
[2019-03-22 23:53:23,388] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.2, 64.0, 1.0, 2.0, 0.3652719402805684, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 407622.5795366474, 407622.5795366471, 124186.7867109967]
[2019-03-22 23:53:23,390] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:53:23,392] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.9375221710117936
[2019-03-22 23:53:45,940] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.03660117], dtype=float32), -0.042737916]
[2019-03-22 23:53:45,941] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.66666666666667, 61.33333333333334, 1.0, 2.0, 0.2722952579524694, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 295663.2837960519, 295663.2837960519, 93969.29366637472]
[2019-03-22 23:53:45,942] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:53:45,945] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.3317753374229727
[2019-03-22 23:54:22,010] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.03660117], dtype=float32), -0.042737916]
[2019-03-22 23:54:22,011] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.0, 94.0, 1.0, 2.0, 0.8650348871531187, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 986667.3008319283, 986667.3008319283, 195154.2851728709]
[2019-03-22 23:54:22,013] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:54:22,017] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 2.2342855e-36 5.3931440e-35 6.5408211e-31], sampled 0.12265260783116683
[2019-03-22 23:54:24,788] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.03660117], dtype=float32), -0.042737916]
[2019-03-22 23:54:24,789] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.9, 71.0, 1.0, 2.0, 0.3856943682009786, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 434046.127764455, 434046.127764455, 127592.1925211134]
[2019-03-22 23:54:24,791] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:54:24,794] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.5451713784440103
[2019-03-22 23:54:35,109] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.03660117], dtype=float32), -0.042737916]
[2019-03-22 23:54:35,110] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.78333333333333, 86.16666666666667, 1.0, 2.0, 0.4038463609519071, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 458129.5891245663, 458129.5891245659, 131388.2569854233]
[2019-03-22 23:54:35,111] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:54:35,114] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.7827877612538381
[2019-03-22 23:54:57,644] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9309 1705967916.6745 465.0000
[2019-03-22 23:54:57,757] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-22 23:54:57,885] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1148 1656229146.4555 80.0000
[2019-03-22 23:54:57,915] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5599 1663815647.6096 105.0000
[2019-03-22 23:54:57,980] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-22 23:54:58,995] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 850000, evaluation results [850000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.114827412715, 1656229146.4555063, 80.0, 8856.559925897878, 1663815647.6095803, 105.0, 8596.930884973775, 1705967916.6744611, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-22 23:55:06,311] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:55:06,320] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0941
[2019-03-22 23:55:06,327] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.5, 74.5, 1.0, 2.0, 0.2256779712720656, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 245032.6110658438, 245032.6110658441, 75766.57837474128], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 167400.0000, 
sim time next is 168000.0000, 
raw observation next is [15.33333333333333, 75.33333333333333, 1.0, 2.0, 0.2238209589298302, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 243015.833551317, 243015.833551317, 75388.60300259451], 
processed observation next is [1.0, 0.9565217391304348, 0.3333333333333332, 0.7533333333333333, 1.0, 1.0, 0.029776198662287735, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09000586427826555, 0.09000586427826555, 0.1838746414697427], 
reward next is 0.8161, 
noisyNet noise sample is [array([1.1848669], dtype=float32), -0.013178071]. 
=============================================
[2019-03-22 23:55:06,340] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[80.66186 ]
 [80.678986]
 [80.681335]
 [80.69404 ]
 [80.67649 ]], R is [[80.64997101]
 [80.65867615]
 [80.66629791]
 [80.67277527]
 [80.67816162]].
[2019-03-22 23:55:09,545] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 9.193815e-33 0.000000e+00 7.883876e-37], sum to 1.0000
[2019-03-22 23:55:09,555] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5419
[2019-03-22 23:55:09,560] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.83333333333334, 83.00000000000001, 1.0, 2.0, 0.2699893623549307, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 293158.7445951381, 293158.7445951384, 94393.69028527121], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 609000.0000, 
sim time next is 609600.0000, 
raw observation next is [16.66666666666667, 84.0, 1.0, 2.0, 0.2685948626334028, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 291644.1206068355, 291644.1206068358, 93632.45578171941], 
processed observation next is [1.0, 0.043478260869565216, 0.39393939393939414, 0.84, 1.0, 1.0, 0.08574357829175351, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10801634096549464, 0.10801634096549474, 0.22837184337004734], 
reward next is 0.7716, 
noisyNet noise sample is [array([0.5639541], dtype=float32), -0.9041499]. 
=============================================
[2019-03-22 23:55:13,083] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:55:13,091] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4269
[2019-03-22 23:55:13,098] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.33333333333333, 90.0, 1.0, 2.0, 0.2011668168460657, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 218413.3507778091, 218413.3507778091, 74934.44187954202], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 423600.0000, 
sim time next is 424200.0000, 
raw observation next is [14.16666666666667, 92.0, 1.0, 2.0, 0.2041997106052938, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 221707.0125621005, 221707.0125621002, 75397.84862086344], 
processed observation next is [1.0, 0.9130434782608695, 0.28030303030303044, 0.92, 1.0, 1.0, 0.005249638256617228, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08211370835633353, 0.0821137083563334, 0.18389719175820352], 
reward next is 0.8161, 
noisyNet noise sample is [array([0.43149933], dtype=float32), 0.0023020892]. 
=============================================
[2019-03-22 23:55:13,156] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:55:13,167] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7181
[2019-03-22 23:55:13,171] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.0, 94.0, 1.0, 2.0, 0.2463069781024801, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 267436.9649127378, 267436.9649127378, 85732.40060586583], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 252000.0000, 
sim time next is 252600.0000, 
raw observation next is [15.0, 94.00000000000001, 1.0, 2.0, 0.2437072559932109, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 264613.4520316194, 264613.4520316191, 85422.90767882968], 
processed observation next is [0.0, 0.9565217391304348, 0.3181818181818182, 0.9400000000000002, 1.0, 1.0, 0.054634069991513594, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0980049822339331, 0.098004982233933, 0.20834855531421873], 
reward next is 0.7917, 
noisyNet noise sample is [array([0.27261433], dtype=float32), -1.1427792]. 
=============================================
[2019-03-22 23:55:15,006] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:55:15,018] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8059
[2019-03-22 23:55:15,022] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.83333333333333, 95.0, 1.0, 2.0, 0.2269581269975035, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 246422.907870062, 246422.9078700623, 83007.64098141323], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 287400.0000, 
sim time next is 288000.0000, 
raw observation next is [15.0, 94.0, 1.0, 2.0, 0.2284793649009284, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 248075.034067205, 248075.0340672053, 83661.67162527377], 
processed observation next is [0.0, 0.34782608695652173, 0.3181818181818182, 0.94, 1.0, 1.0, 0.03559920612616049, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09187964224711297, 0.09187964224711308, 0.20405285762261893], 
reward next is 0.7959, 
noisyNet noise sample is [array([-0.07632412], dtype=float32), 0.16549516]. 
=============================================
[2019-03-22 23:55:15,030] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[72.41563 ]
 [72.414055]
 [72.406334]
 [72.395706]
 [72.38569 ]], R is [[72.53038788]
 [72.60262299]
 [72.67580414]
 [72.74996185]
 [72.82495117]].
[2019-03-22 23:55:15,905] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:55:15,914] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3035
[2019-03-22 23:55:15,918] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 75.5, 1.0, 2.0, 0.4235049734200075, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 481386.7778962652, 481386.7778962652, 129666.7031989274], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 779400.0000, 
sim time next is 780000.0000, 
raw observation next is [22.33333333333334, 76.33333333333334, 1.0, 2.0, 0.4230024210718045, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 480697.6906396446, 480697.6906396446, 129518.3513997626], 
processed observation next is [0.0, 0.0, 0.6515151515151518, 0.7633333333333334, 1.0, 1.0, 0.2787530263397556, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1780361817183869, 0.1780361817183869, 0.31589841804820146], 
reward next is 0.6841, 
noisyNet noise sample is [array([0.8558804], dtype=float32), 2.2634363]. 
=============================================
[2019-03-22 23:55:15,930] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[90.64469 ]
 [91.06683 ]
 [91.524605]
 [92.19121 ]
 [93.02214 ]], R is [[90.12137604]
 [89.90390015]
 [89.68812561]
 [89.47386932]
 [89.26103973]].
[2019-03-22 23:55:17,889] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:55:17,898] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3130
[2019-03-22 23:55:17,902] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.0, 76.0, 1.0, 2.0, 0.3914037029598057, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 425049.9853888366, 425049.9853888364, 86124.05385047401], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 357600.0000, 
sim time next is 358200.0000, 
raw observation next is [12.0, 76.0, 1.0, 2.0, 0.3908563955191692, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 424455.3702577138, 424455.3702577138, 86054.00842794692], 
processed observation next is [1.0, 0.13043478260869565, 0.18181818181818182, 0.76, 1.0, 1.0, 0.23857049439896144, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15720569268804213, 0.15720569268804213, 0.20988782543401688], 
reward next is 0.7901, 
noisyNet noise sample is [array([0.23515448], dtype=float32), -0.8185829]. 
=============================================
[2019-03-22 23:55:37,360] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:55:37,368] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8492
[2019-03-22 23:55:37,375] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.66666666666667, 74.66666666666667, 1.0, 2.0, 0.3600831026558202, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 402240.5332759476, 402240.5332759476, 119623.6659494875], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 688200.0000, 
sim time next is 688800.0000, 
raw observation next is [20.33333333333334, 76.33333333333334, 1.0, 2.0, 0.3578492893087705, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 399243.5721201141, 399243.5721201141, 119219.4990833936], 
processed observation next is [1.0, 1.0, 0.5606060606060609, 0.7633333333333334, 1.0, 1.0, 0.19731161163596314, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14786798967411635, 0.14786798967411635, 0.29077926605705756], 
reward next is 0.7092, 
noisyNet noise sample is [array([-0.08866471], dtype=float32), -0.3474985]. 
=============================================
[2019-03-22 23:55:37,613] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:55:37,621] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2895
[2019-03-22 23:55:37,627] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.83333333333334, 83.83333333333334, 1.0, 2.0, 0.3430907700542853, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 379844.7589729943, 379844.7589729946, 116808.903981164], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 691800.0000, 
sim time next is 692400.0000, 
raw observation next is [18.66666666666667, 84.66666666666667, 1.0, 2.0, 0.3409301821398987, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 377059.6369506057, 377059.6369506057, 116487.7460345273], 
processed observation next is [1.0, 0.0, 0.4848484848484851, 0.8466666666666667, 1.0, 1.0, 0.17616272767487332, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13965171738911322, 0.13965171738911322, 0.2841164537427495], 
reward next is 0.7159, 
noisyNet noise sample is [array([-1.1372515], dtype=float32), 1.9146079]. 
=============================================
[2019-03-22 23:55:40,994] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.9921285e-33 1.9999905e-29 3.7088470e-25], sum to 1.0000
[2019-03-22 23:55:41,002] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5875
[2019-03-22 23:55:41,007] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 65.0, 1.0, 2.0, 0.4881343267555268, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 556894.8919247905, 556894.8919247901, 140256.09526002], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 907200.0000, 
sim time next is 907800.0000, 
raw observation next is [25.5, 67.16666666666667, 1.0, 2.0, 0.4856384270775086, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 554101.0813451242, 554101.0813451242, 139784.6981616789], 
processed observation next is [0.0, 0.5217391304347826, 0.7954545454545454, 0.6716666666666667, 1.0, 1.0, 0.3570480338468857, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20522262272041636, 0.20522262272041636, 0.34093828819921684], 
reward next is 0.6591, 
noisyNet noise sample is [array([0.46272993], dtype=float32), -0.030181866]. 
=============================================
[2019-03-22 23:55:42,945] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:55:42,958] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2028
[2019-03-22 23:55:42,962] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 88.00000000000001, 1.0, 2.0, 0.3986569959993617, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 450470.500832469, 450470.500832469, 125417.1214424027], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 785400.0000, 
sim time next is 786000.0000, 
raw observation next is [20.0, 88.0, 1.0, 2.0, 0.3980543219520277, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 449777.8037989632, 449777.8037989632, 125355.3590414407], 
processed observation next is [0.0, 0.08695652173913043, 0.5454545454545454, 0.88, 1.0, 1.0, 0.24756790244003463, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16658437177739377, 0.16658437177739377, 0.30574477814985535], 
reward next is 0.6943, 
noisyNet noise sample is [array([0.33416456], dtype=float32), -0.33841825]. 
=============================================
[2019-03-22 23:55:42,979] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[69.726395]
 [69.81817 ]
 [69.867004]
 [69.86859 ]
 [69.839005]], R is [[69.53314209]
 [69.53192139]
 [69.53005981]
 [69.5265274 ]
 [69.52136993]].
[2019-03-22 23:55:43,681] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:55:43,693] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8057
[2019-03-22 23:55:43,699] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 55.0, 1.0, 2.0, 0.531194505350845, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 604198.2683923801, 604198.2683923803, 147286.7435828523], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 835800.0000, 
sim time next is 836400.0000, 
raw observation next is [29.0, 55.0, 1.0, 2.0, 0.5298450363106281, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 602663.7507349009, 602663.7507349009, 147118.3968395567], 
processed observation next is [0.0, 0.6956521739130435, 0.9545454545454546, 0.55, 1.0, 1.0, 0.41230629538828506, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22320879656848183, 0.22320879656848183, 0.35882535814526023], 
reward next is 0.6412, 
noisyNet noise sample is [array([-0.8541857], dtype=float32), -2.1591344]. 
=============================================
[2019-03-22 23:55:45,164] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:55:45,176] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1102
[2019-03-22 23:55:45,180] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.16666666666667, 87.16666666666667, 1.0, 2.0, 0.4076093213860184, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 460796.874983707, 460796.8749837073, 126362.7373423741], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 861000.0000, 
sim time next is 861600.0000, 
raw observation next is [20.33333333333334, 86.33333333333334, 1.0, 2.0, 0.4074473655745044, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 460845.7517401295, 460845.7517401298, 126487.5470642552], 
processed observation next is [0.0, 1.0, 0.5606060606060609, 0.8633333333333334, 1.0, 1.0, 0.2593092069681305, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1706836117556035, 0.17068361175560362, 0.30850621235184195], 
reward next is 0.6915, 
noisyNet noise sample is [array([-0.9956252], dtype=float32), 0.2201377]. 
=============================================
[2019-03-22 23:55:46,638] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:55:46,650] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5355
[2019-03-22 23:55:46,657] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 94.0, 1.0, 2.0, 0.41987497021637, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 476957.1112210065, 476957.1112210065, 129061.6418138541], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1321200.0000, 
sim time next is 1321800.0000, 
raw observation next is [20.33333333333334, 94.00000000000001, 1.0, 2.0, 0.4480783693847389, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 509752.1005246878, 509752.1005246875, 132497.9028448156], 
processed observation next is [1.0, 0.30434782608695654, 0.5606060606060609, 0.9400000000000002, 1.0, 1.0, 0.3100979617309236, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1887970742684029, 0.18879707426840278, 0.3231656166946722], 
reward next is 0.6768, 
noisyNet noise sample is [array([-1.040003], dtype=float32), -0.67312026]. 
=============================================
[2019-03-22 23:55:51,542] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-22 23:55:51,544] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-22 23:55:51,544] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:55:51,546] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-22 23:55:51,549] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:55:51,550] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-22 23:55:51,552] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-22 23:55:51,554] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:55:51,555] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:55:51,552] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-22 23:55:51,557] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:55:51,569] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run36
[2019-03-22 23:55:51,591] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run36
[2019-03-22 23:55:51,593] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run36
[2019-03-22 23:55:51,611] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run36
[2019-03-22 23:55:51,655] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run36
[2019-03-22 23:55:56,559] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.28617972], dtype=float32), 0.031024802]
[2019-03-22 23:55:56,562] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.66666666666667, 44.5, 1.0, 2.0, 0.2428107824801744, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 263639.8115714522, 263639.8115714525, 77047.3411479671]
[2019-03-22 23:55:56,565] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:55:56,571] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.6901221370752673
[2019-03-22 23:56:00,486] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.28617972], dtype=float32), 0.031024802]
[2019-03-22 23:56:00,488] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.76768779, 69.79145202999999, 1.0, 2.0, 0.3932264669581655, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 436444.1581301268, 436444.1581301264, 125551.7064330988]
[2019-03-22 23:56:00,489] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:56:00,492] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.6859934895267925
[2019-03-22 23:56:01,951] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.28617972], dtype=float32), 0.031024802]
[2019-03-22 23:56:01,952] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [24.47021263666667, 61.21201806666667, 1.0, 2.0, 0.4238877272600762, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 480881.0828924395, 480881.0828924392, 133311.9500956451]
[2019-03-22 23:56:01,955] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:56:01,957] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.6515568901879054
[2019-03-22 23:56:27,036] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.28617972], dtype=float32), 0.031024802]
[2019-03-22 23:56:27,038] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.31666666666667, 78.5, 1.0, 2.0, 0.4794043650970952, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 546941.1090636455, 546941.1090636455, 142469.7509944109]
[2019-03-22 23:56:27,039] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:56:27,041] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.026401246200572825
[2019-03-22 23:56:27,632] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.28617972], dtype=float32), 0.031024802]
[2019-03-22 23:56:27,633] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.4, 82.0, 1.0, 2.0, 0.3522753489609249, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 392063.5171252995, 392063.5171252993, 118355.4410452336]
[2019-03-22 23:56:27,634] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:56:27,637] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.15229251932732701
[2019-03-22 23:56:59,325] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.28617972], dtype=float32), 0.031024802]
[2019-03-22 23:56:59,326] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.4, 51.33333333333333, 1.0, 2.0, 0.2849507405916038, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 309390.4440358506, 309390.4440358503, 100568.7876369121]
[2019-03-22 23:56:59,328] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:56:59,331] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.4377121834925223
[2019-03-22 23:57:01,523] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.28617972], dtype=float32), 0.031024802]
[2019-03-22 23:57:01,523] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [25.06563587666667, 56.66476692000001, 1.0, 2.0, 0.5968274907638561, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 676630.3563285196, 676630.3563285196, 151785.6880769579]
[2019-03-22 23:57:01,524] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:57:01,528] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.6924068812957527
[2019-03-22 23:57:13,611] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.28617972], dtype=float32), 0.031024802]
[2019-03-22 23:57:13,612] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [26.31600992333333, 72.04154212, 1.0, 2.0, 0.5347166796747116, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 606924.2254746928, 606924.2254746924, 152660.9454988916]
[2019-03-22 23:57:13,614] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:57:13,617] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.8966051304605333
[2019-03-22 23:57:20,300] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.28617972], dtype=float32), 0.031024802]
[2019-03-22 23:57:20,302] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.90398016333333, 78.27129496166667, 1.0, 2.0, 0.580736233592337, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 662505.1926775912, 662505.1926775909, 154086.9141744304]
[2019-03-22 23:57:20,303] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:57:20,305] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.4955532955315215
[2019-03-22 23:57:25,705] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.28617972], dtype=float32), 0.031024802]
[2019-03-22 23:57:25,707] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [14.0, 81.66666666666667, 1.0, 2.0, 0.2036498208738833, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 221109.8416890171, 221109.8416890168, 71891.3873732303]
[2019-03-22 23:57:25,708] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:57:25,709] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.9081729368727278
[2019-03-22 23:57:28,644] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.28617972], dtype=float32), 0.031024802]
[2019-03-22 23:57:28,647] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.06815658333333, 85.90507715000001, 1.0, 2.0, 0.4397140028163821, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 501310.333806242, 501310.3338062417, 137321.6308016318]
[2019-03-22 23:57:28,648] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:57:28,650] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.09642146758872938
[2019-03-22 23:57:34,010] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-22 23:57:34,303] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-22 23:57:34,343] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5599 1663815647.6096 105.0000
[2019-03-22 23:57:34,407] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3485 1683325900.1134 214.0000
[2019-03-22 23:57:34,508] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-22 23:57:35,524] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 875000, evaluation results [875000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8856.559925897878, 1663815647.6095803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8574.348472942609, 1683325900.1133502, 214.0]
[2019-03-22 23:57:42,701] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:57:42,715] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1148
[2019-03-22 23:57:42,723] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 68.0, 1.0, 2.0, 0.5352648060348963, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 584083.2482022295, 584083.2482022295, 130943.3937046399], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1076400.0000, 
sim time next is 1077000.0000, 
raw observation next is [20.16666666666667, 67.33333333333334, 1.0, 2.0, 0.5077212812016749, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 554917.679269824, 554917.679269824, 128648.111976205], 
processed observation next is [1.0, 0.4782608695652174, 0.5530303030303032, 0.6733333333333335, 1.0, 1.0, 0.3846516015020936, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20552506639623108, 0.20552506639623108, 0.31377588286879265], 
reward next is 0.6862, 
noisyNet noise sample is [array([-0.35632882], dtype=float32), 0.19239306]. 
=============================================
[2019-03-22 23:57:42,732] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[64.06165]
 [64.05118]
 [63.78925]
 [63.48183]
 [63.27471]], R is [[64.3860321 ]
 [64.42279816]
 [64.46762085]
 [64.51070404]
 [64.54858398]].
[2019-03-22 23:57:48,855] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:57:48,865] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8552
[2019-03-22 23:57:48,871] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.4099865123135145, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 464760.4840604985, 464760.4840604988, 127395.7751818506], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1225800.0000, 
sim time next is 1226400.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4091689747754452, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 463831.2561950829, 463831.2561950831, 127317.0055032597], 
processed observation next is [1.0, 0.17391304347826086, 0.5, 1.0, 1.0, 1.0, 0.2614612184693065, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.171789354146327, 0.17178935414632707, 0.31052928171526756], 
reward next is 0.6895, 
noisyNet noise sample is [array([-1.8774903], dtype=float32), -0.3984167]. 
=============================================
[2019-03-22 23:57:50,534] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.1299028e-37 1.0532412e-30 6.1255307e-38], sum to 1.0000
[2019-03-22 23:57:50,541] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0528
[2019-03-22 23:57:50,547] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.5, 88.5, 1.0, 2.0, 0.4726254261312315, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 539054.171994824, 539054.1719948243, 136791.0029858685], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1215000.0000, 
sim time next is 1215600.0000, 
raw observation next is [20.66666666666666, 90.33333333333334, 1.0, 2.0, 0.4527535463168793, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 515420.719629058, 515420.719629058, 133318.3911050434], 
processed observation next is [1.0, 0.043478260869565216, 0.5757575757575755, 0.9033333333333334, 1.0, 1.0, 0.3159419328960991, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19089656282557702, 0.19089656282557702, 0.3251668075732766], 
reward next is 0.6748, 
noisyNet noise sample is [array([0.41507447], dtype=float32), -1.9164604]. 
=============================================
[2019-03-22 23:57:50,748] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.6274217e-35 3.3062554e-37], sum to 1.0000
[2019-03-22 23:57:50,759] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3365
[2019-03-22 23:57:50,765] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.4360682108899899, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 494360.4383644059, 494360.4383644059, 129925.0117971821], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1221000.0000, 
sim time next is 1221600.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4125276860313772, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 467658.9076647232, 467658.9076647229, 127648.0980897031], 
processed observation next is [1.0, 0.13043478260869565, 0.5, 1.0, 1.0, 1.0, 0.26565960753922147, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17320700283878637, 0.17320700283878626, 0.31133682460903195], 
reward next is 0.6887, 
noisyNet noise sample is [array([0.50034463], dtype=float32), -0.21726543]. 
=============================================
[2019-03-22 23:57:51,796] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 8.9636501e-35 8.1101446e-32 1.8004206e-30], sum to 1.0000
[2019-03-22 23:57:51,807] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4721
[2019-03-22 23:57:51,811] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.7468624646131665, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 851888.2817081978, 851888.2817081978, 175685.3793948263], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1239600.0000, 
sim time next is 1240200.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.8664473313985614, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 988316.718605617, 988316.7186056172, 195346.4174840604], 
processed observation next is [1.0, 0.34782608695652173, 0.6363636363636364, 0.94, 1.0, 1.0, 0.8330591642482018, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3660432291131915, 0.36604322911319154, 0.4764546767903912], 
reward next is 0.5235, 
noisyNet noise sample is [array([-0.9657023], dtype=float32), 0.20826383]. 
=============================================
[2019-03-22 23:57:51,937] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.7869147e-37 1.0000000e+00 3.0515166e-30 2.0438585e-16 1.4512911e-19], sum to 1.0000
[2019-03-22 23:57:51,943] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2963
[2019-03-22 23:57:51,948] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.8788403882652275, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1002401.101332834, 1002401.101332834, 197584.1189473901], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1242000.0000, 
sim time next is 1242600.0000, 
raw observation next is [22.33333333333334, 91.33333333333334, 1.0, 2.0, 0.9960317095720309, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.335767632339839, 6.9112, 77.32762103376, 1274175.183528612, 1136285.802626154, 219105.9657126178], 
processed observation next is [1.0, 0.391304347826087, 0.6515151515151518, 0.9133333333333334, 1.0, 1.0, 0.9950396369650385, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.04245676323398388, 0.0, 0.5084232741399013, 0.47191673464022665, 0.4208465935652422, 0.534404794421019], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.1535546], dtype=float32), -0.62244207]. 
=============================================
[2019-03-22 23:57:57,584] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 6.6907591e-28 1.6287375e-21 7.5563535e-22], sum to 1.0000
[2019-03-22 23:57:57,591] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7646
[2019-03-22 23:57:57,597] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 88.0, 1.0, 2.0, 0.4725131786463901, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 539127.2168520706, 539127.2168520706, 137374.6078489301], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1377000.0000, 
sim time next is 1377600.0000, 
raw observation next is [22.0, 88.0, 1.0, 2.0, 0.4723908245916151, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 538987.4454171299, 538987.4454171297, 137360.7091459497], 
processed observation next is [1.0, 0.9565217391304348, 0.6363636363636364, 0.88, 1.0, 1.0, 0.3404885307395188, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1996249797841222, 0.1996249797841221, 0.33502611986817], 
reward next is 0.6650, 
noisyNet noise sample is [array([0.07663823], dtype=float32), 0.06526815]. 
=============================================
[2019-03-22 23:57:58,135] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.00000000e+00 1.00000000e+00 3.84104534e-31 1.22363629e-17
 1.10106164e-16], sum to 1.0000
[2019-03-22 23:57:58,145] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4484
[2019-03-22 23:57:58,152] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1414551.227276963 W.
[2019-03-22 23:57:58,160] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.5, 79.5, 1.0, 2.0, 0.6289596501671024, 1.0, 1.0, 0.6289596501671024, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1414551.227276963, 1414551.227276963, 270287.2278161202], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1348200.0000, 
sim time next is 1348800.0000, 
raw observation next is [26.0, 82.66666666666666, 1.0, 2.0, 0.7059068701574247, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9865530188920543, 6.911199999999999, 6.9112, 77.32846344354104, 1342006.509459971, 1342006.509459972, 300672.6356712496], 
processed observation next is [1.0, 0.6086956521739131, 0.8181818181818182, 0.8266666666666665, 1.0, 1.0, 0.6323835876967809, 0.0, 0.5, -0.25, 1.0, 0.5, 0.9807900269886491, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.4970394479481374, 0.49703944794813776, 0.7333478918810966], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.3650515], dtype=float32), 0.861794]. 
=============================================
