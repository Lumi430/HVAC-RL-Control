Using TensorFlow backend.
[2019-03-20 15:22:19,021] A3C_AGENT_MAIN INFO:Namespace(action_repeat_n=1, action_space='part3_v1', activation='linear', agent_num=5, check_args_only=False, clip_norm=5.0, debug_log_prob=0.0005, decay_steps=1000000, dropout_prob=0.0, end_e=0.0, env='Part3-NA-Pit-Train-v1', eval_act_func='part3_pit_det_v1', eval_env_res_max_keep=50, eval_epi_num=1, eval_freq=25000, forecast_dim=0, gamma=0.99, h_decay_bounds=[], h_regu_frac=[0.0], init_e=0.0, isNoisyNet=True, isNoisyNetEval_rmNoise=True, is_greedy_policy=False, is_learning_rate_decay_staircase=False, is_warm_start=False, job_mode='Train', learning_rate=0.001, learning_rate_decay_rate=1.0, learning_rate_decay_steps=100000, max_interactions=2500000, metric_func='part3_v1', model_dir='None', model_param=[19, 1], model_type='nn', num_threads=16, output='./Part3-NA-Pit-Train-v1-res1', p_loss_frac=1.0, raw_state_prcs_func='cslDx_1', reward_func='part3_v3', rmsprop_decay=0.99, rmsprop_epsil=1e-10, rmsprop_momet=0.0, rwd_e_para=1.0, rwd_p_para=1.0, save_freq=500000, save_max_to_keep=5, save_scope='all', sharedNet_type='Dense', state_dim=17, test_env=['Part3-NA-Pit-Test-v1', 'Part3-NA-Pit-Test-v2', 'Part3-NA-Pit-Test-v3', 'Part3-NA-Pit-Test-v4'], test_mode='Multiple', train_act_func='part3_pit_sto_v1', train_freq=5, v_loss_frac=0.5, violation_penalty_scl=50.0, weight_initer='glorot_uniform', window_len=21)
[2019-03-20 15:22:19,021] A3C_AGENT_MAIN INFO:Start compiling...
2019-03-20 15:22:19.053110: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
[2019-03-20 15:22:33,687] A3C_AGENT_MAIN INFO:Start the learning...
[2019-03-20 15:22:33,687] A3C_AGENT_MAIN INFO:Prepare the evaluation environments ['Part3-NA-Pit-Train-v1', 'Part3-NA-Pit-Test-v1', 'Part3-NA-Pit-Test-v2', 'Part3-NA-Pit-Test-v3', 'Part3-NA-Pit-Test-v4'] ...
[2019-03-20 15:22:33,697] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation worker starts!
[2019-03-20 15:22:33,699] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation worker starts!
[2019-03-20 15:22:33,701] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation worker starts!
[2019-03-20 15:22:33,706] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation worker starts!
[2019-03-20 15:22:33,709] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation worker starts!
[2019-03-20 15:22:33,710] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-20 15:22:33,710] A3C_AGENT_WORKER-Thread-2 INFO:Local worker starts!
[2019-03-20 15:22:33,764] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-20 15:22:33,764] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run1
[2019-03-20 15:22:34,711] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-20 15:22:34,713] A3C_AGENT_WORKER-Thread-3 INFO:Local worker starts!
[2019-03-20 15:22:34,804] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-20 15:22:34,805] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run1
[2019-03-20 15:22:34,901] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-20 15:22:34,902] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-20 15:22:34,903] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-20 15:22:34,903] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-20 15:22:34,903] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-20 15:22:34,903] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-20 15:22:34,904] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-20 15:22:34,904] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-20 15:22:34,904] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-20 15:22:34,905] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-20 15:22:34,905] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-20 15:22:34,908] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run1
[2019-03-20 15:22:34,909] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run1
[2019-03-20 15:22:34,926] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run1
[2019-03-20 15:22:34,927] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run1
[2019-03-20 15:22:34,942] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run1
[2019-03-20 15:22:35,713] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-20 15:22:35,714] A3C_AGENT_WORKER-Thread-9 INFO:Local worker starts!
[2019-03-20 15:22:35,798] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-20 15:22:35,799] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run1
[2019-03-20 15:22:36,715] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-20 15:22:36,716] A3C_AGENT_WORKER-Thread-10 INFO:Local worker starts!
[2019-03-20 15:22:36,773] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-20 15:22:36,774] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run1
[2019-03-20 15:22:37,717] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-20 15:22:37,718] A3C_AGENT_WORKER-Thread-11 INFO:Local worker starts!
[2019-03-20 15:22:37,783] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-20 15:22:37,784] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run1
[2019-03-20 15:22:38,719] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-20 15:22:38,720] A3C_AGENT_WORKER-Thread-12 INFO:Local worker starts!
[2019-03-20 15:22:38,791] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-20 15:22:38,792] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run1
[2019-03-20 15:22:39,721] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-20 15:22:39,722] A3C_AGENT_WORKER-Thread-13 INFO:Local worker starts!
[2019-03-20 15:22:39,798] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-20 15:22:39,799] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run1
[2019-03-20 15:22:40,723] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-20 15:22:40,724] A3C_AGENT_WORKER-Thread-14 INFO:Local worker starts!
[2019-03-20 15:22:40,804] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-20 15:22:40,805] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run1
[2019-03-20 15:22:41,726] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-20 15:22:41,733] A3C_AGENT_WORKER-Thread-15 INFO:Local worker starts!
[2019-03-20 15:22:41,790] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-20 15:22:41,791] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run1
[2019-03-20 15:22:42,729] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-20 15:22:42,731] A3C_AGENT_WORKER-Thread-16 INFO:Local worker starts!
[2019-03-20 15:22:42,802] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-20 15:22:42,802] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run1
[2019-03-20 15:22:43,731] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-20 15:22:43,732] A3C_AGENT_WORKER-Thread-17 INFO:Local worker starts!
[2019-03-20 15:22:43,817] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-20 15:22:43,817] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run1
[2019-03-20 15:22:44,733] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-20 15:22:44,737] A3C_AGENT_WORKER-Thread-18 INFO:Local worker starts!
[2019-03-20 15:22:44,838] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-20 15:22:44,839] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run1
[2019-03-20 15:22:45,737] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-20 15:22:45,741] A3C_AGENT_WORKER-Thread-19 INFO:Local worker starts!
[2019-03-20 15:22:45,795] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-20 15:22:45,795] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run1
[2019-03-20 15:22:46,384] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-20 15:22:46,387] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [16.83333333333334, 63.66666666666667, 1.0, 2.0, 0.6004921029942099, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8754997801592208, 7.007084401722323, 6.9112, 95.55302303765883, 1200550.490965085, 1162069.904288839, 220418.2326103964]
[2019-03-20 15:22:46,388] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-20 15:22:46,390] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.13001792 0.12290455 0.2827227  0.38728783 0.077067  ], sampled 0.7786292906327107
[2019-03-20 15:22:46,740] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-20 15:22:46,741] A3C_AGENT_WORKER-Thread-20 INFO:Local worker starts!
[2019-03-20 15:22:46,835] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-20 15:22:46,836] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run1
[2019-03-20 15:22:47,742] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-20 15:22:47,743] A3C_AGENT_WORKER-Thread-21 INFO:Local worker starts!
[2019-03-20 15:22:47,819] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-20 15:22:47,819] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run1
[2019-03-20 15:22:48,744] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-20 15:22:48,747] A3C_AGENT_WORKER-Thread-22 INFO:Local worker starts!
[2019-03-20 15:22:48,808] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-20 15:22:48,810] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run1
[2019-03-20 15:22:49,372] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-20 15:22:49,373] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [26.6824932, 56.4743322, 1.0, 2.0, 0.7512161152951998, 1.0, 2.0, 0.7512161152951998, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 109.1877214233161, 1707337.613475959, 1707337.61347596, 309410.9100185442]
[2019-03-20 15:22:49,376] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-20 15:22:49,380] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0.08492874 0.06234941 0.16444257 0.6285265  0.05975271], sampled 0.6177468447709519
[2019-03-20 15:23:15,630] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-20 15:23:15,631] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [25.35, 54.5, 1.0, 2.0, 0.6063996029408275, 1.0, 1.0, 0.6063996029408275, 0.0, 1.0, 0.0, 6.9112, 6.9112, 107.7941816969677, 1383833.865034579, 1383833.865034579, 256511.3589356122]
[2019-03-20 15:23:15,631] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-20 15:23:15,633] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0.05603015 0.08616915 0.30137807 0.4786834  0.07773921], sampled 0.8067502347583617
[2019-03-20 15:23:33,064] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-20 15:23:33,065] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.11666666666667, 87.33333333333333, 1.0, 2.0, 0.6653583794547927, 1.0, 2.0, 0.6653583794547927, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 113.5264587350623, 1518422.664914983, 1518422.664914983, 278417.7941522115]
[2019-03-20 15:23:33,066] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-20 15:23:33,069] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.11418476 0.07907891 0.16593868 0.5079985  0.1327992 ], sampled 0.7540098317283206
[2019-03-20 15:23:38,063] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-20 15:23:38,064] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.03333333333333, 59.33333333333334, 1.0, 2.0, 0.7931172980515666, 1.0, 2.0, 0.7931172980515666, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 129.0347623584304, 1810868.992089262, 1810868.992089262, 314048.704916532]
[2019-03-20 15:23:38,066] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-20 15:23:38,072] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0.11697041 0.08482211 0.18788944 0.5483128  0.06200524], sampled 0.7552246134089654
[2019-03-20 15:23:39,970] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-20 15:23:39,971] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [16.33333333333333, 90.0, 1.0, 2.0, 0.2, 0.0, 1.0, 0.0, 1.0, 1.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 298168.9550209939, 298168.9550209942, 126784.0122569729]
[2019-03-20 15:23:39,972] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-20 15:23:39,977] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0.04010346 0.06004069 0.17900768 0.64526296 0.07558523], sampled 0.41204392989599203
[2019-03-20 15:23:44,085] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-20 15:23:44,086] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [28.1, 57.0, 1.0, 2.0, 0.5725613926076493, 1.0, 2.0, 0.5300691332454318, 1.0, 1.0, 0.9850007160732566, 6.911199999999999, 6.9112, 109.8286054858923, 1787969.262415776, 1787969.262415777, 379917.4776963789]
[2019-03-20 15:23:44,087] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-20 15:23:44,094] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.0901784  0.10376649 0.29228622 0.47324574 0.04052307], sampled 0.22522508790683982
[2019-03-20 15:23:44,096] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Action function: raw action [0, 0, 1, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 1787969.262415776 W.
[2019-03-20 15:23:48,994] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-20 15:23:48,996] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.65766898, 94.73283677500001, 1.0, 2.0, 0.5317776536355882, 1.0, 1.0, 0.5317776536355882, 0.0, 1.0, 0.0, 6.9112, 6.9112, 107.6054666978985, 1187125.859150918, 1187125.859150918, 221803.6792541581]
[2019-03-20 15:23:48,998] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-20 15:23:49,001] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0.17639834 0.15095647 0.19286983 0.36896753 0.11080789], sampled 0.07732937209609936
[2019-03-20 15:23:49,002] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1187125.859150918 W.
[2019-03-20 15:23:52,239] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-20 15:23:52,239] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.73333333333333, 82.33333333333333, 1.0, 2.0, 0.4615366923271759, 1.0, 2.0, 0.4615366923271759, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338754940475, 1051724.527500873, 1051724.527500873, 219306.5831848768]
[2019-03-20 15:23:52,239] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-20 15:23:52,240] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0.03939613 0.11537248 0.21286196 0.49377167 0.13859774], sampled 0.6421778327886204
[2019-03-20 15:24:39,708] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2552.1781 3709837176.2748 2388.0000
[2019-03-20 15:24:40,133] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 2433.0693 3794947911.1352 2474.0000
[2019-03-20 15:24:40,403] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 2365.6677 3864632949.9219 2472.0000
[2019-03-20 15:24:40,438] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 2596.6418 3671908653.8502 2633.0000
[2019-03-20 15:24:40,452] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 2634.1175 2120534118.3021 345.0000
[2019-03-20 15:24:41,466] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 0, evaluation results [0.0, 2634.117471681138, 2120534118.3020942, 345.0, 2596.6418030512305, 3671908653.850196, 2633.0, 2365.6676627805314, 3864632949.9219484, 2472.0, 2552.1781110877837, 3709837176.2747974, 2388.0, 2433.069305159674, 3794947911.1352453, 2474.0]
[2019-03-20 15:24:53,386] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 2.6554297e-11 4.8358600e-12 9.9023634e-09 2.7485609e-12], sum to 1.0000
[2019-03-20 15:24:53,396] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2121
[2019-03-20 15:24:53,482] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.0, 43.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5613123417530592, 6.911199999999998, 6.9112, 77.32846344354104, 326499.3487163366, 326499.3487163372, 91918.96135634022], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 149400.0000, 
sim time next is 150000.0000, 
raw observation next is [22.0, 43.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5622912518444846, 6.911199999999998, 6.9112, 77.32846344354104, 327068.9442233418, 327068.9442233424, 93001.94854653564], 
processed observation next is [1.0, 0.7391304347826086, 0.6363636363636364, 0.43, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3747017883492637, -1.7763568394002506e-16, 0.0, 0.5084288129206541, 0.12113664600864511, 0.12113664600864534, 0.22683402084520887], 
reward next is 0.7732, 
noisyNet noise sample is [array([-1.677911], dtype=float32), -0.2131135]. 
=============================================
[2019-03-20 15:24:53,497] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[40.053513]
 [39.529053]
 [39.735756]
 [40.17994 ]
 [40.34251 ]], R is [[40.44189453]
 [40.81328201]
 [41.18755341]
 [41.51646805]
 [41.1013031 ]].
[2019-03-20 15:25:03,116] A3C_AGENT_WORKER-Thread-17 INFO:Local step 500, global step 7924: loss 0.2019
[2019-03-20 15:25:03,168] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 500, global step 7925: learning rate 0.0010
[2019-03-20 15:25:03,198] A3C_AGENT_WORKER-Thread-15 INFO:Local step 500, global step 7943: loss 0.4130
[2019-03-20 15:25:03,201] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 500, global step 7943: learning rate 0.0010
[2019-03-20 15:25:03,236] A3C_AGENT_WORKER-Thread-16 INFO:Local step 500, global step 7958: loss 0.3422
[2019-03-20 15:25:03,238] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 500, global step 7958: learning rate 0.0010
[2019-03-20 15:25:03,253] A3C_AGENT_WORKER-Thread-2 INFO:Local step 500, global step 7965: loss 0.5013
[2019-03-20 15:25:03,255] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 500, global step 7965: learning rate 0.0010
[2019-03-20 15:25:03,265] A3C_AGENT_WORKER-Thread-11 INFO:Local step 500, global step 7967: loss 0.5485
[2019-03-20 15:25:03,269] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 500, global step 7968: learning rate 0.0010
[2019-03-20 15:25:03,271] A3C_AGENT_WORKER-Thread-19 INFO:Local step 500, global step 7970: loss 0.3731
[2019-03-20 15:25:03,275] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 500, global step 7970: learning rate 0.0010
[2019-03-20 15:25:03,297] A3C_AGENT_WORKER-Thread-22 INFO:Local step 500, global step 7977: loss 0.3350
[2019-03-20 15:25:03,297] A3C_AGENT_WORKER-Thread-18 INFO:Local step 500, global step 7977: loss 0.1769
[2019-03-20 15:25:03,301] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 500, global step 7977: learning rate 0.0010
[2019-03-20 15:25:03,301] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 500, global step 7977: learning rate 0.0010
[2019-03-20 15:25:03,343] A3C_AGENT_WORKER-Thread-20 INFO:Local step 500, global step 7996: loss 0.1493
[2019-03-20 15:25:03,346] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 500, global step 7996: learning rate 0.0010
[2019-03-20 15:25:03,350] A3C_AGENT_WORKER-Thread-10 INFO:Local step 500, global step 8000: loss 0.2619
[2019-03-20 15:25:03,352] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 500, global step 8000: learning rate 0.0010
[2019-03-20 15:25:03,356] A3C_AGENT_WORKER-Thread-14 INFO:Local step 500, global step 8000: loss 0.1791
[2019-03-20 15:25:03,357] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 500, global step 8000: learning rate 0.0010
[2019-03-20 15:25:03,386] A3C_AGENT_WORKER-Thread-3 INFO:Local step 500, global step 8010: loss 0.1201
[2019-03-20 15:25:03,391] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 500, global step 8012: learning rate 0.0010
[2019-03-20 15:25:03,408] A3C_AGENT_WORKER-Thread-12 INFO:Local step 500, global step 8019: loss 0.1011
[2019-03-20 15:25:03,409] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 500, global step 8019: learning rate 0.0010
[2019-03-20 15:25:03,419] A3C_AGENT_WORKER-Thread-9 INFO:Local step 500, global step 8021: loss 0.0355
[2019-03-20 15:25:03,421] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 500, global step 8021: learning rate 0.0010
[2019-03-20 15:25:03,447] A3C_AGENT_WORKER-Thread-13 INFO:Local step 500, global step 8033: loss 0.0090
[2019-03-20 15:25:03,449] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 500, global step 8033: learning rate 0.0010
[2019-03-20 15:25:03,450] A3C_AGENT_WORKER-Thread-21 INFO:Local step 500, global step 8033: loss 0.0168
[2019-03-20 15:25:03,456] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 500, global step 8035: learning rate 0.0010
[2019-03-20 15:25:04,423] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 1.9090149e-15 2.1521997e-16 3.4641886e-13 5.0311313e-18], sum to 1.0000
[2019-03-20 15:25:04,433] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4546
[2019-03-20 15:25:04,440] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.16666666666667, 42.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4984436115743925, 6.911200000000001, 6.9112, 77.32846344354104, 289919.5046458542, 289919.5046458539, 88365.59358972416], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 313800.0000, 
sim time next is 314400.0000, 
raw observation next is [22.33333333333334, 42.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5020351264329834, 6.911199999999999, 6.9112, 77.32846344354104, 292009.1348101645, 292009.1348101647, 89279.27382729974], 
processed observation next is [0.0, 0.6521739130434783, 0.6515151515151518, 0.42333333333333345, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.28862160918997637, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10815153141117204, 0.1081515314111721, 0.21775432640804815], 
reward next is 0.7822, 
noisyNet noise sample is [array([-0.87159264], dtype=float32), -0.472651]. 
=============================================
[2019-03-20 15:25:04,906] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 7.8033288e-22 5.9561289e-21 6.9927156e-17 1.7062113e-22], sum to 1.0000
[2019-03-20 15:25:04,915] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5140
[2019-03-20 15:25:04,970] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 2.0647206e-22 2.9097144e-21 1.7526319e-16 5.8362442e-23], sum to 1.0000
[2019-03-20 15:25:04,976] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1601
[2019-03-20 15:25:05,009] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.0, 43.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4788734550837279, 6.911199999999999, 6.9112, 77.32846344354104, 278533.2722701731, 278533.2722701734, 80884.95914199819], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 322200.0000, 
sim time next is 322800.0000, 
raw observation next is [21.0, 43.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4789699623406714, 6.9112, 6.9112, 77.32846344354104, 278589.4210932265, 278589.4210932265, 80869.76952808736], 
processed observation next is [0.0, 0.7391304347826086, 0.5909090909090909, 0.43, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.25567137477238777, 0.0, 0.0, 0.5084288129206541, 0.10318126707156539, 0.10318126707156539, 0.1972433403124082], 
reward next is 0.8028, 
noisyNet noise sample is [array([0.41040254], dtype=float32), -0.28485125]. 
=============================================
[2019-03-20 15:25:05,089] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.0, 43.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4797918007326312, 6.9112, 6.9112, 77.32846344354104, 279067.5746047622, 279067.5746047622, 80921.26349630016], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 323400.0000, 
sim time next is 324000.0000, 
raw observation next is [21.0, 43.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4808319267463147, 6.9112, 6.9112, 77.32846344354104, 279672.7306362218, 279672.7306362218, 81001.76537359653], 
processed observation next is [0.0, 0.782608695652174, 0.5909090909090909, 0.43, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.25833132392330677, 0.0, 0.0, 0.5084288129206541, 0.1035824928282303, 0.1035824928282303, 0.1975652813990159], 
reward next is 0.8024, 
noisyNet noise sample is [array([0.6165192], dtype=float32), -0.16569786]. 
=============================================
[2019-03-20 15:25:05,109] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[91.305405]
 [91.29419 ]
 [91.26524 ]
 [91.226814]
 [91.17579 ]], R is [[91.22978973]
 [91.12011719]
 [91.01167297]
 [90.90427399]
 [90.79776764]].
[2019-03-20 15:25:08,008] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 6.0499730e-09 7.4776905e-09 3.7854726e-08 1.9747361e-12], sum to 1.0000
[2019-03-20 15:25:08,015] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8133
[2019-03-20 15:25:08,025] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 549095.3387972307 W.
[2019-03-20 15:25:08,119] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [12.0, 76.0, 1.0, 1.0, 0.2527826741014213, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4718898725525822, 6.9112, 6.9112, 77.32792670606976, 549095.3387972307, 549095.3387972307, 136240.9399609108], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 364800.0000, 
sim time next is 365400.0000, 
raw observation next is [12.0, 76.0, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.3421103, 450118.9585832153, 450118.9585832156, 148345.3678605917], 
processed observation next is [1.0, 0.21739130434782608, 0.18181818181818182, 0.76, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.16671072540119086, 0.16671072540119097, 0.3618179703916871], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.9025924], dtype=float32), 1.0964439]. 
=============================================
[2019-03-20 15:25:10,324] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 4.4729885e-33 8.1209535e-31 7.8546612e-31 7.1210191e-30], sum to 1.0000
[2019-03-20 15:25:10,332] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4628
[2019-03-20 15:25:10,340] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.5, 54.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.706191251315343, 6.91202018229454, 6.9112, 77.32836746582775, 411073.3589234755, 410806.9808204586, 106513.3531633677], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 397800.0000, 
sim time next is 398400.0000, 
raw observation next is [19.33333333333334, 55.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7061313007234581, 6.911517880316283, 6.9112, 77.328415864109, 410875.2634519244, 410772.0224904957, 106042.5900616679], 
processed observation next is [1.0, 0.6086956521739131, 0.5151515151515155, 0.55, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5801875724620831, 3.178803162828814e-05, 0.0, 0.5084285000894783, 0.15217602350071274, 0.152137786107591, 0.25864046356504367], 
reward next is 0.7398, 
noisyNet noise sample is [array([0.72533345], dtype=float32), 0.030911744]. 
=============================================
[2019-03-20 15:25:20,060] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 2.0246874e-27 5.3294216e-26 1.2340331e-25 3.1779604e-28], sum to 1.0000
[2019-03-20 15:25:20,075] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5000
[2019-03-20 15:25:20,089] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 552296.7883438878 W.
[2019-03-20 15:25:20,180] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 94.00000000000001, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 2.0, 0.316426447592557, 6.911199999999999, 6.9112, 77.3421103, 552296.7883438878, 552296.788343888, 176640.9674562615], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 540600.0000, 
sim time next is 541200.0000, 
raw observation next is [14.0, 94.0, 1.0, 2.0, 0.435395196058302, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 472846.3559356111, 472846.3559356108, 98926.44373979568], 
processed observation next is [1.0, 0.2608695652173913, 0.2727272727272727, 0.94, 1.0, 1.0, 0.29424399507287746, 0.0, 0.5, -0.25, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17512827997615227, 0.17512827997615213, 0.24128400912145287], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.6388018], dtype=float32), 0.47555643]. 
=============================================
[2019-03-20 15:25:23,629] A3C_AGENT_WORKER-Thread-17 INFO:Local step 1000, global step 15849: loss 0.0041
[2019-03-20 15:25:23,630] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 1000, global step 15849: learning rate 0.0010
[2019-03-20 15:25:23,822] A3C_AGENT_WORKER-Thread-2 INFO:Local step 1000, global step 15922: loss 0.3273
[2019-03-20 15:25:23,824] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 1000, global step 15922: learning rate 0.0010
[2019-03-20 15:25:23,910] A3C_AGENT_WORKER-Thread-16 INFO:Local step 1000, global step 15958: loss 0.2150
[2019-03-20 15:25:23,913] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 1000, global step 15959: learning rate 0.0010
[2019-03-20 15:25:23,922] A3C_AGENT_WORKER-Thread-19 INFO:Local step 1000, global step 15963: loss 0.2921
[2019-03-20 15:25:23,925] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 1000, global step 15965: learning rate 0.0010
[2019-03-20 15:25:23,933] A3C_AGENT_WORKER-Thread-15 INFO:Local step 1000, global step 15967: loss 0.2848
[2019-03-20 15:25:23,936] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 1000, global step 15967: learning rate 0.0010
[2019-03-20 15:25:23,956] A3C_AGENT_WORKER-Thread-14 INFO:Local step 1000, global step 15976: loss 0.1844
[2019-03-20 15:25:23,959] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 1000, global step 15977: learning rate 0.0010
[2019-03-20 15:25:23,965] A3C_AGENT_WORKER-Thread-18 INFO:Local step 1000, global step 15978: loss 0.1377
[2019-03-20 15:25:23,967] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 1000, global step 15978: learning rate 0.0010
[2019-03-20 15:25:23,986] A3C_AGENT_WORKER-Thread-22 INFO:Local step 1000, global step 15984: loss 0.2191
[2019-03-20 15:25:23,991] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 1000, global step 15986: learning rate 0.0010
[2019-03-20 15:25:23,994] A3C_AGENT_WORKER-Thread-11 INFO:Local step 1000, global step 15987: loss 0.3401
[2019-03-20 15:25:23,996] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 1000, global step 15987: learning rate 0.0010
[2019-03-20 15:25:24,027] A3C_AGENT_WORKER-Thread-10 INFO:Local step 1000, global step 15997: loss 0.0884
[2019-03-20 15:25:24,029] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 1000, global step 15997: learning rate 0.0010
[2019-03-20 15:25:24,062] A3C_AGENT_WORKER-Thread-3 INFO:Local step 1000, global step 16012: loss 0.1053
[2019-03-20 15:25:24,072] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 1000, global step 16012: learning rate 0.0010
[2019-03-20 15:25:24,072] A3C_AGENT_WORKER-Thread-13 INFO:Local step 1000, global step 16012: loss 0.0100
[2019-03-20 15:25:24,078] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 1000, global step 16013: learning rate 0.0010
[2019-03-20 15:25:24,104] A3C_AGENT_WORKER-Thread-20 INFO:Local step 1000, global step 16023: loss 0.1000
[2019-03-20 15:25:24,109] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 1000, global step 16024: learning rate 0.0010
[2019-03-20 15:25:24,149] A3C_AGENT_WORKER-Thread-9 INFO:Local step 1000, global step 16045: loss 0.0359
[2019-03-20 15:25:24,154] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 1000, global step 16047: learning rate 0.0010
[2019-03-20 15:25:24,184] A3C_AGENT_WORKER-Thread-21 INFO:Local step 1000, global step 16061: loss 0.0178
[2019-03-20 15:25:24,189] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 1000, global step 16061: learning rate 0.0010
[2019-03-20 15:25:24,206] A3C_AGENT_WORKER-Thread-12 INFO:Local step 1000, global step 16070: loss 0.0648
[2019-03-20 15:25:24,209] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 1000, global step 16070: learning rate 0.0010
[2019-03-20 15:25:27,883] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 2.4805507e-17 7.1285639e-18 4.5535076e-11 7.9299876e-16], sum to 1.0000
[2019-03-20 15:25:27,893] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1814
[2019-03-20 15:25:27,901] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 872814.2415929622 W.
[2019-03-20 15:25:28,008] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.0, 56.5, 1.0, 2.0, 0.774024612840296, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354051, 872814.2415929622, 872814.2415929622, 167982.563811395], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 654600.0000, 
sim time next is 655200.0000, 
raw observation next is [24.0, 57.0, 1.0, 2.0, 0.3972332970737855, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7821066718486274, 6.911199999999999, 6.9112, 77.32846344354104, 897092.1806033123, 897092.1806033126, 208783.3806295887], 
processed observation next is [1.0, 0.6086956521739131, 0.7272727272727273, 0.57, 1.0, 1.0, 0.24654162134223187, 0.0, 1.0, -0.25, 1.0, 0.5, 0.6887238169266106, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.332256363186412, 0.33225636318641205, 0.5092277576331432], 
reward next is 0.4908, 
noisyNet noise sample is [array([-1.183684], dtype=float32), 1.2465464]. 
=============================================
[2019-03-20 15:25:31,691] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 1.6560823e-24 7.5162948e-25 2.5734539e-20 4.4247855e-28], sum to 1.0000
[2019-03-20 15:25:31,693] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2413
[2019-03-20 15:25:31,697] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 970739.16799879 W.
[2019-03-20 15:25:31,796] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 71.0, 1.0, 2.0, 0.8573526377770861, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32845919866426, 970739.16799879, 970739.1679987897, 182329.1899281426], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 721800.0000, 
sim time next is 722400.0000, 
raw observation next is [22.33333333333333, 70.33333333333334, 1.0, 2.0, 0.76629337136971, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.3284634172649, 866840.8100856363, 866840.8100856361, 168430.0266870464], 
processed observation next is [1.0, 0.34782608695652173, 0.6515151515151513, 0.7033333333333335, 1.0, 1.0, 0.7078667142121375, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288127478904, 0.321052151883569, 0.32105215188356895, 0.41080494313913757], 
reward next is 0.5892, 
noisyNet noise sample is [array([-2.5213497], dtype=float32), -0.357281]. 
=============================================
[2019-03-20 15:25:34,453] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.3442823e-02 2.8531948e-09 2.0393090e-08 6.7538705e-05 9.7648960e-01], sum to 1.0000
[2019-03-20 15:25:34,468] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2230
[2019-03-20 15:25:34,559] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.0, 58.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.812511280538632, 7.603096985360562, 6.9112, 77.32678765351673, 683538.7765251951, 458829.65721184, 144671.880953029], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 759000.0000, 
sim time next is 759600.0000, 
raw observation next is [27.0, 58.0, 1.0, 1.0, 0.2, 1.0, 1.0, 0.2, 1.0, 2.0, 0.3635551591138229, 6.911199999999999, 6.9112, 77.3421103, 615801.289992585, 615801.2899925852, 216033.3277786512], 
processed observation next is [1.0, 0.8260869565217391, 0.8636363636363636, 0.58, 1.0, 0.5, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.09079308444831846, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.22807455184910555, 0.22807455184910563, 0.5269105555576858], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.60221165], dtype=float32), -0.5861428]. 
=============================================
[2019-03-20 15:25:35,809] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.2220118e-20 5.4875190e-23 9.6649859e-21 5.9310933e-15 1.0000000e+00], sum to 1.0000
[2019-03-20 15:25:35,818] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3186
[2019-03-20 15:25:35,825] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.0, 69.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.3421103, 508735.0783411052, 508735.0783411055, 200539.9196429019], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 771600.0000, 
sim time next is 772200.0000, 
raw observation next is [24.0, 69.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.3421103, 507462.9195667208, 507462.9195667211, 200320.4600746629], 
processed observation next is [1.0, 0.9565217391304348, 0.7272727272727273, 0.69, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.18794922946915585, 0.18794922946915596, 0.4885864879869827], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.05223126], dtype=float32), 2.379449]. 
=============================================
[2019-03-20 15:25:36,013] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.5052628e-16 5.5780329e-18 1.6347467e-18 1.4353632e-11 1.0000000e+00], sum to 1.0000
[2019-03-20 15:25:36,023] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7959
[2019-03-20 15:25:36,030] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [21.66666666666667, 79.66666666666667, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.3421103, 474624.7550374913, 474624.7550374916, 192713.5679955467], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 781800.0000, 
sim time next is 782400.0000, 
raw observation next is [21.33333333333334, 81.33333333333334, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.3421103, 472015.9030509578, 472015.903050958, 191992.835246503], 
processed observation next is [0.0, 0.043478260869565216, 0.6060606060606063, 0.8133333333333335, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.17482070483368806, 0.17482070483368814, 0.4682752079183], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.75107354], dtype=float32), 0.027548624]. 
=============================================
[2019-03-20 15:25:38,729] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 3.3210754e-19 4.0311065e-19 4.3759416e-19 1.3958527e-19], sum to 1.0000
[2019-03-20 15:25:38,738] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1496
[2019-03-20 15:25:38,747] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 665109.8158566215 W.
[2019-03-20 15:25:38,751] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.5, 76.5, 1.0, 2.0, 0.2959415756227886, 1.0, 2.0, 0.2959415756227886, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 665109.8158566215, 665109.8158566217, 191602.1042424348], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 815400.0000, 
sim time next is 816000.0000, 
raw observation next is [26.66666666666667, 75.66666666666666, 1.0, 2.0, 0.5930055901825221, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 666773.649654016, 666773.649654016, 157840.6371194921], 
processed observation next is [0.0, 0.43478260869565216, 0.8484848484848487, 0.7566666666666666, 1.0, 1.0, 0.49125698772815257, 0.0, 0.5, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2469532035755615, 0.2469532035755615, 0.3849771637060783], 
reward next is 0.6150, 
noisyNet noise sample is [array([-0.3565323], dtype=float32), -1.1034529]. 
=============================================
[2019-03-20 15:25:38,760] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[20.194597]
 [20.150536]
 [19.93001 ]
 [19.559856]
 [19.681356]], R is [[20.50021935]
 [20.82789612]
 [20.61961746]
 [20.9386673 ]
 [21.34918022]].
[2019-03-20 15:25:44,042] A3C_AGENT_WORKER-Thread-17 INFO:Local step 1500, global step 23888: loss 25.1287
[2019-03-20 15:25:44,044] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 1500, global step 23888: learning rate 0.0010
[2019-03-20 15:25:44,056] A3C_AGENT_WORKER-Thread-16 INFO:Local step 1500, global step 23892: loss 28.8024
[2019-03-20 15:25:44,058] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 1500, global step 23892: learning rate 0.0010
[2019-03-20 15:25:44,091] A3C_AGENT_WORKER-Thread-15 INFO:Local step 1500, global step 23905: loss -3.6600
[2019-03-20 15:25:44,095] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 1500, global step 23906: learning rate 0.0010
[2019-03-20 15:25:44,186] A3C_AGENT_WORKER-Thread-2 INFO:Local step 1500, global step 23942: loss -3.1077
[2019-03-20 15:25:44,188] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 1500, global step 23943: learning rate 0.0010
[2019-03-20 15:25:44,227] A3C_AGENT_WORKER-Thread-19 INFO:Local step 1500, global step 23956: loss 50.3458
[2019-03-20 15:25:44,229] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 1500, global step 23956: learning rate 0.0010
[2019-03-20 15:25:44,247] A3C_AGENT_WORKER-Thread-10 INFO:Local step 1500, global step 23964: loss -8.3554
[2019-03-20 15:25:44,249] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 1500, global step 23964: learning rate 0.0010
[2019-03-20 15:25:44,283] A3C_AGENT_WORKER-Thread-3 INFO:Local step 1500, global step 23975: loss 2.0903
[2019-03-20 15:25:44,284] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 1500, global step 23975: learning rate 0.0010
[2019-03-20 15:25:44,307] A3C_AGENT_WORKER-Thread-18 INFO:Local step 1500, global step 23986: loss 12.1689
[2019-03-20 15:25:44,311] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 1500, global step 23986: learning rate 0.0010
[2019-03-20 15:25:44,368] A3C_AGENT_WORKER-Thread-9 INFO:Local step 1500, global step 24009: loss 18.4932
[2019-03-20 15:25:44,370] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 1500, global step 24011: learning rate 0.0010
[2019-03-20 15:25:44,377] A3C_AGENT_WORKER-Thread-11 INFO:Local step 1500, global step 24014: loss -10.3431
[2019-03-20 15:25:44,380] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 1500, global step 24016: learning rate 0.0010
[2019-03-20 15:25:44,397] A3C_AGENT_WORKER-Thread-14 INFO:Local step 1500, global step 24023: loss 14.6915
[2019-03-20 15:25:44,398] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 1500, global step 24023: learning rate 0.0010
[2019-03-20 15:25:44,406] A3C_AGENT_WORKER-Thread-22 INFO:Local step 1500, global step 24026: loss 36.4237
[2019-03-20 15:25:44,408] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 1500, global step 24026: learning rate 0.0010
[2019-03-20 15:25:44,420] A3C_AGENT_WORKER-Thread-21 INFO:Local step 1500, global step 24032: loss -16.7766
[2019-03-20 15:25:44,422] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 1500, global step 24032: learning rate 0.0010
[2019-03-20 15:25:44,432] A3C_AGENT_WORKER-Thread-13 INFO:Local step 1500, global step 24037: loss -13.7469
[2019-03-20 15:25:44,435] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 1500, global step 24037: learning rate 0.0010
[2019-03-20 15:25:44,487] A3C_AGENT_WORKER-Thread-12 INFO:Local step 1500, global step 24060: loss -13.9633
[2019-03-20 15:25:44,491] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 1500, global step 24060: learning rate 0.0010
[2019-03-20 15:25:44,541] A3C_AGENT_WORKER-Thread-20 INFO:Local step 1500, global step 24079: loss 47.4038
[2019-03-20 15:25:44,545] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 1500, global step 24079: learning rate 0.0010
[2019-03-20 15:25:46,936] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-20 15:25:46,938] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-20 15:25:46,938] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-20 15:25:46,940] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-20 15:25:46,940] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-20 15:25:46,940] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-20 15:25:46,943] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-20 15:25:46,945] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-20 15:25:46,946] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-20 15:25:46,948] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-20 15:25:46,947] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-20 15:25:46,968] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run2
[2019-03-20 15:25:46,969] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run2
[2019-03-20 15:25:46,969] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run2
[2019-03-20 15:25:46,970] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run2
[2019-03-20 15:25:47,003] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run2
[2019-03-20 15:25:56,381] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.22711577], dtype=float32), 0.10380775]
[2019-03-20 15:25:56,382] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [13.53944477666667, 81.4754362, 1.0, 2.0, 0.2321460920653244, 1.0, 2.0, 0.2321460920653244, 1.0, 2.0, 0.433365896244944, 6.911199999999999, 6.9112, 95.55338769695034, 756451.7848483009, 756451.7848483012, 193519.3725683541]
[2019-03-20 15:25:56,383] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-20 15:25:56,387] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.2818653e-11 5.4906621e-11 3.9786815e-12 3.7497561e-09 1.0000000e+00], sampled 0.4794191682160448
[2019-03-20 15:26:17,316] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.22711577], dtype=float32), 0.10380775]
[2019-03-20 15:26:17,317] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.38333333333333, 89.5, 1.0, 2.0, 0.4125485161882719, 1.0, 2.0, 0.4125485161882719, 1.0, 2.0, 0.835416227144967, 6.9112, 6.9112, 109.896378789837, 1409446.756105979, 1409446.756105979, 314318.3657456841]
[2019-03-20 15:26:17,317] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-20 15:26:17,319] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.5645473e-17 2.2786230e-13 7.6926990e-15 5.4634901e-11 1.0000000e+00], sampled 0.5321070307524277
[2019-03-20 15:26:37,453] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.22711577], dtype=float32), 0.10380775]
[2019-03-20 15:26:37,454] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.691506885, 81.04728316, 1.0, 2.0, 0.7154746395591417, 1.0, 2.0, 0.5991132724972968, 1.0, 2.0, 0.9755077900476219, 6.913572451493625, 6.9112, 133.4120271411222, 2040922.453128934, 2039593.096164089, 407033.7260166134]
[2019-03-20 15:26:37,455] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-20 15:26:37,458] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.4822769e-19 4.4827003e-14 1.0256649e-15 1.5443202e-11 1.0000000e+00], sampled 0.49721826543816294
[2019-03-20 15:26:42,652] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.22711577], dtype=float32), 0.10380775]
[2019-03-20 15:26:42,655] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [29.33333333333333, 51.33333333333333, 1.0, 2.0, 0.5624515163677655, 1.0, 2.0, 0.5250141951254901, 1.0, 2.0, 0.9857627401493683, 6.911200000000001, 6.9112, 109.78306744844, 1770900.557536654, 1770900.557536654, 378251.1028140828]
[2019-03-20 15:26:42,655] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-20 15:26:42,661] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.8448598e-22 6.9970719e-15 1.1976465e-16 3.1311815e-12 1.0000000e+00], sampled 0.7015623288650489
[2019-03-20 15:26:58,189] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.22711577], dtype=float32), 0.10380775]
[2019-03-20 15:26:58,191] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.41666666666667, 87.0, 1.0, 2.0, 0.3719551535117803, 1.0, 2.0, 0.3719551535117803, 1.0, 2.0, 0.7441272847934326, 6.911200000000001, 6.9112, 108.5819672296319, 1271100.061852836, 1271100.061852836, 282736.7831261478]
[2019-03-20 15:26:58,193] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-20 15:26:58,195] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [9.5140795e-16 1.4399967e-12 5.6377070e-14 2.0865111e-10 1.0000000e+00], sampled 0.6489228629361469
[2019-03-20 15:27:22,671] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.22711577], dtype=float32), 0.10380775]
[2019-03-20 15:27:22,672] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [25.55, 52.33333333333334, 1.0, 2.0, 0.4328183527989989, 1.0, 2.0, 0.4328183527989989, 1.0, 2.0, 0.8722592119593882, 6.911199999999999, 6.9112, 107.8795973427731, 1482389.824133587, 1482389.824133588, 316421.815727821]
[2019-03-20 15:27:22,673] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-20 15:27:22,677] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.9217529e-20 4.3880217e-14 1.0507651e-15 1.3764290e-11 1.0000000e+00], sampled 0.8952066271859852
[2019-03-20 15:27:49,754] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2697.5435 4173810811.3916 2381.0000
[2019-03-20 15:27:49,937] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 2679.0698 4166333528.4746 2275.0000
[2019-03-20 15:27:49,956] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 2697.9324 4225030079.4559 2157.0000
[2019-03-20 15:27:49,997] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 2508.5932 4304936728.0320 2189.0000
[2019-03-20 15:27:50,050] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 903.6785 2515226386.5922 0.0000
[2019-03-20 15:27:51,064] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 25000, evaluation results [25000.0, 903.6785093081284, 2515226386.592178, 0.0, 2679.0698465636115, 4166333528.474584, 2275.0, 2508.593219411092, 4304936728.032001, 2189.0, 2697.543483840069, 4173810811.3916073, 2381.0, 2697.9323628204975, 4225030079.4559026, 2157.0]
[2019-03-20 15:27:54,352] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.6776819e-17 9.9999619e-01 3.7814573e-06 1.3590561e-13 1.2730876e-12], sum to 1.0000
[2019-03-20 15:27:54,361] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4124
[2019-03-20 15:27:54,367] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 100.0, 1.0, 2.0, 0.5077320463284344, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 553143.9644882332, 553143.9644882332, 128087.5374589601], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 990600.0000, 
sim time next is 991200.0000, 
raw observation next is [16.0, 100.0, 1.0, 2.0, 0.5059398209208376, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 551041.5014549637, 551041.5014549637, 127877.3694112314], 
processed observation next is [1.0, 0.4782608695652174, 0.36363636363636365, 1.0, 1.0, 1.0, 0.3824247761510469, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20408944498331988, 0.20408944498331988, 0.3118960229542229], 
reward next is 0.6881, 
noisyNet noise sample is [array([-0.04117613], dtype=float32), -0.29682642]. 
=============================================
[2019-03-20 15:27:59,159] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.2797961e-29 1.0000000e+00 2.0641690e-11 9.5140573e-28 6.3244395e-30], sum to 1.0000
[2019-03-20 15:27:59,171] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3174
[2019-03-20 15:27:59,177] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 96.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 215955.5714983086, 215955.5714983089, 72406.91107287286], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1053600.0000, 
sim time next is 1054200.0000, 
raw observation next is [13.0, 95.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 211323.3780308952, 211323.3780308955, 71364.7503523428], 
processed observation next is [1.0, 0.17391304347826086, 0.22727272727272727, 0.95, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07826791778922045, 0.07826791778922056, 0.1740603667130312], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1217839], dtype=float32), 0.7470762]. 
=============================================
[2019-03-20 15:28:08,502] A3C_AGENT_WORKER-Thread-16 INFO:Local step 2000, global step 31851: loss 0.4158
[2019-03-20 15:28:08,507] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 2000, global step 31851: learning rate 0.0010
[2019-03-20 15:28:08,546] A3C_AGENT_WORKER-Thread-17 INFO:Local step 2000, global step 31868: loss 0.4566
[2019-03-20 15:28:08,553] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 2000, global step 31871: learning rate 0.0010
[2019-03-20 15:28:08,596] A3C_AGENT_WORKER-Thread-19 INFO:Local step 2000, global step 31887: loss 0.2456
[2019-03-20 15:28:08,599] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 2000, global step 31888: learning rate 0.0010
[2019-03-20 15:28:08,667] A3C_AGENT_WORKER-Thread-2 INFO:Local step 2000, global step 31912: loss 0.2424
[2019-03-20 15:28:08,668] A3C_AGENT_WORKER-Thread-15 INFO:Local step 2000, global step 31913: loss 0.2503
[2019-03-20 15:28:08,670] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 2000, global step 31913: learning rate 0.0010
[2019-03-20 15:28:08,670] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 2000, global step 31913: learning rate 0.0010
[2019-03-20 15:28:08,781] A3C_AGENT_WORKER-Thread-14 INFO:Local step 2000, global step 31956: loss 0.1776
[2019-03-20 15:28:08,786] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 2000, global step 31956: learning rate 0.0010
[2019-03-20 15:28:08,850] A3C_AGENT_WORKER-Thread-18 INFO:Local step 2000, global step 31981: loss 0.1375
[2019-03-20 15:28:08,855] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 2000, global step 31982: learning rate 0.0010
[2019-03-20 15:28:08,898] A3C_AGENT_WORKER-Thread-3 INFO:Local step 2000, global step 31999: loss 0.1366
[2019-03-20 15:28:08,902] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 2000, global step 31999: learning rate 0.0010
[2019-03-20 15:28:08,932] A3C_AGENT_WORKER-Thread-10 INFO:Local step 2000, global step 32011: loss 0.1323
[2019-03-20 15:28:08,934] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 2000, global step 32011: learning rate 0.0010
[2019-03-20 15:28:08,969] A3C_AGENT_WORKER-Thread-13 INFO:Local step 2000, global step 32026: loss 0.1626
[2019-03-20 15:28:08,971] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 2000, global step 32026: learning rate 0.0010
[2019-03-20 15:28:08,998] A3C_AGENT_WORKER-Thread-11 INFO:Local step 2000, global step 32037: loss 0.1385
[2019-03-20 15:28:09,001] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 2000, global step 32037: learning rate 0.0010
[2019-03-20 15:28:09,036] A3C_AGENT_WORKER-Thread-21 INFO:Local step 2000, global step 32053: loss 0.1499
[2019-03-20 15:28:09,039] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 2000, global step 32053: learning rate 0.0010
[2019-03-20 15:28:09,043] A3C_AGENT_WORKER-Thread-9 INFO:Local step 2000, global step 32055: loss 0.1334
[2019-03-20 15:28:09,046] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 2000, global step 32057: learning rate 0.0010
[2019-03-20 15:28:09,068] A3C_AGENT_WORKER-Thread-12 INFO:Local step 2000, global step 32067: loss 0.1022
[2019-03-20 15:28:09,070] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 2000, global step 32067: learning rate 0.0010
[2019-03-20 15:28:09,078] A3C_AGENT_WORKER-Thread-22 INFO:Local step 2000, global step 32070: loss 0.1356
[2019-03-20 15:28:09,083] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 2000, global step 32070: learning rate 0.0010
[2019-03-20 15:28:09,155] A3C_AGENT_WORKER-Thread-20 INFO:Local step 2000, global step 32097: loss 0.1021
[2019-03-20 15:28:09,158] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 2000, global step 32097: learning rate 0.0010
[2019-03-20 15:28:15,095] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.1598837e-29 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-20 15:28:15,104] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8450
[2019-03-20 15:28:15,110] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 98.0, 1.0, 2.0, 0.3772304345175962, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 422557.2128306634, 422557.2128306631, 121566.4605765723], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1290000.0000, 
sim time next is 1290600.0000, 
raw observation next is [18.0, 97.0, 1.0, 2.0, 0.3749921202029073, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 419469.2839158336, 419469.2839158339, 121110.6124046775], 
processed observation next is [1.0, 0.9565217391304348, 0.45454545454545453, 0.97, 1.0, 1.0, 0.21874015025363408, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15535899404290135, 0.15535899404290146, 0.2953917375723841], 
reward next is 0.7046, 
noisyNet noise sample is [array([0.61186546], dtype=float32), 0.981256]. 
=============================================
[2019-03-20 15:28:20,081] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 2.6034757e-24 2.6731452e-33 0.0000000e+00], sum to 1.0000
[2019-03-20 15:28:20,088] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6863
[2019-03-20 15:28:20,187] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 93.00000000000001, 1.0, 2.0, 0.5074204172716779, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 578789.6671576203, 578789.6671576203, 142773.5759532696], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1372200.0000, 
sim time next is 1372800.0000, 
raw observation next is [22.0, 92.0, 1.0, 2.0, 0.5021414255916112, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 572876.201094428, 572876.201094428, 141896.2214322412], 
processed observation next is [1.0, 0.9130434782608695, 0.6363636363636364, 0.92, 1.0, 1.0, 0.377676781989514, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21217637077571405, 0.21217637077571405, 0.3460883449566859], 
reward next is 0.6539, 
noisyNet noise sample is [array([-0.24923943], dtype=float32), -1.2581716]. 
=============================================
[2019-03-20 15:28:24,493] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 2.036769e-30 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-20 15:28:24,504] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0451
[2019-03-20 15:28:24,509] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 71.0, 1.0, 2.0, 0.5305657620625236, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 603445.0426020129, 603445.0426020129, 147231.0573433432], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1436400.0000, 
sim time next is 1437000.0000, 
raw observation next is [25.5, 73.0, 1.0, 2.0, 0.5256289068125499, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 598278.037743388, 598278.037743388, 146325.9144859475], 
processed observation next is [0.0, 0.6521739130434783, 0.7954545454545454, 0.73, 1.0, 1.0, 0.40703613351568735, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22158445842347702, 0.22158445842347702, 0.3568924743559695], 
reward next is 0.6431, 
noisyNet noise sample is [array([1.19648], dtype=float32), -2.0376935]. 
=============================================
[2019-03-20 15:28:24,523] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[68.81583 ]
 [68.80571 ]
 [68.81814 ]
 [68.83022 ]
 [68.838715]], R is [[68.79371643]
 [68.74668121]
 [68.69821167]
 [68.6481781 ]
 [68.59638977]].
[2019-03-20 15:28:28,680] A3C_AGENT_WORKER-Thread-16 INFO:Local step 2500, global step 39858: loss 0.1151
[2019-03-20 15:28:28,682] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 2500, global step 39858: learning rate 0.0010
[2019-03-20 15:28:28,729] A3C_AGENT_WORKER-Thread-17 INFO:Local step 2500, global step 39876: loss 0.1077
[2019-03-20 15:28:28,733] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 2500, global step 39877: learning rate 0.0010
[2019-03-20 15:28:28,761] A3C_AGENT_WORKER-Thread-19 INFO:Local step 2500, global step 39889: loss 0.0312
[2019-03-20 15:28:28,766] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 2500, global step 39890: learning rate 0.0010
[2019-03-20 15:28:28,841] A3C_AGENT_WORKER-Thread-2 INFO:Local step 2500, global step 39916: loss 0.0008
[2019-03-20 15:28:28,844] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 2500, global step 39916: learning rate 0.0010
[2019-03-20 15:28:28,909] A3C_AGENT_WORKER-Thread-15 INFO:Local step 2500, global step 39944: loss 0.0010
[2019-03-20 15:28:28,914] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 2500, global step 39946: learning rate 0.0010
[2019-03-20 15:28:28,946] A3C_AGENT_WORKER-Thread-14 INFO:Local step 2500, global step 39959: loss 0.0244
[2019-03-20 15:28:28,947] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 2500, global step 39959: learning rate 0.0010
[2019-03-20 15:28:28,969] A3C_AGENT_WORKER-Thread-3 INFO:Local step 2500, global step 39967: loss 0.0072
[2019-03-20 15:28:28,975] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 2500, global step 39970: learning rate 0.0010
[2019-03-20 15:28:28,981] A3C_AGENT_WORKER-Thread-10 INFO:Local step 2500, global step 39971: loss 0.0216
[2019-03-20 15:28:28,983] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 2500, global step 39971: learning rate 0.0010
[2019-03-20 15:28:28,995] A3C_AGENT_WORKER-Thread-18 INFO:Local step 2500, global step 39976: loss 0.0300
[2019-03-20 15:28:28,998] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 2500, global step 39976: learning rate 0.0010
[2019-03-20 15:28:29,039] A3C_AGENT_WORKER-Thread-13 INFO:Local step 2500, global step 39987: loss 0.0479
[2019-03-20 15:28:29,042] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 2500, global step 39988: learning rate 0.0010
[2019-03-20 15:28:29,143] A3C_AGENT_WORKER-Thread-11 INFO:Local step 2500, global step 40028: loss 0.0490
[2019-03-20 15:28:29,146] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 2500, global step 40029: learning rate 0.0010
[2019-03-20 15:28:29,199] A3C_AGENT_WORKER-Thread-22 INFO:Local step 2500, global step 40053: loss 0.0277
[2019-03-20 15:28:29,200] A3C_AGENT_WORKER-Thread-21 INFO:Local step 2500, global step 40054: loss 0.0329
[2019-03-20 15:28:29,202] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 2500, global step 40054: learning rate 0.0010
[2019-03-20 15:28:29,205] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 2500, global step 40054: learning rate 0.0010
[2019-03-20 15:28:29,254] A3C_AGENT_WORKER-Thread-9 INFO:Local step 2500, global step 40071: loss 0.0279
[2019-03-20 15:28:29,256] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 2500, global step 40072: learning rate 0.0010
[2019-03-20 15:28:29,301] A3C_AGENT_WORKER-Thread-20 INFO:Local step 2500, global step 40087: loss 0.0027
[2019-03-20 15:28:29,304] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 2500, global step 40088: learning rate 0.0010
[2019-03-20 15:28:29,431] A3C_AGENT_WORKER-Thread-12 INFO:Local step 2500, global step 40142: loss 0.0476
[2019-03-20 15:28:29,435] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 2500, global step 40142: learning rate 0.0010
[2019-03-20 15:28:33,938] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.1348852e-34 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-20 15:28:33,952] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7510
[2019-03-20 15:28:34,058] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.4371958754442346, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 495669.2455010431, 495669.2455010434, 130056.137521141], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1572600.0000, 
sim time next is 1573200.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4277156209456487, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 484910.3825891308, 484910.3825891311, 129125.0218332801], 
processed observation next is [1.0, 0.21739130434782608, 0.5, 1.0, 1.0, 1.0, 0.2846445261820608, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17959643799597436, 0.1795964379959745, 0.31493907764214657], 
reward next is 0.6851, 
noisyNet noise sample is [array([-0.30254522], dtype=float32), -0.39095867]. 
=============================================
[2019-03-20 15:28:40,788] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.7954909e-37 1.0000000e+00 4.0522105e-28 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-20 15:28:40,799] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4883
[2019-03-20 15:28:40,806] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 91.0, 1.0, 2.0, 0.5845111958771495, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 649110.1873376587, 649110.1873376587, 139606.0639030962], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1675800.0000, 
sim time next is 1676400.0000, 
raw observation next is [18.0, 90.0, 1.0, 2.0, 0.5569430480895754, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 617337.9318874725, 617337.9318874725, 136264.49852985], 
processed observation next is [1.0, 0.391304347826087, 0.45454545454545453, 0.9, 1.0, 1.0, 0.4461788101119692, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22864367847684167, 0.22864367847684167, 0.33235243543865856], 
reward next is 0.6676, 
noisyNet noise sample is [array([-0.99603957], dtype=float32), 0.14914434]. 
=============================================
[2019-03-20 15:28:41,272] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 2.868832e-31 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-20 15:28:41,282] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7728
[2019-03-20 15:28:41,289] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.5, 83.0, 1.0, 2.0, 0.6470200401942398, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 713791.1280329049, 713791.1280329049, 144848.2073124284], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1679400.0000, 
sim time next is 1680000.0000, 
raw observation next is [18.66666666666667, 81.33333333333334, 1.0, 2.0, 0.6101186935569594, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 672564.3133418888, 672564.3133418888, 140610.0202335841], 
processed observation next is [1.0, 0.43478260869565216, 0.4848484848484851, 0.8133333333333335, 1.0, 1.0, 0.5126483669461992, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2490978938303292, 0.2490978938303292, 0.34295126886240024], 
reward next is 0.6570, 
noisyNet noise sample is [array([-0.4087264], dtype=float32), 1.1796819]. 
=============================================
[2019-03-20 15:28:41,316] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[72.032036]
 [72.080635]
 [72.09261 ]
 [72.07066 ]
 [72.03416 ]], R is [[71.89243317]
 [71.82022095]
 [71.75588226]
 [71.67507935]
 [71.6287384 ]].
[2019-03-20 15:28:43,976] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.0361789e-38 1.0000000e+00 3.3365284e-27 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-20 15:28:43,983] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2392
[2019-03-20 15:28:43,990] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.66666666666667, 70.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 203563.4814471212, 203563.4814471209, 65956.69098296766], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1718400.0000, 
sim time next is 1719000.0000, 
raw observation next is [12.5, 71.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 200979.3424372083, 200979.3424372086, 65540.12873585602], 
processed observation next is [1.0, 0.9130434782608695, 0.20454545454545456, 0.715, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07443679349526233, 0.07443679349526244, 0.1598539725264781], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.205545], dtype=float32), 0.46921134]. 
=============================================
[2019-03-20 15:28:44,024] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[71.79852]
 [71.72812]
 [71.66806]
 [71.62407]
 [71.61184]], R is [[71.14932251]
 [70.43782806]
 [69.73345184]
 [69.03611755]
 [68.34575653]].
[2019-03-20 15:28:46,752] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 4.250751e-34 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-20 15:28:46,764] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1845
[2019-03-20 15:28:46,854] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.33333333333333, 64.33333333333334, 1.0, 2.0, 0.2600985596005329, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 282416.035395258, 282416.0353952583, 73658.57985954499], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1759200.0000, 
sim time next is 1759800.0000, 
raw observation next is [13.66666666666667, 63.66666666666666, 1.0, 2.0, 0.2678880894790642, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 290876.4667697563, 290876.4667697563, 74623.30857664163], 
processed observation next is [1.0, 0.34782608695652173, 0.25757575757575774, 0.6366666666666666, 1.0, 1.0, 0.0848601118488302, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10773202472953937, 0.10773202472953937, 0.18200806969912595], 
reward next is 0.8180, 
noisyNet noise sample is [array([0.56031334], dtype=float32), -0.5150385]. 
=============================================
[2019-03-20 15:28:48,513] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 3.1879395e-29 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-20 15:28:48,522] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9901
[2019-03-20 15:28:48,615] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.16666666666667, 42.66666666666666, 1.0, 2.0, 0.3193248065549847, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 346747.0527106086, 346747.0527106083, 83766.36830863659], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1789800.0000, 
sim time next is 1790400.0000, 
raw observation next is [19.13333333333333, 43.33333333333334, 1.0, 2.0, 0.2734933868142997, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 296964.6317178563, 296964.6317178563, 79040.6590197684], 
processed observation next is [1.0, 0.7391304347826086, 0.5060606060606059, 0.4333333333333334, 1.0, 1.0, 0.0918667335178746, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10998690063624307, 0.10998690063624307, 0.1927820951701668], 
reward next is 0.8072, 
noisyNet noise sample is [array([1.1307179], dtype=float32), 1.0678209]. 
=============================================
[2019-03-20 15:28:48,920] A3C_AGENT_WORKER-Thread-16 INFO:Local step 3000, global step 47819: loss 0.0027
[2019-03-20 15:28:48,920] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 3000, global step 47819: learning rate 0.0010
[2019-03-20 15:28:48,999] A3C_AGENT_WORKER-Thread-19 INFO:Local step 3000, global step 47855: loss 0.0128
[2019-03-20 15:28:49,003] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 3000, global step 47855: learning rate 0.0010
[2019-03-20 15:28:49,063] A3C_AGENT_WORKER-Thread-17 INFO:Local step 3000, global step 47882: loss 0.0663
[2019-03-20 15:28:49,068] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 3000, global step 47883: learning rate 0.0010
[2019-03-20 15:28:49,182] A3C_AGENT_WORKER-Thread-2 INFO:Local step 3000, global step 47934: loss 0.0101
[2019-03-20 15:28:49,184] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 3000, global step 47934: learning rate 0.0010
[2019-03-20 15:28:49,227] A3C_AGENT_WORKER-Thread-3 INFO:Local step 3000, global step 47952: loss 0.0539
[2019-03-20 15:28:49,229] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 3000, global step 47952: learning rate 0.0010
[2019-03-20 15:28:49,230] A3C_AGENT_WORKER-Thread-14 INFO:Local step 3000, global step 47953: loss 0.0440
[2019-03-20 15:28:49,234] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 3000, global step 47954: learning rate 0.0010
[2019-03-20 15:28:49,282] A3C_AGENT_WORKER-Thread-10 INFO:Local step 3000, global step 47975: loss 0.1085
[2019-03-20 15:28:49,284] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 3000, global step 47975: learning rate 0.0010
[2019-03-20 15:28:49,332] A3C_AGENT_WORKER-Thread-18 INFO:Local step 3000, global step 47992: loss 0.1618
[2019-03-20 15:28:49,333] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 3000, global step 47992: learning rate 0.0010
[2019-03-20 15:28:49,336] A3C_AGENT_WORKER-Thread-15 INFO:Local step 3000, global step 47993: loss 0.2365
[2019-03-20 15:28:49,339] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 3000, global step 47993: learning rate 0.0010
[2019-03-20 15:28:49,369] A3C_AGENT_WORKER-Thread-11 INFO:Local step 3000, global step 48003: loss 0.3785
[2019-03-20 15:28:49,371] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 3000, global step 48003: learning rate 0.0010
[2019-03-20 15:28:49,417] A3C_AGENT_WORKER-Thread-13 INFO:Local step 3000, global step 48020: loss 0.3652
[2019-03-20 15:28:49,423] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 3000, global step 48021: learning rate 0.0010
[2019-03-20 15:28:49,497] A3C_AGENT_WORKER-Thread-12 INFO:Local step 3000, global step 48054: loss 0.1644
[2019-03-20 15:28:49,498] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 3000, global step 48054: learning rate 0.0010
[2019-03-20 15:28:49,508] A3C_AGENT_WORKER-Thread-21 INFO:Local step 3000, global step 48059: loss 0.1133
[2019-03-20 15:28:49,512] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 3000, global step 48059: learning rate 0.0010
[2019-03-20 15:28:49,557] A3C_AGENT_WORKER-Thread-22 INFO:Local step 3000, global step 48075: loss 0.0573
[2019-03-20 15:28:49,560] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 3000, global step 48077: learning rate 0.0010
[2019-03-20 15:28:49,583] A3C_AGENT_WORKER-Thread-9 INFO:Local step 3000, global step 48083: loss 0.0120
[2019-03-20 15:28:49,589] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 3000, global step 48085: learning rate 0.0010
[2019-03-20 15:28:49,735] A3C_AGENT_WORKER-Thread-20 INFO:Local step 3000, global step 48145: loss 0.0390
[2019-03-20 15:28:49,738] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 3000, global step 48146: learning rate 0.0010
[2019-03-20 15:28:54,452] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-20 15:28:54,455] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-20 15:28:54,456] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-20 15:28:54,457] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-20 15:28:54,457] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-20 15:28:54,458] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-20 15:28:54,459] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-20 15:28:54,460] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-20 15:28:54,460] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-20 15:28:54,463] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-20 15:28:54,462] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-20 15:28:54,479] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run3
[2019-03-20 15:28:54,479] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run3
[2019-03-20 15:28:54,495] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run3
[2019-03-20 15:28:54,527] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run3
[2019-03-20 15:28:54,546] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run3
[2019-03-20 15:29:19,693] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.3060438], dtype=float32), -0.041486386]
[2019-03-20 15:29:19,694] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.66666666666667, 79.0, 1.0, 2.0, 0.9179364649179063, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344353936, 1047615.144266214, 1047615.144266214, 203505.5165024781]
[2019-03-20 15:29:19,694] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-20 15:29:19,696] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.4054052e-35 1.0000000e+00 1.1804615e-29 0.0000000e+00 0.0000000e+00], sampled 0.34026240918458384
[2019-03-20 15:29:30,298] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.3060438], dtype=float32), -0.041486386]
[2019-03-20 15:29:30,299] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [13.45804512, 82.61695966, 1.0, 2.0, 0.675006868371841, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 733159.3801817596, 733159.3801817592, 126687.6676006937]
[2019-03-20 15:29:30,299] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-20 15:29:30,302] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.5459667e-31 1.0000000e+00 8.5657766e-28 0.0000000e+00 0.0000000e+00], sampled 0.6829696429544655
[2019-03-20 15:29:35,245] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.3060438], dtype=float32), -0.041486386]
[2019-03-20 15:29:35,246] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.88333333333333, 80.66666666666666, 1.0, 2.0, 0.941483888537904, 1.0, 2.0, 0.941483888537904, 0.0, 2.0, 0.0, 6.9112, 6.9112, 134.5847722217142, 2135422.38316586, 2135422.38316586, 381175.6981078051]
[2019-03-20 15:29:35,246] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-20 15:29:35,248] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [6.9864854e-37 1.0000000e+00 2.2020876e-30 0.0000000e+00 0.0000000e+00], sampled 0.2256964471460876
[2019-03-20 15:29:35,249] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 2135422.38316586 W.
[2019-03-20 15:29:43,649] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.3060438], dtype=float32), -0.041486386]
[2019-03-20 15:29:43,650] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [26.73333333333333, 57.0, 1.0, 2.0, 0.7129429423946632, 1.0, 2.0, 0.7129429423946632, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 109.0368377193198, 1621923.853014024, 1621923.853014024, 296609.9941097748]
[2019-03-20 15:29:43,650] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-20 15:29:43,654] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0.0000000e+00 1.0000000e+00 1.4404402e-29 0.0000000e+00 0.0000000e+00], sampled 0.3980872086275097
[2019-03-20 15:29:43,655] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 1621923.853014024 W.
[2019-03-20 15:29:52,589] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.3060438], dtype=float32), -0.041486386]
[2019-03-20 15:29:52,590] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.03670633, 91.84949101666668, 1.0, 2.0, 0.9607125067836865, 1.0, 2.0, 0.9607125067836865, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 127.237645046519, 2160481.025242586, 2160481.025242585, 392026.5943186223]
[2019-03-20 15:29:52,591] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-20 15:29:52,594] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0.0000000e+00 1.0000000e+00 1.7208576e-32 0.0000000e+00 0.0000000e+00], sampled 0.848434970710508
[2019-03-20 15:29:52,594] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 0, 1] for the demand 2160481.025242586 W.
[2019-03-20 15:30:02,728] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.3060438], dtype=float32), -0.041486386]
[2019-03-20 15:30:02,729] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [28.03914894, 47.75383213, 1.0, 2.0, 0.8939593925413399, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9440865282239724, 6.938781041860323, 6.9112, 108.3870836925355, 1568566.830775764, 1556011.230267507, 312566.8421925954]
[2019-03-20 15:30:02,731] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-20 15:30:02,736] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 2.4869783e-29 0.0000000e+00 0.0000000e+00], sampled 0.9748878942317813
[2019-03-20 15:30:02,738] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1568566.830775764 W.
[2019-03-20 15:30:16,789] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.3060438], dtype=float32), -0.041486386]
[2019-03-20 15:30:16,792] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [17.93333333333333, 86.66666666666667, 1.0, 2.0, 0.6307821334922263, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8566412179534578, 7.027958970071546, 6.9112, 109.0505122151388, 1249755.777025681, 1196278.749959222, 242419.8159817134]
[2019-03-20 15:30:16,792] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-20 15:30:16,795] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.836534e-38 1.000000e+00 3.371788e-29 0.000000e+00 0.000000e+00], sampled 0.3328925611056668
[2019-03-20 15:30:16,796] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1249755.777025681 W.
[2019-03-20 15:30:16,949] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.3060438], dtype=float32), -0.041486386]
[2019-03-20 15:30:16,950] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.4, 72.0, 1.0, 2.0, 0.8519088489135638, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9193787433009719, 6.962440448344325, 6.9112, 111.3351388629787, 1517806.087316239, 1493845.665102609, 296237.5624515599]
[2019-03-20 15:30:16,950] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-20 15:30:16,953] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 5.0564207e-30 0.0000000e+00 0.0000000e+00], sampled 0.2073156388551708
[2019-03-20 15:30:16,955] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1517806.087316239 W.
[2019-03-20 15:30:24,100] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.3060438], dtype=float32), -0.041486386]
[2019-03-20 15:30:24,100] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.3, 81.0, 1.0, 2.0, 0.9278539539758269, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8840428966609637, 6.982675525820412, 6.9112, 125.0348457983256, 1579669.030822191, 1542133.919155091, 286460.0146608495]
[2019-03-20 15:30:24,100] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-20 15:30:24,101] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0.000000e+00 1.000000e+00 1.551515e-30 0.000000e+00 0.000000e+00], sampled 0.2977921842284146
[2019-03-20 15:30:24,105] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1579669.030822191 W.
[2019-03-20 15:30:55,663] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.3060438], dtype=float32), -0.041486386]
[2019-03-20 15:30:55,664] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.91666666666667, 71.5, 1.0, 2.0, 0.7573054581922994, 1.0, 2.0, 0.7573054581922994, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 128.2516629784311, 1724253.191077585, 1724253.191077585, 295485.4909851354]
[2019-03-20 15:30:55,665] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-20 15:30:55,669] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0.0000000e+00 1.0000000e+00 2.4988356e-30 0.0000000e+00 0.0000000e+00], sampled 0.09209558686373298
[2019-03-20 15:30:55,670] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 1724253.191077585 W.
[2019-03-20 15:30:57,133] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2253.5573 3698511688.1296 5675.0000
[2019-03-20 15:30:57,179] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 1924.7737 3866989180.0330 5862.0000
[2019-03-20 15:30:57,330] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-20 15:30:57,374] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 2172.4380 3782240375.2322 5705.0000
[2019-03-20 15:30:57,388] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 2144.1795 3675091189.9661 6098.0000
[2019-03-20 15:30:58,402] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 50000, evaluation results [50000.0, 8513.049178629926, 1773161079.4054089, 173.0, 2144.179453714918, 3675091189.9661098, 6098.0, 1924.77367170601, 3866989180.032976, 5862.0, 2253.5573424559147, 3698511688.129632, 5675.0, 2172.437985818527, 3782240375.2322435, 5705.0]
[2019-03-20 15:31:00,943] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 4.621691e-32 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-20 15:31:00,952] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5550
[2019-03-20 15:31:01,054] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 94.0, 1.0, 2.0, 0.3384032042513861, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 376151.8927272452, 376151.8927272449, 117065.6122214563], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1911600.0000, 
sim time next is 1912200.0000, 
raw observation next is [18.0, 95.0, 1.0, 2.0, 0.3427371908389372, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 381782.9556472254, 381782.9556472254, 117748.4646100777], 
processed observation next is [1.0, 0.13043478260869565, 0.45454545454545453, 0.95, 1.0, 1.0, 0.17842148854867151, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14140109468415754, 0.14140109468415754, 0.2871913770977505], 
reward next is 0.7128, 
noisyNet noise sample is [array([1.9927351], dtype=float32), 1.0151639]. 
=============================================
[2019-03-20 15:31:01,838] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 2.573183e-32 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-20 15:31:01,850] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4544
[2019-03-20 15:31:01,855] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.66666666666666, 96.0, 1.0, 2.0, 0.4330600254318124, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 491649.153039717, 491649.153039717, 130130.9667276763], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1928400.0000, 
sim time next is 1929000.0000, 
raw observation next is [19.83333333333334, 95.0, 1.0, 2.0, 0.4367247768267962, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 495977.3134823611, 495977.3134823611, 130620.3461809839], 
processed observation next is [1.0, 0.30434782608695654, 0.5378787878787882, 0.95, 1.0, 1.0, 0.29590597103349525, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18369530128976336, 0.18369530128976336, 0.3185862101975217], 
reward next is 0.6814, 
noisyNet noise sample is [array([-1.3187463], dtype=float32), -0.58945894]. 
=============================================
[2019-03-20 15:31:01,870] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[75.808205]
 [75.80969 ]
 [75.790474]
 [75.769485]
 [75.72338 ]], R is [[75.71878052]
 [75.64420319]
 [75.5717392 ]
 [75.49996948]
 [75.42599487]].
[2019-03-20 15:31:12,905] A3C_AGENT_WORKER-Thread-16 INFO:Local step 3500, global step 55801: loss 0.0040
[2019-03-20 15:31:12,910] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 3500, global step 55802: learning rate 0.0010
[2019-03-20 15:31:12,976] A3C_AGENT_WORKER-Thread-19 INFO:Local step 3500, global step 55833: loss 0.0022
[2019-03-20 15:31:12,980] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 3500, global step 55833: learning rate 0.0010
[2019-03-20 15:31:13,148] A3C_AGENT_WORKER-Thread-2 INFO:Local step 3500, global step 55900: loss 0.0077
[2019-03-20 15:31:13,150] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 3500, global step 55900: learning rate 0.0010
[2019-03-20 15:31:13,188] A3C_AGENT_WORKER-Thread-10 INFO:Local step 3500, global step 55918: loss 0.0161
[2019-03-20 15:31:13,190] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 3500, global step 55918: learning rate 0.0010
[2019-03-20 15:31:13,225] A3C_AGENT_WORKER-Thread-14 INFO:Local step 3500, global step 55934: loss 0.0144
[2019-03-20 15:31:13,227] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 3500, global step 55934: learning rate 0.0010
[2019-03-20 15:31:13,244] A3C_AGENT_WORKER-Thread-17 INFO:Local step 3500, global step 55940: loss 0.0685
[2019-03-20 15:31:13,247] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 3500, global step 55940: learning rate 0.0010
[2019-03-20 15:31:13,307] A3C_AGENT_WORKER-Thread-15 INFO:Local step 3500, global step 55965: loss 0.0766
[2019-03-20 15:31:13,311] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 3500, global step 55965: learning rate 0.0010
[2019-03-20 15:31:13,343] A3C_AGENT_WORKER-Thread-3 INFO:Local step 3500, global step 55979: loss 0.0751
[2019-03-20 15:31:13,347] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 3500, global step 55979: learning rate 0.0010
[2019-03-20 15:31:13,379] A3C_AGENT_WORKER-Thread-18 INFO:Local step 3500, global step 55995: loss 0.0760
[2019-03-20 15:31:13,381] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 3500, global step 55995: learning rate 0.0010
[2019-03-20 15:31:13,421] A3C_AGENT_WORKER-Thread-11 INFO:Local step 3500, global step 56007: loss 0.0598
[2019-03-20 15:31:13,424] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 3500, global step 56008: learning rate 0.0010
[2019-03-20 15:31:13,461] A3C_AGENT_WORKER-Thread-21 INFO:Local step 3500, global step 56022: loss 0.0504
[2019-03-20 15:31:13,464] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 3500, global step 56022: learning rate 0.0010
[2019-03-20 15:31:13,470] A3C_AGENT_WORKER-Thread-13 INFO:Local step 3500, global step 56023: loss 0.0583
[2019-03-20 15:31:13,473] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 3500, global step 56024: learning rate 0.0010
[2019-03-20 15:31:13,533] A3C_AGENT_WORKER-Thread-12 INFO:Local step 3500, global step 56048: loss 0.0399
[2019-03-20 15:31:13,539] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 3500, global step 56049: learning rate 0.0010
[2019-03-20 15:31:13,622] A3C_AGENT_WORKER-Thread-22 INFO:Local step 3500, global step 56086: loss 0.0039
[2019-03-20 15:31:13,626] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 3500, global step 56088: learning rate 0.0010
[2019-03-20 15:31:13,830] A3C_AGENT_WORKER-Thread-9 INFO:Local step 3500, global step 56167: loss 0.0326
[2019-03-20 15:31:13,834] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 3500, global step 56167: learning rate 0.0010
[2019-03-20 15:31:13,894] A3C_AGENT_WORKER-Thread-20 INFO:Local step 3500, global step 56189: loss 0.0785
[2019-03-20 15:31:13,897] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 3500, global step 56190: learning rate 0.0010
[2019-03-20 15:31:15,826] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.3700181e-36 1.0000000e+00 3.4368970e-31 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-20 15:31:15,838] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3446
[2019-03-20 15:31:15,844] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 54.0, 1.0, 2.0, 0.4141554417034083, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 470351.4711665613, 470351.4711665616, 128423.0007957277], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2138400.0000, 
sim time next is 2139000.0000, 
raw observation next is [25.66666666666667, 55.16666666666666, 1.0, 2.0, 0.4128086259231634, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 468625.4113804636, 468625.4113804639, 128141.7443008568], 
processed observation next is [0.0, 0.782608695652174, 0.8030303030303032, 0.5516666666666665, 1.0, 1.0, 0.26601078240395426, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1735649671779495, 0.1735649671779496, 0.3125408397581873], 
reward next is 0.6875, 
noisyNet noise sample is [array([0.9739884], dtype=float32), -0.65067154]. 
=============================================
[2019-03-20 15:31:15,860] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[77.27325 ]
 [77.219864]
 [77.185646]
 [77.14497 ]
 [77.10066 ]], R is [[77.24202728]
 [77.1563797 ]
 [77.0718689 ]
 [76.9883728 ]
 [76.9057312 ]].
[2019-03-20 15:31:18,374] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 3.9219515e-36 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-20 15:31:18,386] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8961
[2019-03-20 15:31:18,393] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.33333333333333, 92.0, 1.0, 2.0, 0.2925533324136691, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 317667.0640787348, 317667.0640787348, 104572.8205716028], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2169600.0000, 
sim time next is 2170200.0000, 
raw observation next is [16.16666666666667, 93.0, 1.0, 2.0, 0.2903003716646869, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 315219.9089858207, 315219.9089858204, 103238.5737234071], 
processed observation next is [1.0, 0.08695652173913043, 0.37121212121212144, 0.93, 1.0, 1.0, 0.11287546458085863, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11674811443919286, 0.11674811443919275, 0.25180139932538315], 
reward next is 0.7482, 
noisyNet noise sample is [array([0.5413705], dtype=float32), -0.81731385]. 
=============================================
[2019-03-20 15:31:19,083] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.7801368e-33 1.0000000e+00 2.7618771e-31 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-20 15:31:19,094] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1434
[2019-03-20 15:31:19,105] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.43333333333333, 92.66666666666667, 1.0, 2.0, 0.2319932922854099, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 251891.3234914352, 251891.3234914352, 79880.04065475283], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2182800.0000, 
sim time next is 2183400.0000, 
raw observation next is [14.55, 92.0, 1.0, 2.0, 0.2315453933415509, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 251404.8826328927, 251404.8826328925, 80027.21876088354], 
processed observation next is [1.0, 0.2608695652173913, 0.2977272727272728, 0.92, 1.0, 1.0, 0.039431741676938595, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09311291949366396, 0.09311291949366389, 0.19518833844117936], 
reward next is 0.8048, 
noisyNet noise sample is [array([0.84521437], dtype=float32), -2.3703394]. 
=============================================
[2019-03-20 15:31:28,874] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 6.0440514e-33 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-20 15:31:28,888] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7160
[2019-03-20 15:31:28,994] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 54.0, 1.0, 2.0, 0.2334432704827233, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 253466.0763310824, 253466.0763310826, 73906.32278039334], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2326800.0000, 
sim time next is 2327400.0000, 
raw observation next is [17.0, 53.5, 1.0, 2.0, 0.2330165184701041, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 253002.6005956023, 253002.600595602, 73747.4288472536], 
processed observation next is [1.0, 0.9565217391304348, 0.4090909090909091, 0.535, 1.0, 1.0, 0.04127064808763011, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0937046668872601, 0.09370466688726001, 0.17987177767622828], 
reward next is 0.8201, 
noisyNet noise sample is [array([-0.08464982], dtype=float32), 0.9312782]. 
=============================================
[2019-03-20 15:31:33,284] A3C_AGENT_WORKER-Thread-19 INFO:Local step 4000, global step 63814: loss 2.0265
[2019-03-20 15:31:33,286] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 4000, global step 63814: learning rate 0.0010
[2019-03-20 15:31:33,416] A3C_AGENT_WORKER-Thread-16 INFO:Local step 4000, global step 63881: loss 0.6105
[2019-03-20 15:31:33,420] A3C_AGENT_WORKER-Thread-2 INFO:Local step 4000, global step 63883: loss 0.4858
[2019-03-20 15:31:33,423] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 4000, global step 63883: learning rate 0.0010
[2019-03-20 15:31:33,425] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 4000, global step 63883: learning rate 0.0010
[2019-03-20 15:31:33,476] A3C_AGENT_WORKER-Thread-10 INFO:Local step 4000, global step 63904: loss 0.7211
[2019-03-20 15:31:33,478] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 4000, global step 63904: learning rate 0.0010
[2019-03-20 15:31:33,532] A3C_AGENT_WORKER-Thread-15 INFO:Local step 4000, global step 63931: loss 0.4260
[2019-03-20 15:31:33,539] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 4000, global step 63934: learning rate 0.0010
[2019-03-20 15:31:33,557] A3C_AGENT_WORKER-Thread-3 INFO:Local step 4000, global step 63946: loss 0.1463
[2019-03-20 15:31:33,558] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 4000, global step 63946: learning rate 0.0010
[2019-03-20 15:31:33,559] A3C_AGENT_WORKER-Thread-17 INFO:Local step 4000, global step 63947: loss 0.3265
[2019-03-20 15:31:33,562] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 4000, global step 63947: learning rate 0.0010
[2019-03-20 15:31:33,579] A3C_AGENT_WORKER-Thread-14 INFO:Local step 4000, global step 63955: loss 0.0565
[2019-03-20 15:31:33,584] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 4000, global step 63958: learning rate 0.0010
[2019-03-20 15:31:33,630] A3C_AGENT_WORKER-Thread-21 INFO:Local step 4000, global step 63976: loss 0.0773
[2019-03-20 15:31:33,632] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 4000, global step 63976: learning rate 0.0010
[2019-03-20 15:31:33,657] A3C_AGENT_WORKER-Thread-13 INFO:Local step 4000, global step 63988: loss 0.1273
[2019-03-20 15:31:33,664] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 4000, global step 63989: learning rate 0.0010
[2019-03-20 15:31:33,703] A3C_AGENT_WORKER-Thread-11 INFO:Local step 4000, global step 64013: loss 0.1279
[2019-03-20 15:31:33,704] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 4000, global step 64013: learning rate 0.0010
[2019-03-20 15:31:33,711] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 6.0019336e-34 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-20 15:31:33,724] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5350
[2019-03-20 15:31:33,725] A3C_AGENT_WORKER-Thread-18 INFO:Local step 4000, global step 64024: loss 0.0408
[2019-03-20 15:31:33,726] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 4000, global step 64024: learning rate 0.0010
[2019-03-20 15:31:33,728] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.5, 49.5, 1.0, 2.0, 0.2970670769777586, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 322569.9086915394, 322569.9086915394, 95148.90058355757], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2395800.0000, 
sim time next is 2396400.0000, 
raw observation next is [21.33333333333334, 50.66666666666666, 1.0, 2.0, 0.2960218531902059, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 321434.5786803224, 321434.5786803224, 95334.4898168836], 
processed observation next is [1.0, 0.7391304347826086, 0.6060606060606063, 0.5066666666666666, 1.0, 1.0, 0.12002731648775737, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11904984395567496, 0.11904984395567496, 0.23252314589483802], 
reward next is 0.7675, 
noisyNet noise sample is [array([1.7205247], dtype=float32), -0.0991334]. 
=============================================
[2019-03-20 15:31:33,771] A3C_AGENT_WORKER-Thread-12 INFO:Local step 4000, global step 64040: loss 0.0112
[2019-03-20 15:31:33,774] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 4000, global step 64040: learning rate 0.0010
[2019-03-20 15:31:33,934] A3C_AGENT_WORKER-Thread-22 INFO:Local step 4000, global step 64117: loss 0.0043
[2019-03-20 15:31:33,938] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 4000, global step 64117: learning rate 0.0010
[2019-03-20 15:31:34,006] A3C_AGENT_WORKER-Thread-9 INFO:Local step 4000, global step 64149: loss 0.0092
[2019-03-20 15:31:34,008] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 4000, global step 64149: learning rate 0.0010
[2019-03-20 15:31:34,151] A3C_AGENT_WORKER-Thread-20 INFO:Local step 4000, global step 64216: loss 0.0712
[2019-03-20 15:31:34,153] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 4000, global step 64217: learning rate 0.0010
[2019-03-20 15:31:34,571] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-20 15:31:34,584] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9411
[2019-03-20 15:31:34,594] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.66666666666667, 71.0, 1.0, 2.0, 0.2512357436882616, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 272790.0563262376, 272790.0563262376, 86090.86077600718], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2413200.0000, 
sim time next is 2413800.0000, 
raw observation next is [17.5, 72.5, 1.0, 2.0, 0.2519871229396698, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 273606.1282734296, 273606.1282734299, 86382.5788957306], 
processed observation next is [1.0, 0.9565217391304348, 0.4318181818181818, 0.725, 1.0, 1.0, 0.06498390367458723, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10133560306423318, 0.10133560306423328, 0.21068921681885514], 
reward next is 0.7893, 
noisyNet noise sample is [array([0.81048054], dtype=float32), 0.46367714]. 
=============================================
[2019-03-20 15:31:41,592] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.9196445e-33 1.0000000e+00 1.5244806e-30 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-20 15:31:41,603] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5050
[2019-03-20 15:31:41,608] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 94.0, 1.0, 2.0, 0.2010026742331964, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 218235.0958290283, 218235.095829028, 72226.29647893488], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2516400.0000, 
sim time next is 2517000.0000, 
raw observation next is [12.98333333333333, 94.5, 1.0, 2.0, 0.2065446323705059, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 224253.5658492831, 224253.5658492828, 72779.67203310813], 
processed observation next is [1.0, 0.13043478260869565, 0.2265151515151514, 0.945, 1.0, 1.0, 0.008180790463132373, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08305687624047522, 0.08305687624047511, 0.17751139520270276], 
reward next is 0.8225, 
noisyNet noise sample is [array([0.86838096], dtype=float32), -0.2040503]. 
=============================================
[2019-03-20 15:31:41,627] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[75.358154]
 [75.468544]
 [75.60539 ]
 [75.76758 ]
 [75.92361 ]], R is [[75.22868347]
 [75.30023193]
 [75.36968231]
 [75.43656158]
 [75.49573517]].
[2019-03-20 15:31:53,507] A3C_AGENT_WORKER-Thread-19 INFO:Local step 4500, global step 71813: loss 0.0001
[2019-03-20 15:31:53,509] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 4500, global step 71813: learning rate 0.0010
[2019-03-20 15:31:53,564] A3C_AGENT_WORKER-Thread-2 INFO:Local step 4500, global step 71839: loss 0.0039
[2019-03-20 15:31:53,567] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 4500, global step 71841: learning rate 0.0010
[2019-03-20 15:31:53,668] A3C_AGENT_WORKER-Thread-16 INFO:Local step 4500, global step 71884: loss 0.0008
[2019-03-20 15:31:53,670] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 4500, global step 71884: learning rate 0.0010
[2019-03-20 15:31:53,688] A3C_AGENT_WORKER-Thread-10 INFO:Local step 4500, global step 71890: loss 0.0001
[2019-03-20 15:31:53,699] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 4500, global step 71893: learning rate 0.0010
[2019-03-20 15:31:53,848] A3C_AGENT_WORKER-Thread-17 INFO:Local step 4500, global step 71954: loss 0.0050
[2019-03-20 15:31:53,851] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 4500, global step 71955: learning rate 0.0010
[2019-03-20 15:31:53,870] A3C_AGENT_WORKER-Thread-15 INFO:Local step 4500, global step 71963: loss 0.0015
[2019-03-20 15:31:53,873] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 4500, global step 71964: learning rate 0.0010
[2019-03-20 15:31:53,885] A3C_AGENT_WORKER-Thread-21 INFO:Local step 4500, global step 71965: loss 0.0002
[2019-03-20 15:31:53,890] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 4500, global step 71966: learning rate 0.0010
[2019-03-20 15:31:53,901] A3C_AGENT_WORKER-Thread-3 INFO:Local step 4500, global step 71971: loss 0.0034
[2019-03-20 15:31:53,902] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 4500, global step 71971: learning rate 0.0010
[2019-03-20 15:31:53,965] A3C_AGENT_WORKER-Thread-14 INFO:Local step 4500, global step 71993: loss 0.0013
[2019-03-20 15:31:53,966] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 4500, global step 71994: learning rate 0.0010
[2019-03-20 15:31:54,000] A3C_AGENT_WORKER-Thread-12 INFO:Local step 4500, global step 72010: loss 0.0144
[2019-03-20 15:31:54,003] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 4500, global step 72010: learning rate 0.0010
[2019-03-20 15:31:54,030] A3C_AGENT_WORKER-Thread-13 INFO:Local step 4500, global step 72021: loss 0.0055
[2019-03-20 15:31:54,037] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 4500, global step 72022: learning rate 0.0010
[2019-03-20 15:31:54,040] A3C_AGENT_WORKER-Thread-11 INFO:Local step 4500, global step 72025: loss 0.0076
[2019-03-20 15:31:54,043] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 4500, global step 72025: learning rate 0.0010
[2019-03-20 15:31:54,047] A3C_AGENT_WORKER-Thread-18 INFO:Local step 4500, global step 72026: loss 0.0091
[2019-03-20 15:31:54,050] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 4500, global step 72026: learning rate 0.0010
[2019-03-20 15:31:54,273] A3C_AGENT_WORKER-Thread-9 INFO:Local step 4500, global step 72116: loss 0.0002
[2019-03-20 15:31:54,276] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 4500, global step 72116: learning rate 0.0010
[2019-03-20 15:31:54,345] A3C_AGENT_WORKER-Thread-22 INFO:Local step 4500, global step 72139: loss 0.0163
[2019-03-20 15:31:54,347] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 4500, global step 72140: learning rate 0.0010
[2019-03-20 15:31:54,441] A3C_AGENT_WORKER-Thread-20 INFO:Local step 4500, global step 72180: loss 0.0848
[2019-03-20 15:31:54,443] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 4500, global step 72181: learning rate 0.0010
[2019-03-20 15:31:54,835] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.5283162e-33 1.0000000e+00 2.9405961e-32 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-20 15:31:54,844] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2037
[2019-03-20 15:31:54,849] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.33333333333333, 95.83333333333334, 1.0, 2.0, 0.3901628728109616, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 441413.7162250432, 441413.7162250429, 124977.5258011693], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2706600.0000, 
sim time next is 2707200.0000, 
raw observation next is [19.8, 95.0, 1.0, 2.0, 0.4025271629625695, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 456707.5714443323, 456707.5714443323, 126983.2167137312], 
processed observation next is [0.0, 0.34782608695652173, 0.5363636363636364, 0.95, 1.0, 1.0, 0.25315895370321184, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16915095238678973, 0.16915095238678973, 0.3097151627164176], 
reward next is 0.6903, 
noisyNet noise sample is [array([0.93394625], dtype=float32), 1.2314168]. 
=============================================
[2019-03-20 15:31:56,160] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.0389462e-37 1.0000000e+00 3.8845321e-37 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-20 15:31:56,170] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5776
[2019-03-20 15:31:56,176] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.83333333333334, 61.66666666666666, 1.0, 2.0, 0.4550895150030776, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 519122.2280392279, 519122.2280392279, 135092.0012372903], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2735400.0000, 
sim time next is 2736000.0000, 
raw observation next is [26.0, 61.0, 1.0, 2.0, 0.4561877238488979, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 520407.1876095074, 520407.1876095074, 135296.675395883], 
processed observation next is [0.0, 0.6956521739130435, 0.8181818181818182, 0.61, 1.0, 1.0, 0.32023465481112234, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19274340281833607, 0.19274340281833607, 0.32999189120947076], 
reward next is 0.6700, 
noisyNet noise sample is [array([0.3972343], dtype=float32), -0.80687696]. 
=============================================
[2019-03-20 15:31:56,190] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[72.09836 ]
 [72.13117 ]
 [72.156395]
 [72.1781  ]
 [72.18466 ]], R is [[72.03263855]
 [71.9828186 ]
 [71.93398285]
 [71.8861084 ]
 [71.83922577]].
[2019-03-20 15:31:57,286] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.4198779e-29 1.0000000e+00 2.0597628e-31 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-20 15:31:57,293] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4945
[2019-03-20 15:31:57,297] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.16666666666667, 77.16666666666666, 1.0, 2.0, 0.418521006959308, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 475468.5241166329, 475468.5241166329, 128970.0945099055], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2760600.0000, 
sim time next is 2761200.0000, 
raw observation next is [22.0, 78.0, 1.0, 2.0, 0.416297274591592, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 472807.5207987658, 472807.5207987658, 128647.4236175954], 
processed observation next is [0.0, 1.0, 0.6363636363636364, 0.78, 1.0, 1.0, 0.27037159323948995, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1751138965921355, 0.1751138965921355, 0.31377420394535466], 
reward next is 0.6862, 
noisyNet noise sample is [array([1.1473854], dtype=float32), -1.1312448]. 
=============================================
[2019-03-20 15:31:59,625] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.6140869e-26 1.0000000e+00 2.1883997e-34 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-20 15:31:59,635] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2474
[2019-03-20 15:31:59,642] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1095175.695945719 W.
[2019-03-20 15:31:59,648] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.33333333333333, 68.33333333333333, 1.0, 2.0, 0.9598680664264279, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1095175.695945719, 1095175.69594572, 206573.0363613565], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2801400.0000, 
sim time next is 2802000.0000, 
raw observation next is [24.66666666666666, 67.66666666666667, 1.0, 2.0, 0.3302757787556577, 1.0, 1.0, 0.3302757787556577, 1.0, 1.0, 0.6679992327897668, 6.9112, 6.9112, 77.3421103, 1130388.278563713, 1130388.278563713, 267065.0039205933], 
processed observation next is [1.0, 0.43478260869565216, 0.7575757575757573, 0.6766666666666667, 1.0, 1.0, 0.16284472344457213, 1.0, 0.5, 0.16284472344457213, 1.0, 0.5, 0.525713189699667, 0.0, 0.0, 0.5085185399722538, 0.41866232539396775, 0.41866232539396775, 0.6513780583429105], 
reward next is 0.3486, 
noisyNet noise sample is [array([1.2503929], dtype=float32), -0.8607475]. 
=============================================
[2019-03-20 15:31:59,667] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[59.600468]
 [59.64782 ]
 [59.688496]
 [59.736687]
 [59.802284]], R is [[57.26008606]
 [57.18364716]
 [57.14463043]
 [57.12443161]
 [57.09637833]].
[2019-03-20 15:32:00,310] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-20 15:32:00,312] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-20 15:32:00,314] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-20 15:32:00,314] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-20 15:32:00,316] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-20 15:32:00,316] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-20 15:32:00,316] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-20 15:32:00,317] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-20 15:32:00,318] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-20 15:32:00,318] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-20 15:32:00,319] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-20 15:32:00,336] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run4
[2019-03-20 15:32:00,350] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run4
[2019-03-20 15:32:00,368] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run4
[2019-03-20 15:32:00,368] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run4
[2019-03-20 15:32:00,394] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/1/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run4
[2019-03-20 15:32:03,736] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.3069978], dtype=float32), 0.092398554]
[2019-03-20 15:32:03,738] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [16.66666666666666, 53.33333333333333, 1.0, 2.0, 0.5542815090488019, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7867709489099152, 7.074695815804109, 6.9112, 131.2085811414757, 1149991.760133994, 1059893.133274248, 203347.8354800134]
[2019-03-20 15:32:03,738] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-20 15:32:03,740] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.6325995e-28 1.0000000e+00 2.8999070e-29 6.9268520e-38 1.9849353e-35], sampled 0.5327985798743289
[2019-03-20 15:32:03,740] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1149991.760133994 W.
[2019-03-20 15:32:07,361] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.3069978], dtype=float32), 0.092398554]
[2019-03-20 15:32:07,363] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [14.0, 94.0, 1.0, 2.0, 0.2117971504057525, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 229957.7776970225, 229957.7776970222, 76366.8694500232]
[2019-03-20 15:32:07,363] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-20 15:32:07,365] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [7.7583755e-26 1.0000000e+00 2.2930780e-30 4.7334168e-34 5.7524462e-32], sampled 0.9689796243860541
[2019-03-20 15:32:07,473] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.3069978], dtype=float32), 0.092398554]
[2019-03-20 15:32:07,475] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [11.97714184833333, 84.31253762666667, 1.0, 2.0, 0.8010186913370124, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338756958594, 870126.4053785059, 870126.4053785059, 140758.7982360339]
[2019-03-20 15:32:07,477] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-20 15:32:07,480] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.7490212e-28 1.0000000e+00 9.4839215e-33 0.0000000e+00 1.6742872e-32], sampled 0.3651915215996041
